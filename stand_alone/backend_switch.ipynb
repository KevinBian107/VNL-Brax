{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MpkYHwCqk7W-"
   },
   "source": [
    "![Brax banner](https://raw.githubusercontent.com/google/brax/main/docs/img/brax_logo.gif)\n",
    "\n",
    "**A Colab runtime with GPU acceleration is required.** If you're using a CPU-only runtime, you can switch using the menu \"Runtime > Change runtime type\".\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YvyGCsgSCxHQ"
   },
   "source": [
    "# Install MuJoCo, MJX, and Brax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Xqo7pyX-n72M"
   },
   "outputs": [],
   "source": [
    "!pip install mujoco\n",
    "!pip install mujoco_mjx\n",
    "!pip install brax\n",
    "!pip install wandb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "cellView": "form",
    "id": "IbZxYDxzoz5R"
   },
   "outputs": [],
   "source": [
    "#@title Check if MuJoCo installation was successful\n",
    "import distutils.util\n",
    "import os\n",
    "import subprocess\n",
    "if subprocess.run('nvidia-smi').returncode:\n",
    "  raise RuntimeError(\n",
    "      'Cannot communicate with GPU. '\n",
    "      'Make sure you are using a GPU Colab runtime. '\n",
    "      'Go to the Runtime menu and select Choose runtime type.')\n",
    "\n",
    "# Add an ICD config so that glvnd can pick up the Nvidia EGL driver.\n",
    "# This is usually installed as part of an Nvidia driver package, but the Colab\n",
    "# kernel doesn't install its driver via APT, and as a result the ICD is missing.\n",
    "# (https://github.com/NVIDIA/libglvnd/blob/master/src/EGL/icd_enumeration.md)\n",
    "NVIDIA_ICD_CONFIG_PATH = '/usr/share/glvnd/egl_vendor.d/10_nvidia.json'\n",
    "if not os.path.exists(NVIDIA_ICD_CONFIG_PATH):\n",
    "  with open(NVIDIA_ICD_CONFIG_PATH, 'w') as f:\n",
    "    f.write(\"\"\"{\n",
    "    \"file_format_version\" : \"1.0.0\",\n",
    "    \"ICD\" : {\n",
    "        \"library_path\" : \"libEGL_nvidia.so.0\"\n",
    "    }\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Configure MuJoCo to use the EGL rendering backend (requires GPU)\n",
    "print('Setting environment variable to use GPU rendering:')\n",
    "%env MUJOCO_GL=egl\n",
    "\n",
    "try:\n",
    "  print('Checking that the installation succeeded:')\n",
    "  import mujoco\n",
    "  mujoco.MjModel.from_xml_string('<mujoco/>')\n",
    "except Exception as e:\n",
    "  raise e from RuntimeError(\n",
    "      'Something went wrong during installation. Check the shell output above '\n",
    "      'for more information.\\n'\n",
    "      'If using a hosted Colab runtime, make sure you enable GPU acceleration '\n",
    "      'by going to the Runtime menu and selecting \"Choose runtime type\".')\n",
    "\n",
    "print('Installation successful.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "T5f4w3Kq2X14"
   },
   "outputs": [],
   "source": [
    "#@title Import packages for plotting and creating graphics\n",
    "import time\n",
    "import itertools\n",
    "import numpy as np\n",
    "from typing import Callable, NamedTuple, Optional, Union, List\n",
    "\n",
    "# Graphics and plotting.\n",
    "print('Installing mediapy:')\n",
    "!command -v ffmpeg >/dev/null || (apt update && apt install -y ffmpeg)\n",
    "!pip install -q mediapy\n",
    "!pip install tqdm\n",
    "import mediapy as media\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "# More legible printing from numpy.\n",
    "np.set_printoptions(precision=3, suppress=True, linewidth=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ObF1UXrkb0Nd"
   },
   "outputs": [],
   "source": [
    "#@title Import MuJoCo, mjx, Brax, Wandb, & Visual Tools\n",
    "from datetime import datetime\n",
    "import functools\n",
    "from IPython.display import HTML, clear_output\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Sequence, Tuple, Union\n",
    "\n",
    "from brax import base\n",
    "from brax import actuator\n",
    "from brax import envs\n",
    "from brax import math\n",
    "from brax.base import Base, Motion, Transform\n",
    "from brax.envs.base import Env, MjxEnv, State, PipelineEnv\n",
    "from brax.mjx.base import State as MjxState\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.io import html, mjcf, model\n",
    "\n",
    "from etils import epath\n",
    "from flax import struct\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapy as media\n",
    "from ml_collections import config_dict\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "import wandb"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAv6WUVUm78k"
   },
   "source": [
    "# Training a Policy Description\n",
    "\n",
    "Running large batch physics simulation is useful for training RL policies. Here we demonstrate training RL policies with MJX using the RL library from [Brax](https://github.com/google/brax).\n",
    "\n",
    "Below, we implement the classic Humanoid environment using MJX and Brax. We inherit from the `MjxEnv` implementation in Brax so that we can step the physics with MJX while training with Brax RL implementations.\n",
    "\n",
    "***Continuous vs Discrete:*** Remanber that we are dealing with a continuous space, so all actions can be taken with decimal numbers, not discrete set of action space, it is a continuous set of action space.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "mXrzYtrfcG_B"
   },
   "source": [
    "## Making a Full Environment\n",
    "\n",
    "Environment defines a few things:\n",
    "1. agent (init)\n",
    "2. how the agent is rewarded (step)\n",
    "3. environment feedback of how the agent is doing (get_obs)\n",
    "4. resetting the environment (reset)\n",
    "\n",
    "The 3D bipedal robot is designed to simulate a human. It has a torso (abdomen) with a pair of legs and arms. The legs each consist of two links, and so the arms (representing the knees and elbows respectively). The goal of the environment is to walk forward as fast as possible without falling over."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xqwFW8JEihtB"
   },
   "source": [
    "###Action Space\n",
    "The agent take a 17-element vector for actions. The action space is a continuous `(action, ...)` all in `[-1, 1]`, where `action` represents the numerical torques applied at the hinge joints.\n",
    "\n",
    "  | Num | Action                                                                             | Control Min | Control Max | Name (in corresponding config)   | Joint | Unit         |\n",
    "  |-----|------------------------------------------------------------------------------------|-------------|-------------|----------------------------------|-------|--------------|\n",
    "  | 0   | Torque applied on the hinge in the y-coordinate of the abdomen                     | -1.0        | 1.0         | abdomen_yz                       | hinge | torque (N m) |\n",
    "  | 1   | Torque applied on the hinge in the z-coordinate of the abdomen                     | -1.0        | 1.0         | abdomen_yz                       | hinge | torque (N m) |\n",
    "  | 2   | Torque applied on the hinge in the x-coordinate of the abdomen                     | -1.0        | 1.0         | abdomen_x                        | hinge | torque (N m) |\n",
    "  | 3   | Torque applied on the rotor between torso/abdomen and the right hip (x-coordinate) | -1.0        | 1.0         | right_hip_xyz (right_thigh)      | hinge | torque (N m) |\n",
    "  | 4   | Torque applied on the rotor between torso/abdomen and the right hip (y-coordinate) | -1.0        | 1.0         | right_hip_xyz (right_thigh)      | hinge | torque (N m) |\n",
    "  | 5   | Torque applied on the rotor between torso/abdomen and the right hip (z-coordinate) | -1.0        | 1.0         | right_hip_xyz (right_thigh)      | hinge | torque (N m) |\n",
    "  | 6   | Torque applied on the rotor between the right hip/thigh and the right shin         | -1.0        | 1.0         | right_knee                       | hinge | torque (N m) |\n",
    "  | 7   | Torque applied on the rotor between torso/abdomen and the left hip (x-coordinate)  | -1.0        | 1.0         | left_hip_xyz (left_thigh)        | hinge | torque (N m) |\n",
    "  | 8   | Torque applied on the rotor between torso/abdomen and the left hip (y-coordinate)  | -1.0        | 1.0         | left_hip_xyz (left_thigh)        | hinge | torque (N m) |\n",
    "  | 9   | Torque applied on the rotor between torso/abdomen and the left hip (z-coordinate)  | -1.0        | 1.0         | left_hip_xyz (left_thigh)        | hinge | torque (N m) |\n",
    "  | 10  | Torque applied on the rotor between the left hip/thigh and the left shin           | -1.0        | 1.0         | left_knee                        | hinge | torque (N m) |\n",
    "  | 11  | Torque applied on the rotor between the torso and right upper arm (coordinate -1)  | -1.0        | 1.0         | right_shoulder12                 | hinge | torque (N m) |\n",
    "  | 12  | Torque applied on the rotor between the torso and right upper arm (coordinate -2)  | -1.0        | 1.0         | right_shoulder12                 | hinge | torque (N m) |\n",
    "  | 13  | Torque applied on the rotor between the right upper arm and right lower arm        | -1.0        | 1.0         | right_elbow                      | hinge | torque (N m) |\n",
    "  | 14  | Torque applied on the rotor between the torso and left upper arm (coordinate -1)   | -1.0        | 1.0         | left_shoulder12                  | hinge | torque (N m) |\n",
    "  | 15  | Torque applied on the rotor between the torso and left upper arm (coordinate -2)   | -1.0        | 1.0         | left_shoulder12                  | hinge | torque (N m) |\n",
    "  | 16  | Torque applied on the rotor between the left upper arm and left lower arm          | -1.0        | 1.0         | left_elbow                       | hinge | torque (N m) |"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8tEh1airintr"
   },
   "source": [
    "### Observation Space\n",
    "The state space consists of positional values of different body parts of the Humanoid, followed by the velocities of those individual parts (their derivatives) with all the positions ordered before all the velocities. The observation is a `ndarray` with shape `(376,)` where the elements correspond to the following:\n",
    "\n",
    "  | Num | Observation                                                                                                     | Min  | Max | Name (in corresponding config)   | Joint | Unit                     |\n",
    "  |-----|-----------------------------------------------------------------------------------------------------------------|------|-----|----------------------------------|-------|--------------------------|\n",
    "  | 0   | z-coordinate of the torso (centre)                                                                              | -Inf | Inf | root                             | free  | position (m)             |\n",
    "  | 1   | w-orientation of the torso (centre)                                                                             | -Inf | Inf | root                             | free  | angle (rad)              |\n",
    "  | 2   | x-orientation of the torso (centre)                                                                             | -Inf | Inf | root                             | free  | angle (rad)              |\n",
    "  | 3   | y-orientation of the torso (centre)                                                                             | -Inf | Inf | root                             | free  | angle (rad)              |\n",
    "  | 4   | z-orientation of the torso (centre)                                                                             | -Inf | Inf | root                             | free  | angle (rad)              |\n",
    "  | 5   | z-angle of the abdomen (in lower_waist)                                                                         | -Inf | Inf | abdomen_yz                       | hinge | angle (rad)              |\n",
    "  | 6   | y-angle of the abdomen (in lower_waist)                                                                         | -Inf | Inf | abdomen_yy                       | hinge | angle (rad)              |\n",
    "  | 7   | x-angle of the abdomen (in pelvis)                                                                              | -Inf | Inf | abdomen_x                        | hinge | angle (rad)              |\n",
    "  | 8   | x-coordinate of angle between pelvis and right hip (in right_thigh)                                             | -Inf | Inf | right_hip_xyz                    | hinge | angle (rad)              |\n",
    "  | 9   | y-coordinate of angle between pelvis and right hip (in right_thigh)                                             | -Inf | Inf | right_hip_xyz                    | hinge | angle (rad)              |\n",
    "  | 10  | z-coordinate of angle between pelvis and right hip (in right_thigh)                                             | -Inf | Inf | right_hip_xyz                    | hinge | angle (rad)              |\n",
    "  | 11  | angle between right hip and the right shin (in right_knee)                                                      | -Inf | Inf | right_knee                       | hinge | angle (rad)              |\n",
    "  | 12  | x-coordinate of angle between pelvis and left hip (in left_thigh)                                               | -Inf | Inf | left_hip_xyz                     | hinge | angle (rad)              |\n",
    "  | 13  | y-coordinate of angle between pelvis and left hip (in left_thigh)                                               | -Inf | Inf | left_hip_xyz                     | hinge | angle (rad)              |\n",
    "  | 14  | z-coordinate of angle between pelvis and left hip (in left_thigh)                                               | -Inf | Inf | left_hip_xyz                     | hinge | angle (rad)              |\n",
    "  | 15  | angle between left hip and the left shin (in left_knee)                                                         | -Inf | Inf | left_knee                        | hinge | angle (rad)              |\n",
    "  | 16  | coordinate-1 (multi-axis) angle between torso and right arm (in right_upper_arm)                                | -Inf | Inf | right_shoulder12                 | hinge | angle (rad)              |\n",
    "  | 17  | coordinate-2 (multi-axis) angle between torso and right arm (in right_upper_arm)                                | -Inf | Inf | right_shoulder12                 | hinge | angle (rad)              |\n",
    "  | 18  | angle between right upper arm and right_lower_arm                                                               | -Inf | Inf | right_elbow                      | hinge | angle (rad)              |\n",
    "  | 19  | coordinate-1 (multi-axis) angle between torso and left arm (in left_upper_arm)                                  | -Inf | Inf | left_shoulder12                  | hinge | angle (rad)              |\n",
    "  | 20  | coordinate-2 (multi-axis) angle between torso and left arm (in left_upper_arm)                                  | -Inf | Inf | left_shoulder12                  | hinge | angle (rad)              |\n",
    "  | 21  | angle between left upper arm and left_lower_arm                                                                 | -Inf | Inf | left_elbow                       | hinge | angle (rad)              |\n",
    "  | 22  | x-coordinate velocity of the torso (centre)                                                                     | -Inf | Inf | root                             | free  | velocity (m/s)           |\n",
    "  | 23  | y-coordinate velocity of the torso (centre)                                                                     | -Inf | Inf | root                             | free  | velocity (m/s)           |\n",
    "  | 24  | z-coordinate velocity of the torso (centre)                                                                     | -Inf | Inf | root                             | free  | velocity (m/s)           |\n",
    "  | 25  | x-coordinate angular velocity of the torso (centre)                                                             | -Inf | Inf | root                             | free  | angular velocity (rad/s) |\n",
    "  | 26  | y-coordinate angular velocity of the torso (centre)                                                             | -Inf | Inf | root                             | free  | angular velocity (rad/s) |\n",
    "  | 27  | z-coordinate angular velocity of the torso (centre)                                                             | -Inf | Inf | root                             | free  | angular velocity (rad/s) |\n",
    "  | 28  | z-coordinate of angular velocity of the abdomen (in lower_waist)                                                | -Inf | Inf | abdomen_z                        | hinge | angular velocity (rad/s) |\n",
    "  | 29  | y-coordinate of angular velocity of the abdomen (in lower_waist)                                                | -Inf | Inf | abdomen_y                        | hinge | angular velocity (rad/s) |\n",
    "  | 30  | x-coordinate of angular velocity of the abdomen (in pelvis)                                                     | -Inf | Inf | abdomen_x                        | hinge | angular velocity (rad/s) |\n",
    "  | 31  | x-coordinate of the angular velocity of the angle between pelvis and right hip (in right_thigh)                 | -Inf | Inf | right_hip_xyz                    | hinge | angular velocity (rad/s) |\n",
    "  | 32  | y-coordinate of the angular velocity of the angle between pelvis and right hip (in right_thigh)                 | -Inf | Inf | right_hip_z                      | hinge | angular velocity (rad/s) |\n",
    "  | 33  | z-coordinate of the angular velocity of the angle between pelvis and right hip (in right_thigh)                 | -Inf | Inf | right_hip_y                      | hinge | angular velocity (rad/s) |\n",
    "  | 34  | angular velocity of the angle between right hip and the right shin (in right_knee)                              | -Inf | Inf | right_knee                       | hinge | angular velocity (rad/s) |\n",
    "  | 35  | x-coordinate of the angular velocity of the angle between pelvis and left hip (in left_thigh)                   | -Inf | Inf | left_hip_xyz                     | hinge | angular velocity (rad/s) |\n",
    "  | 36  | y-coordinate of the angular velocity of the angle between pelvis and left hip (in left_thigh)                   | -Inf | Inf | left_hip_z                       | hinge | angular velocity (rad/s) |\n",
    "  | 37  | z-coordinate of the angular velocity of the angle between pelvis and left hip (in left_thigh)                   | -Inf | Inf | left_hip_y                       | hinge | angular velocity (rad/s) |\n",
    "  | 38  | angular velocity of the angle between left hip and the left shin (in left_knee)                                 | -Inf | Inf | left_knee                        | hinge | angular velocity (rad/s) |\n",
    "  | 39  | coordinate-1 (multi-axis) of the angular velocity of the angle between torso and right arm (in right_upper_arm) | -Inf | Inf | right_shoulder12                 | hinge | angular velocity (rad/s) |\n",
    "  | 40  | coordinate-2 (multi-axis) of the angular velocity of the angle between torso and right arm (in right_upper_arm) | -Inf | Inf | right_shoulder12                 | hinge | angular velocity (rad/s) |\n",
    "  | 41  | angular velocity of the angle between right upper arm and right_lower_arm                                       | -Inf | Inf | right_elbow                      | hinge | angular velocity (rad/s) |\n",
    "  | 42  | coordinate-1 (multi-axis) of the angular velocity of the angle between torso and left arm (in left_upper_arm)   | -Inf | Inf | left_shoulder12                  | hinge | angular velocity (rad/s) |\n",
    "  | 43  | coordinate-2 (multi-axis) of the angular velocity of the angle between torso and left arm (in left_upper_arm)   | -Inf | Inf | left_shoulder12                  | hinge | angular velocity (rad/s) |\n",
    "  | 44  | angular velocity of the angle between left upper arm and left_lower_arm                                         | -Inf | Inf | left_elbow                       | hinge | angular velocity (rad/s) |\n",
    "\n",
    "  Additionally, after all the positional and velocity based values in the table,\n",
    "  the state_space consists of (in order):\n",
    "\n",
    "  1. *cinert:* Mass and inertia of a single rigid body relative to the center of mass (this is an intermediate result of transition). It has shape 14*10 (*nbody * 10*) and hence adds to another 140 elements in the state space.\n",
    "\n",
    "  2. *cvel:* Center of mass based velocity. It has shape 14 * 6 (*nbody * 6*) and hence adds another 84 elements in the state space\n",
    "  \n",
    "  3. *qfrc_actuator:* Constraint force generated as the actuator force. This has shape `(23,)`  *(nv * 1)* and hence adds another 23 elements to the state space.\n",
    "\n",
    "  The (x,y,z) coordinates are translational DOFs while the orientations are\n",
    "  rotational DOFs expressed as quaternions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Dc4u8Q_i4x-"
   },
   "source": [
    "### Rewards\n",
    "The reward consists of three parts:\n",
    "- *reward_alive*: Every timestep that the humanoid is alive, it gets a reward of 5.\n",
    "\n",
    "- *forward_reward*: A reward of walking forward which is measured as *1.25 * (average center of mass before action - average center of mass after action) / dt*. *dt* is the time between actions - the default *dt = 0.015*. This reward would be positive if the humanoid walks forward (right) desired. The calculation for the center of mass is defined in the `.py` file for the Humanoid.\n",
    "\n",
    "- *reward_quadctrl*: A negative reward for penalising the humanoid if it has too large of a control force. If there are *nu* actuators/controls, then the control has shape  `nu x 1`. It is measured as *0.1 **x** sum(control<sup>2</sup>)*.\n",
    "\n",
    "### Starting State\n",
    "All observations start in state (0.0, 0.0,  1.4, 1.0, 0.0  ... 0.0) with a uniform noise in the range of [-0.01, 0.01] added to the positional and velocity values (values in the table) for stochasticity. Note that the initial z coordinate is intentionally selected to be high, thereby indicating a standing up humanoid. The initial orientation is designed to make it face forward as well.\n",
    "\n",
    "### Episode Termination\n",
    "The episode terminates when any of the following happens:\n",
    "\n",
    "1. The episode duration reaches a 1000 timesteps\n",
    "2. The z-coordinate of the torso (index 0 in state space OR index 2 in the table) is **not** in the range `[0.8, 2.1]` (the humanoid has fallen or is about to fall beyond recovery)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5RRsZlGXlJ0l"
   },
   "source": [
    "# Into Backend Env Setting\n",
    "Brax offers three distinct physics pipelines that are easy to swap, all of them are in the parent class of `PipelineEnv`. Everything is implemented in JAX, but the difference being one is implemented directly in brax and the other is an extension of commuinicating with MuJCo (Multi-Joint-Contact):\n",
    "\n",
    "* ***Generalized*** calculates motion in generalized coordinates using the same accurate robot dynamics algorithms as MuJoCo.\n",
    "* ***Positional*** uses Position Based Dynamics, a fast but stable method of resolving joint and collision constraints.\n",
    "* ***Spring*** provides fast and cheap simulation for rapid experimentation, using simple impulse-based methods often found in video games.\n",
    "\n",
    "Physics pipelines typically become less accurate and unstable as step size grows.  Try fiddling with step size to get a feel for each pipeline's accuracy and stability tradeoffs.\n",
    "\n",
    "All of the above are backends implemented using JAX and implemented by Brax. However, Brax also provides an alternative routes of backends.\n",
    "\n",
    "* ***mjx*** is the JAX adapted version of MujoCo implemented by the brax team, it comes from a different parent class of `MjxEnv` instead of the `PipelineEnv` as the other three backends. ***It is a linakge to the MuJoCo backends, not much implemented. Brax 'mjx' backend is configured to use MuJoCo as an underlaying simulator engine***.\n",
    "\n",
    "The Environment is separated to a few stages:\n",
    "1. Lowest Level: Connection between bodies with no actions. This is the physical constain of the body\n",
    "2. Gym Like Environment: Book keeping of data beyond the current satge.\n",
    "\n",
    "***Observation:***\n",
    "1. It seems like the `PipelineEnv` class is caplabe of storing more piplines state, the HTML render would reach recursion upper limit when using the `MjxEnv` class but not the `PipelineEnv` Class.\n",
    "3. Brax backend doesn't perform as well, but it is computationally much more efficient.\n",
    "2. Not sure if generalized coordinate can take in Mujoco XML files as mjx backends does."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "1xW8ZqtqlXqK"
   },
   "source": [
    "# Training Policy with mjx/pipeline  Env"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-T_z0pMyi67f"
   },
   "source": [
    "### Humanoid Env w/ mjx Backend"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mtGMYNLE3QJN"
   },
   "outputs": [],
   "source": [
    "class Humanoid(MjxEnv):\n",
    "  '''\n",
    "  This is greatly coustomizable of what reward you want to give: reward engineering\n",
    "  '''\n",
    "  def __init__(\n",
    "      self,\n",
    "      forward_reward_weight=1.25,\n",
    "      ctrl_cost_weight=0.1,\n",
    "      healthy_reward=5.0,\n",
    "      terminate_when_unhealthy=True,\n",
    "      healthy_z_range=(1.0, 1.5),\n",
    "      reset_noise_scale=1e-2,\n",
    "      exclude_current_positions_from_observation=True,\n",
    "      **kwargs,):\n",
    "    '''\n",
    "    Defining initilization of the agent\n",
    "    '''\n",
    "\n",
    "    path = epath.Path(epath.resource_path('mujoco')) / ('mjx/benchmark/model/humanoid')\n",
    "    mj_model = mujoco.MjModel.from_xml_path((path / 'humanoid.xml').as_posix())\n",
    "\n",
    "    # solver is an optimization system\n",
    "    mj_model.opt.solver = mujoco.mjtSolver.mjSOL_CG\n",
    "\n",
    "    #Iterations for solver\n",
    "    mj_model.opt.iterations = 6\n",
    "    mj_model.opt.ls_iterations = 6\n",
    "\n",
    "    # Defult framne to be 5, but can self define in kwargs\n",
    "    physics_steps_per_control_step = 5\n",
    "    kwargs['n_frames'] = kwargs.get(\n",
    "        'n_frames', physics_steps_per_control_step)\n",
    "\n",
    "    # Parents inheritence from MjxEnv class\n",
    "    super().__init__(model=mj_model, **kwargs)\n",
    "\n",
    "    # Global vraiable for later calling them\n",
    "    self._forward_reward_weight = forward_reward_weight\n",
    "    self._ctrl_cost_weight = ctrl_cost_weight\n",
    "    self._healthy_reward = healthy_reward\n",
    "    self._terminate_when_unhealthy = terminate_when_unhealthy\n",
    "    self._healthy_z_range = healthy_z_range\n",
    "    self._reset_noise_scale = reset_noise_scale\n",
    "    self._exclude_current_positions_from_observation = (exclude_current_positions_from_observation)\n",
    "\n",
    "  def reset(self, rng: jp.ndarray) -> State:\n",
    "    \"\"\"Resets the environment to an initial state.\"\"\"\n",
    "\n",
    "    #Creating randome keys\n",
    "    #rng = random number generator key for starting random initiation\n",
    "    rng, rng1, rng2 = jax.random.split(rng, 3)\n",
    "\n",
    "    low, hi = -self._reset_noise_scale, self._reset_noise_scale\n",
    "\n",
    "    #Vectors of generalized joint position in the configuration space\n",
    "    qpos = self.sys.qpos0 + jax.random.uniform(\n",
    "        rng1, (self.sys.nq,), minval=low, maxval=hi\n",
    "    )\n",
    "\n",
    "    #Vectors of generalized joint velocities in the configuration space\n",
    "    qvel = jax.random.uniform(\n",
    "        rng2, (self.sys.nv,), minval=low, maxval=hi\n",
    "    )\n",
    "\n",
    "    data = self.pipeline_init(qpos, qvel)\n",
    "\n",
    "    #Reset everything\n",
    "    obs = self._get_obs(data.data, jp.zeros(self.sys.nu))\n",
    "    reward, done, zero = jp.zeros(3)\n",
    "    metrics = {\n",
    "        'forward_reward': zero,\n",
    "        'reward_linvel': zero,\n",
    "        'reward_quadctrl': zero,\n",
    "        'reward_alive': zero,\n",
    "        'x_position': zero,\n",
    "        'y_position': zero,\n",
    "        'distance_from_origin': zero,\n",
    "        'x_velocity': zero,\n",
    "        'y_velocity': zero,\n",
    "    }\n",
    "    return State(data, obs, reward, done, metrics)\n",
    "\n",
    "  def step(self, state: State, action: jp.ndarray) -> State:\n",
    "    \"\"\"Runs one timestep of the environment's dynamics.\"\"\"\n",
    "    #Previous Pipeline\n",
    "    data0 = state.pipeline_state\n",
    "\n",
    "    #Current pipeline state, step 1\n",
    "    data = self.pipeline_step(data0, action)\n",
    "\n",
    "    #Running forward (Velocity)\n",
    "    com_before = data0.data.subtree_com[1]\n",
    "    com_after = data.data.subtree_com[1]\n",
    "    velocity = (com_after - com_before) / self.dt\n",
    "    forward_reward = self._forward_reward_weight * velocity[0] * 2\n",
    "\n",
    "    #Height being healthy\n",
    "    min_z, max_z = self._healthy_z_range\n",
    "    is_healthy = jp.where(data.q[2] < min_z, 0.0, 1.0)\n",
    "    is_healthy = jp.where(data.q[2] > max_z, 0.0, is_healthy)\n",
    "\n",
    "    #Termination condition\n",
    "    if self._terminate_when_unhealthy:\n",
    "      healthy_reward = self._healthy_reward\n",
    "    else:\n",
    "      healthy_reward = self._healthy_reward * is_healthy\n",
    "\n",
    "    #Control quad cost\n",
    "    ctrl_cost = self._ctrl_cost_weight * jp.sum(jp.square(action))\n",
    "\n",
    "    #Feedback from env\n",
    "    obs = self._get_obs(data.data, action)\n",
    "    reward = forward_reward + healthy_reward - ctrl_cost\n",
    "\n",
    "    #Termination State\n",
    "    done = 1.0 - is_healthy if self._terminate_when_unhealthy else 0.0\n",
    "\n",
    "    state.metrics.update(\n",
    "        forward_reward=forward_reward,\n",
    "        reward_linvel=forward_reward,\n",
    "        reward_quadctrl=-ctrl_cost,\n",
    "        reward_alive=healthy_reward,\n",
    "        x_position=com_after[0],\n",
    "        y_position=com_after[1],\n",
    "        distance_from_origin=jp.linalg.norm(com_after),\n",
    "        x_velocity=velocity[0],\n",
    "        y_velocity=velocity[1],\n",
    "    )\n",
    "\n",
    "    return state.replace(\n",
    "        pipeline_state=data, obs=obs, reward=reward, done=done\n",
    "    )\n",
    "\n",
    "  def _get_obs(self, data: mjx.Data, action: jp.ndarray) -> jp.ndarray:\n",
    "    \"\"\"Observes humanoid body position, velocities, and angles.\"\"\"\n",
    "    position = data.qpos\n",
    "    if self._exclude_current_positions_from_observation:\n",
    "      position = position[2:]\n",
    "\n",
    "    # external_contact_forces are excluded\n",
    "    # environment observation described later\n",
    "    return jp.concatenate([\n",
    "        position,\n",
    "        data.qvel,\n",
    "        data.cinert[1:].ravel(),\n",
    "        data.cvel[1:].ravel(),\n",
    "        data.qfrc_actuator,\n",
    "    ])\n",
    "\n",
    "# Registering the environment setup in env as humanoid_mjx\n",
    "envs.register_environment('humanoid_mjx', Humanoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "8wGy__pvfBGB"
   },
   "source": [
    "#### Note: Obs_tracks\n",
    "Observation Components:\n",
    "\n",
    "1. ***Position***: Extracts the positions (qpos) of the humanoid body. (If self._exclude_current_positions_from_observation is True, it excludes the first two elements of the position vector. This could be useful if you want to exclude certain position information from the observation.)\n",
    "\n",
    "2. ***Velocities***: Appends the velocities (qvel) of the humanoid body.\n",
    "\n",
    "3. ***Inertia Matrix***: Appends the inertia matrix (cinert) excluding the first row. (This matrix represents the inertia of the body segments.) Inertia helps to examine the distribution of mass in the humanoid and then calculates the relatyionship it would have with the forces that may be generated to accelerate or deaccelerate\n",
    "\n",
    "4. ***Velocity of Inertia***: Appends the velocity of the inertia matrix (cvel) excluding the first row.\n",
    "\n",
    "5. ***Actuator Forces***: Appends the actuator forces (qfrc_actuator). Actuators are typically modeled as components that generate forces or torques to drive the movement of joints in a simulated robotic system. These forces or torques are applied to the joints of the simulated body, affecting its motion."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RAu9xZGDvC0G"
   },
   "source": [
    "### Humanoid Env w/ Pipeline Setup\n",
    "\n",
    "Generalized and Positional `PipelineEnv` class logs everything into the Class \"[State](https://github.com/google/brax/blob/main/brax/generalized/base.py)\" for saving (link to the generalized documentation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ZcFmidsPq2bX"
   },
   "outputs": [],
   "source": [
    "class Humanoid(PipelineEnv):\n",
    "  def __init__(\n",
    "      self,\n",
    "      forward_reward_weight=1.25,\n",
    "      ctrl_cost_weight=0.1,\n",
    "      healthy_reward=5.0,\n",
    "      terminate_when_unhealthy=False,\n",
    "      healthy_z_range=(1.0, 2.0),\n",
    "      reset_noise_scale=1e-2,\n",
    "      exclude_current_positions_from_observation=True,\n",
    "      backend='generalized',\n",
    "      **kwargs,\n",
    "  ):\n",
    "    path = epath.resource_path('brax') / 'envs/assets/humanoid.xml'\n",
    "    sys = mjcf.load(path)\n",
    "\n",
    "    n_frames = 5\n",
    "\n",
    "    if backend in ['spring', 'positional']:\n",
    "      # time step adjusted\n",
    "      sys = sys.replace(dt=0.0015)\n",
    "      # more frames per time step\n",
    "      n_frames = 10\n",
    "\n",
    "      # how many torque is produced by the acutator given a specific input velocity\n",
    "      gear = jp.array([\n",
    "          350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0, 350.0,\n",
    "          350.0, 100.0, 100.0, 100.0, 100.0, 100.0, 100.0])  # pyformat: disable\n",
    "      sys = sys.replace(actuator=sys.actuator.replace(gear=gear))\n",
    "\n",
    "    if backend == 'mjx':\n",
    "      sys._model.opt.solver = mujoco.mjtSolver.mjSOL_NEWTON\n",
    "      sys._model.opt.disableflags = mujoco.mjtDisableBit.mjDSBL_EULERDAMP\n",
    "      sys._model.opt.iterations = 1\n",
    "      sys._model.opt.ls_iterations = 4\n",
    "\n",
    "    kwargs['n_frames'] = kwargs.get('n_frames', n_frames)\n",
    "\n",
    "    super().__init__(sys=sys, backend=backend, **kwargs)\n",
    "\n",
    "    self._forward_reward_weight = forward_reward_weight\n",
    "    self._ctrl_cost_weight = ctrl_cost_weight\n",
    "    self._healthy_reward = healthy_reward\n",
    "    self._terminate_when_unhealthy = terminate_when_unhealthy\n",
    "    self._healthy_z_range = healthy_z_range\n",
    "    self._reset_noise_scale = reset_noise_scale\n",
    "    self._exclude_current_positions_from_observation = (\n",
    "        exclude_current_positions_from_observation\n",
    "    )\n",
    "\n",
    "  def reset(self, rng: jax.Array) -> State:\n",
    "    \"\"\"Resets the environment to an initial state.\"\"\"\n",
    "    rng, rng1, rng2 = jax.random.split(rng, 3)\n",
    "\n",
    "    low, hi = -self._reset_noise_scale, self._reset_noise_scale\n",
    "    qpos = self.sys.init_q + jax.random.uniform(\n",
    "        rng1, (self.sys.q_size(),), minval=low, maxval=hi\n",
    "    )\n",
    "    qvel = jax.random.uniform(\n",
    "        rng2, (self.sys.qd_size(),), minval=low, maxval=hi\n",
    "    )\n",
    "\n",
    "    pipeline_state = self.pipeline_init(qpos, qvel)\n",
    "\n",
    "    obs = self._get_obs(pipeline_state, jp.zeros(self.sys.act_size()))\n",
    "    reward, done, zero = jp.zeros(3)\n",
    "    metrics = {\n",
    "        'forward_reward': zero,\n",
    "        'reward_linvel': zero,\n",
    "        'reward_quadctrl': zero,\n",
    "        'reward_alive': zero,\n",
    "        'x_position': zero,\n",
    "        'y_position': zero,\n",
    "        'distance_from_origin': zero,\n",
    "        'x_velocity': zero,\n",
    "        'y_velocity': zero,\n",
    "    }\n",
    "    return State(pipeline_state, obs, reward, done, metrics)\n",
    "\n",
    "  def step(self, state: State, action: jax.Array) -> State:\n",
    "    \"\"\"Runs one timestep of the environment's dynamics.\"\"\"\n",
    "\n",
    "    pipeline_state0 = state.pipeline_state\n",
    "    pipeline_state = self.pipeline_step(pipeline_state0, action)\n",
    "\n",
    "    com_before, *_ = self._com(pipeline_state0)\n",
    "    com_after, *_ = self._com(pipeline_state)\n",
    "    velocity = (com_after - com_before) / self.dt\n",
    "    forward_reward = self._forward_reward_weight * 0.5 * velocity[0]\n",
    "\n",
    "    min_z, max_z = self._healthy_z_range\n",
    "    is_healthy = jp.where(pipeline_state.x.pos[0, 2] < min_z, 0.0, 1.0)\n",
    "    is_healthy = jp.where(pipeline_state.x.pos[0, 2] > max_z, 0.0, is_healthy)\n",
    "\n",
    "    if self._terminate_when_unhealthy:\n",
    "      healthy_reward = self._healthy_reward\n",
    "    else:\n",
    "      healthy_reward = self._healthy_reward * is_healthy\n",
    "\n",
    "    ctrl_cost = self._ctrl_cost_weight * jp.sum(jp.square(action))\n",
    "\n",
    "    obs = self._get_obs(pipeline_state, action)\n",
    "\n",
    "    reward = forward_reward + healthy_reward - ctrl_cost\n",
    "\n",
    "    done = 1.0 - is_healthy if self._terminate_when_unhealthy else 0.0\n",
    "\n",
    "    state.metrics.update(\n",
    "        forward_reward=forward_reward,\n",
    "        reward_linvel=forward_reward,\n",
    "        reward_quadctrl=-ctrl_cost,\n",
    "        reward_alive=healthy_reward,\n",
    "        x_position=com_after[0],\n",
    "        y_position=com_after[1],\n",
    "        distance_from_origin=jp.linalg.norm(com_after),\n",
    "        x_velocity=velocity[0],\n",
    "        y_velocity=velocity[1],\n",
    "    )\n",
    "\n",
    "    return state.replace(\n",
    "        pipeline_state=pipeline_state, obs=obs, reward=reward, done=done\n",
    "    )\n",
    "\n",
    "  def _get_obs(\n",
    "      self, pipeline_state: base.State, action: jax.Array\n",
    "  ) -> jax.Array:\n",
    "    \"\"\"Observes humanoid body position, velocities, and angles.\"\"\"\n",
    "    position = pipeline_state.q\n",
    "    velocity = pipeline_state.qd\n",
    "\n",
    "    if self._exclude_current_positions_from_observation:\n",
    "      position = position[2:]\n",
    "\n",
    "    com, inertia, mass_sum, x_i = self._com(pipeline_state)\n",
    "    cinr = x_i.replace(pos=x_i.pos - com).vmap().do(inertia)\n",
    "    com_inertia = jp.hstack(\n",
    "        [cinr.i.reshape((cinr.i.shape[0], -1)), inertia.mass[:, None]]\n",
    "    )\n",
    "\n",
    "    xd_i = (\n",
    "        base.Transform.create(pos=x_i.pos - pipeline_state.x.pos)\n",
    "        .vmap()\n",
    "        .do(pipeline_state.xd)\n",
    "    )\n",
    "    com_vel = inertia.mass[:, None] * xd_i.vel / mass_sum\n",
    "    com_ang = xd_i.ang\n",
    "    com_velocity = jp.hstack([com_vel, com_ang])\n",
    "\n",
    "    qfrc_actuator = actuator.to_tau(\n",
    "        self.sys, action, pipeline_state.q, pipeline_state.qd)\n",
    "\n",
    "    # external_contact_forces are excluded\n",
    "    return jp.concatenate([\n",
    "        position,\n",
    "        velocity,\n",
    "        com_inertia.ravel(),\n",
    "        com_velocity.ravel(),\n",
    "        qfrc_actuator,\n",
    "    ])\n",
    "\n",
    "  # Chaging Center of Mass to more customized standard\n",
    "  def _com(self, pipeline_state: base.State) -> jax.Array:\n",
    "    inertia = self.sys.link.inertia\n",
    "    if self.backend in ['spring', 'positional']:\n",
    "      inertia = inertia.replace(\n",
    "          i=jax.vmap(jp.diag)(\n",
    "              jax.vmap(jp.diagonal)(inertia.i)\n",
    "              ** (1 - self.sys.spring_inertia_scale)\n",
    "          ),\n",
    "          mass=inertia.mass ** (1 - self.sys.spring_mass_scale),\n",
    "      )\n",
    "    mass_sum = jp.sum(inertia.mass)\n",
    "\n",
    "    x_i = pipeline_state.x.vmap().do(inertia.transform)\n",
    "    com = (\n",
    "        jp.sum(jax.vmap(jp.multiply)(inertia.mass, x_i.pos), axis=0) / mass_sum\n",
    "    )\n",
    "\n",
    "    return com, inertia, mass_sum, x_i  # pytype: disable=bad-return-type  # jax-ndarray\n",
    "\n",
    "envs.register_environment('humanoid_generalized', Humanoid)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "M3FlDU1CWS6T"
   },
   "source": [
    "## For More Robust Policy\n",
    "## Domain Randomization\n",
    "In Brax, domain randomization is a technique used in reinforcement learning to improve the generalization ability of a learned policy across diverse environments. The idea is to train an agent in a variety of simulated environments with different randomized parameters, such as physical properties, dynamics, or visual appearance. By exposing the agent to this diversity during training, it is expected to learn a more robust policy that can adapt well to novel environments.\n",
    "\n",
    "***It is worth notice that domain randomization only works for mjx models.***\n",
    "\n",
    "## Network Fatcory\n",
    "Network Factory allows you to change the already implemented PPO's neurla network layer for achieveing different purposes of training. This may improve performance, but also a big cost on time complexity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "jjswMco7WcVL"
   },
   "outputs": [],
   "source": [
    "# @title Domain Randomization & Network Factory\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "make_networks_factory = functools.partial(ppo_networks.make_ppo_networks, policy_hidden_layer_sizes=(64, 64, 64, 64))\n",
    "\n",
    "\n",
    "def domain_randomize(sys, rng):\n",
    "  \"\"\"Randomizes the mjx.Model.\"\"\"\n",
    "  #Todo: add domain randomization functions\n",
    "\n",
    "  @jax.vmap\n",
    "  def rand(rng):\n",
    "    _, key = jax.random.split(rng, 2)\n",
    "\n",
    "    # friction\n",
    "    friction = jax.random.uniform(key, (1,), minval=0.6, maxval=1.4)\n",
    "    friction = sys.geom_friction.at[:, 0].set(friction)\n",
    "\n",
    "    # actuator\n",
    "    _, key = jax.random.split(key, 2)\n",
    "    gain_range = (-5, 5)\n",
    "    param = jax.random.uniform(\n",
    "        key, (1,), minval=gain_range[0], maxval=gain_range[1]\n",
    "    ) + sys.actuator_gainprm[:, 0]\n",
    "    gain = sys.actuator_gainprm.at[:, 0].set(param)\n",
    "    bias = sys.actuator_biasprm.at[:, 1].set(-param)\n",
    "    return friction, gain, bias\n",
    "\n",
    "  friction, gain, bias = rand(rng)\n",
    "\n",
    "  in_axes = jax.tree_map(lambda x: None, sys)\n",
    "  in_axes = in_axes.tree_replace({\n",
    "      'geom_friction': 0,\n",
    "      'actuator_gainprm': 0,\n",
    "      'actuator_biasprm': 0,\n",
    "  })\n",
    "\n",
    "  sys = sys.tree_replace({\n",
    "      'geom_friction': friction,\n",
    "      'actuator_gainprm': gain,\n",
    "      'actuator_biasprm': bias,\n",
    "  })\n",
    "\n",
    "  return sys, in_axes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "8w9E5S5Dzm3g"
   },
   "outputs": [],
   "source": [
    "# # If we wanted 10 environments with randomized friction and actuator params,\n",
    "# # we can call `domain_randomize`, which returns a batched `mjx.Model` along with\n",
    "# # a dictionary specifying the axes that are batched.\n",
    "\n",
    "# rng = jax.random.PRNGKey(0)\n",
    "# rng = jax.random.split(rng, 10)\n",
    "# batched_sys, _ = domain_randomize(env.sys, rng)\n",
    "\n",
    "# print('Single env friction shape: ', env.sys.geom_friction.shape)\n",
    "# print('Batched env friction shape: ', batched_sys.geom_friction.shape)\n",
    "\n",
    "# print('Friction on geom 0: ', env.sys.geom_friction[0, 0])\n",
    "# print('Random frictions on geom 0: ', batched_sys.geom_friction[:, 0, 0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "P1K6IznI2y83"
   },
   "source": [
    "# Instantiation & Visualize a Rollout\n",
    "\n",
    "Let's instantiate the environment and visualize a short rollout. This is before the training that weights learned to do anything, it doesnt know how to stand, run, or anything. So the model would naturally fall on the ground due to physics engine simulation.\n",
    "\n",
    "NOTE: Since episodes terminates early if the torso is below the healthy z-range, the only relevant contacts for this task are between the feet and the plane. We turn off other contacts.\n",
    "\n",
    "Selection of 2 choices:\n",
    "1. mjx_backend\n",
    "2. Pipeline_backend (positiona, spring, generalized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ph8u-v2Q2xLS"
   },
   "outputs": [],
   "source": [
    "# Instantiate two different environment\n",
    "env_name = 'humanoid_mjx' # @param ['humanoid_generalized','humanoid_mjx']\n",
    "backend = 'positional' # @param ['generalized', 'positional', 'spring']\n",
    "\n",
    "if env_name == 'humanoid_mjx':\n",
    "  # mjx model takes in no backend argument, doens't matter\n",
    "  env = envs.get_environment(env_name=env_name)\n",
    "\n",
    "  # define the jit reset/step functions\n",
    "  jit_reset = jax.jit(env.reset)\n",
    "  jit_step = jax.jit(env.step)\n",
    "\n",
    "  # initialize the state\n",
    "  state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "  #Creating an container for rollout states\n",
    "  rollout = [state.pipeline_state]\n",
    "\n",
    "  # grab a trajectory\n",
    "  for i in tqdm(range(100)):\n",
    "    ctrl = -0.1 * jp.ones(env.sys.nu)\n",
    "    state = jit_step(state, ctrl)\n",
    "    rollout.append(state.pipeline_state)\n",
    "\n",
    "  media.show_video(env.render(rollout, camera='side'), fps=1.0 / env.dt)\n",
    "  #HTML(html.render(env.sys, rollout))\n",
    "\n",
    "else:\n",
    "  env = envs.get_environment(env_name=env_name, backend=backend)\n",
    "\n",
    "  # define the jit reset/step functions\n",
    "  jit_reset = jax.jit(env.reset)\n",
    "  jit_step = jax.jit(env.step)\n",
    "\n",
    "  # initialize the state\n",
    "  state = jit_reset(jax.random.PRNGKey(0))\n",
    "\n",
    "  HTML(html.render(env.sys, [state.pipeline_state]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BQDG6NQ1CbZD"
   },
   "source": [
    "## Train Humanoid Policy\n",
    "\n",
    "Let's now train a policy with PPO to make the Humanoid run forwards. Training takes about 9-10 minutes on a Tesla A100 GPU.\n",
    "\n",
    "There isn't really much to do here with the training loop as the brax system already compact the whole ppo training loops already. More detail can be found in the implementation of [Proximal Policy Gradient](https://github.com/google/brax/blob/main/brax/training/agents/ppo/train.py)\n",
    "\n",
    "***The function we define here concurrently feeds back into the system of PPO that is defined by barx, creating a feedback loop between them and establishes training.***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "xLiddQYPApBw"
   },
   "outputs": [],
   "source": [
    "config = {\n",
    "    \"env_name\": env_name,\n",
    "    \"algo_name\": \"ppo\",\n",
    "    \"task_name\": \"run\",\n",
    "    \"num_timesteps\": 30_000_000,\n",
    "    \"num_evals\": 5,\n",
    "    \"episode_length\": 1000,\n",
    "    \"num_envs\": 4096,\n",
    "    \"batch_size\": 1024,\n",
    "    \"num_minibatches\": 32,\n",
    "    \"num_updates_per_batch\": 8,\n",
    "    \"unroll_length\": 10,\n",
    "    \"network_factory\": make_networks_factory,\n",
    "    \"randomization_fn\": domain_randomize #not added\n",
    "    }\n",
    "\n",
    "# The functools.partial() function is a function that allow us to pre-pass in parameters\n",
    "# This is literally the only thing you need to write for this training\n",
    "train_fn = functools.partial(\n",
    "    ppo.train, num_timesteps=config['num_timesteps'], num_evals=config['num_evals'], reward_scaling=0.1,\n",
    "    episode_length=config['episode_length'], normalize_observations=True, action_repeat=1,\n",
    "    unroll_length=config['unroll_length'], num_minibatches=config['num_minibatches'], num_updates_per_batch=config['num_updates_per_batch'],\n",
    "    discounting=0.97, learning_rate=3e-4, entropy_cost=1e-3, num_envs=config['num_envs'],\n",
    "    batch_size=config['batch_size'], network_factory=config['network_factory'], seed=0)\n",
    "\n",
    "# Saving everything to Wandb\n",
    "run = wandb.init(project=\"vnl_backend_switch\", config=config)\n",
    "wandb.run.name = f\"{config['env_name']}_{config['task_name']}_{config['algo_name']}_brax\"\n",
    "def wandb_progress(num_steps, metrics):\n",
    "    metrics[\"num_steps\"] = num_steps\n",
    "    wandb.log(metrics)\n",
    "\n",
    "# Making inference & diectly use wandb as progress function\n",
    "make_inference_fn, params, _= train_fn(environment=env, progress_fn=wandb_progress)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YYIch0HEApBx"
   },
   "source": [
    "<!-- ## Save and Load Policy -->\n",
    "\n",
    "We can save and load the policy using the brax model API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Z8gI6qH6ApBx"
   },
   "outputs": [],
   "source": [
    "#@title Save Model\n",
    "model_path = '/tmp/mjx_brax_policy'\n",
    "model.save_params(model_path, params)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "h4reaWgxApBx"
   },
   "outputs": [],
   "source": [
    "#@title Load Model and Define Inference Function\n",
    "params = model.load_params(model_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0G357XIfApBy"
   },
   "source": [
    "## Visualize One Policy Trajectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "d-UhypudApBy"
   },
   "outputs": [],
   "source": [
    "env_name = 'humanoid_mjx' # @param ['humanoid_generalized','humanoid_mjx']\n",
    "backend = 'positional' # @param ['generalized', 'positional', 'spring']\n",
    "\n",
    "if env_name == 'humanoid_generalized':\n",
    "  env = envs.create(env_name=env_name, backend=backend)\n",
    "\n",
    "  jit_env_reset = jax.jit(env.reset)\n",
    "  jit_env_step = jax.jit(env.step)\n",
    "  inference_fn = make_inference_fn(params)\n",
    "  jit_inference_fn = jax.jit(inference_fn)\n",
    "\n",
    "  rollout = []\n",
    "  rng = jax.random.PRNGKey(seed=1)\n",
    "  state = jit_env_reset(rng=rng)\n",
    "  for _ in range(1000):\n",
    "    rollout.append(state.pipeline_state)\n",
    "    act_rng, rng = jax.random.split(rng)\n",
    "    act, _ = jit_inference_fn(state.obs, act_rng)\n",
    "    state = jit_env_step(state, act)\n",
    "\n",
    "  HTML(html.render(env.sys.replace(dt=env.dt), rollout))\n",
    "\n",
    "else:\n",
    "  env = envs.create(env_name=env_name)\n",
    "\n",
    "  jit_env_reset = jax.jit(env.reset)\n",
    "  jit_env_step = jax.jit(env.step)\n",
    "  inference_fn = make_inference_fn(params)\n",
    "  jit_inference_fn = jax.jit(inference_fn)\n",
    "\n",
    "  # initialize the state\n",
    "  rng = jax.random.PRNGKey(0)\n",
    "  state = jit_reset(rng)\n",
    "  rollout = [state.pipeline_state]\n",
    "\n",
    "  # grab a trajectory\n",
    "  n_steps = 1000\n",
    "  render_every = 1\n",
    "\n",
    "  for i in range(n_steps):\n",
    "    act_rng, rng = jax.random.split(rng)\n",
    "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "    state = jit_step(state, ctrl)\n",
    "    rollout.append(state.pipeline_state)\n",
    "\n",
    "    if state.done:\n",
    "      break\n",
    "\n",
    "  media.show_video(env.render(rollout[::render_every], camera='side'), fps=1.0 / env.dt / render_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cRySgFXbopa-"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuClass": "premium",
   "gpuType": "T4",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
