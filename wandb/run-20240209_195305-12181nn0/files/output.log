
{'eval/walltime': 288.64107728004456, 'eval/episode_distance_from_origin': Array(3393.0894, dtype=float32), 'eval/episode_distance_reward': Array(-0.09767264, dtype=float32), 'eval/episode_forward_reward': Array(-9.767248, dtype=float32), 'eval/episode_reward': Array(-221.17604, dtype=float32), 'eval/episode_reward_alive': Array(1.6953125, dtype=float32), 'eval/episode_reward_linvel': Array(-9.767248, dtype=float32), 'eval/episode_reward_quadctrl': Array(-213.00642, dtype=float32), 'eval/episode_x_position': Array(3356.3076, dtype=float32), 'eval/episode_x_velocity': Array(-1.953451, dtype=float32), 'eval/episode_y_position': Array(374.1032, dtype=float32), 'eval/episode_y_velocity': Array(2.602766, dtype=float32), 'eval/episode_distance_from_origin_std': Array(97.1213, dtype=float32), 'eval/episode_distance_reward_std': Array(0.79309046, dtype=float32), 'eval/episode_forward_reward_std': Array(79.30902, dtype=float32), 'eval/episode_reward_std': Array(80.365204, dtype=float32), 'eval/episode_reward_alive_std': Array(2.6599123, dtype=float32), 'eval/episode_reward_linvel_std': Array(79.30902, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.2752588, dtype=float32), 'eval/episode_x_position_std': Array(100.88203, dtype=float32), 'eval/episode_x_velocity_std': Array(15.861798, dtype=float32), 'eval/episode_y_position_std': Array(91.563156, dtype=float32), 'eval/episode_y_velocity_std': Array(12.185605, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 288.64107728004456, 'eval/sps': 443.45732494551424, 'num_steps': 0}
{'eval/walltime': 543.8104932308197, 'training/sps': 169.37622070947282, 'training/walltime': 483.65703082084656, 'training/entropy_loss': Array(-0.00507604, dtype=float32), 'training/policy_loss': Array(-0.0129559, dtype=float32), 'training/total_loss': Array(0.01469615, dtype=float32), 'training/v_loss': Array(0.0327281, dtype=float32), 'eval/episode_distance_from_origin': Array(3534.2212, dtype=float32), 'eval/episode_distance_reward': Array(0.7424561, dtype=float32), 'eval/episode_forward_reward': Array(74.245605, dtype=float32), 'eval/episode_reward': Array(-136.55984, dtype=float32), 'eval/episode_reward_alive': Array(7.6835938, dtype=float32), 'eval/episode_reward_linvel': Array(74.245605, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.23148, dtype=float32), 'eval/episode_x_position': Array(3499.2827, dtype=float32), 'eval/episode_x_velocity': Array(14.8491125, dtype=float32), 'eval/episode_y_position': Array(339.28012, dtype=float32), 'eval/episode_y_velocity': Array(-3.7419813, dtype=float32), 'eval/episode_distance_from_origin_std': Array(106.815636, dtype=float32), 'eval/episode_distance_reward_std': Array(0.6953514, dtype=float32), 'eval/episode_forward_reward_std': Array(69.53512, dtype=float32), 'eval/episode_reward_std': Array(74.92773, dtype=float32), 'eval/episode_reward_alive_std': Array(18.710047, dtype=float32), 'eval/episode_reward_linvel_std': Array(69.53512, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.810867, dtype=float32), 'eval/episode_x_position_std': Array(105.47731, dtype=float32), 'eval/episode_x_velocity_std': Array(13.907015, dtype=float32), 'eval/episode_y_position_std': Array(144.70827, dtype=float32), 'eval/episode_y_velocity_std': Array(19.19835, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.16941595077515, 'eval/sps': 501.62751489266464, 'num_steps': 81920}
{'eval/walltime': 799.1339812278748, 'training/sps': 179.51033014532229, 'training/walltime': 940.0095980167389, 'training/entropy_loss': Array(-0.00494888, dtype=float32), 'training/policy_loss': Array(0.00611982, dtype=float32), 'training/total_loss': Array(0.02775938, dtype=float32), 'training/v_loss': Array(0.02658844, dtype=float32), 'eval/episode_distance_from_origin': Array(3600.8557, dtype=float32), 'eval/episode_distance_reward': Array(1.185123, dtype=float32), 'eval/episode_forward_reward': Array(118.512276, dtype=float32), 'eval/episode_reward': Array(-94.94809, dtype=float32), 'eval/episode_reward_alive': Array(1.4570312, dtype=float32), 'eval/episode_reward_linvel': Array(118.512276, dtype=float32), 'eval/episode_reward_quadctrl': Array(-216.10254, dtype=float32), 'eval/episode_x_position': Array(3572.6216, dtype=float32), 'eval/episode_x_velocity': Array(23.702446, dtype=float32), 'eval/episode_y_position': Array(302.33606, dtype=float32), 'eval/episode_y_velocity': Array(-10.43057, dtype=float32), 'eval/episode_distance_from_origin_std': Array(78.474335, dtype=float32), 'eval/episode_distance_reward_std': Array(0.47471476, dtype=float32), 'eval/episode_forward_reward_std': Array(47.47146, dtype=float32), 'eval/episode_reward_std': Array(47.713577, dtype=float32), 'eval/episode_reward_alive_std': Array(2.6078513, dtype=float32), 'eval/episode_reward_linvel_std': Array(47.47146, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.1224082, dtype=float32), 'eval/episode_x_position_std': Array(79.366714, dtype=float32), 'eval/episode_x_velocity_std': Array(9.494279, dtype=float32), 'eval/episode_y_position_std': Array(109.959015, dtype=float32), 'eval/episode_y_velocity_std': Array(13.641817, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.32348799705505, 'eval/sps': 501.3248134910188, 'num_steps': 163840}
{'eval/walltime': 1054.302029132843, 'training/sps': 178.68831408936893, 'training/walltime': 1398.4615142345428, 'training/entropy_loss': Array(-0.0049049, dtype=float32), 'training/policy_loss': Array(-0.02558536, dtype=float32), 'training/total_loss': Array(-0.0176698, dtype=float32), 'training/v_loss': Array(0.01282047, dtype=float32), 'eval/episode_distance_from_origin': Array(3637.9663, dtype=float32), 'eval/episode_distance_reward': Array(1.4300132, dtype=float32), 'eval/episode_forward_reward': Array(143.00128, dtype=float32), 'eval/episode_reward': Array(-68.79849, dtype=float32), 'eval/episode_reward_alive': Array(1.4101562, dtype=float32), 'eval/episode_reward_linvel': Array(143.00128, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.63994, dtype=float32), 'eval/episode_x_position': Array(3606.4756, dtype=float32), 'eval/episode_x_velocity': Array(28.600235, dtype=float32), 'eval/episode_y_position': Array(344.4533, dtype=float32), 'eval/episode_y_velocity': Array(-5.594486, dtype=float32), 'eval/episode_distance_from_origin_std': Array(80.68224, dtype=float32), 'eval/episode_distance_reward_std': Array(0.46825042, dtype=float32), 'eval/episode_forward_reward_std': Array(46.825024, dtype=float32), 'eval/episode_reward_std': Array(47.03966, dtype=float32), 'eval/episode_reward_alive_std': Array(2.2856836, dtype=float32), 'eval/episode_reward_linvel_std': Array(46.825024, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.7421622, dtype=float32), 'eval/episode_x_position_std': Array(82.7419, dtype=float32), 'eval/episode_x_velocity_std': Array(9.364985, dtype=float32), 'eval/episode_y_position_std': Array(104.33794, dtype=float32), 'eval/episode_y_velocity_std': Array(12.938461, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.16804790496826, 'eval/sps': 501.63020429450785, 'num_steps': 245760}
{'eval/walltime': 1309.510747909546, 'training/sps': 179.7870899860095, 'training/walltime': 1854.1115834712982, 'training/entropy_loss': Array(-0.00473288, dtype=float32), 'training/policy_loss': Array(-0.02177006, dtype=float32), 'training/total_loss': Array(-0.01728739, dtype=float32), 'training/v_loss': Array(0.00921554, dtype=float32), 'eval/episode_distance_from_origin': Array(3668.5894, dtype=float32), 'eval/episode_distance_reward': Array(1.5379182, dtype=float32), 'eval/episode_forward_reward': Array(153.79178, dtype=float32), 'eval/episode_reward': Array(-57.73247, dtype=float32), 'eval/episode_reward_alive': Array(1.5273438, dtype=float32), 'eval/episode_reward_linvel': Array(153.79178, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.58955, dtype=float32), 'eval/episode_x_position': Array(3638.27, dtype=float32), 'eval/episode_x_velocity': Array(30.758331, dtype=float32), 'eval/episode_y_position': Array(337.21457, dtype=float32), 'eval/episode_y_velocity': Array(-5.1473484, dtype=float32), 'eval/episode_distance_from_origin_std': Array(67.05779, dtype=float32), 'eval/episode_distance_reward_std': Array(0.41023192, dtype=float32), 'eval/episode_forward_reward_std': Array(41.023174, dtype=float32), 'eval/episode_reward_std': Array(41.60641, dtype=float32), 'eval/episode_reward_alive_std': Array(2.593794, dtype=float32), 'eval/episode_reward_linvel_std': Array(41.023174, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.0936446, dtype=float32), 'eval/episode_x_position_std': Array(66.57047, dtype=float32), 'eval/episode_x_velocity_std': Array(8.2046175, dtype=float32), 'eval/episode_y_position_std': Array(95.65229, dtype=float32), 'eval/episode_y_velocity_std': Array(11.546436, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.20871877670288, 'eval/sps': 501.55026291243104, 'num_steps': 327680}
{'eval/walltime': 1564.7304916381836, 'training/sps': 179.3825805976679, 'training/walltime': 2310.7891478538513, 'training/entropy_loss': Array(-0.00465742, dtype=float32), 'training/policy_loss': Array(-0.02574527, dtype=float32), 'training/total_loss': Array(-0.02268478, dtype=float32), 'training/v_loss': Array(0.00771791, dtype=float32), 'eval/episode_distance_from_origin': Array(3670.2402, dtype=float32), 'eval/episode_distance_reward': Array(1.4464164, dtype=float32), 'eval/episode_forward_reward': Array(144.64163, dtype=float32), 'eval/episode_reward': Array(-66.19526, dtype=float32), 'eval/episode_reward_alive': Array(2.4375, dtype=float32), 'eval/episode_reward_linvel': Array(144.64163, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.72083, dtype=float32), 'eval/episode_x_position': Array(3640.2676, dtype=float32), 'eval/episode_x_velocity': Array(28.92831, dtype=float32), 'eval/episode_y_position': Array(332.22083, dtype=float32), 'eval/episode_y_velocity': Array(-2.8889446, dtype=float32), 'eval/episode_distance_from_origin_std': Array(68.90325, dtype=float32), 'eval/episode_distance_reward_std': Array(0.4413551, dtype=float32), 'eval/episode_forward_reward_std': Array(44.135498, dtype=float32), 'eval/episode_reward_std': Array(45.559464, dtype=float32), 'eval/episode_reward_alive_std': Array(3.5405023, dtype=float32), 'eval/episode_reward_linvel_std': Array(44.135498, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.8580303, dtype=float32), 'eval/episode_x_position_std': Array(71.153755, dtype=float32), 'eval/episode_x_velocity_std': Array(8.827077, dtype=float32), 'eval/episode_y_position_std': Array(101.68327, dtype=float32), 'eval/episode_y_velocity_std': Array(13.460752, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.2197437286377, 'eval/sps': 501.5285970042191, 'num_steps': 409600}
{'eval/walltime': 1820.0427994728088, 'training/sps': 178.95402677972092, 'training/walltime': 2768.5603501796722, 'training/entropy_loss': Array(-0.0045428, dtype=float32), 'training/policy_loss': Array(-0.01778548, dtype=float32), 'training/total_loss': Array(-0.0124891, dtype=float32), 'training/v_loss': Array(0.00983917, dtype=float32), 'eval/episode_distance_from_origin': Array(3703.1528, dtype=float32), 'eval/episode_distance_reward': Array(1.6051052, dtype=float32), 'eval/episode_forward_reward': Array(160.5105, dtype=float32), 'eval/episode_reward': Array(-48.92646, dtype=float32), 'eval/episode_reward_alive': Array(4.7460938, dtype=float32), 'eval/episode_reward_linvel': Array(160.5105, dtype=float32), 'eval/episode_reward_quadctrl': Array(-215.78816, dtype=float32), 'eval/episode_x_position': Array(3671.619, dtype=float32), 'eval/episode_x_velocity': Array(32.10209, dtype=float32), 'eval/episode_y_position': Array(351.5, dtype=float32), 'eval/episode_y_velocity': Array(0.7254545, dtype=float32), 'eval/episode_distance_from_origin_std': Array(69.53004, dtype=float32), 'eval/episode_distance_reward_std': Array(0.4267471, dtype=float32), 'eval/episode_forward_reward_std': Array(42.67469, dtype=float32), 'eval/episode_reward_std': Array(44.616116, dtype=float32), 'eval/episode_reward_alive_std': Array(5.0117035, dtype=float32), 'eval/episode_reward_linvel_std': Array(42.67469, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.993672, dtype=float32), 'eval/episode_x_position_std': Array(70.11297, dtype=float32), 'eval/episode_x_velocity_std': Array(8.534917, dtype=float32), 'eval/episode_y_position_std': Array(100.28454, dtype=float32), 'eval/episode_y_velocity_std': Array(12.782799, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.31230783462524, 'eval/sps': 501.3467665762126, 'num_steps': 491520}
{'eval/walltime': 2076.2835581302643, 'training/sps': 179.75509884687304, 'training/walltime': 3224.291511774063, 'training/entropy_loss': Array(-0.00442383, dtype=float32), 'training/policy_loss': Array(-0.02493764, dtype=float32), 'training/total_loss': Array(-0.02263655, dtype=float32), 'training/v_loss': Array(0.00672492, dtype=float32), 'eval/episode_distance_from_origin': Array(3764.7017, dtype=float32), 'eval/episode_distance_reward': Array(2.0012205, dtype=float32), 'eval/episode_forward_reward': Array(200.12202, dtype=float32), 'eval/episode_reward': Array(-4.528837, dtype=float32), 'eval/episode_reward_alive': Array(7.9804688, dtype=float32), 'eval/episode_reward_linvel': Array(200.12202, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.63257, dtype=float32), 'eval/episode_x_position': Array(3736.2327, dtype=float32), 'eval/episode_x_velocity': Array(40.02438, dtype=float32), 'eval/episode_y_position': Array(324.12973, dtype=float32), 'eval/episode_y_velocity': Array(-1.6913648, dtype=float32), 'eval/episode_distance_from_origin_std': Array(64.72399, dtype=float32), 'eval/episode_distance_reward_std': Array(0.3717735, dtype=float32), 'eval/episode_forward_reward_std': Array(37.17735, dtype=float32), 'eval/episode_reward_std': Array(39.46319, dtype=float32), 'eval/episode_reward_alive_std': Array(5.702385, dtype=float32), 'eval/episode_reward_linvel_std': Array(37.17735, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.5459332, dtype=float32), 'eval/episode_x_position_std': Array(64.04363, dtype=float32), 'eval/episode_x_velocity_std': Array(7.435454, dtype=float32), 'eval/episode_y_position_std': Array(96.263016, dtype=float32), 'eval/episode_y_velocity_std': Array(11.606416, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.24075865745544, 'eval/sps': 499.5302100674442, 'num_steps': 573440}
{'eval/walltime': 2331.4478425979614, 'training/sps': 179.54954663885465, 'training/walltime': 3680.5444042682648, 'training/entropy_loss': Array(-0.00422817, dtype=float32), 'training/policy_loss': Array(-0.02236234, dtype=float32), 'training/total_loss': Array(-0.01954592, dtype=float32), 'training/v_loss': Array(0.00704459, dtype=float32), 'eval/episode_distance_from_origin': Array(3833.774, dtype=float32), 'eval/episode_distance_reward': Array(2.4182365, dtype=float32), 'eval/episode_forward_reward': Array(241.8236, dtype=float32), 'eval/episode_reward': Array(42.71954, dtype=float32), 'eval/episode_reward_alive': Array(11.808594, dtype=float32), 'eval/episode_reward_linvel': Array(241.8236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-213.33095, dtype=float32), 'eval/episode_x_position': Array(3808.7166, dtype=float32), 'eval/episode_x_velocity': Array(48.36468, dtype=float32), 'eval/episode_y_position': Array(291.62848, dtype=float32), 'eval/episode_y_velocity': Array(-5.2431545, dtype=float32), 'eval/episode_distance_from_origin_std': Array(68.943504, dtype=float32), 'eval/episode_distance_reward_std': Array(0.3985617, dtype=float32), 'eval/episode_forward_reward_std': Array(39.85614, dtype=float32), 'eval/episode_reward_std': Array(42.043217, dtype=float32), 'eval/episode_reward_alive_std': Array(5.367408, dtype=float32), 'eval/episode_reward_linvel_std': Array(39.85614, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.7003, dtype=float32), 'eval/episode_x_position_std': Array(70.4045, dtype=float32), 'eval/episode_x_velocity_std': Array(7.971219, dtype=float32), 'eval/episode_y_position_std': Array(80.58221, dtype=float32), 'eval/episode_y_velocity_std': Array(9.93686, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.16428446769714, 'eval/sps': 501.63760287621415, 'num_steps': 655360}
{'eval/walltime': 2587.580340385437, 'training/sps': 179.5542876496944, 'training/walltime': 4136.785249710083, 'training/entropy_loss': Array(-0.00406895, dtype=float32), 'training/policy_loss': Array(-0.01120333, dtype=float32), 'training/total_loss': Array(-0.00620328, dtype=float32), 'training/v_loss': Array(0.009069, dtype=float32), 'eval/episode_distance_from_origin': Array(3868.8423, dtype=float32), 'eval/episode_distance_reward': Array(2.6376758, dtype=float32), 'eval/episode_forward_reward': Array(263.76755, dtype=float32), 'eval/episode_reward': Array(67.37793, dtype=float32), 'eval/episode_reward_alive': Array(14.160156, dtype=float32), 'eval/episode_reward_linvel': Array(263.76755, dtype=float32), 'eval/episode_reward_quadctrl': Array(-213.18747, dtype=float32), 'eval/episode_x_position': Array(3847.2659, dtype=float32), 'eval/episode_x_velocity': Array(52.75346, dtype=float32), 'eval/episode_y_position': Array(245.87378, dtype=float32), 'eval/episode_y_velocity': Array(-10.913903, dtype=float32), 'eval/episode_distance_from_origin_std': Array(66.89143, dtype=float32), 'eval/episode_distance_reward_std': Array(0.37852868, dtype=float32), 'eval/episode_forward_reward_std': Array(37.852886, dtype=float32), 'eval/episode_reward_std': Array(39.848778, dtype=float32), 'eval/episode_reward_alive_std': Array(4.864144, dtype=float32), 'eval/episode_reward_linvel_std': Array(37.852886, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.3388202, dtype=float32), 'eval/episode_x_position_std': Array(67.84675, dtype=float32), 'eval/episode_x_velocity_std': Array(7.5705605, dtype=float32), 'eval/episode_y_position_std': Array(77.938545, dtype=float32), 'eval/episode_y_velocity_std': Array(9.047584, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.1324977874756, 'eval/sps': 499.74134912863434, 'num_steps': 737280}
{'eval/walltime': 2843.53710770607, 'training/sps': 179.31612723401923, 'training/walltime': 4593.63205575943, 'training/entropy_loss': Array(-0.00384748, dtype=float32), 'training/policy_loss': Array(-0.01512003, dtype=float32), 'training/total_loss': Array(-0.01382714, dtype=float32), 'training/v_loss': Array(0.00514038, dtype=float32), 'eval/episode_distance_from_origin': Array(3900.1313, dtype=float32), 'eval/episode_distance_reward': Array(2.8215845, dtype=float32), 'eval/episode_forward_reward': Array(282.1584, dtype=float32), 'eval/episode_reward': Array(88.66697, dtype=float32), 'eval/episode_reward_alive': Array(16.40625, dtype=float32), 'eval/episode_reward_linvel': Array(282.1584, dtype=float32), 'eval/episode_reward_quadctrl': Array(-212.71928, dtype=float32), 'eval/episode_x_position': Array(3879.7446, dtype=float32), 'eval/episode_x_velocity': Array(56.431618, dtype=float32), 'eval/episode_y_position': Array(228.73824, dtype=float32), 'eval/episode_y_velocity': Array(-12.308384, dtype=float32), 'eval/episode_distance_from_origin_std': Array(51.89689, dtype=float32), 'eval/episode_distance_reward_std': Array(0.30303007, dtype=float32), 'eval/episode_forward_reward_std': Array(30.30299, dtype=float32), 'eval/episode_reward_std': Array(31.822575, dtype=float32), 'eval/episode_reward_alive_std': Array(4.0213056, dtype=float32), 'eval/episode_reward_linvel_std': Array(30.30299, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.3337607, dtype=float32), 'eval/episode_x_position_std': Array(52.082493, dtype=float32), 'eval/episode_x_velocity_std': Array(6.0605836, dtype=float32), 'eval/episode_y_position_std': Array(75.4489, dtype=float32), 'eval/episode_y_velocity_std': Array(9.032186, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.95676732063293, 'eval/sps': 500.0844530891284, 'num_steps': 819200}
{'eval/walltime': 3099.3173949718475, 'training/sps': 179.59163431357018, 'training/walltime': 5049.778024435043, 'training/entropy_loss': Array(-0.00356635, dtype=float32), 'training/policy_loss': Array(-0.01435622, dtype=float32), 'training/total_loss': Array(-0.01275485, dtype=float32), 'training/v_loss': Array(0.00516772, dtype=float32), 'eval/episode_distance_from_origin': Array(3929.1572, dtype=float32), 'eval/episode_distance_reward': Array(2.9831727, dtype=float32), 'eval/episode_forward_reward': Array(298.31717, dtype=float32), 'eval/episode_reward': Array(106.767555, dtype=float32), 'eval/episode_reward_alive': Array(17.375, dtype=float32), 'eval/episode_reward_linvel': Array(298.31717, dtype=float32), 'eval/episode_reward_quadctrl': Array(-211.9079, dtype=float32), 'eval/episode_x_position': Array(3911.392, dtype=float32), 'eval/episode_x_velocity': Array(59.663376, dtype=float32), 'eval/episode_y_position': Array(179.80241, dtype=float32), 'eval/episode_y_velocity': Array(-17.45939, dtype=float32), 'eval/episode_distance_from_origin_std': Array(52.85961, dtype=float32), 'eval/episode_distance_reward_std': Array(0.31616637, dtype=float32), 'eval/episode_forward_reward_std': Array(31.616611, dtype=float32), 'eval/episode_reward_std': Array(33.17268, dtype=float32), 'eval/episode_reward_alive_std': Array(3.4988837, dtype=float32), 'eval/episode_reward_linvel_std': Array(31.616611, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.5197287, dtype=float32), 'eval/episode_x_position_std': Array(53.161316, dtype=float32), 'eval/episode_x_velocity_std': Array(6.3233085, dtype=float32), 'eval/episode_y_position_std': Array(73.84535, dtype=float32), 'eval/episode_y_velocity_std': Array(8.441772, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.7802872657776, 'eval/sps': 500.4294950493861, 'num_steps': 901120}
{'eval/walltime': 3354.4930744171143, 'training/sps': 179.86842091377002, 'training/walltime': 5505.222062826157, 'training/entropy_loss': Array(-0.00327986, dtype=float32), 'training/policy_loss': Array(-0.00885858, dtype=float32), 'training/total_loss': Array(-0.00694757, dtype=float32), 'training/v_loss': Array(0.00519086, dtype=float32), 'eval/episode_distance_from_origin': Array(3967.6245, dtype=float32), 'eval/episode_distance_reward': Array(3.2138312, dtype=float32), 'eval/episode_forward_reward': Array(321.38306, dtype=float32), 'eval/episode_reward': Array(132.16495, dtype=float32), 'eval/episode_reward_alive': Array(18.695312, dtype=float32), 'eval/episode_reward_linvel': Array(321.38306, dtype=float32), 'eval/episode_reward_quadctrl': Array(-211.1273, dtype=float32), 'eval/episode_x_position': Array(3950.2222, dtype=float32), 'eval/episode_x_velocity': Array(64.276535, dtype=float32), 'eval/episode_y_position': Array(158.06805, dtype=float32), 'eval/episode_y_velocity': Array(-20.26778, dtype=float32), 'eval/episode_distance_from_origin_std': Array(74.98706, dtype=float32), 'eval/episode_distance_reward_std': Array(0.43857324, dtype=float32), 'eval/episode_forward_reward_std': Array(43.8573, dtype=float32), 'eval/episode_reward_std': Array(45.020634, dtype=float32), 'eval/episode_reward_alive_std': Array(2.7316391, dtype=float32), 'eval/episode_reward_linvel_std': Array(43.8573, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.6356509, dtype=float32), 'eval/episode_x_position_std': Array(75.019264, dtype=float32), 'eval/episode_x_velocity_std': Array(8.771424, dtype=float32), 'eval/episode_y_position_std': Array(92.572754, dtype=float32), 'eval/episode_y_velocity_std': Array(11.626504, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.17567944526672, 'eval/sps': 501.6152020375243, 'num_steps': 983040}
{'eval/walltime': 3609.7198102474213, 'training/sps': 179.486514685519, 'training/walltime': 5961.635181903839, 'training/entropy_loss': Array(-0.00300142, dtype=float32), 'training/policy_loss': Array(-0.00996147, dtype=float32), 'training/total_loss': Array(-0.00696525, dtype=float32), 'training/v_loss': Array(0.00599764, dtype=float32), 'eval/episode_distance_from_origin': Array(4032.5898, dtype=float32), 'eval/episode_distance_reward': Array(3.6499534, dtype=float32), 'eval/episode_forward_reward': Array(364.99524, dtype=float32), 'eval/episode_reward': Array(177.67398, dtype=float32), 'eval/episode_reward_alive': Array(19.589844, dtype=float32), 'eval/episode_reward_linvel': Array(364.99524, dtype=float32), 'eval/episode_reward_quadctrl': Array(-210.56113, dtype=float32), 'eval/episode_x_position': Array(4015.5098, dtype=float32), 'eval/episode_x_velocity': Array(72.998924, dtype=float32), 'eval/episode_y_position': Array(73.55254, dtype=float32), 'eval/episode_y_velocity': Array(-29.70999, dtype=float32), 'eval/episode_distance_from_origin_std': Array(105.9316, dtype=float32), 'eval/episode_distance_reward_std': Array(0.6758486, dtype=float32), 'eval/episode_forward_reward_std': Array(67.58478, dtype=float32), 'eval/episode_reward_std': Array(68.243, dtype=float32), 'eval/episode_reward_alive_std': Array(3.0716913, dtype=float32), 'eval/episode_reward_linvel_std': Array(67.58478, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.2756395, dtype=float32), 'eval/episode_x_position_std': Array(105.21317, dtype=float32), 'eval/episode_x_velocity_std': Array(13.516919, dtype=float32), 'eval/episode_y_position_std': Array(142.77411, dtype=float32), 'eval/episode_y_velocity_std': Array(17.825863, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.226735830307, 'eval/sps': 501.51485730359985, 'num_steps': 1064960}
{'eval/walltime': 3864.9262590408325, 'training/sps': 179.24928479877636, 'training/walltime': 6418.65234708786, 'training/entropy_loss': Array(-0.00280799, dtype=float32), 'training/policy_loss': Array(-0.01076688, dtype=float32), 'training/total_loss': Array(-0.00909278, dtype=float32), 'training/v_loss': Array(0.00448209, dtype=float32), 'eval/episode_distance_from_origin': Array(4201.0615, dtype=float32), 'eval/episode_distance_reward': Array(4.6479807, dtype=float32), 'eval/episode_forward_reward': Array(464.7979, dtype=float32), 'eval/episode_reward': Array(273.0983, dtype=float32), 'eval/episode_reward_alive': Array(21.535156, dtype=float32), 'eval/episode_reward_linvel': Array(464.7979, dtype=float32), 'eval/episode_reward_quadctrl': Array(-217.88293, dtype=float32), 'eval/episode_x_position': Array(4172.727, dtype=float32), 'eval/episode_x_velocity': Array(92.95945, dtype=float32), 'eval/episode_y_position': Array(-176.56726, dtype=float32), 'eval/episode_y_velocity': Array(-64.921455, dtype=float32), 'eval/episode_distance_from_origin_std': Array(179.9651, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1860373, dtype=float32), 'eval/episode_forward_reward_std': Array(118.60375, dtype=float32), 'eval/episode_reward_std': Array(118.70736, dtype=float32), 'eval/episode_reward_alive_std': Array(3.3976, dtype=float32), 'eval/episode_reward_linvel_std': Array(118.60375, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.3859086, dtype=float32), 'eval/episode_x_position_std': Array(169.85062, dtype=float32), 'eval/episode_x_velocity_std': Array(23.720688, dtype=float32), 'eval/episode_y_position_std': Array(233.37196, dtype=float32), 'eval/episode_y_velocity_std': Array(31.338562, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.20644879341125, 'eval/sps': 501.55472404859, 'num_steps': 1146880}
{'eval/walltime': 4120.165840148926, 'training/sps': 179.39881827647105, 'training/walltime': 6875.288576841354, 'training/entropy_loss': Array(-0.00206783, dtype=float32), 'training/policy_loss': Array(-0.00311459, dtype=float32), 'training/total_loss': Array(0.0144654, dtype=float32), 'training/v_loss': Array(0.01964782, dtype=float32), 'eval/episode_distance_from_origin': Array(4361.9956, dtype=float32), 'eval/episode_distance_reward': Array(5.4322953, dtype=float32), 'eval/episode_forward_reward': Array(543.22955, dtype=float32), 'eval/episode_reward': Array(343.29044, dtype=float32), 'eval/episode_reward_alive': Array(23.738281, dtype=float32), 'eval/episode_reward_linvel': Array(543.22955, dtype=float32), 'eval/episode_reward_quadctrl': Array(-229.10979, dtype=float32), 'eval/episode_x_position': Array(4300.249, dtype=float32), 'eval/episode_x_velocity': Array(108.645775, dtype=float32), 'eval/episode_y_position': Array(-481.41895, dtype=float32), 'eval/episode_y_velocity': Array(-107.81716, dtype=float32), 'eval/episode_distance_from_origin_std': Array(243.7471, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4945683, dtype=float32), 'eval/episode_forward_reward_std': Array(149.45718, dtype=float32), 'eval/episode_reward_std': Array(149.81218, dtype=float32), 'eval/episode_reward_alive_std': Array(4.9240184, dtype=float32), 'eval/episode_reward_linvel_std': Array(149.45718, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(10.007842, dtype=float32), 'eval/episode_x_position_std': Array(213.52621, dtype=float32), 'eval/episode_x_velocity_std': Array(29.891346, dtype=float32), 'eval/episode_y_position_std': Array(280.83945, dtype=float32), 'eval/episode_y_velocity_std': Array(39.759823, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.23958110809326, 'eval/sps': 501.48961788881934, 'num_steps': 1228800}
{'eval/walltime': 4375.954516887665, 'training/sps': 179.2203964595874, 'training/walltime': 7332.379408121109, 'training/entropy_loss': Array(-0.0015349, dtype=float32), 'training/policy_loss': Array(0.05731769, dtype=float32), 'training/total_loss': Array(0.07417769, dtype=float32), 'training/v_loss': Array(0.01839491, dtype=float32), 'eval/episode_distance_from_origin': Array(4365.226, dtype=float32), 'eval/episode_distance_reward': Array(5.3263693, dtype=float32), 'eval/episode_forward_reward': Array(532.6369, dtype=float32), 'eval/episode_reward': Array(327.7801, dtype=float32), 'eval/episode_reward_alive': Array(21.75, dtype=float32), 'eval/episode_reward_linvel': Array(532.6369, dtype=float32), 'eval/episode_reward_quadctrl': Array(-231.93332, dtype=float32), 'eval/episode_x_position': Array(4286.8447, dtype=float32), 'eval/episode_x_velocity': Array(106.52724, dtype=float32), 'eval/episode_y_position': Array(-581.0567, dtype=float32), 'eval/episode_y_velocity': Array(-120.92096, dtype=float32), 'eval/episode_distance_from_origin_std': Array(202.56644, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2529131, dtype=float32), 'eval/episode_forward_reward_std': Array(125.29147, dtype=float32), 'eval/episode_reward_std': Array(126.75411, dtype=float32), 'eval/episode_reward_alive_std': Array(5.173928, dtype=float32), 'eval/episode_reward_linvel_std': Array(125.29147, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.982472, dtype=float32), 'eval/episode_x_position_std': Array(182.59299, dtype=float32), 'eval/episode_x_velocity_std': Array(25.058245, dtype=float32), 'eval/episode_y_position_std': Array(284.92908, dtype=float32), 'eval/episode_y_velocity_std': Array(39.712364, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.788676738739, 'eval/sps': 500.41308173597696, 'num_steps': 1310720}
