
{'eval/walltime': 288.64107728004456, 'eval/episode_distance_from_origin': Array(3393.0894, dtype=float32), 'eval/episode_distance_reward': Array(-0.09767264, dtype=float32), 'eval/episode_forward_reward': Array(-9.767248, dtype=float32), 'eval/episode_reward': Array(-221.17604, dtype=float32), 'eval/episode_reward_alive': Array(1.6953125, dtype=float32), 'eval/episode_reward_linvel': Array(-9.767248, dtype=float32), 'eval/episode_reward_quadctrl': Array(-213.00642, dtype=float32), 'eval/episode_x_position': Array(3356.3076, dtype=float32), 'eval/episode_x_velocity': Array(-1.953451, dtype=float32), 'eval/episode_y_position': Array(374.1032, dtype=float32), 'eval/episode_y_velocity': Array(2.602766, dtype=float32), 'eval/episode_distance_from_origin_std': Array(97.1213, dtype=float32), 'eval/episode_distance_reward_std': Array(0.79309046, dtype=float32), 'eval/episode_forward_reward_std': Array(79.30902, dtype=float32), 'eval/episode_reward_std': Array(80.365204, dtype=float32), 'eval/episode_reward_alive_std': Array(2.6599123, dtype=float32), 'eval/episode_reward_linvel_std': Array(79.30902, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.2752588, dtype=float32), 'eval/episode_x_position_std': Array(100.88203, dtype=float32), 'eval/episode_x_velocity_std': Array(15.861798, dtype=float32), 'eval/episode_y_position_std': Array(91.563156, dtype=float32), 'eval/episode_y_velocity_std': Array(12.185605, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 288.64107728004456, 'eval/sps': 443.45732494551424, 'num_steps': 0}
{'eval/walltime': 543.8104932308197, 'training/sps': 169.37622070947282, 'training/walltime': 483.65703082084656, 'training/entropy_loss': Array(-0.00507604, dtype=float32), 'training/policy_loss': Array(-0.0129559, dtype=float32), 'training/total_loss': Array(0.01469615, dtype=float32), 'training/v_loss': Array(0.0327281, dtype=float32), 'eval/episode_distance_from_origin': Array(3534.2212, dtype=float32), 'eval/episode_distance_reward': Array(0.7424561, dtype=float32), 'eval/episode_forward_reward': Array(74.245605, dtype=float32), 'eval/episode_reward': Array(-136.55984, dtype=float32), 'eval/episode_reward_alive': Array(7.6835938, dtype=float32), 'eval/episode_reward_linvel': Array(74.245605, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.23148, dtype=float32), 'eval/episode_x_position': Array(3499.2827, dtype=float32), 'eval/episode_x_velocity': Array(14.8491125, dtype=float32), 'eval/episode_y_position': Array(339.28012, dtype=float32), 'eval/episode_y_velocity': Array(-3.7419813, dtype=float32), 'eval/episode_distance_from_origin_std': Array(106.815636, dtype=float32), 'eval/episode_distance_reward_std': Array(0.6953514, dtype=float32), 'eval/episode_forward_reward_std': Array(69.53512, dtype=float32), 'eval/episode_reward_std': Array(74.92773, dtype=float32), 'eval/episode_reward_alive_std': Array(18.710047, dtype=float32), 'eval/episode_reward_linvel_std': Array(69.53512, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.810867, dtype=float32), 'eval/episode_x_position_std': Array(105.47731, dtype=float32), 'eval/episode_x_velocity_std': Array(13.907015, dtype=float32), 'eval/episode_y_position_std': Array(144.70827, dtype=float32), 'eval/episode_y_velocity_std': Array(19.19835, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.16941595077515, 'eval/sps': 501.62751489266464, 'num_steps': 81920}
{'eval/walltime': 799.1339812278748, 'training/sps': 179.51033014532229, 'training/walltime': 940.0095980167389, 'training/entropy_loss': Array(-0.00494888, dtype=float32), 'training/policy_loss': Array(0.00611982, dtype=float32), 'training/total_loss': Array(0.02775938, dtype=float32), 'training/v_loss': Array(0.02658844, dtype=float32), 'eval/episode_distance_from_origin': Array(3600.8557, dtype=float32), 'eval/episode_distance_reward': Array(1.185123, dtype=float32), 'eval/episode_forward_reward': Array(118.512276, dtype=float32), 'eval/episode_reward': Array(-94.94809, dtype=float32), 'eval/episode_reward_alive': Array(1.4570312, dtype=float32), 'eval/episode_reward_linvel': Array(118.512276, dtype=float32), 'eval/episode_reward_quadctrl': Array(-216.10254, dtype=float32), 'eval/episode_x_position': Array(3572.6216, dtype=float32), 'eval/episode_x_velocity': Array(23.702446, dtype=float32), 'eval/episode_y_position': Array(302.33606, dtype=float32), 'eval/episode_y_velocity': Array(-10.43057, dtype=float32), 'eval/episode_distance_from_origin_std': Array(78.474335, dtype=float32), 'eval/episode_distance_reward_std': Array(0.47471476, dtype=float32), 'eval/episode_forward_reward_std': Array(47.47146, dtype=float32), 'eval/episode_reward_std': Array(47.713577, dtype=float32), 'eval/episode_reward_alive_std': Array(2.6078513, dtype=float32), 'eval/episode_reward_linvel_std': Array(47.47146, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.1224082, dtype=float32), 'eval/episode_x_position_std': Array(79.366714, dtype=float32), 'eval/episode_x_velocity_std': Array(9.494279, dtype=float32), 'eval/episode_y_position_std': Array(109.959015, dtype=float32), 'eval/episode_y_velocity_std': Array(13.641817, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.32348799705505, 'eval/sps': 501.3248134910188, 'num_steps': 163840}
{'eval/walltime': 1054.302029132843, 'training/sps': 178.68831408936893, 'training/walltime': 1398.4615142345428, 'training/entropy_loss': Array(-0.0049049, dtype=float32), 'training/policy_loss': Array(-0.02558536, dtype=float32), 'training/total_loss': Array(-0.0176698, dtype=float32), 'training/v_loss': Array(0.01282047, dtype=float32), 'eval/episode_distance_from_origin': Array(3637.9663, dtype=float32), 'eval/episode_distance_reward': Array(1.4300132, dtype=float32), 'eval/episode_forward_reward': Array(143.00128, dtype=float32), 'eval/episode_reward': Array(-68.79849, dtype=float32), 'eval/episode_reward_alive': Array(1.4101562, dtype=float32), 'eval/episode_reward_linvel': Array(143.00128, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.63994, dtype=float32), 'eval/episode_x_position': Array(3606.4756, dtype=float32), 'eval/episode_x_velocity': Array(28.600235, dtype=float32), 'eval/episode_y_position': Array(344.4533, dtype=float32), 'eval/episode_y_velocity': Array(-5.594486, dtype=float32), 'eval/episode_distance_from_origin_std': Array(80.68224, dtype=float32), 'eval/episode_distance_reward_std': Array(0.46825042, dtype=float32), 'eval/episode_forward_reward_std': Array(46.825024, dtype=float32), 'eval/episode_reward_std': Array(47.03966, dtype=float32), 'eval/episode_reward_alive_std': Array(2.2856836, dtype=float32), 'eval/episode_reward_linvel_std': Array(46.825024, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.7421622, dtype=float32), 'eval/episode_x_position_std': Array(82.7419, dtype=float32), 'eval/episode_x_velocity_std': Array(9.364985, dtype=float32), 'eval/episode_y_position_std': Array(104.33794, dtype=float32), 'eval/episode_y_velocity_std': Array(12.938461, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.16804790496826, 'eval/sps': 501.63020429450785, 'num_steps': 245760}
{'eval/walltime': 1309.510747909546, 'training/sps': 179.7870899860095, 'training/walltime': 1854.1115834712982, 'training/entropy_loss': Array(-0.00473288, dtype=float32), 'training/policy_loss': Array(-0.02177006, dtype=float32), 'training/total_loss': Array(-0.01728739, dtype=float32), 'training/v_loss': Array(0.00921554, dtype=float32), 'eval/episode_distance_from_origin': Array(3668.5894, dtype=float32), 'eval/episode_distance_reward': Array(1.5379182, dtype=float32), 'eval/episode_forward_reward': Array(153.79178, dtype=float32), 'eval/episode_reward': Array(-57.73247, dtype=float32), 'eval/episode_reward_alive': Array(1.5273438, dtype=float32), 'eval/episode_reward_linvel': Array(153.79178, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.58955, dtype=float32), 'eval/episode_x_position': Array(3638.27, dtype=float32), 'eval/episode_x_velocity': Array(30.758331, dtype=float32), 'eval/episode_y_position': Array(337.21457, dtype=float32), 'eval/episode_y_velocity': Array(-5.1473484, dtype=float32), 'eval/episode_distance_from_origin_std': Array(67.05779, dtype=float32), 'eval/episode_distance_reward_std': Array(0.41023192, dtype=float32), 'eval/episode_forward_reward_std': Array(41.023174, dtype=float32), 'eval/episode_reward_std': Array(41.60641, dtype=float32), 'eval/episode_reward_alive_std': Array(2.593794, dtype=float32), 'eval/episode_reward_linvel_std': Array(41.023174, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.0936446, dtype=float32), 'eval/episode_x_position_std': Array(66.57047, dtype=float32), 'eval/episode_x_velocity_std': Array(8.2046175, dtype=float32), 'eval/episode_y_position_std': Array(95.65229, dtype=float32), 'eval/episode_y_velocity_std': Array(11.546436, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.20871877670288, 'eval/sps': 501.55026291243104, 'num_steps': 327680}
{'eval/walltime': 1564.7304916381836, 'training/sps': 179.3825805976679, 'training/walltime': 2310.7891478538513, 'training/entropy_loss': Array(-0.00465742, dtype=float32), 'training/policy_loss': Array(-0.02574527, dtype=float32), 'training/total_loss': Array(-0.02268478, dtype=float32), 'training/v_loss': Array(0.00771791, dtype=float32), 'eval/episode_distance_from_origin': Array(3670.2402, dtype=float32), 'eval/episode_distance_reward': Array(1.4464164, dtype=float32), 'eval/episode_forward_reward': Array(144.64163, dtype=float32), 'eval/episode_reward': Array(-66.19526, dtype=float32), 'eval/episode_reward_alive': Array(2.4375, dtype=float32), 'eval/episode_reward_linvel': Array(144.64163, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.72083, dtype=float32), 'eval/episode_x_position': Array(3640.2676, dtype=float32), 'eval/episode_x_velocity': Array(28.92831, dtype=float32), 'eval/episode_y_position': Array(332.22083, dtype=float32), 'eval/episode_y_velocity': Array(-2.8889446, dtype=float32), 'eval/episode_distance_from_origin_std': Array(68.90325, dtype=float32), 'eval/episode_distance_reward_std': Array(0.4413551, dtype=float32), 'eval/episode_forward_reward_std': Array(44.135498, dtype=float32), 'eval/episode_reward_std': Array(45.559464, dtype=float32), 'eval/episode_reward_alive_std': Array(3.5405023, dtype=float32), 'eval/episode_reward_linvel_std': Array(44.135498, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.8580303, dtype=float32), 'eval/episode_x_position_std': Array(71.153755, dtype=float32), 'eval/episode_x_velocity_std': Array(8.827077, dtype=float32), 'eval/episode_y_position_std': Array(101.68327, dtype=float32), 'eval/episode_y_velocity_std': Array(13.460752, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.2197437286377, 'eval/sps': 501.5285970042191, 'num_steps': 409600}
{'eval/walltime': 1820.0427994728088, 'training/sps': 178.95402677972092, 'training/walltime': 2768.5603501796722, 'training/entropy_loss': Array(-0.0045428, dtype=float32), 'training/policy_loss': Array(-0.01778548, dtype=float32), 'training/total_loss': Array(-0.0124891, dtype=float32), 'training/v_loss': Array(0.00983917, dtype=float32), 'eval/episode_distance_from_origin': Array(3703.1528, dtype=float32), 'eval/episode_distance_reward': Array(1.6051052, dtype=float32), 'eval/episode_forward_reward': Array(160.5105, dtype=float32), 'eval/episode_reward': Array(-48.92646, dtype=float32), 'eval/episode_reward_alive': Array(4.7460938, dtype=float32), 'eval/episode_reward_linvel': Array(160.5105, dtype=float32), 'eval/episode_reward_quadctrl': Array(-215.78816, dtype=float32), 'eval/episode_x_position': Array(3671.619, dtype=float32), 'eval/episode_x_velocity': Array(32.10209, dtype=float32), 'eval/episode_y_position': Array(351.5, dtype=float32), 'eval/episode_y_velocity': Array(0.7254545, dtype=float32), 'eval/episode_distance_from_origin_std': Array(69.53004, dtype=float32), 'eval/episode_distance_reward_std': Array(0.4267471, dtype=float32), 'eval/episode_forward_reward_std': Array(42.67469, dtype=float32), 'eval/episode_reward_std': Array(44.616116, dtype=float32), 'eval/episode_reward_alive_std': Array(5.0117035, dtype=float32), 'eval/episode_reward_linvel_std': Array(42.67469, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.993672, dtype=float32), 'eval/episode_x_position_std': Array(70.11297, dtype=float32), 'eval/episode_x_velocity_std': Array(8.534917, dtype=float32), 'eval/episode_y_position_std': Array(100.28454, dtype=float32), 'eval/episode_y_velocity_std': Array(12.782799, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.31230783462524, 'eval/sps': 501.3467665762126, 'num_steps': 491520}
{'eval/walltime': 2076.2835581302643, 'training/sps': 179.75509884687304, 'training/walltime': 3224.291511774063, 'training/entropy_loss': Array(-0.00442383, dtype=float32), 'training/policy_loss': Array(-0.02493764, dtype=float32), 'training/total_loss': Array(-0.02263655, dtype=float32), 'training/v_loss': Array(0.00672492, dtype=float32), 'eval/episode_distance_from_origin': Array(3764.7017, dtype=float32), 'eval/episode_distance_reward': Array(2.0012205, dtype=float32), 'eval/episode_forward_reward': Array(200.12202, dtype=float32), 'eval/episode_reward': Array(-4.528837, dtype=float32), 'eval/episode_reward_alive': Array(7.9804688, dtype=float32), 'eval/episode_reward_linvel': Array(200.12202, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.63257, dtype=float32), 'eval/episode_x_position': Array(3736.2327, dtype=float32), 'eval/episode_x_velocity': Array(40.02438, dtype=float32), 'eval/episode_y_position': Array(324.12973, dtype=float32), 'eval/episode_y_velocity': Array(-1.6913648, dtype=float32), 'eval/episode_distance_from_origin_std': Array(64.72399, dtype=float32), 'eval/episode_distance_reward_std': Array(0.3717735, dtype=float32), 'eval/episode_forward_reward_std': Array(37.17735, dtype=float32), 'eval/episode_reward_std': Array(39.46319, dtype=float32), 'eval/episode_reward_alive_std': Array(5.702385, dtype=float32), 'eval/episode_reward_linvel_std': Array(37.17735, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.5459332, dtype=float32), 'eval/episode_x_position_std': Array(64.04363, dtype=float32), 'eval/episode_x_velocity_std': Array(7.435454, dtype=float32), 'eval/episode_y_position_std': Array(96.263016, dtype=float32), 'eval/episode_y_velocity_std': Array(11.606416, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.24075865745544, 'eval/sps': 499.5302100674442, 'num_steps': 573440}
{'eval/walltime': 2331.4478425979614, 'training/sps': 179.54954663885465, 'training/walltime': 3680.5444042682648, 'training/entropy_loss': Array(-0.00422817, dtype=float32), 'training/policy_loss': Array(-0.02236234, dtype=float32), 'training/total_loss': Array(-0.01954592, dtype=float32), 'training/v_loss': Array(0.00704459, dtype=float32), 'eval/episode_distance_from_origin': Array(3833.774, dtype=float32), 'eval/episode_distance_reward': Array(2.4182365, dtype=float32), 'eval/episode_forward_reward': Array(241.8236, dtype=float32), 'eval/episode_reward': Array(42.71954, dtype=float32), 'eval/episode_reward_alive': Array(11.808594, dtype=float32), 'eval/episode_reward_linvel': Array(241.8236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-213.33095, dtype=float32), 'eval/episode_x_position': Array(3808.7166, dtype=float32), 'eval/episode_x_velocity': Array(48.36468, dtype=float32), 'eval/episode_y_position': Array(291.62848, dtype=float32), 'eval/episode_y_velocity': Array(-5.2431545, dtype=float32), 'eval/episode_distance_from_origin_std': Array(68.943504, dtype=float32), 'eval/episode_distance_reward_std': Array(0.3985617, dtype=float32), 'eval/episode_forward_reward_std': Array(39.85614, dtype=float32), 'eval/episode_reward_std': Array(42.043217, dtype=float32), 'eval/episode_reward_alive_std': Array(5.367408, dtype=float32), 'eval/episode_reward_linvel_std': Array(39.85614, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.7003, dtype=float32), 'eval/episode_x_position_std': Array(70.4045, dtype=float32), 'eval/episode_x_velocity_std': Array(7.971219, dtype=float32), 'eval/episode_y_position_std': Array(80.58221, dtype=float32), 'eval/episode_y_velocity_std': Array(9.93686, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.16428446769714, 'eval/sps': 501.63760287621415, 'num_steps': 655360}
{'eval/walltime': 2587.580340385437, 'training/sps': 179.5542876496944, 'training/walltime': 4136.785249710083, 'training/entropy_loss': Array(-0.00406895, dtype=float32), 'training/policy_loss': Array(-0.01120333, dtype=float32), 'training/total_loss': Array(-0.00620328, dtype=float32), 'training/v_loss': Array(0.009069, dtype=float32), 'eval/episode_distance_from_origin': Array(3868.8423, dtype=float32), 'eval/episode_distance_reward': Array(2.6376758, dtype=float32), 'eval/episode_forward_reward': Array(263.76755, dtype=float32), 'eval/episode_reward': Array(67.37793, dtype=float32), 'eval/episode_reward_alive': Array(14.160156, dtype=float32), 'eval/episode_reward_linvel': Array(263.76755, dtype=float32), 'eval/episode_reward_quadctrl': Array(-213.18747, dtype=float32), 'eval/episode_x_position': Array(3847.2659, dtype=float32), 'eval/episode_x_velocity': Array(52.75346, dtype=float32), 'eval/episode_y_position': Array(245.87378, dtype=float32), 'eval/episode_y_velocity': Array(-10.913903, dtype=float32), 'eval/episode_distance_from_origin_std': Array(66.89143, dtype=float32), 'eval/episode_distance_reward_std': Array(0.37852868, dtype=float32), 'eval/episode_forward_reward_std': Array(37.852886, dtype=float32), 'eval/episode_reward_std': Array(39.848778, dtype=float32), 'eval/episode_reward_alive_std': Array(4.864144, dtype=float32), 'eval/episode_reward_linvel_std': Array(37.852886, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.3388202, dtype=float32), 'eval/episode_x_position_std': Array(67.84675, dtype=float32), 'eval/episode_x_velocity_std': Array(7.5705605, dtype=float32), 'eval/episode_y_position_std': Array(77.938545, dtype=float32), 'eval/episode_y_velocity_std': Array(9.047584, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.1324977874756, 'eval/sps': 499.74134912863434, 'num_steps': 737280}
{'eval/walltime': 2843.53710770607, 'training/sps': 179.31612723401923, 'training/walltime': 4593.63205575943, 'training/entropy_loss': Array(-0.00384748, dtype=float32), 'training/policy_loss': Array(-0.01512003, dtype=float32), 'training/total_loss': Array(-0.01382714, dtype=float32), 'training/v_loss': Array(0.00514038, dtype=float32), 'eval/episode_distance_from_origin': Array(3900.1313, dtype=float32), 'eval/episode_distance_reward': Array(2.8215845, dtype=float32), 'eval/episode_forward_reward': Array(282.1584, dtype=float32), 'eval/episode_reward': Array(88.66697, dtype=float32), 'eval/episode_reward_alive': Array(16.40625, dtype=float32), 'eval/episode_reward_linvel': Array(282.1584, dtype=float32), 'eval/episode_reward_quadctrl': Array(-212.71928, dtype=float32), 'eval/episode_x_position': Array(3879.7446, dtype=float32), 'eval/episode_x_velocity': Array(56.431618, dtype=float32), 'eval/episode_y_position': Array(228.73824, dtype=float32), 'eval/episode_y_velocity': Array(-12.308384, dtype=float32), 'eval/episode_distance_from_origin_std': Array(51.89689, dtype=float32), 'eval/episode_distance_reward_std': Array(0.30303007, dtype=float32), 'eval/episode_forward_reward_std': Array(30.30299, dtype=float32), 'eval/episode_reward_std': Array(31.822575, dtype=float32), 'eval/episode_reward_alive_std': Array(4.0213056, dtype=float32), 'eval/episode_reward_linvel_std': Array(30.30299, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.3337607, dtype=float32), 'eval/episode_x_position_std': Array(52.082493, dtype=float32), 'eval/episode_x_velocity_std': Array(6.0605836, dtype=float32), 'eval/episode_y_position_std': Array(75.4489, dtype=float32), 'eval/episode_y_velocity_std': Array(9.032186, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.95676732063293, 'eval/sps': 500.0844530891284, 'num_steps': 819200}
{'eval/walltime': 3099.3173949718475, 'training/sps': 179.59163431357018, 'training/walltime': 5049.778024435043, 'training/entropy_loss': Array(-0.00356635, dtype=float32), 'training/policy_loss': Array(-0.01435622, dtype=float32), 'training/total_loss': Array(-0.01275485, dtype=float32), 'training/v_loss': Array(0.00516772, dtype=float32), 'eval/episode_distance_from_origin': Array(3929.1572, dtype=float32), 'eval/episode_distance_reward': Array(2.9831727, dtype=float32), 'eval/episode_forward_reward': Array(298.31717, dtype=float32), 'eval/episode_reward': Array(106.767555, dtype=float32), 'eval/episode_reward_alive': Array(17.375, dtype=float32), 'eval/episode_reward_linvel': Array(298.31717, dtype=float32), 'eval/episode_reward_quadctrl': Array(-211.9079, dtype=float32), 'eval/episode_x_position': Array(3911.392, dtype=float32), 'eval/episode_x_velocity': Array(59.663376, dtype=float32), 'eval/episode_y_position': Array(179.80241, dtype=float32), 'eval/episode_y_velocity': Array(-17.45939, dtype=float32), 'eval/episode_distance_from_origin_std': Array(52.85961, dtype=float32), 'eval/episode_distance_reward_std': Array(0.31616637, dtype=float32), 'eval/episode_forward_reward_std': Array(31.616611, dtype=float32), 'eval/episode_reward_std': Array(33.17268, dtype=float32), 'eval/episode_reward_alive_std': Array(3.4988837, dtype=float32), 'eval/episode_reward_linvel_std': Array(31.616611, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.5197287, dtype=float32), 'eval/episode_x_position_std': Array(53.161316, dtype=float32), 'eval/episode_x_velocity_std': Array(6.3233085, dtype=float32), 'eval/episode_y_position_std': Array(73.84535, dtype=float32), 'eval/episode_y_velocity_std': Array(8.441772, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.7802872657776, 'eval/sps': 500.4294950493861, 'num_steps': 901120}
{'eval/walltime': 3354.4930744171143, 'training/sps': 179.86842091377002, 'training/walltime': 5505.222062826157, 'training/entropy_loss': Array(-0.00327986, dtype=float32), 'training/policy_loss': Array(-0.00885858, dtype=float32), 'training/total_loss': Array(-0.00694757, dtype=float32), 'training/v_loss': Array(0.00519086, dtype=float32), 'eval/episode_distance_from_origin': Array(3967.6245, dtype=float32), 'eval/episode_distance_reward': Array(3.2138312, dtype=float32), 'eval/episode_forward_reward': Array(321.38306, dtype=float32), 'eval/episode_reward': Array(132.16495, dtype=float32), 'eval/episode_reward_alive': Array(18.695312, dtype=float32), 'eval/episode_reward_linvel': Array(321.38306, dtype=float32), 'eval/episode_reward_quadctrl': Array(-211.1273, dtype=float32), 'eval/episode_x_position': Array(3950.2222, dtype=float32), 'eval/episode_x_velocity': Array(64.276535, dtype=float32), 'eval/episode_y_position': Array(158.06805, dtype=float32), 'eval/episode_y_velocity': Array(-20.26778, dtype=float32), 'eval/episode_distance_from_origin_std': Array(74.98706, dtype=float32), 'eval/episode_distance_reward_std': Array(0.43857324, dtype=float32), 'eval/episode_forward_reward_std': Array(43.8573, dtype=float32), 'eval/episode_reward_std': Array(45.020634, dtype=float32), 'eval/episode_reward_alive_std': Array(2.7316391, dtype=float32), 'eval/episode_reward_linvel_std': Array(43.8573, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.6356509, dtype=float32), 'eval/episode_x_position_std': Array(75.019264, dtype=float32), 'eval/episode_x_velocity_std': Array(8.771424, dtype=float32), 'eval/episode_y_position_std': Array(92.572754, dtype=float32), 'eval/episode_y_velocity_std': Array(11.626504, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.17567944526672, 'eval/sps': 501.6152020375243, 'num_steps': 983040}
{'eval/walltime': 3609.7198102474213, 'training/sps': 179.486514685519, 'training/walltime': 5961.635181903839, 'training/entropy_loss': Array(-0.00300142, dtype=float32), 'training/policy_loss': Array(-0.00996147, dtype=float32), 'training/total_loss': Array(-0.00696525, dtype=float32), 'training/v_loss': Array(0.00599764, dtype=float32), 'eval/episode_distance_from_origin': Array(4032.5898, dtype=float32), 'eval/episode_distance_reward': Array(3.6499534, dtype=float32), 'eval/episode_forward_reward': Array(364.99524, dtype=float32), 'eval/episode_reward': Array(177.67398, dtype=float32), 'eval/episode_reward_alive': Array(19.589844, dtype=float32), 'eval/episode_reward_linvel': Array(364.99524, dtype=float32), 'eval/episode_reward_quadctrl': Array(-210.56113, dtype=float32), 'eval/episode_x_position': Array(4015.5098, dtype=float32), 'eval/episode_x_velocity': Array(72.998924, dtype=float32), 'eval/episode_y_position': Array(73.55254, dtype=float32), 'eval/episode_y_velocity': Array(-29.70999, dtype=float32), 'eval/episode_distance_from_origin_std': Array(105.9316, dtype=float32), 'eval/episode_distance_reward_std': Array(0.6758486, dtype=float32), 'eval/episode_forward_reward_std': Array(67.58478, dtype=float32), 'eval/episode_reward_std': Array(68.243, dtype=float32), 'eval/episode_reward_alive_std': Array(3.0716913, dtype=float32), 'eval/episode_reward_linvel_std': Array(67.58478, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.2756395, dtype=float32), 'eval/episode_x_position_std': Array(105.21317, dtype=float32), 'eval/episode_x_velocity_std': Array(13.516919, dtype=float32), 'eval/episode_y_position_std': Array(142.77411, dtype=float32), 'eval/episode_y_velocity_std': Array(17.825863, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.226735830307, 'eval/sps': 501.51485730359985, 'num_steps': 1064960}
{'eval/walltime': 3864.9262590408325, 'training/sps': 179.24928479877636, 'training/walltime': 6418.65234708786, 'training/entropy_loss': Array(-0.00280799, dtype=float32), 'training/policy_loss': Array(-0.01076688, dtype=float32), 'training/total_loss': Array(-0.00909278, dtype=float32), 'training/v_loss': Array(0.00448209, dtype=float32), 'eval/episode_distance_from_origin': Array(4201.0615, dtype=float32), 'eval/episode_distance_reward': Array(4.6479807, dtype=float32), 'eval/episode_forward_reward': Array(464.7979, dtype=float32), 'eval/episode_reward': Array(273.0983, dtype=float32), 'eval/episode_reward_alive': Array(21.535156, dtype=float32), 'eval/episode_reward_linvel': Array(464.7979, dtype=float32), 'eval/episode_reward_quadctrl': Array(-217.88293, dtype=float32), 'eval/episode_x_position': Array(4172.727, dtype=float32), 'eval/episode_x_velocity': Array(92.95945, dtype=float32), 'eval/episode_y_position': Array(-176.56726, dtype=float32), 'eval/episode_y_velocity': Array(-64.921455, dtype=float32), 'eval/episode_distance_from_origin_std': Array(179.9651, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1860373, dtype=float32), 'eval/episode_forward_reward_std': Array(118.60375, dtype=float32), 'eval/episode_reward_std': Array(118.70736, dtype=float32), 'eval/episode_reward_alive_std': Array(3.3976, dtype=float32), 'eval/episode_reward_linvel_std': Array(118.60375, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.3859086, dtype=float32), 'eval/episode_x_position_std': Array(169.85062, dtype=float32), 'eval/episode_x_velocity_std': Array(23.720688, dtype=float32), 'eval/episode_y_position_std': Array(233.37196, dtype=float32), 'eval/episode_y_velocity_std': Array(31.338562, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.20644879341125, 'eval/sps': 501.55472404859, 'num_steps': 1146880}
{'eval/walltime': 4120.165840148926, 'training/sps': 179.39881827647105, 'training/walltime': 6875.288576841354, 'training/entropy_loss': Array(-0.00206783, dtype=float32), 'training/policy_loss': Array(-0.00311459, dtype=float32), 'training/total_loss': Array(0.0144654, dtype=float32), 'training/v_loss': Array(0.01964782, dtype=float32), 'eval/episode_distance_from_origin': Array(4361.9956, dtype=float32), 'eval/episode_distance_reward': Array(5.4322953, dtype=float32), 'eval/episode_forward_reward': Array(543.22955, dtype=float32), 'eval/episode_reward': Array(343.29044, dtype=float32), 'eval/episode_reward_alive': Array(23.738281, dtype=float32), 'eval/episode_reward_linvel': Array(543.22955, dtype=float32), 'eval/episode_reward_quadctrl': Array(-229.10979, dtype=float32), 'eval/episode_x_position': Array(4300.249, dtype=float32), 'eval/episode_x_velocity': Array(108.645775, dtype=float32), 'eval/episode_y_position': Array(-481.41895, dtype=float32), 'eval/episode_y_velocity': Array(-107.81716, dtype=float32), 'eval/episode_distance_from_origin_std': Array(243.7471, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4945683, dtype=float32), 'eval/episode_forward_reward_std': Array(149.45718, dtype=float32), 'eval/episode_reward_std': Array(149.81218, dtype=float32), 'eval/episode_reward_alive_std': Array(4.9240184, dtype=float32), 'eval/episode_reward_linvel_std': Array(149.45718, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(10.007842, dtype=float32), 'eval/episode_x_position_std': Array(213.52621, dtype=float32), 'eval/episode_x_velocity_std': Array(29.891346, dtype=float32), 'eval/episode_y_position_std': Array(280.83945, dtype=float32), 'eval/episode_y_velocity_std': Array(39.759823, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.23958110809326, 'eval/sps': 501.48961788881934, 'num_steps': 1228800}
{'eval/walltime': 4375.954516887665, 'training/sps': 179.2203964595874, 'training/walltime': 7332.379408121109, 'training/entropy_loss': Array(-0.0015349, dtype=float32), 'training/policy_loss': Array(0.05731769, dtype=float32), 'training/total_loss': Array(0.07417769, dtype=float32), 'training/v_loss': Array(0.01839491, dtype=float32), 'eval/episode_distance_from_origin': Array(4365.226, dtype=float32), 'eval/episode_distance_reward': Array(5.3263693, dtype=float32), 'eval/episode_forward_reward': Array(532.6369, dtype=float32), 'eval/episode_reward': Array(327.7801, dtype=float32), 'eval/episode_reward_alive': Array(21.75, dtype=float32), 'eval/episode_reward_linvel': Array(532.6369, dtype=float32), 'eval/episode_reward_quadctrl': Array(-231.93332, dtype=float32), 'eval/episode_x_position': Array(4286.8447, dtype=float32), 'eval/episode_x_velocity': Array(106.52724, dtype=float32), 'eval/episode_y_position': Array(-581.0567, dtype=float32), 'eval/episode_y_velocity': Array(-120.92096, dtype=float32), 'eval/episode_distance_from_origin_std': Array(202.56644, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2529131, dtype=float32), 'eval/episode_forward_reward_std': Array(125.29147, dtype=float32), 'eval/episode_reward_std': Array(126.75411, dtype=float32), 'eval/episode_reward_alive_std': Array(5.173928, dtype=float32), 'eval/episode_reward_linvel_std': Array(125.29147, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.982472, dtype=float32), 'eval/episode_x_position_std': Array(182.59299, dtype=float32), 'eval/episode_x_velocity_std': Array(25.058245, dtype=float32), 'eval/episode_y_position_std': Array(284.92908, dtype=float32), 'eval/episode_y_velocity_std': Array(39.712364, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.788676738739, 'eval/sps': 500.41308173597696, 'num_steps': 1310720}
{'eval/walltime': 4632.380164861679, 'training/sps': 179.2268162414512, 'training/walltime': 7789.4538667202, 'training/entropy_loss': Array(-0.00144636, dtype=float32), 'training/policy_loss': Array(0.00675448, dtype=float32), 'training/total_loss': Array(0.03392023, dtype=float32), 'training/v_loss': Array(0.02861211, dtype=float32), 'eval/episode_distance_from_origin': Array(4313.3223, dtype=float32), 'eval/episode_distance_reward': Array(5.067267, dtype=float32), 'eval/episode_forward_reward': Array(506.72656, dtype=float32), 'eval/episode_reward': Array(310.39667, dtype=float32), 'eval/episode_reward_alive': Array(20.507812, dtype=float32), 'eval/episode_reward_linvel': Array(506.72656, dtype=float32), 'eval/episode_reward_quadctrl': Array(-221.90517, dtype=float32), 'eval/episode_x_position': Array(4258.652, dtype=float32), 'eval/episode_x_velocity': Array(101.3452, dtype=float32), 'eval/episode_y_position': Array(-462.0725, dtype=float32), 'eval/episode_y_velocity': Array(-101.14261, dtype=float32), 'eval/episode_distance_from_origin_std': Array(181.12909, dtype=float32), 'eval/episode_distance_reward_std': Array(1.0617021, dtype=float32), 'eval/episode_forward_reward_std': Array(106.17021, dtype=float32), 'eval/episode_reward_std': Array(106.66274, dtype=float32), 'eval/episode_reward_alive_std': Array(3.3065894, dtype=float32), 'eval/episode_reward_linvel_std': Array(106.17021, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.1215253, dtype=float32), 'eval/episode_x_position_std': Array(162.87889, dtype=float32), 'eval/episode_x_velocity_std': Array(21.234003, dtype=float32), 'eval/episode_y_position_std': Array(233.41011, dtype=float32), 'eval/episode_y_velocity_std': Array(30.596561, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.4256479740143, 'eval/sps': 499.17003627098677, 'num_steps': 1392640}
{'eval/walltime': 4888.10556769371, 'training/sps': 179.12058883499787, 'training/walltime': 8246.799393177032, 'training/entropy_loss': Array(-0.00171054, dtype=float32), 'training/policy_loss': Array(-0.003384, dtype=float32), 'training/total_loss': Array(0.011354, dtype=float32), 'training/v_loss': Array(0.01644855, dtype=float32), 'eval/episode_distance_from_origin': Array(4424.1353, dtype=float32), 'eval/episode_distance_reward': Array(5.7838078, dtype=float32), 'eval/episode_forward_reward': Array(578.38086, dtype=float32), 'eval/episode_reward': Array(384.34296, dtype=float32), 'eval/episode_reward_alive': Array(22.242188, dtype=float32), 'eval/episode_reward_linvel': Array(578.38086, dtype=float32), 'eval/episode_reward_quadctrl': Array(-222.06386, dtype=float32), 'eval/episode_x_position': Array(4368.991, dtype=float32), 'eval/episode_x_velocity': Array(115.67601, dtype=float32), 'eval/episode_y_position': Array(-473.08737, dtype=float32), 'eval/episode_y_velocity': Array(-103.37391, dtype=float32), 'eval/episode_distance_from_origin_std': Array(254.80026, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5640856, dtype=float32), 'eval/episode_forward_reward_std': Array(156.40889, dtype=float32), 'eval/episode_reward_std': Array(155.74835, dtype=float32), 'eval/episode_reward_alive_std': Array(3.9394758, dtype=float32), 'eval/episode_reward_linvel_std': Array(156.40889, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.9115124, dtype=float32), 'eval/episode_x_position_std': Array(235.4531, dtype=float32), 'eval/episode_x_velocity_std': Array(31.281708, dtype=float32), 'eval/episode_y_position_std': Array(238.06166, dtype=float32), 'eval/episode_y_velocity_std': Array(32.48001, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.72540283203125, 'eval/sps': 500.53689849527603, 'num_steps': 1474560}
{'eval/walltime': 5143.86260509491, 'training/sps': 178.93375997576848, 'training/walltime': 8704.62244462967, 'training/entropy_loss': Array(-0.00156437, dtype=float32), 'training/policy_loss': Array(-0.00305416, dtype=float32), 'training/total_loss': Array(0.01552773, dtype=float32), 'training/v_loss': Array(0.02014627, dtype=float32), 'eval/episode_distance_from_origin': Array(4439.857, dtype=float32), 'eval/episode_distance_reward': Array(5.905382, dtype=float32), 'eval/episode_forward_reward': Array(590.5382, dtype=float32), 'eval/episode_reward': Array(396.46036, dtype=float32), 'eval/episode_reward_alive': Array(21.605469, dtype=float32), 'eval/episode_reward_linvel': Array(590.5382, dtype=float32), 'eval/episode_reward_quadctrl': Array(-221.58878, dtype=float32), 'eval/episode_x_position': Array(4389.5293, dtype=float32), 'eval/episode_x_velocity': Array(118.10746, dtype=float32), 'eval/episode_y_position': Array(-456.09177, dtype=float32), 'eval/episode_y_velocity': Array(-99.49475, dtype=float32), 'eval/episode_distance_from_origin_std': Array(224.16628, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3521968, dtype=float32), 'eval/episode_forward_reward_std': Array(135.21992, dtype=float32), 'eval/episode_reward_std': Array(133.98889, dtype=float32), 'eval/episode_reward_alive_std': Array(3.8470018, dtype=float32), 'eval/episode_reward_linvel_std': Array(135.21992, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.780785, dtype=float32), 'eval/episode_x_position_std': Array(208.09357, dtype=float32), 'eval/episode_x_velocity_std': Array(27.043936, dtype=float32), 'eval/episode_y_position_std': Array(205.81213, dtype=float32), 'eval/episode_y_velocity_std': Array(26.47689, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.75703740119934, 'eval/sps': 500.4749871230709, 'num_steps': 1556480}
{'eval/walltime': 5400.0015025138855, 'training/sps': 179.03236063425362, 'training/walltime': 9162.193353652954, 'training/entropy_loss': Array(-0.00146294, dtype=float32), 'training/policy_loss': Array(-0.00639752, dtype=float32), 'training/total_loss': Array(0.00399605, dtype=float32), 'training/v_loss': Array(0.01185651, dtype=float32), 'eval/episode_distance_from_origin': Array(4487.665, dtype=float32), 'eval/episode_distance_reward': Array(6.1913013, dtype=float32), 'eval/episode_forward_reward': Array(619.13025, dtype=float32), 'eval/episode_reward': Array(426.1131, dtype=float32), 'eval/episode_reward_alive': Array(23.554688, dtype=float32), 'eval/episode_reward_linvel': Array(619.13025, dtype=float32), 'eval/episode_reward_quadctrl': Array(-222.76332, dtype=float32), 'eval/episode_x_position': Array(4441.077, dtype=float32), 'eval/episode_x_velocity': Array(123.8259, dtype=float32), 'eval/episode_y_position': Array(-425.9431, dtype=float32), 'eval/episode_y_velocity': Array(-95.38258, dtype=float32), 'eval/episode_distance_from_origin_std': Array(249.72389, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5365425, dtype=float32), 'eval/episode_forward_reward_std': Array(153.65475, dtype=float32), 'eval/episode_reward_std': Array(153.70415, dtype=float32), 'eval/episode_reward_alive_std': Array(4.518726, dtype=float32), 'eval/episode_reward_linvel_std': Array(153.65475, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.980239, dtype=float32), 'eval/episode_x_position_std': Array(235.2665, dtype=float32), 'eval/episode_x_velocity_std': Array(30.730911, dtype=float32), 'eval/episode_y_position_std': Array(215.77548, dtype=float32), 'eval/episode_y_velocity_std': Array(27.847927, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.13889741897583, 'eval/sps': 499.7288630887861, 'num_steps': 1638400}
{'eval/walltime': 5656.225544929504, 'training/sps': 179.28453602655375, 'training/walltime': 9619.120659351349, 'training/entropy_loss': Array(-0.00121909, dtype=float32), 'training/policy_loss': Array(-0.0053703, dtype=float32), 'training/total_loss': Array(0.0022735, dtype=float32), 'training/v_loss': Array(0.00886289, dtype=float32), 'eval/episode_distance_from_origin': Array(4612.046, dtype=float32), 'eval/episode_distance_reward': Array(7.007369, dtype=float32), 'eval/episode_forward_reward': Array(700.73724, dtype=float32), 'eval/episode_reward': Array(501.44635, dtype=float32), 'eval/episode_reward_alive': Array(24.425781, dtype=float32), 'eval/episode_reward_linvel': Array(700.73724, dtype=float32), 'eval/episode_reward_quadctrl': Array(-230.72426, dtype=float32), 'eval/episode_x_position': Array(4560.872, dtype=float32), 'eval/episode_x_velocity': Array(140.14726, dtype=float32), 'eval/episode_y_position': Array(-482.28497, dtype=float32), 'eval/episode_y_velocity': Array(-103.81027, dtype=float32), 'eval/episode_distance_from_origin_std': Array(252.9567, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6290349, dtype=float32), 'eval/episode_forward_reward_std': Array(162.90437, dtype=float32), 'eval/episode_reward_std': Array(162.52231, dtype=float32), 'eval/episode_reward_alive_std': Array(4.829956, dtype=float32), 'eval/episode_reward_linvel_std': Array(162.90437, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.636127, dtype=float32), 'eval/episode_x_position_std': Array(241.54863, dtype=float32), 'eval/episode_x_velocity_std': Array(32.58083, dtype=float32), 'eval/episode_y_position_std': Array(174.6791, dtype=float32), 'eval/episode_y_velocity_std': Array(23.699978, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.2240424156189, 'eval/sps': 499.56279977962515, 'num_steps': 1720320}
{'eval/walltime': 5912.2311408519745, 'training/sps': 179.27773017968235, 'training/walltime': 10076.065311193466, 'training/entropy_loss': Array(-0.00072002, dtype=float32), 'training/policy_loss': Array(-0.00288925, dtype=float32), 'training/total_loss': Array(0.01230412, dtype=float32), 'training/v_loss': Array(0.01591339, dtype=float32), 'eval/episode_distance_from_origin': Array(4593.8184, dtype=float32), 'eval/episode_distance_reward': Array(6.899875, dtype=float32), 'eval/episode_forward_reward': Array(689.98785, dtype=float32), 'eval/episode_reward': Array(492.0258, dtype=float32), 'eval/episode_reward_alive': Array(25.59375, dtype=float32), 'eval/episode_reward_linvel': Array(689.98785, dtype=float32), 'eval/episode_reward_quadctrl': Array(-230.45587, dtype=float32), 'eval/episode_x_position': Array(4544.373, dtype=float32), 'eval/episode_x_velocity': Array(137.99738, dtype=float32), 'eval/episode_y_position': Array(-463.81317, dtype=float32), 'eval/episode_y_velocity': Array(-101.05886, dtype=float32), 'eval/episode_distance_from_origin_std': Array(241.23013, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4798074, dtype=float32), 'eval/episode_forward_reward_std': Array(147.98154, dtype=float32), 'eval/episode_reward_std': Array(147.40501, dtype=float32), 'eval/episode_reward_alive_std': Array(6.34144, dtype=float32), 'eval/episode_reward_linvel_std': Array(147.98154, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.948216, dtype=float32), 'eval/episode_x_position_std': Array(225.69511, dtype=float32), 'eval/episode_x_velocity_std': Array(29.596268, dtype=float32), 'eval/episode_y_position_std': Array(197.5647, dtype=float32), 'eval/episode_y_velocity_std': Array(25.743185, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.0055959224701, 'eval/sps': 499.9890707028299, 'num_steps': 1802240}
{'eval/walltime': 6032.386557340622, 'training/sps': 245.65270697924916, 'training/walltime': 10409.544233560562, 'training/entropy_loss': Array(-0.0007287, dtype=float32), 'training/policy_loss': Array(-0.00020403, dtype=float32), 'training/total_loss': Array(0.01345757, dtype=float32), 'training/v_loss': Array(0.0143903, dtype=float32), 'eval/episode_distance_from_origin': Array(4627.169, dtype=float32), 'eval/episode_distance_reward': Array(7.0736084, dtype=float32), 'eval/episode_forward_reward': Array(707.3613, dtype=float32), 'eval/episode_reward': Array(506.4963, dtype=float32), 'eval/episode_reward_alive': Array(25.214844, dtype=float32), 'eval/episode_reward_linvel': Array(707.3613, dtype=float32), 'eval/episode_reward_quadctrl': Array(-233.15366, dtype=float32), 'eval/episode_x_position': Array(4576.49, dtype=float32), 'eval/episode_x_velocity': Array(141.47208, dtype=float32), 'eval/episode_y_position': Array(-482.316, dtype=float32), 'eval/episode_y_velocity': Array(-103.22181, dtype=float32), 'eval/episode_distance_from_origin_std': Array(238.35466, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4784107, dtype=float32), 'eval/episode_forward_reward_std': Array(147.84195, dtype=float32), 'eval/episode_reward_std': Array(147.09233, dtype=float32), 'eval/episode_reward_alive_std': Array(5.070859, dtype=float32), 'eval/episode_reward_linvel_std': Array(147.84195, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.649963, dtype=float32), 'eval/episode_x_position_std': Array(224.251, dtype=float32), 'eval/episode_x_velocity_std': Array(29.568365, dtype=float32), 'eval/episode_y_position_std': Array(175.64206, dtype=float32), 'eval/episode_y_velocity_std': Array(23.559673, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.15541648864746, 'eval/sps': 1065.2869736595997, 'num_steps': 1884160}
{'eval/walltime': 6152.292717933655, 'training/sps': 585.4985080460837, 'training/walltime': 10549.459192991257, 'training/entropy_loss': Array(-0.00049903, dtype=float32), 'training/policy_loss': Array(-0.00197528, dtype=float32), 'training/total_loss': Array(0.01592412, dtype=float32), 'training/v_loss': Array(0.01839842, dtype=float32), 'eval/episode_distance_from_origin': Array(4672.925, dtype=float32), 'eval/episode_distance_reward': Array(7.4206295, dtype=float32), 'eval/episode_forward_reward': Array(742.0634, dtype=float32), 'eval/episode_reward': Array(538.7416, dtype=float32), 'eval/episode_reward_alive': Array(26.304688, dtype=float32), 'eval/episode_reward_linvel': Array(742.0634, dtype=float32), 'eval/episode_reward_quadctrl': Array(-237.04733, dtype=float32), 'eval/episode_x_position': Array(4622.002, dtype=float32), 'eval/episode_x_velocity': Array(148.41248, dtype=float32), 'eval/episode_y_position': Array(-486.41592, dtype=float32), 'eval/episode_y_velocity': Array(-105.10631, dtype=float32), 'eval/episode_distance_from_origin_std': Array(235.12553, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5037832, dtype=float32), 'eval/episode_forward_reward_std': Array(150.37941, dtype=float32), 'eval/episode_reward_std': Array(151.09804, dtype=float32), 'eval/episode_reward_alive_std': Array(6.436964, dtype=float32), 'eval/episode_reward_linvel_std': Array(150.37941, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(13.300911, dtype=float32), 'eval/episode_x_position_std': Array(224.2205, dtype=float32), 'eval/episode_x_velocity_std': Array(30.075819, dtype=float32), 'eval/episode_y_position_std': Array(171.3295, dtype=float32), 'eval/episode_y_velocity_std': Array(22.503119, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90616059303284, 'eval/sps': 1067.5014475231012, 'num_steps': 1966080}
{'eval/walltime': 6272.140587568283, 'training/sps': 585.3248104281445, 'training/walltime': 10689.415672779083, 'training/entropy_loss': Array(-0.00019571, dtype=float32), 'training/policy_loss': Array(-0.00350955, dtype=float32), 'training/total_loss': Array(0.00681432, dtype=float32), 'training/v_loss': Array(0.01051958, dtype=float32), 'eval/episode_distance_from_origin': Array(4696.2227, dtype=float32), 'eval/episode_distance_reward': Array(7.63183, dtype=float32), 'eval/episode_forward_reward': Array(763.18384, dtype=float32), 'eval/episode_reward': Array(551.68225, dtype=float32), 'eval/episode_reward_alive': Array(24.503906, dtype=float32), 'eval/episode_reward_linvel': Array(763.18384, dtype=float32), 'eval/episode_reward_quadctrl': Array(-243.63754, dtype=float32), 'eval/episode_x_position': Array(4639.7188, dtype=float32), 'eval/episode_x_velocity': Array(152.63657, dtype=float32), 'eval/episode_y_position': Array(-518.3097, dtype=float32), 'eval/episode_y_velocity': Array(-110.12904, dtype=float32), 'eval/episode_distance_from_origin_std': Array(275.534, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8263313, dtype=float32), 'eval/episode_forward_reward_std': Array(182.63466, dtype=float32), 'eval/episode_reward_std': Array(182.21468, dtype=float32), 'eval/episode_reward_alive_std': Array(7.053782, dtype=float32), 'eval/episode_reward_linvel_std': Array(182.63466, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.489881, dtype=float32), 'eval/episode_x_position_std': Array(256.93152, dtype=float32), 'eval/episode_x_velocity_std': Array(36.52685, dtype=float32), 'eval/episode_y_position_std': Array(210.25366, dtype=float32), 'eval/episode_y_velocity_std': Array(29.26269, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8478696346283, 'eval/sps': 1068.0206531015072, 'num_steps': 2048000}
{'eval/walltime': 6392.101379394531, 'training/sps': 585.3843819773939, 'training/walltime': 10829.357909917831, 'training/entropy_loss': Array(0.00049205, dtype=float32), 'training/policy_loss': Array(-0.00217861, dtype=float32), 'training/total_loss': Array(0.01392272, dtype=float32), 'training/v_loss': Array(0.01560928, dtype=float32), 'eval/episode_distance_from_origin': Array(4735.2627, dtype=float32), 'eval/episode_distance_reward': Array(7.8310966, dtype=float32), 'eval/episode_forward_reward': Array(783.11035, dtype=float32), 'eval/episode_reward': Array(563.60583, dtype=float32), 'eval/episode_reward_alive': Array(24.355469, dtype=float32), 'eval/episode_reward_linvel': Array(783.11035, dtype=float32), 'eval/episode_reward_quadctrl': Array(-251.69138, dtype=float32), 'eval/episode_x_position': Array(4675.3433, dtype=float32), 'eval/episode_x_velocity': Array(156.62183, dtype=float32), 'eval/episode_y_position': Array(-551.214, dtype=float32), 'eval/episode_y_velocity': Array(-114.138245, dtype=float32), 'eval/episode_distance_from_origin_std': Array(255.11214, dtype=float32), 'eval/episode_distance_reward_std': Array(1.686227, dtype=float32), 'eval/episode_forward_reward_std': Array(168.62392, dtype=float32), 'eval/episode_reward_std': Array(169.72795, dtype=float32), 'eval/episode_reward_alive_std': Array(6.2930245, dtype=float32), 'eval/episode_reward_linvel_std': Array(168.62392, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(13.060321, dtype=float32), 'eval/episode_x_position_std': Array(241.20319, dtype=float32), 'eval/episode_x_velocity_std': Array(33.724743, dtype=float32), 'eval/episode_y_position_std': Array(184.45018, dtype=float32), 'eval/episode_y_velocity_std': Array(24.534452, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96079182624817, 'eval/sps': 1067.0152976765596, 'num_steps': 2129920}
{'eval/walltime': 6512.114785194397, 'training/sps': 584.9923129364681, 'training/walltime': 10969.393938064575, 'training/entropy_loss': Array(0.0007283, dtype=float32), 'training/policy_loss': Array(-0.00195704, dtype=float32), 'training/total_loss': Array(0.0125129, dtype=float32), 'training/v_loss': Array(0.01374164, dtype=float32), 'eval/episode_distance_from_origin': Array(4782.6084, dtype=float32), 'eval/episode_distance_reward': Array(8.142231, dtype=float32), 'eval/episode_forward_reward': Array(814.22406, dtype=float32), 'eval/episode_reward': Array(591.72327, dtype=float32), 'eval/episode_reward_alive': Array(24.390625, dtype=float32), 'eval/episode_reward_linvel': Array(814.22406, dtype=float32), 'eval/episode_reward_quadctrl': Array(-255.0339, dtype=float32), 'eval/episode_x_position': Array(4712.868, dtype=float32), 'eval/episode_x_velocity': Array(162.8446, dtype=float32), 'eval/episode_y_position': Array(-614.4127, dtype=float32), 'eval/episode_y_velocity': Array(-123.57723, dtype=float32), 'eval/episode_distance_from_origin_std': Array(288.86102, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9722648, dtype=float32), 'eval/episode_forward_reward_std': Array(197.22823, dtype=float32), 'eval/episode_reward_std': Array(199.96483, dtype=float32), 'eval/episode_reward_alive_std': Array(6.495773, dtype=float32), 'eval/episode_reward_linvel_std': Array(197.22823, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.5142565, dtype=float32), 'eval/episode_x_position_std': Array(268.8648, dtype=float32), 'eval/episode_x_velocity_std': Array(39.445576, dtype=float32), 'eval/episode_y_position_std': Array(212.1267, dtype=float32), 'eval/episode_y_velocity_std': Array(31.094955, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01340579986572, 'eval/sps': 1066.5475173119637, 'num_steps': 2211840}
{'eval/walltime': 6631.895414113998, 'training/sps': 584.5342284627952, 'training/walltime': 11109.539708852768, 'training/entropy_loss': Array(0.00116542, dtype=float32), 'training/policy_loss': Array(-0.00391459, dtype=float32), 'training/total_loss': Array(0.011161, dtype=float32), 'training/v_loss': Array(0.01391017, dtype=float32), 'eval/episode_distance_from_origin': Array(4828.432, dtype=float32), 'eval/episode_distance_reward': Array(8.347158, dtype=float32), 'eval/episode_forward_reward': Array(834.71686, dtype=float32), 'eval/episode_reward': Array(612.0802, dtype=float32), 'eval/episode_reward_alive': Array(24.355469, dtype=float32), 'eval/episode_reward_linvel': Array(834.71686, dtype=float32), 'eval/episode_reward_quadctrl': Array(-255.33942, dtype=float32), 'eval/episode_x_position': Array(4750.629, dtype=float32), 'eval/episode_x_velocity': Array(166.94315, dtype=float32), 'eval/episode_y_position': Array(-675.7598, dtype=float32), 'eval/episode_y_velocity': Array(-130.74533, dtype=float32), 'eval/episode_distance_from_origin_std': Array(262.29883, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7549694, dtype=float32), 'eval/episode_forward_reward_std': Array(175.4984, dtype=float32), 'eval/episode_reward_std': Array(178.98357, dtype=float32), 'eval/episode_reward_alive_std': Array(6.531819, dtype=float32), 'eval/episode_reward_linvel_std': Array(175.4984, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(13.018911, dtype=float32), 'eval/episode_x_position_std': Array(242.96407, dtype=float32), 'eval/episode_x_velocity_std': Array(35.09962, dtype=float32), 'eval/episode_y_position_std': Array(193.74219, dtype=float32), 'eval/episode_y_velocity_std': Array(26.967924, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78062891960144, 'eval/sps': 1068.6202030706945, 'num_steps': 2293760}
{'eval/walltime': 6751.6488428115845, 'training/sps': 583.6773413747197, 'training/walltime': 11249.891225337982, 'training/entropy_loss': Array(0.00121088, dtype=float32), 'training/policy_loss': Array(-0.00250701, dtype=float32), 'training/total_loss': Array(0.0108499, dtype=float32), 'training/v_loss': Array(0.01214603, dtype=float32), 'eval/episode_distance_from_origin': Array(4801.851, dtype=float32), 'eval/episode_distance_reward': Array(8.197205, dtype=float32), 'eval/episode_forward_reward': Array(819.7214, dtype=float32), 'eval/episode_reward': Array(596.6332, dtype=float32), 'eval/episode_reward_alive': Array(22.558594, dtype=float32), 'eval/episode_reward_linvel': Array(819.7214, dtype=float32), 'eval/episode_reward_quadctrl': Array(-253.84415, dtype=float32), 'eval/episode_x_position': Array(4730.573, dtype=float32), 'eval/episode_x_velocity': Array(163.94408, dtype=float32), 'eval/episode_y_position': Array(-628.42773, dtype=float32), 'eval/episode_y_velocity': Array(-124.42067, dtype=float32), 'eval/episode_distance_from_origin_std': Array(280.01166, dtype=float32), 'eval/episode_distance_reward_std': Array(1.837321, dtype=float32), 'eval/episode_forward_reward_std': Array(183.73332, dtype=float32), 'eval/episode_reward_std': Array(183.55426, dtype=float32), 'eval/episode_reward_alive_std': Array(4.5832663, dtype=float32), 'eval/episode_reward_linvel_std': Array(183.73332, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(11.971238, dtype=float32), 'eval/episode_x_position_std': Array(254.85039, dtype=float32), 'eval/episode_x_velocity_std': Array(36.74664, dtype=float32), 'eval/episode_y_position_std': Array(224.2812, dtype=float32), 'eval/episode_y_velocity_std': Array(31.563143, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.75342869758606, 'eval/sps': 1068.862924361348, 'num_steps': 2375680}
{'eval/walltime': 6871.337050437927, 'training/sps': 582.96149562089, 'training/walltime': 11390.41508603096, 'training/entropy_loss': Array(0.00137311, dtype=float32), 'training/policy_loss': Array(-0.00411236, dtype=float32), 'training/total_loss': Array(0.00712911, dtype=float32), 'training/v_loss': Array(0.00986836, dtype=float32), 'eval/episode_distance_from_origin': Array(4857.195, dtype=float32), 'eval/episode_distance_reward': Array(8.504972, dtype=float32), 'eval/episode_forward_reward': Array(850.4984, dtype=float32), 'eval/episode_reward': Array(632.5142, dtype=float32), 'eval/episode_reward_alive': Array(23.5625, dtype=float32), 'eval/episode_reward_linvel': Array(850.4984, dtype=float32), 'eval/episode_reward_quadctrl': Array(-250.05186, dtype=float32), 'eval/episode_x_position': Array(4779.7246, dtype=float32), 'eval/episode_x_velocity': Array(170.09947, dtype=float32), 'eval/episode_y_position': Array(-669.6883, dtype=float32), 'eval/episode_y_velocity': Array(-129.87007, dtype=float32), 'eval/episode_distance_from_origin_std': Array(299.05225, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9467275, dtype=float32), 'eval/episode_forward_reward_std': Array(194.67459, dtype=float32), 'eval/episode_reward_std': Array(193.34294, dtype=float32), 'eval/episode_reward_alive_std': Array(4.8287063, dtype=float32), 'eval/episode_reward_linvel_std': Array(194.67459, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.599832, dtype=float32), 'eval/episode_x_position_std': Array(277.51776, dtype=float32), 'eval/episode_x_velocity_std': Array(38.934853, dtype=float32), 'eval/episode_y_position_std': Array(222.10536, dtype=float32), 'eval/episode_y_velocity_std': Array(31.271345, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.68820762634277, 'eval/sps': 1069.445374264489, 'num_steps': 2457600}
{'eval/walltime': 6991.1083726882935, 'training/sps': 585.553597467518, 'training/walltime': 11530.316882133484, 'training/entropy_loss': Array(0.00137428, dtype=float32), 'training/policy_loss': Array(-0.00271763, dtype=float32), 'training/total_loss': Array(0.01071834, dtype=float32), 'training/v_loss': Array(0.01206169, dtype=float32), 'eval/episode_distance_from_origin': Array(4940.0596, dtype=float32), 'eval/episode_distance_reward': Array(8.984255, dtype=float32), 'eval/episode_forward_reward': Array(898.42694, dtype=float32), 'eval/episode_reward': Array(681.0797, dtype=float32), 'eval/episode_reward_alive': Array(25.492188, dtype=float32), 'eval/episode_reward_linvel': Array(898.42694, dtype=float32), 'eval/episode_reward_quadctrl': Array(-251.82382, dtype=float32), 'eval/episode_x_position': Array(4850.4834, dtype=float32), 'eval/episode_x_velocity': Array(179.68517, dtype=float32), 'eval/episode_y_position': Array(-748.81885, dtype=float32), 'eval/episode_y_velocity': Array(-139.85349, dtype=float32), 'eval/episode_distance_from_origin_std': Array(305.40695, dtype=float32), 'eval/episode_distance_reward_std': Array(2.025624, dtype=float32), 'eval/episode_forward_reward_std': Array(202.56418, dtype=float32), 'eval/episode_reward_std': Array(201.0758, dtype=float32), 'eval/episode_reward_alive_std': Array(5.4104877, dtype=float32), 'eval/episode_reward_linvel_std': Array(202.56418, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(11.739842, dtype=float32), 'eval/episode_x_position_std': Array(281.5691, dtype=float32), 'eval/episode_x_velocity_std': Array(40.51277, dtype=float32), 'eval/episode_y_position_std': Array(225.59369, dtype=float32), 'eval/episode_y_velocity_std': Array(32.150276, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77132225036621, 'eval/sps': 1068.7032387638906, 'num_steps': 2539520}
{'eval/walltime': 7110.79536652565, 'training/sps': 584.076783400202, 'training/walltime': 11670.572414159775, 'training/entropy_loss': Array(0.00142942, dtype=float32), 'training/policy_loss': Array(-0.00356856, dtype=float32), 'training/total_loss': Array(0.00730071, dtype=float32), 'training/v_loss': Array(0.00943985, dtype=float32), 'eval/episode_distance_from_origin': Array(4837.182, dtype=float32), 'eval/episode_distance_reward': Array(8.430645, dtype=float32), 'eval/episode_forward_reward': Array(843.0656, dtype=float32), 'eval/episode_reward': Array(624.8195, dtype=float32), 'eval/episode_reward_alive': Array(24.589844, dtype=float32), 'eval/episode_reward_linvel': Array(843.0656, dtype=float32), 'eval/episode_reward_quadctrl': Array(-251.2667, dtype=float32), 'eval/episode_x_position': Array(4763.967, dtype=float32), 'eval/episode_x_velocity': Array(168.61288, dtype=float32), 'eval/episode_y_position': Array(-645.2336, dtype=float32), 'eval/episode_y_velocity': Array(-126.032585, dtype=float32), 'eval/episode_distance_from_origin_std': Array(306.4573, dtype=float32), 'eval/episode_distance_reward_std': Array(2.0194745, dtype=float32), 'eval/episode_forward_reward_std': Array(201.94888, dtype=float32), 'eval/episode_reward_std': Array(203.43813, dtype=float32), 'eval/episode_reward_alive_std': Array(5.0584216, dtype=float32), 'eval/episode_reward_linvel_std': Array(201.94888, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.249373, dtype=float32), 'eval/episode_x_position_std': Array(282.46695, dtype=float32), 'eval/episode_x_velocity_std': Array(40.389767, dtype=float32), 'eval/episode_y_position_std': Array(221.64441, dtype=float32), 'eval/episode_y_velocity_std': Array(31.284254, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.68699383735657, 'eval/sps': 1069.456219895873, 'num_steps': 2621440}
{'eval/walltime': 7230.715141534805, 'training/sps': 584.9923099485292, 'training/walltime': 11810.608443021774, 'training/entropy_loss': Array(0.00171256, dtype=float32), 'training/policy_loss': Array(-0.00160797, dtype=float32), 'training/total_loss': Array(0.01179651, dtype=float32), 'training/v_loss': Array(0.01169192, dtype=float32), 'eval/episode_distance_from_origin': Array(4950.2427, dtype=float32), 'eval/episode_distance_reward': Array(9.195974, dtype=float32), 'eval/episode_forward_reward': Array(919.59894, dtype=float32), 'eval/episode_reward': Array(694.14685, dtype=float32), 'eval/episode_reward_alive': Array(25.398438, dtype=float32), 'eval/episode_reward_linvel': Array(919.59894, dtype=float32), 'eval/episode_reward_quadctrl': Array(-260.04654, dtype=float32), 'eval/episode_x_position': Array(4863.3945, dtype=float32), 'eval/episode_x_velocity': Array(183.91956, dtype=float32), 'eval/episode_y_position': Array(-736.298, dtype=float32), 'eval/episode_y_velocity': Array(-140.59903, dtype=float32), 'eval/episode_distance_from_origin_std': Array(313.23914, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2057912, dtype=float32), 'eval/episode_forward_reward_std': Array(220.58072, dtype=float32), 'eval/episode_reward_std': Array(225.17569, dtype=float32), 'eval/episode_reward_alive_std': Array(5.7477436, dtype=float32), 'eval/episode_reward_linvel_std': Array(220.58072, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(15.23876, dtype=float32), 'eval/episode_x_position_std': Array(291.471, dtype=float32), 'eval/episode_x_velocity_std': Array(44.116096, dtype=float32), 'eval/episode_y_position_std': Array(195.22621, dtype=float32), 'eval/episode_y_velocity_std': Array(30.469788, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.91977500915527, 'eval/sps': 1067.380254759716, 'num_steps': 2703360}
{'eval/walltime': 7350.6753969192505, 'training/sps': 583.879373341423, 'training/walltime': 11950.911395549774, 'training/entropy_loss': Array(0.00193753, dtype=float32), 'training/policy_loss': Array(-0.00238654, dtype=float32), 'training/total_loss': Array(0.01057981, dtype=float32), 'training/v_loss': Array(0.01102882, dtype=float32), 'eval/episode_distance_from_origin': Array(4986.504, dtype=float32), 'eval/episode_distance_reward': Array(9.776384, dtype=float32), 'eval/episode_forward_reward': Array(977.6407, dtype=float32), 'eval/episode_reward': Array(738.9667, dtype=float32), 'eval/episode_reward_alive': Array(25.855469, dtype=float32), 'eval/episode_reward_linvel': Array(977.6407, dtype=float32), 'eval/episode_reward_quadctrl': Array(-274.30612, dtype=float32), 'eval/episode_x_position': Array(4881.6157, dtype=float32), 'eval/episode_x_velocity': Array(195.52792, dtype=float32), 'eval/episode_y_position': Array(-818.9197, dtype=float32), 'eval/episode_y_velocity': Array(-158.72656, dtype=float32), 'eval/episode_distance_from_origin_std': Array(317.64325, dtype=float32), 'eval/episode_distance_reward_std': Array(2.6110237, dtype=float32), 'eval/episode_forward_reward_std': Array(261.1048, dtype=float32), 'eval/episode_reward_std': Array(261.8856, dtype=float32), 'eval/episode_reward_alive_std': Array(6.5765185, dtype=float32), 'eval/episode_reward_linvel_std': Array(261.1048, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.75987, dtype=float32), 'eval/episode_x_position_std': Array(290.0431, dtype=float32), 'eval/episode_x_velocity_std': Array(52.220856, dtype=float32), 'eval/episode_y_position_std': Array(238.94907, dtype=float32), 'eval/episode_y_velocity_std': Array(40.66296, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96025538444519, 'eval/sps': 1067.0200691869925, 'num_steps': 2785280}
{'eval/walltime': 7470.609628915787, 'training/sps': 584.7099844472426, 'training/walltime': 12091.015040397644, 'training/entropy_loss': Array(0.00283297, dtype=float32), 'training/policy_loss': Array(0.00232485, dtype=float32), 'training/total_loss': Array(0.01974497, dtype=float32), 'training/v_loss': Array(0.01458715, dtype=float32), 'eval/episode_distance_from_origin': Array(5062.0713, dtype=float32), 'eval/episode_distance_reward': Array(10.679571, dtype=float32), 'eval/episode_forward_reward': Array(1067.96, dtype=float32), 'eval/episode_reward': Array(822.56793, dtype=float32), 'eval/episode_reward_alive': Array(27.042969, dtype=float32), 'eval/episode_reward_linvel': Array(1067.96, dtype=float32), 'eval/episode_reward_quadctrl': Array(-283.11502, dtype=float32), 'eval/episode_x_position': Array(4962.95, dtype=float32), 'eval/episode_x_velocity': Array(213.59174, dtype=float32), 'eval/episode_y_position': Array(-799.6044, dtype=float32), 'eval/episode_y_velocity': Array(-161.87494, dtype=float32), 'eval/episode_distance_from_origin_std': Array(359.49942, dtype=float32), 'eval/episode_distance_reward_std': Array(3.329101, dtype=float32), 'eval/episode_forward_reward_std': Array(332.9132, dtype=float32), 'eval/episode_reward_std': Array(338.41977, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6705475, dtype=float32), 'eval/episode_reward_linvel_std': Array(332.9132, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.495155, dtype=float32), 'eval/episode_x_position_std': Array(336.1015, dtype=float32), 'eval/episode_x_velocity_std': Array(66.58256, dtype=float32), 'eval/episode_y_position_std': Array(209.51923, dtype=float32), 'eval/episode_y_velocity_std': Array(42.817818, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.93423199653625, 'eval/sps': 1067.251591719841, 'num_steps': 2867200}
{'eval/walltime': 7590.4533150196075, 'training/sps': 583.0128628904959, 'training/walltime': 12231.52652001381, 'training/entropy_loss': Array(0.00290857, dtype=float32), 'training/policy_loss': Array(0.07904974, dtype=float32), 'training/total_loss': Array(0.0983411, dtype=float32), 'training/v_loss': Array(0.01638279, dtype=float32), 'eval/episode_distance_from_origin': Array(4870.4736, dtype=float32), 'eval/episode_distance_reward': Array(8.848025, dtype=float32), 'eval/episode_forward_reward': Array(884.8038, dtype=float32), 'eval/episode_reward': Array(612.43964, dtype=float32), 'eval/episode_reward_alive': Array(25.847656, dtype=float32), 'eval/episode_reward_linvel': Array(884.8038, dtype=float32), 'eval/episode_reward_quadctrl': Array(-307.05994, dtype=float32), 'eval/episode_x_position': Array(4790.0083, dtype=float32), 'eval/episode_x_velocity': Array(176.96051, dtype=float32), 'eval/episode_y_position': Array(-694.2011, dtype=float32), 'eval/episode_y_velocity': Array(-137.00333, dtype=float32), 'eval/episode_distance_from_origin_std': Array(300.8644, dtype=float32), 'eval/episode_distance_reward_std': Array(2.3966768, dtype=float32), 'eval/episode_forward_reward_std': Array(239.66963, dtype=float32), 'eval/episode_reward_std': Array(246.74707, dtype=float32), 'eval/episode_reward_alive_std': Array(6.440399, dtype=float32), 'eval/episode_reward_linvel_std': Array(239.66963, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.347075, dtype=float32), 'eval/episode_x_position_std': Array(283.07437, dtype=float32), 'eval/episode_x_velocity_std': Array(47.93386, dtype=float32), 'eval/episode_y_position_std': Array(203.81085, dtype=float32), 'eval/episode_y_velocity_std': Array(36.7864, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8436861038208, 'eval/sps': 1068.057935810764, 'num_steps': 2949120}
{'eval/walltime': 7710.459333181381, 'training/sps': 584.4280506100856, 'training/walltime': 12371.69775223732, 'training/entropy_loss': Array(0.00463677, dtype=float32), 'training/policy_loss': Array(0.01599882, dtype=float32), 'training/total_loss': Array(0.03673293, dtype=float32), 'training/v_loss': Array(0.01609734, dtype=float32), 'eval/episode_distance_from_origin': Array(4854.859, dtype=float32), 'eval/episode_distance_reward': Array(8.686037, dtype=float32), 'eval/episode_forward_reward': Array(868.60486, dtype=float32), 'eval/episode_reward': Array(595.64716, dtype=float32), 'eval/episode_reward_alive': Array(25.015625, dtype=float32), 'eval/episode_reward_linvel': Array(868.60486, dtype=float32), 'eval/episode_reward_quadctrl': Array(-306.6596, dtype=float32), 'eval/episode_x_position': Array(4780.8906, dtype=float32), 'eval/episode_x_velocity': Array(173.72075, dtype=float32), 'eval/episode_y_position': Array(-654.6887, dtype=float32), 'eval/episode_y_velocity': Array(-131.17804, dtype=float32), 'eval/episode_distance_from_origin_std': Array(261.15796, dtype=float32), 'eval/episode_distance_reward_std': Array(2.0651276, dtype=float32), 'eval/episode_forward_reward_std': Array(206.5143, dtype=float32), 'eval/episode_reward_std': Array(216.14093, dtype=float32), 'eval/episode_reward_alive_std': Array(5.74828, dtype=float32), 'eval/episode_reward_linvel_std': Array(206.5143, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.043554, dtype=float32), 'eval/episode_x_position_std': Array(247.58107, dtype=float32), 'eval/episode_x_velocity_std': Array(41.3028, dtype=float32), 'eval/episode_y_position_std': Array(187.10512, dtype=float32), 'eval/episode_y_velocity_std': Array(36.014435, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.00601816177368, 'eval/sps': 1066.6131745780453, 'num_steps': 3031040}
{'eval/walltime': 7830.366899967194, 'training/sps': 583.8144008216037, 'training/walltime': 12512.016319036484, 'training/entropy_loss': Array(0.00453473, dtype=float32), 'training/policy_loss': Array(0.00624655, dtype=float32), 'training/total_loss': Array(0.02785616, dtype=float32), 'training/v_loss': Array(0.01707487, dtype=float32), 'eval/episode_distance_from_origin': Array(4955.7705, dtype=float32), 'eval/episode_distance_reward': Array(9.279414, dtype=float32), 'eval/episode_forward_reward': Array(927.94293, dtype=float32), 'eval/episode_reward': Array(658.6295, dtype=float32), 'eval/episode_reward_alive': Array(25.5625, dtype=float32), 'eval/episode_reward_linvel': Array(927.94293, dtype=float32), 'eval/episode_reward_quadctrl': Array(-304.1557, dtype=float32), 'eval/episode_x_position': Array(4889.4365, dtype=float32), 'eval/episode_x_velocity': Array(185.5884, dtype=float32), 'eval/episode_y_position': Array(-607.76514, dtype=float32), 'eval/episode_y_velocity': Array(-124.207214, dtype=float32), 'eval/episode_distance_from_origin_std': Array(248.7175, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8704087, dtype=float32), 'eval/episode_forward_reward_std': Array(187.04225, dtype=float32), 'eval/episode_reward_std': Array(194.17586, dtype=float32), 'eval/episode_reward_alive_std': Array(5.124619, dtype=float32), 'eval/episode_reward_linvel_std': Array(187.04225, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.410349, dtype=float32), 'eval/episode_x_position_std': Array(234.55165, dtype=float32), 'eval/episode_x_velocity_std': Array(37.408398, dtype=float32), 'eval/episode_y_position_std': Array(191.94992, dtype=float32), 'eval/episode_y_velocity_std': Array(33.124294, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90756678581238, 'eval/sps': 1067.4889286065068, 'num_steps': 3112960}
{'eval/walltime': 7950.226576089859, 'training/sps': 584.300289251422, 'training/walltime': 12652.218200683594, 'training/entropy_loss': Array(0.00470677, dtype=float32), 'training/policy_loss': Array(0.00794596, dtype=float32), 'training/total_loss': Array(0.02479447, dtype=float32), 'training/v_loss': Array(0.01214174, dtype=float32), 'eval/episode_distance_from_origin': Array(4924.882, dtype=float32), 'eval/episode_distance_reward': Array(9.002888, dtype=float32), 'eval/episode_forward_reward': Array(900.2903, dtype=float32), 'eval/episode_reward': Array(635.6592, dtype=float32), 'eval/episode_reward_alive': Array(23.046875, dtype=float32), 'eval/episode_reward_linvel': Array(900.2903, dtype=float32), 'eval/episode_reward_quadctrl': Array(-296.68115, dtype=float32), 'eval/episode_x_position': Array(4862.0254, dtype=float32), 'eval/episode_x_velocity': Array(180.05783, dtype=float32), 'eval/episode_y_position': Array(-590.03296, dtype=float32), 'eval/episode_y_velocity': Array(-118.571884, dtype=float32), 'eval/episode_distance_from_origin_std': Array(290.17825, dtype=float32), 'eval/episode_distance_reward_std': Array(2.0388176, dtype=float32), 'eval/episode_forward_reward_std': Array(203.88318, dtype=float32), 'eval/episode_reward_std': Array(208.60315, dtype=float32), 'eval/episode_reward_alive_std': Array(3.8382518, dtype=float32), 'eval/episode_reward_linvel_std': Array(203.88318, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.0515, dtype=float32), 'eval/episode_x_position_std': Array(272.3591, dtype=float32), 'eval/episode_x_velocity_std': Array(40.776596, dtype=float32), 'eval/episode_y_position_std': Array(206.01613, dtype=float32), 'eval/episode_y_velocity_std': Array(32.242107, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8596761226654, 'eval/sps': 1067.9154503054365, 'num_steps': 3194880}
{'eval/walltime': 8070.060507059097, 'training/sps': 583.8617624363438, 'training/walltime': 12792.525385141373, 'training/entropy_loss': Array(0.00432298, dtype=float32), 'training/policy_loss': Array(0.00252713, dtype=float32), 'training/total_loss': Array(0.01813013, dtype=float32), 'training/v_loss': Array(0.01128003, dtype=float32), 'eval/episode_distance_from_origin': Array(4914.4395, dtype=float32), 'eval/episode_distance_reward': Array(8.916308, dtype=float32), 'eval/episode_forward_reward': Array(891.6323, dtype=float32), 'eval/episode_reward': Array(631.0928, dtype=float32), 'eval/episode_reward_alive': Array(23.199219, dtype=float32), 'eval/episode_reward_linvel': Array(891.6323, dtype=float32), 'eval/episode_reward_quadctrl': Array(-292.6553, dtype=float32), 'eval/episode_x_position': Array(4862.613, dtype=float32), 'eval/episode_x_velocity': Array(178.32626, dtype=float32), 'eval/episode_y_position': Array(-513.01843, dtype=float32), 'eval/episode_y_velocity': Array(-107.3161, dtype=float32), 'eval/episode_distance_from_origin_std': Array(275.51544, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9266177, dtype=float32), 'eval/episode_forward_reward_std': Array(192.66356, dtype=float32), 'eval/episode_reward_std': Array(201.30229, dtype=float32), 'eval/episode_reward_alive_std': Array(4.5754695, dtype=float32), 'eval/episode_reward_linvel_std': Array(192.66356, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.806149, dtype=float32), 'eval/episode_x_position_std': Array(261.823, dtype=float32), 'eval/episode_x_velocity_std': Array(38.532677, dtype=float32), 'eval/episode_y_position_std': Array(185.65222, dtype=float32), 'eval/episode_y_velocity_std': Array(26.829535, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83393096923828, 'eval/sps': 1068.1448815432582, 'num_steps': 3276800}
{'eval/walltime': 8190.120605945587, 'training/sps': 585.0767593008135, 'training/walltime': 12932.541201353073, 'training/entropy_loss': Array(0.0044686, dtype=float32), 'training/policy_loss': Array(0.00221767, dtype=float32), 'training/total_loss': Array(0.01767546, dtype=float32), 'training/v_loss': Array(0.01098919, dtype=float32), 'eval/episode_distance_from_origin': Array(4964.4717, dtype=float32), 'eval/episode_distance_reward': Array(9.190597, dtype=float32), 'eval/episode_forward_reward': Array(919.06165, dtype=float32), 'eval/episode_reward': Array(658.75745, dtype=float32), 'eval/episode_reward_alive': Array(22.933594, dtype=float32), 'eval/episode_reward_linvel': Array(919.06165, dtype=float32), 'eval/episode_reward_quadctrl': Array(-292.42868, dtype=float32), 'eval/episode_x_position': Array(4909.673, dtype=float32), 'eval/episode_x_velocity': Array(183.8121, dtype=float32), 'eval/episode_y_position': Array(-535.48206, dtype=float32), 'eval/episode_y_velocity': Array(-110.585304, dtype=float32), 'eval/episode_distance_from_origin_std': Array(236.18336, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6216674, dtype=float32), 'eval/episode_forward_reward_std': Array(162.16847, dtype=float32), 'eval/episode_reward_std': Array(169.29878, dtype=float32), 'eval/episode_reward_alive_std': Array(5.352194, dtype=float32), 'eval/episode_reward_linvel_std': Array(162.16847, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.90617, dtype=float32), 'eval/episode_x_position_std': Array(228.70003, dtype=float32), 'eval/episode_x_velocity_std': Array(32.433647, dtype=float32), 'eval/episode_y_position_std': Array(176.62302, dtype=float32), 'eval/episode_y_velocity_std': Array(23.884466, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.06009888648987, 'eval/sps': 1066.1327217547678, 'num_steps': 3358720}
{'eval/walltime': 8309.611476421356, 'training/sps': 583.3333722621345, 'training/walltime': 13072.975477695465, 'training/entropy_loss': Array(0.0040425, dtype=float32), 'training/policy_loss': Array(8.705935e-05, dtype=float32), 'training/total_loss': Array(0.01751277, dtype=float32), 'training/v_loss': Array(0.01338321, dtype=float32), 'eval/episode_distance_from_origin': Array(4923.09, dtype=float32), 'eval/episode_distance_reward': Array(8.983818, dtype=float32), 'eval/episode_forward_reward': Array(898.38354, dtype=float32), 'eval/episode_reward': Array(641.6812, dtype=float32), 'eval/episode_reward_alive': Array(22.628906, dtype=float32), 'eval/episode_reward_linvel': Array(898.38354, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.31528, dtype=float32), 'eval/episode_x_position': Array(4873.2607, dtype=float32), 'eval/episode_x_velocity': Array(179.67645, dtype=float32), 'eval/episode_y_position': Array(-498.31888, dtype=float32), 'eval/episode_y_velocity': Array(-105.63, dtype=float32), 'eval/episode_distance_from_origin_std': Array(261.43936, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8871897, dtype=float32), 'eval/episode_forward_reward_std': Array(188.72075, dtype=float32), 'eval/episode_reward_std': Array(195.1623, dtype=float32), 'eval/episode_reward_alive_std': Array(4.406248, dtype=float32), 'eval/episode_reward_linvel_std': Array(188.72075, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.272816, dtype=float32), 'eval/episode_x_position_std': Array(252.43297, dtype=float32), 'eval/episode_x_velocity_std': Array(37.74408, dtype=float32), 'eval/episode_y_position_std': Array(173.71948, dtype=float32), 'eval/episode_y_velocity_std': Array(24.805876, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.49087047576904, 'eval/sps': 1071.2115452029993, 'num_steps': 3440640}
{'eval/walltime': 8429.652671337128, 'training/sps': 584.5469374324349, 'training/walltime': 13213.118201494217, 'training/entropy_loss': Array(0.00406398, dtype=float32), 'training/policy_loss': Array(0.00032468, dtype=float32), 'training/total_loss': Array(0.01426706, dtype=float32), 'training/v_loss': Array(0.0098784, dtype=float32), 'eval/episode_distance_from_origin': Array(4919.3145, dtype=float32), 'eval/episode_distance_reward': Array(8.907383, dtype=float32), 'eval/episode_forward_reward': Array(890.74023, dtype=float32), 'eval/episode_reward': Array(629.28906, dtype=float32), 'eval/episode_reward_alive': Array(22.144531, dtype=float32), 'eval/episode_reward_linvel': Array(890.74023, dtype=float32), 'eval/episode_reward_quadctrl': Array(-292.50317, dtype=float32), 'eval/episode_x_position': Array(4869.7266, dtype=float32), 'eval/episode_x_velocity': Array(178.1478, dtype=float32), 'eval/episode_y_position': Array(-498.62952, dtype=float32), 'eval/episode_y_velocity': Array(-104.886665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(217.9661, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4866114, dtype=float32), 'eval/episode_forward_reward_std': Array(148.66264, dtype=float32), 'eval/episode_reward_std': Array(151.43297, dtype=float32), 'eval/episode_reward_alive_std': Array(4.3959994, dtype=float32), 'eval/episode_reward_linvel_std': Array(148.66264, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.04794, dtype=float32), 'eval/episode_x_position_std': Array(208.01685, dtype=float32), 'eval/episode_x_velocity_std': Array(29.732508, dtype=float32), 'eval/episode_y_position_std': Array(174.12451, dtype=float32), 'eval/episode_y_velocity_std': Array(23.376932, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04119491577148, 'eval/sps': 1066.3006152997136, 'num_steps': 3522560}
{'eval/walltime': 8549.272439956665, 'training/sps': 582.7200295635998, 'training/walltime': 13353.700292110443, 'training/entropy_loss': Array(0.00405085, dtype=float32), 'training/policy_loss': Array(-0.00072092, dtype=float32), 'training/total_loss': Array(0.01389681, dtype=float32), 'training/v_loss': Array(0.01056688, dtype=float32), 'eval/episode_distance_from_origin': Array(4873.5293, dtype=float32), 'eval/episode_distance_reward': Array(8.66494, dtype=float32), 'eval/episode_forward_reward': Array(866.49524, dtype=float32), 'eval/episode_reward': Array(619.7578, dtype=float32), 'eval/episode_reward_alive': Array(22.121094, dtype=float32), 'eval/episode_reward_linvel': Array(866.49524, dtype=float32), 'eval/episode_reward_quadctrl': Array(-277.5238, dtype=float32), 'eval/episode_x_position': Array(4834.0234, dtype=float32), 'eval/episode_x_velocity': Array(173.29886, dtype=float32), 'eval/episode_y_position': Array(-412.45862, dtype=float32), 'eval/episode_y_velocity': Array(-93.54209, dtype=float32), 'eval/episode_distance_from_origin_std': Array(214.95529, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5182023, dtype=float32), 'eval/episode_forward_reward_std': Array(151.82167, dtype=float32), 'eval/episode_reward_std': Array(157.4843, dtype=float32), 'eval/episode_reward_alive_std': Array(4.155073, dtype=float32), 'eval/episode_reward_linvel_std': Array(151.82167, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.365757, dtype=float32), 'eval/episode_x_position_std': Array(208.091, dtype=float32), 'eval/episode_x_velocity_std': Array(30.364307, dtype=float32), 'eval/episode_y_position_std': Array(156.09222, dtype=float32), 'eval/episode_y_velocity_std': Array(21.493332, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.61976861953735, 'eval/sps': 1070.0572445271719, 'num_steps': 3604480}
{'eval/walltime': 8669.354151010513, 'training/sps': 584.6575815177972, 'training/walltime': 13493.816494464874, 'training/entropy_loss': Array(0.00411203, dtype=float32), 'training/policy_loss': Array(-0.0005277, dtype=float32), 'training/total_loss': Array(0.01365703, dtype=float32), 'training/v_loss': Array(0.0100727, dtype=float32), 'eval/episode_distance_from_origin': Array(4957.964, dtype=float32), 'eval/episode_distance_reward': Array(9.264193, dtype=float32), 'eval/episode_forward_reward': Array(926.4212, dtype=float32), 'eval/episode_reward': Array(683.60095, dtype=float32), 'eval/episode_reward_alive': Array(22.769531, dtype=float32), 'eval/episode_reward_linvel': Array(926.4212, dtype=float32), 'eval/episode_reward_quadctrl': Array(-274.85443, dtype=float32), 'eval/episode_x_position': Array(4913.539, dtype=float32), 'eval/episode_x_velocity': Array(185.28403, dtype=float32), 'eval/episode_y_position': Array(-453.8725, dtype=float32), 'eval/episode_y_velocity': Array(-100.4359, dtype=float32), 'eval/episode_distance_from_origin_std': Array(249.28247, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7903248, dtype=float32), 'eval/episode_forward_reward_std': Array(179.03398, dtype=float32), 'eval/episode_reward_std': Array(183.46411, dtype=float32), 'eval/episode_reward_alive_std': Array(4.6409783, dtype=float32), 'eval/episode_reward_linvel_std': Array(179.03398, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.357222, dtype=float32), 'eval/episode_x_position_std': Array(242.61134, dtype=float32), 'eval/episode_x_velocity_std': Array(35.80678, dtype=float32), 'eval/episode_y_position_std': Array(171.29857, dtype=float32), 'eval/episode_y_velocity_std': Array(24.348484, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.08171105384827, 'eval/sps': 1065.9408404215771, 'num_steps': 3686400}
{'eval/walltime': 8788.96650314331, 'training/sps': 582.2420175019827, 'training/walltime': 13634.51400089264, 'training/entropy_loss': Array(0.00399764, dtype=float32), 'training/policy_loss': Array(-0.00094858, dtype=float32), 'training/total_loss': Array(0.01366352, dtype=float32), 'training/v_loss': Array(0.01061446, dtype=float32), 'eval/episode_distance_from_origin': Array(5024.4297, dtype=float32), 'eval/episode_distance_reward': Array(9.738813, dtype=float32), 'eval/episode_forward_reward': Array(973.88416, dtype=float32), 'eval/episode_reward': Array(738.8974, dtype=float32), 'eval/episode_reward_alive': Array(23.292969, dtype=float32), 'eval/episode_reward_linvel': Array(973.88416, dtype=float32), 'eval/episode_reward_quadctrl': Array(-268.01898, dtype=float32), 'eval/episode_x_position': Array(4982.8975, dtype=float32), 'eval/episode_x_velocity': Array(194.77661, dtype=float32), 'eval/episode_y_position': Array(-428.22705, dtype=float32), 'eval/episode_y_velocity': Array(-97.89834, dtype=float32), 'eval/episode_distance_from_origin_std': Array(252.66833, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8230169, dtype=float32), 'eval/episode_forward_reward_std': Array(182.30376, dtype=float32), 'eval/episode_reward_std': Array(188.79726, dtype=float32), 'eval/episode_reward_alive_std': Array(4.6760387, dtype=float32), 'eval/episode_reward_linvel_std': Array(182.30376, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.301546, dtype=float32), 'eval/episode_x_position_std': Array(245.29178, dtype=float32), 'eval/episode_x_velocity_std': Array(36.460697, dtype=float32), 'eval/episode_y_position_std': Array(172.08624, dtype=float32), 'eval/episode_y_velocity_std': Array(23.157381, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.61235213279724, 'eval/sps': 1070.1235927363969, 'num_steps': 3768320}
{'eval/walltime': 8908.9620616436, 'training/sps': 585.2457022646001, 'training/walltime': 13774.48939871788, 'training/entropy_loss': Array(0.00372177, dtype=float32), 'training/policy_loss': Array(-0.0010195, dtype=float32), 'training/total_loss': Array(0.01351758, dtype=float32), 'training/v_loss': Array(0.01081531, dtype=float32), 'eval/episode_distance_from_origin': Array(5043.0264, dtype=float32), 'eval/episode_distance_reward': Array(9.840239, dtype=float32), 'eval/episode_forward_reward': Array(984.0265, dtype=float32), 'eval/episode_reward': Array(743.7361, dtype=float32), 'eval/episode_reward_alive': Array(23.703125, dtype=float32), 'eval/episode_reward_linvel': Array(984.0265, dtype=float32), 'eval/episode_reward_quadctrl': Array(-273.83395, dtype=float32), 'eval/episode_x_position': Array(4996.7124, dtype=float32), 'eval/episode_x_velocity': Array(196.80504, dtype=float32), 'eval/episode_y_position': Array(-466.7629, dtype=float32), 'eval/episode_y_velocity': Array(-103.14052, dtype=float32), 'eval/episode_distance_from_origin_std': Array(222.00873, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6555977, dtype=float32), 'eval/episode_forward_reward_std': Array(165.56131, dtype=float32), 'eval/episode_reward_std': Array(170.85387, dtype=float32), 'eval/episode_reward_alive_std': Array(4.7792835, dtype=float32), 'eval/episode_reward_linvel_std': Array(165.56131, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.300282, dtype=float32), 'eval/episode_x_position_std': Array(213.65462, dtype=float32), 'eval/episode_x_velocity_std': Array(33.112236, dtype=float32), 'eval/episode_y_position_std': Array(183.3551, dtype=float32), 'eval/episode_y_velocity_std': Array(24.46914, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99555850028992, 'eval/sps': 1066.706148125397, 'num_steps': 3850240}
{'eval/walltime': 9028.48665857315, 'training/sps': 583.240871461857, 'training/walltime': 13914.945947647095, 'training/entropy_loss': Array(0.00412169, dtype=float32), 'training/policy_loss': Array(-0.00053423, dtype=float32), 'training/total_loss': Array(0.01284431, dtype=float32), 'training/v_loss': Array(0.00925685, dtype=float32), 'eval/episode_distance_from_origin': Array(5070.0576, dtype=float32), 'eval/episode_distance_reward': Array(10.052303, dtype=float32), 'eval/episode_forward_reward': Array(1005.23315, dtype=float32), 'eval/episode_reward': Array(773.3398, dtype=float32), 'eval/episode_reward_alive': Array(22.867188, dtype=float32), 'eval/episode_reward_linvel': Array(1005.23315, dtype=float32), 'eval/episode_reward_quadctrl': Array(-264.81317, dtype=float32), 'eval/episode_x_position': Array(5021.977, dtype=float32), 'eval/episode_x_velocity': Array(201.04636, dtype=float32), 'eval/episode_y_position': Array(-487.8993, dtype=float32), 'eval/episode_y_velocity': Array(-105.7672, dtype=float32), 'eval/episode_distance_from_origin_std': Array(258.55743, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9119434, dtype=float32), 'eval/episode_forward_reward_std': Array(191.19623, dtype=float32), 'eval/episode_reward_std': Array(196.15355, dtype=float32), 'eval/episode_reward_alive_std': Array(5.1993403, dtype=float32), 'eval/episode_reward_linvel_std': Array(191.19623, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.62133, dtype=float32), 'eval/episode_x_position_std': Array(249.68553, dtype=float32), 'eval/episode_x_velocity_std': Array(38.2392, dtype=float32), 'eval/episode_y_position_std': Array(186.44926, dtype=float32), 'eval/episode_y_velocity_std': Array(26.033691, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.52459692955017, 'eval/sps': 1070.9092796643806, 'num_steps': 3932160}
{'eval/walltime': 9148.75076842308, 'training/sps': 585.0642813198605, 'training/walltime': 14054.964750051498, 'training/entropy_loss': Array(0.00373622, dtype=float32), 'training/policy_loss': Array(-0.00013991, dtype=float32), 'training/total_loss': Array(0.01859983, dtype=float32), 'training/v_loss': Array(0.01500352, dtype=float32), 'eval/episode_distance_from_origin': Array(5107.5073, dtype=float32), 'eval/episode_distance_reward': Array(10.349451, dtype=float32), 'eval/episode_forward_reward': Array(1034.9486, dtype=float32), 'eval/episode_reward': Array(804.7687, dtype=float32), 'eval/episode_reward_alive': Array(22.863281, dtype=float32), 'eval/episode_reward_linvel': Array(1034.9486, dtype=float32), 'eval/episode_reward_quadctrl': Array(-263.3929, dtype=float32), 'eval/episode_x_position': Array(5052.815, dtype=float32), 'eval/episode_x_velocity': Array(206.98943, dtype=float32), 'eval/episode_y_position': Array(-548.6791, dtype=float32), 'eval/episode_y_velocity': Array(-113.888336, dtype=float32), 'eval/episode_distance_from_origin_std': Array(273.35855, dtype=float32), 'eval/episode_distance_reward_std': Array(2.1261494, dtype=float32), 'eval/episode_forward_reward_std': Array(212.61699, dtype=float32), 'eval/episode_reward_std': Array(220.47011, dtype=float32), 'eval/episode_reward_alive_std': Array(4.63121, dtype=float32), 'eval/episode_reward_linvel_std': Array(212.61699, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.992014, dtype=float32), 'eval/episode_x_position_std': Array(266.3541, dtype=float32), 'eval/episode_x_velocity_std': Array(42.52335, dtype=float32), 'eval/episode_y_position_std': Array(168.93654, dtype=float32), 'eval/episode_y_velocity_std': Array(23.561985, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.26410984992981, 'eval/sps': 1064.3241791730163, 'num_steps': 4014080}