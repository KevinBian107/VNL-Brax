
{'eval/walltime': 41.07788634300232, 'eval/episode_distance_from_origin': Array(14.105996, dtype=float32), 'eval/episode_forward_reward': Array(-0.27879423, dtype=float32), 'eval/episode_reward': Array(65.70462, dtype=float32), 'eval/episode_reward_alive': Array(85.390625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.27879423, dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.407211, dtype=float32), 'eval/episode_x_position': Array(0.23764455, dtype=float32), 'eval/episode_x_velocity': Array(-0.11151768, dtype=float32), 'eval/episode_y_position': Array(-0.14168827, dtype=float32), 'eval/episode_y_velocity': Array(-0.79583377, dtype=float32), 'eval/episode_distance_from_origin_std': Array(2.3385932, dtype=float32), 'eval/episode_forward_reward_std': Array(7.735317, dtype=float32), 'eval/episode_reward_std': Array(14.775618, dtype=float32), 'eval/episode_reward_alive_std': Array(13.296636, dtype=float32), 'eval/episode_reward_linvel_std': Array(7.735317, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.3400724, dtype=float32), 'eval/episode_x_position_std': Array(0.58294755, dtype=float32), 'eval/episode_x_velocity_std': Array(3.094127, dtype=float32), 'eval/episode_y_position_std': Array(0.46550792, dtype=float32), 'eval/episode_y_velocity_std': Array(3.0419056, dtype=float32), 'eval/avg_episode_length': Array(17.078125, dtype=float32), 'eval/epoch_eval_time': 41.07788634300232, 'eval/sps': 1558.015898520117, 'num_steps': 0}
{'eval/walltime': 46.936683654785156, 'training/sps': 44.78005072689408, 'training/walltime': 28.58415699005127, 'training/entropy_loss': Array(-0.0134311, dtype=float32), 'training/policy_loss': Array(0.24471268, dtype=float32), 'training/total_loss': Array(9.490858, dtype=float32), 'training/v_loss': Array(9.259577, dtype=float32), 'eval/episode_distance_from_origin': Array(13.032615, dtype=float32), 'eval/episode_forward_reward': Array(3.1157308, dtype=float32), 'eval/episode_reward': Array(75.41704, dtype=float32), 'eval/episode_reward_alive': Array(81.44531, dtype=float32), 'eval/episode_reward_linvel': Array(3.1157308, dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.144, dtype=float32), 'eval/episode_x_position': Array(0.455035, dtype=float32), 'eval/episode_x_velocity': Array(1.2462924, dtype=float32), 'eval/episode_y_position': Array(0.06883056, dtype=float32), 'eval/episode_y_velocity': Array(0.401454, dtype=float32), 'eval/episode_distance_from_origin_std': Array(3.3311887, dtype=float32), 'eval/episode_forward_reward_std': Array(3.9436693, dtype=float32), 'eval/episode_reward_std': Array(17.910076, dtype=float32), 'eval/episode_reward_alive_std': Array(20.166807, dtype=float32), 'eval/episode_reward_linvel_std': Array(3.9436693, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.347751, dtype=float32), 'eval/episode_x_position_std': Array(0.3045316, dtype=float32), 'eval/episode_x_velocity_std': Array(1.5774678, dtype=float32), 'eval/episode_y_position_std': Array(0.32571107, dtype=float32), 'eval/episode_y_velocity_std': Array(1.8479669, dtype=float32), 'eval/avg_episode_length': Array(16.289062, dtype=float32), 'eval/epoch_eval_time': 5.858797311782837, 'eval/sps': 10923.743661738785, 'num_steps': 1280}
{'eval/walltime': 52.77430820465088, 'training/sps': 699.504524875971, 'training/walltime': 30.414023637771606, 'training/entropy_loss': Array(-0.01336907, dtype=float32), 'training/policy_loss': Array(-0.08169228, dtype=float32), 'training/total_loss': Array(7.082858, dtype=float32), 'training/v_loss': Array(7.1779194, dtype=float32), 'eval/episode_distance_from_origin': Array(16.489231, dtype=float32), 'eval/episode_forward_reward': Array(3.6737702, dtype=float32), 'eval/episode_reward': Array(94.81482, dtype=float32), 'eval/episode_reward_alive': Array(102.96875, dtype=float32), 'eval/episode_reward_linvel': Array(3.6737702, dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.827701, dtype=float32), 'eval/episode_x_position': Array(0.60450685, dtype=float32), 'eval/episode_x_velocity': Array(1.4695082, dtype=float32), 'eval/episode_y_position': Array(0.14009772, dtype=float32), 'eval/episode_y_velocity': Array(0.75432205, dtype=float32), 'eval/episode_distance_from_origin_std': Array(5.002422, dtype=float32), 'eval/episode_forward_reward_std': Array(6.938098, dtype=float32), 'eval/episode_reward_std': Array(28.809286, dtype=float32), 'eval/episode_reward_alive_std': Array(30.506386, dtype=float32), 'eval/episode_reward_linvel_std': Array(6.938098, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.642161, dtype=float32), 'eval/episode_x_position_std': Array(0.57976854, dtype=float32), 'eval/episode_x_velocity_std': Array(2.775239, dtype=float32), 'eval/episode_y_position_std': Array(0.8750224, dtype=float32), 'eval/episode_y_velocity_std': Array(3.535505, dtype=float32), 'eval/avg_episode_length': Array(20.59375, dtype=float32), 'eval/epoch_eval_time': 5.837624549865723, 'eval/sps': 10963.363514269196, 'num_steps': 2560}
{'eval/walltime': 58.61065435409546, 'training/sps': 697.182526145112, 'training/walltime': 32.24998474121094, 'training/entropy_loss': Array(-0.0131658, dtype=float32), 'training/policy_loss': Array(-0.08221246, dtype=float32), 'training/total_loss': Array(7.786289, dtype=float32), 'training/v_loss': Array(7.881667, dtype=float32), 'eval/episode_distance_from_origin': Array(17.849113, dtype=float32), 'eval/episode_forward_reward': Array(4.855179, dtype=float32), 'eval/episode_reward': Array(103.4284, dtype=float32), 'eval/episode_reward_alive': Array(111.25, dtype=float32), 'eval/episode_reward_linvel': Array(4.855179, dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.67678, dtype=float32), 'eval/episode_x_position': Array(0.788482, dtype=float32), 'eval/episode_x_velocity': Array(1.9420717, dtype=float32), 'eval/episode_y_position': Array(0.3270655, dtype=float32), 'eval/episode_y_velocity': Array(1.2447934, dtype=float32), 'eval/episode_distance_from_origin_std': Array(5.6623282, dtype=float32), 'eval/episode_forward_reward_std': Array(8.091659, dtype=float32), 'eval/episode_reward_std': Array(32.473415, dtype=float32), 'eval/episode_reward_alive_std': Array(34.28397, dtype=float32), 'eval/episode_reward_linvel_std': Array(8.091659, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.937271, dtype=float32), 'eval/episode_x_position_std': Array(0.7417917, dtype=float32), 'eval/episode_x_velocity_std': Array(3.2366636, dtype=float32), 'eval/episode_y_position_std': Array(1.001418, dtype=float32), 'eval/episode_y_velocity_std': Array(3.6097362, dtype=float32), 'eval/avg_episode_length': Array(22.25, dtype=float32), 'eval/epoch_eval_time': 5.83634614944458, 'eval/sps': 10965.764942864227, 'num_steps': 3840}
{'eval/walltime': 64.43743538856506, 'training/sps': 706.2691419305595, 'training/walltime': 34.06232500076294, 'training/entropy_loss': Array(-0.01308924, dtype=float32), 'training/policy_loss': Array(-0.06990131, dtype=float32), 'training/total_loss': Array(9.59734, dtype=float32), 'training/v_loss': Array(9.68033, dtype=float32), 'eval/episode_distance_from_origin': Array(20.99272, dtype=float32), 'eval/episode_forward_reward': Array(5.770869, dtype=float32), 'eval/episode_reward': Array(121.11342, dtype=float32), 'eval/episode_reward_alive': Array(130.3125, dtype=float32), 'eval/episode_reward_linvel': Array(5.770869, dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.969955, dtype=float32), 'eval/episode_x_position': Array(0.97566843, dtype=float32), 'eval/episode_x_velocity': Array(2.3083475, dtype=float32), 'eval/episode_y_position': Array(0.3760453, dtype=float32), 'eval/episode_y_velocity': Array(1.9106302, dtype=float32), 'eval/episode_distance_from_origin_std': Array(6.5359726, dtype=float32), 'eval/episode_forward_reward_std': Array(13.57359, dtype=float32), 'eval/episode_reward_std': Array(37.896347, dtype=float32), 'eval/episode_reward_alive_std': Array(39.079994, dtype=float32), 'eval/episode_reward_linvel_std': Array(13.57359, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.6034584, dtype=float32), 'eval/episode_x_position_std': Array(1.6612151, dtype=float32), 'eval/episode_x_velocity_std': Array(5.429436, dtype=float32), 'eval/episode_y_position_std': Array(1.3136063, dtype=float32), 'eval/episode_y_velocity_std': Array(4.969959, dtype=float32), 'eval/avg_episode_length': Array(26.0625, dtype=float32), 'eval/epoch_eval_time': 5.8267810344696045, 'eval/sps': 10983.766100252253, 'num_steps': 5120}
{'eval/walltime': 70.25483512878418, 'training/sps': 701.3286148825841, 'training/walltime': 35.88743233680725, 'training/entropy_loss': Array(-0.01296557, dtype=float32), 'training/policy_loss': Array(-0.06836544, dtype=float32), 'training/total_loss': Array(11.335018, dtype=float32), 'training/v_loss': Array(11.41635, dtype=float32), 'eval/episode_distance_from_origin': Array(24.608706, dtype=float32), 'eval/episode_forward_reward': Array(8.281273, dtype=float32), 'eval/episode_reward': Array(142.98013, dtype=float32), 'eval/episode_reward_alive': Array(152.26562, dtype=float32), 'eval/episode_reward_linvel': Array(8.281273, dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.566776, dtype=float32), 'eval/episode_x_position': Array(1.3692762, dtype=float32), 'eval/episode_x_velocity': Array(3.312509, dtype=float32), 'eval/episode_y_position': Array(0.63534474, dtype=float32), 'eval/episode_y_velocity': Array(2.8984838, dtype=float32), 'eval/episode_distance_from_origin_std': Array(7.197591, dtype=float32), 'eval/episode_forward_reward_std': Array(11.924686, dtype=float32), 'eval/episode_reward_std': Array(41.819153, dtype=float32), 'eval/episode_reward_alive_std': Array(43.178673, dtype=float32), 'eval/episode_reward_linvel_std': Array(11.924686, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.0135875, dtype=float32), 'eval/episode_x_position_std': Array(1.281141, dtype=float32), 'eval/episode_x_velocity_std': Array(4.769875, dtype=float32), 'eval/episode_y_position_std': Array(1.8403472, dtype=float32), 'eval/episode_y_velocity_std': Array(6.293847, dtype=float32), 'eval/avg_episode_length': Array(30.453125, dtype=float32), 'eval/epoch_eval_time': 5.817399740219116, 'eval/sps': 11001.478814930018, 'num_steps': 6400}
{'eval/walltime': 76.11741375923157, 'training/sps': 696.1310856421181, 'training/walltime': 37.72616648674011, 'training/entropy_loss': Array(-0.01288779, dtype=float32), 'training/policy_loss': Array(-0.0675069, dtype=float32), 'training/total_loss': Array(10.082825, dtype=float32), 'training/v_loss': Array(10.163219, dtype=float32), 'eval/episode_distance_from_origin': Array(24.58144, dtype=float32), 'eval/episode_forward_reward': Array(10.484734, dtype=float32), 'eval/episode_reward': Array(145.56131, dtype=float32), 'eval/episode_reward_alive': Array(152.5, dtype=float32), 'eval/episode_reward_linvel': Array(10.484734, dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.423433, dtype=float32), 'eval/episode_x_position': Array(1.7612531, dtype=float32), 'eval/episode_x_velocity': Array(4.1938934, dtype=float32), 'eval/episode_y_position': Array(0.5969991, dtype=float32), 'eval/episode_y_velocity': Array(2.348631, dtype=float32), 'eval/episode_distance_from_origin_std': Array(7.1823716, dtype=float32), 'eval/episode_forward_reward_std': Array(12.39197, dtype=float32), 'eval/episode_reward_std': Array(41.02705, dtype=float32), 'eval/episode_reward_alive_std': Array(42.710873, dtype=float32), 'eval/episode_reward_linvel_std': Array(12.39197, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.072795, dtype=float32), 'eval/episode_x_position_std': Array(1.3561524, dtype=float32), 'eval/episode_x_velocity_std': Array(4.9567876, dtype=float32), 'eval/episode_y_position_std': Array(1.8468821, dtype=float32), 'eval/episode_y_velocity_std': Array(6.4018726, dtype=float32), 'eval/avg_episode_length': Array(30.5, dtype=float32), 'eval/epoch_eval_time': 5.862578630447388, 'eval/sps': 10916.697930090875, 'num_steps': 7680}
{'eval/walltime': 81.9615364074707, 'training/sps': 700.2980726085005, 'training/walltime': 39.553959608078, 'training/entropy_loss': Array(-0.01284719, dtype=float32), 'training/policy_loss': Array(-0.07379389, dtype=float32), 'training/total_loss': Array(7.306679, dtype=float32), 'training/v_loss': Array(7.39332, dtype=float32), 'eval/episode_distance_from_origin': Array(25.563663, dtype=float32), 'eval/episode_forward_reward': Array(13.511851, dtype=float32), 'eval/episode_reward': Array(153.4324, dtype=float32), 'eval/episode_reward_alive': Array(158.08594, dtype=float32), 'eval/episode_reward_linvel': Array(13.511851, dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.165388, dtype=float32), 'eval/episode_x_position': Array(2.048144, dtype=float32), 'eval/episode_x_velocity': Array(5.4047403, dtype=float32), 'eval/episode_y_position': Array(0.6393628, dtype=float32), 'eval/episode_y_velocity': Array(2.4390235, dtype=float32), 'eval/episode_distance_from_origin_std': Array(6.7466903, dtype=float32), 'eval/episode_forward_reward_std': Array(13.079438, dtype=float32), 'eval/episode_reward_std': Array(41.502316, dtype=float32), 'eval/episode_reward_alive_std': Array(39.839134, dtype=float32), 'eval/episode_reward_linvel_std': Array(13.079438, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.709145, dtype=float32), 'eval/episode_x_position_std': Array(1.6637162, dtype=float32), 'eval/episode_x_velocity_std': Array(5.2317753, dtype=float32), 'eval/episode_y_position_std': Array(1.8385129, dtype=float32), 'eval/episode_y_velocity_std': Array(6.3121343, dtype=float32), 'eval/avg_episode_length': Array(31.617188, dtype=float32), 'eval/epoch_eval_time': 5.844122648239136, 'eval/sps': 10951.173315858374, 'num_steps': 8960}
{'eval/walltime': 87.79647207260132, 'training/sps': 697.6008740169032, 'training/walltime': 41.38881969451904, 'training/entropy_loss': Array(-0.01276061, dtype=float32), 'training/policy_loss': Array(-0.07205713, dtype=float32), 'training/total_loss': Array(7.645423, dtype=float32), 'training/v_loss': Array(7.730241, dtype=float32), 'eval/episode_distance_from_origin': Array(27.032726, dtype=float32), 'eval/episode_forward_reward': Array(14.120435, dtype=float32), 'eval/episode_reward': Array(161.92693, dtype=float32), 'eval/episode_reward_alive': Array(167.07031, dtype=float32), 'eval/episode_reward_linvel': Array(14.120435, dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.263817, dtype=float32), 'eval/episode_x_position': Array(2.2887578, dtype=float32), 'eval/episode_x_velocity': Array(5.6481743, dtype=float32), 'eval/episode_y_position': Array(1.2956736, dtype=float32), 'eval/episode_y_velocity': Array(4.365901, dtype=float32), 'eval/episode_distance_from_origin_std': Array(6.8836865, dtype=float32), 'eval/episode_forward_reward_std': Array(15.0721245, dtype=float32), 'eval/episode_reward_std': Array(42.750862, dtype=float32), 'eval/episode_reward_alive_std': Array(40.97697, dtype=float32), 'eval/episode_reward_linvel_std': Array(15.0721245, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.76217, dtype=float32), 'eval/episode_x_position_std': Array(1.9053274, dtype=float32), 'eval/episode_x_velocity_std': Array(6.02885, dtype=float32), 'eval/episode_y_position_std': Array(1.8061117, dtype=float32), 'eval/episode_y_velocity_std': Array(5.919894, dtype=float32), 'eval/avg_episode_length': Array(33.414062, dtype=float32), 'eval/epoch_eval_time': 5.834935665130615, 'eval/sps': 10968.41570721369, 'num_steps': 10240}
{'eval/walltime': 93.61909866333008, 'training/sps': 705.5083647811222, 'training/walltime': 43.20311427116394, 'training/entropy_loss': Array(-0.01268819, dtype=float32), 'training/policy_loss': Array(-0.07102157, dtype=float32), 'training/total_loss': Array(6.2288733, dtype=float32), 'training/v_loss': Array(6.312583, dtype=float32), 'eval/episode_distance_from_origin': Array(27.514727, dtype=float32), 'eval/episode_forward_reward': Array(15.648941, dtype=float32), 'eval/episode_reward': Array(166.0303, dtype=float32), 'eval/episode_reward_alive': Array(169.80469, dtype=float32), 'eval/episode_reward_linvel': Array(15.648941, dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.423336, dtype=float32), 'eval/episode_x_position': Array(2.406629, dtype=float32), 'eval/episode_x_velocity': Array(6.2595763, dtype=float32), 'eval/episode_y_position': Array(0.92657995, dtype=float32), 'eval/episode_y_velocity': Array(3.1771107, dtype=float32), 'eval/episode_distance_from_origin_std': Array(6.865566, dtype=float32), 'eval/episode_forward_reward_std': Array(13.9054365, dtype=float32), 'eval/episode_reward_std': Array(40.37794, dtype=float32), 'eval/episode_reward_alive_std': Array(40.045883, dtype=float32), 'eval/episode_reward_linvel_std': Array(13.9054365, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.6439366, dtype=float32), 'eval/episode_x_position_std': Array(1.6818297, dtype=float32), 'eval/episode_x_velocity_std': Array(5.5621743, dtype=float32), 'eval/episode_y_position_std': Array(2.1562154, dtype=float32), 'eval/episode_y_velocity_std': Array(7.6172256, dtype=float32), 'eval/avg_episode_length': Array(33.960938, dtype=float32), 'eval/epoch_eval_time': 5.82262659072876, 'eval/sps': 10991.60301673918, 'num_steps': 11520}