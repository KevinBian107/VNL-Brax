{"eval/walltime": 1971.919399023056, "eval/episode_distance_from_origin": 0.0, "eval/episode_forward_reward": 0.0, "eval/episode_reward": 4.199999809265137, "eval/episode_reward_alive": 5.0, "eval/episode_reward_linvel": 0.0, "eval/episode_reward_quadctrl": -0.800000011920929, "eval/episode_x_position": 0.0, "eval/episode_x_velocity": 0.0, "eval/episode_y_position": 0.0, "eval/episode_y_velocity": 0.0, "eval/episode_distance_from_origin_std": 0.0, "eval/episode_forward_reward_std": 0.0, "eval/episode_reward_std": 0.0, "eval/episode_reward_alive_std": 0.0, "eval/episode_reward_linvel_std": 0.0, "eval/episode_reward_quadctrl_std": 0.0, "eval/episode_x_position_std": 0.0, "eval/episode_x_velocity_std": 0.0, "eval/episode_y_position_std": 0.0, "eval/episode_y_velocity_std": 0.0, "eval/avg_episode_length": 1.0, "eval/epoch_eval_time": 958.142226934433, "eval/sps": 133.59185766139834, "num_steps": 15073280, "_timestamp": 1706930815.590537, "_runtime": 20032.351989984512, "_step": 1, "training/sps": 836.3498907613324, "training/walltime": 18022.696202278137, "training/entropy_loss": 0.8068484663963318, "training/policy_loss": 0.2807546854019165, "training/total_loss": 63600.5, "training/v_loss": 63599.41796875, "_wandb": {"runtime": 20031}}