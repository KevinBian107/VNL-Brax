
{'eval/walltime': 288.8218710422516, 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(-211.30324, dtype=float32), 'eval/episode_reward_alive': Array(1.6875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-212.99074, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(3.5647297, dtype=float32), 'eval/episode_reward_alive_std': Array(2.622022, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.2860975, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 288.8218710422516, 'eval/sps': 443.17973406271216, 'num_steps': 0}
{'eval/walltime': 408.9836599826813, 'training/sps': 493.33832502862674, 'training/walltime': 166.0523738861084, 'training/entropy_loss': Array(-0.0050582, dtype=float32), 'training/policy_loss': Array(0.02507056, dtype=float32), 'training/total_loss': Array(0.02141912, dtype=float32), 'training/v_loss': Array(0.00140676, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(-194.14107, dtype=float32), 'eval/episode_reward_alive': Array(19.894531, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.0356, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(26.850391, dtype=float32), 'eval/episode_reward_alive_std': Array(32.978603, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.779012, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.16178894042969, 'eval/sps': 1065.2304790789701, 'num_steps': 81920}
{'eval/walltime': 528.909362077713, 'training/sps': 583.9438621327547, 'training/walltime': 306.33983182907104, 'training/entropy_loss': Array(-0.00495457, dtype=float32), 'training/policy_loss': Array(0.03849904, dtype=float32), 'training/total_loss': Array(0.03385919, dtype=float32), 'training/v_loss': Array(0.00031472, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(-179.47629, dtype=float32), 'eval/episode_reward_alive': Array(18.636719, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-198.113, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(20.7005, dtype=float32), 'eval/episode_reward_alive_std': Array(20.483103, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.2164688, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.92570209503174, 'eval/sps': 1067.3275016440598, 'num_steps': 163840}
{'eval/walltime': 648.8725306987762, 'training/sps': 580.5639478924818, 'training/walltime': 447.4440121650696, 'training/entropy_loss': Array(-0.00452656, dtype=float32), 'training/policy_loss': Array(0.01671939, dtype=float32), 'training/total_loss': Array(0.01249018, dtype=float32), 'training/v_loss': Array(0.00029736, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(-90.89278, dtype=float32), 'eval/episode_reward_alive': Array(98.6875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-189.58026, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(55.053265, dtype=float32), 'eval/episode_reward_alive_std': Array(56.751377, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.233468, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96316862106323, 'eval/sps': 1066.9941572177318, 'num_steps': 245760}
{'eval/walltime': 769.126472234726, 'training/sps': 584.8422911477425, 'training/walltime': 587.5159618854523, 'training/entropy_loss': Array(-0.00353022, dtype=float32), 'training/policy_loss': Array(-0.00874082, dtype=float32), 'training/total_loss': Array(-0.01082448, dtype=float32), 'training/v_loss': Array(0.00144657, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(262.57425, dtype=float32), 'eval/episode_reward_alive': Array(455.84766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-193.2734, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(57.71294, dtype=float32), 'eval/episode_reward_alive_std': Array(57.67492, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.4043207, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.2539415359497, 'eval/sps': 1064.4141752454295, 'num_steps': 327680}
{'eval/walltime': 888.9224026203156, 'training/sps': 584.2666788504315, 'training/walltime': 727.7259087562561, 'training/entropy_loss': Array(-0.00291457, dtype=float32), 'training/policy_loss': Array(0.00204747, dtype=float32), 'training/total_loss': Array(0.0001223, dtype=float32), 'training/v_loss': Array(0.00098941, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(293.34348, dtype=float32), 'eval/episode_reward_alive': Array(477.19922, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-183.85574, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(36.065388, dtype=float32), 'eval/episode_reward_alive_std': Array(35.969025, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.4021432, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7959303855896, 'eval/sps': 1068.4837088205234, 'num_steps': 409600}
{'eval/walltime': 1009.0261425971985, 'training/sps': 583.781046650319, 'training/walltime': 868.0524926185608, 'training/entropy_loss': Array(-0.00256803, dtype=float32), 'training/policy_loss': Array(-0.01371317, dtype=float32), 'training/total_loss': Array(-0.01590321, dtype=float32), 'training/v_loss': Array(0.000378, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(320.1347, dtype=float32), 'eval/episode_reward_alive': Array(493.7422, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-173.60745, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.511028, dtype=float32), 'eval/episode_reward_alive_std': Array(8.82335, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.0427108, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.10373997688293, 'eval/sps': 1065.7453300341597, 'num_steps': 491520}
{'eval/walltime': 1129.2232720851898, 'training/sps': 585.1006447865013, 'training/walltime': 1008.0625929832458, 'training/entropy_loss': Array(-0.00252881, dtype=float32), 'training/policy_loss': Array(-0.03122729, dtype=float32), 'training/total_loss': Array(-0.03359732, dtype=float32), 'training/v_loss': Array(0.00015879, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(337.71588, dtype=float32), 'eval/episode_reward_alive': Array(496.0703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-158.3544, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9828396, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3225718, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.970385, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.19712948799133, 'eval/sps': 1064.9172783513789, 'num_steps': 573440}
{'eval/walltime': 1249.5287413597107, 'training/sps': 584.8791377635202, 'training/walltime': 1148.1257183551788, 'training/entropy_loss': Array(-0.00209293, dtype=float32), 'training/policy_loss': Array(-0.03580573, dtype=float32), 'training/total_loss': Array(-0.03779473, dtype=float32), 'training/v_loss': Array(0.00010394, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(355.80652, dtype=float32), 'eval/episode_reward_alive': Array(498.14062, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-142.33414, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(3.315311, dtype=float32), 'eval/episode_reward_alive_std': Array(2.4613714, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.675325, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.30546927452087, 'eval/sps': 1063.9582786375342, 'num_steps': 655360}
{'eval/walltime': 1369.3836600780487, 'training/sps': 585.1411551388792, 'training/walltime': 1288.126125574112, 'training/entropy_loss': Array(-0.00164276, dtype=float32), 'training/policy_loss': Array(-0.05419937, dtype=float32), 'training/total_loss': Array(-0.05579722, dtype=float32), 'training/v_loss': Array(4.48989e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(372.01984, dtype=float32), 'eval/episode_reward_alive': Array(498.53125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-126.51134, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2.7724698, dtype=float32), 'eval/episode_reward_alive_std': Array(1.7741085, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.1953967, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85491871833801, 'eval/sps': 1067.9578391004804, 'num_steps': 737280}
{'eval/walltime': 1489.4483592510223, 'training/sps': 583.9510423274919, 'training/walltime': 1428.4118585586548, 'training/entropy_loss': Array(-0.00131133, dtype=float32), 'training/policy_loss': Array(-0.05029928, dtype=float32), 'training/total_loss': Array(-0.05156472, dtype=float32), 'training/v_loss': Array(4.588857e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(386.60315, dtype=float32), 'eval/episode_reward_alive': Array(498.71484, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-112.11171, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2.8690276, dtype=float32), 'eval/episode_reward_alive_std': Array(1.2557424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.4496894, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.06469917297363, 'eval/sps': 1066.091872812626, 'num_steps': 819200}
{'eval/walltime': 1609.3928956985474, 'training/sps': 584.7557837624925, 'training/walltime': 1568.5045301914215, 'training/entropy_loss': Array(-0.00095476, dtype=float32), 'training/policy_loss': Array(-0.0480812, dtype=float32), 'training/total_loss': Array(-0.0489933, dtype=float32), 'training/v_loss': Array(4.2662974e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(399.52795, dtype=float32), 'eval/episode_reward_alive': Array(498.71484, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-99.18689, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2.372757, dtype=float32), 'eval/episode_reward_alive_std': Array(1.2065634, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.7850138, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94453644752502, 'eval/sps': 1067.1599039944533, 'num_steps': 901120}
{'eval/walltime': 1729.1821439266205, 'training/sps': 585.315468633298, 'training/walltime': 1708.4632437229156, 'training/entropy_loss': Array(-0.00056248, dtype=float32), 'training/policy_loss': Array(-0.0597792, dtype=float32), 'training/total_loss': Array(-0.06031656, dtype=float32), 'training/v_loss': Array(2.5116227e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(409.63052, dtype=float32), 'eval/episode_reward_alive': Array(496.44922, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-86.81867, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(23.995073, dtype=float32), 'eval/episode_reward_alive_std': Array(22.739166, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.3155868, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78924822807312, 'eval/sps': 1068.543311635899, 'num_steps': 983040}
{'eval/walltime': 1849.2070546150208, 'training/sps': 584.9697668178518, 'training/walltime': 1848.5046691894531, 'training/entropy_loss': Array(-0.00022327, dtype=float32), 'training/policy_loss': Array(-0.04436268, dtype=float32), 'training/total_loss': Array(-0.04455151, dtype=float32), 'training/v_loss': Array(3.4446803e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(420.8324, dtype=float32), 'eval/episode_reward_alive': Array(497.8672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-77.03479, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.7762575, dtype=float32), 'eval/episode_reward_alive_std': Array(9.001189, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.6038929, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02491068840027, 'eval/sps': 1066.4452842818944, 'num_steps': 1064960}
{'eval/walltime': 1969.3909122943878, 'training/sps': 585.1464176316775, 'training/walltime': 1988.50381731987, 'training/entropy_loss': Array(0.00021184, dtype=float32), 'training/policy_loss': Array(-0.04323722, dtype=float32), 'training/total_loss': Array(-0.04300177, dtype=float32), 'training/v_loss': Array(2.3606895e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(430.89996, dtype=float32), 'eval/episode_reward_alive': Array(498.57422, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-67.67424, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(4.8597417, dtype=float32), 'eval/episode_reward_alive_std': Array(3.9340706, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.9309777, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.18385767936707, 'eval/sps': 1065.0348763266134, 'num_steps': 1146880}
{'eval/walltime': 2089.440502166748, 'training/sps': 585.0136266817852, 'training/walltime': 2128.5347435474396, 'training/entropy_loss': Array(0.00044269, dtype=float32), 'training/policy_loss': Array(-0.02521229, dtype=float32), 'training/total_loss': Array(-0.0246739, dtype=float32), 'training/v_loss': Array(9.570185e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(437.77692, dtype=float32), 'eval/episode_reward_alive': Array(498.91406, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-61.13711, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2.1205912, dtype=float32), 'eval/episode_reward_alive_std': Array(1.057173, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.7468188, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04958987236023, 'eval/sps': 1066.2260498856585, 'num_steps': 1228800}
{'eval/walltime': 2209.208879709244, 'training/sps': 584.7899709975665, 'training/walltime': 2268.6192252635956, 'training/entropy_loss': Array(0.00107076, dtype=float32), 'training/policy_loss': Array(-0.05130588, dtype=float32), 'training/total_loss': Array(-0.05022013, dtype=float32), 'training/v_loss': Array(1.499121e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(445.63763, dtype=float32), 'eval/episode_reward_alive': Array(498.90234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-53.264694, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.6975304, dtype=float32), 'eval/episode_reward_alive_std': Array(1.0459344, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3314883, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76837754249573, 'eval/sps': 1068.729514638232, 'num_steps': 1310720}
{'eval/walltime': 2329.161960840225, 'training/sps': 585.520250820245, 'training/walltime': 2408.5289890766144, 'training/entropy_loss': Array(0.00149371, dtype=float32), 'training/policy_loss': Array(-0.0345961, dtype=float32), 'training/total_loss': Array(-0.03308286, dtype=float32), 'training/v_loss': Array(1.951975e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(452.28088, dtype=float32), 'eval/episode_reward_alive': Array(498.86328, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-46.5824, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2.2032318, dtype=float32), 'eval/episode_reward_alive_std': Array(1.0052885, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.9088279, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95308113098145, 'eval/sps': 1067.083886409152, 'num_steps': 1392640}
{'eval/walltime': 2449.029367685318, 'training/sps': 585.0161566654141, 'training/walltime': 2548.559309720993, 'training/entropy_loss': Array(0.00191762, dtype=float32), 'training/policy_loss': Array(-0.02914689, dtype=float32), 'training/total_loss': Array(-0.02721261, dtype=float32), 'training/v_loss': Array(1.6656442e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(459.96686, dtype=float32), 'eval/episode_reward_alive': Array(499., dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-39.033157, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.686888, dtype=float32), 'eval/episode_reward_alive_std': Array(0.99215674, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2582356, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86740684509277, 'eval/sps': 1067.8465762208166, 'num_steps': 1474560}
{'eval/walltime': 2569.0946414470673, 'training/sps': 585.3093276798836, 'training/walltime': 2688.519491672516, 'training/entropy_loss': Array(0.00269074, dtype=float32), 'training/policy_loss': Array(-0.036429, dtype=float32), 'training/total_loss': Array(-0.03371966, dtype=float32), 'training/v_loss': Array(1.858742e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(463.8422, dtype=float32), 'eval/episode_reward_alive': Array(498.9453, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-35.103085, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2.1175365, dtype=float32), 'eval/episode_reward_alive_std': Array(0.9827305, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.8986918, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.06527376174927, 'eval/sps': 1066.086770884277, 'num_steps': 1556480}
{'eval/walltime': 2689.134283542633, 'training/sps': 585.1804851204279, 'training/walltime': 2828.510489463806, 'training/entropy_loss': Array(0.00316941, dtype=float32), 'training/policy_loss': Array(-0.04017325, dtype=float32), 'training/total_loss': Array(-0.03699308, dtype=float32), 'training/v_loss': Array(1.0763639e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(469.06183, dtype=float32), 'eval/episode_reward_alive': Array(499.08203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-30.020206, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2.244476, dtype=float32), 'eval/episode_reward_alive_std': Array(0.9956494, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.0830867, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.0396420955658, 'eval/sps': 1066.3144088525091, 'num_steps': 1638400}
{'eval/walltime': 2809.0842168331146, 'training/sps': 585.4271240412351, 'training/walltime': 2968.4425094127655, 'training/entropy_loss': Array(0.0040162, dtype=float32), 'training/policy_loss': Array(-0.04910332, dtype=float32), 'training/total_loss': Array(-0.04508068, dtype=float32), 'training/v_loss': Array(6.4383166e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(473.0818, dtype=float32), 'eval/episode_reward_alive': Array(499.08203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-26.000206, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.800423, dtype=float32), 'eval/episode_reward_alive_std': Array(0.9453367, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.5836495, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94993329048157, 'eval/sps': 1067.1118898417699, 'num_steps': 1720320}
{'eval/walltime': 2929.020227432251, 'training/sps': 585.3131284950847, 'training/walltime': 3108.401782512665, 'training/entropy_loss': Array(0.00460477, dtype=float32), 'training/policy_loss': Array(-0.0357423, dtype=float32), 'training/total_loss': Array(-0.03113101, dtype=float32), 'training/v_loss': Array(6.519077e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(474.81137, dtype=float32), 'eval/episode_reward_alive': Array(499.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-24.251095, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.769853, dtype=float32), 'eval/episode_reward_alive_std': Array(0.99215674, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.762528, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.93601059913635, 'eval/sps': 1067.2357648097536, 'num_steps': 1802240}
{'eval/walltime': 3048.9482860565186, 'training/sps': 585.6090246269285, 'training/walltime': 3248.290337085724, 'training/entropy_loss': Array(0.00517964, dtype=float32), 'training/policy_loss': Array(-0.02664299, dtype=float32), 'training/total_loss': Array(-0.02145695, dtype=float32), 'training/v_loss': Array(6.4006886e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(479.28122, dtype=float32), 'eval/episode_reward_alive': Array(499.0547, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.77346, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.6494328, dtype=float32), 'eval/episode_reward_alive_std': Array(0.95245236, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2780031, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.92805862426758, 'eval/sps': 1067.3065291669707, 'num_steps': 1884160}
{'eval/walltime': 3168.8555574417114, 'training/sps': 585.2499667886, 'training/walltime': 3388.2647149562836, 'training/entropy_loss': Array(0.00575142, dtype=float32), 'training/policy_loss': Array(-0.02348636, dtype=float32), 'training/total_loss': Array(-0.01772842, dtype=float32), 'training/v_loss': Array(6.5204467e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(482.45898, dtype=float32), 'eval/episode_reward_alive': Array(499.28906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.830097, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.1706413, dtype=float32), 'eval/episode_reward_alive_std': Array(0.92409027, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9098856, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90727138519287, 'eval/sps': 1067.4915584461085, 'num_steps': 1966080}
{'eval/walltime': 3288.9014661312103, 'training/sps': 585.0873348686339, 'training/walltime': 3528.278000354767, 'training/entropy_loss': Array(0.00675522, dtype=float32), 'training/policy_loss': Array(-0.02733635, dtype=float32), 'training/total_loss': Array(-0.02057733, dtype=float32), 'training/v_loss': Array(3.806545e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(483.98404, dtype=float32), 'eval/episode_reward_alive': Array(499.1328, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.1488, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.4181243, dtype=float32), 'eval/episode_reward_alive_std': Array(0.93850857, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9670059, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.0459086894989, 'eval/sps': 1066.2587454860666, 'num_steps': 2048000}
{'eval/walltime': 3408.8847982883453, 'training/sps': 584.8041741420391, 'training/walltime': 3668.359079837799, 'training/entropy_loss': Array(0.00731626, dtype=float32), 'training/policy_loss': Array(-0.02118659, dtype=float32), 'training/total_loss': Array(-0.01386609, dtype=float32), 'training/v_loss': Array(4.24069e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(485.05664, dtype=float32), 'eval/episode_reward_alive': Array(498.98438, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.927719, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2.3597002, dtype=float32), 'eval/episode_reward_alive_std': Array(0.9761562, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.0893018, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98333215713501, 'eval/sps': 1066.8148458518058, 'num_steps': 2129920}
{'eval/walltime': 3664.633736848831, 'training/sps': 231.29265606480237, 'training/walltime': 4022.5423963069916, 'training/entropy_loss': Array(0.00771706, dtype=float32), 'training/policy_loss': Array(-0.01583755, dtype=float32), 'training/total_loss': Array(-0.00811613, dtype=float32), 'training/v_loss': Array(4.3521613e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(486.2094, dtype=float32), 'eval/episode_reward_alive': Array(498.97656, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.76717, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.1218857, dtype=float32), 'eval/episode_reward_alive_std': Array(0.92250377, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.80953795, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.74893856048584, 'eval/sps': 500.49083574095613, 'num_steps': 2211840}
{'eval/walltime': 3920.037674665451, 'training/sps': 180.03614161891997, 'training/walltime': 4477.562145471573, 'training/entropy_loss': Array(0.00838373, dtype=float32), 'training/policy_loss': Array(-0.02426695, dtype=float32), 'training/total_loss': Array(-0.01588117, dtype=float32), 'training/v_loss': Array(2.0539494e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(486.76294, dtype=float32), 'eval/episode_reward_alive': Array(499.16016, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.397211, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.2037425, dtype=float32), 'eval/episode_reward_alive_std': Array(0.91841745, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.82531404, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.40393781661987, 'eval/sps': 501.1669009265787, 'num_steps': 2293760}
{'eval/walltime': 4175.667407035828, 'training/sps': 180.0234175783641, 'training/walltime': 4932.614055395126, 'training/entropy_loss': Array(0.00850034, dtype=float32), 'training/policy_loss': Array(-0.01837299, dtype=float32), 'training/total_loss': Array(-0.00986952, dtype=float32), 'training/v_loss': Array(3.1345085e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(487.10535, dtype=float32), 'eval/episode_reward_alive': Array(499.03516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.929817, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.2058979, dtype=float32), 'eval/episode_reward_alive_std': Array(0.9726406, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7518775, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.6297323703766, 'eval/sps': 500.7242264547829, 'num_steps': 2375680}
{'eval/walltime': 4430.909071683884, 'training/sps': 179.78288095533935, 'training/walltime': 5388.2747921943665, 'training/entropy_loss': Array(0.0090162, dtype=float32), 'training/policy_loss': Array(-0.0122431, dtype=float32), 'training/total_loss': Array(-0.00322412, dtype=float32), 'training/v_loss': Array(2.7856966e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(487.62695, dtype=float32), 'eval/episode_reward_alive': Array(499.04297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.415979, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.1929815, dtype=float32), 'eval/episode_reward_alive_std': Array(0.9228593, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.938402, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.24166464805603, 'eval/sps': 501.48552422463945, 'num_steps': 2457600}
{'eval/walltime': 4686.413879871368, 'training/sps': 179.8163780397928, 'training/walltime': 5843.8506462574005, 'training/entropy_loss': Array(0.00914145, dtype=float32), 'training/policy_loss': Array(-0.00307363, dtype=float32), 'training/total_loss': Array(0.00607109, dtype=float32), 'training/v_loss': Array(3.2709995e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(488.38165, dtype=float32), 'eval/episode_reward_alive': Array(499.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.68085, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.2443631, dtype=float32), 'eval/episode_reward_alive_std': Array(0.8992184, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9220206, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.50480818748474, 'eval/sps': 500.96904597613656, 'num_steps': 2539520}
{'eval/walltime': 4942.078145742416, 'training/sps': 179.93797196564844, 'training/walltime': 6299.118642807007, 'training/entropy_loss': Array(0.00967027, dtype=float32), 'training/policy_loss': Array(0.0114678, dtype=float32), 'training/total_loss': Array(0.02114758, dtype=float32), 'training/v_loss': Array(9.5031955e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(489.51373, dtype=float32), 'eval/episode_reward_alive': Array(499.1172, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.603469, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.1452876, dtype=float32), 'eval/episode_reward_alive_std': Array(0.85806006, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.75186926, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.66426587104797, 'eval/sps': 500.656591815458, 'num_steps': 2621440}
{'eval/walltime': 5198.212949037552, 'training/sps': 179.97495315179893, 'training/walltime': 6754.293091058731, 'training/entropy_loss': Array(0.00998322, dtype=float32), 'training/policy_loss': Array(0.00264278, dtype=float32), 'training/total_loss': Array(0.01263, dtype=float32), 'training/v_loss': Array(3.996096e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(489.40643, dtype=float32), 'eval/episode_reward_alive': Array(499.0664, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.659985, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2.222366, dtype=float32), 'eval/episode_reward_alive_std': Array(0.87359506, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.1240523, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.1348032951355, 'eval/sps': 499.7368508820331, 'num_steps': 2703360}
{'eval/walltime': 5454.507440090179, 'training/sps': 179.80325881225346, 'training/walltime': 7209.902185916901, 'training/entropy_loss': Array(0.01038356, dtype=float32), 'training/policy_loss': Array(-0.01085552, dtype=float32), 'training/total_loss': Array(-0.00046919, dtype=float32), 'training/v_loss': Array(2.772008e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(490.01495, dtype=float32), 'eval/episode_reward_alive': Array(498.94922, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.934217, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.0760338, dtype=float32), 'eval/episode_reward_alive_std': Array(0.88573736, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.58753675, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.29449105262756, 'eval/sps': 499.4254830616568, 'num_steps': 2785280}
{'eval/walltime': 5710.771861791611, 'training/sps': 180.02274743052496, 'training/walltime': 7664.955789804459, 'training/entropy_loss': Array(0.01090247, dtype=float32), 'training/policy_loss': Array(-0.01027084, dtype=float32), 'training/total_loss': Array(0.00063339, dtype=float32), 'training/v_loss': Array(1.7619917e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(490.7182, dtype=float32), 'eval/episode_reward_alive': Array(499.16797, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.449778, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(0.91567165, dtype=float32), 'eval/episode_reward_alive_std': Array(0.85302156, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3867903, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.2644217014313, 'eval/sps': 499.48408425235993, 'num_steps': 2867200}
{'eval/walltime': 5967.096967697144, 'training/sps': 179.8987509345081, 'training/walltime': 8120.323042631149, 'training/entropy_loss': Array(0.01117122, dtype=float32), 'training/policy_loss': Array(-0.0079222, dtype=float32), 'training/total_loss': Array(0.00325101, dtype=float32), 'training/v_loss': Array(1.9892955e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(490.84967, dtype=float32), 'eval/episode_reward_alive': Array(499.20703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.357394, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.0102438, dtype=float32), 'eval/episode_reward_alive_std': Array(0.9089987, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.4020198, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.32510590553284, 'eval/sps': 499.3658328855765, 'num_steps': 2949120}
{'eval/walltime': 6223.367575645447, 'training/sps': 179.79729527885462, 'training/walltime': 8575.947249174118, 'training/entropy_loss': Array(0.01153454, dtype=float32), 'training/policy_loss': Array(-0.01556473, dtype=float32), 'training/total_loss': Array(-0.00402882, dtype=float32), 'training/v_loss': Array(1.3697725e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(490.93323, dtype=float32), 'eval/episode_reward_alive': Array(499.25, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.31678, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.0013599, dtype=float32), 'eval/episode_reward_alive_std': Array(0.8637672, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.4280952, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 256.2706079483032, 'eval/sps': 499.47202695137435, 'num_steps': 3031040}
{'eval/walltime': 6478.985721111298, 'training/sps': 179.8595417252756, 'training/walltime': 9031.413771629333, 'training/entropy_loss': Array(0.0117051, dtype=float32), 'training/policy_loss': Array(-0.01166861, dtype=float32), 'training/total_loss': Array(3.8612634e-05, dtype=float32), 'training/v_loss': Array(2.1192384e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(490.98373, dtype=float32), 'eval/episode_reward_alive': Array(499.34375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.360025, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.0395138, dtype=float32), 'eval/episode_reward_alive_std': Array(0.8332682, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.5702915, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.61814546585083, 'eval/sps': 500.7469237628911, 'num_steps': 3112960}
{'eval/walltime': 6734.28847193718, 'training/sps': 179.99570431427895, 'training/walltime': 9486.535744190216, 'training/entropy_loss': Array(0.01190155, dtype=float32), 'training/policy_loss': Array(-0.00976783, dtype=float32), 'training/total_loss': Array(0.00213488, dtype=float32), 'training/v_loss': Array(1.16418e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(490.9109, dtype=float32), 'eval/episode_reward_alive': Array(499.2539, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.343008, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.1292716, dtype=float32), 'eval/episode_reward_alive_std': Array(0.8614942, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.61978686, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.30275082588196, 'eval/sps': 501.3655340020084, 'num_steps': 3194880}
{'eval/walltime': 6989.432894945145, 'training/sps': 179.58836988944984, 'training/walltime': 9942.690004348755, 'training/entropy_loss': Array(0.01206216, dtype=float32), 'training/policy_loss': Array(-0.00946321, dtype=float32), 'training/total_loss': Array(0.00260057, dtype=float32), 'training/v_loss': Array(1.6223592e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(491.29144, dtype=float32), 'eval/episode_reward_alive': Array(499.0703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-7.778885, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.0664133, dtype=float32), 'eval/episode_reward_alive_std': Array(0.8699281, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.4513763, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.1444230079651, 'eval/sps': 501.67665234839995, 'num_steps': 3276800}
{'eval/walltime': 7244.720792770386, 'training/sps': 179.90467080492658, 'training/walltime': 10398.042273044586, 'training/entropy_loss': Array(0.01277563, dtype=float32), 'training/policy_loss': Array(-0.00964009, dtype=float32), 'training/total_loss': Array(0.00313651, dtype=float32), 'training/v_loss': Array(9.658678e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(491.98282, dtype=float32), 'eval/episode_reward_alive': Array(499.22656, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-7.24375, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.0668193, dtype=float32), 'eval/episode_reward_alive_std': Array(0.8923708, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.44601184, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.2878978252411, 'eval/sps': 501.39470413761325, 'num_steps': 3358720}
{'eval/walltime': 7499.8712413311005, 'training/sps': 179.98544263931447, 'training/walltime': 10853.190193891525, 'training/entropy_loss': Array(0.01313053, dtype=float32), 'training/policy_loss': Array(-0.0058301, dtype=float32), 'training/total_loss': Array(0.00730184, dtype=float32), 'training/v_loss': Array(1.406286e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(492.13995, dtype=float32), 'eval/episode_reward_alive': Array(499.22656, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-7.0866375, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.0167704, dtype=float32), 'eval/episode_reward_alive_std': Array(0.8474672, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.44443208, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.15044856071472, 'eval/sps': 501.664804910353, 'num_steps': 3440640}
{'eval/walltime': 7755.844780445099, 'training/sps': 179.88925761255302, 'training/walltime': 11308.581477880478, 'training/entropy_loss': Array(0.01342749, dtype=float32), 'training/policy_loss': Array(-0.00625324, dtype=float32), 'training/total_loss': Array(0.00717621, dtype=float32), 'training/v_loss': Array(1.9607842e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(492.09265, dtype=float32), 'eval/episode_reward_alive': Array(499.13672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-7.044078, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(0.9780927, dtype=float32), 'eval/episode_reward_alive_std': Array(0.84018886, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.4513077, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.9735391139984, 'eval/sps': 500.051686760462, 'num_steps': 3522560}
{'eval/walltime': 8011.039522409439, 'training/sps': 179.82666514975404, 'training/walltime': 11764.13127040863, 'training/entropy_loss': Array(0.01376327, dtype=float32), 'training/policy_loss': Array(-0.006468, dtype=float32), 'training/total_loss': Array(0.00729621, dtype=float32), 'training/v_loss': Array(9.340156e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(492.34302, dtype=float32), 'eval/episode_reward_alive': Array(499.07422, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-6.7311873, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(0.9057109, dtype=float32), 'eval/episode_reward_alive_std': Array(0.84569186, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.28017747, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.1947419643402, 'eval/sps': 501.57773242007534, 'num_steps': 3604480}
{'eval/walltime': 8266.730364561081, 'training/sps': 179.78373473021895, 'training/walltime': 12219.789843320847, 'training/entropy_loss': Array(0.01402482, dtype=float32), 'training/policy_loss': Array(-0.0033096, dtype=float32), 'training/total_loss': Array(0.01071638, dtype=float32), 'training/v_loss': Array(1.1562552e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(492.43808, dtype=float32), 'eval/episode_reward_alive': Array(499.02734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-6.5892844, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1.0313847, dtype=float32), 'eval/episode_reward_alive_std': Array(0.89116454, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3681303, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.69084215164185, 'eval/sps': 500.6045540109231, 'num_steps': 3686400}
{'eval/walltime': 8521.89232802391, 'training/sps': 179.75838344172612, 'training/walltime': 12675.512677669525, 'training/entropy_loss': Array(0.01448371, dtype=float32), 'training/policy_loss': Array(-0.00837903, dtype=float32), 'training/total_loss': Array(0.00610565, dtype=float32), 'training/v_loss': Array(9.712832e-07, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(492.8961, dtype=float32), 'eval/episode_reward_alive': Array(499.19922, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-6.3031588, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(0.94951, dtype=float32), 'eval/episode_reward_alive_std': Array(0.8712864, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.31520373, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.1619634628296, 'eval/sps': 501.6421658733875, 'num_steps': 3768320}
{'eval/walltime': 8777.428111314774, 'training/sps': 179.93979149878245, 'training/walltime': 13130.776070594788, 'training/entropy_loss': Array(0.01494251, dtype=float32), 'training/policy_loss': Array(-0.00404026, dtype=float32), 'training/total_loss': Array(0.01090363, dtype=float32), 'training/v_loss': Array(1.386584e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(492.8668, dtype=float32), 'eval/episode_reward_alive': Array(499.10547, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-6.2386346, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(0.96567976, dtype=float32), 'eval/episode_reward_alive_std': Array(0.865241, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2539639, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.53578329086304, 'eval/sps': 500.9083203595963, 'num_steps': 3850240}
{'eval/walltime': 9032.675191402435, 'training/sps': 179.81559321484806, 'training/walltime': 13586.353913068771, 'training/entropy_loss': Array(0.01534819, dtype=float32), 'training/policy_loss': Array(-0.00196078, dtype=float32), 'training/total_loss': Array(0.01338855, dtype=float32), 'training/v_loss': Array(1.1415534e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(492.9325, dtype=float32), 'eval/episode_reward_alive': Array(499.21094, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-6.2784586, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(0.90124124, dtype=float32), 'eval/episode_reward_alive_std': Array(0.83293855, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24877985, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.24708008766174, 'eval/sps': 501.4748844767973, 'num_steps': 3932160}
{'eval/walltime': 9288.580026626587, 'training/sps': 179.76743059285442, 'training/walltime': 14042.053812265396, 'training/entropy_loss': Array(0.01541365, dtype=float32), 'training/policy_loss': Array(-0.00263257, dtype=float32), 'training/total_loss': Array(0.01278222, dtype=float32), 'training/v_loss': Array(1.140904e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(492.62515, dtype=float32), 'eval/episode_reward_alive': Array(499.1875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-6.5623617, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(0.9254126, dtype=float32), 'eval/episode_reward_alive_std': Array(0.8477912, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.28143904, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 255.9048352241516, 'eval/sps': 500.18593782287275, 'num_steps': 4014080}