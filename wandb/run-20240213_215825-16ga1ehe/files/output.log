
{'eval/walltime': 170.31577563285828, 'eval/episode_distance_from_origin': Array(3040.6353, dtype=float32), 'eval/episode_distance_reward': Array(0.05001232, dtype=float32), 'eval/episode_forward_reward': Array(8.33539, dtype=float32), 'eval/episode_reward': Array(-202.40869, dtype=float32), 'eval/episode_reward_alive': Array(1.8320312, dtype=float32), 'eval/episode_reward_linvel': Array(8.33539, dtype=float32), 'eval/episode_reward_quadctrl': Array(-212.6261, dtype=float32), 'eval/episode_x_position': Array(3020.0205, dtype=float32), 'eval/episode_x_velocity': Array(1.6670766, dtype=float32), 'eval/episode_y_position': Array(-1.0245423, dtype=float32), 'eval/episode_y_velocity': Array(-1.7963622, dtype=float32), 'eval/episode_distance_from_origin_std': Array(52.553, dtype=float32), 'eval/episode_distance_reward_std': Array(0.37821695, dtype=float32), 'eval/episode_forward_reward_std': Array(63.036163, dtype=float32), 'eval/episode_reward_std': Array(63.247475, dtype=float32), 'eval/episode_reward_alive_std': Array(2.5975327, dtype=float32), 'eval/episode_reward_linvel_std': Array(63.036163, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.1968799, dtype=float32), 'eval/episode_x_position_std': Array(52.82417, dtype=float32), 'eval/episode_x_velocity_std': Array(12.607232, dtype=float32), 'eval/episode_y_position_std': Array(56.90352, dtype=float32), 'eval/episode_y_velocity_std': Array(12.41615, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 170.31577563285828, 'eval/sps': 751.5451785037435, 'num_steps': 0}
{'eval/walltime': 306.72169637680054, 'training/sps': 1488.8062159536705, 'training/walltime': 55.023950815200806, 'training/entropy_loss': Array(-0.00509988, dtype=float32), 'training/policy_loss': Array(-0.01965451, dtype=float32), 'training/total_loss': Array(-0.00082416, dtype=float32), 'training/v_loss': Array(0.02393024, dtype=float32), 'eval/episode_distance_from_origin': Array(3157.0508, dtype=float32), 'eval/episode_distance_reward': Array(0.60457665, dtype=float32), 'eval/episode_forward_reward': Array(100.76278, dtype=float32), 'eval/episode_reward': Array(-109.40407, dtype=float32), 'eval/episode_reward_alive': Array(2.0351562, dtype=float32), 'eval/episode_reward_linvel': Array(100.76278, dtype=float32), 'eval/episode_reward_quadctrl': Array(-212.80658, dtype=float32), 'eval/episode_x_position': Array(3136.0876, dtype=float32), 'eval/episode_x_velocity': Array(20.152554, dtype=float32), 'eval/episode_y_position': Array(1.6758246, dtype=float32), 'eval/episode_y_velocity': Array(-1.6064665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(53.605904, dtype=float32), 'eval/episode_distance_reward_std': Array(0.33467916, dtype=float32), 'eval/episode_forward_reward_std': Array(55.779858, dtype=float32), 'eval/episode_reward_std': Array(56.93495, dtype=float32), 'eval/episode_reward_alive_std': Array(4.043795, dtype=float32), 'eval/episode_reward_linvel_std': Array(55.779858, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.27003, dtype=float32), 'eval/episode_x_position_std': Array(53.56466, dtype=float32), 'eval/episode_x_velocity_std': Array(11.155969, dtype=float32), 'eval/episode_y_position_std': Array(96.89512, dtype=float32), 'eval/episode_y_velocity_std': Array(18.232498, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40592074394226, 'eval/sps': 938.3756900133269, 'num_steps': 81920}
{'eval/walltime': 443.06702613830566, 'training/sps': 2955.8873864743705, 'training/walltime': 82.73813247680664, 'training/entropy_loss': Array(-0.00498613, dtype=float32), 'training/policy_loss': Array(-0.05912998, dtype=float32), 'training/total_loss': Array(-0.05095282, dtype=float32), 'training/v_loss': Array(0.01316329, dtype=float32), 'eval/episode_distance_from_origin': Array(3179.6548, dtype=float32), 'eval/episode_distance_reward': Array(0.7566397, dtype=float32), 'eval/episode_forward_reward': Array(126.10663, dtype=float32), 'eval/episode_reward': Array(-84.78659, dtype=float32), 'eval/episode_reward_alive': Array(3.0117188, dtype=float32), 'eval/episode_reward_linvel': Array(126.10663, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.66158, dtype=float32), 'eval/episode_x_position': Array(3159.1138, dtype=float32), 'eval/episode_x_velocity': Array(25.221321, dtype=float32), 'eval/episode_y_position': Array(-34.59899, dtype=float32), 'eval/episode_y_velocity': Array(-7.719862, dtype=float32), 'eval/episode_distance_from_origin_std': Array(62.350643, dtype=float32), 'eval/episode_distance_reward_std': Array(0.35405394, dtype=float32), 'eval/episode_forward_reward_std': Array(59.009003, dtype=float32), 'eval/episode_reward_std': Array(61.000458, dtype=float32), 'eval/episode_reward_alive_std': Array(5.090764, dtype=float32), 'eval/episode_reward_linvel_std': Array(59.009003, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.067565, dtype=float32), 'eval/episode_x_position_std': Array(62.21786, dtype=float32), 'eval/episode_x_velocity_std': Array(11.801797, dtype=float32), 'eval/episode_y_position_std': Array(87.30769, dtype=float32), 'eval/episode_y_velocity_std': Array(16.130838, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34532976150513, 'eval/sps': 938.7926980989906, 'num_steps': 163840}
{'eval/walltime': 579.5691838264465, 'training/sps': 2969.670476770224, 'training/walltime': 110.32368469238281, 'training/entropy_loss': Array(-0.00478135, dtype=float32), 'training/policy_loss': Array(-0.04832844, dtype=float32), 'training/total_loss': Array(-0.03932086, dtype=float32), 'training/v_loss': Array(0.01378894, dtype=float32), 'eval/episode_distance_from_origin': Array(3159.1277, dtype=float32), 'eval/episode_distance_reward': Array(0.64932036, dtype=float32), 'eval/episode_forward_reward': Array(108.22006, dtype=float32), 'eval/episode_reward': Array(-104.45972, dtype=float32), 'eval/episode_reward_alive': Array(3.0351562, dtype=float32), 'eval/episode_reward_linvel': Array(108.22006, dtype=float32), 'eval/episode_reward_quadctrl': Array(-216.36424, dtype=float32), 'eval/episode_x_position': Array(3138.0796, dtype=float32), 'eval/episode_x_velocity': Array(21.644009, dtype=float32), 'eval/episode_y_position': Array(-58.95859, dtype=float32), 'eval/episode_y_velocity': Array(-12.375412, dtype=float32), 'eval/episode_distance_from_origin_std': Array(63.19086, dtype=float32), 'eval/episode_distance_reward_std': Array(0.34988073, dtype=float32), 'eval/episode_forward_reward_std': Array(58.313465, dtype=float32), 'eval/episode_reward_std': Array(59.641693, dtype=float32), 'eval/episode_reward_alive_std': Array(4.5983963, dtype=float32), 'eval/episode_reward_linvel_std': Array(58.313465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.3262072, dtype=float32), 'eval/episode_x_position_std': Array(62.77725, dtype=float32), 'eval/episode_x_velocity_std': Array(11.662691, dtype=float32), 'eval/episode_y_position_std': Array(83.29825, dtype=float32), 'eval/episode_y_velocity_std': Array(15.229034, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50215768814087, 'eval/sps': 937.714115057688, 'num_steps': 245760}
{'eval/walltime': 715.8597800731659, 'training/sps': 2949.265919719615, 'training/walltime': 138.10008811950684, 'training/entropy_loss': Array(-0.00452325, dtype=float32), 'training/policy_loss': Array(-0.04637373, dtype=float32), 'training/total_loss': Array(-0.04671864, dtype=float32), 'training/v_loss': Array(0.00417833, dtype=float32), 'eval/episode_distance_from_origin': Array(3112.6216, dtype=float32), 'eval/episode_distance_reward': Array(0.40919876, dtype=float32), 'eval/episode_forward_reward': Array(68.19978, dtype=float32), 'eval/episode_reward': Array(-148.80124, dtype=float32), 'eval/episode_reward_alive': Array(2.2695312, dtype=float32), 'eval/episode_reward_linvel': Array(68.19978, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.67975, dtype=float32), 'eval/episode_x_position': Array(3091.9082, dtype=float32), 'eval/episode_x_velocity': Array(13.63996, dtype=float32), 'eval/episode_y_position': Array(-51.318985, dtype=float32), 'eval/episode_y_velocity': Array(-10.9036, dtype=float32), 'eval/episode_distance_from_origin_std': Array(67.148575, dtype=float32), 'eval/episode_distance_reward_std': Array(0.36820942, dtype=float32), 'eval/episode_forward_reward_std': Array(61.368225, dtype=float32), 'eval/episode_reward_std': Array(66.16957, dtype=float32), 'eval/episode_reward_alive_std': Array(3.75047, dtype=float32), 'eval/episode_reward_linvel_std': Array(61.368225, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(15.176515, dtype=float32), 'eval/episode_x_position_std': Array(67.27048, dtype=float32), 'eval/episode_x_velocity_std': Array(12.273647, dtype=float32), 'eval/episode_y_position_std': Array(71.257355, dtype=float32), 'eval/episode_y_velocity_std': Array(13.088629, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29059624671936, 'eval/sps': 939.169711814076, 'num_steps': 327680}
{'eval/walltime': 852.3182847499847, 'training/sps': 2965.6574569124496, 'training/walltime': 165.72296810150146, 'training/entropy_loss': Array(-0.00419036, dtype=float32), 'training/policy_loss': Array(-0.05332772, dtype=float32), 'training/total_loss': Array(-0.05659205, dtype=float32), 'training/v_loss': Array(0.00092602, dtype=float32), 'eval/episode_distance_from_origin': Array(3082.233, dtype=float32), 'eval/episode_distance_reward': Array(0.27425313, dtype=float32), 'eval/episode_forward_reward': Array(45.708855, dtype=float32), 'eval/episode_reward': Array(-170.97333, dtype=float32), 'eval/episode_reward_alive': Array(2.890625, dtype=float32), 'eval/episode_reward_linvel': Array(45.708855, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.84706, dtype=float32), 'eval/episode_x_position': Array(3060.9233, dtype=float32), 'eval/episode_x_velocity': Array(9.141773, dtype=float32), 'eval/episode_y_position': Array(-51.23089, dtype=float32), 'eval/episode_y_velocity': Array(-10.425396, dtype=float32), 'eval/episode_distance_from_origin_std': Array(78.04211, dtype=float32), 'eval/episode_distance_reward_std': Array(0.44784695, dtype=float32), 'eval/episode_forward_reward_std': Array(74.64115, dtype=float32), 'eval/episode_reward_std': Array(80.612816, dtype=float32), 'eval/episode_reward_alive_std': Array(11.722363, dtype=float32), 'eval/episode_reward_linvel_std': Array(74.64115, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.191677, dtype=float32), 'eval/episode_x_position_std': Array(77.097305, dtype=float32), 'eval/episode_x_velocity_std': Array(14.928233, dtype=float32), 'eval/episode_y_position_std': Array(88.27201, dtype=float32), 'eval/episode_y_velocity_std': Array(16.594461, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45850467681885, 'eval/sps': 938.0140893610734, 'num_steps': 409600}
{'eval/walltime': 988.5115416049957, 'training/sps': 2964.4477926356085, 'training/walltime': 193.35711979866028, 'training/entropy_loss': Array(-0.00381768, dtype=float32), 'training/policy_loss': Array(-0.05144442, dtype=float32), 'training/total_loss': Array(-0.05486162, dtype=float32), 'training/v_loss': Array(0.00040047, dtype=float32), 'eval/episode_distance_from_origin': Array(3053.8896, dtype=float32), 'eval/episode_distance_reward': Array(0.13817042, dtype=float32), 'eval/episode_forward_reward': Array(23.0284, dtype=float32), 'eval/episode_reward': Array(-197.1033, dtype=float32), 'eval/episode_reward_alive': Array(3.1835938, dtype=float32), 'eval/episode_reward_linvel': Array(23.0284, dtype=float32), 'eval/episode_reward_quadctrl': Array(-223.45349, dtype=float32), 'eval/episode_x_position': Array(3032.4758, dtype=float32), 'eval/episode_x_velocity': Array(4.605678, dtype=float32), 'eval/episode_y_position': Array(-33.991035, dtype=float32), 'eval/episode_y_velocity': Array(-7.1464167, dtype=float32), 'eval/episode_distance_from_origin_std': Array(83.51541, dtype=float32), 'eval/episode_distance_reward_std': Array(0.48189923, dtype=float32), 'eval/episode_forward_reward_std': Array(80.31653, dtype=float32), 'eval/episode_reward_std': Array(94.26433, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4754467, dtype=float32), 'eval/episode_reward_linvel_std': Array(80.31653, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.166658, dtype=float32), 'eval/episode_x_position_std': Array(82.63847, dtype=float32), 'eval/episode_x_velocity_std': Array(16.0633, dtype=float32), 'eval/episode_y_position_std': Array(80.59029, dtype=float32), 'eval/episode_y_velocity_std': Array(15.724931, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.193256855011, 'eval/sps': 939.8409506886718, 'num_steps': 491520}
{'eval/walltime': 1125.0018072128296, 'training/sps': 2964.8727782473393, 'training/walltime': 220.9873104095459, 'training/entropy_loss': Array(-0.0033172, dtype=float32), 'training/policy_loss': Array(0.06198757, dtype=float32), 'training/total_loss': Array(0.09375972, dtype=float32), 'training/v_loss': Array(0.03508935, dtype=float32), 'eval/episode_distance_from_origin': Array(3102.4734, dtype=float32), 'eval/episode_distance_reward': Array(0.3974158, dtype=float32), 'eval/episode_forward_reward': Array(66.23596, dtype=float32), 'eval/episode_reward': Array(-138.11214, dtype=float32), 'eval/episode_reward_alive': Array(13.175781, dtype=float32), 'eval/episode_reward_linvel': Array(66.23596, dtype=float32), 'eval/episode_reward_quadctrl': Array(-217.9213, dtype=float32), 'eval/episode_x_position': Array(3079.86, dtype=float32), 'eval/episode_x_velocity': Array(13.247192, dtype=float32), 'eval/episode_y_position': Array(-58.114674, dtype=float32), 'eval/episode_y_velocity': Array(-10.925607, dtype=float32), 'eval/episode_distance_from_origin_std': Array(90.0621, dtype=float32), 'eval/episode_distance_reward_std': Array(0.51741654, dtype=float32), 'eval/episode_forward_reward_std': Array(86.236084, dtype=float32), 'eval/episode_reward_std': Array(112.49484, dtype=float32), 'eval/episode_reward_alive_std': Array(45.796577, dtype=float32), 'eval/episode_reward_linvel_std': Array(86.236084, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.9124742, dtype=float32), 'eval/episode_x_position_std': Array(87.931816, dtype=float32), 'eval/episode_x_velocity_std': Array(17.247217, dtype=float32), 'eval/episode_y_position_std': Array(100.60936, dtype=float32), 'eval/episode_y_velocity_std': Array(19.544744, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49026560783386, 'eval/sps': 937.7958159138745, 'num_steps': 573440}
{'eval/walltime': 1261.4211356639862, 'training/sps': 2969.271339326566, 'training/walltime': 248.57657074928284, 'training/entropy_loss': Array(-0.00371369, dtype=float32), 'training/policy_loss': Array(-0.02484784, dtype=float32), 'training/total_loss': Array(-0.0226924, dtype=float32), 'training/v_loss': Array(0.00586914, dtype=float32), 'eval/episode_distance_from_origin': Array(3131.9487, dtype=float32), 'eval/episode_distance_reward': Array(0.54248065, dtype=float32), 'eval/episode_forward_reward': Array(90.413445, dtype=float32), 'eval/episode_reward': Array(-118.0251, dtype=float32), 'eval/episode_reward_alive': Array(10.9765625, dtype=float32), 'eval/episode_reward_linvel': Array(90.413445, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.95758, dtype=float32), 'eval/episode_x_position': Array(3108.8127, dtype=float32), 'eval/episode_x_velocity': Array(18.082691, dtype=float32), 'eval/episode_y_position': Array(-90.112045, dtype=float32), 'eval/episode_y_velocity': Array(-16.844097, dtype=float32), 'eval/episode_distance_from_origin_std': Array(69.73642, dtype=float32), 'eval/episode_distance_reward_std': Array(0.37875858, dtype=float32), 'eval/episode_forward_reward_std': Array(63.126434, dtype=float32), 'eval/episode_reward_std': Array(79.51066, dtype=float32), 'eval/episode_reward_alive_std': Array(37.486187, dtype=float32), 'eval/episode_reward_linvel_std': Array(63.126434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.2246857, dtype=float32), 'eval/episode_x_position_std': Array(68.30593, dtype=float32), 'eval/episode_x_velocity_std': Array(12.625289, dtype=float32), 'eval/episode_y_position_std': Array(109.91432, dtype=float32), 'eval/episode_y_velocity_std': Array(20.292559, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41932845115662, 'eval/sps': 938.2834635916636, 'num_steps': 655360}
{'eval/walltime': 1398.3567008972168, 'training/sps': 2961.339927231498, 'training/walltime': 276.23972392082214, 'training/entropy_loss': Array(-0.00327095, dtype=float32), 'training/policy_loss': Array(-0.03671196, dtype=float32), 'training/total_loss': Array(-0.03880279, dtype=float32), 'training/v_loss': Array(0.00118013, dtype=float32), 'eval/episode_distance_from_origin': Array(3102.5981, dtype=float32), 'eval/episode_distance_reward': Array(0.38340932, dtype=float32), 'eval/episode_forward_reward': Array(63.901558, dtype=float32), 'eval/episode_reward': Array(-153.30309, dtype=float32), 'eval/episode_reward_alive': Array(4.4882812, dtype=float32), 'eval/episode_reward_linvel': Array(63.901558, dtype=float32), 'eval/episode_reward_quadctrl': Array(-222.07632, dtype=float32), 'eval/episode_x_position': Array(3080.5244, dtype=float32), 'eval/episode_x_velocity': Array(12.78031, dtype=float32), 'eval/episode_y_position': Array(-95.028275, dtype=float32), 'eval/episode_y_velocity': Array(-18.311714, dtype=float32), 'eval/episode_distance_from_origin_std': Array(65.193085, dtype=float32), 'eval/episode_distance_reward_std': Array(0.34891272, dtype=float32), 'eval/episode_forward_reward_std': Array(58.152115, dtype=float32), 'eval/episode_reward_std': Array(69.720184, dtype=float32), 'eval/episode_reward_alive_std': Array(10.326782, dtype=float32), 'eval/episode_reward_linvel_std': Array(58.152115, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.909622, dtype=float32), 'eval/episode_x_position_std': Array(64.33227, dtype=float32), 'eval/episode_x_velocity_std': Array(11.6304245, dtype=float32), 'eval/episode_y_position_std': Array(80.57972, dtype=float32), 'eval/episode_y_velocity_std': Array(14.698525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.9355652332306, 'eval/sps': 934.7462055017526, 'num_steps': 737280}
{'eval/walltime': 1534.8246235847473, 'training/sps': 2964.710305475342, 'training/walltime': 303.87142872810364, 'training/entropy_loss': Array(-0.00289711, dtype=float32), 'training/policy_loss': Array(-0.03883576, dtype=float32), 'training/total_loss': Array(-0.04115118, dtype=float32), 'training/v_loss': Array(0.00058169, dtype=float32), 'eval/episode_distance_from_origin': Array(3103.1968, dtype=float32), 'eval/episode_distance_reward': Array(0.3928075, dtype=float32), 'eval/episode_forward_reward': Array(65.46791, dtype=float32), 'eval/episode_reward': Array(-152.12292, dtype=float32), 'eval/episode_reward_alive': Array(3.0820312, dtype=float32), 'eval/episode_reward_linvel': Array(65.46791, dtype=float32), 'eval/episode_reward_quadctrl': Array(-221.06567, dtype=float32), 'eval/episode_x_position': Array(3081.5684, dtype=float32), 'eval/episode_x_velocity': Array(13.093582, dtype=float32), 'eval/episode_y_position': Array(-69.93165, dtype=float32), 'eval/episode_y_velocity': Array(-13.207336, dtype=float32), 'eval/episode_distance_from_origin_std': Array(72.61255, dtype=float32), 'eval/episode_distance_reward_std': Array(0.37842992, dtype=float32), 'eval/episode_forward_reward_std': Array(63.071636, dtype=float32), 'eval/episode_reward_std': Array(66.20194, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9072475, dtype=float32), 'eval/episode_reward_linvel_std': Array(63.071636, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.0865047, dtype=float32), 'eval/episode_x_position_std': Array(71.050354, dtype=float32), 'eval/episode_x_velocity_std': Array(12.614327, dtype=float32), 'eval/episode_y_position_std': Array(100.79157, dtype=float32), 'eval/episode_y_velocity_std': Array(18.439564, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46792268753052, 'eval/sps': 937.9493545386526, 'num_steps': 819200}
{'eval/walltime': 1671.7787861824036, 'training/sps': 2966.144907330401, 'training/walltime': 331.4897692203522, 'training/entropy_loss': Array(-0.00256358, dtype=float32), 'training/policy_loss': Array(-0.04356208, dtype=float32), 'training/total_loss': Array(-0.04579629, dtype=float32), 'training/v_loss': Array(0.00032937, dtype=float32), 'eval/episode_distance_from_origin': Array(3100.3142, dtype=float32), 'eval/episode_distance_reward': Array(0.36782032, dtype=float32), 'eval/episode_forward_reward': Array(61.3034, dtype=float32), 'eval/episode_reward': Array(-156.13272, dtype=float32), 'eval/episode_reward_alive': Array(1.9257812, dtype=float32), 'eval/episode_reward_linvel': Array(61.3034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.72975, dtype=float32), 'eval/episode_x_position': Array(3078.8164, dtype=float32), 'eval/episode_x_velocity': Array(12.260678, dtype=float32), 'eval/episode_y_position': Array(-81.2887, dtype=float32), 'eval/episode_y_velocity': Array(-15.25477, dtype=float32), 'eval/episode_distance_from_origin_std': Array(67.45002, dtype=float32), 'eval/episode_distance_reward_std': Array(0.35989, dtype=float32), 'eval/episode_forward_reward_std': Array(59.98167, dtype=float32), 'eval/episode_reward_std': Array(60.9571, dtype=float32), 'eval/episode_reward_alive_std': Array(2.589107, dtype=float32), 'eval/episode_reward_linvel_std': Array(59.98167, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.8114858, dtype=float32), 'eval/episode_x_position_std': Array(66.63967, dtype=float32), 'eval/episode_x_velocity_std': Array(11.996334, dtype=float32), 'eval/episode_y_position_std': Array(89.54706, dtype=float32), 'eval/episode_y_velocity_std': Array(16.051592, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.95416259765625, 'eval/sps': 934.6192738663827, 'num_steps': 901120}
{'eval/walltime': 1808.3679089546204, 'training/sps': 2936.8611305495397, 'training/walltime': 359.38349533081055, 'training/entropy_loss': Array(-0.00232065, dtype=float32), 'training/policy_loss': Array(-0.05004935, dtype=float32), 'training/total_loss': Array(-0.05205724, dtype=float32), 'training/v_loss': Array(0.00031276, dtype=float32), 'eval/episode_distance_from_origin': Array(3113.0063, dtype=float32), 'eval/episode_distance_reward': Array(0.41827813, dtype=float32), 'eval/episode_forward_reward': Array(69.713, dtype=float32), 'eval/episode_reward': Array(-142.57097, dtype=float32), 'eval/episode_reward_alive': Array(1.9101562, dtype=float32), 'eval/episode_reward_linvel': Array(69.713, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.6124, dtype=float32), 'eval/episode_x_position': Array(3089.7812, dtype=float32), 'eval/episode_x_velocity': Array(13.942603, dtype=float32), 'eval/episode_y_position': Array(-78.08078, dtype=float32), 'eval/episode_y_velocity': Array(-14.715149, dtype=float32), 'eval/episode_distance_from_origin_std': Array(75.75766, dtype=float32), 'eval/episode_distance_reward_std': Array(0.40641963, dtype=float32), 'eval/episode_forward_reward_std': Array(67.736595, dtype=float32), 'eval/episode_reward_std': Array(68.82328, dtype=float32), 'eval/episode_reward_alive_std': Array(3.3856509, dtype=float32), 'eval/episode_reward_linvel_std': Array(67.736595, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.703803, dtype=float32), 'eval/episode_x_position_std': Array(74.67195, dtype=float32), 'eval/episode_x_velocity_std': Array(13.54732, dtype=float32), 'eval/episode_y_position_std': Array(107.7539, dtype=float32), 'eval/episode_y_velocity_std': Array(19.354204, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5891227722168, 'eval/sps': 937.1170807902437, 'num_steps': 983040}
{'eval/walltime': 1944.7420234680176, 'training/sps': 2946.2756072829607, 'training/walltime': 387.18809032440186, 'training/entropy_loss': Array(-0.00200319, dtype=float32), 'training/policy_loss': Array(0.01764506, dtype=float32), 'training/total_loss': Array(0.04204268, dtype=float32), 'training/v_loss': Array(0.02640081, dtype=float32), 'eval/episode_distance_from_origin': Array(3173.622, dtype=float32), 'eval/episode_distance_reward': Array(0.73675495, dtype=float32), 'eval/episode_forward_reward': Array(122.792496, dtype=float32), 'eval/episode_reward': Array(-85.87448, dtype=float32), 'eval/episode_reward_alive': Array(5.2109375, dtype=float32), 'eval/episode_reward_linvel': Array(122.792496, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.61465, dtype=float32), 'eval/episode_x_position': Array(3149.0625, dtype=float32), 'eval/episode_x_velocity': Array(24.558493, dtype=float32), 'eval/episode_y_position': Array(-51.36543, dtype=float32), 'eval/episode_y_velocity': Array(-9.509768, dtype=float32), 'eval/episode_distance_from_origin_std': Array(71.25185, dtype=float32), 'eval/episode_distance_reward_std': Array(0.39255378, dtype=float32), 'eval/episode_forward_reward_std': Array(65.42565, dtype=float32), 'eval/episode_reward_std': Array(68.764244, dtype=float32), 'eval/episode_reward_alive_std': Array(9.771132, dtype=float32), 'eval/episode_reward_linvel_std': Array(65.42565, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.4053097, dtype=float32), 'eval/episode_x_position_std': Array(70.77559, dtype=float32), 'eval/episode_x_velocity_std': Array(13.085119, dtype=float32), 'eval/episode_y_position_std': Array(111.35181, dtype=float32), 'eval/episode_y_velocity_std': Array(20.461525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37411451339722, 'eval/sps': 938.5945452824586, 'num_steps': 1064960}
{'eval/walltime': 2081.322564601898, 'training/sps': 2972.8193702494495, 'training/walltime': 414.74442315101624, 'training/entropy_loss': Array(-0.00286631, dtype=float32), 'training/policy_loss': Array(-0.02300145, dtype=float32), 'training/total_loss': Array(-0.02017224, dtype=float32), 'training/v_loss': Array(0.00569552, dtype=float32), 'eval/episode_distance_from_origin': Array(3172.5242, dtype=float32), 'eval/episode_distance_reward': Array(0.7655609, dtype=float32), 'eval/episode_forward_reward': Array(127.59349, dtype=float32), 'eval/episode_reward': Array(-92.465775, dtype=float32), 'eval/episode_reward_alive': Array(3.4023438, dtype=float32), 'eval/episode_reward_linvel': Array(127.59349, dtype=float32), 'eval/episode_reward_quadctrl': Array(-224.22716, dtype=float32), 'eval/episode_x_position': Array(3145.7104, dtype=float32), 'eval/episode_x_velocity': Array(25.518696, dtype=float32), 'eval/episode_y_position': Array(-34.621532, dtype=float32), 'eval/episode_y_velocity': Array(-4.5216107, dtype=float32), 'eval/episode_distance_from_origin_std': Array(80.57301, dtype=float32), 'eval/episode_distance_reward_std': Array(0.4636621, dtype=float32), 'eval/episode_forward_reward_std': Array(77.27701, dtype=float32), 'eval/episode_reward_std': Array(77.8703, dtype=float32), 'eval/episode_reward_alive_std': Array(4.354891, dtype=float32), 'eval/episode_reward_linvel_std': Array(77.27701, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.9048195, dtype=float32), 'eval/episode_x_position_std': Array(80.53644, dtype=float32), 'eval/episode_x_velocity_std': Array(15.4553995, dtype=float32), 'eval/episode_y_position_std': Array(105.220955, dtype=float32), 'eval/episode_y_velocity_std': Array(20.512148, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58054113388062, 'eval/sps': 937.1759617977374, 'num_steps': 1146880}
{'eval/walltime': 2217.663383245468, 'training/sps': 2976.246545132671, 'training/walltime': 442.2690246105194, 'training/entropy_loss': Array(-0.00253608, dtype=float32), 'training/policy_loss': Array(-0.04742029, dtype=float32), 'training/total_loss': Array(-0.04797032, dtype=float32), 'training/v_loss': Array(0.00198605, dtype=float32), 'eval/episode_distance_from_origin': Array(3243.44, dtype=float32), 'eval/episode_distance_reward': Array(1.3533592, dtype=float32), 'eval/episode_forward_reward': Array(225.55988, dtype=float32), 'eval/episode_reward': Array(-6.275696, dtype=float32), 'eval/episode_reward_alive': Array(3.1445312, dtype=float32), 'eval/episode_reward_linvel': Array(225.55988, dtype=float32), 'eval/episode_reward_quadctrl': Array(-236.33348, dtype=float32), 'eval/episode_x_position': Array(3208.4136, dtype=float32), 'eval/episode_x_velocity': Array(45.111977, dtype=float32), 'eval/episode_y_position': Array(140.02875, dtype=float32), 'eval/episode_y_velocity': Array(53.605408, dtype=float32), 'eval/episode_distance_from_origin_std': Array(74.93128, dtype=float32), 'eval/episode_distance_reward_std': Array(0.5090833, dtype=float32), 'eval/episode_forward_reward_std': Array(84.84721, dtype=float32), 'eval/episode_reward_std': Array(86.96591, dtype=float32), 'eval/episode_reward_alive_std': Array(4.924093, dtype=float32), 'eval/episode_reward_linvel_std': Array(84.84721, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.4105887, dtype=float32), 'eval/episode_x_position_std': Array(76.163506, dtype=float32), 'eval/episode_x_velocity_std': Array(16.969439, dtype=float32), 'eval/episode_y_position_std': Array(131.09068, dtype=float32), 'eval/episode_y_velocity_std': Array(35.00993, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34081864356995, 'eval/sps': 938.8237599968136, 'num_steps': 1228800}
{'eval/walltime': 2354.235156059265, 'training/sps': 2954.340599355493, 'training/walltime': 469.99771642684937, 'training/entropy_loss': Array(-0.00095147, dtype=float32), 'training/policy_loss': Array(-0.01090474, dtype=float32), 'training/total_loss': Array(-0.00983507, dtype=float32), 'training/v_loss': Array(0.00202115, dtype=float32), 'eval/episode_distance_from_origin': Array(3267.0728, dtype=float32), 'eval/episode_distance_reward': Array(1.6299621, dtype=float32), 'eval/episode_forward_reward': Array(271.66034, dtype=float32), 'eval/episode_reward': Array(34.455765, dtype=float32), 'eval/episode_reward_alive': Array(4.3554688, dtype=float32), 'eval/episode_reward_linvel': Array(271.66034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-243.19003, dtype=float32), 'eval/episode_x_position': Array(3228.9521, dtype=float32), 'eval/episode_x_velocity': Array(54.33207, dtype=float32), 'eval/episode_y_position': Array(174.93839, dtype=float32), 'eval/episode_y_velocity': Array(61.052513, dtype=float32), 'eval/episode_distance_from_origin_std': Array(86.892456, dtype=float32), 'eval/episode_distance_reward_std': Array(0.6626792, dtype=float32), 'eval/episode_forward_reward_std': Array(110.44653, dtype=float32), 'eval/episode_reward_std': Array(110.92614, dtype=float32), 'eval/episode_reward_alive_std': Array(6.2693925, dtype=float32), 'eval/episode_reward_linvel_std': Array(110.44653, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.387643, dtype=float32), 'eval/episode_x_position_std': Array(89.63255, dtype=float32), 'eval/episode_x_velocity_std': Array(22.089306, dtype=float32), 'eval/episode_y_position_std': Array(144.99147, dtype=float32), 'eval/episode_y_velocity_std': Array(35.563328, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.571772813797, 'eval/sps': 937.2361313235363, 'num_steps': 1310720}
{'eval/walltime': 2490.5418128967285, 'training/sps': 2956.715580287861, 'training/walltime': 497.70413517951965, 'training/entropy_loss': Array(-0.00015319, dtype=float32), 'training/policy_loss': Array(0.04311073, dtype=float32), 'training/total_loss': Array(0.0459262, dtype=float32), 'training/v_loss': Array(0.00296866, dtype=float32), 'eval/episode_distance_from_origin': Array(3272.3555, dtype=float32), 'eval/episode_distance_reward': Array(1.6461766, dtype=float32), 'eval/episode_forward_reward': Array(274.36273, dtype=float32), 'eval/episode_reward': Array(30.494247, dtype=float32), 'eval/episode_reward_alive': Array(4.2890625, dtype=float32), 'eval/episode_reward_linvel': Array(274.36273, dtype=float32), 'eval/episode_reward_quadctrl': Array(-249.80374, dtype=float32), 'eval/episode_x_position': Array(3241.297, dtype=float32), 'eval/episode_x_velocity': Array(54.872543, dtype=float32), 'eval/episode_y_position': Array(57.9337, dtype=float32), 'eval/episode_y_velocity': Array(19.786308, dtype=float32), 'eval/episode_distance_from_origin_std': Array(94.18461, dtype=float32), 'eval/episode_distance_reward_std': Array(0.6529215, dtype=float32), 'eval/episode_forward_reward_std': Array(108.82023, dtype=float32), 'eval/episode_reward_std': Array(110.54906, dtype=float32), 'eval/episode_reward_alive_std': Array(6.2059727, dtype=float32), 'eval/episode_reward_linvel_std': Array(108.82023, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.602436, dtype=float32), 'eval/episode_x_position_std': Array(94.98286, dtype=float32), 'eval/episode_x_velocity_std': Array(21.764051, dtype=float32), 'eval/episode_y_position_std': Array(139.30269, dtype=float32), 'eval/episode_y_velocity_std': Array(28.571325, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30665683746338, 'eval/sps': 939.0590523589136, 'num_steps': 1392640}
{'eval/walltime': 2626.944475412369, 'training/sps': 2954.940060399056, 'training/walltime': 525.4272017478943, 'training/entropy_loss': Array(0.00078288, dtype=float32), 'training/policy_loss': Array(0.06658784, dtype=float32), 'training/total_loss': Array(0.0772412, dtype=float32), 'training/v_loss': Array(0.00987048, dtype=float32), 'eval/episode_distance_from_origin': Array(3378.371, dtype=float32), 'eval/episode_distance_reward': Array(2.6799831, dtype=float32), 'eval/episode_forward_reward': Array(446.66367, dtype=float32), 'eval/episode_reward': Array(186.57591, dtype=float32), 'eval/episode_reward_alive': Array(6.0820312, dtype=float32), 'eval/episode_reward_linvel': Array(446.66367, dtype=float32), 'eval/episode_reward_quadctrl': Array(-268.8498, dtype=float32), 'eval/episode_x_position': Array(3347.4895, dtype=float32), 'eval/episode_x_velocity': Array(89.33273, dtype=float32), 'eval/episode_y_position': Array(80.56389, dtype=float32), 'eval/episode_y_velocity': Array(23.39016, dtype=float32), 'eval/episode_distance_from_origin_std': Array(140.5249, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3843874, dtype=float32), 'eval/episode_forward_reward_std': Array(230.7309, dtype=float32), 'eval/episode_reward_std': Array(225.97969, dtype=float32), 'eval/episode_reward_alive_std': Array(7.6747293, dtype=float32), 'eval/episode_reward_linvel_std': Array(230.7309, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.645007, dtype=float32), 'eval/episode_x_position_std': Array(140.87726, dtype=float32), 'eval/episode_x_velocity_std': Array(46.146187, dtype=float32), 'eval/episode_y_position_std': Array(144.47368, dtype=float32), 'eval/episode_y_velocity_std': Array(32.60014, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40266251564026, 'eval/sps': 938.3981048414155, 'num_steps': 1474560}
{'eval/walltime': 2763.222722530365, 'training/sps': 2953.155655891798, 'training/walltime': 553.1670196056366, 'training/entropy_loss': Array(7.449669e-05, dtype=float32), 'training/policy_loss': Array(0.02433373, dtype=float32), 'training/total_loss': Array(0.04744988, dtype=float32), 'training/v_loss': Array(0.02304165, dtype=float32), 'eval/episode_distance_from_origin': Array(3488.731, dtype=float32), 'eval/episode_distance_reward': Array(3.9448755, dtype=float32), 'eval/episode_forward_reward': Array(657.47876, dtype=float32), 'eval/episode_reward': Array(387.43503, dtype=float32), 'eval/episode_reward_alive': Array(9.238281, dtype=float32), 'eval/episode_reward_linvel': Array(657.47876, dtype=float32), 'eval/episode_reward_quadctrl': Array(-283.22693, dtype=float32), 'eval/episode_x_position': Array(3453.8523, dtype=float32), 'eval/episode_x_velocity': Array(131.49576, dtype=float32), 'eval/episode_y_position': Array(119.23009, dtype=float32), 'eval/episode_y_velocity': Array(53.53821, dtype=float32), 'eval/episode_distance_from_origin_std': Array(112.37356, dtype=float32), 'eval/episode_distance_reward_std': Array(0.9884624, dtype=float32), 'eval/episode_forward_reward_std': Array(164.74321, dtype=float32), 'eval/episode_reward_std': Array(162.86523, dtype=float32), 'eval/episode_reward_alive_std': Array(9.753398, dtype=float32), 'eval/episode_reward_linvel_std': Array(164.74321, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.152291, dtype=float32), 'eval/episode_x_position_std': Array(115.31617, dtype=float32), 'eval/episode_x_velocity_std': Array(32.94863, dtype=float32), 'eval/episode_y_position_std': Array(172.94403, dtype=float32), 'eval/episode_y_velocity_std': Array(43.45986, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27824711799622, 'eval/sps': 939.2548165751757, 'num_steps': 1556480}
{'eval/walltime': 2899.5984477996826, 'training/sps': 2943.815110279358, 'training/walltime': 580.9948542118073, 'training/entropy_loss': Array(0.00167884, dtype=float32), 'training/policy_loss': Array(0.0615266, dtype=float32), 'training/total_loss': Array(0.09551245, dtype=float32), 'training/v_loss': Array(0.03230701, dtype=float32), 'eval/episode_distance_from_origin': Array(3373.4512, dtype=float32), 'eval/episode_distance_reward': Array(2.333587, dtype=float32), 'eval/episode_forward_reward': Array(388.93112, dtype=float32), 'eval/episode_reward': Array(147.1929, dtype=float32), 'eval/episode_reward_alive': Array(13.3828125, dtype=float32), 'eval/episode_reward_linvel': Array(388.93112, dtype=float32), 'eval/episode_reward_quadctrl': Array(-257.45465, dtype=float32), 'eval/episode_x_position': Array(3343.1611, dtype=float32), 'eval/episode_x_velocity': Array(77.786224, dtype=float32), 'eval/episode_y_position': Array(26.93203, dtype=float32), 'eval/episode_y_velocity': Array(13.777077, dtype=float32), 'eval/episode_distance_from_origin_std': Array(93.491516, dtype=float32), 'eval/episode_distance_reward_std': Array(0.7529216, dtype=float32), 'eval/episode_forward_reward_std': Array(125.48679, dtype=float32), 'eval/episode_reward_std': Array(122.981255, dtype=float32), 'eval/episode_reward_alive_std': Array(10.903605, dtype=float32), 'eval/episode_reward_linvel_std': Array(125.48679, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.971784, dtype=float32), 'eval/episode_x_position_std': Array(94.5852, dtype=float32), 'eval/episode_x_velocity_std': Array(25.097359, dtype=float32), 'eval/episode_y_position_std': Array(139.91003, dtype=float32), 'eval/episode_y_velocity_std': Array(32.284157, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37572526931763, 'eval/sps': 938.5834593892932, 'num_steps': 1638400}
{'eval/walltime': 3035.8811469078064, 'training/sps': 2948.656485674677, 'training/walltime': 608.7769985198975, 'training/entropy_loss': Array(0.00100254, dtype=float32), 'training/policy_loss': Array(0.01495139, dtype=float32), 'training/total_loss': Array(0.03813628, dtype=float32), 'training/v_loss': Array(0.02218235, dtype=float32), 'eval/episode_distance_from_origin': Array(3414.3137, dtype=float32), 'eval/episode_distance_reward': Array(2.81945, dtype=float32), 'eval/episode_forward_reward': Array(469.9083, dtype=float32), 'eval/episode_reward': Array(226.77022, dtype=float32), 'eval/episode_reward_alive': Array(12.386719, dtype=float32), 'eval/episode_reward_linvel': Array(469.9083, dtype=float32), 'eval/episode_reward_quadctrl': Array(-258.3443, dtype=float32), 'eval/episode_x_position': Array(3384.46, dtype=float32), 'eval/episode_x_velocity': Array(93.98164, dtype=float32), 'eval/episode_y_position': Array(-47.69756, dtype=float32), 'eval/episode_y_velocity': Array(2.538724, dtype=float32), 'eval/episode_distance_from_origin_std': Array(105.34322, dtype=float32), 'eval/episode_distance_reward_std': Array(0.87296385, dtype=float32), 'eval/episode_forward_reward_std': Array(145.49385, dtype=float32), 'eval/episode_reward_std': Array(146.39635, dtype=float32), 'eval/episode_reward_alive_std': Array(11.39922, dtype=float32), 'eval/episode_reward_linvel_std': Array(145.49385, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.670486, dtype=float32), 'eval/episode_x_position_std': Array(105.45119, dtype=float32), 'eval/episode_x_velocity_std': Array(29.098763, dtype=float32), 'eval/episode_y_position_std': Array(121.47781, dtype=float32), 'eval/episode_y_velocity_std': Array(30.357792, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28269910812378, 'eval/sps': 939.2241336403789, 'num_steps': 1720320}
{'eval/walltime': 3172.286086320877, 'training/sps': 2957.4956665601726, 'training/walltime': 636.4761092662811, 'training/entropy_loss': Array(0.00129855, dtype=float32), 'training/policy_loss': Array(0.01172955, dtype=float32), 'training/total_loss': Array(0.02977399, dtype=float32), 'training/v_loss': Array(0.0167459, dtype=float32), 'eval/episode_distance_from_origin': Array(3490.1077, dtype=float32), 'eval/episode_distance_reward': Array(4.0726595, dtype=float32), 'eval/episode_forward_reward': Array(678.776, dtype=float32), 'eval/episode_reward': Array(444.1859, dtype=float32), 'eval/episode_reward_alive': Array(20.132812, dtype=float32), 'eval/episode_reward_linvel': Array(678.776, dtype=float32), 'eval/episode_reward_quadctrl': Array(-258.7956, dtype=float32), 'eval/episode_x_position': Array(3459.3828, dtype=float32), 'eval/episode_x_velocity': Array(135.7552, dtype=float32), 'eval/episode_y_position': Array(-69.48892, dtype=float32), 'eval/episode_y_velocity': Array(3.8605258, dtype=float32), 'eval/episode_distance_from_origin_std': Array(99.25612, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1155397, dtype=float32), 'eval/episode_forward_reward_std': Array(185.92273, dtype=float32), 'eval/episode_reward_std': Array(191.88634, dtype=float32), 'eval/episode_reward_alive_std': Array(14.406417, dtype=float32), 'eval/episode_reward_linvel_std': Array(185.92273, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.2863364, dtype=float32), 'eval/episode_x_position_std': Array(99.033325, dtype=float32), 'eval/episode_x_velocity_std': Array(37.18455, dtype=float32), 'eval/episode_y_position_std': Array(134.23262, dtype=float32), 'eval/episode_y_velocity_std': Array(33.76009, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40493941307068, 'eval/sps': 938.3824409201321, 'num_steps': 1802240}
{'eval/walltime': 3308.665069580078, 'training/sps': 2944.905436617953, 'training/walltime': 664.2936408519745, 'training/entropy_loss': Array(0.00089123, dtype=float32), 'training/policy_loss': Array(0.0039272, dtype=float32), 'training/total_loss': Array(0.01869382, dtype=float32), 'training/v_loss': Array(0.01387538, dtype=float32), 'eval/episode_distance_from_origin': Array(3598.5432, dtype=float32), 'eval/episode_distance_reward': Array(5.3531837, dtype=float32), 'eval/episode_forward_reward': Array(892.19617, dtype=float32), 'eval/episode_reward': Array(674.5024, dtype=float32), 'eval/episode_reward_alive': Array(43.210938, dtype=float32), 'eval/episode_reward_linvel': Array(892.19617, dtype=float32), 'eval/episode_reward_quadctrl': Array(-266.2578, dtype=float32), 'eval/episode_x_position': Array(3566.8838, dtype=float32), 'eval/episode_x_velocity': Array(178.43922, dtype=float32), 'eval/episode_y_position': Array(-118.17498, dtype=float32), 'eval/episode_y_velocity': Array(-11.612244, dtype=float32), 'eval/episode_distance_from_origin_std': Array(126.84127, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1641841, dtype=float32), 'eval/episode_forward_reward_std': Array(194.03023, dtype=float32), 'eval/episode_reward_std': Array(207.69878, dtype=float32), 'eval/episode_reward_alive_std': Array(21.509045, dtype=float32), 'eval/episode_reward_linvel_std': Array(194.03023, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.463362, dtype=float32), 'eval/episode_x_position_std': Array(126.77333, dtype=float32), 'eval/episode_x_velocity_std': Array(38.80603, dtype=float32), 'eval/episode_y_position_std': Array(127.59077, dtype=float32), 'eval/episode_y_velocity_std': Array(32.766106, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37898325920105, 'eval/sps': 938.5610373463776, 'num_steps': 1884160}
{'eval/walltime': 3445.05263876915, 'training/sps': 2959.093490824906, 'training/walltime': 691.9777948856354, 'training/entropy_loss': Array(0.00121391, dtype=float32), 'training/policy_loss': Array(-0.00539417, dtype=float32), 'training/total_loss': Array(0.01537938, dtype=float32), 'training/v_loss': Array(0.01955965, dtype=float32), 'eval/episode_distance_from_origin': Array(3769.764, dtype=float32), 'eval/episode_distance_reward': Array(7.1829715, dtype=float32), 'eval/episode_forward_reward': Array(1197.16, dtype=float32), 'eval/episode_reward': Array(1010.9277, dtype=float32), 'eval/episode_reward_alive': Array(85.47656, dtype=float32), 'eval/episode_reward_linvel': Array(1197.16, dtype=float32), 'eval/episode_reward_quadctrl': Array(-278.89178, dtype=float32), 'eval/episode_x_position': Array(3735.7397, dtype=float32), 'eval/episode_x_velocity': Array(239.43198, dtype=float32), 'eval/episode_y_position': Array(-189.36627, dtype=float32), 'eval/episode_y_velocity': Array(-33.99415, dtype=float32), 'eval/episode_distance_from_origin_std': Array(115.847534, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3303872, dtype=float32), 'eval/episode_forward_reward_std': Array(221.73044, dtype=float32), 'eval/episode_reward_std': Array(244.81966, dtype=float32), 'eval/episode_reward_alive_std': Array(29.624395, dtype=float32), 'eval/episode_reward_linvel_std': Array(221.73044, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.138932, dtype=float32), 'eval/episode_x_position_std': Array(115.79144, dtype=float32), 'eval/episode_x_velocity_std': Array(44.346104, dtype=float32), 'eval/episode_y_position_std': Array(122.17449, dtype=float32), 'eval/episode_y_velocity_std': Array(35.684116, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38756918907166, 'eval/sps': 938.5019526417095, 'num_steps': 1966080}
{'eval/walltime': 3581.430413246155, 'training/sps': 2947.7219561883853, 'training/walltime': 719.7687470912933, 'training/entropy_loss': Array(0.00324953, dtype=float32), 'training/policy_loss': Array(0.10500934, dtype=float32), 'training/total_loss': Array(0.13988987, dtype=float32), 'training/v_loss': Array(0.03163099, dtype=float32), 'eval/episode_distance_from_origin': Array(3648.3787, dtype=float32), 'eval/episode_distance_reward': Array(4.9523044, dtype=float32), 'eval/episode_forward_reward': Array(825.3838, dtype=float32), 'eval/episode_reward': Array(629.13873, dtype=float32), 'eval/episode_reward_alive': Array(169.67578, dtype=float32), 'eval/episode_reward_linvel': Array(825.3838, dtype=float32), 'eval/episode_reward_quadctrl': Array(-370.87317, dtype=float32), 'eval/episode_x_position': Array(3612.4917, dtype=float32), 'eval/episode_x_velocity': Array(165.07674, dtype=float32), 'eval/episode_y_position': Array(116.10293, dtype=float32), 'eval/episode_y_velocity': Array(50.14753, dtype=float32), 'eval/episode_distance_from_origin_std': Array(115.58069, dtype=float32), 'eval/episode_distance_reward_std': Array(1.117987, dtype=float32), 'eval/episode_forward_reward_std': Array(186.3307, dtype=float32), 'eval/episode_reward_std': Array(186.54741, dtype=float32), 'eval/episode_reward_alive_std': Array(18.838497, dtype=float32), 'eval/episode_reward_linvel_std': Array(186.3307, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.507227, dtype=float32), 'eval/episode_x_position_std': Array(116.17871, dtype=float32), 'eval/episode_x_velocity_std': Array(37.266144, dtype=float32), 'eval/episode_y_position_std': Array(168.22667, dtype=float32), 'eval/episode_y_velocity_std': Array(38.458244, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.377774477005, 'eval/sps': 938.5693562669363, 'num_steps': 2048000}
{'eval/walltime': 3717.82377409935, 'training/sps': 2958.248580903747, 'training/walltime': 747.4608080387115, 'training/entropy_loss': Array(0.00192763, dtype=float32), 'training/policy_loss': Array(0.03178094, dtype=float32), 'training/total_loss': Array(0.078238, dtype=float32), 'training/v_loss': Array(0.04452943, dtype=float32), 'eval/episode_distance_from_origin': Array(3721.1934, dtype=float32), 'eval/episode_distance_reward': Array(5.564947, dtype=float32), 'eval/episode_forward_reward': Array(927.4904, dtype=float32), 'eval/episode_reward': Array(736.47107, dtype=float32), 'eval/episode_reward_alive': Array(163.07812, dtype=float32), 'eval/episode_reward_linvel': Array(927.4904, dtype=float32), 'eval/episode_reward_quadctrl': Array(-359.6625, dtype=float32), 'eval/episode_x_position': Array(3687.6853, dtype=float32), 'eval/episode_x_velocity': Array(185.49808, dtype=float32), 'eval/episode_y_position': Array(88.19617, dtype=float32), 'eval/episode_y_velocity': Array(47.1591, dtype=float32), 'eval/episode_distance_from_origin_std': Array(132.03787, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2377365, dtype=float32), 'eval/episode_forward_reward_std': Array(206.28877, dtype=float32), 'eval/episode_reward_std': Array(206.02367, dtype=float32), 'eval/episode_reward_alive_std': Array(24.153435, dtype=float32), 'eval/episode_reward_linvel_std': Array(206.28877, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.499615, dtype=float32), 'eval/episode_x_position_std': Array(131.24771, dtype=float32), 'eval/episode_x_velocity_std': Array(41.25772, dtype=float32), 'eval/episode_y_position_std': Array(153.92604, dtype=float32), 'eval/episode_y_velocity_std': Array(34.843067, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3933608531952, 'eval/sps': 938.4621010825501, 'num_steps': 2129920}
{'eval/walltime': 3854.0756125450134, 'training/sps': 2953.334329360656, 'training/walltime': 775.1989476680756, 'training/entropy_loss': Array(0.00497929, dtype=float32), 'training/policy_loss': Array(0.08630387, dtype=float32), 'training/total_loss': Array(0.12786102, dtype=float32), 'training/v_loss': Array(0.03657786, dtype=float32), 'eval/episode_distance_from_origin': Array(3797.5806, dtype=float32), 'eval/episode_distance_reward': Array(6.2727017, dtype=float32), 'eval/episode_forward_reward': Array(1045.4495, dtype=float32), 'eval/episode_reward': Array(847.8585, dtype=float32), 'eval/episode_reward_alive': Array(132.32812, dtype=float32), 'eval/episode_reward_linvel': Array(1045.4495, dtype=float32), 'eval/episode_reward_quadctrl': Array(-336.19165, dtype=float32), 'eval/episode_x_position': Array(3766.134, dtype=float32), 'eval/episode_x_velocity': Array(209.08989, dtype=float32), 'eval/episode_y_position': Array(27.834688, dtype=float32), 'eval/episode_y_velocity': Array(36.496475, dtype=float32), 'eval/episode_distance_from_origin_std': Array(145.90631, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3295352, dtype=float32), 'eval/episode_forward_reward_std': Array(221.58846, dtype=float32), 'eval/episode_reward_std': Array(232.8625, dtype=float32), 'eval/episode_reward_alive_std': Array(28.376337, dtype=float32), 'eval/episode_reward_linvel_std': Array(221.58846, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.019274, dtype=float32), 'eval/episode_x_position_std': Array(145.65071, dtype=float32), 'eval/episode_x_velocity_std': Array(44.317696, dtype=float32), 'eval/episode_y_position_std': Array(159.36852, dtype=float32), 'eval/episode_y_velocity_std': Array(40.444313, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25183844566345, 'eval/sps': 939.4368652944507, 'num_steps': 2211840}
{'eval/walltime': 3990.5180315971375, 'training/sps': 2951.3458486925883, 'training/walltime': 802.955775976181, 'training/entropy_loss': Array(0.00503305, dtype=float32), 'training/policy_loss': Array(0.02906409, dtype=float32), 'training/total_loss': Array(0.06794307, dtype=float32), 'training/v_loss': Array(0.03384593, dtype=float32), 'eval/episode_distance_from_origin': Array(3834.2073, dtype=float32), 'eval/episode_distance_reward': Array(6.6327076, dtype=float32), 'eval/episode_forward_reward': Array(1105.4502, dtype=float32), 'eval/episode_reward': Array(923.48315, dtype=float32), 'eval/episode_reward_alive': Array(153.03906, dtype=float32), 'eval/episode_reward_linvel': Array(1105.4502, dtype=float32), 'eval/episode_reward_quadctrl': Array(-341.6389, dtype=float32), 'eval/episode_x_position': Array(3803.0488, dtype=float32), 'eval/episode_x_velocity': Array(221.09006, dtype=float32), 'eval/episode_y_position': Array(45.16868, dtype=float32), 'eval/episode_y_velocity': Array(43.11719, dtype=float32), 'eval/episode_distance_from_origin_std': Array(151.04745, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3330973, dtype=float32), 'eval/episode_forward_reward_std': Array(222.18185, dtype=float32), 'eval/episode_reward_std': Array(235.1885, dtype=float32), 'eval/episode_reward_alive_std': Array(33.864193, dtype=float32), 'eval/episode_reward_linvel_std': Array(222.18185, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.373793, dtype=float32), 'eval/episode_x_position_std': Array(151.79883, dtype=float32), 'eval/episode_x_velocity_std': Array(44.43639, dtype=float32), 'eval/episode_y_position_std': Array(141.3116, dtype=float32), 'eval/episode_y_velocity_std': Array(37.230167, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44241905212402, 'eval/sps': 938.124674783882, 'num_steps': 2293760}
{'eval/walltime': 4126.881391763687, 'training/sps': 2956.3079878613207, 'training/walltime': 830.6660146713257, 'training/entropy_loss': Array(0.00642512, dtype=float32), 'training/policy_loss': Array(0.04406103, dtype=float32), 'training/total_loss': Array(0.08071071, dtype=float32), 'training/v_loss': Array(0.03022455, dtype=float32), 'eval/episode_distance_from_origin': Array(3856.3296, dtype=float32), 'eval/episode_distance_reward': Array(7.022498, dtype=float32), 'eval/episode_forward_reward': Array(1170.4149, dtype=float32), 'eval/episode_reward': Array(982.23755, dtype=float32), 'eval/episode_reward_alive': Array(138.71484, dtype=float32), 'eval/episode_reward_linvel': Array(1170.4149, dtype=float32), 'eval/episode_reward_quadctrl': Array(-333.9147, dtype=float32), 'eval/episode_x_position': Array(3825.4482, dtype=float32), 'eval/episode_x_velocity': Array(234.08295, dtype=float32), 'eval/episode_y_position': Array(36.210564, dtype=float32), 'eval/episode_y_velocity': Array(39.22838, dtype=float32), 'eval/episode_distance_from_origin_std': Array(156.52307, dtype=float32), 'eval/episode_distance_reward_std': Array(1.562823, dtype=float32), 'eval/episode_forward_reward_std': Array(260.46887, dtype=float32), 'eval/episode_reward_std': Array(286.56946, dtype=float32), 'eval/episode_reward_alive_std': Array(34.56333, dtype=float32), 'eval/episode_reward_linvel_std': Array(260.46887, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.53034, dtype=float32), 'eval/episode_x_position_std': Array(157.08453, dtype=float32), 'eval/episode_x_velocity_std': Array(52.093746, dtype=float32), 'eval/episode_y_position_std': Array(142.18683, dtype=float32), 'eval/episode_y_velocity_std': Array(42.51718, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.36336016654968, 'eval/sps': 938.6685678885079, 'num_steps': 2375680}
{'eval/walltime': 4263.282289505005, 'training/sps': 2950.6983305000344, 'training/walltime': 858.42893409729, 'training/entropy_loss': Array(0.00712307, dtype=float32), 'training/policy_loss': Array(0.03689635, dtype=float32), 'training/total_loss': Array(0.08139379, dtype=float32), 'training/v_loss': Array(0.03737437, dtype=float32), 'eval/episode_distance_from_origin': Array(3874.771, dtype=float32), 'eval/episode_distance_reward': Array(7.14777, dtype=float32), 'eval/episode_forward_reward': Array(1191.2935, dtype=float32), 'eval/episode_reward': Array(1012.5985, dtype=float32), 'eval/episode_reward_alive': Array(149.82812, dtype=float32), 'eval/episode_reward_linvel': Array(1191.2935, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.67072, dtype=float32), 'eval/episode_x_position': Array(3843.2344, dtype=float32), 'eval/episode_x_velocity': Array(238.25865, dtype=float32), 'eval/episode_y_position': Array(51.641968, dtype=float32), 'eval/episode_y_velocity': Array(39.429512, dtype=float32), 'eval/episode_distance_from_origin_std': Array(180.4077, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7092215, dtype=float32), 'eval/episode_forward_reward_std': Array(284.86856, dtype=float32), 'eval/episode_reward_std': Array(304.26678, dtype=float32), 'eval/episode_reward_alive_std': Array(29.469492, dtype=float32), 'eval/episode_reward_linvel_std': Array(284.86856, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.381641, dtype=float32), 'eval/episode_x_position_std': Array(181.14632, dtype=float32), 'eval/episode_x_velocity_std': Array(56.973698, dtype=float32), 'eval/episode_y_position_std': Array(155.62259, dtype=float32), 'eval/episode_y_velocity_std': Array(44.836147, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40089774131775, 'eval/sps': 938.410245970302, 'num_steps': 2457600}
{'eval/walltime': 4399.535154104233, 'training/sps': 2954.161270731657, 'training/walltime': 886.1593091487885, 'training/entropy_loss': Array(0.00729153, dtype=float32), 'training/policy_loss': Array(0.04600934, dtype=float32), 'training/total_loss': Array(0.0723504, dtype=float32), 'training/v_loss': Array(0.01904953, dtype=float32), 'eval/episode_distance_from_origin': Array(3860.5833, dtype=float32), 'eval/episode_distance_reward': Array(7.359913, dtype=float32), 'eval/episode_forward_reward': Array(1226.6501, dtype=float32), 'eval/episode_reward': Array(1052.7866, dtype=float32), 'eval/episode_reward_alive': Array(150.4375, dtype=float32), 'eval/episode_reward_linvel': Array(1226.6501, dtype=float32), 'eval/episode_reward_quadctrl': Array(-331.66098, dtype=float32), 'eval/episode_x_position': Array(3829.0425, dtype=float32), 'eval/episode_x_velocity': Array(245.33, dtype=float32), 'eval/episode_y_position': Array(3.3745828, dtype=float32), 'eval/episode_y_velocity': Array(27.131117, dtype=float32), 'eval/episode_distance_from_origin_std': Array(173.99739, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7041864, dtype=float32), 'eval/episode_forward_reward_std': Array(284.02914, dtype=float32), 'eval/episode_reward_std': Array(307.17435, dtype=float32), 'eval/episode_reward_alive_std': Array(31.864029, dtype=float32), 'eval/episode_reward_linvel_std': Array(284.02914, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.678005, dtype=float32), 'eval/episode_x_position_std': Array(174.83414, dtype=float32), 'eval/episode_x_velocity_std': Array(56.80582, dtype=float32), 'eval/episode_y_position_std': Array(157.44974, dtype=float32), 'eval/episode_y_velocity_std': Array(46.832943, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2528645992279, 'eval/sps': 939.4297901662269, 'num_steps': 2539520}
{'eval/walltime': 4535.926936864853, 'training/sps': 2944.3936542383517, 'training/walltime': 913.981675863266, 'training/entropy_loss': Array(0.00315004, dtype=float32), 'training/policy_loss': Array(0.00786362, dtype=float32), 'training/total_loss': Array(0.05283146, dtype=float32), 'training/v_loss': Array(0.0418178, dtype=float32), 'eval/episode_distance_from_origin': Array(3984.8027, dtype=float32), 'eval/episode_distance_reward': Array(8.294802, dtype=float32), 'eval/episode_forward_reward': Array(1382.4636, dtype=float32), 'eval/episode_reward': Array(1209.4167, dtype=float32), 'eval/episode_reward_alive': Array(148.89453, dtype=float32), 'eval/episode_reward_linvel': Array(1382.4636, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.23627, dtype=float32), 'eval/episode_x_position': Array(3953.4224, dtype=float32), 'eval/episode_x_velocity': Array(276.49274, dtype=float32), 'eval/episode_y_position': Array(63.33774, dtype=float32), 'eval/episode_y_velocity': Array(32.302525, dtype=float32), 'eval/episode_distance_from_origin_std': Array(170.71846, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8853469, dtype=float32), 'eval/episode_forward_reward_std': Array(314.22156, dtype=float32), 'eval/episode_reward_std': Array(347.58472, dtype=float32), 'eval/episode_reward_alive_std': Array(35.509884, dtype=float32), 'eval/episode_reward_linvel_std': Array(314.22156, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.839308, dtype=float32), 'eval/episode_x_position_std': Array(171.8592, dtype=float32), 'eval/episode_x_velocity_std': Array(62.84431, dtype=float32), 'eval/episode_y_position_std': Array(166.21652, dtype=float32), 'eval/episode_y_velocity_std': Array(52.599964, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39178276062012, 'eval/sps': 938.4729593618667, 'num_steps': 2621440}
{'eval/walltime': 4672.201342582703, 'training/sps': 2953.960174244055, 'training/walltime': 941.7139387130737, 'training/entropy_loss': Array(0.00445289, dtype=float32), 'training/policy_loss': Array(0.00345641, dtype=float32), 'training/total_loss': Array(0.03825274, dtype=float32), 'training/v_loss': Array(0.03034344, dtype=float32), 'eval/episode_distance_from_origin': Array(3994.2563, dtype=float32), 'eval/episode_distance_reward': Array(8.617422, dtype=float32), 'eval/episode_forward_reward': Array(1436.2328, dtype=float32), 'eval/episode_reward': Array(1272.0502, dtype=float32), 'eval/episode_reward_alive': Array(152.0664, dtype=float32), 'eval/episode_reward_linvel': Array(1436.2328, dtype=float32), 'eval/episode_reward_quadctrl': Array(-324.8665, dtype=float32), 'eval/episode_x_position': Array(3962.8516, dtype=float32), 'eval/episode_x_velocity': Array(287.24655, dtype=float32), 'eval/episode_y_position': Array(38.85542, dtype=float32), 'eval/episode_y_velocity': Array(20.367128, dtype=float32), 'eval/episode_distance_from_origin_std': Array(175.76814, dtype=float32), 'eval/episode_distance_reward_std': Array(2.0699358, dtype=float32), 'eval/episode_forward_reward_std': Array(344.98602, dtype=float32), 'eval/episode_reward_std': Array(379.10968, dtype=float32), 'eval/episode_reward_alive_std': Array(39.43623, dtype=float32), 'eval/episode_reward_linvel_std': Array(344.98602, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.619013, dtype=float32), 'eval/episode_x_position_std': Array(176.78993, dtype=float32), 'eval/episode_x_velocity_std': Array(68.997215, dtype=float32), 'eval/episode_y_position_std': Array(172.85262, dtype=float32), 'eval/episode_y_velocity_std': Array(54.71428, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27440571784973, 'eval/sps': 939.2812929598715, 'num_steps': 2703360}
{'eval/walltime': 4808.715479135513, 'training/sps': 2939.3221818398824, 'training/walltime': 969.5843098163605, 'training/entropy_loss': Array(0.00523987, dtype=float32), 'training/policy_loss': Array(0.00448252, dtype=float32), 'training/total_loss': Array(0.04483454, dtype=float32), 'training/v_loss': Array(0.03511215, dtype=float32), 'eval/episode_distance_from_origin': Array(4063.092, dtype=float32), 'eval/episode_distance_reward': Array(9.699724, dtype=float32), 'eval/episode_forward_reward': Array(1616.6143, dtype=float32), 'eval/episode_reward': Array(1470.8728, dtype=float32), 'eval/episode_reward_alive': Array(162.77734, dtype=float32), 'eval/episode_reward_linvel': Array(1616.6143, dtype=float32), 'eval/episode_reward_quadctrl': Array(-318.21832, dtype=float32), 'eval/episode_x_position': Array(4031.3394, dtype=float32), 'eval/episode_x_velocity': Array(323.32285, dtype=float32), 'eval/episode_y_position': Array(0.34498549, dtype=float32), 'eval/episode_y_velocity': Array(-3.725055, dtype=float32), 'eval/episode_distance_from_origin_std': Array(178.09811, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2014303, dtype=float32), 'eval/episode_forward_reward_std': Array(366.90143, dtype=float32), 'eval/episode_reward_std': Array(398.15594, dtype=float32), 'eval/episode_reward_alive_std': Array(36.98262, dtype=float32), 'eval/episode_reward_linvel_std': Array(366.90143, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.149048, dtype=float32), 'eval/episode_x_position_std': Array(178.88594, dtype=float32), 'eval/episode_x_velocity_std': Array(73.38029, dtype=float32), 'eval/episode_y_position_std': Array(190.04433, dtype=float32), 'eval/episode_y_velocity_std': Array(56.61756, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51413655281067, 'eval/sps': 937.6318323669215, 'num_steps': 2785280}
{'eval/walltime': 4945.561982393265, 'training/sps': 2950.1471957787367, 'training/walltime': 997.3524158000946, 'training/entropy_loss': Array(0.00559736, dtype=float32), 'training/policy_loss': Array(0.00812575, dtype=float32), 'training/total_loss': Array(0.04770932, dtype=float32), 'training/v_loss': Array(0.0339862, dtype=float32), 'eval/episode_distance_from_origin': Array(4072.081, dtype=float32), 'eval/episode_distance_reward': Array(9.678523, dtype=float32), 'eval/episode_forward_reward': Array(1613.081, dtype=float32), 'eval/episode_reward': Array(1466.8208, dtype=float32), 'eval/episode_reward_alive': Array(162.3164, dtype=float32), 'eval/episode_reward_linvel': Array(1613.081, dtype=float32), 'eval/episode_reward_quadctrl': Array(-318.25507, dtype=float32), 'eval/episode_x_position': Array(4040.95, dtype=float32), 'eval/episode_x_velocity': Array(322.6162, dtype=float32), 'eval/episode_y_position': Array(-19.562168, dtype=float32), 'eval/episode_y_velocity': Array(-7.2117367, dtype=float32), 'eval/episode_distance_from_origin_std': Array(191.29893, dtype=float32), 'eval/episode_distance_reward_std': Array(2.3536499, dtype=float32), 'eval/episode_forward_reward_std': Array(392.2709, dtype=float32), 'eval/episode_reward_std': Array(426.25153, dtype=float32), 'eval/episode_reward_alive_std': Array(41.26282, dtype=float32), 'eval/episode_reward_linvel_std': Array(392.2709, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.967937, dtype=float32), 'eval/episode_x_position_std': Array(191.97194, dtype=float32), 'eval/episode_x_velocity_std': Array(78.454216, dtype=float32), 'eval/episode_y_position_std': Array(172.60266, dtype=float32), 'eval/episode_y_velocity_std': Array(55.457706, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84650325775146, 'eval/sps': 935.3545538457128, 'num_steps': 2867200}
{'eval/walltime': 5083.032575368881, 'training/sps': 2938.9049917570187, 'training/walltime': 1025.226743221283, 'training/entropy_loss': Array(0.00594598, dtype=float32), 'training/policy_loss': Array(0.01901341, dtype=float32), 'training/total_loss': Array(0.06116014, dtype=float32), 'training/v_loss': Array(0.03620074, dtype=float32), 'eval/episode_distance_from_origin': Array(4109.4736, dtype=float32), 'eval/episode_distance_reward': Array(10.093391, dtype=float32), 'eval/episode_forward_reward': Array(1682.2251, dtype=float32), 'eval/episode_reward': Array(1543.5471, dtype=float32), 'eval/episode_reward_alive': Array(170.53516, dtype=float32), 'eval/episode_reward_linvel': Array(1682.2251, dtype=float32), 'eval/episode_reward_quadctrl': Array(-319.30634, dtype=float32), 'eval/episode_x_position': Array(4077.6843, dtype=float32), 'eval/episode_x_velocity': Array(336.445, dtype=float32), 'eval/episode_y_position': Array(-27.922134, dtype=float32), 'eval/episode_y_velocity': Array(-11.194802, dtype=float32), 'eval/episode_distance_from_origin_std': Array(164.5298, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2694697, dtype=float32), 'eval/episode_forward_reward_std': Array(378.24084, dtype=float32), 'eval/episode_reward_std': Array(401.75226, dtype=float32), 'eval/episode_reward_alive_std': Array(36.52916, dtype=float32), 'eval/episode_reward_linvel_std': Array(378.24084, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.444906, dtype=float32), 'eval/episode_x_position_std': Array(166.29819, dtype=float32), 'eval/episode_x_velocity_std': Array(75.64817, dtype=float32), 'eval/episode_y_position_std': Array(190.26303, dtype=float32), 'eval/episode_y_velocity_std': Array(56.491528, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.47059297561646, 'eval/sps': 931.1082263441151, 'num_steps': 2949120}
{'eval/walltime': 5219.787202835083, 'training/sps': 2925.530818066639, 'training/walltime': 1053.228499174118, 'training/entropy_loss': Array(0.00601492, dtype=float32), 'training/policy_loss': Array(0.02002554, dtype=float32), 'training/total_loss': Array(0.06250266, dtype=float32), 'training/v_loss': Array(0.0364622, dtype=float32), 'eval/episode_distance_from_origin': Array(4090.3154, dtype=float32), 'eval/episode_distance_reward': Array(9.605841, dtype=float32), 'eval/episode_forward_reward': Array(1600.9672, dtype=float32), 'eval/episode_reward': Array(1453.1841, dtype=float32), 'eval/episode_reward_alive': Array(167.1836, dtype=float32), 'eval/episode_reward_linvel': Array(1600.9672, dtype=float32), 'eval/episode_reward_quadctrl': Array(-324.57245, dtype=float32), 'eval/episode_x_position': Array(4058.7476, dtype=float32), 'eval/episode_x_velocity': Array(320.19345, dtype=float32), 'eval/episode_y_position': Array(12.079084, dtype=float32), 'eval/episode_y_velocity': Array(5.971305, dtype=float32), 'eval/episode_distance_from_origin_std': Array(180.73225, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4716966, dtype=float32), 'eval/episode_forward_reward_std': Array(411.9456, dtype=float32), 'eval/episode_reward_std': Array(440.95126, dtype=float32), 'eval/episode_reward_alive_std': Array(48.50036, dtype=float32), 'eval/episode_reward_linvel_std': Array(411.9456, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.190313, dtype=float32), 'eval/episode_x_position_std': Array(182.41983, dtype=float32), 'eval/episode_x_velocity_std': Array(82.389114, dtype=float32), 'eval/episode_y_position_std': Array(187.98517, dtype=float32), 'eval/episode_y_velocity_std': Array(55.201874, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.75462746620178, 'eval/sps': 935.9829526180717, 'num_steps': 3031040}
{'eval/walltime': 5356.556962251663, 'training/sps': 2948.243902215512, 'training/walltime': 1081.0145313739777, 'training/entropy_loss': Array(0.00583237, dtype=float32), 'training/policy_loss': Array(0.0325674, dtype=float32), 'training/total_loss': Array(0.08142971, dtype=float32), 'training/v_loss': Array(0.04302995, dtype=float32), 'eval/episode_distance_from_origin': Array(4176.4043, dtype=float32), 'eval/episode_distance_reward': Array(10.442835, dtype=float32), 'eval/episode_forward_reward': Array(1740.4647, dtype=float32), 'eval/episode_reward': Array(1608.3411, dtype=float32), 'eval/episode_reward_alive': Array(181.85156, dtype=float32), 'eval/episode_reward_linvel': Array(1740.4647, dtype=float32), 'eval/episode_reward_quadctrl': Array(-324.41797, dtype=float32), 'eval/episode_x_position': Array(4145.2124, dtype=float32), 'eval/episode_x_velocity': Array(348.0929, dtype=float32), 'eval/episode_y_position': Array(51.504234, dtype=float32), 'eval/episode_y_velocity': Array(6.684273, dtype=float32), 'eval/episode_distance_from_origin_std': Array(194.46538, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4891708, dtype=float32), 'eval/episode_forward_reward_std': Array(414.8577, dtype=float32), 'eval/episode_reward_std': Array(431.7082, dtype=float32), 'eval/episode_reward_alive_std': Array(42.598934, dtype=float32), 'eval/episode_reward_linvel_std': Array(414.8577, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.409578, dtype=float32), 'eval/episode_x_position_std': Array(195.36397, dtype=float32), 'eval/episode_x_velocity_std': Array(82.971504, dtype=float32), 'eval/episode_y_position_std': Array(180.06737, dtype=float32), 'eval/episode_y_velocity_std': Array(50.458958, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7697594165802, 'eval/sps': 935.8793972147832, 'num_steps': 3112960}
{'eval/walltime': 5493.5059633255005, 'training/sps': 2938.215155812273, 'training/walltime': 1108.8954031467438, 'training/entropy_loss': Array(0.00259089, dtype=float32), 'training/policy_loss': Array(-0.00236247, dtype=float32), 'training/total_loss': Array(0.02324262, dtype=float32), 'training/v_loss': Array(0.02301421, dtype=float32), 'eval/episode_distance_from_origin': Array(4163.0244, dtype=float32), 'eval/episode_distance_reward': Array(10.187554, dtype=float32), 'eval/episode_forward_reward': Array(1697.9183, dtype=float32), 'eval/episode_reward': Array(1566.0173, dtype=float32), 'eval/episode_reward_alive': Array(186.22656, dtype=float32), 'eval/episode_reward_linvel': Array(1697.9183, dtype=float32), 'eval/episode_reward_quadctrl': Array(-328.31494, dtype=float32), 'eval/episode_x_position': Array(4131.3887, dtype=float32), 'eval/episode_x_velocity': Array(339.58362, dtype=float32), 'eval/episode_y_position': Array(-15.76216, dtype=float32), 'eval/episode_y_velocity': Array(-6.732373, dtype=float32), 'eval/episode_distance_from_origin_std': Array(193.71544, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7597427, dtype=float32), 'eval/episode_forward_reward_std': Array(459.95288, dtype=float32), 'eval/episode_reward_std': Array(475.6009, dtype=float32), 'eval/episode_reward_alive_std': Array(56.376694, dtype=float32), 'eval/episode_reward_linvel_std': Array(459.95288, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.218103, dtype=float32), 'eval/episode_x_position_std': Array(194.44981, dtype=float32), 'eval/episode_x_velocity_std': Array(91.99056, dtype=float32), 'eval/episode_y_position_std': Array(190.62772, dtype=float32), 'eval/episode_y_velocity_std': Array(58.477444, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.94900107383728, 'eval/sps': 934.6544990933352, 'num_steps': 3194880}
{'eval/walltime': 5630.539432287216, 'training/sps': 2939.2701083192583, 'training/walltime': 1136.7662680149078, 'training/entropy_loss': Array(0.00589035, dtype=float32), 'training/policy_loss': Array(0.01114174, dtype=float32), 'training/total_loss': Array(0.05226473, dtype=float32), 'training/v_loss': Array(0.03523263, dtype=float32), 'eval/episode_distance_from_origin': Array(4130.759, dtype=float32), 'eval/episode_distance_reward': Array(9.533922, dtype=float32), 'eval/episode_forward_reward': Array(1588.9807, dtype=float32), 'eval/episode_reward': Array(1446.481, dtype=float32), 'eval/episode_reward_alive': Array(175.51953, dtype=float32), 'eval/episode_reward_linvel': Array(1588.9807, dtype=float32), 'eval/episode_reward_quadctrl': Array(-327.55304, dtype=float32), 'eval/episode_x_position': Array(4099.364, dtype=float32), 'eval/episode_x_velocity': Array(317.7961, dtype=float32), 'eval/episode_y_position': Array(14.211144, dtype=float32), 'eval/episode_y_velocity': Array(9.721025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(197.92793, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7442882, dtype=float32), 'eval/episode_forward_reward_std': Array(457.3766, dtype=float32), 'eval/episode_reward_std': Array(476.70065, dtype=float32), 'eval/episode_reward_alive_std': Array(50.52074, dtype=float32), 'eval/episode_reward_linvel_std': Array(457.3766, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.188251, dtype=float32), 'eval/episode_x_position_std': Array(197.9608, dtype=float32), 'eval/episode_x_velocity_std': Array(91.475296, dtype=float32), 'eval/episode_y_position_std': Array(180.22571, dtype=float32), 'eval/episode_y_velocity_std': Array(62.74127, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.0334689617157, 'eval/sps': 934.0783749389029, 'num_steps': 3276800}
{'eval/walltime': 5767.255861282349, 'training/sps': 2951.4757261649793, 'training/walltime': 1164.5218749046326, 'training/entropy_loss': Array(0.00510354, dtype=float32), 'training/policy_loss': Array(0.01307518, dtype=float32), 'training/total_loss': Array(0.0644718, dtype=float32), 'training/v_loss': Array(0.04629307, dtype=float32), 'eval/episode_distance_from_origin': Array(4143.4434, dtype=float32), 'eval/episode_distance_reward': Array(9.6531925, dtype=float32), 'eval/episode_forward_reward': Array(1608.859, dtype=float32), 'eval/episode_reward': Array(1472.597, dtype=float32), 'eval/episode_reward_alive': Array(189.15234, dtype=float32), 'eval/episode_reward_linvel': Array(1608.859, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.06763, dtype=float32), 'eval/episode_x_position': Array(4110.7627, dtype=float32), 'eval/episode_x_velocity': Array(321.77182, dtype=float32), 'eval/episode_y_position': Array(22.227312, dtype=float32), 'eval/episode_y_velocity': Array(12.848499, dtype=float32), 'eval/episode_distance_from_origin_std': Array(252.33417, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3088374, dtype=float32), 'eval/episode_forward_reward_std': Array(551.4679, dtype=float32), 'eval/episode_reward_std': Array(574.28046, dtype=float32), 'eval/episode_reward_alive_std': Array(67.04606, dtype=float32), 'eval/episode_reward_linvel_std': Array(551.4679, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.542084, dtype=float32), 'eval/episode_x_position_std': Array(254.28519, dtype=float32), 'eval/episode_x_velocity_std': Array(110.2936, dtype=float32), 'eval/episode_y_position_std': Array(197.88756, dtype=float32), 'eval/episode_y_velocity_std': Array(70.684425, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.71642899513245, 'eval/sps': 936.2444655759493, 'num_steps': 3358720}
{'eval/walltime': 5903.8800740242, 'training/sps': 2937.6777159357903, 'training/walltime': 1192.40784740448, 'training/entropy_loss': Array(0.00651061, dtype=float32), 'training/policy_loss': Array(0.03303193, dtype=float32), 'training/total_loss': Array(0.07606971, dtype=float32), 'training/v_loss': Array(0.03652718, dtype=float32), 'eval/episode_distance_from_origin': Array(4088.531, dtype=float32), 'eval/episode_distance_reward': Array(8.822907, dtype=float32), 'eval/episode_forward_reward': Array(1470.4792, dtype=float32), 'eval/episode_reward': Array(1320.6304, dtype=float32), 'eval/episode_reward_alive': Array(174.1914, dtype=float32), 'eval/episode_reward_linvel': Array(1470.4792, dtype=float32), 'eval/episode_reward_quadctrl': Array(-332.86313, dtype=float32), 'eval/episode_x_position': Array(4054.1118, dtype=float32), 'eval/episode_x_velocity': Array(294.09583, dtype=float32), 'eval/episode_y_position': Array(86.83101, dtype=float32), 'eval/episode_y_velocity': Array(43.10817, dtype=float32), 'eval/episode_distance_from_origin_std': Array(239.23848, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0322897, dtype=float32), 'eval/episode_forward_reward_std': Array(505.3771, dtype=float32), 'eval/episode_reward_std': Array(529.52966, dtype=float32), 'eval/episode_reward_alive_std': Array(67.02734, dtype=float32), 'eval/episode_reward_linvel_std': Array(505.3771, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.204693, dtype=float32), 'eval/episode_x_position_std': Array(242.3917, dtype=float32), 'eval/episode_x_velocity_std': Array(101.07542, dtype=float32), 'eval/episode_y_position_std': Array(201.40231, dtype=float32), 'eval/episode_y_velocity_std': Array(71.446396, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6242127418518, 'eval/sps': 936.8763957077867, 'num_steps': 3440640}
{'eval/walltime': 6040.403616905212, 'training/sps': 2951.255146590973, 'training/walltime': 1220.1655287742615, 'training/entropy_loss': Array(0.00676428, dtype=float32), 'training/policy_loss': Array(0.04857764, dtype=float32), 'training/total_loss': Array(0.08598894, dtype=float32), 'training/v_loss': Array(0.03064702, dtype=float32), 'eval/episode_distance_from_origin': Array(4108.326, dtype=float32), 'eval/episode_distance_reward': Array(8.791958, dtype=float32), 'eval/episode_forward_reward': Array(1465.321, dtype=float32), 'eval/episode_reward': Array(1339.6279, dtype=float32), 'eval/episode_reward_alive': Array(216.1914, dtype=float32), 'eval/episode_reward_linvel': Array(1465.321, dtype=float32), 'eval/episode_reward_quadctrl': Array(-350.67645, dtype=float32), 'eval/episode_x_position': Array(4072.2656, dtype=float32), 'eval/episode_x_velocity': Array(293.06415, dtype=float32), 'eval/episode_y_position': Array(82.217636, dtype=float32), 'eval/episode_y_velocity': Array(32.902115, dtype=float32), 'eval/episode_distance_from_origin_std': Array(259.48752, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3430016, dtype=float32), 'eval/episode_forward_reward_std': Array(557.1618, dtype=float32), 'eval/episode_reward_std': Array(561.8085, dtype=float32), 'eval/episode_reward_alive_std': Array(78.71795, dtype=float32), 'eval/episode_reward_linvel_std': Array(557.1618, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.7907, dtype=float32), 'eval/episode_x_position_std': Array(262.4935, dtype=float32), 'eval/episode_x_velocity_std': Array(111.432335, dtype=float32), 'eval/episode_y_position_std': Array(228.03073, dtype=float32), 'eval/episode_y_velocity_std': Array(71.03602, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52354288101196, 'eval/sps': 937.5672305219862, 'num_steps': 3522560}
{'eval/walltime': 6177.268951654434, 'training/sps': 2934.726961848524, 'training/walltime': 1248.0795395374298, 'training/entropy_loss': Array(0.00759501, dtype=float32), 'training/policy_loss': Array(0.117635, dtype=float32), 'training/total_loss': Array(0.16567731, dtype=float32), 'training/v_loss': Array(0.04044729, dtype=float32), 'eval/episode_distance_from_origin': Array(4061.5486, dtype=float32), 'eval/episode_distance_reward': Array(7.5707717, dtype=float32), 'eval/episode_forward_reward': Array(1261.7927, dtype=float32), 'eval/episode_reward': Array(1070.8229, dtype=float32), 'eval/episode_reward_alive': Array(131.9375, dtype=float32), 'eval/episode_reward_linvel': Array(1261.7927, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.4781, dtype=float32), 'eval/episode_x_position': Array(4030.5303, dtype=float32), 'eval/episode_x_velocity': Array(252.35854, dtype=float32), 'eval/episode_y_position': Array(82.20835, dtype=float32), 'eval/episode_y_velocity': Array(31.592165, dtype=float32), 'eval/episode_distance_from_origin_std': Array(172.85657, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2203639, dtype=float32), 'eval/episode_forward_reward_std': Array(370.0573, dtype=float32), 'eval/episode_reward_std': Array(397.93423, dtype=float32), 'eval/episode_reward_alive_std': Array(53.893486, dtype=float32), 'eval/episode_reward_linvel_std': Array(370.0573, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.699348, dtype=float32), 'eval/episode_x_position_std': Array(173.45103, dtype=float32), 'eval/episode_x_velocity_std': Array(74.01146, dtype=float32), 'eval/episode_y_position_std': Array(173.5872, dtype=float32), 'eval/episode_y_velocity_std': Array(53.23498, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8653347492218, 'eval/sps': 935.2258571137407, 'num_steps': 3604480}
{'eval/walltime': 6313.771224737167, 'training/sps': 2946.851378364207, 'training/walltime': 1275.8787019252777, 'training/entropy_loss': Array(0.00277348, dtype=float32), 'training/policy_loss': Array(0.00376477, dtype=float32), 'training/total_loss': Array(0.04589649, dtype=float32), 'training/v_loss': Array(0.03935824, dtype=float32), 'eval/episode_distance_from_origin': Array(4068.3613, dtype=float32), 'eval/episode_distance_reward': Array(7.6207485, dtype=float32), 'eval/episode_forward_reward': Array(1270.1221, dtype=float32), 'eval/episode_reward': Array(1084.9283, dtype=float32), 'eval/episode_reward_alive': Array(144.01172, dtype=float32), 'eval/episode_reward_linvel': Array(1270.1221, dtype=float32), 'eval/episode_reward_quadctrl': Array(-336.8263, dtype=float32), 'eval/episode_x_position': Array(4036.9868, dtype=float32), 'eval/episode_x_velocity': Array(254.02441, dtype=float32), 'eval/episode_y_position': Array(121.12548, dtype=float32), 'eval/episode_y_velocity': Array(39.42208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(201.38252, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4043875, dtype=float32), 'eval/episode_forward_reward_std': Array(400.72818, dtype=float32), 'eval/episode_reward_std': Array(425.34607, dtype=float32), 'eval/episode_reward_alive_std': Array(64.66408, dtype=float32), 'eval/episode_reward_linvel_std': Array(400.72818, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.586933, dtype=float32), 'eval/episode_x_position_std': Array(204.17395, dtype=float32), 'eval/episode_x_velocity_std': Array(80.14563, dtype=float32), 'eval/episode_y_position_std': Array(162.41734, dtype=float32), 'eval/episode_y_velocity_std': Array(45.737354, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50227308273315, 'eval/sps': 937.7133223446032, 'num_steps': 3686400}
{'eval/walltime': 6450.47270989418, 'training/sps': 2940.1615215188176, 'training/walltime': 1303.7411167621613, 'training/entropy_loss': Array(0.00511098, dtype=float32), 'training/policy_loss': Array(-0.00064546, dtype=float32), 'training/total_loss': Array(0.03119439, dtype=float32), 'training/v_loss': Array(0.02672887, dtype=float32), 'eval/episode_distance_from_origin': Array(4073.8828, dtype=float32), 'eval/episode_distance_reward': Array(7.54893, dtype=float32), 'eval/episode_forward_reward': Array(1258.1528, dtype=float32), 'eval/episode_reward': Array(1074.9336, dtype=float32), 'eval/episode_reward_alive': Array(143.63281, dtype=float32), 'eval/episode_reward_linvel': Array(1258.1528, dtype=float32), 'eval/episode_reward_quadctrl': Array(-334.40125, dtype=float32), 'eval/episode_x_position': Array(4042.1848, dtype=float32), 'eval/episode_x_velocity': Array(251.6306, dtype=float32), 'eval/episode_y_position': Array(113.10633, dtype=float32), 'eval/episode_y_velocity': Array(36.934097, dtype=float32), 'eval/episode_distance_from_origin_std': Array(169.35725, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9007008, dtype=float32), 'eval/episode_forward_reward_std': Array(316.78107, dtype=float32), 'eval/episode_reward_std': Array(333.4293, dtype=float32), 'eval/episode_reward_alive_std': Array(49.769566, dtype=float32), 'eval/episode_reward_linvel_std': Array(316.78107, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.185148, dtype=float32), 'eval/episode_x_position_std': Array(171.20592, dtype=float32), 'eval/episode_x_velocity_std': Array(63.35623, dtype=float32), 'eval/episode_y_position_std': Array(175.9716, dtype=float32), 'eval/episode_y_velocity_std': Array(47.00109, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70148515701294, 'eval/sps': 936.3468132989296, 'num_steps': 3768320}
{'eval/walltime': 6587.247317075729, 'training/sps': 2929.85770614765, 'training/walltime': 1331.7015190124512, 'training/entropy_loss': Array(0.00533739, dtype=float32), 'training/policy_loss': Array(0.0121288, dtype=float32), 'training/total_loss': Array(0.06109996, dtype=float32), 'training/v_loss': Array(0.04363376, dtype=float32), 'eval/episode_distance_from_origin': Array(4068.6196, dtype=float32), 'eval/episode_distance_reward': Array(7.430171, dtype=float32), 'eval/episode_forward_reward': Array(1238.3593, dtype=float32), 'eval/episode_reward': Array(1059.373, dtype=float32), 'eval/episode_reward_alive': Array(156.30078, dtype=float32), 'eval/episode_reward_linvel': Array(1238.3593, dtype=float32), 'eval/episode_reward_quadctrl': Array(-342.71735, dtype=float32), 'eval/episode_x_position': Array(4035.2732, dtype=float32), 'eval/episode_x_velocity': Array(247.67184, dtype=float32), 'eval/episode_y_position': Array(133.36436, dtype=float32), 'eval/episode_y_velocity': Array(45.12185, dtype=float32), 'eval/episode_distance_from_origin_std': Array(189.91133, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2606122, dtype=float32), 'eval/episode_forward_reward_std': Array(376.7658, dtype=float32), 'eval/episode_reward_std': Array(398.6174, dtype=float32), 'eval/episode_reward_alive_std': Array(73.7002, dtype=float32), 'eval/episode_reward_linvel_std': Array(376.7658, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.4801, dtype=float32), 'eval/episode_x_position_std': Array(192.23276, dtype=float32), 'eval/episode_x_velocity_std': Array(75.35314, dtype=float32), 'eval/episode_y_position_std': Array(186.85783, dtype=float32), 'eval/episode_y_velocity_std': Array(50.320316, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.77460718154907, 'eval/sps': 935.8462264131966, 'num_steps': 3850240}
{'eval/walltime': 6723.919704914093, 'training/sps': 2933.76271286933, 'training/walltime': 1359.624704360962, 'training/entropy_loss': Array(0.00716641, dtype=float32), 'training/policy_loss': Array(0.04886902, dtype=float32), 'training/total_loss': Array(0.09366859, dtype=float32), 'training/v_loss': Array(0.03763315, dtype=float32), 'eval/episode_distance_from_origin': Array(4079.523, dtype=float32), 'eval/episode_distance_reward': Array(7.3165007, dtype=float32), 'eval/episode_forward_reward': Array(1219.415, dtype=float32), 'eval/episode_reward': Array(1038.1409, dtype=float32), 'eval/episode_reward_alive': Array(158.91797, dtype=float32), 'eval/episode_reward_linvel': Array(1219.415, dtype=float32), 'eval/episode_reward_quadctrl': Array(-347.5087, dtype=float32), 'eval/episode_x_position': Array(4047.5784, dtype=float32), 'eval/episode_x_velocity': Array(243.88303, dtype=float32), 'eval/episode_y_position': Array(105.43807, dtype=float32), 'eval/episode_y_velocity': Array(37.12529, dtype=float32), 'eval/episode_distance_from_origin_std': Array(173.90741, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8994049, dtype=float32), 'eval/episode_forward_reward_std': Array(316.5656, dtype=float32), 'eval/episode_reward_std': Array(339.58466, dtype=float32), 'eval/episode_reward_alive_std': Array(71.34976, dtype=float32), 'eval/episode_reward_linvel_std': Array(316.5656, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.10428, dtype=float32), 'eval/episode_x_position_std': Array(176.05338, dtype=float32), 'eval/episode_x_velocity_std': Array(63.31316, dtype=float32), 'eval/episode_y_position_std': Array(174.66977, dtype=float32), 'eval/episode_y_velocity_std': Array(50.727253, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67238783836365, 'eval/sps': 936.5461599410987, 'num_steps': 3932160}
{'eval/walltime': 6860.5875787734985, 'training/sps': 2939.125438603229, 'training/walltime': 1387.4969410896301, 'training/entropy_loss': Array(0.00699066, dtype=float32), 'training/policy_loss': Array(0.28252926, dtype=float32), 'training/total_loss': Array(0.31790575, dtype=float32), 'training/v_loss': Array(0.02838581, dtype=float32), 'eval/episode_distance_from_origin': Array(3947.4932, dtype=float32), 'eval/episode_distance_reward': Array(6.968725, dtype=float32), 'eval/episode_forward_reward': Array(1161.4521, dtype=float32), 'eval/episode_reward': Array(1096.1958, dtype=float32), 'eval/episode_reward_alive': Array(273.26172, dtype=float32), 'eval/episode_reward_linvel': Array(1161.4521, dtype=float32), 'eval/episode_reward_quadctrl': Array(-345.48676, dtype=float32), 'eval/episode_x_position': Array(3906.8223, dtype=float32), 'eval/episode_x_velocity': Array(232.29044, dtype=float32), 'eval/episode_y_position': Array(-166.33853, dtype=float32), 'eval/episode_y_velocity': Array(-51.847404, dtype=float32), 'eval/episode_distance_from_origin_std': Array(154.36894, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4161247, dtype=float32), 'eval/episode_forward_reward_std': Array(236.01958, dtype=float32), 'eval/episode_reward_std': Array(225.94283, dtype=float32), 'eval/episode_reward_alive_std': Array(50.797886, dtype=float32), 'eval/episode_reward_linvel_std': Array(236.01958, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.40462, dtype=float32), 'eval/episode_x_position_std': Array(153.65305, dtype=float32), 'eval/episode_x_velocity_std': Array(47.20394, dtype=float32), 'eval/episode_y_position_std': Array(183.19122, dtype=float32), 'eval/episode_y_velocity_std': Array(52.38107, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66787385940552, 'eval/sps': 936.5770929580538, 'num_steps': 4014080}
{'eval/walltime': 6997.503719568253, 'training/sps': 2933.405374311053, 'training/walltime': 1415.423527956009, 'training/entropy_loss': Array(0.00740799, dtype=float32), 'training/policy_loss': Array(0.09145296, dtype=float32), 'training/total_loss': Array(0.12874614, dtype=float32), 'training/v_loss': Array(0.0298852, dtype=float32), 'eval/episode_distance_from_origin': Array(3844.081, dtype=float32), 'eval/episode_distance_reward': Array(6.3209987, dtype=float32), 'eval/episode_forward_reward': Array(1053.4982, dtype=float32), 'eval/episode_reward': Array(1010.5687, dtype=float32), 'eval/episode_reward_alive': Array(268.70703, dtype=float32), 'eval/episode_reward_linvel': Array(1053.4982, dtype=float32), 'eval/episode_reward_quadctrl': Array(-317.9573, dtype=float32), 'eval/episode_x_position': Array(3802.5024, dtype=float32), 'eval/episode_x_velocity': Array(210.69962, dtype=float32), 'eval/episode_y_position': Array(-197.0326, dtype=float32), 'eval/episode_y_velocity': Array(-52.412304, dtype=float32), 'eval/episode_distance_from_origin_std': Array(142.95424, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2302723, dtype=float32), 'eval/episode_forward_reward_std': Array(205.04533, dtype=float32), 'eval/episode_reward_std': Array(191.85567, dtype=float32), 'eval/episode_reward_alive_std': Array(50.955807, dtype=float32), 'eval/episode_reward_linvel_std': Array(205.04533, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.312113, dtype=float32), 'eval/episode_x_position_std': Array(141.98738, dtype=float32), 'eval/episode_x_velocity_std': Array(41.009075, dtype=float32), 'eval/episode_y_position_std': Array(156.75638, dtype=float32), 'eval/episode_y_velocity_std': Array(45.300663, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.91614079475403, 'eval/sps': 934.8788189398364, 'num_steps': 4096000}
{'eval/walltime': 7134.143122911453, 'training/sps': 2939.3738045870937, 'training/walltime': 1443.2934095859528, 'training/entropy_loss': Array(0.00438493, dtype=float32), 'training/policy_loss': Array(0.0654731, dtype=float32), 'training/total_loss': Array(0.1194098, dtype=float32), 'training/v_loss': Array(0.04955176, dtype=float32), 'eval/episode_distance_from_origin': Array(3847.5396, dtype=float32), 'eval/episode_distance_reward': Array(6.5117083, dtype=float32), 'eval/episode_forward_reward': Array(1085.2827, dtype=float32), 'eval/episode_reward': Array(1035.9132, dtype=float32), 'eval/episode_reward_alive': Array(263.52734, dtype=float32), 'eval/episode_reward_linvel': Array(1085.2827, dtype=float32), 'eval/episode_reward_quadctrl': Array(-319.40866, dtype=float32), 'eval/episode_x_position': Array(3802.877, dtype=float32), 'eval/episode_x_velocity': Array(217.05655, dtype=float32), 'eval/episode_y_position': Array(-212.36455, dtype=float32), 'eval/episode_y_velocity': Array(-55.310474, dtype=float32), 'eval/episode_distance_from_origin_std': Array(140.57838, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3180298, dtype=float32), 'eval/episode_forward_reward_std': Array(219.67079, dtype=float32), 'eval/episode_reward_std': Array(213.53908, dtype=float32), 'eval/episode_reward_alive_std': Array(43.808815, dtype=float32), 'eval/episode_reward_linvel_std': Array(219.67079, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.308748, dtype=float32), 'eval/episode_x_position_std': Array(140.6319, dtype=float32), 'eval/episode_x_velocity_std': Array(43.934177, dtype=float32), 'eval/episode_y_position_std': Array(179.65607, dtype=float32), 'eval/episode_y_velocity_std': Array(54.102486, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63940334320068, 'eval/sps': 936.7722404239363, 'num_steps': 4177920}
{'eval/walltime': 7270.991782426834, 'training/sps': 2932.527663415772, 'training/walltime': 1471.2283549308777, 'training/entropy_loss': Array(0.00465629, dtype=float32), 'training/policy_loss': Array(0.10066886, dtype=float32), 'training/total_loss': Array(0.15778722, dtype=float32), 'training/v_loss': Array(0.05246207, dtype=float32), 'eval/episode_distance_from_origin': Array(3839.855, dtype=float32), 'eval/episode_distance_reward': Array(7.0429935, dtype=float32), 'eval/episode_forward_reward': Array(1173.8302, dtype=float32), 'eval/episode_reward': Array(1124.7322, dtype=float32), 'eval/episode_reward_alive': Array(265.32812, dtype=float32), 'eval/episode_reward_linvel': Array(1173.8302, dtype=float32), 'eval/episode_reward_quadctrl': Array(-321.4691, dtype=float32), 'eval/episode_x_position': Array(3792.1548, dtype=float32), 'eval/episode_x_velocity': Array(234.76604, dtype=float32), 'eval/episode_y_position': Array(-254.32433, dtype=float32), 'eval/episode_y_velocity': Array(-69.21157, dtype=float32), 'eval/episode_distance_from_origin_std': Array(138.16035, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3917396, dtype=float32), 'eval/episode_forward_reward_std': Array(231.95569, dtype=float32), 'eval/episode_reward_std': Array(233.66258, dtype=float32), 'eval/episode_reward_alive_std': Array(35.76663, dtype=float32), 'eval/episode_reward_linvel_std': Array(231.95569, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.129528, dtype=float32), 'eval/episode_x_position_std': Array(137.92819, dtype=float32), 'eval/episode_x_velocity_std': Array(46.39112, dtype=float32), 'eval/episode_y_position_std': Array(179.44818, dtype=float32), 'eval/episode_y_velocity_std': Array(50.61515, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84865951538086, 'eval/sps': 935.3398159198897, 'num_steps': 4259840}
{'eval/walltime': 7407.431080579758, 'training/sps': 2939.02291627334, 'training/walltime': 1499.1015639305115, 'training/entropy_loss': Array(0.00556212, dtype=float32), 'training/policy_loss': Array(0.04394411, dtype=float32), 'training/total_loss': Array(0.11750882, dtype=float32), 'training/v_loss': Array(0.06800259, dtype=float32), 'eval/episode_distance_from_origin': Array(3878.9602, dtype=float32), 'eval/episode_distance_reward': Array(7.603894, dtype=float32), 'eval/episode_forward_reward': Array(1267.3132, dtype=float32), 'eval/episode_reward': Array(1203.102, dtype=float32), 'eval/episode_reward_alive': Array(259.125, dtype=float32), 'eval/episode_reward_linvel': Array(1267.3132, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.94, dtype=float32), 'eval/episode_x_position': Array(3830.8623, dtype=float32), 'eval/episode_x_velocity': Array(253.46265, dtype=float32), 'eval/episode_y_position': Array(-249.55234, dtype=float32), 'eval/episode_y_velocity': Array(-70.99602, dtype=float32), 'eval/episode_distance_from_origin_std': Array(138.60371, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3650612, dtype=float32), 'eval/episode_forward_reward_std': Array(227.50885, dtype=float32), 'eval/episode_reward_std': Array(231.68318, dtype=float32), 'eval/episode_reward_alive_std': Array(34.894985, dtype=float32), 'eval/episode_reward_linvel_std': Array(227.50885, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.108412, dtype=float32), 'eval/episode_x_position_std': Array(141.5543, dtype=float32), 'eval/episode_x_velocity_std': Array(45.50174, dtype=float32), 'eval/episode_y_position_std': Array(191.56161, dtype=float32), 'eval/episode_y_velocity_std': Array(61.91416, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43929815292358, 'eval/sps': 938.1461333562074, 'num_steps': 4341760}
{'eval/walltime': 7544.398213863373, 'training/sps': 2931.368452469755, 'training/walltime': 1527.0475561618805, 'training/entropy_loss': Array(0.00568468, dtype=float32), 'training/policy_loss': Array(0.05254272, dtype=float32), 'training/total_loss': Array(0.10599116, dtype=float32), 'training/v_loss': Array(0.04776376, dtype=float32), 'eval/episode_distance_from_origin': Array(3928.0098, dtype=float32), 'eval/episode_distance_reward': Array(8.205345, dtype=float32), 'eval/episode_forward_reward': Array(1367.5543, dtype=float32), 'eval/episode_reward': Array(1305.5714, dtype=float32), 'eval/episode_reward_alive': Array(265.0664, dtype=float32), 'eval/episode_reward_linvel': Array(1367.5543, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.2545, dtype=float32), 'eval/episode_x_position': Array(3878.902, dtype=float32), 'eval/episode_x_velocity': Array(273.51083, dtype=float32), 'eval/episode_y_position': Array(-256.59155, dtype=float32), 'eval/episode_y_velocity': Array(-77.06813, dtype=float32), 'eval/episode_distance_from_origin_std': Array(139.96558, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3989664, dtype=float32), 'eval/episode_forward_reward_std': Array(233.15909, dtype=float32), 'eval/episode_reward_std': Array(235.52303, dtype=float32), 'eval/episode_reward_alive_std': Array(34.620228, dtype=float32), 'eval/episode_reward_linvel_std': Array(233.15909, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(15.323815, dtype=float32), 'eval/episode_x_position_std': Array(141.37683, dtype=float32), 'eval/episode_x_velocity_std': Array(46.631832, dtype=float32), 'eval/episode_y_position_std': Array(205.23923, dtype=float32), 'eval/episode_y_velocity_std': Array(67.40897, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.9671332836151, 'eval/sps': 934.5307661141812, 'num_steps': 4423680}
{'eval/walltime': 7681.013286113739, 'training/sps': 2945.672913538312, 'training/walltime': 1554.8578400611877, 'training/entropy_loss': Array(0.00786593, dtype=float32), 'training/policy_loss': Array(0.12751561, dtype=float32), 'training/total_loss': Array(0.19194806, dtype=float32), 'training/v_loss': Array(0.05656651, dtype=float32), 'eval/episode_distance_from_origin': Array(3796.4473, dtype=float32), 'eval/episode_distance_reward': Array(6.8649445, dtype=float32), 'eval/episode_forward_reward': Array(1144.1547, dtype=float32), 'eval/episode_reward': Array(1064.4484, dtype=float32), 'eval/episode_reward_alive': Array(297.21094, dtype=float32), 'eval/episode_reward_linvel': Array(1144.1547, dtype=float32), 'eval/episode_reward_quadctrl': Array(-383.78232, dtype=float32), 'eval/episode_x_position': Array(3758.639, dtype=float32), 'eval/episode_x_velocity': Array(228.83095, dtype=float32), 'eval/episode_y_position': Array(14.850348, dtype=float32), 'eval/episode_y_velocity': Array(-14.137739, dtype=float32), 'eval/episode_distance_from_origin_std': Array(240.10748, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0082211, dtype=float32), 'eval/episode_forward_reward_std': Array(501.36783, dtype=float32), 'eval/episode_reward_std': Array(531.1451, dtype=float32), 'eval/episode_reward_alive_std': Array(95.01621, dtype=float32), 'eval/episode_reward_linvel_std': Array(501.36783, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.30981, dtype=float32), 'eval/episode_x_position_std': Array(241.05254, dtype=float32), 'eval/episode_x_velocity_std': Array(100.2736, dtype=float32), 'eval/episode_y_position_std': Array(193.1536, dtype=float32), 'eval/episode_y_velocity_std': Array(57.71025, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6150722503662, 'eval/sps': 936.9390792065908, 'num_steps': 4505600}
{'eval/walltime': 7817.825605392456, 'training/sps': 2942.0545921052567, 'training/walltime': 1582.7023267745972, 'training/entropy_loss': Array(0.00982865, dtype=float32), 'training/policy_loss': Array(0.04767602, dtype=float32), 'training/total_loss': Array(0.11973715, dtype=float32), 'training/v_loss': Array(0.06223248, dtype=float32), 'eval/episode_distance_from_origin': Array(3804.7944, dtype=float32), 'eval/episode_distance_reward': Array(6.7373514, dtype=float32), 'eval/episode_forward_reward': Array(1122.8896, dtype=float32), 'eval/episode_reward': Array(1054.7256, dtype=float32), 'eval/episode_reward_alive': Array(321.28125, dtype=float32), 'eval/episode_reward_linvel': Array(1122.8896, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.18262, dtype=float32), 'eval/episode_x_position': Array(3768.742, dtype=float32), 'eval/episode_x_velocity': Array(224.57793, dtype=float32), 'eval/episode_y_position': Array(85.79737, dtype=float32), 'eval/episode_y_velocity': Array(11.148594, dtype=float32), 'eval/episode_distance_from_origin_std': Array(234.07451, dtype=float32), 'eval/episode_distance_reward_std': Array(3.01403, dtype=float32), 'eval/episode_forward_reward_std': Array(502.33618, dtype=float32), 'eval/episode_reward_std': Array(524.32904, dtype=float32), 'eval/episode_reward_alive_std': Array(96.34321, dtype=float32), 'eval/episode_reward_linvel_std': Array(502.33618, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.34358, dtype=float32), 'eval/episode_x_position_std': Array(236.24088, dtype=float32), 'eval/episode_x_velocity_std': Array(100.46725, dtype=float32), 'eval/episode_y_position_std': Array(152.43332, dtype=float32), 'eval/episode_y_velocity_std': Array(44.348213, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.81231927871704, 'eval/sps': 935.5882618964715, 'num_steps': 4587520}
{'eval/walltime': 7954.526916027069, 'training/sps': 2931.541872996329, 'training/walltime': 1610.6466658115387, 'training/entropy_loss': Array(0.00888965, dtype=float32), 'training/policy_loss': Array(0.07171758, dtype=float32), 'training/total_loss': Array(0.13960263, dtype=float32), 'training/v_loss': Array(0.05899541, dtype=float32), 'eval/episode_distance_from_origin': Array(3918.7183, dtype=float32), 'eval/episode_distance_reward': Array(8.00164, dtype=float32), 'eval/episode_forward_reward': Array(1333.603, dtype=float32), 'eval/episode_reward': Array(1275.3557, dtype=float32), 'eval/episode_reward_alive': Array(319.55078, dtype=float32), 'eval/episode_reward_linvel': Array(1333.603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-385.7999, dtype=float32), 'eval/episode_x_position': Array(3881.4568, dtype=float32), 'eval/episode_x_velocity': Array(266.72064, dtype=float32), 'eval/episode_y_position': Array(31.462385, dtype=float32), 'eval/episode_y_velocity': Array(-5.128651, dtype=float32), 'eval/episode_distance_from_origin_std': Array(233.03111, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0086687, dtype=float32), 'eval/episode_forward_reward_std': Array(501.44177, dtype=float32), 'eval/episode_reward_std': Array(519.44116, dtype=float32), 'eval/episode_reward_alive_std': Array(75.2911, dtype=float32), 'eval/episode_reward_linvel_std': Array(501.44177, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.40754, dtype=float32), 'eval/episode_x_position_std': Array(235.95114, dtype=float32), 'eval/episode_x_velocity_std': Array(100.28835, dtype=float32), 'eval/episode_y_position_std': Array(191.35144, dtype=float32), 'eval/episode_y_velocity_std': Array(59.834305, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70131063461304, 'eval/sps': 936.3480087043888, 'num_steps': 4669440}
{'eval/walltime': 8091.099217414856, 'training/sps': 2948.4511029985565, 'training/walltime': 1638.4307453632355, 'training/entropy_loss': Array(0.00855877, dtype=float32), 'training/policy_loss': Array(0.08069869, dtype=float32), 'training/total_loss': Array(0.15548608, dtype=float32), 'training/v_loss': Array(0.06622861, dtype=float32), 'eval/episode_distance_from_origin': Array(3982.457, dtype=float32), 'eval/episode_distance_reward': Array(9.04359, dtype=float32), 'eval/episode_forward_reward': Array(1507.2603, dtype=float32), 'eval/episode_reward': Array(1464.2979, dtype=float32), 'eval/episode_reward_alive': Array(317.5664, dtype=float32), 'eval/episode_reward_linvel': Array(1507.2603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-369.57233, dtype=float32), 'eval/episode_x_position': Array(3946.9119, dtype=float32), 'eval/episode_x_velocity': Array(301.45203, dtype=float32), 'eval/episode_y_position': Array(29.779352, dtype=float32), 'eval/episode_y_velocity': Array(-4.1615114, dtype=float32), 'eval/episode_distance_from_origin_std': Array(224.39737, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8677688, dtype=float32), 'eval/episode_forward_reward_std': Array(477.95782, dtype=float32), 'eval/episode_reward_std': Array(480.8014, dtype=float32), 'eval/episode_reward_alive_std': Array(55.379173, dtype=float32), 'eval/episode_reward_linvel_std': Array(477.95782, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.585083, dtype=float32), 'eval/episode_x_position_std': Array(224.481, dtype=float32), 'eval/episode_x_velocity_std': Array(95.591576, dtype=float32), 'eval/episode_y_position_std': Array(170.38905, dtype=float32), 'eval/episode_y_velocity_std': Array(57.113644, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57230138778687, 'eval/sps': 937.2325039508088, 'num_steps': 4751360}
{'eval/walltime': 8227.649457216263, 'training/sps': 2937.7808226278153, 'training/walltime': 1666.3157391548157, 'training/entropy_loss': Array(0.00703643, dtype=float32), 'training/policy_loss': Array(0.1158186, dtype=float32), 'training/total_loss': Array(0.1913926, dtype=float32), 'training/v_loss': Array(0.06853758, dtype=float32), 'eval/episode_distance_from_origin': Array(3979.9033, dtype=float32), 'eval/episode_distance_reward': Array(9.076384, dtype=float32), 'eval/episode_forward_reward': Array(1512.7257, dtype=float32), 'eval/episode_reward': Array(1494.3215, dtype=float32), 'eval/episode_reward_alive': Array(332.7422, dtype=float32), 'eval/episode_reward_linvel': Array(1512.7257, dtype=float32), 'eval/episode_reward_quadctrl': Array(-360.22266, dtype=float32), 'eval/episode_x_position': Array(3943.9526, dtype=float32), 'eval/episode_x_velocity': Array(302.5451, dtype=float32), 'eval/episode_y_position': Array(84.94587, dtype=float32), 'eval/episode_y_velocity': Array(24.149818, dtype=float32), 'eval/episode_distance_from_origin_std': Array(215.32219, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8408728, dtype=float32), 'eval/episode_forward_reward_std': Array(473.47534, dtype=float32), 'eval/episode_reward_std': Array(486.05923, dtype=float32), 'eval/episode_reward_alive_std': Array(54.631397, dtype=float32), 'eval/episode_reward_linvel_std': Array(473.47534, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.416885, dtype=float32), 'eval/episode_x_position_std': Array(215.76697, dtype=float32), 'eval/episode_x_velocity_std': Array(94.69507, dtype=float32), 'eval/episode_y_position_std': Array(154.00581, dtype=float32), 'eval/episode_y_velocity_std': Array(55.035137, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55023980140686, 'eval/sps': 937.3839268693927, 'num_steps': 4833280}
{'eval/walltime': 8364.526623249054, 'training/sps': 2948.236363590809, 'training/walltime': 1694.1018424034119, 'training/entropy_loss': Array(0.00725551, dtype=float32), 'training/policy_loss': Array(0.04485366, dtype=float32), 'training/total_loss': Array(0.10506541, dtype=float32), 'training/v_loss': Array(0.05295623, dtype=float32), 'eval/episode_distance_from_origin': Array(4011.159, dtype=float32), 'eval/episode_distance_reward': Array(9.535479, dtype=float32), 'eval/episode_forward_reward': Array(1589.2411, dtype=float32), 'eval/episode_reward': Array(1576.2301, dtype=float32), 'eval/episode_reward_alive': Array(333.82422, dtype=float32), 'eval/episode_reward_linvel': Array(1589.2411, dtype=float32), 'eval/episode_reward_quadctrl': Array(-356.37076, dtype=float32), 'eval/episode_x_position': Array(3973.901, dtype=float32), 'eval/episode_x_velocity': Array(317.8482, dtype=float32), 'eval/episode_y_position': Array(83.48658, dtype=float32), 'eval/episode_y_velocity': Array(23.081753, dtype=float32), 'eval/episode_distance_from_origin_std': Array(209.8998, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7809622, dtype=float32), 'eval/episode_forward_reward_std': Array(463.49048, dtype=float32), 'eval/episode_reward_std': Array(461.4028, dtype=float32), 'eval/episode_reward_alive_std': Array(48.58673, dtype=float32), 'eval/episode_reward_linvel_std': Array(463.49048, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.691769, dtype=float32), 'eval/episode_x_position_std': Array(210.61607, dtype=float32), 'eval/episode_x_velocity_std': Array(92.69808, dtype=float32), 'eval/episode_y_position_std': Array(176.48737, dtype=float32), 'eval/episode_y_velocity_std': Array(60.23929, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.87716603279114, 'eval/sps': 935.1450187778985, 'num_steps': 4915200}
{'eval/walltime': 8500.909317493439, 'training/sps': 2948.9716368391705, 'training/walltime': 1721.8810176849365, 'training/entropy_loss': Array(0.00722284, dtype=float32), 'training/policy_loss': Array(0.018195, dtype=float32), 'training/total_loss': Array(0.08014381, dtype=float32), 'training/v_loss': Array(0.05472597, dtype=float32), 'eval/episode_distance_from_origin': Array(4033.3706, dtype=float32), 'eval/episode_distance_reward': Array(9.857681, dtype=float32), 'eval/episode_forward_reward': Array(1642.941, dtype=float32), 'eval/episode_reward': Array(1629.9348, dtype=float32), 'eval/episode_reward_alive': Array(335.33984, dtype=float32), 'eval/episode_reward_linvel': Array(1642.941, dtype=float32), 'eval/episode_reward_quadctrl': Array(-358.2038, dtype=float32), 'eval/episode_x_position': Array(3996.7983, dtype=float32), 'eval/episode_x_velocity': Array(328.5882, dtype=float32), 'eval/episode_y_position': Array(76.136024, dtype=float32), 'eval/episode_y_velocity': Array(16.342987, dtype=float32), 'eval/episode_distance_from_origin_std': Array(214.78326, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7983785, dtype=float32), 'eval/episode_forward_reward_std': Array(466.39285, dtype=float32), 'eval/episode_reward_std': Array(474.88855, dtype=float32), 'eval/episode_reward_alive_std': Array(46.059444, dtype=float32), 'eval/episode_reward_linvel_std': Array(466.39285, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.663122, dtype=float32), 'eval/episode_x_position_std': Array(215.70378, dtype=float32), 'eval/episode_x_velocity_std': Array(93.2786, dtype=float32), 'eval/episode_y_position_std': Array(172.01938, dtype=float32), 'eval/episode_y_velocity_std': Array(58.830917, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38269424438477, 'eval/sps': 938.535499017465, 'num_steps': 4997120}
{'eval/walltime': 8637.84597992897, 'training/sps': 2948.9580201472013, 'training/walltime': 1749.6603212356567, 'training/entropy_loss': Array(0.00758267, dtype=float32), 'training/policy_loss': Array(0.01009228, dtype=float32), 'training/total_loss': Array(0.06521691, dtype=float32), 'training/v_loss': Array(0.04754196, dtype=float32), 'eval/episode_distance_from_origin': Array(4072.8518, dtype=float32), 'eval/episode_distance_reward': Array(10.308632, dtype=float32), 'eval/episode_forward_reward': Array(1718.0988, dtype=float32), 'eval/episode_reward': Array(1708.5123, dtype=float32), 'eval/episode_reward_alive': Array(343.375, dtype=float32), 'eval/episode_reward_linvel': Array(1718.0988, dtype=float32), 'eval/episode_reward_quadctrl': Array(-363.27008, dtype=float32), 'eval/episode_x_position': Array(4038.3547, dtype=float32), 'eval/episode_x_velocity': Array(343.61975, dtype=float32), 'eval/episode_y_position': Array(19.078285, dtype=float32), 'eval/episode_y_velocity': Array(-3.3565502, dtype=float32), 'eval/episode_distance_from_origin_std': Array(250.48398, dtype=float32), 'eval/episode_distance_reward_std': Array(3.1964383, dtype=float32), 'eval/episode_forward_reward_std': Array(532.7361, dtype=float32), 'eval/episode_reward_std': Array(538.8991, dtype=float32), 'eval/episode_reward_alive_std': Array(47.3392, dtype=float32), 'eval/episode_reward_linvel_std': Array(532.7361, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.250183, dtype=float32), 'eval/episode_x_position_std': Array(250.24928, dtype=float32), 'eval/episode_x_velocity_std': Array(106.54722, dtype=float32), 'eval/episode_y_position_std': Array(148.41684, dtype=float32), 'eval/episode_y_velocity_std': Array(56.10292, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.93666243553162, 'eval/sps': 934.7387158662575, 'num_steps': 5079040}
{'eval/walltime': 8774.375918149948, 'training/sps': 2946.643770601418, 'training/walltime': 1777.461442232132, 'training/entropy_loss': Array(0.00752158, dtype=float32), 'training/policy_loss': Array(0.02473904, dtype=float32), 'training/total_loss': Array(0.08971976, dtype=float32), 'training/v_loss': Array(0.05745914, dtype=float32), 'eval/episode_distance_from_origin': Array(4143.845, dtype=float32), 'eval/episode_distance_reward': Array(10.635868, dtype=float32), 'eval/episode_forward_reward': Array(1772.6375, dtype=float32), 'eval/episode_reward': Array(1765.066, dtype=float32), 'eval/episode_reward_alive': Array(338.22266, dtype=float32), 'eval/episode_reward_linvel': Array(1772.6375, dtype=float32), 'eval/episode_reward_quadctrl': Array(-356.43018, dtype=float32), 'eval/episode_x_position': Array(4107.6914, dtype=float32), 'eval/episode_x_velocity': Array(354.5275, dtype=float32), 'eval/episode_y_position': Array(-25.18233, dtype=float32), 'eval/episode_y_velocity': Array(-12.493687, dtype=float32), 'eval/episode_distance_from_origin_std': Array(232.23695, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9556143, dtype=float32), 'eval/episode_forward_reward_std': Array(492.5986, dtype=float32), 'eval/episode_reward_std': Array(491.79492, dtype=float32), 'eval/episode_reward_alive_std': Array(49.393303, dtype=float32), 'eval/episode_reward_linvel_std': Array(492.5986, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.699444, dtype=float32), 'eval/episode_x_position_std': Array(231.80116, dtype=float32), 'eval/episode_x_velocity_std': Array(98.519684, dtype=float32), 'eval/episode_y_position_std': Array(185.77115, dtype=float32), 'eval/episode_y_velocity_std': Array(70.45101, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52993822097778, 'eval/sps': 937.5233129661875, 'num_steps': 5160960}
{'eval/walltime': 8911.133795022964, 'training/sps': 2946.765071645315, 'training/walltime': 1805.2614188194275, 'training/entropy_loss': Array(0.00436446, dtype=float32), 'training/policy_loss': Array(-0.00285171, dtype=float32), 'training/total_loss': Array(0.05517142, dtype=float32), 'training/v_loss': Array(0.05365867, dtype=float32), 'eval/episode_distance_from_origin': Array(4156.038, dtype=float32), 'eval/episode_distance_reward': Array(10.635008, dtype=float32), 'eval/episode_forward_reward': Array(1772.4937, dtype=float32), 'eval/episode_reward': Array(1757.5056, dtype=float32), 'eval/episode_reward_alive': Array(337.66016, dtype=float32), 'eval/episode_reward_linvel': Array(1772.4937, dtype=float32), 'eval/episode_reward_quadctrl': Array(-363.28323, dtype=float32), 'eval/episode_x_position': Array(4120.56, dtype=float32), 'eval/episode_x_velocity': Array(354.49872, dtype=float32), 'eval/episode_y_position': Array(-14.04684, dtype=float32), 'eval/episode_y_velocity': Array(-18.859581, dtype=float32), 'eval/episode_distance_from_origin_std': Array(258.11975, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3676763, dtype=float32), 'eval/episode_forward_reward_std': Array(561.2749, dtype=float32), 'eval/episode_reward_std': Array(569.5526, dtype=float32), 'eval/episode_reward_alive_std': Array(53.646297, dtype=float32), 'eval/episode_reward_linvel_std': Array(561.2749, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.525936, dtype=float32), 'eval/episode_x_position_std': Array(258.60733, dtype=float32), 'eval/episode_x_velocity_std': Array(112.25498, dtype=float32), 'eval/episode_y_position_std': Array(188.33603, dtype=float32), 'eval/episode_y_velocity_std': Array(58.130123, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.75787687301636, 'eval/sps': 935.9607133916805, 'num_steps': 5242880}
{'eval/walltime': 9047.523788928986, 'training/sps': 2950.539231723711, 'training/walltime': 1833.02583527565, 'training/entropy_loss': Array(0.00719724, dtype=float32), 'training/policy_loss': Array(0.01898364, dtype=float32), 'training/total_loss': Array(0.10678566, dtype=float32), 'training/v_loss': Array(0.08060478, dtype=float32), 'eval/episode_distance_from_origin': Array(4166.7285, dtype=float32), 'eval/episode_distance_reward': Array(10.604553, dtype=float32), 'eval/episode_forward_reward': Array(1767.4181, dtype=float32), 'eval/episode_reward': Array(1737.3662, dtype=float32), 'eval/episode_reward_alive': Array(328.1211, dtype=float32), 'eval/episode_reward_linvel': Array(1767.4181, dtype=float32), 'eval/episode_reward_quadctrl': Array(-368.77777, dtype=float32), 'eval/episode_x_position': Array(4129.4966, dtype=float32), 'eval/episode_x_velocity': Array(353.4837, dtype=float32), 'eval/episode_y_position': Array(-67.34182, dtype=float32), 'eval/episode_y_velocity': Array(-26.073992, dtype=float32), 'eval/episode_distance_from_origin_std': Array(277.44907, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3488295, dtype=float32), 'eval/episode_forward_reward_std': Array(558.1337, dtype=float32), 'eval/episode_reward_std': Array(577.60297, dtype=float32), 'eval/episode_reward_alive_std': Array(62.473766, dtype=float32), 'eval/episode_reward_linvel_std': Array(558.1337, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.808372, dtype=float32), 'eval/episode_x_position_std': Array(278.59137, dtype=float32), 'eval/episode_x_velocity_std': Array(111.62679, dtype=float32), 'eval/episode_y_position_std': Array(204.68198, dtype=float32), 'eval/episode_y_velocity_std': Array(66.98277, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38999390602112, 'eval/sps': 938.4852681216321, 'num_steps': 5324800}
{'eval/walltime': 9184.246881246567, 'training/sps': 2953.5835031305774, 'training/walltime': 1860.7616348266602, 'training/entropy_loss': Array(0.00618753, dtype=float32), 'training/policy_loss': Array(0.01807107, dtype=float32), 'training/total_loss': Array(0.09132427, dtype=float32), 'training/v_loss': Array(0.06706566, dtype=float32), 'eval/episode_distance_from_origin': Array(4199.1006, dtype=float32), 'eval/episode_distance_reward': Array(10.7222595, dtype=float32), 'eval/episode_forward_reward': Array(1787.0359, dtype=float32), 'eval/episode_reward': Array(1769.2776, dtype=float32), 'eval/episode_reward_alive': Array(334.26172, dtype=float32), 'eval/episode_reward_linvel': Array(1787.0359, dtype=float32), 'eval/episode_reward_quadctrl': Array(-362.7422, dtype=float32), 'eval/episode_x_position': Array(4161.7993, dtype=float32), 'eval/episode_x_velocity': Array(357.4071, dtype=float32), 'eval/episode_y_position': Array(-79.77241, dtype=float32), 'eval/episode_y_velocity': Array(-29.35332, dtype=float32), 'eval/episode_distance_from_origin_std': Array(249.39699, dtype=float32), 'eval/episode_distance_reward_std': Array(3.151167, dtype=float32), 'eval/episode_forward_reward_std': Array(525.1903, dtype=float32), 'eval/episode_reward_std': Array(531.96014, dtype=float32), 'eval/episode_reward_alive_std': Array(61.47017, dtype=float32), 'eval/episode_reward_linvel_std': Array(525.1903, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.775417, dtype=float32), 'eval/episode_x_position_std': Array(248.37656, dtype=float32), 'eval/episode_x_velocity_std': Array(105.03804, dtype=float32), 'eval/episode_y_position_std': Array(202.75067, dtype=float32), 'eval/episode_y_velocity_std': Array(66.008415, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.72309231758118, 'eval/sps': 936.1988368627655, 'num_steps': 5406720}
{'eval/walltime': 9320.822926044464, 'training/sps': 2941.605423176834, 'training/walltime': 1888.6103732585907, 'training/entropy_loss': Array(0.00729029, dtype=float32), 'training/policy_loss': Array(0.01403041, dtype=float32), 'training/total_loss': Array(0.08710821, dtype=float32), 'training/v_loss': Array(0.06578751, dtype=float32), 'eval/episode_distance_from_origin': Array(4208.506, dtype=float32), 'eval/episode_distance_reward': Array(10.887438, dtype=float32), 'eval/episode_forward_reward': Array(1814.5652, dtype=float32), 'eval/episode_reward': Array(1791.0382, dtype=float32), 'eval/episode_reward_alive': Array(329.8203, dtype=float32), 'eval/episode_reward_linvel': Array(1814.5652, dtype=float32), 'eval/episode_reward_quadctrl': Array(-364.23477, dtype=float32), 'eval/episode_x_position': Array(4169.6226, dtype=float32), 'eval/episode_x_velocity': Array(362.91302, dtype=float32), 'eval/episode_y_position': Array(-121.858, dtype=float32), 'eval/episode_y_velocity': Array(-49.48792, dtype=float32), 'eval/episode_distance_from_origin_std': Array(267.55106, dtype=float32), 'eval/episode_distance_reward_std': Array(3.4420724, dtype=float32), 'eval/episode_forward_reward_std': Array(573.6744, dtype=float32), 'eval/episode_reward_std': Array(582.2517, dtype=float32), 'eval/episode_reward_alive_std': Array(59.00218, dtype=float32), 'eval/episode_reward_linvel_std': Array(573.6744, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.1783, dtype=float32), 'eval/episode_x_position_std': Array(267.693, dtype=float32), 'eval/episode_x_velocity_std': Array(114.73486, dtype=float32), 'eval/episode_y_position_std': Array(201.86932, dtype=float32), 'eval/episode_y_velocity_std': Array(70.24413, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57604479789734, 'eval/sps': 937.2068153636459, 'num_steps': 5488640}
{'eval/walltime': 9457.667205810547, 'training/sps': 2942.278182412138, 'training/walltime': 1916.4527440071106, 'training/entropy_loss': Array(0.00695925, dtype=float32), 'training/policy_loss': Array(0.00460094, dtype=float32), 'training/total_loss': Array(0.08096414, dtype=float32), 'training/v_loss': Array(0.06940396, dtype=float32), 'eval/episode_distance_from_origin': Array(4231.6543, dtype=float32), 'eval/episode_distance_reward': Array(11.069257, dtype=float32), 'eval/episode_forward_reward': Array(1844.8679, dtype=float32), 'eval/episode_reward': Array(1825.7886, dtype=float32), 'eval/episode_reward_alive': Array(333.91016, dtype=float32), 'eval/episode_reward_linvel': Array(1844.8679, dtype=float32), 'eval/episode_reward_quadctrl': Array(-364.05878, dtype=float32), 'eval/episode_x_position': Array(4192.079, dtype=float32), 'eval/episode_x_velocity': Array(368.97363, dtype=float32), 'eval/episode_y_position': Array(-115.48704, dtype=float32), 'eval/episode_y_velocity': Array(-52.267517, dtype=float32), 'eval/episode_distance_from_origin_std': Array(312.19763, dtype=float32), 'eval/episode_distance_reward_std': Array(3.9196086, dtype=float32), 'eval/episode_forward_reward_std': Array(653.26294, dtype=float32), 'eval/episode_reward_std': Array(664.49365, dtype=float32), 'eval/episode_reward_alive_std': Array(61.88391, dtype=float32), 'eval/episode_reward_linvel_std': Array(653.26294, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.06051, dtype=float32), 'eval/episode_x_position_std': Array(311.65564, dtype=float32), 'eval/episode_x_velocity_std': Array(130.65262, dtype=float32), 'eval/episode_y_position_std': Array(227.28464, dtype=float32), 'eval/episode_y_velocity_std': Array(71.52883, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84427976608276, 'eval/sps': 935.3697517996303, 'num_steps': 5570560}
{'eval/walltime': 9594.293818712234, 'training/sps': 2939.5098730341933, 'training/walltime': 1944.321335554123, 'training/entropy_loss': Array(0.00866151, dtype=float32), 'training/policy_loss': Array(0.1147953, dtype=float32), 'training/total_loss': Array(0.18024963, dtype=float32), 'training/v_loss': Array(0.05679283, dtype=float32), 'eval/episode_distance_from_origin': Array(4294.0117, dtype=float32), 'eval/episode_distance_reward': Array(10.982784, dtype=float32), 'eval/episode_forward_reward': Array(1830.4564, dtype=float32), 'eval/episode_reward': Array(1781.5767, dtype=float32), 'eval/episode_reward_alive': Array(355.91797, dtype=float32), 'eval/episode_reward_linvel': Array(1830.4564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.78052, dtype=float32), 'eval/episode_x_position': Array(4251.1934, dtype=float32), 'eval/episode_x_velocity': Array(366.0913, dtype=float32), 'eval/episode_y_position': Array(-214.10873, dtype=float32), 'eval/episode_y_velocity': Array(-76.31763, dtype=float32), 'eval/episode_distance_from_origin_std': Array(305.03006, dtype=float32), 'eval/episode_distance_reward_std': Array(3.9408097, dtype=float32), 'eval/episode_forward_reward_std': Array(656.7964, dtype=float32), 'eval/episode_reward_std': Array(683.2087, dtype=float32), 'eval/episode_reward_alive_std': Array(57.505222, dtype=float32), 'eval/episode_reward_linvel_std': Array(656.7964, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.72265, dtype=float32), 'eval/episode_x_position_std': Array(301.601, dtype=float32), 'eval/episode_x_velocity_std': Array(131.35927, dtype=float32), 'eval/episode_y_position_std': Array(217.29976, dtype=float32), 'eval/episode_y_velocity_std': Array(71.75013, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62661290168762, 'eval/sps': 936.8599373249846, 'num_steps': 5652480}
{'eval/walltime': 9730.95030450821, 'training/sps': 2943.3753379435657, 'training/walltime': 1972.1533279418945, 'training/entropy_loss': Array(0.00561005, dtype=float32), 'training/policy_loss': Array(0.00425906, dtype=float32), 'training/total_loss': Array(0.07907711, dtype=float32), 'training/v_loss': Array(0.06920798, dtype=float32), 'eval/episode_distance_from_origin': Array(4225.286, dtype=float32), 'eval/episode_distance_reward': Array(10.464233, dtype=float32), 'eval/episode_forward_reward': Array(1744.0317, dtype=float32), 'eval/episode_reward': Array(1697.3256, dtype=float32), 'eval/episode_reward_alive': Array(356.4297, dtype=float32), 'eval/episode_reward_linvel': Array(1744.0317, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.6001, dtype=float32), 'eval/episode_x_position': Array(4184.4287, dtype=float32), 'eval/episode_x_velocity': Array(348.80634, dtype=float32), 'eval/episode_y_position': Array(-170.2473, dtype=float32), 'eval/episode_y_velocity': Array(-62.124504, dtype=float32), 'eval/episode_distance_from_origin_std': Array(342.2139, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2302494, dtype=float32), 'eval/episode_forward_reward_std': Array(705.03577, dtype=float32), 'eval/episode_reward_std': Array(723.5404, dtype=float32), 'eval/episode_reward_alive_std': Array(60.49389, dtype=float32), 'eval/episode_reward_linvel_std': Array(705.03577, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.10203, dtype=float32), 'eval/episode_x_position_std': Array(341.8739, dtype=float32), 'eval/episode_x_velocity_std': Array(141.00719, dtype=float32), 'eval/episode_y_position_std': Array(213.87177, dtype=float32), 'eval/episode_y_velocity_std': Array(72.63952, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65648579597473, 'eval/sps': 936.6551412064065, 'num_steps': 5734400}
{'eval/walltime': 9867.469226360321, 'training/sps': 2948.18551682712, 'training/walltime': 1999.9399104118347, 'training/entropy_loss': Array(0.00968939, dtype=float32), 'training/policy_loss': Array(0.02744422, dtype=float32), 'training/total_loss': Array(0.1092681, dtype=float32), 'training/v_loss': Array(0.07213449, dtype=float32), 'eval/episode_distance_from_origin': Array(4245.162, dtype=float32), 'eval/episode_distance_reward': Array(10.097038, dtype=float32), 'eval/episode_forward_reward': Array(1682.833, dtype=float32), 'eval/episode_reward': Array(1630.0718, dtype=float32), 'eval/episode_reward_alive': Array(361.3086, dtype=float32), 'eval/episode_reward_linvel': Array(1682.833, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.16705, dtype=float32), 'eval/episode_x_position': Array(4201.009, dtype=float32), 'eval/episode_x_velocity': Array(336.56665, dtype=float32), 'eval/episode_y_position': Array(-204.64932, dtype=float32), 'eval/episode_y_velocity': Array(-69.948456, dtype=float32), 'eval/episode_distance_from_origin_std': Array(346.41882, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2141604, dtype=float32), 'eval/episode_forward_reward_std': Array(702.35474, dtype=float32), 'eval/episode_reward_std': Array(714.5758, dtype=float32), 'eval/episode_reward_alive_std': Array(54.951828, dtype=float32), 'eval/episode_reward_linvel_std': Array(702.35474, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.79817, dtype=float32), 'eval/episode_x_position_std': Array(342.74716, dtype=float32), 'eval/episode_x_velocity_std': Array(140.47101, dtype=float32), 'eval/episode_y_position_std': Array(241.25932, dtype=float32), 'eval/episode_y_velocity_std': Array(71.60878, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51892185211182, 'eval/sps': 937.598966234584, 'num_steps': 5816320}
{'eval/walltime': 10004.341495752335, 'training/sps': 2935.0861518838865, 'training/walltime': 2027.8505051136017, 'training/entropy_loss': Array(0.01227944, dtype=float32), 'training/policy_loss': Array(0.05247205, dtype=float32), 'training/total_loss': Array(0.14010039, dtype=float32), 'training/v_loss': Array(0.0753489, dtype=float32), 'eval/episode_distance_from_origin': Array(4327.7256, dtype=float32), 'eval/episode_distance_reward': Array(11.087873, dtype=float32), 'eval/episode_forward_reward': Array(1847.9712, dtype=float32), 'eval/episode_reward': Array(1786.7261, dtype=float32), 'eval/episode_reward_alive': Array(357.79688, dtype=float32), 'eval/episode_reward_linvel': Array(1847.9712, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.12982, dtype=float32), 'eval/episode_x_position': Array(4288.0586, dtype=float32), 'eval/episode_x_velocity': Array(369.59424, dtype=float32), 'eval/episode_y_position': Array(-163.52583, dtype=float32), 'eval/episode_y_velocity': Array(-60.660942, dtype=float32), 'eval/episode_distance_from_origin_std': Array(315.5362, dtype=float32), 'eval/episode_distance_reward_std': Array(3.8412404, dtype=float32), 'eval/episode_forward_reward_std': Array(640.20154, dtype=float32), 'eval/episode_reward_std': Array(659.51294, dtype=float32), 'eval/episode_reward_alive_std': Array(55.265636, dtype=float32), 'eval/episode_reward_linvel_std': Array(640.20154, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.50323, dtype=float32), 'eval/episode_x_position_std': Array(315.3241, dtype=float32), 'eval/episode_x_velocity_std': Array(128.04031, dtype=float32), 'eval/episode_y_position_std': Array(210.00049, dtype=float32), 'eval/episode_y_velocity_std': Array(66.489586, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.87226939201355, 'eval/sps': 935.1784738323975, 'num_steps': 5898240}
{'eval/walltime': 10141.05853152275, 'training/sps': 2935.7040601173203, 'training/walltime': 2055.7552251815796, 'training/entropy_loss': Array(0.01382226, dtype=float32), 'training/policy_loss': Array(0.08795719, dtype=float32), 'training/total_loss': Array(0.15373495, dtype=float32), 'training/v_loss': Array(0.05195551, dtype=float32), 'eval/episode_distance_from_origin': Array(4340.7324, dtype=float32), 'eval/episode_distance_reward': Array(11.013746, dtype=float32), 'eval/episode_forward_reward': Array(1835.617, dtype=float32), 'eval/episode_reward': Array(1781.0558, dtype=float32), 'eval/episode_reward_alive': Array(372.76562, dtype=float32), 'eval/episode_reward_linvel': Array(1835.617, dtype=float32), 'eval/episode_reward_quadctrl': Array(-438.34058, dtype=float32), 'eval/episode_x_position': Array(4303.518, dtype=float32), 'eval/episode_x_velocity': Array(367.1234, dtype=float32), 'eval/episode_y_position': Array(-116.943375, dtype=float32), 'eval/episode_y_velocity': Array(-41.561584, dtype=float32), 'eval/episode_distance_from_origin_std': Array(307.27374, dtype=float32), 'eval/episode_distance_reward_std': Array(4.055142, dtype=float32), 'eval/episode_forward_reward_std': Array(675.8515, dtype=float32), 'eval/episode_reward_std': Array(699.8317, dtype=float32), 'eval/episode_reward_alive_std': Array(51.587376, dtype=float32), 'eval/episode_reward_linvel_std': Array(675.8515, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.047424, dtype=float32), 'eval/episode_x_position_std': Array(306.75275, dtype=float32), 'eval/episode_x_velocity_std': Array(135.1703, dtype=float32), 'eval/episode_y_position_std': Array(216.23131, dtype=float32), 'eval/episode_y_velocity_std': Array(61.477566, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.71703577041626, 'eval/sps': 936.2403103512685, 'num_steps': 5980160}
{'eval/walltime': 10278.05883693695, 'training/sps': 2923.210376774825, 'training/walltime': 2083.7792088985443, 'training/entropy_loss': Array(0.01706438, dtype=float32), 'training/policy_loss': Array(0.03712362, dtype=float32), 'training/total_loss': Array(0.09965715, dtype=float32), 'training/v_loss': Array(0.04546915, dtype=float32), 'eval/episode_distance_from_origin': Array(4301.3916, dtype=float32), 'eval/episode_distance_reward': Array(10.66291, dtype=float32), 'eval/episode_forward_reward': Array(1777.1449, dtype=float32), 'eval/episode_reward': Array(1722.1809, dtype=float32), 'eval/episode_reward_alive': Array(365.03516, dtype=float32), 'eval/episode_reward_linvel': Array(1777.1449, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.6621, dtype=float32), 'eval/episode_x_position': Array(4263.589, dtype=float32), 'eval/episode_x_velocity': Array(355.42896, dtype=float32), 'eval/episode_y_position': Array(-103.76643, dtype=float32), 'eval/episode_y_velocity': Array(-38.69317, dtype=float32), 'eval/episode_distance_from_origin_std': Array(339.29758, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2517953, dtype=float32), 'eval/episode_forward_reward_std': Array(708.6267, dtype=float32), 'eval/episode_reward_std': Array(733.6695, dtype=float32), 'eval/episode_reward_alive_std': Array(61.30002, dtype=float32), 'eval/episode_reward_linvel_std': Array(708.6267, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.745235, dtype=float32), 'eval/episode_x_position_std': Array(340.20288, dtype=float32), 'eval/episode_x_velocity_std': Array(141.72539, dtype=float32), 'eval/episode_y_position_std': Array(224.93683, dtype=float32), 'eval/episode_y_velocity_std': Array(61.928364, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.00030541419983, 'eval/sps': 934.3044864973931, 'num_steps': 6062080}
{'eval/walltime': 10414.779838085175, 'training/sps': 2935.273327540538, 'training/walltime': 2111.6880238056183, 'training/entropy_loss': Array(0.01872931, dtype=float32), 'training/policy_loss': Array(0.06397203, dtype=float32), 'training/total_loss': Array(0.11572525, dtype=float32), 'training/v_loss': Array(0.03302391, dtype=float32), 'eval/episode_distance_from_origin': Array(4229.8525, dtype=float32), 'eval/episode_distance_reward': Array(8.561571, dtype=float32), 'eval/episode_forward_reward': Array(1426.925, dtype=float32), 'eval/episode_reward': Array(1315.9165, dtype=float32), 'eval/episode_reward_alive': Array(382.28906, dtype=float32), 'eval/episode_reward_linvel': Array(1426.925, dtype=float32), 'eval/episode_reward_quadctrl': Array(-501.8593, dtype=float32), 'eval/episode_x_position': Array(4193.595, dtype=float32), 'eval/episode_x_velocity': Array(285.385, dtype=float32), 'eval/episode_y_position': Array(-133.41925, dtype=float32), 'eval/episode_y_velocity': Array(-41.087444, dtype=float32), 'eval/episode_distance_from_origin_std': Array(269.9983, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8262198, dtype=float32), 'eval/episode_forward_reward_std': Array(471.0334, dtype=float32), 'eval/episode_reward_std': Array(481.25433, dtype=float32), 'eval/episode_reward_alive_std': Array(41.36105, dtype=float32), 'eval/episode_reward_linvel_std': Array(471.0334, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.075195, dtype=float32), 'eval/episode_x_position_std': Array(269.58, dtype=float32), 'eval/episode_x_velocity_std': Array(94.206665, dtype=float32), 'eval/episode_y_position_std': Array(187.78815, dtype=float32), 'eval/episode_y_velocity_std': Array(44.75716, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.72100114822388, 'eval/sps': 936.2131561721878, 'num_steps': 6144000}
{'eval/walltime': 10551.62755894661, 'training/sps': 2925.1920425759326, 'training/walltime': 2139.6930227279663, 'training/entropy_loss': Array(0.00622113, dtype=float32), 'training/policy_loss': Array(0.0283429, dtype=float32), 'training/total_loss': Array(0.09936996, dtype=float32), 'training/v_loss': Array(0.06480592, dtype=float32), 'eval/episode_distance_from_origin': Array(4188.8, dtype=float32), 'eval/episode_distance_reward': Array(7.996616, dtype=float32), 'eval/episode_forward_reward': Array(1332.7664, dtype=float32), 'eval/episode_reward': Array(1209.6305, dtype=float32), 'eval/episode_reward_alive': Array(377.3672, dtype=float32), 'eval/episode_reward_linvel': Array(1332.7664, dtype=float32), 'eval/episode_reward_quadctrl': Array(-508.49976, dtype=float32), 'eval/episode_x_position': Array(4149.1, dtype=float32), 'eval/episode_x_velocity': Array(266.55325, dtype=float32), 'eval/episode_y_position': Array(-193.74129, dtype=float32), 'eval/episode_y_velocity': Array(-52.20433, dtype=float32), 'eval/episode_distance_from_origin_std': Array(289.08356, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8924618, dtype=float32), 'eval/episode_forward_reward_std': Array(482.0737, dtype=float32), 'eval/episode_reward_std': Array(494.88943, dtype=float32), 'eval/episode_reward_alive_std': Array(63.12591, dtype=float32), 'eval/episode_reward_linvel_std': Array(482.0737, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(71.037575, dtype=float32), 'eval/episode_x_position_std': Array(286.95648, dtype=float32), 'eval/episode_x_velocity_std': Array(96.41474, dtype=float32), 'eval/episode_y_position_std': Array(203.09167, dtype=float32), 'eval/episode_y_velocity_std': Array(50.638824, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84772086143494, 'eval/sps': 935.3462315211395, 'num_steps': 6225920}
{'eval/walltime': 10688.527825593948, 'training/sps': 2941.717696254154, 'training/walltime': 2167.540698289871, 'training/entropy_loss': Array(0.00773492, dtype=float32), 'training/policy_loss': Array(0.23805133, dtype=float32), 'training/total_loss': Array(0.32388222, dtype=float32), 'training/v_loss': Array(0.078096, dtype=float32), 'eval/episode_distance_from_origin': Array(4308.594, dtype=float32), 'eval/episode_distance_reward': Array(10.309553, dtype=float32), 'eval/episode_forward_reward': Array(1718.2526, dtype=float32), 'eval/episode_reward': Array(1690.823, dtype=float32), 'eval/episode_reward_alive': Array(393.28516, dtype=float32), 'eval/episode_reward_linvel': Array(1718.2526, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.0242, dtype=float32), 'eval/episode_x_position': Array(4261.785, dtype=float32), 'eval/episode_x_velocity': Array(343.65048, dtype=float32), 'eval/episode_y_position': Array(-264.18152, dtype=float32), 'eval/episode_y_velocity': Array(-84.14151, dtype=float32), 'eval/episode_distance_from_origin_std': Array(462.31537, dtype=float32), 'eval/episode_distance_reward_std': Array(5.554276, dtype=float32), 'eval/episode_forward_reward_std': Array(925.70624, dtype=float32), 'eval/episode_reward_std': Array(961.48016, dtype=float32), 'eval/episode_reward_alive_std': Array(52.886806, dtype=float32), 'eval/episode_reward_linvel_std': Array(925.70624, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.008156, dtype=float32), 'eval/episode_x_position_std': Array(453.79303, dtype=float32), 'eval/episode_x_velocity_std': Array(185.1412, dtype=float32), 'eval/episode_y_position_std': Array(228.48473, dtype=float32), 'eval/episode_y_velocity_std': Array(76.04536, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.90026664733887, 'eval/sps': 934.9872219733045, 'num_steps': 6307840}
{'eval/walltime': 10825.57992386818, 'training/sps': 2926.230335546217, 'training/walltime': 2195.5357604026794, 'training/entropy_loss': Array(0.01325938, dtype=float32), 'training/policy_loss': Array(0.07007205, dtype=float32), 'training/total_loss': Array(0.14853601, dtype=float32), 'training/v_loss': Array(0.06520458, dtype=float32), 'eval/episode_distance_from_origin': Array(4350.8774, dtype=float32), 'eval/episode_distance_reward': Array(10.478182, dtype=float32), 'eval/episode_forward_reward': Array(1746.3572, dtype=float32), 'eval/episode_reward': Array(1718.6819, dtype=float32), 'eval/episode_reward_alive': Array(405.625, dtype=float32), 'eval/episode_reward_linvel': Array(1746.3572, dtype=float32), 'eval/episode_reward_quadctrl': Array(-443.7786, dtype=float32), 'eval/episode_x_position': Array(4303.0757, dtype=float32), 'eval/episode_x_velocity': Array(349.27145, dtype=float32), 'eval/episode_y_position': Array(-258.22717, dtype=float32), 'eval/episode_y_velocity': Array(-81.74985, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.31714, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2895327, dtype=float32), 'eval/episode_forward_reward_std': Array(881.5822, dtype=float32), 'eval/episode_reward_std': Array(918.9193, dtype=float32), 'eval/episode_reward_alive_std': Array(37.4789, dtype=float32), 'eval/episode_reward_linvel_std': Array(881.5822, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.45891, dtype=float32), 'eval/episode_x_position_std': Array(432.47055, dtype=float32), 'eval/episode_x_velocity_std': Array(176.31648, dtype=float32), 'eval/episode_y_position_std': Array(253.44246, dtype=float32), 'eval/episode_y_velocity_std': Array(81.99473, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.05209827423096, 'eval/sps': 933.9514068867564, 'num_steps': 6389760}
{'eval/walltime': 10962.15476489067, 'training/sps': 2949.737993537054, 'training/walltime': 2223.307718515396, 'training/entropy_loss': Array(0.01743111, dtype=float32), 'training/policy_loss': Array(0.0428804, dtype=float32), 'training/total_loss': Array(0.08819261, dtype=float32), 'training/v_loss': Array(0.0278811, dtype=float32), 'eval/episode_distance_from_origin': Array(4340.875, dtype=float32), 'eval/episode_distance_reward': Array(10.855611, dtype=float32), 'eval/episode_forward_reward': Array(1809.2611, dtype=float32), 'eval/episode_reward': Array(1792.1099, dtype=float32), 'eval/episode_reward_alive': Array(398.42188, dtype=float32), 'eval/episode_reward_linvel': Array(1809.2611, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.4287, dtype=float32), 'eval/episode_x_position': Array(4294.7617, dtype=float32), 'eval/episode_x_velocity': Array(361.85223, dtype=float32), 'eval/episode_y_position': Array(-258.51645, dtype=float32), 'eval/episode_y_velocity': Array(-92.84758, dtype=float32), 'eval/episode_distance_from_origin_std': Array(475.60947, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7552533, dtype=float32), 'eval/episode_forward_reward_std': Array(959.2019, dtype=float32), 'eval/episode_reward_std': Array(994.2955, dtype=float32), 'eval/episode_reward_alive_std': Array(46.636284, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.2019, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.68809, dtype=float32), 'eval/episode_x_position_std': Array(467.73502, dtype=float32), 'eval/episode_x_velocity_std': Array(191.84042, dtype=float32), 'eval/episode_y_position_std': Array(219.35655, dtype=float32), 'eval/episode_y_velocity_std': Array(82.29993, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57484102249146, 'eval/sps': 937.2150759371608, 'num_steps': 6471680}
{'eval/walltime': 11099.038215875626, 'training/sps': 2930.245542374799, 'training/walltime': 2251.264420032501, 'training/entropy_loss': Array(0.01771703, dtype=float32), 'training/policy_loss': Array(0.02208423, dtype=float32), 'training/total_loss': Array(0.06261705, dtype=float32), 'training/v_loss': Array(0.02281579, dtype=float32), 'eval/episode_distance_from_origin': Array(4412.2607, dtype=float32), 'eval/episode_distance_reward': Array(11.214171, dtype=float32), 'eval/episode_forward_reward': Array(1869.0215, dtype=float32), 'eval/episode_reward': Array(1856.3416, dtype=float32), 'eval/episode_reward_alive': Array(405.1328, dtype=float32), 'eval/episode_reward_linvel': Array(1869.0215, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.02686, dtype=float32), 'eval/episode_x_position': Array(4363.21, dtype=float32), 'eval/episode_x_velocity': Array(373.80423, dtype=float32), 'eval/episode_y_position': Array(-296.5015, dtype=float32), 'eval/episode_y_velocity': Array(-96.93476, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.9501, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2805834, dtype=float32), 'eval/episode_forward_reward_std': Array(880.0906, dtype=float32), 'eval/episode_reward_std': Array(911.6823, dtype=float32), 'eval/episode_reward_alive_std': Array(40.20414, dtype=float32), 'eval/episode_reward_linvel_std': Array(880.0906, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.4033, dtype=float32), 'eval/episode_x_position_std': Array(400.76517, dtype=float32), 'eval/episode_x_velocity_std': Array(176.0181, dtype=float32), 'eval/episode_y_position_std': Array(231.22964, dtype=float32), 'eval/episode_y_velocity_std': Array(77.13678, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.88345098495483, 'eval/sps': 935.1020819461131, 'num_steps': 6553600}
{'eval/walltime': 11235.661992073059, 'training/sps': 2948.638646079177, 'training/walltime': 2279.0467324256897, 'training/entropy_loss': Array(0.01813232, dtype=float32), 'training/policy_loss': Array(0.02287387, dtype=float32), 'training/total_loss': Array(0.06056079, dtype=float32), 'training/v_loss': Array(0.0195546, dtype=float32), 'eval/episode_distance_from_origin': Array(4454.954, dtype=float32), 'eval/episode_distance_reward': Array(11.583271, dtype=float32), 'eval/episode_forward_reward': Array(1930.5375, dtype=float32), 'eval/episode_reward': Array(1919.1938, dtype=float32), 'eval/episode_reward_alive': Array(408.14844, dtype=float32), 'eval/episode_reward_linvel': Array(1930.5375, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.07526, dtype=float32), 'eval/episode_x_position': Array(4409.9053, dtype=float32), 'eval/episode_x_velocity': Array(386.10745, dtype=float32), 'eval/episode_y_position': Array(-244.5173, dtype=float32), 'eval/episode_y_velocity': Array(-80.82485, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.85764, dtype=float32), 'eval/episode_distance_reward_std': Array(5.406908, dtype=float32), 'eval/episode_forward_reward_std': Array(901.1445, dtype=float32), 'eval/episode_reward_std': Array(932.75995, dtype=float32), 'eval/episode_reward_alive_std': Array(46.968212, dtype=float32), 'eval/episode_reward_linvel_std': Array(901.1445, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.18246, dtype=float32), 'eval/episode_x_position_std': Array(437.3601, dtype=float32), 'eval/episode_x_velocity_std': Array(180.22891, dtype=float32), 'eval/episode_y_position_std': Array(235.07312, dtype=float32), 'eval/episode_y_velocity_std': Array(80.86047, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62377619743347, 'eval/sps': 936.8793892435577, 'num_steps': 6635520}
{'eval/walltime': 11372.432165622711, 'training/sps': 2930.729919623949, 'training/walltime': 2306.998813390732, 'training/entropy_loss': Array(0.00694709, dtype=float32), 'training/policy_loss': Array(0.04624092, dtype=float32), 'training/total_loss': Array(0.10983356, dtype=float32), 'training/v_loss': Array(0.05664556, dtype=float32), 'eval/episode_distance_from_origin': Array(4391.027, dtype=float32), 'eval/episode_distance_reward': Array(10.803244, dtype=float32), 'eval/episode_forward_reward': Array(1800.5337, dtype=float32), 'eval/episode_reward': Array(1783.7456, dtype=float32), 'eval/episode_reward_alive': Array(399.30078, dtype=float32), 'eval/episode_reward_linvel': Array(1800.5337, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.89203, dtype=float32), 'eval/episode_x_position': Array(4346.995, dtype=float32), 'eval/episode_x_velocity': Array(360.1067, dtype=float32), 'eval/episode_y_position': Array(-223.9333, dtype=float32), 'eval/episode_y_velocity': Array(-77.96504, dtype=float32), 'eval/episode_distance_from_origin_std': Array(443.6083, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1104927, dtype=float32), 'eval/episode_forward_reward_std': Array(851.74255, dtype=float32), 'eval/episode_reward_std': Array(889.21985, dtype=float32), 'eval/episode_reward_alive_std': Array(40.789925, dtype=float32), 'eval/episode_reward_linvel_std': Array(851.74255, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.94735, dtype=float32), 'eval/episode_x_position_std': Array(436.37592, dtype=float32), 'eval/episode_x_velocity_std': Array(170.34846, dtype=float32), 'eval/episode_y_position_std': Array(228.8323, dtype=float32), 'eval/episode_y_velocity_std': Array(78.58864, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7701735496521, 'eval/sps': 935.8765634199606, 'num_steps': 6717440}
{'eval/walltime': 11508.769402980804, 'training/sps': 2948.04409109783, 'training/walltime': 2334.7867288589478, 'training/entropy_loss': Array(0.0071229, dtype=float32), 'training/policy_loss': Array(0.00214655, dtype=float32), 'training/total_loss': Array(0.06301708, dtype=float32), 'training/v_loss': Array(0.05374763, dtype=float32), 'eval/episode_distance_from_origin': Array(4375.2207, dtype=float32), 'eval/episode_distance_reward': Array(10.581564, dtype=float32), 'eval/episode_forward_reward': Array(1763.5868, dtype=float32), 'eval/episode_reward': Array(1751.0151, dtype=float32), 'eval/episode_reward_alive': Array(412.98047, dtype=float32), 'eval/episode_reward_linvel': Array(1763.5868, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.13373, dtype=float32), 'eval/episode_x_position': Array(4328.729, dtype=float32), 'eval/episode_x_velocity': Array(352.71738, dtype=float32), 'eval/episode_y_position': Array(-249.44006, dtype=float32), 'eval/episode_y_velocity': Array(-81.47633, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.44565, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3042984, dtype=float32), 'eval/episode_forward_reward_std': Array(884.0429, dtype=float32), 'eval/episode_reward_std': Array(925.61786, dtype=float32), 'eval/episode_reward_alive_std': Array(35.479275, dtype=float32), 'eval/episode_reward_linvel_std': Array(884.0429, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.11582, dtype=float32), 'eval/episode_x_position_std': Array(441.63956, dtype=float32), 'eval/episode_x_velocity_std': Array(176.8086, dtype=float32), 'eval/episode_y_position_std': Array(246.69096, dtype=float32), 'eval/episode_y_velocity_std': Array(83.59284, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33723735809326, 'eval/sps': 938.8484208742232, 'num_steps': 6799360}
{'eval/walltime': 11645.438736438751, 'training/sps': 2937.934252754717, 'training/walltime': 2362.670266389847, 'training/entropy_loss': Array(0.00873388, dtype=float32), 'training/policy_loss': Array(0.0027265, dtype=float32), 'training/total_loss': Array(0.07138277, dtype=float32), 'training/v_loss': Array(0.0599224, dtype=float32), 'eval/episode_distance_from_origin': Array(4444.4307, dtype=float32), 'eval/episode_distance_reward': Array(11.408857, dtype=float32), 'eval/episode_forward_reward': Array(1901.4685, dtype=float32), 'eval/episode_reward': Array(1890.8678, dtype=float32), 'eval/episode_reward_alive': Array(414.1836, dtype=float32), 'eval/episode_reward_linvel': Array(1901.4685, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.19284, dtype=float32), 'eval/episode_x_position': Array(4401.2344, dtype=float32), 'eval/episode_x_velocity': Array(380.29367, dtype=float32), 'eval/episode_y_position': Array(-224.61008, dtype=float32), 'eval/episode_y_velocity': Array(-74.62187, dtype=float32), 'eval/episode_distance_from_origin_std': Array(438.1928, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3817763, dtype=float32), 'eval/episode_forward_reward_std': Array(896.9557, dtype=float32), 'eval/episode_reward_std': Array(936.91046, dtype=float32), 'eval/episode_reward_alive_std': Array(39.01962, dtype=float32), 'eval/episode_reward_linvel_std': Array(896.9557, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.95281, dtype=float32), 'eval/episode_x_position_std': Array(431.26077, dtype=float32), 'eval/episode_x_velocity_std': Array(179.39113, dtype=float32), 'eval/episode_y_position_std': Array(231.30838, dtype=float32), 'eval/episode_y_velocity_std': Array(75.84627, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66933345794678, 'eval/sps': 936.5670905198763, 'num_steps': 6881280}
{'eval/walltime': 11782.042079925537, 'training/sps': 2950.4911938029873, 'training/walltime': 2390.4351348876953, 'training/entropy_loss': Array(0.01147053, dtype=float32), 'training/policy_loss': Array(0.00238237, dtype=float32), 'training/total_loss': Array(0.04448058, dtype=float32), 'training/v_loss': Array(0.03062768, dtype=float32), 'eval/episode_distance_from_origin': Array(4471.1562, dtype=float32), 'eval/episode_distance_reward': Array(11.786157, dtype=float32), 'eval/episode_forward_reward': Array(1964.3506, dtype=float32), 'eval/episode_reward': Array(1957.9656, dtype=float32), 'eval/episode_reward_alive': Array(412.5547, dtype=float32), 'eval/episode_reward_linvel': Array(1964.3506, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.726, dtype=float32), 'eval/episode_x_position': Array(4429.644, dtype=float32), 'eval/episode_x_velocity': Array(392.87018, dtype=float32), 'eval/episode_y_position': Array(-192.30139, dtype=float32), 'eval/episode_y_velocity': Array(-66.226105, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.7181, dtype=float32), 'eval/episode_distance_reward_std': Array(5.719526, dtype=float32), 'eval/episode_forward_reward_std': Array(953.2468, dtype=float32), 'eval/episode_reward_std': Array(997.78925, dtype=float32), 'eval/episode_reward_alive_std': Array(45.0973, dtype=float32), 'eval/episode_reward_linvel_std': Array(953.2468, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.98945, dtype=float32), 'eval/episode_x_position_std': Array(446.38885, dtype=float32), 'eval/episode_x_velocity_std': Array(190.64938, dtype=float32), 'eval/episode_y_position_std': Array(235.82639, dtype=float32), 'eval/episode_y_velocity_std': Array(79.72414, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6033434867859, 'eval/sps': 937.0195247994196, 'num_steps': 6963200}
{'eval/walltime': 11918.644805431366, 'training/sps': 2920.696424794695, 'training/walltime': 2418.483239889145, 'training/entropy_loss': Array(0.01291727, dtype=float32), 'training/policy_loss': Array(0.00380814, dtype=float32), 'training/total_loss': Array(0.03940418, dtype=float32), 'training/v_loss': Array(0.02267877, dtype=float32), 'eval/episode_distance_from_origin': Array(4495.534, dtype=float32), 'eval/episode_distance_reward': Array(12.049831, dtype=float32), 'eval/episode_forward_reward': Array(2008.2964, dtype=float32), 'eval/episode_reward': Array(2007.5542, dtype=float32), 'eval/episode_reward_alive': Array(411.35547, dtype=float32), 'eval/episode_reward_linvel': Array(2008.2964, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.14764, dtype=float32), 'eval/episode_x_position': Array(4453.431, dtype=float32), 'eval/episode_x_velocity': Array(401.6592, dtype=float32), 'eval/episode_y_position': Array(-209.62561, dtype=float32), 'eval/episode_y_velocity': Array(-69.74045, dtype=float32), 'eval/episode_distance_from_origin_std': Array(490.28058, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9080696, dtype=float32), 'eval/episode_forward_reward_std': Array(984.6707, dtype=float32), 'eval/episode_reward_std': Array(1020.94965, dtype=float32), 'eval/episode_reward_alive_std': Array(38.967594, dtype=float32), 'eval/episode_reward_linvel_std': Array(984.6707, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.23609, dtype=float32), 'eval/episode_x_position_std': Array(484.89304, dtype=float32), 'eval/episode_x_velocity_std': Array(196.93413, dtype=float32), 'eval/episode_y_position_std': Array(228.42964, dtype=float32), 'eval/episode_y_velocity_std': Array(79.73658, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60272550582886, 'eval/sps': 937.0237638087112, 'num_steps': 7045120}
{'eval/walltime': 12055.251032352448, 'training/sps': 2947.6500121428494, 'training/walltime': 2446.2748703956604, 'training/entropy_loss': Array(0.01336312, dtype=float32), 'training/policy_loss': Array(0.00272703, dtype=float32), 'training/total_loss': Array(0.03687125, dtype=float32), 'training/v_loss': Array(0.0207811, dtype=float32), 'eval/episode_distance_from_origin': Array(4491.467, dtype=float32), 'eval/episode_distance_reward': Array(11.739151, dtype=float32), 'eval/episode_forward_reward': Array(1956.5168, dtype=float32), 'eval/episode_reward': Array(1950.1309, dtype=float32), 'eval/episode_reward_alive': Array(414.89062, dtype=float32), 'eval/episode_reward_linvel': Array(1956.5168, dtype=float32), 'eval/episode_reward_quadctrl': Array(-433.01584, dtype=float32), 'eval/episode_x_position': Array(4451.5015, dtype=float32), 'eval/episode_x_velocity': Array(391.3034, dtype=float32), 'eval/episode_y_position': Array(-178.24736, dtype=float32), 'eval/episode_y_velocity': Array(-55.412857, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.60168, dtype=float32), 'eval/episode_distance_reward_std': Array(5.439672, dtype=float32), 'eval/episode_forward_reward_std': Array(906.6048, dtype=float32), 'eval/episode_reward_std': Array(944.19464, dtype=float32), 'eval/episode_reward_alive_std': Array(38.278885, dtype=float32), 'eval/episode_reward_linvel_std': Array(906.6048, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.626465, dtype=float32), 'eval/episode_x_position_std': Array(455.94833, dtype=float32), 'eval/episode_x_velocity_std': Array(181.32097, dtype=float32), 'eval/episode_y_position_std': Array(227.45343, dtype=float32), 'eval/episode_y_velocity_std': Array(69.031075, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60622692108154, 'eval/sps': 936.9997465338573, 'num_steps': 7127040}
{'eval/walltime': 12191.915265321732, 'training/sps': 2924.556247173358, 'training/walltime': 2474.2859575748444, 'training/entropy_loss': Array(0.00887707, dtype=float32), 'training/policy_loss': Array(0.00054971, dtype=float32), 'training/total_loss': Array(0.04933199, dtype=float32), 'training/v_loss': Array(0.03990521, dtype=float32), 'eval/episode_distance_from_origin': Array(4434.871, dtype=float32), 'eval/episode_distance_reward': Array(11.430754, dtype=float32), 'eval/episode_forward_reward': Array(1905.1177, dtype=float32), 'eval/episode_reward': Array(1892.1088, dtype=float32), 'eval/episode_reward_alive': Array(409.71875, dtype=float32), 'eval/episode_reward_linvel': Array(1905.1177, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.15817, dtype=float32), 'eval/episode_x_position': Array(4392.658, dtype=float32), 'eval/episode_x_velocity': Array(381.0235, dtype=float32), 'eval/episode_y_position': Array(-190.69977, dtype=float32), 'eval/episode_y_velocity': Array(-67.00185, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.17993, dtype=float32), 'eval/episode_distance_reward_std': Array(5.706167, dtype=float32), 'eval/episode_forward_reward_std': Array(951.0207, dtype=float32), 'eval/episode_reward_std': Array(988.513, dtype=float32), 'eval/episode_reward_alive_std': Array(39.97742, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.0207, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.76013, dtype=float32), 'eval/episode_x_position_std': Array(471.7691, dtype=float32), 'eval/episode_x_velocity_std': Array(190.20413, dtype=float32), 'eval/episode_y_position_std': Array(247.0151, dtype=float32), 'eval/episode_y_velocity_std': Array(80.91068, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66423296928406, 'eval/sps': 936.6020444337372, 'num_steps': 7208960}
{'eval/walltime': 12328.488044261932, 'training/sps': 2949.3060445483366, 'training/walltime': 2502.0619831085205, 'training/entropy_loss': Array(0.00632094, dtype=float32), 'training/policy_loss': Array(0.00072605, dtype=float32), 'training/total_loss': Array(0.06274033, dtype=float32), 'training/v_loss': Array(0.05569332, dtype=float32), 'eval/episode_distance_from_origin': Array(4398.9785, dtype=float32), 'eval/episode_distance_reward': Array(10.809923, dtype=float32), 'eval/episode_forward_reward': Array(1801.647, dtype=float32), 'eval/episode_reward': Array(1787.8362, dtype=float32), 'eval/episode_reward_alive': Array(412.82422, dtype=float32), 'eval/episode_reward_linvel': Array(1801.647, dtype=float32), 'eval/episode_reward_quadctrl': Array(-437.44476, dtype=float32), 'eval/episode_x_position': Array(4357.4795, dtype=float32), 'eval/episode_x_velocity': Array(360.32938, dtype=float32), 'eval/episode_y_position': Array(-204.45285, dtype=float32), 'eval/episode_y_velocity': Array(-66.997025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(456.02054, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5261464, dtype=float32), 'eval/episode_forward_reward_std': Array(921.0177, dtype=float32), 'eval/episode_reward_std': Array(955.84546, dtype=float32), 'eval/episode_reward_alive_std': Array(43.652863, dtype=float32), 'eval/episode_reward_linvel_std': Array(921.0177, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.185715, dtype=float32), 'eval/episode_x_position_std': Array(450.8818, dtype=float32), 'eval/episode_x_velocity_std': Array(184.20354, dtype=float32), 'eval/episode_y_position_std': Array(223.76344, dtype=float32), 'eval/episode_y_velocity_std': Array(74.92376, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5727789402008, 'eval/sps': 937.2292267410444, 'num_steps': 7290880}
{'eval/walltime': 12465.098806619644, 'training/sps': 2932.478533342637, 'training/walltime': 2529.997396469116, 'training/entropy_loss': Array(0.0101373, dtype=float32), 'training/policy_loss': Array(0.00733946, dtype=float32), 'training/total_loss': Array(0.0874633, dtype=float32), 'training/v_loss': Array(0.06998653, dtype=float32), 'eval/episode_distance_from_origin': Array(4526.8154, dtype=float32), 'eval/episode_distance_reward': Array(12.386496, dtype=float32), 'eval/episode_forward_reward': Array(2064.407, dtype=float32), 'eval/episode_reward': Array(2059.542, dtype=float32), 'eval/episode_reward_alive': Array(422.19922, dtype=float32), 'eval/episode_reward_linvel': Array(2064.407, dtype=float32), 'eval/episode_reward_quadctrl': Array(-439.4506, dtype=float32), 'eval/episode_x_position': Array(4485.1084, dtype=float32), 'eval/episode_x_velocity': Array(412.88135, dtype=float32), 'eval/episode_y_position': Array(-182.2486, dtype=float32), 'eval/episode_y_velocity': Array(-66.62062, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.25577, dtype=float32), 'eval/episode_distance_reward_std': Array(5.872178, dtype=float32), 'eval/episode_forward_reward_std': Array(978.68896, dtype=float32), 'eval/episode_reward_std': Array(1022.8284, dtype=float32), 'eval/episode_reward_alive_std': Array(32.28428, dtype=float32), 'eval/episode_reward_linvel_std': Array(978.68896, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.33353, dtype=float32), 'eval/episode_x_position_std': Array(465.7713, dtype=float32), 'eval/episode_x_velocity_std': Array(195.73781, dtype=float32), 'eval/episode_y_position_std': Array(247.00049, dtype=float32), 'eval/episode_y_velocity_std': Array(83.03471, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6107623577118, 'eval/sps': 936.9686384212927, 'num_steps': 7372800}
{'eval/walltime': 12601.674519777298, 'training/sps': 2949.2202268436276, 'training/walltime': 2557.7742302417755, 'training/entropy_loss': Array(0.01161578, dtype=float32), 'training/policy_loss': Array(0.00469229, dtype=float32), 'training/total_loss': Array(0.06337476, dtype=float32), 'training/v_loss': Array(0.0470667, dtype=float32), 'eval/episode_distance_from_origin': Array(4437.6855, dtype=float32), 'eval/episode_distance_reward': Array(11.29287, dtype=float32), 'eval/episode_forward_reward': Array(1882.1372, dtype=float32), 'eval/episode_reward': Array(1870.3296, dtype=float32), 'eval/episode_reward_alive': Array(417.20703, dtype=float32), 'eval/episode_reward_linvel': Array(1882.1372, dtype=float32), 'eval/episode_reward_quadctrl': Array(-440.30746, dtype=float32), 'eval/episode_x_position': Array(4390.8984, dtype=float32), 'eval/episode_x_velocity': Array(376.42743, dtype=float32), 'eval/episode_y_position': Array(-248.97443, dtype=float32), 'eval/episode_y_velocity': Array(-82.60341, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.71393, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7853603, dtype=float32), 'eval/episode_forward_reward_std': Array(964.21967, dtype=float32), 'eval/episode_reward_std': Array(1008.6635, dtype=float32), 'eval/episode_reward_alive_std': Array(36.471817, dtype=float32), 'eval/episode_reward_linvel_std': Array(964.21967, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(74.81005, dtype=float32), 'eval/episode_x_position_std': Array(464.5255, dtype=float32), 'eval/episode_x_velocity_std': Array(192.8439, dtype=float32), 'eval/episode_y_position_std': Array(263.70123, dtype=float32), 'eval/episode_y_velocity_std': Array(85.26293, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5757131576538, 'eval/sps': 937.2090911379347, 'num_steps': 7454720}
{'eval/walltime': 12738.517623662949, 'training/sps': 2923.2110482564904, 'training/walltime': 2585.7982075214386, 'training/entropy_loss': Array(0.01310361, dtype=float32), 'training/policy_loss': Array(0.003678, dtype=float32), 'training/total_loss': Array(0.05551146, dtype=float32), 'training/v_loss': Array(0.03872985, dtype=float32), 'eval/episode_distance_from_origin': Array(4429.1875, dtype=float32), 'eval/episode_distance_reward': Array(11.177796, dtype=float32), 'eval/episode_forward_reward': Array(1862.9585, dtype=float32), 'eval/episode_reward': Array(1850.7234, dtype=float32), 'eval/episode_reward_alive': Array(414.65625, dtype=float32), 'eval/episode_reward_linvel': Array(1862.9585, dtype=float32), 'eval/episode_reward_quadctrl': Array(-438.06903, dtype=float32), 'eval/episode_x_position': Array(4383.9443, dtype=float32), 'eval/episode_x_velocity': Array(372.59167, dtype=float32), 'eval/episode_y_position': Array(-228.69681, dtype=float32), 'eval/episode_y_velocity': Array(-77.171745, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.67413, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7234125, dtype=float32), 'eval/episode_forward_reward_std': Array(953.89484, dtype=float32), 'eval/episode_reward_std': Array(994.0188, dtype=float32), 'eval/episode_reward_alive_std': Array(37.774452, dtype=float32), 'eval/episode_reward_linvel_std': Array(953.89484, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.39277, dtype=float32), 'eval/episode_x_position_std': Array(456.01617, dtype=float32), 'eval/episode_x_velocity_std': Array(190.7789, dtype=float32), 'eval/episode_y_position_std': Array(255.72726, dtype=float32), 'eval/episode_y_velocity_std': Array(85.42266, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84310388565063, 'eval/sps': 935.3777893474256, 'num_steps': 7536640}
{'eval/walltime': 12874.917031764984, 'training/sps': 2945.580564890871, 'training/walltime': 2613.6093633174896, 'training/entropy_loss': Array(0.01321137, dtype=float32), 'training/policy_loss': Array(0.00469334, dtype=float32), 'training/total_loss': Array(0.05250537, dtype=float32), 'training/v_loss': Array(0.03460065, dtype=float32), 'eval/episode_distance_from_origin': Array(4428.822, dtype=float32), 'eval/episode_distance_reward': Array(11.1025305, dtype=float32), 'eval/episode_forward_reward': Array(1850.4143, dtype=float32), 'eval/episode_reward': Array(1833.5469, dtype=float32), 'eval/episode_reward_alive': Array(419.35156, dtype=float32), 'eval/episode_reward_linvel': Array(1850.4143, dtype=float32), 'eval/episode_reward_quadctrl': Array(-447.3216, dtype=float32), 'eval/episode_x_position': Array(4383.202, dtype=float32), 'eval/episode_x_velocity': Array(370.08286, dtype=float32), 'eval/episode_y_position': Array(-251.23184, dtype=float32), 'eval/episode_y_velocity': Array(-84.82765, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.67484, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8349195, dtype=float32), 'eval/episode_forward_reward_std': Array(972.47943, dtype=float32), 'eval/episode_reward_std': Array(1022.6756, dtype=float32), 'eval/episode_reward_alive_std': Array(33.19529, dtype=float32), 'eval/episode_reward_linvel_std': Array(972.47943, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(73.913086, dtype=float32), 'eval/episode_x_position_std': Array(484.07477, dtype=float32), 'eval/episode_x_velocity_std': Array(194.49586, dtype=float32), 'eval/episode_y_position_std': Array(231.9265, dtype=float32), 'eval/episode_y_velocity_std': Array(80.67721, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39940810203552, 'eval/sps': 938.4204944954583, 'num_steps': 7618560}
{'eval/walltime': 13011.55529999733, 'training/sps': 2935.6183298704423, 'training/walltime': 2641.514898300171, 'training/entropy_loss': Array(0.01042476, dtype=float32), 'training/policy_loss': Array(-0.00037916, dtype=float32), 'training/total_loss': Array(0.0425868, dtype=float32), 'training/v_loss': Array(0.0325412, dtype=float32), 'eval/episode_distance_from_origin': Array(4431.0264, dtype=float32), 'eval/episode_distance_reward': Array(10.99572, dtype=float32), 'eval/episode_forward_reward': Array(1832.6128, dtype=float32), 'eval/episode_reward': Array(1810.1919, dtype=float32), 'eval/episode_reward_alive': Array(421.42578, dtype=float32), 'eval/episode_reward_linvel': Array(1832.6128, dtype=float32), 'eval/episode_reward_quadctrl': Array(-454.84235, dtype=float32), 'eval/episode_x_position': Array(4389.7676, dtype=float32), 'eval/episode_x_velocity': Array(366.52252, dtype=float32), 'eval/episode_y_position': Array(-167.24454, dtype=float32), 'eval/episode_y_velocity': Array(-54.890686, dtype=float32), 'eval/episode_distance_from_origin_std': Array(505.41602, dtype=float32), 'eval/episode_distance_reward_std': Array(5.906503, dtype=float32), 'eval/episode_forward_reward_std': Array(984.41003, dtype=float32), 'eval/episode_reward_std': Array(1031.338, dtype=float32), 'eval/episode_reward_alive_std': Array(39.33426, dtype=float32), 'eval/episode_reward_linvel_std': Array(984.41003, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(74.52926, dtype=float32), 'eval/episode_x_position_std': Array(498.91156, dtype=float32), 'eval/episode_x_velocity_std': Array(196.882, dtype=float32), 'eval/episode_y_position_std': Array(253.3182, dtype=float32), 'eval/episode_y_velocity_std': Array(81.51285, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63826823234558, 'eval/sps': 936.780022580082, 'num_steps': 7700480}
{'eval/walltime': 13148.130062580109, 'training/sps': 2923.915901036947, 'training/walltime': 2669.532119989395, 'training/entropy_loss': Array(0.00568167, dtype=float32), 'training/policy_loss': Array(-8.75744e-05, dtype=float32), 'training/total_loss': Array(0.06478302, dtype=float32), 'training/v_loss': Array(0.05918893, dtype=float32), 'eval/episode_distance_from_origin': Array(4510.2295, dtype=float32), 'eval/episode_distance_reward': Array(12.155333, dtype=float32), 'eval/episode_forward_reward': Array(2025.8798, dtype=float32), 'eval/episode_reward': Array(2020.6992, dtype=float32), 'eval/episode_reward_alive': Array(423.8086, dtype=float32), 'eval/episode_reward_linvel': Array(2025.8798, dtype=float32), 'eval/episode_reward_quadctrl': Array(-441.1443, dtype=float32), 'eval/episode_x_position': Array(4463.9, dtype=float32), 'eval/episode_x_velocity': Array(405.17596, dtype=float32), 'eval/episode_y_position': Array(-255.71051, dtype=float32), 'eval/episode_y_velocity': Array(-82.78507, dtype=float32), 'eval/episode_distance_from_origin_std': Array(511.881, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1335545, dtype=float32), 'eval/episode_forward_reward_std': Array(1022.25134, dtype=float32), 'eval/episode_reward_std': Array(1071.397, dtype=float32), 'eval/episode_reward_alive_std': Array(38.809383, dtype=float32), 'eval/episode_reward_linvel_std': Array(1022.25134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.529526, dtype=float32), 'eval/episode_x_position_std': Array(501.73444, dtype=float32), 'eval/episode_x_velocity_std': Array(204.45027, dtype=float32), 'eval/episode_y_position_std': Array(255.85707, dtype=float32), 'eval/episode_y_velocity_std': Array(81.05371, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57476258277893, 'eval/sps': 937.2156142128989, 'num_steps': 7782400}
{'eval/walltime': 13284.724741458893, 'training/sps': 2924.5046706337926, 'training/walltime': 2697.543701171875, 'training/entropy_loss': Array(0.00972158, dtype=float32), 'training/policy_loss': Array(0.00642115, dtype=float32), 'training/total_loss': Array(0.07548296, dtype=float32), 'training/v_loss': Array(0.05934023, dtype=float32), 'eval/episode_distance_from_origin': Array(4494.834, dtype=float32), 'eval/episode_distance_reward': Array(11.71286, dtype=float32), 'eval/episode_forward_reward': Array(1952.135, dtype=float32), 'eval/episode_reward': Array(1939.2455, dtype=float32), 'eval/episode_reward_alive': Array(419.70312, dtype=float32), 'eval/episode_reward_linvel': Array(1952.135, dtype=float32), 'eval/episode_reward_quadctrl': Array(-444.30566, dtype=float32), 'eval/episode_x_position': Array(4447.3076, dtype=float32), 'eval/episode_x_velocity': Array(390.42703, dtype=float32), 'eval/episode_y_position': Array(-235.5706, dtype=float32), 'eval/episode_y_velocity': Array(-77.52309, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.18668, dtype=float32), 'eval/episode_distance_reward_std': Array(5.797378, dtype=float32), 'eval/episode_forward_reward_std': Array(966.2224, dtype=float32), 'eval/episode_reward_std': Array(1015.404, dtype=float32), 'eval/episode_reward_alive_std': Array(36.299988, dtype=float32), 'eval/episode_reward_linvel_std': Array(966.2224, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(71.46947, dtype=float32), 'eval/episode_x_position_std': Array(470.14316, dtype=float32), 'eval/episode_x_velocity_std': Array(193.24446, dtype=float32), 'eval/episode_y_position_std': Array(281.65927, dtype=float32), 'eval/episode_y_velocity_std': Array(88.31602, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59467887878418, 'eval/sps': 937.0789627434082, 'num_steps': 7864320}
{'eval/walltime': 13421.328516483307, 'training/sps': 2944.2119234515867, 'training/walltime': 2725.367785215378, 'training/entropy_loss': Array(0.01217852, dtype=float32), 'training/policy_loss': Array(0.00596014, dtype=float32), 'training/total_loss': Array(0.07348552, dtype=float32), 'training/v_loss': Array(0.05534686, dtype=float32), 'eval/episode_distance_from_origin': Array(4557.4478, dtype=float32), 'eval/episode_distance_reward': Array(12.291761, dtype=float32), 'eval/episode_forward_reward': Array(2048.6182, dtype=float32), 'eval/episode_reward': Array(2043.5448, dtype=float32), 'eval/episode_reward_alive': Array(419.53125, dtype=float32), 'eval/episode_reward_linvel': Array(2048.6182, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.89664, dtype=float32), 'eval/episode_x_position': Array(4509.5596, dtype=float32), 'eval/episode_x_velocity': Array(409.72366, dtype=float32), 'eval/episode_y_position': Array(-260.40167, dtype=float32), 'eval/episode_y_velocity': Array(-88.063286, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.7275, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8158984, dtype=float32), 'eval/episode_forward_reward_std': Array(969.3095, dtype=float32), 'eval/episode_reward_std': Array(1014.7248, dtype=float32), 'eval/episode_reward_alive_std': Array(45.502823, dtype=float32), 'eval/episode_reward_linvel_std': Array(969.3095, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.13712, dtype=float32), 'eval/episode_x_position_std': Array(473.16174, dtype=float32), 'eval/episode_x_velocity_std': Array(193.86192, dtype=float32), 'eval/episode_y_position_std': Array(268.2211, dtype=float32), 'eval/episode_y_velocity_std': Array(85.84969, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60377502441406, 'eval/sps': 937.0165647115068, 'num_steps': 7946240}
{'eval/walltime': 13557.908893823624, 'training/sps': 2932.834119056047, 'training/walltime': 2753.299811601639, 'training/entropy_loss': Array(0.01283186, dtype=float32), 'training/policy_loss': Array(0.02866794, dtype=float32), 'training/total_loss': Array(0.07477244, dtype=float32), 'training/v_loss': Array(0.03327265, dtype=float32), 'eval/episode_distance_from_origin': Array(4423.743, dtype=float32), 'eval/episode_distance_reward': Array(10.177347, dtype=float32), 'eval/episode_forward_reward': Array(1696.219, dtype=float32), 'eval/episode_reward': Array(1658.8105, dtype=float32), 'eval/episode_reward_alive': Array(421.8828, dtype=float32), 'eval/episode_reward_linvel': Array(1696.219, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.46848, dtype=float32), 'eval/episode_x_position': Array(4380.815, dtype=float32), 'eval/episode_x_velocity': Array(339.2438, dtype=float32), 'eval/episode_y_position': Array(-205.2211, dtype=float32), 'eval/episode_y_velocity': Array(-60.738113, dtype=float32), 'eval/episode_distance_from_origin_std': Array(407.52563, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7031517, dtype=float32), 'eval/episode_forward_reward_std': Array(783.8529, dtype=float32), 'eval/episode_reward_std': Array(825.45905, dtype=float32), 'eval/episode_reward_alive_std': Array(32.903, dtype=float32), 'eval/episode_reward_linvel_std': Array(783.8529, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.66482, dtype=float32), 'eval/episode_x_position_std': Array(402.7545, dtype=float32), 'eval/episode_x_velocity_std': Array(156.77058, dtype=float32), 'eval/episode_y_position_std': Array(252.97862, dtype=float32), 'eval/episode_y_velocity_std': Array(70.09032, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58037734031677, 'eval/sps': 937.1770857028965, 'num_steps': 8028160}
{'eval/walltime': 13694.39560174942, 'training/sps': 2941.47245941972, 'training/walltime': 2781.149808883667, 'training/entropy_loss': Array(0.01351972, dtype=float32), 'training/policy_loss': Array(0.00632229, dtype=float32), 'training/total_loss': Array(0.04454693, dtype=float32), 'training/v_loss': Array(0.02470493, dtype=float32), 'eval/episode_distance_from_origin': Array(4460.475, dtype=float32), 'eval/episode_distance_reward': Array(10.618181, dtype=float32), 'eval/episode_forward_reward': Array(1769.6904, dtype=float32), 'eval/episode_reward': Array(1742.2208, dtype=float32), 'eval/episode_reward_alive': Array(431.64844, dtype=float32), 'eval/episode_reward_linvel': Array(1769.6904, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.73636, dtype=float32), 'eval/episode_x_position': Array(4415.377, dtype=float32), 'eval/episode_x_velocity': Array(353.9381, dtype=float32), 'eval/episode_y_position': Array(-216.97716, dtype=float32), 'eval/episode_y_velocity': Array(-66.2287, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.17508, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0947037, dtype=float32), 'eval/episode_forward_reward_std': Array(849.1108, dtype=float32), 'eval/episode_reward_std': Array(897.432, dtype=float32), 'eval/episode_reward_alive_std': Array(28.892672, dtype=float32), 'eval/episode_reward_linvel_std': Array(849.1108, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.86822, dtype=float32), 'eval/episode_x_position_std': Array(412.76733, dtype=float32), 'eval/episode_x_velocity_std': Array(169.82217, dtype=float32), 'eval/episode_y_position_std': Array(275.0703, dtype=float32), 'eval/episode_y_velocity_std': Array(80.89237, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4867079257965, 'eval/sps': 937.8202606336548, 'num_steps': 8110080}
{'eval/walltime': 13830.981243133545, 'training/sps': 2932.060005867066, 'training/walltime': 2809.089209794998, 'training/entropy_loss': Array(0.01400219, dtype=float32), 'training/policy_loss': Array(0.0036609, dtype=float32), 'training/total_loss': Array(0.0446449, dtype=float32), 'training/v_loss': Array(0.02698181, dtype=float32), 'eval/episode_distance_from_origin': Array(4462.4443, dtype=float32), 'eval/episode_distance_reward': Array(10.785933, dtype=float32), 'eval/episode_forward_reward': Array(1797.649, dtype=float32), 'eval/episode_reward': Array(1769.3275, dtype=float32), 'eval/episode_reward_alive': Array(423.6836, dtype=float32), 'eval/episode_reward_linvel': Array(1797.649, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.7909, dtype=float32), 'eval/episode_x_position': Array(4416.8325, dtype=float32), 'eval/episode_x_velocity': Array(359.5298, dtype=float32), 'eval/episode_y_position': Array(-237.05865, dtype=float32), 'eval/episode_y_velocity': Array(-73.47652, dtype=float32), 'eval/episode_distance_from_origin_std': Array(464.6734, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4165177, dtype=float32), 'eval/episode_forward_reward_std': Array(902.7461, dtype=float32), 'eval/episode_reward_std': Array(949.19763, dtype=float32), 'eval/episode_reward_alive_std': Array(41.31996, dtype=float32), 'eval/episode_reward_linvel_std': Array(902.7461, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.10986, dtype=float32), 'eval/episode_x_position_std': Array(452.9059, dtype=float32), 'eval/episode_x_velocity_std': Array(180.5492, dtype=float32), 'eval/episode_y_position_std': Array(263.2274, dtype=float32), 'eval/episode_y_velocity_std': Array(80.970314, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58564138412476, 'eval/sps': 937.1409666702882, 'num_steps': 8192000}
{'eval/walltime': 13967.388110637665, 'training/sps': 2941.4944681205448, 'training/walltime': 2836.9389986991882, 'training/entropy_loss': Array(0.00442812, dtype=float32), 'training/policy_loss': Array(0.00101422, dtype=float32), 'training/total_loss': Array(0.06339542, dtype=float32), 'training/v_loss': Array(0.05795309, dtype=float32), 'eval/episode_distance_from_origin': Array(4449.2744, dtype=float32), 'eval/episode_distance_reward': Array(10.756054, dtype=float32), 'eval/episode_forward_reward': Array(1792.6692, dtype=float32), 'eval/episode_reward': Array(1768.6511, dtype=float32), 'eval/episode_reward_alive': Array(432.35938, dtype=float32), 'eval/episode_reward_linvel': Array(1792.6692, dtype=float32), 'eval/episode_reward_quadctrl': Array(-467.1331, dtype=float32), 'eval/episode_x_position': Array(4406.6567, dtype=float32), 'eval/episode_x_velocity': Array(358.53378, dtype=float32), 'eval/episode_y_position': Array(-184.12991, dtype=float32), 'eval/episode_y_velocity': Array(-62.186226, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.05893, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7100005, dtype=float32), 'eval/episode_forward_reward_std': Array(951.6599, dtype=float32), 'eval/episode_reward_std': Array(995.3621, dtype=float32), 'eval/episode_reward_alive_std': Array(30.577383, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.6599, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.040886, dtype=float32), 'eval/episode_x_position_std': Array(478.65247, dtype=float32), 'eval/episode_x_velocity_std': Array(190.33202, dtype=float32), 'eval/episode_y_position_std': Array(250.14494, dtype=float32), 'eval/episode_y_velocity_std': Array(80.09177, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40686750411987, 'eval/sps': 938.3691770220736, 'num_steps': 8273920}
{'eval/walltime': 14104.206431388855, 'training/sps': 2932.5494633794756, 'training/walltime': 2864.8737363815308, 'training/entropy_loss': Array(0.00908797, dtype=float32), 'training/policy_loss': Array(0.00467319, dtype=float32), 'training/total_loss': Array(0.07899851, dtype=float32), 'training/v_loss': Array(0.06523736, dtype=float32), 'eval/episode_distance_from_origin': Array(4467.4717, dtype=float32), 'eval/episode_distance_reward': Array(10.79059, dtype=float32), 'eval/episode_forward_reward': Array(1798.4253, dtype=float32), 'eval/episode_reward': Array(1770.9302, dtype=float32), 'eval/episode_reward_alive': Array(429.88672, dtype=float32), 'eval/episode_reward_linvel': Array(1798.4253, dtype=float32), 'eval/episode_reward_quadctrl': Array(-468.17255, dtype=float32), 'eval/episode_x_position': Array(4421.6743, dtype=float32), 'eval/episode_x_velocity': Array(359.68503, dtype=float32), 'eval/episode_y_position': Array(-204.54922, dtype=float32), 'eval/episode_y_velocity': Array(-69.07435, dtype=float32), 'eval/episode_distance_from_origin_std': Array(469.17654, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5673127, dtype=float32), 'eval/episode_forward_reward_std': Array(927.8786, dtype=float32), 'eval/episode_reward_std': Array(974.9308, dtype=float32), 'eval/episode_reward_alive_std': Array(30.753061, dtype=float32), 'eval/episode_reward_linvel_std': Array(927.8786, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(72.02377, dtype=float32), 'eval/episode_x_position_std': Array(458.9455, dtype=float32), 'eval/episode_x_velocity_std': Array(185.57568, dtype=float32), 'eval/episode_y_position_std': Array(290.04147, dtype=float32), 'eval/episode_y_velocity_std': Array(86.25951, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.81832075119019, 'eval/sps': 935.547222749308, 'num_steps': 8355840}
{'eval/walltime': 14240.81741809845, 'training/sps': 2932.754764354433, 'training/walltime': 2892.8065185546875, 'training/entropy_loss': Array(0.01252275, dtype=float32), 'training/policy_loss': Array(0.00759266, dtype=float32), 'training/total_loss': Array(0.06647897, dtype=float32), 'training/v_loss': Array(0.04636356, dtype=float32), 'eval/episode_distance_from_origin': Array(4517.6377, dtype=float32), 'eval/episode_distance_reward': Array(11.36979, dtype=float32), 'eval/episode_forward_reward': Array(1894.9578, dtype=float32), 'eval/episode_reward': Array(1879.5161, dtype=float32), 'eval/episode_reward_alive': Array(428.20703, dtype=float32), 'eval/episode_reward_linvel': Array(1894.9578, dtype=float32), 'eval/episode_reward_quadctrl': Array(-455.0185, dtype=float32), 'eval/episode_x_position': Array(4472.456, dtype=float32), 'eval/episode_x_velocity': Array(378.99158, dtype=float32), 'eval/episode_y_position': Array(-196.19678, dtype=float32), 'eval/episode_y_velocity': Array(-67.450836, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.22772, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3032913, dtype=float32), 'eval/episode_forward_reward_std': Array(883.87494, dtype=float32), 'eval/episode_reward_std': Array(924.1246, dtype=float32), 'eval/episode_reward_alive_std': Array(32.187107, dtype=float32), 'eval/episode_reward_linvel_std': Array(883.87494, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.105995, dtype=float32), 'eval/episode_x_position_std': Array(417.3487, dtype=float32), 'eval/episode_x_velocity_std': Array(176.77507, dtype=float32), 'eval/episode_y_position_std': Array(285.74173, dtype=float32), 'eval/episode_y_velocity_std': Array(86.71631, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.61098670959473, 'eval/sps': 936.9670996674681, 'num_steps': 8437760}
{'eval/walltime': 14377.556420326233, 'training/sps': 2929.365875016562, 'training/walltime': 2920.7716152668, 'training/entropy_loss': Array(0.0141975, dtype=float32), 'training/policy_loss': Array(0.00786818, dtype=float32), 'training/total_loss': Array(0.05708957, dtype=float32), 'training/v_loss': Array(0.03502389, dtype=float32), 'eval/episode_distance_from_origin': Array(4569.881, dtype=float32), 'eval/episode_distance_reward': Array(12.163988, dtype=float32), 'eval/episode_forward_reward': Array(2027.3232, dtype=float32), 'eval/episode_reward': Array(2015.2032, dtype=float32), 'eval/episode_reward_alive': Array(427.01172, dtype=float32), 'eval/episode_reward_linvel': Array(2027.3232, dtype=float32), 'eval/episode_reward_quadctrl': Array(-451.2954, dtype=float32), 'eval/episode_x_position': Array(4519.312, dtype=float32), 'eval/episode_x_velocity': Array(405.46463, dtype=float32), 'eval/episode_y_position': Array(-289.2063, dtype=float32), 'eval/episode_y_velocity': Array(-91.689316, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.59647, dtype=float32), 'eval/episode_distance_reward_std': Array(5.69318, dtype=float32), 'eval/episode_forward_reward_std': Array(948.8566, dtype=float32), 'eval/episode_reward_std': Array(995.0133, dtype=float32), 'eval/episode_reward_alive_std': Array(36.65477, dtype=float32), 'eval/episode_reward_linvel_std': Array(948.8566, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(72.01252, dtype=float32), 'eval/episode_x_position_std': Array(462.28204, dtype=float32), 'eval/episode_x_velocity_std': Array(189.77133, dtype=float32), 'eval/episode_y_position_std': Array(281.6752, dtype=float32), 'eval/episode_y_velocity_std': Array(89.36918, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7390022277832, 'eval/sps': 936.0899078872496, 'num_steps': 8519680}
{'eval/walltime': 14514.203881978989, 'training/sps': 2927.670262065122, 'training/walltime': 2948.7529084682465, 'training/entropy_loss': Array(0.01524518, dtype=float32), 'training/policy_loss': Array(0.00284932, dtype=float32), 'training/total_loss': Array(0.04455113, dtype=float32), 'training/v_loss': Array(0.02645662, dtype=float32), 'eval/episode_distance_from_origin': Array(4517.9736, dtype=float32), 'eval/episode_distance_reward': Array(11.2659645, dtype=float32), 'eval/episode_forward_reward': Array(1877.6536, dtype=float32), 'eval/episode_reward': Array(1854.5117, dtype=float32), 'eval/episode_reward_alive': Array(426.3828, dtype=float32), 'eval/episode_reward_linvel': Array(1877.6536, dtype=float32), 'eval/episode_reward_quadctrl': Array(-460.7907, dtype=float32), 'eval/episode_x_position': Array(4471.823, dtype=float32), 'eval/episode_x_velocity': Array(375.5307, dtype=float32), 'eval/episode_y_position': Array(-197.26395, dtype=float32), 'eval/episode_y_velocity': Array(-66.27305, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.17764, dtype=float32), 'eval/episode_distance_reward_std': Array(5.622771, dtype=float32), 'eval/episode_forward_reward_std': Array(937.1215, dtype=float32), 'eval/episode_reward_std': Array(978.56323, dtype=float32), 'eval/episode_reward_alive_std': Array(31.812468, dtype=float32), 'eval/episode_reward_linvel_std': Array(937.1215, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.954956, dtype=float32), 'eval/episode_x_position_std': Array(460.40616, dtype=float32), 'eval/episode_x_velocity_std': Array(187.42427, dtype=float32), 'eval/episode_y_position_std': Array(302.05002, dtype=float32), 'eval/episode_y_velocity_std': Array(90.14867, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64746165275574, 'eval/sps': 936.716997533914, 'num_steps': 8601600}
{'eval/walltime': 14650.6938829422, 'training/sps': 2930.5294759948233, 'training/walltime': 2976.7069013118744, 'training/entropy_loss': Array(0.01620566, dtype=float32), 'training/policy_loss': Array(0.01404509, dtype=float32), 'training/total_loss': Array(0.04989884, dtype=float32), 'training/v_loss': Array(0.01964808, dtype=float32), 'eval/episode_distance_from_origin': Array(4557.537, dtype=float32), 'eval/episode_distance_reward': Array(11.684247, dtype=float32), 'eval/episode_forward_reward': Array(1947.367, dtype=float32), 'eval/episode_reward': Array(1929.9015, dtype=float32), 'eval/episode_reward_alive': Array(430.5586, dtype=float32), 'eval/episode_reward_linvel': Array(1947.367, dtype=float32), 'eval/episode_reward_quadctrl': Array(-459.70813, dtype=float32), 'eval/episode_x_position': Array(4513.366, dtype=float32), 'eval/episode_x_velocity': Array(389.47336, dtype=float32), 'eval/episode_y_position': Array(-197.92885, dtype=float32), 'eval/episode_y_velocity': Array(-66.542274, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.977, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4953966, dtype=float32), 'eval/episode_forward_reward_std': Array(915.89276, dtype=float32), 'eval/episode_reward_std': Array(960.6575, dtype=float32), 'eval/episode_reward_alive_std': Array(30.811209, dtype=float32), 'eval/episode_reward_linvel_std': Array(915.89276, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.69289, dtype=float32), 'eval/episode_x_position_std': Array(444.5627, dtype=float32), 'eval/episode_x_velocity_std': Array(183.17845, dtype=float32), 'eval/episode_y_position_std': Array(278.8821, dtype=float32), 'eval/episode_y_velocity_std': Array(84.46956, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49000096321106, 'eval/sps': 937.797634234764, 'num_steps': 8683520}
{'eval/walltime': 14786.979754924774, 'training/sps': 2932.6518349373537, 'training/walltime': 3004.6406638622284, 'training/entropy_loss': Array(0.00797284, dtype=float32), 'training/policy_loss': Array(0.00820007, dtype=float32), 'training/total_loss': Array(0.06003589, dtype=float32), 'training/v_loss': Array(0.04386298, dtype=float32), 'eval/episode_distance_from_origin': Array(4516.522, dtype=float32), 'eval/episode_distance_reward': Array(11.349678, dtype=float32), 'eval/episode_forward_reward': Array(1891.606, dtype=float32), 'eval/episode_reward': Array(1865.9326, dtype=float32), 'eval/episode_reward_alive': Array(429.22266, dtype=float32), 'eval/episode_reward_linvel': Array(1891.606, dtype=float32), 'eval/episode_reward_quadctrl': Array(-466.24548, dtype=float32), 'eval/episode_x_position': Array(4471.0293, dtype=float32), 'eval/episode_x_velocity': Array(378.32114, dtype=float32), 'eval/episode_y_position': Array(-184.8378, dtype=float32), 'eval/episode_y_velocity': Array(-61.93482, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.37637, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7592063, dtype=float32), 'eval/episode_forward_reward_std': Array(959.8611, dtype=float32), 'eval/episode_reward_std': Array(1011.2564, dtype=float32), 'eval/episode_reward_alive_std': Array(33.595352, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.8611, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(75.35372, dtype=float32), 'eval/episode_x_position_std': Array(474.36633, dtype=float32), 'eval/episode_x_velocity_std': Array(191.97218, dtype=float32), 'eval/episode_y_position_std': Array(298.491, dtype=float32), 'eval/episode_y_velocity_std': Array(88.82946, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28587198257446, 'eval/sps': 939.2022675422006, 'num_steps': 8765440}
{'eval/walltime': 14923.56837272644, 'training/sps': 2943.668101395951, 'training/walltime': 3032.4698882102966, 'training/entropy_loss': Array(0.00803312, dtype=float32), 'training/policy_loss': Array(0.0598676, dtype=float32), 'training/total_loss': Array(0.12909335, dtype=float32), 'training/v_loss': Array(0.06119262, dtype=float32), 'eval/episode_distance_from_origin': Array(4410.3506, dtype=float32), 'eval/episode_distance_reward': Array(9.9178505, dtype=float32), 'eval/episode_forward_reward': Array(1652.9698, dtype=float32), 'eval/episode_reward': Array(1632.1835, dtype=float32), 'eval/episode_reward_alive': Array(431.54688, dtype=float32), 'eval/episode_reward_linvel': Array(1652.9698, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.25098, dtype=float32), 'eval/episode_x_position': Array(4366.9653, dtype=float32), 'eval/episode_x_velocity': Array(330.59393, dtype=float32), 'eval/episode_y_position': Array(-175.52325, dtype=float32), 'eval/episode_y_velocity': Array(-53.48977, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.58023, dtype=float32), 'eval/episode_distance_reward_std': Array(4.637814, dtype=float32), 'eval/episode_forward_reward_std': Array(772.9632, dtype=float32), 'eval/episode_reward_std': Array(808.74774, dtype=float32), 'eval/episode_reward_alive_std': Array(42.017406, dtype=float32), 'eval/episode_reward_linvel_std': Array(772.9632, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.15666, dtype=float32), 'eval/episode_x_position_std': Array(407.2154, dtype=float32), 'eval/episode_x_velocity_std': Array(154.59262, dtype=float32), 'eval/episode_y_position_std': Array(274.1243, dtype=float32), 'eval/episode_y_velocity_std': Array(78.65716, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58861780166626, 'eval/sps': 937.1205453287669, 'num_steps': 8847360}
{'eval/walltime': 15059.971554517746, 'training/sps': 2935.814202490423, 'training/walltime': 3060.3735613822937, 'training/entropy_loss': Array(0.01145364, dtype=float32), 'training/policy_loss': Array(0.00652896, dtype=float32), 'training/total_loss': Array(0.07749532, dtype=float32), 'training/v_loss': Array(0.05951272, dtype=float32), 'eval/episode_distance_from_origin': Array(4398.6777, dtype=float32), 'eval/episode_distance_reward': Array(9.804877, dtype=float32), 'eval/episode_forward_reward': Array(1634.1411, dtype=float32), 'eval/episode_reward': Array(1599.6196, dtype=float32), 'eval/episode_reward_alive': Array(428.64453, dtype=float32), 'eval/episode_reward_linvel': Array(1634.1411, dtype=float32), 'eval/episode_reward_quadctrl': Array(-472.97107, dtype=float32), 'eval/episode_x_position': Array(4355.042, dtype=float32), 'eval/episode_x_velocity': Array(326.82822, dtype=float32), 'eval/episode_y_position': Array(-148.54019, dtype=float32), 'eval/episode_y_velocity': Array(-48.23696, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.05963, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6433454, dtype=float32), 'eval/episode_forward_reward_std': Array(773.8854, dtype=float32), 'eval/episode_reward_std': Array(811.9279, dtype=float32), 'eval/episode_reward_alive_std': Array(31.048986, dtype=float32), 'eval/episode_reward_linvel_std': Array(773.8854, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.32955, dtype=float32), 'eval/episode_x_position_std': Array(418.73343, dtype=float32), 'eval/episode_x_velocity_std': Array(154.77704, dtype=float32), 'eval/episode_y_position_std': Array(292.6388, dtype=float32), 'eval/episode_y_velocity_std': Array(80.39119, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40318179130554, 'eval/sps': 938.3945324372106, 'num_steps': 8929280}
{'eval/walltime': 15196.743147611618, 'training/sps': 2934.874131890763, 'training/walltime': 3088.286172389984, 'training/entropy_loss': Array(0.01438577, dtype=float32), 'training/policy_loss': Array(0.02518495, dtype=float32), 'training/total_loss': Array(0.08031002, dtype=float32), 'training/v_loss': Array(0.04073929, dtype=float32), 'eval/episode_distance_from_origin': Array(4431.867, dtype=float32), 'eval/episode_distance_reward': Array(10.280649, dtype=float32), 'eval/episode_forward_reward': Array(1713.4354, dtype=float32), 'eval/episode_reward': Array(1693.8948, dtype=float32), 'eval/episode_reward_alive': Array(433.13672, dtype=float32), 'eval/episode_reward_linvel': Array(1713.4354, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.95795, dtype=float32), 'eval/episode_x_position': Array(4388.0576, dtype=float32), 'eval/episode_x_velocity': Array(342.68707, dtype=float32), 'eval/episode_y_position': Array(-164.37323, dtype=float32), 'eval/episode_y_velocity': Array(-54.53546, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.72205, dtype=float32), 'eval/episode_distance_reward_std': Array(5.013333, dtype=float32), 'eval/episode_forward_reward_std': Array(835.54926, dtype=float32), 'eval/episode_reward_std': Array(874.9202, dtype=float32), 'eval/episode_reward_alive_std': Array(29.128334, dtype=float32), 'eval/episode_reward_linvel_std': Array(835.54926, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.70672, dtype=float32), 'eval/episode_x_position_std': Array(442.0442, dtype=float32), 'eval/episode_x_velocity_std': Array(167.10982, dtype=float32), 'eval/episode_y_position_std': Array(283.1833, dtype=float32), 'eval/episode_y_velocity_std': Array(82.03058, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.77159309387207, 'eval/sps': 935.8668500128404, 'num_steps': 9011200}
{'eval/walltime': 15333.436896324158, 'training/sps': 2930.5401236386892, 'training/walltime': 3116.2400636672974, 'training/entropy_loss': Array(0.01514303, dtype=float32), 'training/policy_loss': Array(0.00360453, dtype=float32), 'training/total_loss': Array(0.04185693, dtype=float32), 'training/v_loss': Array(0.02310937, dtype=float32), 'eval/episode_distance_from_origin': Array(4371.7754, dtype=float32), 'eval/episode_distance_reward': Array(9.631857, dtype=float32), 'eval/episode_forward_reward': Array(1605.3047, dtype=float32), 'eval/episode_reward': Array(1579.5616, dtype=float32), 'eval/episode_reward_alive': Array(435.125, dtype=float32), 'eval/episode_reward_linvel': Array(1605.3047, dtype=float32), 'eval/episode_reward_quadctrl': Array(-470.5, dtype=float32), 'eval/episode_x_position': Array(4331.185, dtype=float32), 'eval/episode_x_velocity': Array(321.06097, dtype=float32), 'eval/episode_y_position': Array(-122.080215, dtype=float32), 'eval/episode_y_velocity': Array(-39.661694, dtype=float32), 'eval/episode_distance_from_origin_std': Array(412.81638, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7659955, dtype=float32), 'eval/episode_forward_reward_std': Array(794.3269, dtype=float32), 'eval/episode_reward_std': Array(831.5408, dtype=float32), 'eval/episode_reward_alive_std': Array(34.527954, dtype=float32), 'eval/episode_reward_linvel_std': Array(794.3269, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(71.37636, dtype=float32), 'eval/episode_x_position_std': Array(406.48853, dtype=float32), 'eval/episode_x_velocity_std': Array(158.86537, dtype=float32), 'eval/episode_y_position_std': Array(259.76025, dtype=float32), 'eval/episode_y_velocity_std': Array(74.29052, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69374871253967, 'eval/sps': 936.3998076399075, 'num_steps': 9093120}
{'eval/walltime': 15470.143034934998, 'training/sps': 2938.5590908665235, 'training/walltime': 3144.1176722049713, 'training/entropy_loss': Array(0.01588761, dtype=float32), 'training/policy_loss': Array(0.0098114, dtype=float32), 'training/total_loss': Array(0.04492385, dtype=float32), 'training/v_loss': Array(0.01922485, dtype=float32), 'eval/episode_distance_from_origin': Array(4321.815, dtype=float32), 'eval/episode_distance_reward': Array(8.9297695, dtype=float32), 'eval/episode_forward_reward': Array(1488.291, dtype=float32), 'eval/episode_reward': Array(1460.4059, dtype=float32), 'eval/episode_reward_alive': Array(436.36328, dtype=float32), 'eval/episode_reward_linvel': Array(1488.291, dtype=float32), 'eval/episode_reward_quadctrl': Array(-473.1781, dtype=float32), 'eval/episode_x_position': Array(4280.634, dtype=float32), 'eval/episode_x_velocity': Array(297.65814, dtype=float32), 'eval/episode_y_position': Array(-136.67386, dtype=float32), 'eval/episode_y_velocity': Array(-42.297928, dtype=float32), 'eval/episode_distance_from_origin_std': Array(406.13058, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2629113, dtype=float32), 'eval/episode_forward_reward_std': Array(710.4801, dtype=float32), 'eval/episode_reward_std': Array(737.14984, dtype=float32), 'eval/episode_reward_alive_std': Array(32.84229, dtype=float32), 'eval/episode_reward_linvel_std': Array(710.4801, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.45898, dtype=float32), 'eval/episode_x_position_std': Array(396.77353, dtype=float32), 'eval/episode_x_velocity_std': Array(142.09598, dtype=float32), 'eval/episode_y_position_std': Array(266.03848, dtype=float32), 'eval/episode_y_velocity_std': Array(73.99015, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70613861083984, 'eval/sps': 936.3149402118398, 'num_steps': 9175040}
{'eval/walltime': 15606.772383213043, 'training/sps': 2928.6523266449003, 'training/walltime': 3172.0895824432373, 'training/entropy_loss': Array(0.010392, dtype=float32), 'training/policy_loss': Array(0.00202348, dtype=float32), 'training/total_loss': Array(0.04723733, dtype=float32), 'training/v_loss': Array(0.03482185, dtype=float32), 'eval/episode_distance_from_origin': Array(4288.5938, dtype=float32), 'eval/episode_distance_reward': Array(8.66852, dtype=float32), 'eval/episode_forward_reward': Array(1444.7498, dtype=float32), 'eval/episode_reward': Array(1419.5867, dtype=float32), 'eval/episode_reward_alive': Array(431.33203, dtype=float32), 'eval/episode_reward_linvel': Array(1444.7498, dtype=float32), 'eval/episode_reward_quadctrl': Array(-465.16364, dtype=float32), 'eval/episode_x_position': Array(4244.404, dtype=float32), 'eval/episode_x_velocity': Array(288.94992, dtype=float32), 'eval/episode_y_position': Array(-107.82802, dtype=float32), 'eval/episode_y_velocity': Array(-37.56975, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.4196, dtype=float32), 'eval/episode_distance_reward_std': Array(4.339306, dtype=float32), 'eval/episode_forward_reward_std': Array(723.2125, dtype=float32), 'eval/episode_reward_std': Array(750.5445, dtype=float32), 'eval/episode_reward_alive_std': Array(33.23139, dtype=float32), 'eval/episode_reward_linvel_std': Array(723.2125, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.044437, dtype=float32), 'eval/episode_x_position_std': Array(418.4516, dtype=float32), 'eval/episode_x_velocity_std': Array(144.64247, dtype=float32), 'eval/episode_y_position_std': Array(312.10068, dtype=float32), 'eval/episode_y_velocity_std': Array(84.08478, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62934827804565, 'eval/sps': 936.8411809995272, 'num_steps': 9256960}
{'eval/walltime': 15743.289878606796, 'training/sps': 2932.6901322470667, 'training/walltime': 3200.0229802131653, 'training/entropy_loss': Array(0.0060585, dtype=float32), 'training/policy_loss': Array(0.0061435, dtype=float32), 'training/total_loss': Array(0.06638767, dtype=float32), 'training/v_loss': Array(0.05418567, dtype=float32), 'eval/episode_distance_from_origin': Array(4382.6377, dtype=float32), 'eval/episode_distance_reward': Array(9.548694, dtype=float32), 'eval/episode_forward_reward': Array(1591.4443, dtype=float32), 'eval/episode_reward': Array(1554.8833, dtype=float32), 'eval/episode_reward_alive': Array(436.6953, dtype=float32), 'eval/episode_reward_linvel': Array(1591.4443, dtype=float32), 'eval/episode_reward_quadctrl': Array(-482.80536, dtype=float32), 'eval/episode_x_position': Array(4337.5186, dtype=float32), 'eval/episode_x_velocity': Array(318.28888, dtype=float32), 'eval/episode_y_position': Array(-191.36313, dtype=float32), 'eval/episode_y_velocity': Array(-57.482193, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.05978, dtype=float32), 'eval/episode_distance_reward_std': Array(4.594815, dtype=float32), 'eval/episode_forward_reward_std': Array(765.7971, dtype=float32), 'eval/episode_reward_std': Array(801.14923, dtype=float32), 'eval/episode_reward_alive_std': Array(29.628508, dtype=float32), 'eval/episode_reward_linvel_std': Array(765.7971, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.643684, dtype=float32), 'eval/episode_x_position_std': Array(411.96292, dtype=float32), 'eval/episode_x_velocity_std': Array(153.15942, dtype=float32), 'eval/episode_y_position_std': Array(285.25, dtype=float32), 'eval/episode_y_velocity_std': Array(78.84511, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51749539375305, 'eval/sps': 937.6087631172378, 'num_steps': 9338880}
{'eval/walltime': 15879.922421455383, 'training/sps': 2934.0290138740497, 'training/walltime': 3227.94363117218, 'training/entropy_loss': Array(0.0105371, dtype=float32), 'training/policy_loss': Array(0.00401872, dtype=float32), 'training/total_loss': Array(0.0719946, dtype=float32), 'training/v_loss': Array(0.05743878, dtype=float32), 'eval/episode_distance_from_origin': Array(4422.1006, dtype=float32), 'eval/episode_distance_reward': Array(10.087799, dtype=float32), 'eval/episode_forward_reward': Array(1681.2944, dtype=float32), 'eval/episode_reward': Array(1658.5923, dtype=float32), 'eval/episode_reward_alive': Array(434.58594, dtype=float32), 'eval/episode_reward_linvel': Array(1681.2944, dtype=float32), 'eval/episode_reward_quadctrl': Array(-467.3759, dtype=float32), 'eval/episode_x_position': Array(4376.0176, dtype=float32), 'eval/episode_x_velocity': Array(336.25885, dtype=float32), 'eval/episode_y_position': Array(-184.60217, dtype=float32), 'eval/episode_y_velocity': Array(-60.488716, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.0035, dtype=float32), 'eval/episode_distance_reward_std': Array(5.445564, dtype=float32), 'eval/episode_forward_reward_std': Array(907.5878, dtype=float32), 'eval/episode_reward_std': Array(951.9522, dtype=float32), 'eval/episode_reward_alive_std': Array(31.050873, dtype=float32), 'eval/episode_reward_linvel_std': Array(907.5878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(76.39758, dtype=float32), 'eval/episode_x_position_std': Array(479.44894, dtype=float32), 'eval/episode_x_velocity_std': Array(181.51749, dtype=float32), 'eval/episode_y_position_std': Array(302.78894, dtype=float32), 'eval/episode_y_velocity_std': Array(85.52601, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63254284858704, 'eval/sps': 936.8192769554657, 'num_steps': 9420800}
{'eval/walltime': 16016.71968960762, 'training/sps': 2933.3019484709002, 'training/walltime': 3255.8712027072906, 'training/entropy_loss': Array(0.01163472, dtype=float32), 'training/policy_loss': Array(0.14341712, dtype=float32), 'training/total_loss': Array(0.19693953, dtype=float32), 'training/v_loss': Array(0.04188769, dtype=float32), 'eval/episode_distance_from_origin': Array(4690.6787, dtype=float32), 'eval/episode_distance_reward': Array(13.127557, dtype=float32), 'eval/episode_forward_reward': Array(2187.9177, dtype=float32), 'eval/episode_reward': Array(2165.9624, dtype=float32), 'eval/episode_reward_alive': Array(415.1836, dtype=float32), 'eval/episode_reward_linvel': Array(2187.9177, dtype=float32), 'eval/episode_reward_quadctrl': Array(-450.26636, dtype=float32), 'eval/episode_x_position': Array(4639.8525, dtype=float32), 'eval/episode_x_velocity': Array(437.5835, dtype=float32), 'eval/episode_y_position': Array(-255.33038, dtype=float32), 'eval/episode_y_velocity': Array(-89.11384, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.55978, dtype=float32), 'eval/episode_distance_reward_std': Array(5.921534, dtype=float32), 'eval/episode_forward_reward_std': Array(986.9149, dtype=float32), 'eval/episode_reward_std': Array(1037.8219, dtype=float32), 'eval/episode_reward_alive_std': Array(43.600586, dtype=float32), 'eval/episode_reward_linvel_std': Array(986.9149, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.78968, dtype=float32), 'eval/episode_x_position_std': Array(459.1595, dtype=float32), 'eval/episode_x_velocity_std': Array(197.38297, dtype=float32), 'eval/episode_y_position_std': Array(315.3151, dtype=float32), 'eval/episode_y_velocity_std': Array(96.05418, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.79726815223694, 'eval/sps': 935.6912000432146, 'num_steps': 9502720}
{'eval/walltime': 16153.184864521027, 'training/sps': 2923.7317632331738, 'training/walltime': 3283.890188932419, 'training/entropy_loss': Array(0.0127432, dtype=float32), 'training/policy_loss': Array(0.00185651, dtype=float32), 'training/total_loss': Array(0.04504461, dtype=float32), 'training/v_loss': Array(0.03044489, dtype=float32), 'eval/episode_distance_from_origin': Array(4661.1216, dtype=float32), 'eval/episode_distance_reward': Array(12.868784, dtype=float32), 'eval/episode_forward_reward': Array(2144.789, dtype=float32), 'eval/episode_reward': Array(2107.9585, dtype=float32), 'eval/episode_reward_alive': Array(414.35547, dtype=float32), 'eval/episode_reward_linvel': Array(2144.789, dtype=float32), 'eval/episode_reward_quadctrl': Array(-464.05463, dtype=float32), 'eval/episode_x_position': Array(4613.5728, dtype=float32), 'eval/episode_x_velocity': Array(428.95776, dtype=float32), 'eval/episode_y_position': Array(-214.48453, dtype=float32), 'eval/episode_y_velocity': Array(-77.7416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.89127, dtype=float32), 'eval/episode_distance_reward_std': Array(6.174733, dtype=float32), 'eval/episode_forward_reward_std': Array(1029.1151, dtype=float32), 'eval/episode_reward_std': Array(1089.7744, dtype=float32), 'eval/episode_reward_alive_std': Array(40.87147, dtype=float32), 'eval/episode_reward_linvel_std': Array(1029.1151, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.22027, dtype=float32), 'eval/episode_x_position_std': Array(483.46146, dtype=float32), 'eval/episode_x_velocity_std': Array(205.82301, dtype=float32), 'eval/episode_y_position_std': Array(307.77686, dtype=float32), 'eval/episode_y_velocity_std': Array(95.73993, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46517491340637, 'eval/sps': 937.9682404776315, 'num_steps': 9584640}
{'eval/walltime': 16289.852428913116, 'training/sps': 2926.763794112729, 'training/walltime': 3311.880148410797, 'training/entropy_loss': Array(0.01416989, dtype=float32), 'training/policy_loss': Array(0.00935669, dtype=float32), 'training/total_loss': Array(0.0537768, dtype=float32), 'training/v_loss': Array(0.03025022, dtype=float32), 'eval/episode_distance_from_origin': Array(4718.7256, dtype=float32), 'eval/episode_distance_reward': Array(13.718918, dtype=float32), 'eval/episode_forward_reward': Array(2286.4766, dtype=float32), 'eval/episode_reward': Array(2265.809, dtype=float32), 'eval/episode_reward_alive': Array(416.45703, dtype=float32), 'eval/episode_reward_linvel': Array(2286.4766, dtype=float32), 'eval/episode_reward_quadctrl': Array(-450.84363, dtype=float32), 'eval/episode_x_position': Array(4670.757, dtype=float32), 'eval/episode_x_velocity': Array(457.29532, dtype=float32), 'eval/episode_y_position': Array(-224.93576, dtype=float32), 'eval/episode_y_velocity': Array(-87.50536, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.7328, dtype=float32), 'eval/episode_distance_reward_std': Array(6.298774, dtype=float32), 'eval/episode_forward_reward_std': Array(1049.7878, dtype=float32), 'eval/episode_reward_std': Array(1107.5323, dtype=float32), 'eval/episode_reward_alive_std': Array(33.385418, dtype=float32), 'eval/episode_reward_linvel_std': Array(1049.7878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.35762, dtype=float32), 'eval/episode_x_position_std': Array(470.78992, dtype=float32), 'eval/episode_x_velocity_std': Array(209.95758, dtype=float32), 'eval/episode_y_position_std': Array(292.88092, dtype=float32), 'eval/episode_y_velocity_std': Array(98.78622, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66756439208984, 'eval/sps': 936.5792137246026, 'num_steps': 9666560}
{'eval/walltime': 16426.20376110077, 'training/sps': 2939.2872061331996, 'training/walltime': 3339.7508511543274, 'training/entropy_loss': Array(0.01165826, dtype=float32), 'training/policy_loss': Array(0.01167673, dtype=float32), 'training/total_loss': Array(0.04678117, dtype=float32), 'training/v_loss': Array(0.02344619, dtype=float32), 'eval/episode_distance_from_origin': Array(4583.1895, dtype=float32), 'eval/episode_distance_reward': Array(11.7692, dtype=float32), 'eval/episode_forward_reward': Array(1961.5264, dtype=float32), 'eval/episode_reward': Array(1928.8801, dtype=float32), 'eval/episode_reward_alive': Array(417.48828, dtype=float32), 'eval/episode_reward_linvel': Array(1961.5264, dtype=float32), 'eval/episode_reward_quadctrl': Array(-461.9035, dtype=float32), 'eval/episode_x_position': Array(4535.7007, dtype=float32), 'eval/episode_x_velocity': Array(392.3053, dtype=float32), 'eval/episode_y_position': Array(-195.71979, dtype=float32), 'eval/episode_y_velocity': Array(-67.22543, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.28894, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8119636, dtype=float32), 'eval/episode_forward_reward_std': Array(968.6543, dtype=float32), 'eval/episode_reward_std': Array(1016.6526, dtype=float32), 'eval/episode_reward_alive_std': Array(38.79455, dtype=float32), 'eval/episode_reward_linvel_std': Array(968.6543, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.9981, dtype=float32), 'eval/episode_x_position_std': Array(476.87216, dtype=float32), 'eval/episode_x_velocity_std': Array(193.7309, dtype=float32), 'eval/episode_y_position_std': Array(318.92856, dtype=float32), 'eval/episode_y_velocity_std': Array(91.2215, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3513321876526, 'eval/sps': 938.7513707885221, 'num_steps': 9748480}
{'eval/walltime': 16562.70863676071, 'training/sps': 2929.5897138900486, 'training/walltime': 3367.713811159134, 'training/entropy_loss': Array(0.0067938, dtype=float32), 'training/policy_loss': Array(0.00340711, dtype=float32), 'training/total_loss': Array(0.07265832, dtype=float32), 'training/v_loss': Array(0.06245741, dtype=float32), 'eval/episode_distance_from_origin': Array(4642.389, dtype=float32), 'eval/episode_distance_reward': Array(12.322497, dtype=float32), 'eval/episode_forward_reward': Array(2053.7424, dtype=float32), 'eval/episode_reward': Array(2019.2755, dtype=float32), 'eval/episode_reward_alive': Array(415.9414, dtype=float32), 'eval/episode_reward_linvel': Array(2053.7424, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.7307, dtype=float32), 'eval/episode_x_position': Array(4592.1206, dtype=float32), 'eval/episode_x_velocity': Array(410.74847, dtype=float32), 'eval/episode_y_position': Array(-217.19946, dtype=float32), 'eval/episode_y_velocity': Array(-77.540344, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.96936, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8334136, dtype=float32), 'eval/episode_forward_reward_std': Array(972.229, dtype=float32), 'eval/episode_reward_std': Array(1023.5017, dtype=float32), 'eval/episode_reward_alive_std': Array(45.00927, dtype=float32), 'eval/episode_reward_linvel_std': Array(972.229, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.55774, dtype=float32), 'eval/episode_x_position_std': Array(474.6253, dtype=float32), 'eval/episode_x_velocity_std': Array(194.44576, dtype=float32), 'eval/episode_y_position_std': Array(338.3295, dtype=float32), 'eval/episode_y_velocity_std': Array(100.56817, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50487565994263, 'eval/sps': 937.6954440724172, 'num_steps': 9830400}
{'eval/walltime': 16699.555199861526, 'training/sps': 2951.856323089767, 'training/walltime': 3395.4658393859863, 'training/entropy_loss': Array(0.00992342, dtype=float32), 'training/policy_loss': Array(0.01228225, dtype=float32), 'training/total_loss': Array(0.10447341, dtype=float32), 'training/v_loss': Array(0.08226775, dtype=float32), 'eval/episode_distance_from_origin': Array(4720.6436, dtype=float32), 'eval/episode_distance_reward': Array(13.29157, dtype=float32), 'eval/episode_forward_reward': Array(2215.2524, dtype=float32), 'eval/episode_reward': Array(2183.9285, dtype=float32), 'eval/episode_reward_alive': Array(418.1797, dtype=float32), 'eval/episode_reward_linvel': Array(2215.2524, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.79553, dtype=float32), 'eval/episode_x_position': Array(4672.818, dtype=float32), 'eval/episode_x_velocity': Array(443.05054, dtype=float32), 'eval/episode_y_position': Array(-240.43921, dtype=float32), 'eval/episode_y_velocity': Array(-84.51949, dtype=float32), 'eval/episode_distance_from_origin_std': Array(553.64856, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6783257, dtype=float32), 'eval/episode_forward_reward_std': Array(1113.0466, dtype=float32), 'eval/episode_reward_std': Array(1172.305, dtype=float32), 'eval/episode_reward_alive_std': Array(37.14965, dtype=float32), 'eval/episode_reward_linvel_std': Array(1113.0466, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.927246, dtype=float32), 'eval/episode_x_position_std': Array(543.5058, dtype=float32), 'eval/episode_x_velocity_std': Array(222.60931, dtype=float32), 'eval/episode_y_position_std': Array(295.3782, dtype=float32), 'eval/episode_y_velocity_std': Array(89.899506, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84656310081482, 'eval/sps': 935.3541448147473, 'num_steps': 9912320}
{'eval/walltime': 16836.339416265488, 'training/sps': 2920.401262449102, 'training/walltime': 3423.5167791843414, 'training/entropy_loss': Array(0.01258163, dtype=float32), 'training/policy_loss': Array(0.01536853, dtype=float32), 'training/total_loss': Array(0.09308767, dtype=float32), 'training/v_loss': Array(0.06513751, dtype=float32), 'eval/episode_distance_from_origin': Array(4667.3, dtype=float32), 'eval/episode_distance_reward': Array(12.077321, dtype=float32), 'eval/episode_forward_reward': Array(2012.8795, dtype=float32), 'eval/episode_reward': Array(1967.1537, dtype=float32), 'eval/episode_reward_alive': Array(425.58984, dtype=float32), 'eval/episode_reward_linvel': Array(2012.8795, dtype=float32), 'eval/episode_reward_quadctrl': Array(-483.3933, dtype=float32), 'eval/episode_x_position': Array(4618.797, dtype=float32), 'eval/episode_x_velocity': Array(402.57593, dtype=float32), 'eval/episode_y_position': Array(-184.72261, dtype=float32), 'eval/episode_y_velocity': Array(-66.09801, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.2398, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8640776, dtype=float32), 'eval/episode_forward_reward_std': Array(977.3393, dtype=float32), 'eval/episode_reward_std': Array(1027.5038, dtype=float32), 'eval/episode_reward_alive_std': Array(33.172752, dtype=float32), 'eval/episode_reward_linvel_std': Array(977.3393, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.51416, dtype=float32), 'eval/episode_x_position_std': Array(496.44308, dtype=float32), 'eval/episode_x_velocity_std': Array(195.46786, dtype=float32), 'eval/episode_y_position_std': Array(344.62518, dtype=float32), 'eval/episode_y_velocity_std': Array(95.988365, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.78421640396118, 'eval/sps': 935.7804823180842, 'num_steps': 9994240}
{'eval/walltime': 16973.08427810669, 'training/sps': 2946.0704550911823, 'training/walltime': 3451.3233103752136, 'training/entropy_loss': Array(0.01523361, dtype=float32), 'training/policy_loss': Array(0.01316581, dtype=float32), 'training/total_loss': Array(0.07315361, dtype=float32), 'training/v_loss': Array(0.0447542, dtype=float32), 'eval/episode_distance_from_origin': Array(4668.7593, dtype=float32), 'eval/episode_distance_reward': Array(12.544381, dtype=float32), 'eval/episode_forward_reward': Array(2090.722, dtype=float32), 'eval/episode_reward': Array(2062.835, dtype=float32), 'eval/episode_reward_alive': Array(428.60156, dtype=float32), 'eval/episode_reward_linvel': Array(2090.722, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.0332, dtype=float32), 'eval/episode_x_position': Array(4619.343, dtype=float32), 'eval/episode_x_velocity': Array(418.1444, dtype=float32), 'eval/episode_y_position': Array(-220.86905, dtype=float32), 'eval/episode_y_velocity': Array(-77.9662, dtype=float32), 'eval/episode_distance_from_origin_std': Array(560.3527, dtype=float32), 'eval/episode_distance_reward_std': Array(6.435704, dtype=float32), 'eval/episode_forward_reward_std': Array(1072.6101, dtype=float32), 'eval/episode_reward_std': Array(1124.11, dtype=float32), 'eval/episode_reward_alive_std': Array(32.073788, dtype=float32), 'eval/episode_reward_linvel_std': Array(1072.6101, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.33255, dtype=float32), 'eval/episode_x_position_std': Array(545.95233, dtype=float32), 'eval/episode_x_velocity_std': Array(214.52202, dtype=float32), 'eval/episode_y_position_std': Array(326.78867, dtype=float32), 'eval/episode_y_velocity_std': Array(96.56107, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.74486184120178, 'eval/sps': 936.0497957769195, 'num_steps': 10076160}
{'eval/walltime': 17109.836733579636, 'training/sps': 2926.7655890871424, 'training/walltime': 3479.313252687454, 'training/entropy_loss': Array(0.01668982, dtype=float32), 'training/policy_loss': Array(0.02621472, dtype=float32), 'training/total_loss': Array(0.07816582, dtype=float32), 'training/v_loss': Array(0.03526128, dtype=float32), 'eval/episode_distance_from_origin': Array(4707.5864, dtype=float32), 'eval/episode_distance_reward': Array(12.582111, dtype=float32), 'eval/episode_forward_reward': Array(2097.0103, dtype=float32), 'eval/episode_reward': Array(2057.527, dtype=float32), 'eval/episode_reward_alive': Array(422.39844, dtype=float32), 'eval/episode_reward_linvel': Array(2097.0103, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.46375, dtype=float32), 'eval/episode_x_position': Array(4654.207, dtype=float32), 'eval/episode_x_velocity': Array(419.4021, dtype=float32), 'eval/episode_y_position': Array(-262.50787, dtype=float32), 'eval/episode_y_velocity': Array(-85.36955, dtype=float32), 'eval/episode_distance_from_origin_std': Array(568.8749, dtype=float32), 'eval/episode_distance_reward_std': Array(6.278037, dtype=float32), 'eval/episode_forward_reward_std': Array(1046.3319, dtype=float32), 'eval/episode_reward_std': Array(1097.8685, dtype=float32), 'eval/episode_reward_alive_std': Array(35.71635, dtype=float32), 'eval/episode_reward_linvel_std': Array(1046.3319, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.93572, dtype=float32), 'eval/episode_x_position_std': Array(555.1443, dtype=float32), 'eval/episode_x_velocity_std': Array(209.26646, dtype=float32), 'eval/episode_y_position_std': Array(349.1525, dtype=float32), 'eval/episode_y_velocity_std': Array(97.50135, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.75245547294617, 'eval/sps': 935.9978185205042, 'num_steps': 10158080}
{'eval/walltime': 17246.490101099014, 'training/sps': 2934.4422143121114, 'training/walltime': 3507.2299721240997, 'training/entropy_loss': Array(0.01751939, dtype=float32), 'training/policy_loss': Array(0.00814036, dtype=float32), 'training/total_loss': Array(0.05208359, dtype=float32), 'training/v_loss': Array(0.02642383, dtype=float32), 'eval/episode_distance_from_origin': Array(4757.6953, dtype=float32), 'eval/episode_distance_reward': Array(13.326115, dtype=float32), 'eval/episode_forward_reward': Array(2221.0103, dtype=float32), 'eval/episode_reward': Array(2188.1958, dtype=float32), 'eval/episode_reward_alive': Array(420.05078, dtype=float32), 'eval/episode_reward_linvel': Array(2221.0103, dtype=float32), 'eval/episode_reward_quadctrl': Array(-466.19144, dtype=float32), 'eval/episode_x_position': Array(4705.6953, dtype=float32), 'eval/episode_x_velocity': Array(444.2021, dtype=float32), 'eval/episode_y_position': Array(-261.60016, dtype=float32), 'eval/episode_y_velocity': Array(-92.83122, dtype=float32), 'eval/episode_distance_from_origin_std': Array(522.7053, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2181463, dtype=float32), 'eval/episode_forward_reward_std': Array(1036.3505, dtype=float32), 'eval/episode_reward_std': Array(1086.6365, dtype=float32), 'eval/episode_reward_alive_std': Array(31.774832, dtype=float32), 'eval/episode_reward_linvel_std': Array(1036.3505, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.525604, dtype=float32), 'eval/episode_x_position_std': Array(511.081, dtype=float32), 'eval/episode_x_velocity_std': Array(207.27013, dtype=float32), 'eval/episode_y_position_std': Array(331.4574, dtype=float32), 'eval/episode_y_velocity_std': Array(94.45391, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65336751937866, 'eval/sps': 936.6765146263115, 'num_steps': 10240000}
{'eval/walltime': 17383.188069581985, 'training/sps': 2928.5251489012107, 'training/walltime': 3535.2030971050262, 'training/entropy_loss': Array(0.00548365, dtype=float32), 'training/policy_loss': Array(-0.00100555, dtype=float32), 'training/total_loss': Array(0.06370672, dtype=float32), 'training/v_loss': Array(0.05922863, dtype=float32), 'eval/episode_distance_from_origin': Array(4677.873, dtype=float32), 'eval/episode_distance_reward': Array(12.596902, dtype=float32), 'eval/episode_forward_reward': Array(2099.476, dtype=float32), 'eval/episode_reward': Array(2056.6426, dtype=float32), 'eval/episode_reward_alive': Array(412.77734, dtype=float32), 'eval/episode_reward_linvel': Array(2099.476, dtype=float32), 'eval/episode_reward_quadctrl': Array(-468.20813, dtype=float32), 'eval/episode_x_position': Array(4630.3594, dtype=float32), 'eval/episode_x_velocity': Array(419.8952, dtype=float32), 'eval/episode_y_position': Array(-199.4151, dtype=float32), 'eval/episode_y_velocity': Array(-72.74907, dtype=float32), 'eval/episode_distance_from_origin_std': Array(534.59247, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2022734, dtype=float32), 'eval/episode_forward_reward_std': Array(1033.7053, dtype=float32), 'eval/episode_reward_std': Array(1086.2217, dtype=float32), 'eval/episode_reward_alive_std': Array(35.926075, dtype=float32), 'eval/episode_reward_linvel_std': Array(1033.7053, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.87184, dtype=float32), 'eval/episode_x_position_std': Array(525.523, dtype=float32), 'eval/episode_x_velocity_std': Array(206.74112, dtype=float32), 'eval/episode_y_position_std': Array(315.6829, dtype=float32), 'eval/episode_y_velocity_std': Array(96.03545, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6979684829712, 'eval/sps': 936.3709016344693, 'num_steps': 10321920}
{'eval/walltime': 17519.713210105896, 'training/sps': 2938.558512841342, 'training/walltime': 3563.0807111263275, 'training/entropy_loss': Array(0.00900414, dtype=float32), 'training/policy_loss': Array(0.00476333, dtype=float32), 'training/total_loss': Array(0.08664964, dtype=float32), 'training/v_loss': Array(0.07288217, dtype=float32), 'eval/episode_distance_from_origin': Array(4627.241, dtype=float32), 'eval/episode_distance_reward': Array(11.774183, dtype=float32), 'eval/episode_forward_reward': Array(1962.3568, dtype=float32), 'eval/episode_reward': Array(1915.9977, dtype=float32), 'eval/episode_reward_alive': Array(422.64844, dtype=float32), 'eval/episode_reward_linvel': Array(1962.3568, dtype=float32), 'eval/episode_reward_quadctrl': Array(-480.78186, dtype=float32), 'eval/episode_x_position': Array(4579.954, dtype=float32), 'eval/episode_x_velocity': Array(392.47137, dtype=float32), 'eval/episode_y_position': Array(-233.91977, dtype=float32), 'eval/episode_y_velocity': Array(-73.43142, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.9296, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9346375, dtype=float32), 'eval/episode_forward_reward_std': Array(989.0994, dtype=float32), 'eval/episode_reward_std': Array(1037.5244, dtype=float32), 'eval/episode_reward_alive_std': Array(33.365772, dtype=float32), 'eval/episode_reward_linvel_std': Array(989.0994, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.59691, dtype=float32), 'eval/episode_x_position_std': Array(517.12683, dtype=float32), 'eval/episode_x_velocity_std': Array(197.8199, dtype=float32), 'eval/episode_y_position_std': Array(302.2949, dtype=float32), 'eval/episode_y_velocity_std': Array(86.80621, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52514052391052, 'eval/sps': 937.556258933735, 'num_steps': 10403840}
{'eval/walltime': 17656.398981571198, 'training/sps': 2928.7433921961538, 'training/walltime': 3591.051751613617, 'training/entropy_loss': Array(0.01251042, dtype=float32), 'training/policy_loss': Array(0.00265889, dtype=float32), 'training/total_loss': Array(0.08432579, dtype=float32), 'training/v_loss': Array(0.06915648, dtype=float32), 'eval/episode_distance_from_origin': Array(4586.1343, dtype=float32), 'eval/episode_distance_reward': Array(11.623568, dtype=float32), 'eval/episode_forward_reward': Array(1937.2545, dtype=float32), 'eval/episode_reward': Array(1895.9436, dtype=float32), 'eval/episode_reward_alive': Array(427.76953, dtype=float32), 'eval/episode_reward_linvel': Array(1937.2545, dtype=float32), 'eval/episode_reward_quadctrl': Array(-480.70398, dtype=float32), 'eval/episode_x_position': Array(4539.137, dtype=float32), 'eval/episode_x_velocity': Array(387.45093, dtype=float32), 'eval/episode_y_position': Array(-188.20074, dtype=float32), 'eval/episode_y_velocity': Array(-62.170258, dtype=float32), 'eval/episode_distance_from_origin_std': Array(540.1943, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3763227, dtype=float32), 'eval/episode_forward_reward_std': Array(1062.7131, dtype=float32), 'eval/episode_reward_std': Array(1109.3737, dtype=float32), 'eval/episode_reward_alive_std': Array(29.477541, dtype=float32), 'eval/episode_reward_linvel_std': Array(1062.7131, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.70248, dtype=float32), 'eval/episode_x_position_std': Array(529.75055, dtype=float32), 'eval/episode_x_velocity_std': Array(212.54262, dtype=float32), 'eval/episode_y_position_std': Array(316.10965, dtype=float32), 'eval/episode_y_velocity_std': Array(93.414276, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6857714653015, 'eval/sps': 936.4544577523459, 'num_steps': 10485760}
{'eval/walltime': 17792.813474178314, 'training/sps': 2938.843079518395, 'training/walltime': 3618.9266662597656, 'training/entropy_loss': Array(0.01497263, dtype=float32), 'training/policy_loss': Array(0.02825905, dtype=float32), 'training/total_loss': Array(0.09041798, dtype=float32), 'training/v_loss': Array(0.0471863, dtype=float32), 'eval/episode_distance_from_origin': Array(4636.4746, dtype=float32), 'eval/episode_distance_reward': Array(11.973588, dtype=float32), 'eval/episode_forward_reward': Array(1995.5906, dtype=float32), 'eval/episode_reward': Array(1957.1145, dtype=float32), 'eval/episode_reward_alive': Array(424.3789, dtype=float32), 'eval/episode_reward_linvel': Array(1995.5906, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.82883, dtype=float32), 'eval/episode_x_position': Array(4591.0986, dtype=float32), 'eval/episode_x_velocity': Array(399.11813, dtype=float32), 'eval/episode_y_position': Array(-211.383, dtype=float32), 'eval/episode_y_velocity': Array(-72.581566, dtype=float32), 'eval/episode_distance_from_origin_std': Array(534.17615, dtype=float32), 'eval/episode_distance_reward_std': Array(6.033332, dtype=float32), 'eval/episode_forward_reward_std': Array(1005.5486, dtype=float32), 'eval/episode_reward_std': Array(1054.6018, dtype=float32), 'eval/episode_reward_alive_std': Array(30.817617, dtype=float32), 'eval/episode_reward_linvel_std': Array(1005.5486, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.84434, dtype=float32), 'eval/episode_x_position_std': Array(521.0679, dtype=float32), 'eval/episode_x_velocity_std': Array(201.10973, dtype=float32), 'eval/episode_y_position_std': Array(290.78333, dtype=float32), 'eval/episode_y_velocity_std': Array(88.20274, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4144926071167, 'eval/sps': 938.3167253984441, 'num_steps': 10567680}
{'eval/walltime': 17929.56723999977, 'training/sps': 2938.32598924402, 'training/walltime': 3646.8064863681793, 'training/entropy_loss': Array(0.01607759, dtype=float32), 'training/policy_loss': Array(0.05391745, dtype=float32), 'training/total_loss': Array(0.10364686, dtype=float32), 'training/v_loss': Array(0.03365183, dtype=float32), 'eval/episode_distance_from_origin': Array(4619.167, dtype=float32), 'eval/episode_distance_reward': Array(11.682463, dtype=float32), 'eval/episode_forward_reward': Array(1947.0702, dtype=float32), 'eval/episode_reward': Array(1904.9009, dtype=float32), 'eval/episode_reward_alive': Array(417.8828, dtype=float32), 'eval/episode_reward_linvel': Array(1947.0702, dtype=float32), 'eval/episode_reward_quadctrl': Array(-471.73468, dtype=float32), 'eval/episode_x_position': Array(4575.038, dtype=float32), 'eval/episode_x_velocity': Array(389.41406, dtype=float32), 'eval/episode_y_position': Array(-210.32076, dtype=float32), 'eval/episode_y_velocity': Array(-72.76209, dtype=float32), 'eval/episode_distance_from_origin_std': Array(498.54422, dtype=float32), 'eval/episode_distance_reward_std': Array(5.539311, dtype=float32), 'eval/episode_forward_reward_std': Array(923.2123, dtype=float32), 'eval/episode_reward_std': Array(970.72253, dtype=float32), 'eval/episode_reward_alive_std': Array(40.737274, dtype=float32), 'eval/episode_reward_linvel_std': Array(923.2123, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.427994, dtype=float32), 'eval/episode_x_position_std': Array(485.8661, dtype=float32), 'eval/episode_x_velocity_std': Array(184.64249, dtype=float32), 'eval/episode_y_position_std': Array(263.38525, dtype=float32), 'eval/episode_y_velocity_std': Array(84.84319, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7537658214569, 'eval/sps': 935.9888499678638, 'num_steps': 10649600}
{'eval/walltime': 18065.957282066345, 'training/sps': 2936.942565317318, 'training/walltime': 3674.699439048767, 'training/entropy_loss': Array(0.01615787, dtype=float32), 'training/policy_loss': Array(0.01334966, dtype=float32), 'training/total_loss': Array(0.05230375, dtype=float32), 'training/v_loss': Array(0.02279622, dtype=float32), 'eval/episode_distance_from_origin': Array(4634.2803, dtype=float32), 'eval/episode_distance_reward': Array(12.19316, dtype=float32), 'eval/episode_forward_reward': Array(2032.1859, dtype=float32), 'eval/episode_reward': Array(1991.4565, dtype=float32), 'eval/episode_reward_alive': Array(413.33984, dtype=float32), 'eval/episode_reward_linvel': Array(2032.1859, dtype=float32), 'eval/episode_reward_quadctrl': Array(-466.26245, dtype=float32), 'eval/episode_x_position': Array(4588.067, dtype=float32), 'eval/episode_x_velocity': Array(406.43716, dtype=float32), 'eval/episode_y_position': Array(-204.74576, dtype=float32), 'eval/episode_y_velocity': Array(-71.13427, dtype=float32), 'eval/episode_distance_from_origin_std': Array(582.942, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6556334, dtype=float32), 'eval/episode_forward_reward_std': Array(1109.265, dtype=float32), 'eval/episode_reward_std': Array(1153.9795, dtype=float32), 'eval/episode_reward_alive_std': Array(39.717457, dtype=float32), 'eval/episode_reward_linvel_std': Array(1109.265, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.106247, dtype=float32), 'eval/episode_x_position_std': Array(570.8959, dtype=float32), 'eval/episode_x_velocity_std': Array(221.85298, dtype=float32), 'eval/episode_y_position_std': Array(310.3609, dtype=float32), 'eval/episode_y_velocity_std': Array(93.183846, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3900420665741, 'eval/sps': 938.4849367340265, 'num_steps': 10731520}
{'eval/walltime': 18202.804746627808, 'training/sps': 2935.244014732611, 'training/walltime': 3702.60853266716, 'training/entropy_loss': Array(0.00864332, dtype=float32), 'training/policy_loss': Array(-0.00094072, dtype=float32), 'training/total_loss': Array(0.04658636, dtype=float32), 'training/v_loss': Array(0.03888377, dtype=float32), 'eval/episode_distance_from_origin': Array(4687.2515, dtype=float32), 'eval/episode_distance_reward': Array(12.516708, dtype=float32), 'eval/episode_forward_reward': Array(2086.1104, dtype=float32), 'eval/episode_reward': Array(2040.3176, dtype=float32), 'eval/episode_reward_alive': Array(411.67188, dtype=float32), 'eval/episode_reward_linvel': Array(2086.1104, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.98157, dtype=float32), 'eval/episode_x_position': Array(4637.6875, dtype=float32), 'eval/episode_x_velocity': Array(417.2221, dtype=float32), 'eval/episode_y_position': Array(-240.31094, dtype=float32), 'eval/episode_y_velocity': Array(-82.49191, dtype=float32), 'eval/episode_distance_from_origin_std': Array(522.15765, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2020907, dtype=float32), 'eval/episode_forward_reward_std': Array(1033.675, dtype=float32), 'eval/episode_reward_std': Array(1079.9489, dtype=float32), 'eval/episode_reward_alive_std': Array(36.078552, dtype=float32), 'eval/episode_reward_linvel_std': Array(1033.675, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.508656, dtype=float32), 'eval/episode_x_position_std': Array(509.46136, dtype=float32), 'eval/episode_x_velocity_std': Array(206.73495, dtype=float32), 'eval/episode_y_position_std': Array(326.96194, dtype=float32), 'eval/episode_y_velocity_std': Array(94.72004, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8474645614624, 'eval/sps': 935.347983319861, 'num_steps': 10813440}
{'eval/walltime': 18339.180168628693, 'training/sps': 2937.4465371041692, 'training/walltime': 3730.496699810028, 'training/entropy_loss': Array(0.00730767, dtype=float32), 'training/policy_loss': Array(0.01928935, dtype=float32), 'training/total_loss': Array(0.09266051, dtype=float32), 'training/v_loss': Array(0.06606349, dtype=float32), 'eval/episode_distance_from_origin': Array(4641.856, dtype=float32), 'eval/episode_distance_reward': Array(11.895166, dtype=float32), 'eval/episode_forward_reward': Array(1982.5206, dtype=float32), 'eval/episode_reward': Array(1941.0271, dtype=float32), 'eval/episode_reward_alive': Array(416.9375, dtype=float32), 'eval/episode_reward_linvel': Array(1982.5206, dtype=float32), 'eval/episode_reward_quadctrl': Array(-470.3261, dtype=float32), 'eval/episode_x_position': Array(4595.0186, dtype=float32), 'eval/episode_x_velocity': Array(396.5041, dtype=float32), 'eval/episode_y_position': Array(-214.88101, dtype=float32), 'eval/episode_y_velocity': Array(-67.91597, dtype=float32), 'eval/episode_distance_from_origin_std': Array(541.84106, dtype=float32), 'eval/episode_distance_reward_std': Array(6.121407, dtype=float32), 'eval/episode_forward_reward_std': Array(1020.2277, dtype=float32), 'eval/episode_reward_std': Array(1066.9617, dtype=float32), 'eval/episode_reward_alive_std': Array(36.702137, dtype=float32), 'eval/episode_reward_linvel_std': Array(1020.2277, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.271572, dtype=float32), 'eval/episode_x_position_std': Array(526.596, dtype=float32), 'eval/episode_x_velocity_std': Array(204.04561, dtype=float32), 'eval/episode_y_position_std': Array(313.4665, dtype=float32), 'eval/episode_y_velocity_std': Array(90.063194, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.375422000885, 'eval/sps': 938.5855465889546, 'num_steps': 10895360}
{'eval/walltime': 18475.7282538414, 'training/sps': 2932.698667927566, 'training/walltime': 3758.4300162792206, 'training/entropy_loss': Array(0.01119303, dtype=float32), 'training/policy_loss': Array(0.00319251, dtype=float32), 'training/total_loss': Array(0.07638884, dtype=float32), 'training/v_loss': Array(0.0620033, dtype=float32), 'eval/episode_distance_from_origin': Array(4708.9043, dtype=float32), 'eval/episode_distance_reward': Array(12.780628, dtype=float32), 'eval/episode_forward_reward': Array(2130.0962, dtype=float32), 'eval/episode_reward': Array(2099.8755, dtype=float32), 'eval/episode_reward_alive': Array(420.2539, dtype=float32), 'eval/episode_reward_linvel': Array(2130.0962, dtype=float32), 'eval/episode_reward_quadctrl': Array(-463.2551, dtype=float32), 'eval/episode_x_position': Array(4654.6973, dtype=float32), 'eval/episode_x_velocity': Array(426.01926, dtype=float32), 'eval/episode_y_position': Array(-291.50092, dtype=float32), 'eval/episode_y_velocity': Array(-93.402725, dtype=float32), 'eval/episode_distance_from_origin_std': Array(556.03546, dtype=float32), 'eval/episode_distance_reward_std': Array(6.286421, dtype=float32), 'eval/episode_forward_reward_std': Array(1047.7303, dtype=float32), 'eval/episode_reward_std': Array(1098.16, dtype=float32), 'eval/episode_reward_alive_std': Array(35.885777, dtype=float32), 'eval/episode_reward_linvel_std': Array(1047.7303, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.412224, dtype=float32), 'eval/episode_x_position_std': Array(541.2457, dtype=float32), 'eval/episode_x_velocity_std': Array(209.54607, dtype=float32), 'eval/episode_y_position_std': Array(329.44446, dtype=float32), 'eval/episode_y_velocity_std': Array(95.51178, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54808521270752, 'eval/sps': 937.3987178260921, 'num_steps': 10977280}
{'eval/walltime': 18612.077750205994, 'training/sps': 2945.2125157158844, 'training/walltime': 3786.244647502899, 'training/entropy_loss': Array(0.01475018, dtype=float32), 'training/policy_loss': Array(0.00245451, dtype=float32), 'training/total_loss': Array(0.07025519, dtype=float32), 'training/v_loss': Array(0.0530505, dtype=float32), 'eval/episode_distance_from_origin': Array(4702.4575, dtype=float32), 'eval/episode_distance_reward': Array(12.562853, dtype=float32), 'eval/episode_forward_reward': Array(2093.801, dtype=float32), 'eval/episode_reward': Array(2064.864, dtype=float32), 'eval/episode_reward_alive': Array(420.5664, dtype=float32), 'eval/episode_reward_linvel': Array(2093.801, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.06647, dtype=float32), 'eval/episode_x_position': Array(4651.887, dtype=float32), 'eval/episode_x_velocity': Array(418.76022, dtype=float32), 'eval/episode_y_position': Array(-241.1007, dtype=float32), 'eval/episode_y_velocity': Array(-80.27383, dtype=float32), 'eval/episode_distance_from_origin_std': Array(565.0277, dtype=float32), 'eval/episode_distance_reward_std': Array(6.222099, dtype=float32), 'eval/episode_forward_reward_std': Array(1037.0101, dtype=float32), 'eval/episode_reward_std': Array(1086.8232, dtype=float32), 'eval/episode_reward_alive_std': Array(35.129467, dtype=float32), 'eval/episode_reward_linvel_std': Array(1037.0101, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.94335, dtype=float32), 'eval/episode_x_position_std': Array(549.70654, dtype=float32), 'eval/episode_x_velocity_std': Array(207.402, dtype=float32), 'eval/episode_y_position_std': Array(334.26077, dtype=float32), 'eval/episode_y_velocity_std': Array(96.80587, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3494963645935, 'eval/sps': 938.7640102295115, 'num_steps': 11059200}
{'eval/walltime': 18748.621477365494, 'training/sps': 2935.0938992037004, 'training/walltime': 3814.155168533325, 'training/entropy_loss': Array(0.0167243, dtype=float32), 'training/policy_loss': Array(0.00617361, dtype=float32), 'training/total_loss': Array(0.05886145, dtype=float32), 'training/v_loss': Array(0.03596354, dtype=float32), 'eval/episode_distance_from_origin': Array(4840.5874, dtype=float32), 'eval/episode_distance_reward': Array(14.15368, dtype=float32), 'eval/episode_forward_reward': Array(2358.937, dtype=float32), 'eval/episode_reward': Array(2343.332, dtype=float32), 'eval/episode_reward_alive': Array(418.3711, dtype=float32), 'eval/episode_reward_linvel': Array(2358.937, dtype=float32), 'eval/episode_reward_quadctrl': Array(-448.12964, dtype=float32), 'eval/episode_x_position': Array(4786.391, dtype=float32), 'eval/episode_x_velocity': Array(471.78735, dtype=float32), 'eval/episode_y_position': Array(-301.7171, dtype=float32), 'eval/episode_y_velocity': Array(-103.82919, dtype=float32), 'eval/episode_distance_from_origin_std': Array(581.2145, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6896143, dtype=float32), 'eval/episode_forward_reward_std': Array(1114.9286, dtype=float32), 'eval/episode_reward_std': Array(1164.7876, dtype=float32), 'eval/episode_reward_alive_std': Array(34.413002, dtype=float32), 'eval/episode_reward_linvel_std': Array(1114.9286, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.958557, dtype=float32), 'eval/episode_x_position_std': Array(567.3547, dtype=float32), 'eval/episode_x_velocity_std': Array(222.98573, dtype=float32), 'eval/episode_y_position_std': Array(325.71487, dtype=float32), 'eval/episode_y_velocity_std': Array(92.46783, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54372715950012, 'eval/sps': 937.4286366921859, 'num_steps': 11141120}
{'eval/walltime': 18884.998284101486, 'training/sps': 2930.269607494902, 'training/walltime': 3842.1116404533386, 'training/entropy_loss': Array(0.01786039, dtype=float32), 'training/policy_loss': Array(0.00748324, dtype=float32), 'training/total_loss': Array(0.05334058, dtype=float32), 'training/v_loss': Array(0.02799695, dtype=float32), 'eval/episode_distance_from_origin': Array(4670.1177, dtype=float32), 'eval/episode_distance_reward': Array(12.126743, dtype=float32), 'eval/episode_forward_reward': Array(2021.1166, dtype=float32), 'eval/episode_reward': Array(1990.3425, dtype=float32), 'eval/episode_reward_alive': Array(424.66406, dtype=float32), 'eval/episode_reward_linvel': Array(2021.1166, dtype=float32), 'eval/episode_reward_quadctrl': Array(-467.56464, dtype=float32), 'eval/episode_x_position': Array(4617.3105, dtype=float32), 'eval/episode_x_velocity': Array(404.22327, dtype=float32), 'eval/episode_y_position': Array(-258.54968, dtype=float32), 'eval/episode_y_velocity': Array(-86.55663, dtype=float32), 'eval/episode_distance_from_origin_std': Array(567.9513, dtype=float32), 'eval/episode_distance_reward_std': Array(6.051272, dtype=float32), 'eval/episode_forward_reward_std': Array(1008.53864, dtype=float32), 'eval/episode_reward_std': Array(1053.9064, dtype=float32), 'eval/episode_reward_alive_std': Array(37.980675, dtype=float32), 'eval/episode_reward_linvel_std': Array(1008.53864, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.591625, dtype=float32), 'eval/episode_x_position_std': Array(553.3036, dtype=float32), 'eval/episode_x_velocity_std': Array(201.7077, dtype=float32), 'eval/episode_y_position_std': Array(338.6445, dtype=float32), 'eval/episode_y_velocity_std': Array(97.98176, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37680673599243, 'eval/sps': 938.5760164321135, 'num_steps': 11223040}
{'eval/walltime': 19021.56707048416, 'training/sps': 2935.0665706526984, 'training/walltime': 3870.022421360016, 'training/entropy_loss': Array(0.01204201, dtype=float32), 'training/policy_loss': Array(0.00134471, dtype=float32), 'training/total_loss': Array(0.04704511, dtype=float32), 'training/v_loss': Array(0.03365839, dtype=float32), 'eval/episode_distance_from_origin': Array(4691.976, dtype=float32), 'eval/episode_distance_reward': Array(12.060383, dtype=float32), 'eval/episode_forward_reward': Array(2010.0564, dtype=float32), 'eval/episode_reward': Array(1963.5308, dtype=float32), 'eval/episode_reward_alive': Array(409.23438, dtype=float32), 'eval/episode_reward_linvel': Array(2010.0564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-467.82043, dtype=float32), 'eval/episode_x_position': Array(4641.6206, dtype=float32), 'eval/episode_x_velocity': Array(402.01126, dtype=float32), 'eval/episode_y_position': Array(-269.82758, dtype=float32), 'eval/episode_y_velocity': Array(-83.17343, dtype=float32), 'eval/episode_distance_from_origin_std': Array(512.7025, dtype=float32), 'eval/episode_distance_reward_std': Array(5.38347, dtype=float32), 'eval/episode_forward_reward_std': Array(897.239, dtype=float32), 'eval/episode_reward_std': Array(942.80884, dtype=float32), 'eval/episode_reward_alive_std': Array(48.00585, dtype=float32), 'eval/episode_reward_linvel_std': Array(897.239, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.85043, dtype=float32), 'eval/episode_x_position_std': Array(496.1124, dtype=float32), 'eval/episode_x_velocity_std': Array(179.44783, dtype=float32), 'eval/episode_y_position_std': Array(320.7439, dtype=float32), 'eval/episode_y_velocity_std': Array(91.47666, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56878638267517, 'eval/sps': 937.2566264251274, 'num_steps': 11304960}
{'eval/walltime': 19158.10449695587, 'training/sps': 2943.0556845793226, 'training/walltime': 3897.857436656952, 'training/entropy_loss': Array(0.00677653, dtype=float32), 'training/policy_loss': Array(-3.664408e-05, dtype=float32), 'training/total_loss': Array(0.07409052, dtype=float32), 'training/v_loss': Array(0.06735064, dtype=float32), 'eval/episode_distance_from_origin': Array(4741.5957, dtype=float32), 'eval/episode_distance_reward': Array(13.168128, dtype=float32), 'eval/episode_forward_reward': Array(2194.68, dtype=float32), 'eval/episode_reward': Array(2167.5464, dtype=float32), 'eval/episode_reward_alive': Array(421.21094, dtype=float32), 'eval/episode_reward_linvel': Array(2194.68, dtype=float32), 'eval/episode_reward_quadctrl': Array(-461.51245, dtype=float32), 'eval/episode_x_position': Array(4692.38, dtype=float32), 'eval/episode_x_velocity': Array(438.9359, dtype=float32), 'eval/episode_y_position': Array(-256.60428, dtype=float32), 'eval/episode_y_velocity': Array(-86.94342, dtype=float32), 'eval/episode_distance_from_origin_std': Array(564.86926, dtype=float32), 'eval/episode_distance_reward_std': Array(6.7135224, dtype=float32), 'eval/episode_forward_reward_std': Array(1118.9137, dtype=float32), 'eval/episode_reward_std': Array(1172.8429, dtype=float32), 'eval/episode_reward_alive_std': Array(34.489445, dtype=float32), 'eval/episode_reward_linvel_std': Array(1118.9137, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.970184, dtype=float32), 'eval/episode_x_position_std': Array(553.27734, dtype=float32), 'eval/episode_x_velocity_std': Array(223.78271, dtype=float32), 'eval/episode_y_position_std': Array(314.0775, dtype=float32), 'eval/episode_y_velocity_std': Array(90.54262, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5374264717102, 'eval/sps': 937.4718954917529, 'num_steps': 11386880}
{'eval/walltime': 19294.590247392654, 'training/sps': 2939.0537627252866, 'training/walltime': 3925.730353116989, 'training/entropy_loss': Array(0.01029341, dtype=float32), 'training/policy_loss': Array(0.00112829, dtype=float32), 'training/total_loss': Array(0.08195393, dtype=float32), 'training/v_loss': Array(0.07053223, dtype=float32), 'eval/episode_distance_from_origin': Array(4802.3916, dtype=float32), 'eval/episode_distance_reward': Array(13.387608, dtype=float32), 'eval/episode_forward_reward': Array(2231.2593, dtype=float32), 'eval/episode_reward': Array(2200.9805, dtype=float32), 'eval/episode_reward_alive': Array(421.33203, dtype=float32), 'eval/episode_reward_linvel': Array(2231.2593, dtype=float32), 'eval/episode_reward_quadctrl': Array(-464.99838, dtype=float32), 'eval/episode_x_position': Array(4750.789, dtype=float32), 'eval/episode_x_velocity': Array(446.25183, dtype=float32), 'eval/episode_y_position': Array(-298.8692, dtype=float32), 'eval/episode_y_velocity': Array(-94.02278, dtype=float32), 'eval/episode_distance_from_origin_std': Array(565.3458, dtype=float32), 'eval/episode_distance_reward_std': Array(6.520594, dtype=float32), 'eval/episode_forward_reward_std': Array(1086.7589, dtype=float32), 'eval/episode_reward_std': Array(1135.8198, dtype=float32), 'eval/episode_reward_alive_std': Array(33.834114, dtype=float32), 'eval/episode_reward_linvel_std': Array(1086.7589, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.89445, dtype=float32), 'eval/episode_x_position_std': Array(552.33215, dtype=float32), 'eval/episode_x_velocity_std': Array(217.35179, dtype=float32), 'eval/episode_y_position_std': Array(309.13742, dtype=float32), 'eval/episode_y_velocity_std': Array(92.15892, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48575043678284, 'eval/sps': 937.8268397277616, 'num_steps': 11468800}
{'eval/walltime': 19431.054997205734, 'training/sps': 2942.423691822377, 'training/walltime': 3953.5713469982147, 'training/entropy_loss': Array(0.01456185, dtype=float32), 'training/policy_loss': Array(0.007252, dtype=float32), 'training/total_loss': Array(0.08680952, dtype=float32), 'training/v_loss': Array(0.06499567, dtype=float32), 'eval/episode_distance_from_origin': Array(4757.5054, dtype=float32), 'eval/episode_distance_reward': Array(12.822699, dtype=float32), 'eval/episode_forward_reward': Array(2137.1084, dtype=float32), 'eval/episode_reward': Array(2102.2131, dtype=float32), 'eval/episode_reward_alive': Array(422.39453, dtype=float32), 'eval/episode_reward_linvel': Array(2137.1084, dtype=float32), 'eval/episode_reward_quadctrl': Array(-470.1129, dtype=float32), 'eval/episode_x_position': Array(4705.149, dtype=float32), 'eval/episode_x_velocity': Array(427.42172, dtype=float32), 'eval/episode_y_position': Array(-297.7696, dtype=float32), 'eval/episode_y_velocity': Array(-89.8369, dtype=float32), 'eval/episode_distance_from_origin_std': Array(578.44464, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4275894, dtype=float32), 'eval/episode_forward_reward_std': Array(1071.258, dtype=float32), 'eval/episode_reward_std': Array(1119.521, dtype=float32), 'eval/episode_reward_alive_std': Array(35.41758, dtype=float32), 'eval/episode_reward_linvel_std': Array(1071.258, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.629044, dtype=float32), 'eval/episode_x_position_std': Array(562.5729, dtype=float32), 'eval/episode_x_velocity_std': Array(214.25172, dtype=float32), 'eval/episode_y_position_std': Array(323.0793, dtype=float32), 'eval/episode_y_velocity_std': Array(92.713684, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46474981307983, 'eval/sps': 937.9711623355169, 'num_steps': 11550720}
{'eval/walltime': 19567.66189646721, 'training/sps': 2937.6278354907677, 'training/walltime': 3981.4577929973602, 'training/entropy_loss': Array(0.01755368, dtype=float32), 'training/policy_loss': Array(0.00931401, dtype=float32), 'training/total_loss': Array(0.05989729, dtype=float32), 'training/v_loss': Array(0.03302961, dtype=float32), 'eval/episode_distance_from_origin': Array(4772.5483, dtype=float32), 'eval/episode_distance_reward': Array(13.078617, dtype=float32), 'eval/episode_forward_reward': Array(2179.7612, dtype=float32), 'eval/episode_reward': Array(2156.2795, dtype=float32), 'eval/episode_reward_alive': Array(428.23828, dtype=float32), 'eval/episode_reward_linvel': Array(2179.7612, dtype=float32), 'eval/episode_reward_quadctrl': Array(-464.79865, dtype=float32), 'eval/episode_x_position': Array(4722.8745, dtype=float32), 'eval/episode_x_velocity': Array(435.95224, dtype=float32), 'eval/episode_y_position': Array(-259.9291, dtype=float32), 'eval/episode_y_velocity': Array(-86.11754, dtype=float32), 'eval/episode_distance_from_origin_std': Array(576.21826, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3963895, dtype=float32), 'eval/episode_forward_reward_std': Array(1066.0587, dtype=float32), 'eval/episode_reward_std': Array(1114.1476, dtype=float32), 'eval/episode_reward_alive_std': Array(32.609367, dtype=float32), 'eval/episode_reward_linvel_std': Array(1066.0587, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.017326, dtype=float32), 'eval/episode_x_position_std': Array(563.2222, dtype=float32), 'eval/episode_x_velocity_std': Array(213.21167, dtype=float32), 'eval/episode_y_position_std': Array(315.18982, dtype=float32), 'eval/episode_y_velocity_std': Array(91.30862, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6068992614746, 'eval/sps': 936.9951348869984, 'num_steps': 11632640}
{'eval/walltime': 19704.069157361984, 'training/sps': 2948.5155714043576, 'training/walltime': 4009.2412650585175, 'training/entropy_loss': Array(0.01917207, dtype=float32), 'training/policy_loss': Array(0.01425582, dtype=float32), 'training/total_loss': Array(0.0561522, dtype=float32), 'training/v_loss': Array(0.02272431, dtype=float32), 'eval/episode_distance_from_origin': Array(4788.797, dtype=float32), 'eval/episode_distance_reward': Array(13.565034, dtype=float32), 'eval/episode_forward_reward': Array(2260.8298, dtype=float32), 'eval/episode_reward': Array(2247.8936, dtype=float32), 'eval/episode_reward_alive': Array(428.23047, dtype=float32), 'eval/episode_reward_linvel': Array(2260.8298, dtype=float32), 'eval/episode_reward_quadctrl': Array(-454.73196, dtype=float32), 'eval/episode_x_position': Array(4738.3115, dtype=float32), 'eval/episode_x_velocity': Array(452.16595, dtype=float32), 'eval/episode_y_position': Array(-276.26013, dtype=float32), 'eval/episode_y_velocity': Array(-90.88043, dtype=float32), 'eval/episode_distance_from_origin_std': Array(601.1911, dtype=float32), 'eval/episode_distance_reward_std': Array(6.8400526, dtype=float32), 'eval/episode_forward_reward_std': Array(1140.0015, dtype=float32), 'eval/episode_reward_std': Array(1186.0066, dtype=float32), 'eval/episode_reward_alive_std': Array(33.002953, dtype=float32), 'eval/episode_reward_linvel_std': Array(1140.0015, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.527554, dtype=float32), 'eval/episode_x_position_std': Array(588.6062, dtype=float32), 'eval/episode_x_velocity_std': Array(228.00029, dtype=float32), 'eval/episode_y_position_std': Array(314.8085, dtype=float32), 'eval/episode_y_velocity_std': Array(90.64982, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4072608947754, 'eval/sps': 938.3664708196087, 'num_steps': 11714560}
{'eval/walltime': 19840.782394886017, 'training/sps': 2945.79221524927, 'training/walltime': 4037.050422668457, 'training/entropy_loss': Array(0.01551423, dtype=float32), 'training/policy_loss': Array(-7.0323294e-05, dtype=float32), 'training/total_loss': Array(0.0318229, dtype=float32), 'training/v_loss': Array(0.01637899, dtype=float32), 'eval/episode_distance_from_origin': Array(4655.9336, dtype=float32), 'eval/episode_distance_reward': Array(11.885672, dtype=float32), 'eval/episode_forward_reward': Array(1980.9382, dtype=float32), 'eval/episode_reward': Array(1936.7831, dtype=float32), 'eval/episode_reward_alive': Array(417.26172, dtype=float32), 'eval/episode_reward_linvel': Array(1980.9382, dtype=float32), 'eval/episode_reward_quadctrl': Array(-473.30225, dtype=float32), 'eval/episode_x_position': Array(4608.058, dtype=float32), 'eval/episode_x_velocity': Array(396.1876, dtype=float32), 'eval/episode_y_position': Array(-273.6045, dtype=float32), 'eval/episode_y_velocity': Array(-80.56857, dtype=float32), 'eval/episode_distance_from_origin_std': Array(531.64905, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6332197, dtype=float32), 'eval/episode_forward_reward_std': Array(938.86395, dtype=float32), 'eval/episode_reward_std': Array(986.9039, dtype=float32), 'eval/episode_reward_alive_std': Array(40.556145, dtype=float32), 'eval/episode_reward_linvel_std': Array(938.86395, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.14844, dtype=float32), 'eval/episode_x_position_std': Array(518.6111, dtype=float32), 'eval/episode_x_velocity_std': Array(187.77277, dtype=float32), 'eval/episode_y_position_std': Array(276.8769, dtype=float32), 'eval/episode_y_velocity_std': Array(80.23277, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7132375240326, 'eval/sps': 936.2663215220771, 'num_steps': 11796480}
{'eval/walltime': 19977.19709420204, 'training/sps': 2944.132077992469, 'training/walltime': 4064.8752613067627, 'training/entropy_loss': Array(0.00716864, dtype=float32), 'training/policy_loss': Array(0.00121375, dtype=float32), 'training/total_loss': Array(0.06502999, dtype=float32), 'training/v_loss': Array(0.05664761, dtype=float32), 'eval/episode_distance_from_origin': Array(4737.7407, dtype=float32), 'eval/episode_distance_reward': Array(12.918457, dtype=float32), 'eval/episode_forward_reward': Array(2153.0679, dtype=float32), 'eval/episode_reward': Array(2121.7783, dtype=float32), 'eval/episode_reward_alive': Array(422.6172, dtype=float32), 'eval/episode_reward_linvel': Array(2153.0679, dtype=float32), 'eval/episode_reward_quadctrl': Array(-466.825, dtype=float32), 'eval/episode_x_position': Array(4686.8467, dtype=float32), 'eval/episode_x_velocity': Array(430.61353, dtype=float32), 'eval/episode_y_position': Array(-290.0971, dtype=float32), 'eval/episode_y_velocity': Array(-91.86977, dtype=float32), 'eval/episode_distance_from_origin_std': Array(553.5798, dtype=float32), 'eval/episode_distance_reward_std': Array(6.17625, dtype=float32), 'eval/episode_forward_reward_std': Array(1029.3685, dtype=float32), 'eval/episode_reward_std': Array(1073.1528, dtype=float32), 'eval/episode_reward_alive_std': Array(34.55908, dtype=float32), 'eval/episode_reward_linvel_std': Array(1029.3685, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.84014, dtype=float32), 'eval/episode_x_position_std': Array(538.1414, dtype=float32), 'eval/episode_x_velocity_std': Array(205.87373, dtype=float32), 'eval/episode_y_position_std': Array(299.7698, dtype=float32), 'eval/episode_y_velocity_std': Array(86.482315, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41469931602478, 'eval/sps': 938.3153035690759, 'num_steps': 11878400}
{'eval/walltime': 20113.761562108994, 'training/sps': 2944.0543305886645, 'training/walltime': 4092.700834751129, 'training/entropy_loss': Array(0.01034809, dtype=float32), 'training/policy_loss': Array(0.00444964, dtype=float32), 'training/total_loss': Array(0.10117806, dtype=float32), 'training/v_loss': Array(0.08638033, dtype=float32), 'eval/episode_distance_from_origin': Array(4697.0996, dtype=float32), 'eval/episode_distance_reward': Array(12.315946, dtype=float32), 'eval/episode_forward_reward': Array(2052.65, dtype=float32), 'eval/episode_reward': Array(2020.1382, dtype=float32), 'eval/episode_reward_alive': Array(428.7461, dtype=float32), 'eval/episode_reward_linvel': Array(2052.65, dtype=float32), 'eval/episode_reward_quadctrl': Array(-473.57373, dtype=float32), 'eval/episode_x_position': Array(4649.675, dtype=float32), 'eval/episode_x_velocity': Array(410.52997, dtype=float32), 'eval/episode_y_position': Array(-248.77835, dtype=float32), 'eval/episode_y_velocity': Array(-79.25831, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.8225, dtype=float32), 'eval/episode_distance_reward_std': Array(6.05587, dtype=float32), 'eval/episode_forward_reward_std': Array(1009.3053, dtype=float32), 'eval/episode_reward_std': Array(1058.5238, dtype=float32), 'eval/episode_reward_alive_std': Array(31.195452, dtype=float32), 'eval/episode_reward_linvel_std': Array(1009.3053, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.843475, dtype=float32), 'eval/episode_x_position_std': Array(518.9955, dtype=float32), 'eval/episode_x_velocity_std': Array(201.86108, dtype=float32), 'eval/episode_y_position_std': Array(287.69916, dtype=float32), 'eval/episode_y_velocity_std': Array(82.98637, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5644679069519, 'eval/sps': 937.2862645883313, 'num_steps': 11960320}
{'eval/walltime': 20250.26856160164, 'training/sps': 2948.733135130501, 'training/walltime': 4120.482256889343, 'training/entropy_loss': Array(0.0138956, dtype=float32), 'training/policy_loss': Array(0.00733331, dtype=float32), 'training/total_loss': Array(0.09544596, dtype=float32), 'training/v_loss': Array(0.07421704, dtype=float32), 'eval/episode_distance_from_origin': Array(4684.7944, dtype=float32), 'eval/episode_distance_reward': Array(12.343662, dtype=float32), 'eval/episode_forward_reward': Array(2057.2698, dtype=float32), 'eval/episode_reward': Array(2022.3132, dtype=float32), 'eval/episode_reward_alive': Array(426.7578, dtype=float32), 'eval/episode_reward_linvel': Array(2057.2698, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.0579, dtype=float32), 'eval/episode_x_position': Array(4643.038, dtype=float32), 'eval/episode_x_velocity': Array(411.45392, dtype=float32), 'eval/episode_y_position': Array(-189.32285, dtype=float32), 'eval/episode_y_velocity': Array(-64.11807, dtype=float32), 'eval/episode_distance_from_origin_std': Array(575.5388, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5251665, dtype=float32), 'eval/episode_forward_reward_std': Array(1087.5206, dtype=float32), 'eval/episode_reward_std': Array(1136.1913, dtype=float32), 'eval/episode_reward_alive_std': Array(32.181187, dtype=float32), 'eval/episode_reward_linvel_std': Array(1087.5206, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.9174, dtype=float32), 'eval/episode_x_position_std': Array(565.1841, dtype=float32), 'eval/episode_x_velocity_std': Array(217.50417, dtype=float32), 'eval/episode_y_position_std': Array(268.42914, dtype=float32), 'eval/episode_y_velocity_std': Array(79.19396, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50699949264526, 'eval/sps': 937.680855016496, 'num_steps': 12042240}
{'eval/walltime': 20386.68682360649, 'training/sps': 2944.7599087940234, 'training/walltime': 4148.301163196564, 'training/entropy_loss': Array(0.01730299, dtype=float32), 'training/policy_loss': Array(0.0083327, dtype=float32), 'training/total_loss': Array(0.06871879, dtype=float32), 'training/v_loss': Array(0.0430831, dtype=float32), 'eval/episode_distance_from_origin': Array(4780.3345, dtype=float32), 'eval/episode_distance_reward': Array(13.279512, dtype=float32), 'eval/episode_forward_reward': Array(2213.2432, dtype=float32), 'eval/episode_reward': Array(2183.8516, dtype=float32), 'eval/episode_reward_alive': Array(422.01953, dtype=float32), 'eval/episode_reward_linvel': Array(2213.2432, dtype=float32), 'eval/episode_reward_quadctrl': Array(-464.69086, dtype=float32), 'eval/episode_x_position': Array(4735.449, dtype=float32), 'eval/episode_x_velocity': Array(442.64862, dtype=float32), 'eval/episode_y_position': Array(-233.8273, dtype=float32), 'eval/episode_y_velocity': Array(-77.78971, dtype=float32), 'eval/episode_distance_from_origin_std': Array(606.3611, dtype=float32), 'eval/episode_distance_reward_std': Array(6.767429, dtype=float32), 'eval/episode_forward_reward_std': Array(1127.8975, dtype=float32), 'eval/episode_reward_std': Array(1180.9116, dtype=float32), 'eval/episode_reward_alive_std': Array(46.636284, dtype=float32), 'eval/episode_reward_linvel_std': Array(1127.8975, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.541626, dtype=float32), 'eval/episode_x_position_std': Array(595.0961, dtype=float32), 'eval/episode_x_velocity_std': Array(225.57947, dtype=float32), 'eval/episode_y_position_std': Array(275.85843, dtype=float32), 'eval/episode_y_velocity_std': Array(84.01134, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4182620048523, 'eval/sps': 938.2907985988498, 'num_steps': 12124160}
{'eval/walltime': 20523.029515981674, 'training/sps': 2954.0713606077416, 'training/walltime': 4176.032382249832, 'training/entropy_loss': Array(0.01900724, dtype=float32), 'training/policy_loss': Array(0.01782412, dtype=float32), 'training/total_loss': Array(0.06565645, dtype=float32), 'training/v_loss': Array(0.02882509, dtype=float32), 'eval/episode_distance_from_origin': Array(4860.7217, dtype=float32), 'eval/episode_distance_reward': Array(13.784791, dtype=float32), 'eval/episode_forward_reward': Array(2297.456, dtype=float32), 'eval/episode_reward': Array(2274.995, dtype=float32), 'eval/episode_reward_alive': Array(426.73047, dtype=float32), 'eval/episode_reward_linvel': Array(2297.456, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.9762, dtype=float32), 'eval/episode_x_position': Array(4811.071, dtype=float32), 'eval/episode_x_velocity': Array(459.49115, dtype=float32), 'eval/episode_y_position': Array(-298.27478, dtype=float32), 'eval/episode_y_velocity': Array(-93.01175, dtype=float32), 'eval/episode_distance_from_origin_std': Array(569.90045, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3217955, dtype=float32), 'eval/episode_forward_reward_std': Array(1053.626, dtype=float32), 'eval/episode_reward_std': Array(1103.6952, dtype=float32), 'eval/episode_reward_alive_std': Array(41.49397, dtype=float32), 'eval/episode_reward_linvel_std': Array(1053.626, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.301544, dtype=float32), 'eval/episode_x_position_std': Array(558.3051, dtype=float32), 'eval/episode_x_velocity_std': Array(210.72511, dtype=float32), 'eval/episode_y_position_std': Array(286.30014, dtype=float32), 'eval/episode_y_velocity_std': Array(83.18181, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3426923751831, 'eval/sps': 938.810857920966, 'num_steps': 12206080}
{'eval/walltime': 20659.478410959244, 'training/sps': 2940.639820657262, 'training/walltime': 4203.890265226364, 'training/entropy_loss': Array(0.02019738, dtype=float32), 'training/policy_loss': Array(0.00567965, dtype=float32), 'training/total_loss': Array(0.04466186, dtype=float32), 'training/v_loss': Array(0.01878483, dtype=float32), 'eval/episode_distance_from_origin': Array(4907.114, dtype=float32), 'eval/episode_distance_reward': Array(14.381752, dtype=float32), 'eval/episode_forward_reward': Array(2396.9487, dtype=float32), 'eval/episode_reward': Array(2379.4077, dtype=float32), 'eval/episode_reward_alive': Array(430.76172, dtype=float32), 'eval/episode_reward_linvel': Array(2396.9487, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.68433, dtype=float32), 'eval/episode_x_position': Array(4854.969, dtype=float32), 'eval/episode_x_velocity': Array(479.3897, dtype=float32), 'eval/episode_y_position': Array(-321.37445, dtype=float32), 'eval/episode_y_velocity': Array(-101.51436, dtype=float32), 'eval/episode_distance_from_origin_std': Array(647.4498, dtype=float32), 'eval/episode_distance_reward_std': Array(7.2435527, dtype=float32), 'eval/episode_forward_reward_std': Array(1207.2507, dtype=float32), 'eval/episode_reward_std': Array(1255.3278, dtype=float32), 'eval/episode_reward_alive_std': Array(31.988337, dtype=float32), 'eval/episode_reward_linvel_std': Array(1207.2507, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.473392, dtype=float32), 'eval/episode_x_position_std': Array(638.2606, dtype=float32), 'eval/episode_x_velocity_std': Array(241.45016, dtype=float32), 'eval/episode_y_position_std': Array(300.79416, dtype=float32), 'eval/episode_y_velocity_std': Array(88.04625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44889497756958, 'eval/sps': 938.0801509681814, 'num_steps': 12288000}
{'eval/walltime': 20795.83075594902, 'training/sps': 2951.603941627344, 'training/walltime': 4231.644666433334, 'training/entropy_loss': Array(0.00627659, dtype=float32), 'training/policy_loss': Array(0.00015646, dtype=float32), 'training/total_loss': Array(0.0488189, dtype=float32), 'training/v_loss': Array(0.04238585, dtype=float32), 'eval/episode_distance_from_origin': Array(4819.1406, dtype=float32), 'eval/episode_distance_reward': Array(13.196215, dtype=float32), 'eval/episode_forward_reward': Array(2199.3608, dtype=float32), 'eval/episode_reward': Array(2166.1655, dtype=float32), 'eval/episode_reward_alive': Array(432.17578, dtype=float32), 'eval/episode_reward_linvel': Array(2199.3608, dtype=float32), 'eval/episode_reward_quadctrl': Array(-478.56754, dtype=float32), 'eval/episode_x_position': Array(4769.9766, dtype=float32), 'eval/episode_x_velocity': Array(439.8722, dtype=float32), 'eval/episode_y_position': Array(-297.6027, dtype=float32), 'eval/episode_y_velocity': Array(-88.0321, dtype=float32), 'eval/episode_distance_from_origin_std': Array(631.26855, dtype=float32), 'eval/episode_distance_reward_std': Array(6.95064, dtype=float32), 'eval/episode_forward_reward_std': Array(1158.4329, dtype=float32), 'eval/episode_reward_std': Array(1208.616, dtype=float32), 'eval/episode_reward_alive_std': Array(28.42442, dtype=float32), 'eval/episode_reward_linvel_std': Array(1158.4329, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.329624, dtype=float32), 'eval/episode_x_position_std': Array(618.4403, dtype=float32), 'eval/episode_x_velocity_std': Array(231.6866, dtype=float32), 'eval/episode_y_position_std': Array(293.39673, dtype=float32), 'eval/episode_y_velocity_std': Array(86.28814, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3523449897766, 'eval/sps': 938.7443979023401, 'num_steps': 12369920}
{'eval/walltime': 20932.259584903717, 'training/sps': 2944.64397132176, 'training/walltime': 4259.464668035507, 'training/entropy_loss': Array(0.00907398, dtype=float32), 'training/policy_loss': Array(0.00213754, dtype=float32), 'training/total_loss': Array(0.08738538, dtype=float32), 'training/v_loss': Array(0.07617386, dtype=float32), 'eval/episode_distance_from_origin': Array(4775.0146, dtype=float32), 'eval/episode_distance_reward': Array(13.0482, dtype=float32), 'eval/episode_forward_reward': Array(2174.6917, dtype=float32), 'eval/episode_reward': Array(2141.5376, dtype=float32), 'eval/episode_reward_alive': Array(427.96484, dtype=float32), 'eval/episode_reward_linvel': Array(2174.6917, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.167, dtype=float32), 'eval/episode_x_position': Array(4730.574, dtype=float32), 'eval/episode_x_velocity': Array(434.93823, dtype=float32), 'eval/episode_y_position': Array(-257.25626, dtype=float32), 'eval/episode_y_velocity': Array(-80.023926, dtype=float32), 'eval/episode_distance_from_origin_std': Array(629.33716, dtype=float32), 'eval/episode_distance_reward_std': Array(6.809487, dtype=float32), 'eval/episode_forward_reward_std': Array(1134.9081, dtype=float32), 'eval/episode_reward_std': Array(1190.0918, dtype=float32), 'eval/episode_reward_alive_std': Array(31.969234, dtype=float32), 'eval/episode_reward_linvel_std': Array(1134.9081, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.774605, dtype=float32), 'eval/episode_x_position_std': Array(618.6212, dtype=float32), 'eval/episode_x_velocity_std': Array(226.98148, dtype=float32), 'eval/episode_y_position_std': Array(259.437, dtype=float32), 'eval/episode_y_velocity_std': Array(79.04969, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42882895469666, 'eval/sps': 938.2181242829873, 'num_steps': 12451840}
{'eval/walltime': 21068.6415245533, 'training/sps': 2956.964357963881, 'training/walltime': 4287.16875576973, 'training/entropy_loss': Array(0.01284125, dtype=float32), 'training/policy_loss': Array(0.0054769, dtype=float32), 'training/total_loss': Array(0.09222119, dtype=float32), 'training/v_loss': Array(0.07390304, dtype=float32), 'eval/episode_distance_from_origin': Array(4787.3438, dtype=float32), 'eval/episode_distance_reward': Array(12.972004, dtype=float32), 'eval/episode_forward_reward': Array(2161.9922, dtype=float32), 'eval/episode_reward': Array(2133.2954, dtype=float32), 'eval/episode_reward_alive': Array(430.6172, dtype=float32), 'eval/episode_reward_linvel': Array(2161.9922, dtype=float32), 'eval/episode_reward_quadctrl': Array(-472.28625, dtype=float32), 'eval/episode_x_position': Array(4738.7847, dtype=float32), 'eval/episode_x_velocity': Array(432.39847, dtype=float32), 'eval/episode_y_position': Array(-285.88483, dtype=float32), 'eval/episode_y_velocity': Array(-82.88249, dtype=float32), 'eval/episode_distance_from_origin_std': Array(612.86456, dtype=float32), 'eval/episode_distance_reward_std': Array(6.542344, dtype=float32), 'eval/episode_forward_reward_std': Array(1090.3838, dtype=float32), 'eval/episode_reward_std': Array(1137.3326, dtype=float32), 'eval/episode_reward_alive_std': Array(29.524717, dtype=float32), 'eval/episode_reward_linvel_std': Array(1090.3838, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.684837, dtype=float32), 'eval/episode_x_position_std': Array(601.7208, dtype=float32), 'eval/episode_x_velocity_std': Array(218.07677, dtype=float32), 'eval/episode_y_position_std': Array(282.37604, dtype=float32), 'eval/episode_y_velocity_std': Array(83.85103, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3819396495819, 'eval/sps': 938.5406918898619, 'num_steps': 12533760}
{'eval/walltime': 21205.098841667175, 'training/sps': 2948.9695614244656, 'training/walltime': 4314.947950601578, 'training/entropy_loss': Array(0.01614534, dtype=float32), 'training/policy_loss': Array(0.0084193, dtype=float32), 'training/total_loss': Array(0.07567476, dtype=float32), 'training/v_loss': Array(0.05111012, dtype=float32), 'eval/episode_distance_from_origin': Array(5041.145, dtype=float32), 'eval/episode_distance_reward': Array(16.076794, dtype=float32), 'eval/episode_forward_reward': Array(2679.4536, dtype=float32), 'eval/episode_reward': Array(2673.4434, dtype=float32), 'eval/episode_reward_alive': Array(428.22266, dtype=float32), 'eval/episode_reward_linvel': Array(2679.4536, dtype=float32), 'eval/episode_reward_quadctrl': Array(-450.30942, dtype=float32), 'eval/episode_x_position': Array(4993.7183, dtype=float32), 'eval/episode_x_velocity': Array(535.8907, dtype=float32), 'eval/episode_y_position': Array(-263.70233, dtype=float32), 'eval/episode_y_velocity': Array(-91.55722, dtype=float32), 'eval/episode_distance_from_origin_std': Array(636.01294, dtype=float32), 'eval/episode_distance_reward_std': Array(7.660819, dtype=float32), 'eval/episode_forward_reward_std': Array(1276.7954, dtype=float32), 'eval/episode_reward_std': Array(1328.608, dtype=float32), 'eval/episode_reward_alive_std': Array(30.874102, dtype=float32), 'eval/episode_reward_linvel_std': Array(1276.7954, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(57.769966, dtype=float32), 'eval/episode_x_position_std': Array(628.0287, dtype=float32), 'eval/episode_x_velocity_std': Array(255.35904, dtype=float32), 'eval/episode_y_position_std': Array(304.35745, dtype=float32), 'eval/episode_y_velocity_std': Array(92.37261, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45731711387634, 'eval/sps': 938.0222527252346, 'num_steps': 12615680}
{'eval/walltime': 21341.433371782303, 'training/sps': 2938.6980748259293, 'training/walltime': 4342.824240684509, 'training/entropy_loss': Array(0.01851051, dtype=float32), 'training/policy_loss': Array(0.00720699, dtype=float32), 'training/total_loss': Array(0.06305598, dtype=float32), 'training/v_loss': Array(0.03733847, dtype=float32), 'eval/episode_distance_from_origin': Array(4882.8438, dtype=float32), 'eval/episode_distance_reward': Array(14.151901, dtype=float32), 'eval/episode_forward_reward': Array(2358.641, dtype=float32), 'eval/episode_reward': Array(2335.042, dtype=float32), 'eval/episode_reward_alive': Array(431.6797, dtype=float32), 'eval/episode_reward_linvel': Array(2358.641, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.43057, dtype=float32), 'eval/episode_x_position': Array(4838.133, dtype=float32), 'eval/episode_x_velocity': Array(471.7282, dtype=float32), 'eval/episode_y_position': Array(-263.9726, dtype=float32), 'eval/episode_y_velocity': Array(-84.25772, dtype=float32), 'eval/episode_distance_from_origin_std': Array(693.84424, dtype=float32), 'eval/episode_distance_reward_std': Array(7.622568, dtype=float32), 'eval/episode_forward_reward_std': Array(1270.4202, dtype=float32), 'eval/episode_reward_std': Array(1329.4246, dtype=float32), 'eval/episode_reward_alive_std': Array(29.721474, dtype=float32), 'eval/episode_reward_linvel_std': Array(1270.4202, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.23474, dtype=float32), 'eval/episode_x_position_std': Array(684.0354, dtype=float32), 'eval/episode_x_velocity_std': Array(254.084, dtype=float32), 'eval/episode_y_position_std': Array(255.4903, dtype=float32), 'eval/episode_y_velocity_std': Array(82.14392, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33453011512756, 'eval/sps': 938.8670639192471, 'num_steps': 12697600}
{'eval/walltime': 21477.900943040848, 'training/sps': 2940.2207972026135, 'training/walltime': 4370.6860938072205, 'training/entropy_loss': Array(0.0186205, dtype=float32), 'training/policy_loss': Array(0.08684994, dtype=float32), 'training/total_loss': Array(0.13502955, dtype=float32), 'training/v_loss': Array(0.02955913, dtype=float32), 'eval/episode_distance_from_origin': Array(4716.302, dtype=float32), 'eval/episode_distance_reward': Array(11.62973, dtype=float32), 'eval/episode_forward_reward': Array(1938.2814, dtype=float32), 'eval/episode_reward': Array(1869.0955, dtype=float32), 'eval/episode_reward_alive': Array(416.6328, dtype=float32), 'eval/episode_reward_linvel': Array(1938.2814, dtype=float32), 'eval/episode_reward_quadctrl': Array(-497.4485, dtype=float32), 'eval/episode_x_position': Array(4657.7197, dtype=float32), 'eval/episode_x_velocity': Array(387.65625, dtype=float32), 'eval/episode_y_position': Array(-373.62848, dtype=float32), 'eval/episode_y_velocity': Array(-104.11084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(565.8074, dtype=float32), 'eval/episode_distance_reward_std': Array(5.385334, dtype=float32), 'eval/episode_forward_reward_std': Array(897.5506, dtype=float32), 'eval/episode_reward_std': Array(937.10144, dtype=float32), 'eval/episode_reward_alive_std': Array(32.476162, dtype=float32), 'eval/episode_reward_linvel_std': Array(897.5506, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.15962, dtype=float32), 'eval/episode_x_position_std': Array(549.7048, dtype=float32), 'eval/episode_x_velocity_std': Array(179.51012, dtype=float32), 'eval/episode_y_position_std': Array(318.54663, dtype=float32), 'eval/episode_y_velocity_std': Array(85.485985, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46757125854492, 'eval/sps': 937.9517699299955, 'num_steps': 12779520}
{'eval/walltime': 21614.172510147095, 'training/sps': 2937.1149136496174, 'training/walltime': 4398.577409744263, 'training/entropy_loss': Array(0.00945945, dtype=float32), 'training/policy_loss': Array(-0.00058188, dtype=float32), 'training/total_loss': Array(0.05522674, dtype=float32), 'training/v_loss': Array(0.04634917, dtype=float32), 'eval/episode_distance_from_origin': Array(4788.677, dtype=float32), 'eval/episode_distance_reward': Array(12.340047, dtype=float32), 'eval/episode_forward_reward': Array(2056.6665, dtype=float32), 'eval/episode_reward': Array(2000.1125, dtype=float32), 'eval/episode_reward_alive': Array(416.0039, dtype=float32), 'eval/episode_reward_linvel': Array(2056.6665, dtype=float32), 'eval/episode_reward_quadctrl': Array(-484.89777, dtype=float32), 'eval/episode_x_position': Array(4731.693, dtype=float32), 'eval/episode_x_velocity': Array(411.33328, dtype=float32), 'eval/episode_y_position': Array(-361.66626, dtype=float32), 'eval/episode_y_velocity': Array(-103.868454, dtype=float32), 'eval/episode_distance_from_origin_std': Array(562.33514, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4150524, dtype=float32), 'eval/episode_forward_reward_std': Array(902.50287, dtype=float32), 'eval/episode_reward_std': Array(933.0235, dtype=float32), 'eval/episode_reward_alive_std': Array(37.23917, dtype=float32), 'eval/episode_reward_linvel_std': Array(902.50287, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.28876, dtype=float32), 'eval/episode_x_position_std': Array(547.1444, dtype=float32), 'eval/episode_x_velocity_std': Array(180.5006, dtype=float32), 'eval/episode_y_position_std': Array(316.2886, dtype=float32), 'eval/episode_y_velocity_std': Array(83.36749, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27156710624695, 'eval/sps': 939.3008587051924, 'num_steps': 12861440}
{'eval/walltime': 21750.59689426422, 'training/sps': 2934.84209464111, 'training/walltime': 4426.490325450897, 'training/entropy_loss': Array(0.00829872, dtype=float32), 'training/policy_loss': Array(0.00208074, dtype=float32), 'training/total_loss': Array(0.11817098, dtype=float32), 'training/v_loss': Array(0.10779153, dtype=float32), 'eval/episode_distance_from_origin': Array(4895.7017, dtype=float32), 'eval/episode_distance_reward': Array(13.645012, dtype=float32), 'eval/episode_forward_reward': Array(2274.1597, dtype=float32), 'eval/episode_reward': Array(2219.3872, dtype=float32), 'eval/episode_reward_alive': Array(410.20312, dtype=float32), 'eval/episode_reward_linvel': Array(2274.1597, dtype=float32), 'eval/episode_reward_quadctrl': Array(-478.62048, dtype=float32), 'eval/episode_x_position': Array(4831.8975, dtype=float32), 'eval/episode_x_velocity': Array(454.8319, dtype=float32), 'eval/episode_y_position': Array(-411.65286, dtype=float32), 'eval/episode_y_velocity': Array(-119.999084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(568.65247, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8622, dtype=float32), 'eval/episode_forward_reward_std': Array(977.02734, dtype=float32), 'eval/episode_reward_std': Array(1023.1139, dtype=float32), 'eval/episode_reward_alive_std': Array(33.87151, dtype=float32), 'eval/episode_reward_linvel_std': Array(977.02734, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.97219, dtype=float32), 'eval/episode_x_position_std': Array(551.8774, dtype=float32), 'eval/episode_x_velocity_std': Array(195.40547, dtype=float32), 'eval/episode_y_position_std': Array(350.87448, dtype=float32), 'eval/episode_y_velocity_std': Array(89.31081, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42438411712646, 'eval/sps': 938.2486923313229, 'num_steps': 12943360}
{'eval/walltime': 21886.88665151596, 'training/sps': 2945.1388765269066, 'training/walltime': 4454.305652141571, 'training/entropy_loss': Array(0.01314423, dtype=float32), 'training/policy_loss': Array(0.00479733, dtype=float32), 'training/total_loss': Array(0.11627088, dtype=float32), 'training/v_loss': Array(0.09832934, dtype=float32), 'eval/episode_distance_from_origin': Array(4859.8438, dtype=float32), 'eval/episode_distance_reward': Array(12.938262, dtype=float32), 'eval/episode_forward_reward': Array(2156.369, dtype=float32), 'eval/episode_reward': Array(2098.1199, dtype=float32), 'eval/episode_reward_alive': Array(412.39453, dtype=float32), 'eval/episode_reward_linvel': Array(2156.369, dtype=float32), 'eval/episode_reward_quadctrl': Array(-483.5818, dtype=float32), 'eval/episode_x_position': Array(4798.767, dtype=float32), 'eval/episode_x_velocity': Array(431.2738, dtype=float32), 'eval/episode_y_position': Array(-410.02002, dtype=float32), 'eval/episode_y_velocity': Array(-116.046555, dtype=float32), 'eval/episode_distance_from_origin_std': Array(597.55383, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6088424, dtype=float32), 'eval/episode_forward_reward_std': Array(934.8019, dtype=float32), 'eval/episode_reward_std': Array(968.49426, dtype=float32), 'eval/episode_reward_alive_std': Array(32.651012, dtype=float32), 'eval/episode_reward_linvel_std': Array(934.8019, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.671333, dtype=float32), 'eval/episode_x_position_std': Array(578.6916, dtype=float32), 'eval/episode_x_velocity_std': Array(186.96046, dtype=float32), 'eval/episode_y_position_std': Array(322.33762, dtype=float32), 'eval/episode_y_velocity_std': Array(87.076385, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2897572517395, 'eval/sps': 939.175493309981, 'num_steps': 13025280}
{'eval/walltime': 22023.301220417023, 'training/sps': 2941.3294612496325, 'training/walltime': 4482.15700340271, 'training/entropy_loss': Array(0.02013558, dtype=float32), 'training/policy_loss': Array(0.01420361, dtype=float32), 'training/total_loss': Array(0.08084668, dtype=float32), 'training/v_loss': Array(0.0465075, dtype=float32), 'eval/episode_distance_from_origin': Array(4873.9814, dtype=float32), 'eval/episode_distance_reward': Array(13.205412, dtype=float32), 'eval/episode_forward_reward': Array(2200.8936, dtype=float32), 'eval/episode_reward': Array(2142.6074, dtype=float32), 'eval/episode_reward_alive': Array(414.5586, dtype=float32), 'eval/episode_reward_linvel': Array(2200.8936, dtype=float32), 'eval/episode_reward_quadctrl': Array(-486.05008, dtype=float32), 'eval/episode_x_position': Array(4813.158, dtype=float32), 'eval/episode_x_velocity': Array(440.17868, dtype=float32), 'eval/episode_y_position': Array(-403.3388, dtype=float32), 'eval/episode_y_velocity': Array(-116.24544, dtype=float32), 'eval/episode_distance_from_origin_std': Array(594.78314, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1321607, dtype=float32), 'eval/episode_forward_reward_std': Array(1022.021, dtype=float32), 'eval/episode_reward_std': Array(1061.2053, dtype=float32), 'eval/episode_reward_alive_std': Array(29.109346, dtype=float32), 'eval/episode_reward_linvel_std': Array(1022.021, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.268753, dtype=float32), 'eval/episode_x_position_std': Array(577.564, dtype=float32), 'eval/episode_x_velocity_std': Array(204.40419, dtype=float32), 'eval/episode_y_position_std': Array(328.05136, dtype=float32), 'eval/episode_y_velocity_std': Array(89.02792, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.414568901062, 'eval/sps': 938.31620061663, 'num_steps': 13107200}
{'eval/walltime': 22159.551693677902, 'training/sps': 2949.8014546151776, 'training/walltime': 4509.928364038467, 'training/entropy_loss': Array(0.02600294, dtype=float32), 'training/policy_loss': Array(0.10207641, dtype=float32), 'training/total_loss': Array(0.15440172, dtype=float32), 'training/v_loss': Array(0.02632237, dtype=float32), 'eval/episode_distance_from_origin': Array(4689.426, dtype=float32), 'eval/episode_distance_reward': Array(13.480364, dtype=float32), 'eval/episode_forward_reward': Array(2246.7183, dtype=float32), 'eval/episode_reward': Array(2080.3037, dtype=float32), 'eval/episode_reward_alive': Array(296.6836, dtype=float32), 'eval/episode_reward_linvel': Array(2246.7183, dtype=float32), 'eval/episode_reward_quadctrl': Array(-476.57834, dtype=float32), 'eval/episode_x_position': Array(4623.7295, dtype=float32), 'eval/episode_x_velocity': Array(449.34363, dtype=float32), 'eval/episode_y_position': Array(-397.88635, dtype=float32), 'eval/episode_y_velocity': Array(-143.7652, dtype=float32), 'eval/episode_distance_from_origin_std': Array(600.6076, dtype=float32), 'eval/episode_distance_reward_std': Array(7.2151794, dtype=float32), 'eval/episode_forward_reward_std': Array(1202.5232, dtype=float32), 'eval/episode_reward_std': Array(1294.4644, dtype=float32), 'eval/episode_reward_alive_std': Array(50.969425, dtype=float32), 'eval/episode_reward_linvel_std': Array(1202.5232, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(77.96939, dtype=float32), 'eval/episode_x_position_std': Array(584.8322, dtype=float32), 'eval/episode_x_velocity_std': Array(240.50465, dtype=float32), 'eval/episode_y_position_std': Array(340.9783, dtype=float32), 'eval/episode_y_velocity_std': Array(99.62587, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25047326087952, 'eval/sps': 939.446278141858, 'num_steps': 13189120}
{'eval/walltime': 22295.9738574028, 'training/sps': 2941.5240569959383, 'training/walltime': 4537.777872800827, 'training/entropy_loss': Array(0.03266324, dtype=float32), 'training/policy_loss': Array(0.13436452, dtype=float32), 'training/total_loss': Array(0.19735822, dtype=float32), 'training/v_loss': Array(0.03033045, dtype=float32), 'eval/episode_distance_from_origin': Array(4603.964, dtype=float32), 'eval/episode_distance_reward': Array(11.825993, dtype=float32), 'eval/episode_forward_reward': Array(1970.9907, dtype=float32), 'eval/episode_reward': Array(1843.8589, dtype=float32), 'eval/episode_reward_alive': Array(352.42578, dtype=float32), 'eval/episode_reward_linvel': Array(1970.9907, dtype=float32), 'eval/episode_reward_quadctrl': Array(-491.38367, dtype=float32), 'eval/episode_x_position': Array(4532.4727, dtype=float32), 'eval/episode_x_velocity': Array(394.19815, dtype=float32), 'eval/episode_y_position': Array(-449.991, dtype=float32), 'eval/episode_y_velocity': Array(-149.17413, dtype=float32), 'eval/episode_distance_from_origin_std': Array(521.95636, dtype=float32), 'eval/episode_distance_reward_std': Array(5.632028, dtype=float32), 'eval/episode_forward_reward_std': Array(938.6658, dtype=float32), 'eval/episode_reward_std': Array(981.4774, dtype=float32), 'eval/episode_reward_alive_std': Array(49.578777, dtype=float32), 'eval/episode_reward_linvel_std': Array(938.6658, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(72.19375, dtype=float32), 'eval/episode_x_position_std': Array(499.86713, dtype=float32), 'eval/episode_x_velocity_std': Array(187.73315, dtype=float32), 'eval/episode_y_position_std': Array(335.2037, dtype=float32), 'eval/episode_y_velocity_std': Array(97.89954, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4221637248993, 'eval/sps': 938.2639631644978, 'num_steps': 13271040}
{'eval/walltime': 22432.232739925385, 'training/sps': 2946.8498872242426, 'training/walltime': 4565.577049255371, 'training/entropy_loss': Array(0.02056354, dtype=float32), 'training/policy_loss': Array(0.12779906, dtype=float32), 'training/total_loss': Array(0.19391902, dtype=float32), 'training/v_loss': Array(0.0455564, dtype=float32), 'eval/episode_distance_from_origin': Array(4753.454, dtype=float32), 'eval/episode_distance_reward': Array(13.3181305, dtype=float32), 'eval/episode_forward_reward': Array(2219.6787, dtype=float32), 'eval/episode_reward': Array(2125.0083, dtype=float32), 'eval/episode_reward_alive': Array(388.73047, dtype=float32), 'eval/episode_reward_linvel': Array(2219.6787, dtype=float32), 'eval/episode_reward_quadctrl': Array(-496.71884, dtype=float32), 'eval/episode_x_position': Array(4684.46, dtype=float32), 'eval/episode_x_velocity': Array(443.9358, dtype=float32), 'eval/episode_y_position': Array(-442.3418, dtype=float32), 'eval/episode_y_velocity': Array(-141.46097, dtype=float32), 'eval/episode_distance_from_origin_std': Array(556.50183, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4587803, dtype=float32), 'eval/episode_forward_reward_std': Array(1076.4573, dtype=float32), 'eval/episode_reward_std': Array(1121.1304, dtype=float32), 'eval/episode_reward_alive_std': Array(43.263226, dtype=float32), 'eval/episode_reward_linvel_std': Array(1076.4573, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.301704, dtype=float32), 'eval/episode_x_position_std': Array(538.0962, dtype=float32), 'eval/episode_x_velocity_std': Array(215.2915, dtype=float32), 'eval/episode_y_position_std': Array(334.73007, dtype=float32), 'eval/episode_y_velocity_std': Array(100.972404, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.258882522583, 'eval/sps': 939.3882999061422, 'num_steps': 13352960}
{'eval/walltime': 22568.67528605461, 'training/sps': 2937.1495363880167, 'training/walltime': 4593.468036413193, 'training/entropy_loss': Array(0.00903767, dtype=float32), 'training/policy_loss': Array(0.00514746, dtype=float32), 'training/total_loss': Array(0.14807981, dtype=float32), 'training/v_loss': Array(0.13389468, dtype=float32), 'eval/episode_distance_from_origin': Array(4789.515, dtype=float32), 'eval/episode_distance_reward': Array(13.111788, dtype=float32), 'eval/episode_forward_reward': Array(2185.288, dtype=float32), 'eval/episode_reward': Array(2088.6123, dtype=float32), 'eval/episode_reward_alive': Array(385.73828, dtype=float32), 'eval/episode_reward_linvel': Array(2185.288, dtype=float32), 'eval/episode_reward_quadctrl': Array(-495.52582, dtype=float32), 'eval/episode_x_position': Array(4714.218, dtype=float32), 'eval/episode_x_velocity': Array(437.0576, dtype=float32), 'eval/episode_y_position': Array(-509.62497, dtype=float32), 'eval/episode_y_velocity': Array(-157.23389, dtype=float32), 'eval/episode_distance_from_origin_std': Array(523.2882, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5769477, dtype=float32), 'eval/episode_forward_reward_std': Array(929.48596, dtype=float32), 'eval/episode_reward_std': Array(960.5561, dtype=float32), 'eval/episode_reward_alive_std': Array(43.37144, dtype=float32), 'eval/episode_reward_linvel_std': Array(929.48596, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.264774, dtype=float32), 'eval/episode_x_position_std': Array(505.471, dtype=float32), 'eval/episode_x_velocity_std': Array(185.89719, dtype=float32), 'eval/episode_y_position_std': Array(318.15698, dtype=float32), 'eval/episode_y_velocity_std': Array(90.524, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44254612922668, 'eval/sps': 938.1238010522712, 'num_steps': 13434880}
{'eval/walltime': 22705.007827043533, 'training/sps': 2948.3958719088664, 'training/walltime': 4621.252636432648, 'training/entropy_loss': Array(0.02042313, dtype=float32), 'training/policy_loss': Array(0.06408796, dtype=float32), 'training/total_loss': Array(0.20968229, dtype=float32), 'training/v_loss': Array(0.12517121, dtype=float32), 'eval/episode_distance_from_origin': Array(4750.7754, dtype=float32), 'eval/episode_distance_reward': Array(12.805071, dtype=float32), 'eval/episode_forward_reward': Array(2134.1692, dtype=float32), 'eval/episode_reward': Array(2036.7589, dtype=float32), 'eval/episode_reward_alive': Array(389.80078, dtype=float32), 'eval/episode_reward_linvel': Array(2134.1692, dtype=float32), 'eval/episode_reward_quadctrl': Array(-500.01608, dtype=float32), 'eval/episode_x_position': Array(4680.04, dtype=float32), 'eval/episode_x_velocity': Array(426.83386, dtype=float32), 'eval/episode_y_position': Array(-458.44092, dtype=float32), 'eval/episode_y_velocity': Array(-143.87398, dtype=float32), 'eval/episode_distance_from_origin_std': Array(519.9162, dtype=float32), 'eval/episode_distance_reward_std': Array(5.640972, dtype=float32), 'eval/episode_forward_reward_std': Array(940.1569, dtype=float32), 'eval/episode_reward_std': Array(972.40375, dtype=float32), 'eval/episode_reward_alive_std': Array(43.833996, dtype=float32), 'eval/episode_reward_linvel_std': Array(940.1569, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.86654, dtype=float32), 'eval/episode_x_position_std': Array(501.83246, dtype=float32), 'eval/episode_x_velocity_std': Array(188.03142, dtype=float32), 'eval/episode_y_position_std': Array(335.13928, dtype=float32), 'eval/episode_y_velocity_std': Array(91.499985, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33254098892212, 'eval/sps': 938.8807622268318, 'num_steps': 13516800}
{'eval/walltime': 22841.442135810852, 'training/sps': 2939.304253857494, 'training/walltime': 4649.123177528381, 'training/entropy_loss': Array(0.03175392, dtype=float32), 'training/policy_loss': Array(0.1489529, dtype=float32), 'training/total_loss': Array(0.25268772, dtype=float32), 'training/v_loss': Array(0.07198089, dtype=float32), 'eval/episode_distance_from_origin': Array(4648.6226, dtype=float32), 'eval/episode_distance_reward': Array(11.865377, dtype=float32), 'eval/episode_forward_reward': Array(1977.5537, dtype=float32), 'eval/episode_reward': Array(1866.1318, dtype=float32), 'eval/episode_reward_alive': Array(389.15234, dtype=float32), 'eval/episode_reward_linvel': Array(1977.5537, dtype=float32), 'eval/episode_reward_quadctrl': Array(-512.4397, dtype=float32), 'eval/episode_x_position': Array(4574.426, dtype=float32), 'eval/episode_x_velocity': Array(395.5108, dtype=float32), 'eval/episode_y_position': Array(-472.83914, dtype=float32), 'eval/episode_y_velocity': Array(-149.3523, dtype=float32), 'eval/episode_distance_from_origin_std': Array(525.45154, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7105727, dtype=float32), 'eval/episode_forward_reward_std': Array(951.7564, dtype=float32), 'eval/episode_reward_std': Array(985.73315, dtype=float32), 'eval/episode_reward_alive_std': Array(40.39215, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.7564, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.788433, dtype=float32), 'eval/episode_x_position_std': Array(507.55435, dtype=float32), 'eval/episode_x_velocity_std': Array(190.35133, dtype=float32), 'eval/episode_y_position_std': Array(337.0076, dtype=float32), 'eval/episode_y_velocity_std': Array(91.734886, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43430876731873, 'eval/sps': 938.1804412429502, 'num_steps': 13598720}
{'eval/walltime': 22977.761128902435, 'training/sps': 2948.7355391891097, 'training/walltime': 4676.90457701683, 'training/entropy_loss': Array(0.04223446, dtype=float32), 'training/policy_loss': Array(0.12943701, dtype=float32), 'training/total_loss': Array(0.21730196, dtype=float32), 'training/v_loss': Array(0.04563048, dtype=float32), 'eval/episode_distance_from_origin': Array(4538.4526, dtype=float32), 'eval/episode_distance_reward': Array(10.574779, dtype=float32), 'eval/episode_forward_reward': Array(1762.4553, dtype=float32), 'eval/episode_reward': Array(1655.2034, dtype=float32), 'eval/episode_reward_alive': Array(402.04688, dtype=float32), 'eval/episode_reward_linvel': Array(1762.4553, dtype=float32), 'eval/episode_reward_quadctrl': Array(-519.87354, dtype=float32), 'eval/episode_x_position': Array(4481.955, dtype=float32), 'eval/episode_x_velocity': Array(352.49103, dtype=float32), 'eval/episode_y_position': Array(-336.787, dtype=float32), 'eval/episode_y_velocity': Array(-105.359436, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.8413, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4842615, dtype=float32), 'eval/episode_forward_reward_std': Array(747.3722, dtype=float32), 'eval/episode_reward_std': Array(766.8928, dtype=float32), 'eval/episode_reward_alive_std': Array(34.97697, dtype=float32), 'eval/episode_reward_linvel_std': Array(747.3722, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.344772, dtype=float32), 'eval/episode_x_position_std': Array(455.51837, dtype=float32), 'eval/episode_x_velocity_std': Array(149.47443, dtype=float32), 'eval/episode_y_position_std': Array(303.87668, dtype=float32), 'eval/episode_y_velocity_std': Array(84.83063, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31899309158325, 'eval/sps': 938.9740717495301, 'num_steps': 13680640}
{'eval/walltime': 23114.220910787582, 'training/sps': 2940.1848440514855, 'training/walltime': 4704.766770839691, 'training/entropy_loss': Array(0.04426308, dtype=float32), 'training/policy_loss': Array(0.12451847, dtype=float32), 'training/total_loss': Array(0.19805115, dtype=float32), 'training/v_loss': Array(0.0292696, dtype=float32), 'eval/episode_distance_from_origin': Array(4674.0146, dtype=float32), 'eval/episode_distance_reward': Array(12.408035, dtype=float32), 'eval/episode_forward_reward': Array(2067.9966, dtype=float32), 'eval/episode_reward': Array(1971.6111, dtype=float32), 'eval/episode_reward_alive': Array(366.15234, dtype=float32), 'eval/episode_reward_linvel': Array(2067.9966, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.94568, dtype=float32), 'eval/episode_x_position': Array(4598.823, dtype=float32), 'eval/episode_x_velocity': Array(413.5993, dtype=float32), 'eval/episode_y_position': Array(-496.5367, dtype=float32), 'eval/episode_y_velocity': Array(-153.55405, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.03314, dtype=float32), 'eval/episode_distance_reward_std': Array(5.329916, dtype=float32), 'eval/episode_forward_reward_std': Array(888.31384, dtype=float32), 'eval/episode_reward_std': Array(917.6122, dtype=float32), 'eval/episode_reward_alive_std': Array(49.841805, dtype=float32), 'eval/episode_reward_linvel_std': Array(888.31384, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.29465, dtype=float32), 'eval/episode_x_position_std': Array(456.9572, dtype=float32), 'eval/episode_x_velocity_std': Array(177.66278, dtype=float32), 'eval/episode_y_position_std': Array(316.8002, dtype=float32), 'eval/episode_y_velocity_std': Array(87.87182, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4597818851471, 'eval/sps': 938.0053099288451, 'num_steps': 13762560}
{'eval/walltime': 23250.54743552208, 'training/sps': 2946.549718624227, 'training/walltime': 4732.568779230118, 'training/entropy_loss': Array(0.03431177, dtype=float32), 'training/policy_loss': Array(0.06504689, dtype=float32), 'training/total_loss': Array(0.12258005, dtype=float32), 'training/v_loss': Array(0.02322139, dtype=float32), 'eval/episode_distance_from_origin': Array(4753.7734, dtype=float32), 'eval/episode_distance_reward': Array(13.545966, dtype=float32), 'eval/episode_forward_reward': Array(2257.6504, dtype=float32), 'eval/episode_reward': Array(2161.8384, dtype=float32), 'eval/episode_reward_alive': Array(341.16406, dtype=float32), 'eval/episode_reward_linvel': Array(2257.6504, dtype=float32), 'eval/episode_reward_quadctrl': Array(-450.5221, dtype=float32), 'eval/episode_x_position': Array(4670.0664, dtype=float32), 'eval/episode_x_velocity': Array(451.53006, dtype=float32), 'eval/episode_y_position': Array(-575.3417, dtype=float32), 'eval/episode_y_velocity': Array(-178.09421, dtype=float32), 'eval/episode_distance_from_origin_std': Array(424.37793, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6194153, dtype=float32), 'eval/episode_forward_reward_std': Array(936.56445, dtype=float32), 'eval/episode_reward_std': Array(974.915, dtype=float32), 'eval/episode_reward_alive_std': Array(49.36685, dtype=float32), 'eval/episode_reward_linvel_std': Array(936.56445, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.502266, dtype=float32), 'eval/episode_x_position_std': Array(417.649, dtype=float32), 'eval/episode_x_velocity_std': Array(187.31288, dtype=float32), 'eval/episode_y_position_std': Array(282.45367, dtype=float32), 'eval/episode_y_velocity_std': Array(81.0723, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32652473449707, 'eval/sps': 938.9221961704561, 'num_steps': 13844480}
{'eval/walltime': 23386.999384641647, 'training/sps': 2941.8722431563942, 'training/walltime': 4760.414991855621, 'training/entropy_loss': Array(0.00810656, dtype=float32), 'training/policy_loss': Array(0.00189173, dtype=float32), 'training/total_loss': Array(0.11562046, dtype=float32), 'training/v_loss': Array(0.10562216, dtype=float32), 'eval/episode_distance_from_origin': Array(4751.0176, dtype=float32), 'eval/episode_distance_reward': Array(13.528967, dtype=float32), 'eval/episode_forward_reward': Array(2254.8171, dtype=float32), 'eval/episode_reward': Array(2155.0583, dtype=float32), 'eval/episode_reward_alive': Array(344.1875, dtype=float32), 'eval/episode_reward_linvel': Array(2254.8171, dtype=float32), 'eval/episode_reward_quadctrl': Array(-457.47522, dtype=float32), 'eval/episode_x_position': Array(4670.0825, dtype=float32), 'eval/episode_x_velocity': Array(450.9635, dtype=float32), 'eval/episode_y_position': Array(-561.98035, dtype=float32), 'eval/episode_y_velocity': Array(-175.24918, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.42322, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9497743, dtype=float32), 'eval/episode_forward_reward_std': Array(991.62427, dtype=float32), 'eval/episode_reward_std': Array(1023.88684, dtype=float32), 'eval/episode_reward_alive_std': Array(54.361454, dtype=float32), 'eval/episode_reward_linvel_std': Array(991.62427, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.96053, dtype=float32), 'eval/episode_x_position_std': Array(454.91434, dtype=float32), 'eval/episode_x_velocity_std': Array(198.32487, dtype=float32), 'eval/episode_y_position_std': Array(285.811, dtype=float32), 'eval/episode_y_velocity_std': Array(80.95723, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45194911956787, 'eval/sps': 938.0591543462547, 'num_steps': 13926400}
{'eval/walltime': 23523.36984229088, 'training/sps': 2937.681533642857, 'training/walltime': 4788.300928115845, 'training/entropy_loss': Array(0.01103747, dtype=float32), 'training/policy_loss': Array(0.07022955, dtype=float32), 'training/total_loss': Array(0.23003817, dtype=float32), 'training/v_loss': Array(0.14877115, dtype=float32), 'eval/episode_distance_from_origin': Array(4649.6104, dtype=float32), 'eval/episode_distance_reward': Array(13.199266, dtype=float32), 'eval/episode_forward_reward': Array(2199.8684, dtype=float32), 'eval/episode_reward': Array(2107.6758, dtype=float32), 'eval/episode_reward_alive': Array(320.51172, dtype=float32), 'eval/episode_reward_linvel': Array(2199.8684, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.90375, dtype=float32), 'eval/episode_x_position': Array(4578.076, dtype=float32), 'eval/episode_x_velocity': Array(439.97363, dtype=float32), 'eval/episode_y_position': Array(-464.87787, dtype=float32), 'eval/episode_y_velocity': Array(-150.19922, dtype=float32), 'eval/episode_distance_from_origin_std': Array(441.6316, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0979, dtype=float32), 'eval/episode_forward_reward_std': Array(1016.31116, dtype=float32), 'eval/episode_reward_std': Array(1052.7935, dtype=float32), 'eval/episode_reward_alive_std': Array(60.41162, dtype=float32), 'eval/episode_reward_linvel_std': Array(1016.31116, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.414604, dtype=float32), 'eval/episode_x_position_std': Array(434.06497, dtype=float32), 'eval/episode_x_velocity_std': Array(203.26224, dtype=float32), 'eval/episode_y_position_std': Array(305.2014, dtype=float32), 'eval/episode_y_velocity_std': Array(95.41505, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37045764923096, 'eval/sps': 938.6197143170021, 'num_steps': 14008320}
{'eval/walltime': 23659.794723272324, 'training/sps': 2939.1936231809773, 'training/walltime': 4816.172518253326, 'training/entropy_loss': Array(0.01783208, dtype=float32), 'training/policy_loss': Array(0.09000148, dtype=float32), 'training/total_loss': Array(0.23348147, dtype=float32), 'training/v_loss': Array(0.1256479, dtype=float32), 'eval/episode_distance_from_origin': Array(4673.6807, dtype=float32), 'eval/episode_distance_reward': Array(12.8796835, dtype=float32), 'eval/episode_forward_reward': Array(2146.605, dtype=float32), 'eval/episode_reward': Array(2047.304, dtype=float32), 'eval/episode_reward_alive': Array(320.23828, dtype=float32), 'eval/episode_reward_linvel': Array(2146.605, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.41888, dtype=float32), 'eval/episode_x_position': Array(4606.4155, dtype=float32), 'eval/episode_x_velocity': Array(429.32092, dtype=float32), 'eval/episode_y_position': Array(-429.72803, dtype=float32), 'eval/episode_y_velocity': Array(-144.05997, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.1615, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1063414, dtype=float32), 'eval/episode_forward_reward_std': Array(1017.7182, dtype=float32), 'eval/episode_reward_std': Array(1051.3221, dtype=float32), 'eval/episode_reward_alive_std': Array(65.33519, dtype=float32), 'eval/episode_reward_linvel_std': Array(1017.7182, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.114403, dtype=float32), 'eval/episode_x_position_std': Array(479.70898, dtype=float32), 'eval/episode_x_velocity_std': Array(203.54364, dtype=float32), 'eval/episode_y_position_std': Array(310.75833, dtype=float32), 'eval/episode_y_velocity_std': Array(89.78743, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4248809814453, 'eval/sps': 938.2452751958702, 'num_steps': 14090240}
{'eval/walltime': 23796.10656261444, 'training/sps': 2947.392888301983, 'training/walltime': 4843.966573238373, 'training/entropy_loss': Array(0.02303063, dtype=float32), 'training/policy_loss': Array(0.04349305, dtype=float32), 'training/total_loss': Array(0.14133805, dtype=float32), 'training/v_loss': Array(0.07481437, dtype=float32), 'eval/episode_distance_from_origin': Array(4607.953, dtype=float32), 'eval/episode_distance_reward': Array(12.24953, dtype=float32), 'eval/episode_forward_reward': Array(2041.5793, dtype=float32), 'eval/episode_reward': Array(1937.5487, dtype=float32), 'eval/episode_reward_alive': Array(318.85547, dtype=float32), 'eval/episode_reward_linvel': Array(2041.5793, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.13556, dtype=float32), 'eval/episode_x_position': Array(4541.9414, dtype=float32), 'eval/episode_x_velocity': Array(408.31586, dtype=float32), 'eval/episode_y_position': Array(-416.62592, dtype=float32), 'eval/episode_y_velocity': Array(-135.0264, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.40106, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0949397, dtype=float32), 'eval/episode_forward_reward_std': Array(1015.8173, dtype=float32), 'eval/episode_reward_std': Array(1050.7848, dtype=float32), 'eval/episode_reward_alive_std': Array(60.502327, dtype=float32), 'eval/episode_reward_linvel_std': Array(1015.8173, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.609257, dtype=float32), 'eval/episode_x_position_std': Array(472.70837, dtype=float32), 'eval/episode_x_velocity_std': Array(203.16351, dtype=float32), 'eval/episode_y_position_std': Array(308.4842, dtype=float32), 'eval/episode_y_velocity_std': Array(90.83914, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3118393421173, 'eval/sps': 939.0233498261575, 'num_steps': 14172160}
{'eval/walltime': 23932.556117534637, 'training/sps': 2935.6159220715513, 'training/walltime': 4871.872131109238, 'training/entropy_loss': Array(0.02857837, dtype=float32), 'training/policy_loss': Array(0.04702106, dtype=float32), 'training/total_loss': Array(0.13180846, dtype=float32), 'training/v_loss': Array(0.05620903, dtype=float32), 'eval/episode_distance_from_origin': Array(4695.003, dtype=float32), 'eval/episode_distance_reward': Array(13.7483835, dtype=float32), 'eval/episode_forward_reward': Array(2291.3867, dtype=float32), 'eval/episode_reward': Array(2199.5532, dtype=float32), 'eval/episode_reward_alive': Array(317.66016, dtype=float32), 'eval/episode_reward_linvel': Array(2291.3867, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.2422, dtype=float32), 'eval/episode_x_position': Array(4629.9844, dtype=float32), 'eval/episode_x_velocity': Array(458.2774, dtype=float32), 'eval/episode_y_position': Array(-426.36615, dtype=float32), 'eval/episode_y_velocity': Array(-141.61804, dtype=float32), 'eval/episode_distance_from_origin_std': Array(545.4865, dtype=float32), 'eval/episode_distance_reward_std': Array(6.954901, dtype=float32), 'eval/episode_forward_reward_std': Array(1159.1437, dtype=float32), 'eval/episode_reward_std': Array(1199.5656, dtype=float32), 'eval/episode_reward_alive_std': Array(68.16776, dtype=float32), 'eval/episode_reward_linvel_std': Array(1159.1437, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.644634, dtype=float32), 'eval/episode_x_position_std': Array(535.6534, dtype=float32), 'eval/episode_x_velocity_std': Array(231.82874, dtype=float32), 'eval/episode_y_position_std': Array(294.9192, dtype=float32), 'eval/episode_y_velocity_std': Array(95.31975, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44955492019653, 'eval/sps': 938.0756139135938, 'num_steps': 14254080}
{'eval/walltime': 24068.890620946884, 'training/sps': 2939.819273832929, 'training/walltime': 4899.73778963089, 'training/entropy_loss': Array(0.0333317, dtype=float32), 'training/policy_loss': Array(0.08773522, dtype=float32), 'training/total_loss': Array(0.1616176, dtype=float32), 'training/v_loss': Array(0.04055069, dtype=float32), 'eval/episode_distance_from_origin': Array(4443.924, dtype=float32), 'eval/episode_distance_reward': Array(10.552071, dtype=float32), 'eval/episode_forward_reward': Array(1758.6713, dtype=float32), 'eval/episode_reward': Array(1655.9423, dtype=float32), 'eval/episode_reward_alive': Array(322.89844, dtype=float32), 'eval/episode_reward_linvel': Array(1758.6713, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.1794, dtype=float32), 'eval/episode_x_position': Array(4384.7637, dtype=float32), 'eval/episode_x_velocity': Array(351.73425, dtype=float32), 'eval/episode_y_position': Array(-315.8685, dtype=float32), 'eval/episode_y_velocity': Array(-112.317215, dtype=float32), 'eval/episode_distance_from_origin_std': Array(528.08606, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8239193, dtype=float32), 'eval/episode_forward_reward_std': Array(970.6472, dtype=float32), 'eval/episode_reward_std': Array(996.91833, dtype=float32), 'eval/episode_reward_alive_std': Array(81.872215, dtype=float32), 'eval/episode_reward_linvel_std': Array(970.6472, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.798847, dtype=float32), 'eval/episode_x_position_std': Array(512.44104, dtype=float32), 'eval/episode_x_velocity_std': Array(194.12949, dtype=float32), 'eval/episode_y_position_std': Array(324.14365, dtype=float32), 'eval/episode_y_velocity_std': Array(94.086624, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3345034122467, 'eval/sps': 938.8672478085394, 'num_steps': 14336000}
{'eval/walltime': 24205.314481973648, 'training/sps': 2938.5388098580893, 'training/walltime': 4927.615590572357, 'training/entropy_loss': Array(0.00501159, dtype=float32), 'training/policy_loss': Array(-0.00118239, dtype=float32), 'training/total_loss': Array(0.07930581, dtype=float32), 'training/v_loss': Array(0.07547662, dtype=float32), 'eval/episode_distance_from_origin': Array(4503.1694, dtype=float32), 'eval/episode_distance_reward': Array(11.128415, dtype=float32), 'eval/episode_forward_reward': Array(1854.7285, dtype=float32), 'eval/episode_reward': Array(1754.3931, dtype=float32), 'eval/episode_reward_alive': Array(325.90234, dtype=float32), 'eval/episode_reward_linvel': Array(1854.7285, dtype=float32), 'eval/episode_reward_quadctrl': Array(-437.36597, dtype=float32), 'eval/episode_x_position': Array(4438.2217, dtype=float32), 'eval/episode_x_velocity': Array(370.94568, dtype=float32), 'eval/episode_y_position': Array(-366.24622, dtype=float32), 'eval/episode_y_velocity': Array(-123.17136, dtype=float32), 'eval/episode_distance_from_origin_std': Array(541.0799, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9894457, dtype=float32), 'eval/episode_forward_reward_std': Array(998.23505, dtype=float32), 'eval/episode_reward_std': Array(1024.0785, dtype=float32), 'eval/episode_reward_alive_std': Array(63.298374, dtype=float32), 'eval/episode_reward_linvel_std': Array(998.23505, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.38497, dtype=float32), 'eval/episode_x_position_std': Array(521.1139, dtype=float32), 'eval/episode_x_velocity_std': Array(199.64702, dtype=float32), 'eval/episode_y_position_std': Array(350.3354, dtype=float32), 'eval/episode_y_velocity_std': Array(98.24318, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42386102676392, 'eval/sps': 938.2522898607062, 'num_steps': 14417920}
{'eval/walltime': 24341.693250656128, 'training/sps': 2945.8004485349697, 'training/walltime': 4955.42467045784, 'training/entropy_loss': Array(0.00961209, dtype=float32), 'training/policy_loss': Array(0.00143032, dtype=float32), 'training/total_loss': Array(0.13554345, dtype=float32), 'training/v_loss': Array(0.12450105, dtype=float32), 'eval/episode_distance_from_origin': Array(4382.827, dtype=float32), 'eval/episode_distance_reward': Array(9.899761, dtype=float32), 'eval/episode_forward_reward': Array(1649.9534, dtype=float32), 'eval/episode_reward': Array(1529.6016, dtype=float32), 'eval/episode_reward_alive': Array(308.64844, dtype=float32), 'eval/episode_reward_linvel': Array(1649.9534, dtype=float32), 'eval/episode_reward_quadctrl': Array(-438.89993, dtype=float32), 'eval/episode_x_position': Array(4333.244, dtype=float32), 'eval/episode_x_velocity': Array(329.99066, dtype=float32), 'eval/episode_y_position': Array(-228.37201, dtype=float32), 'eval/episode_y_velocity': Array(-86.38133, dtype=float32), 'eval/episode_distance_from_origin_std': Array(542.41254, dtype=float32), 'eval/episode_distance_reward_std': Array(5.673786, dtype=float32), 'eval/episode_forward_reward_std': Array(945.6251, dtype=float32), 'eval/episode_reward_std': Array(981.95374, dtype=float32), 'eval/episode_reward_alive_std': Array(85.09901, dtype=float32), 'eval/episode_reward_linvel_std': Array(945.6251, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.097546, dtype=float32), 'eval/episode_x_position_std': Array(531.06757, dtype=float32), 'eval/episode_x_velocity_std': Array(189.12505, dtype=float32), 'eval/episode_y_position_std': Array(298.2341, dtype=float32), 'eval/episode_y_velocity_std': Array(84.32487, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37876868247986, 'eval/sps': 938.5625140670722, 'num_steps': 14499840}
{'eval/walltime': 24478.104998111725, 'training/sps': 2934.053567106201, 'training/walltime': 4983.345087766647, 'training/entropy_loss': Array(0.0134209, dtype=float32), 'training/policy_loss': Array(0.01410388, dtype=float32), 'training/total_loss': Array(0.1363849, dtype=float32), 'training/v_loss': Array(0.10886011, dtype=float32), 'eval/episode_distance_from_origin': Array(4451.7095, dtype=float32), 'eval/episode_distance_reward': Array(10.721218, dtype=float32), 'eval/episode_forward_reward': Array(1786.8623, dtype=float32), 'eval/episode_reward': Array(1675.8999, dtype=float32), 'eval/episode_reward_alive': Array(315.60938, dtype=float32), 'eval/episode_reward_linvel': Array(1786.8623, dtype=float32), 'eval/episode_reward_quadctrl': Array(-437.29303, dtype=float32), 'eval/episode_x_position': Array(4396.893, dtype=float32), 'eval/episode_x_velocity': Array(357.37247, dtype=float32), 'eval/episode_y_position': Array(-290.80676, dtype=float32), 'eval/episode_y_velocity': Array(-108.42141, dtype=float32), 'eval/episode_distance_from_origin_std': Array(540.537, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7553043, dtype=float32), 'eval/episode_forward_reward_std': Array(959.21136, dtype=float32), 'eval/episode_reward_std': Array(982.7667, dtype=float32), 'eval/episode_reward_alive_std': Array(89.219086, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.21136, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.917847, dtype=float32), 'eval/episode_x_position_std': Array(524.33124, dtype=float32), 'eval/episode_x_velocity_std': Array(191.84229, dtype=float32), 'eval/episode_y_position_std': Array(310.07254, dtype=float32), 'eval/episode_y_velocity_std': Array(94.99858, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41174745559692, 'eval/sps': 938.33560809464, 'num_steps': 14581760}
{'eval/walltime': 24614.43725347519, 'training/sps': 2947.4995099830535, 'training/walltime': 5011.138137340546, 'training/entropy_loss': Array(0.01912483, dtype=float32), 'training/policy_loss': Array(0.02009137, dtype=float32), 'training/total_loss': Array(0.11270198, dtype=float32), 'training/v_loss': Array(0.07348578, dtype=float32), 'eval/episode_distance_from_origin': Array(4442.305, dtype=float32), 'eval/episode_distance_reward': Array(10.28419, dtype=float32), 'eval/episode_forward_reward': Array(1714.0248, dtype=float32), 'eval/episode_reward': Array(1605.895, dtype=float32), 'eval/episode_reward_alive': Array(324.89453, dtype=float32), 'eval/episode_reward_linvel': Array(1714.0248, dtype=float32), 'eval/episode_reward_quadctrl': Array(-443.3086, dtype=float32), 'eval/episode_x_position': Array(4385.092, dtype=float32), 'eval/episode_x_velocity': Array(342.80496, dtype=float32), 'eval/episode_y_position': Array(-318.59705, dtype=float32), 'eval/episode_y_velocity': Array(-109.4817, dtype=float32), 'eval/episode_distance_from_origin_std': Array(518.97034, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2654552, dtype=float32), 'eval/episode_forward_reward_std': Array(877.57056, dtype=float32), 'eval/episode_reward_std': Array(903.1156, dtype=float32), 'eval/episode_reward_alive_std': Array(77.93591, dtype=float32), 'eval/episode_reward_linvel_std': Array(877.57056, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.029263, dtype=float32), 'eval/episode_x_position_std': Array(503.3247, dtype=float32), 'eval/episode_x_velocity_std': Array(175.51416, dtype=float32), 'eval/episode_y_position_std': Array(304.94287, dtype=float32), 'eval/episode_y_velocity_std': Array(87.98613, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33225536346436, 'eval/sps': 938.8827292466452, 'num_steps': 14663680}
{'eval/walltime': 24750.842550754547, 'training/sps': 2934.6120386013404, 'training/walltime': 5039.053241252899, 'training/entropy_loss': Array(0.02488025, dtype=float32), 'training/policy_loss': Array(0.0535701, dtype=float32), 'training/total_loss': Array(0.13404092, dtype=float32), 'training/v_loss': Array(0.05559056, dtype=float32), 'eval/episode_distance_from_origin': Array(4330.2207, dtype=float32), 'eval/episode_distance_reward': Array(9.105799, dtype=float32), 'eval/episode_forward_reward': Array(1517.6274, dtype=float32), 'eval/episode_reward': Array(1403.4448, dtype=float32), 'eval/episode_reward_alive': Array(330.26562, dtype=float32), 'eval/episode_reward_linvel': Array(1517.6274, dtype=float32), 'eval/episode_reward_quadctrl': Array(-453.55396, dtype=float32), 'eval/episode_x_position': Array(4280.6553, dtype=float32), 'eval/episode_x_velocity': Array(303.52545, dtype=float32), 'eval/episode_y_position': Array(-225.2769, dtype=float32), 'eval/episode_y_velocity': Array(-84.82243, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.76004, dtype=float32), 'eval/episode_distance_reward_std': Array(3.6015277, dtype=float32), 'eval/episode_forward_reward_std': Array(600.25, dtype=float32), 'eval/episode_reward_std': Array(607.6126, dtype=float32), 'eval/episode_reward_alive_std': Array(77.20667, dtype=float32), 'eval/episode_reward_linvel_std': Array(600.25, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.71602, dtype=float32), 'eval/episode_x_position_std': Array(414.66696, dtype=float32), 'eval/episode_x_velocity_std': Array(120.04996, dtype=float32), 'eval/episode_y_position_std': Array(286.49405, dtype=float32), 'eval/episode_y_velocity_std': Array(77.36913, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4052972793579, 'eval/sps': 938.3799790257128, 'num_steps': 14745600}
{'eval/walltime': 24887.16530442238, 'training/sps': 2945.5322337807524, 'training/walltime': 5066.864853382111, 'training/entropy_loss': Array(0.03266644, dtype=float32), 'training/policy_loss': Array(0.27402085, dtype=float32), 'training/total_loss': Array(0.3444286, dtype=float32), 'training/v_loss': Array(0.03774133, dtype=float32), 'eval/episode_distance_from_origin': Array(4229.6694, dtype=float32), 'eval/episode_distance_reward': Array(8.062065, dtype=float32), 'eval/episode_forward_reward': Array(1343.6732, dtype=float32), 'eval/episode_reward': Array(1112.3766, dtype=float32), 'eval/episode_reward_alive': Array(254.51562, dtype=float32), 'eval/episode_reward_linvel': Array(1343.6732, dtype=float32), 'eval/episode_reward_quadctrl': Array(-493.8744, dtype=float32), 'eval/episode_x_position': Array(4161.2812, dtype=float32), 'eval/episode_x_velocity': Array(268.73462, dtype=float32), 'eval/episode_y_position': Array(-415.3192, dtype=float32), 'eval/episode_y_velocity': Array(-144.09879, dtype=float32), 'eval/episode_distance_from_origin_std': Array(392.7281, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8453596, dtype=float32), 'eval/episode_forward_reward_std': Array(474.22293, dtype=float32), 'eval/episode_reward_std': Array(492.95752, dtype=float32), 'eval/episode_reward_alive_std': Array(76.68821, dtype=float32), 'eval/episode_reward_linvel_std': Array(474.22293, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.457655, dtype=float32), 'eval/episode_x_position_std': Array(373.3422, dtype=float32), 'eval/episode_x_velocity_std': Array(94.84462, dtype=float32), 'eval/episode_y_position_std': Array(284.65457, dtype=float32), 'eval/episode_y_velocity_std': Array(75.523834, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32275366783142, 'eval/sps': 938.9481693708233, 'num_steps': 14827520}
{'eval/walltime': 25023.573561906815, 'training/sps': 2943.965740888635, 'training/walltime': 5094.691264152527, 'training/entropy_loss': Array(0.01405185, dtype=float32), 'training/policy_loss': Array(0.03305096, dtype=float32), 'training/total_loss': Array(0.099555, dtype=float32), 'training/v_loss': Array(0.05245218, dtype=float32), 'eval/episode_distance_from_origin': Array(4212.2, dtype=float32), 'eval/episode_distance_reward': Array(8.013715, dtype=float32), 'eval/episode_forward_reward': Array(1335.615, dtype=float32), 'eval/episode_reward': Array(1089.992, dtype=float32), 'eval/episode_reward_alive': Array(233.91016, dtype=float32), 'eval/episode_reward_linvel': Array(1335.615, dtype=float32), 'eval/episode_reward_quadctrl': Array(-487.54706, dtype=float32), 'eval/episode_x_position': Array(4145.747, dtype=float32), 'eval/episode_x_velocity': Array(267.12296, dtype=float32), 'eval/episode_y_position': Array(-394.60147, dtype=float32), 'eval/episode_y_velocity': Array(-138.02647, dtype=float32), 'eval/episode_distance_from_origin_std': Array(381.1102, dtype=float32), 'eval/episode_distance_reward_std': Array(3.075908, dtype=float32), 'eval/episode_forward_reward_std': Array(512.6479, dtype=float32), 'eval/episode_reward_std': Array(537.6766, dtype=float32), 'eval/episode_reward_alive_std': Array(77.64375, dtype=float32), 'eval/episode_reward_linvel_std': Array(512.6479, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.522846, dtype=float32), 'eval/episode_x_position_std': Array(362.42758, dtype=float32), 'eval/episode_x_velocity_std': Array(102.529564, dtype=float32), 'eval/episode_y_position_std': Array(295.61215, dtype=float32), 'eval/episode_y_velocity_std': Array(75.25465, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40825748443604, 'eval/sps': 938.3596151765563, 'num_steps': 14909440}
{'eval/walltime': 25159.895753383636, 'training/sps': 2947.363712169385, 'training/walltime': 5122.4855942726135, 'training/entropy_loss': Array(0.014173, dtype=float32), 'training/policy_loss': Array(0.01138772, dtype=float32), 'training/total_loss': Array(0.14436582, dtype=float32), 'training/v_loss': Array(0.1188051, dtype=float32), 'eval/episode_distance_from_origin': Array(4271.8506, dtype=float32), 'eval/episode_distance_reward': Array(8.372242, dtype=float32), 'eval/episode_forward_reward': Array(1395.369, dtype=float32), 'eval/episode_reward': Array(1164.4778, dtype=float32), 'eval/episode_reward_alive': Array(249.51953, dtype=float32), 'eval/episode_reward_linvel': Array(1395.369, dtype=float32), 'eval/episode_reward_quadctrl': Array(-488.78308, dtype=float32), 'eval/episode_x_position': Array(4200.284, dtype=float32), 'eval/episode_x_velocity': Array(279.07385, dtype=float32), 'eval/episode_y_position': Array(-433.51178, dtype=float32), 'eval/episode_y_velocity': Array(-146.784, dtype=float32), 'eval/episode_distance_from_origin_std': Array(418.00717, dtype=float32), 'eval/episode_distance_reward_std': Array(3.209416, dtype=float32), 'eval/episode_forward_reward_std': Array(534.8988, dtype=float32), 'eval/episode_reward_std': Array(557.8398, dtype=float32), 'eval/episode_reward_alive_std': Array(73.81129, dtype=float32), 'eval/episode_reward_linvel_std': Array(534.8988, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.430653, dtype=float32), 'eval/episode_x_position_std': Array(393.9019, dtype=float32), 'eval/episode_x_velocity_std': Array(106.97977, dtype=float32), 'eval/episode_y_position_std': Array(322.27167, dtype=float32), 'eval/episode_y_velocity_std': Array(83.35675, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3221914768219, 'eval/sps': 938.9520415813087, 'num_steps': 14991360}
{'eval/walltime': 25296.320487976074, 'training/sps': 2941.2449127888563, 'training/walltime': 5150.337746143341, 'training/entropy_loss': Array(0.02411598, dtype=float32), 'training/policy_loss': Array(0.05148292, dtype=float32), 'training/total_loss': Array(0.14694512, dtype=float32), 'training/v_loss': Array(0.07134621, dtype=float32), 'eval/episode_distance_from_origin': Array(4321.8994, dtype=float32), 'eval/episode_distance_reward': Array(8.828614, dtype=float32), 'eval/episode_forward_reward': Array(1471.4312, dtype=float32), 'eval/episode_reward': Array(1224.204, dtype=float32), 'eval/episode_reward_alive': Array(229.3125, dtype=float32), 'eval/episode_reward_linvel': Array(1471.4312, dtype=float32), 'eval/episode_reward_quadctrl': Array(-485.36804, dtype=float32), 'eval/episode_x_position': Array(4252.8223, dtype=float32), 'eval/episode_x_velocity': Array(294.2862, dtype=float32), 'eval/episode_y_position': Array(-432.40125, dtype=float32), 'eval/episode_y_velocity': Array(-148.38208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.27866, dtype=float32), 'eval/episode_distance_reward_std': Array(3.432901, dtype=float32), 'eval/episode_forward_reward_std': Array(572.1463, dtype=float32), 'eval/episode_reward_std': Array(608.5799, dtype=float32), 'eval/episode_reward_alive_std': Array(62.69423, dtype=float32), 'eval/episode_reward_linvel_std': Array(572.1463, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.806978, dtype=float32), 'eval/episode_x_position_std': Array(402.35074, dtype=float32), 'eval/episode_x_velocity_std': Array(114.429214, dtype=float32), 'eval/episode_y_position_std': Array(290.31036, dtype=float32), 'eval/episode_y_velocity_std': Array(71.58509, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42473459243774, 'eval/sps': 938.2462819692761, 'num_steps': 15073280}
{'eval/walltime': 25432.637505054474, 'training/sps': 2943.777404593748, 'training/walltime': 5178.1659371852875, 'training/entropy_loss': Array(0.03235647, dtype=float32), 'training/policy_loss': Array(0.11741766, dtype=float32), 'training/total_loss': Array(0.20308623, dtype=float32), 'training/v_loss': Array(0.05331209, dtype=float32), 'eval/episode_distance_from_origin': Array(4347.0356, dtype=float32), 'eval/episode_distance_reward': Array(8.946112, dtype=float32), 'eval/episode_forward_reward': Array(1491.0135, dtype=float32), 'eval/episode_reward': Array(1250.4645, dtype=float32), 'eval/episode_reward_alive': Array(235.32031, dtype=float32), 'eval/episode_reward_linvel': Array(1491.0135, dtype=float32), 'eval/episode_reward_quadctrl': Array(-484.8155, dtype=float32), 'eval/episode_x_position': Array(4283.6216, dtype=float32), 'eval/episode_x_velocity': Array(298.2027, dtype=float32), 'eval/episode_y_position': Array(-400.5191, dtype=float32), 'eval/episode_y_velocity': Array(-129.42038, dtype=float32), 'eval/episode_distance_from_origin_std': Array(406.70084, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2661028, dtype=float32), 'eval/episode_forward_reward_std': Array(544.3465, dtype=float32), 'eval/episode_reward_std': Array(567.0602, dtype=float32), 'eval/episode_reward_alive_std': Array(58.76884, dtype=float32), 'eval/episode_reward_linvel_std': Array(544.3465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.343838, dtype=float32), 'eval/episode_x_position_std': Array(387.8017, dtype=float32), 'eval/episode_x_velocity_std': Array(108.86928, dtype=float32), 'eval/episode_y_position_std': Array(296.4851, dtype=float32), 'eval/episode_y_velocity_std': Array(77.39753, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31701707839966, 'eval/sps': 938.9876828538853, 'num_steps': 15155200}
{'eval/walltime': 25569.06259894371, 'training/sps': 2942.369618593205, 'training/walltime': 5206.007442712784, 'training/entropy_loss': Array(0.02814796, dtype=float32), 'training/policy_loss': Array(0.3860429, dtype=float32), 'training/total_loss': Array(0.4480945, dtype=float32), 'training/v_loss': Array(0.03390361, dtype=float32), 'eval/episode_distance_from_origin': Array(4445.736, dtype=float32), 'eval/episode_distance_reward': Array(9.748767, dtype=float32), 'eval/episode_forward_reward': Array(1624.7896, dtype=float32), 'eval/episode_reward': Array(1335.6857, dtype=float32), 'eval/episode_reward_alive': Array(153.9336, dtype=float32), 'eval/episode_reward_linvel': Array(1624.7896, dtype=float32), 'eval/episode_reward_quadctrl': Array(-452.78647, dtype=float32), 'eval/episode_x_position': Array(4356.825, dtype=float32), 'eval/episode_x_velocity': Array(324.95792, dtype=float32), 'eval/episode_y_position': Array(-613.5573, dtype=float32), 'eval/episode_y_velocity': Array(-167.52126, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.8895, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6679077, dtype=float32), 'eval/episode_forward_reward_std': Array(777.98, dtype=float32), 'eval/episode_reward_std': Array(862.0653, dtype=float32), 'eval/episode_reward_alive_std': Array(56.47124, dtype=float32), 'eval/episode_reward_linvel_std': Array(777.98, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.124577, dtype=float32), 'eval/episode_x_position_std': Array(360.10367, dtype=float32), 'eval/episode_x_velocity_std': Array(155.59602, dtype=float32), 'eval/episode_y_position_std': Array(301.68176, dtype=float32), 'eval/episode_y_velocity_std': Array(77.10923, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42509388923645, 'eval/sps': 938.2438109511086, 'num_steps': 15237120}
{'eval/walltime': 25705.405876159668, 'training/sps': 2944.918788746365, 'training/walltime': 5233.824848175049, 'training/entropy_loss': Array(0.03178779, dtype=float32), 'training/policy_loss': Array(0.16687375, dtype=float32), 'training/total_loss': Array(0.22391157, dtype=float32), 'training/v_loss': Array(0.02525005, dtype=float32), 'eval/episode_distance_from_origin': Array(4441.172, dtype=float32), 'eval/episode_distance_reward': Array(9.626695, dtype=float32), 'eval/episode_forward_reward': Array(1604.4443, dtype=float32), 'eval/episode_reward': Array(1319.1191, dtype=float32), 'eval/episode_reward_alive': Array(159.71094, dtype=float32), 'eval/episode_reward_linvel': Array(1604.4443, dtype=float32), 'eval/episode_reward_quadctrl': Array(-454.6628, dtype=float32), 'eval/episode_x_position': Array(4360.6113, dtype=float32), 'eval/episode_x_velocity': Array(320.88885, dtype=float32), 'eval/episode_y_position': Array(-557.3229, dtype=float32), 'eval/episode_y_velocity': Array(-157.72292, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.57242, dtype=float32), 'eval/episode_distance_reward_std': Array(4.154911, dtype=float32), 'eval/episode_forward_reward_std': Array(692.48065, dtype=float32), 'eval/episode_reward_std': Array(772.4168, dtype=float32), 'eval/episode_reward_alive_std': Array(61.474705, dtype=float32), 'eval/episode_reward_linvel_std': Array(692.48065, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.632015, dtype=float32), 'eval/episode_x_position_std': Array(381.67032, dtype=float32), 'eval/episode_x_velocity_std': Array(138.49615, dtype=float32), 'eval/episode_y_position_std': Array(295.08957, dtype=float32), 'eval/episode_y_velocity_std': Array(79.64115, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34327721595764, 'eval/sps': 938.8068309173578, 'num_steps': 15319040}
{'eval/walltime': 25841.86692070961, 'training/sps': 2943.439735863507, 'training/walltime': 5261.656231641769, 'training/entropy_loss': Array(0.01882802, dtype=float32), 'training/policy_loss': Array(0.02335016, dtype=float32), 'training/total_loss': Array(0.08620273, dtype=float32), 'training/v_loss': Array(0.04402456, dtype=float32), 'eval/episode_distance_from_origin': Array(4524.404, dtype=float32), 'eval/episode_distance_reward': Array(10.563749, dtype=float32), 'eval/episode_forward_reward': Array(1760.6193, dtype=float32), 'eval/episode_reward': Array(1491.9777, dtype=float32), 'eval/episode_reward_alive': Array(169.86328, dtype=float32), 'eval/episode_reward_linvel': Array(1760.6193, dtype=float32), 'eval/episode_reward_quadctrl': Array(-449.06857, dtype=float32), 'eval/episode_x_position': Array(4438.877, dtype=float32), 'eval/episode_x_velocity': Array(352.12384, dtype=float32), 'eval/episode_y_position': Array(-600.2607, dtype=float32), 'eval/episode_y_velocity': Array(-170.26877, dtype=float32), 'eval/episode_distance_from_origin_std': Array(447.45096, dtype=float32), 'eval/episode_distance_reward_std': Array(4.894159, dtype=float32), 'eval/episode_forward_reward_std': Array(815.68805, dtype=float32), 'eval/episode_reward_std': Array(904.41895, dtype=float32), 'eval/episode_reward_alive_std': Array(63.101597, dtype=float32), 'eval/episode_reward_linvel_std': Array(815.68805, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.515514, dtype=float32), 'eval/episode_x_position_std': Array(431.06372, dtype=float32), 'eval/episode_x_velocity_std': Array(163.13768, dtype=float32), 'eval/episode_y_position_std': Array(292.8806, dtype=float32), 'eval/episode_y_velocity_std': Array(77.90568, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46104454994202, 'eval/sps': 937.996630629297, 'num_steps': 15400960}
{'eval/walltime': 25978.22368788719, 'training/sps': 2945.937491514611, 'training/walltime': 5289.464017868042, 'training/entropy_loss': Array(0.0082433, dtype=float32), 'training/policy_loss': Array(-0.00011302, dtype=float32), 'training/total_loss': Array(0.15095836, dtype=float32), 'training/v_loss': Array(0.14282808, dtype=float32), 'eval/episode_distance_from_origin': Array(4539.56, dtype=float32), 'eval/episode_distance_reward': Array(10.610574, dtype=float32), 'eval/episode_forward_reward': Array(1768.423, dtype=float32), 'eval/episode_reward': Array(1499.7948, dtype=float32), 'eval/episode_reward_alive': Array(167.20703, dtype=float32), 'eval/episode_reward_linvel': Array(1768.423, dtype=float32), 'eval/episode_reward_quadctrl': Array(-446.44577, dtype=float32), 'eval/episode_x_position': Array(4450.9917, dtype=float32), 'eval/episode_x_velocity': Array(353.6846, dtype=float32), 'eval/episode_y_position': Array(-611.75195, dtype=float32), 'eval/episode_y_velocity': Array(-174.05026, dtype=float32), 'eval/episode_distance_from_origin_std': Array(401.41785, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4599276, dtype=float32), 'eval/episode_forward_reward_std': Array(743.31647, dtype=float32), 'eval/episode_reward_std': Array(820.5711, dtype=float32), 'eval/episode_reward_alive_std': Array(52.349094, dtype=float32), 'eval/episode_reward_linvel_std': Array(743.31647, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.937557, dtype=float32), 'eval/episode_x_position_std': Array(387.87756, dtype=float32), 'eval/episode_x_velocity_std': Array(148.66336, dtype=float32), 'eval/episode_y_position_std': Array(304.8276, dtype=float32), 'eval/episode_y_velocity_std': Array(78.20988, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3567671775818, 'eval/sps': 938.7139534725218, 'num_steps': 15482880}
{'eval/walltime': 26114.80811023712, 'training/sps': 2939.689665652757, 'training/walltime': 5317.330904960632, 'training/entropy_loss': Array(0.01167385, dtype=float32), 'training/policy_loss': Array(0.00167436, dtype=float32), 'training/total_loss': Array(0.15165454, dtype=float32), 'training/v_loss': Array(0.13830632, dtype=float32), 'eval/episode_distance_from_origin': Array(4570.2446, dtype=float32), 'eval/episode_distance_reward': Array(10.872002, dtype=float32), 'eval/episode_forward_reward': Array(1811.994, dtype=float32), 'eval/episode_reward': Array(1545.4514, dtype=float32), 'eval/episode_reward_alive': Array(169.47266, dtype=float32), 'eval/episode_reward_linvel': Array(1811.994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-446.88733, dtype=float32), 'eval/episode_x_position': Array(4483.027, dtype=float32), 'eval/episode_x_velocity': Array(362.3988, dtype=float32), 'eval/episode_y_position': Array(-614.3088, dtype=float32), 'eval/episode_y_velocity': Array(-176.91057, dtype=float32), 'eval/episode_distance_from_origin_std': Array(410.39786, dtype=float32), 'eval/episode_distance_reward_std': Array(4.583777, dtype=float32), 'eval/episode_forward_reward_std': Array(763.9572, dtype=float32), 'eval/episode_reward_std': Array(841.93146, dtype=float32), 'eval/episode_reward_alive_std': Array(54.28672, dtype=float32), 'eval/episode_reward_linvel_std': Array(763.9572, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.800816, dtype=float32), 'eval/episode_x_position_std': Array(399.8264, dtype=float32), 'eval/episode_x_velocity_std': Array(152.79144, dtype=float32), 'eval/episode_y_position_std': Array(285.22696, dtype=float32), 'eval/episode_y_velocity_std': Array(75.99724, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5844223499298, 'eval/sps': 937.1493307784655, 'num_steps': 15564800}
{'eval/walltime': 26251.144112110138, 'training/sps': 2942.3577509696347, 'training/walltime': 5345.172522783279, 'training/entropy_loss': Array(0.01493734, dtype=float32), 'training/policy_loss': Array(0.00457655, dtype=float32), 'training/total_loss': Array(0.09924342, dtype=float32), 'training/v_loss': Array(0.07972953, dtype=float32), 'eval/episode_distance_from_origin': Array(4527.536, dtype=float32), 'eval/episode_distance_reward': Array(10.675001, dtype=float32), 'eval/episode_forward_reward': Array(1779.1611, dtype=float32), 'eval/episode_reward': Array(1526.331, dtype=float32), 'eval/episode_reward_alive': Array(177.83594, dtype=float32), 'eval/episode_reward_linvel': Array(1779.1611, dtype=float32), 'eval/episode_reward_quadctrl': Array(-441.3409, dtype=float32), 'eval/episode_x_position': Array(4442.2134, dtype=float32), 'eval/episode_x_velocity': Array(355.8322, dtype=float32), 'eval/episode_y_position': Array(-613.966, dtype=float32), 'eval/episode_y_velocity': Array(-179.91856, dtype=float32), 'eval/episode_distance_from_origin_std': Array(441.0647, dtype=float32), 'eval/episode_distance_reward_std': Array(4.906434, dtype=float32), 'eval/episode_forward_reward_std': Array(817.7341, dtype=float32), 'eval/episode_reward_std': Array(898.21643, dtype=float32), 'eval/episode_reward_alive_std': Array(56.788673, dtype=float32), 'eval/episode_reward_linvel_std': Array(817.7341, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.12016, dtype=float32), 'eval/episode_x_position_std': Array(430.56357, dtype=float32), 'eval/episode_x_velocity_std': Array(163.54675, dtype=float32), 'eval/episode_y_position_std': Array(254.25282, dtype=float32), 'eval/episode_y_velocity_std': Array(64.1536, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33600187301636, 'eval/sps': 938.856928775273, 'num_steps': 15646720}
{'eval/walltime': 26387.634706258774, 'training/sps': 2930.3266606518328, 'training/walltime': 5373.128450393677, 'training/entropy_loss': Array(0.01919494, dtype=float32), 'training/policy_loss': Array(0.02529638, dtype=float32), 'training/total_loss': Array(0.09871229, dtype=float32), 'training/v_loss': Array(0.05422097, dtype=float32), 'eval/episode_distance_from_origin': Array(4485.2095, dtype=float32), 'eval/episode_distance_reward': Array(10.220774, dtype=float32), 'eval/episode_forward_reward': Array(1703.4564, dtype=float32), 'eval/episode_reward': Array(1458.8596, dtype=float32), 'eval/episode_reward_alive': Array(182.11719, dtype=float32), 'eval/episode_reward_linvel': Array(1703.4564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.9347, dtype=float32), 'eval/episode_x_position': Array(4402.19, dtype=float32), 'eval/episode_x_velocity': Array(340.69128, dtype=float32), 'eval/episode_y_position': Array(-599.5679, dtype=float32), 'eval/episode_y_velocity': Array(-173.64276, dtype=float32), 'eval/episode_distance_from_origin_std': Array(474.89682, dtype=float32), 'eval/episode_distance_reward_std': Array(4.547837, dtype=float32), 'eval/episode_forward_reward_std': Array(757.9674, dtype=float32), 'eval/episode_reward_std': Array(831.2258, dtype=float32), 'eval/episode_reward_alive_std': Array(54.17973, dtype=float32), 'eval/episode_reward_linvel_std': Array(757.9674, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.052635, dtype=float32), 'eval/episode_x_position_std': Array(452.33066, dtype=float32), 'eval/episode_x_velocity_std': Array(151.59349, dtype=float32), 'eval/episode_y_position_std': Array(279.46558, dtype=float32), 'eval/episode_y_velocity_std': Array(71.63469, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49059414863586, 'eval/sps': 937.7935585847787, 'num_steps': 15728640}
{'eval/walltime': 26523.957482099533, 'training/sps': 2933.872408998863, 'training/walltime': 5401.05059170723, 'training/entropy_loss': Array(0.02348694, dtype=float32), 'training/policy_loss': Array(0.05582317, dtype=float32), 'training/total_loss': Array(0.12592098, dtype=float32), 'training/v_loss': Array(0.04661087, dtype=float32), 'eval/episode_distance_from_origin': Array(4408.84, dtype=float32), 'eval/episode_distance_reward': Array(9.748266, dtype=float32), 'eval/episode_forward_reward': Array(1624.7063, dtype=float32), 'eval/episode_reward': Array(1384.5083, dtype=float32), 'eval/episode_reward_alive': Array(170.51172, dtype=float32), 'eval/episode_reward_linvel': Array(1624.7063, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.45764, dtype=float32), 'eval/episode_x_position': Array(4325.673, dtype=float32), 'eval/episode_x_velocity': Array(324.94122, dtype=float32), 'eval/episode_y_position': Array(-607.52856, dtype=float32), 'eval/episode_y_velocity': Array(-171.92377, dtype=float32), 'eval/episode_distance_from_origin_std': Array(389.83276, dtype=float32), 'eval/episode_distance_reward_std': Array(4.037266, dtype=float32), 'eval/episode_forward_reward_std': Array(672.87317, dtype=float32), 'eval/episode_reward_std': Array(741.78143, dtype=float32), 'eval/episode_reward_alive_std': Array(52.809853, dtype=float32), 'eval/episode_reward_linvel_std': Array(672.87317, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.81112, dtype=float32), 'eval/episode_x_position_std': Array(379.6017, dtype=float32), 'eval/episode_x_velocity_std': Array(134.57458, dtype=float32), 'eval/episode_y_position_std': Array(218.5668, dtype=float32), 'eval/episode_y_velocity_std': Array(57.810577, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32277584075928, 'eval/sps': 938.9480166507082, 'num_steps': 15810560}
{'eval/walltime': 26660.397438526154, 'training/sps': 2937.3395366039745, 'training/walltime': 5428.939774751663, 'training/entropy_loss': Array(0.02141122, dtype=float32), 'training/policy_loss': Array(0.06428255, dtype=float32), 'training/total_loss': Array(0.12141097, dtype=float32), 'training/v_loss': Array(0.0357172, dtype=float32), 'eval/episode_distance_from_origin': Array(4285.702, dtype=float32), 'eval/episode_distance_reward': Array(8.378077, dtype=float32), 'eval/episode_forward_reward': Array(1396.3434, dtype=float32), 'eval/episode_reward': Array(1160.7645, dtype=float32), 'eval/episode_reward_alive': Array(160.33203, dtype=float32), 'eval/episode_reward_linvel': Array(1396.3434, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.28894, dtype=float32), 'eval/episode_x_position': Array(4217.6387, dtype=float32), 'eval/episode_x_velocity': Array(279.26865, dtype=float32), 'eval/episode_y_position': Array(-496.3822, dtype=float32), 'eval/episode_y_velocity': Array(-138.20872, dtype=float32), 'eval/episode_distance_from_origin_std': Array(387.73758, dtype=float32), 'eval/episode_distance_reward_std': Array(3.4280112, dtype=float32), 'eval/episode_forward_reward_std': Array(571.3322, dtype=float32), 'eval/episode_reward_std': Array(616.5733, dtype=float32), 'eval/episode_reward_alive_std': Array(44.448017, dtype=float32), 'eval/episode_reward_linvel_std': Array(571.3322, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.380913, dtype=float32), 'eval/episode_x_position_std': Array(380.2827, dtype=float32), 'eval/episode_x_velocity_std': Array(114.26641, dtype=float32), 'eval/episode_y_position_std': Array(222.1891, dtype=float32), 'eval/episode_y_velocity_std': Array(56.782955, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43995642662048, 'eval/sps': 938.1416071386711, 'num_steps': 15892480}
{'eval/walltime': 26796.74409365654, 'training/sps': 2942.518412953455, 'training/walltime': 5456.77987241745, 'training/entropy_loss': Array(0.00535815, dtype=float32), 'training/policy_loss': Array(-0.00175405, dtype=float32), 'training/total_loss': Array(0.12804547, dtype=float32), 'training/v_loss': Array(0.12444137, dtype=float32), 'eval/episode_distance_from_origin': Array(4362.1157, dtype=float32), 'eval/episode_distance_reward': Array(8.744563, dtype=float32), 'eval/episode_forward_reward': Array(1457.424, dtype=float32), 'eval/episode_reward': Array(1206.3059, dtype=float32), 'eval/episode_reward_alive': Array(161.40625, dtype=float32), 'eval/episode_reward_linvel': Array(1457.424, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.2691, dtype=float32), 'eval/episode_x_position': Array(4277.226, dtype=float32), 'eval/episode_x_velocity': Array(291.48483, dtype=float32), 'eval/episode_y_position': Array(-611.4064, dtype=float32), 'eval/episode_y_velocity': Array(-167.33948, dtype=float32), 'eval/episode_distance_from_origin_std': Array(375.13818, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3508167, dtype=float32), 'eval/episode_forward_reward_std': Array(558.4661, dtype=float32), 'eval/episode_reward_std': Array(605.31573, dtype=float32), 'eval/episode_reward_alive_std': Array(43.65269, dtype=float32), 'eval/episode_reward_linvel_std': Array(558.4661, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.1536, dtype=float32), 'eval/episode_x_position_std': Array(359.48862, dtype=float32), 'eval/episode_x_velocity_std': Array(111.693184, dtype=float32), 'eval/episode_y_position_std': Array(238.08797, dtype=float32), 'eval/episode_y_velocity_std': Array(60.74339, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34665513038635, 'eval/sps': 938.783572487315, 'num_steps': 15974400}
{'eval/walltime': 26933.181394338608, 'training/sps': 2939.663106567227, 'training/walltime': 5484.64701128006, 'training/entropy_loss': Array(0.00886246, dtype=float32), 'training/policy_loss': Array(-0.00064153, dtype=float32), 'training/total_loss': Array(0.13013583, dtype=float32), 'training/v_loss': Array(0.12191489, dtype=float32), 'eval/episode_distance_from_origin': Array(4489.073, dtype=float32), 'eval/episode_distance_reward': Array(10.267546, dtype=float32), 'eval/episode_forward_reward': Array(1711.2527, dtype=float32), 'eval/episode_reward': Array(1497.456, dtype=float32), 'eval/episode_reward_alive': Array(179.42578, dtype=float32), 'eval/episode_reward_linvel': Array(1711.2527, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.48975, dtype=float32), 'eval/episode_x_position': Array(4400.4272, dtype=float32), 'eval/episode_x_velocity': Array(342.2505, dtype=float32), 'eval/episode_y_position': Array(-648.4741, dtype=float32), 'eval/episode_y_velocity': Array(-179.628, dtype=float32), 'eval/episode_distance_from_origin_std': Array(413.24612, dtype=float32), 'eval/episode_distance_reward_std': Array(3.758517, dtype=float32), 'eval/episode_forward_reward_std': Array(626.41534, dtype=float32), 'eval/episode_reward_std': Array(678.282, dtype=float32), 'eval/episode_reward_alive_std': Array(52.62448, dtype=float32), 'eval/episode_reward_linvel_std': Array(626.41534, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.28819, dtype=float32), 'eval/episode_x_position_std': Array(401.74673, dtype=float32), 'eval/episode_x_velocity_std': Array(125.28302, dtype=float32), 'eval/episode_y_position_std': Array(221.28848, dtype=float32), 'eval/episode_y_velocity_std': Array(53.984467, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43730068206787, 'eval/sps': 938.1598680134487, 'num_steps': 16056320}
{'eval/walltime': 27070.15629887581, 'training/sps': 2946.2668408064255, 'training/walltime': 5512.451689004898, 'training/entropy_loss': Array(0.01060724, dtype=float32), 'training/policy_loss': Array(0.00164141, dtype=float32), 'training/total_loss': Array(0.08934723, dtype=float32), 'training/v_loss': Array(0.07709858, dtype=float32), 'eval/episode_distance_from_origin': Array(4486.505, dtype=float32), 'eval/episode_distance_reward': Array(10.364271, dtype=float32), 'eval/episode_forward_reward': Array(1727.373, dtype=float32), 'eval/episode_reward': Array(1505.6035, dtype=float32), 'eval/episode_reward_alive': Array(176.35547, dtype=float32), 'eval/episode_reward_linvel': Array(1727.373, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.48938, dtype=float32), 'eval/episode_x_position': Array(4402.1504, dtype=float32), 'eval/episode_x_velocity': Array(345.4746, dtype=float32), 'eval/episode_y_position': Array(-610.427, dtype=float32), 'eval/episode_y_velocity': Array(-173.33984, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.08603, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8331842, dtype=float32), 'eval/episode_forward_reward_std': Array(805.52576, dtype=float32), 'eval/episode_reward_std': Array(876.4651, dtype=float32), 'eval/episode_reward_alive_std': Array(57.118984, dtype=float32), 'eval/episode_reward_linvel_std': Array(805.52576, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.949627, dtype=float32), 'eval/episode_x_position_std': Array(483.1966, dtype=float32), 'eval/episode_x_velocity_std': Array(161.10513, dtype=float32), 'eval/episode_y_position_std': Array(247.12646, dtype=float32), 'eval/episode_y_velocity_std': Array(64.601326, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.97490453720093, 'eval/sps': 934.4777456314018, 'num_steps': 16138240}
{'eval/walltime': 27206.590648651123, 'training/sps': 2940.878651019304, 'training/walltime': 5540.307309627533, 'training/entropy_loss': Array(0.01234064, dtype=float32), 'training/policy_loss': Array(0.0055459, dtype=float32), 'training/total_loss': Array(0.07323821, dtype=float32), 'training/v_loss': Array(0.05535167, dtype=float32), 'eval/episode_distance_from_origin': Array(4515.359, dtype=float32), 'eval/episode_distance_reward': Array(10.577757, dtype=float32), 'eval/episode_forward_reward': Array(1762.9543, dtype=float32), 'eval/episode_reward': Array(1561.7822, dtype=float32), 'eval/episode_reward_alive': Array(181.10156, dtype=float32), 'eval/episode_reward_linvel': Array(1762.9543, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.8515, dtype=float32), 'eval/episode_x_position': Array(4436.161, dtype=float32), 'eval/episode_x_velocity': Array(352.59082, dtype=float32), 'eval/episode_y_position': Array(-581.6725, dtype=float32), 'eval/episode_y_velocity': Array(-159.89726, dtype=float32), 'eval/episode_distance_from_origin_std': Array(467.13013, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5287786, dtype=float32), 'eval/episode_forward_reward_std': Array(754.7918, dtype=float32), 'eval/episode_reward_std': Array(808.74994, dtype=float32), 'eval/episode_reward_alive_std': Array(56.71207, dtype=float32), 'eval/episode_reward_linvel_std': Array(754.7918, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.93502, dtype=float32), 'eval/episode_x_position_std': Array(455.9712, dtype=float32), 'eval/episode_x_velocity_std': Array(150.95828, dtype=float32), 'eval/episode_y_position_std': Array(258.85434, dtype=float32), 'eval/episode_y_velocity_std': Array(64.55608, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43434977531433, 'eval/sps': 938.1801592545838, 'num_steps': 16220160}
{'eval/walltime': 27342.952004671097, 'training/sps': 2945.559656567075, 'training/walltime': 5568.1186628341675, 'training/entropy_loss': Array(0.01224658, dtype=float32), 'training/policy_loss': Array(0.00297066, dtype=float32), 'training/total_loss': Array(0.0569465, dtype=float32), 'training/v_loss': Array(0.04172926, dtype=float32), 'eval/episode_distance_from_origin': Array(4466.0444, dtype=float32), 'eval/episode_distance_reward': Array(9.988916, dtype=float32), 'eval/episode_forward_reward': Array(1664.815, dtype=float32), 'eval/episode_reward': Array(1506.6029, dtype=float32), 'eval/episode_reward_alive': Array(213.23828, dtype=float32), 'eval/episode_reward_linvel': Array(1664.815, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.43906, dtype=float32), 'eval/episode_x_position': Array(4390.8716, dtype=float32), 'eval/episode_x_velocity': Array(332.96295, dtype=float32), 'eval/episode_y_position': Array(-538.89465, dtype=float32), 'eval/episode_y_velocity': Array(-144.46222, dtype=float32), 'eval/episode_distance_from_origin_std': Array(426.79526, dtype=float32), 'eval/episode_distance_reward_std': Array(4.0835834, dtype=float32), 'eval/episode_forward_reward_std': Array(680.5927, dtype=float32), 'eval/episode_reward_std': Array(718.3163, dtype=float32), 'eval/episode_reward_alive_std': Array(65.99914, dtype=float32), 'eval/episode_reward_linvel_std': Array(680.5927, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.271904, dtype=float32), 'eval/episode_x_position_std': Array(413.95453, dtype=float32), 'eval/episode_x_velocity_std': Array(136.11859, dtype=float32), 'eval/episode_y_position_std': Array(285.459, dtype=float32), 'eval/episode_y_velocity_std': Array(74.13983, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.36135601997375, 'eval/sps': 938.6823638014497, 'num_steps': 16302080}
{'eval/walltime': 27479.391285657883, 'training/sps': 2934.5921378671637, 'training/walltime': 5596.033956050873, 'training/entropy_loss': Array(0.01168083, dtype=float32), 'training/policy_loss': Array(0.00178128, dtype=float32), 'training/total_loss': Array(0.05008833, dtype=float32), 'training/v_loss': Array(0.03662622, dtype=float32), 'eval/episode_distance_from_origin': Array(4558.452, dtype=float32), 'eval/episode_distance_reward': Array(11.165466, dtype=float32), 'eval/episode_forward_reward': Array(1860.9048, dtype=float32), 'eval/episode_reward': Array(1695.3882, dtype=float32), 'eval/episode_reward_alive': Array(205.28906, dtype=float32), 'eval/episode_reward_linvel': Array(1860.9048, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.97134, dtype=float32), 'eval/episode_x_position': Array(4483.167, dtype=float32), 'eval/episode_x_velocity': Array(372.181, dtype=float32), 'eval/episode_y_position': Array(-552.48145, dtype=float32), 'eval/episode_y_velocity': Array(-150.47757, dtype=float32), 'eval/episode_distance_from_origin_std': Array(459.03592, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7536073, dtype=float32), 'eval/episode_forward_reward_std': Array(792.26263, dtype=float32), 'eval/episode_reward_std': Array(832.5156, dtype=float32), 'eval/episode_reward_alive_std': Array(63.668285, dtype=float32), 'eval/episode_reward_linvel_std': Array(792.26263, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.30285, dtype=float32), 'eval/episode_x_position_std': Array(445.39398, dtype=float32), 'eval/episode_x_velocity_std': Array(158.45255, dtype=float32), 'eval/episode_y_position_std': Array(277.29855, dtype=float32), 'eval/episode_y_velocity_std': Array(75.12891, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4392809867859, 'eval/sps': 938.1462513892665, 'num_steps': 16384000}
{'eval/walltime': 27616.374332666397, 'training/sps': 2944.132128446368, 'training/walltime': 5623.858794212341, 'training/entropy_loss': Array(0.0049949, dtype=float32), 'training/policy_loss': Array(-0.00257001, dtype=float32), 'training/total_loss': Array(0.08464162, dtype=float32), 'training/v_loss': Array(0.08221672, dtype=float32), 'eval/episode_distance_from_origin': Array(4681.1216, dtype=float32), 'eval/episode_distance_reward': Array(11.727897, dtype=float32), 'eval/episode_forward_reward': Array(1954.6423, dtype=float32), 'eval/episode_reward': Array(1759.0985, dtype=float32), 'eval/episode_reward_alive': Array(194.20312, dtype=float32), 'eval/episode_reward_linvel': Array(1954.6423, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.47498, dtype=float32), 'eval/episode_x_position': Array(4602.2383, dtype=float32), 'eval/episode_x_velocity': Array(390.92847, dtype=float32), 'eval/episode_y_position': Array(-588.4633, dtype=float32), 'eval/episode_y_velocity': Array(-160.84747, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.8302, dtype=float32), 'eval/episode_distance_reward_std': Array(3.980056, dtype=float32), 'eval/episode_forward_reward_std': Array(663.33777, dtype=float32), 'eval/episode_reward_std': Array(710.0762, dtype=float32), 'eval/episode_reward_alive_std': Array(62.209618, dtype=float32), 'eval/episode_reward_linvel_std': Array(663.33777, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.582775, dtype=float32), 'eval/episode_x_position_std': Array(426.8162, dtype=float32), 'eval/episode_x_velocity_std': Array(132.66762, dtype=float32), 'eval/episode_y_position_std': Array(280.89957, dtype=float32), 'eval/episode_y_velocity_std': Array(67.50977, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.9830470085144, 'eval/sps': 934.4221989166583, 'num_steps': 16465920}
{'eval/walltime': 27752.657165050507, 'training/sps': 2948.5157738213743, 'training/walltime': 5651.64226436615, 'training/entropy_loss': Array(0.00866337, dtype=float32), 'training/policy_loss': Array(-0.0016092, dtype=float32), 'training/total_loss': Array(0.1529902, dtype=float32), 'training/v_loss': Array(0.14593603, dtype=float32), 'eval/episode_distance_from_origin': Array(4658.2607, dtype=float32), 'eval/episode_distance_reward': Array(11.5076885, dtype=float32), 'eval/episode_forward_reward': Array(1917.941, dtype=float32), 'eval/episode_reward': Array(1708.2751, dtype=float32), 'eval/episode_reward_alive': Array(192.66406, dtype=float32), 'eval/episode_reward_linvel': Array(1917.941, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.83752, dtype=float32), 'eval/episode_x_position': Array(4578.498, dtype=float32), 'eval/episode_x_velocity': Array(383.58823, dtype=float32), 'eval/episode_y_position': Array(-581.3796, dtype=float32), 'eval/episode_y_velocity': Array(-163.76022, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.4514, dtype=float32), 'eval/episode_distance_reward_std': Array(4.1196575, dtype=float32), 'eval/episode_forward_reward_std': Array(686.6048, dtype=float32), 'eval/episode_reward_std': Array(728.95245, dtype=float32), 'eval/episode_reward_alive_std': Array(68.32047, dtype=float32), 'eval/episode_reward_linvel_std': Array(686.6048, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.37522, dtype=float32), 'eval/episode_x_position_std': Array(416.40363, dtype=float32), 'eval/episode_x_velocity_std': Array(137.32098, dtype=float32), 'eval/episode_y_position_std': Array(292.39023, dtype=float32), 'eval/episode_y_velocity_std': Array(71.510704, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2828323841095, 'eval/sps': 939.2232151386129, 'num_steps': 16547840}
{'eval/walltime': 27888.92722415924, 'training/sps': 2946.7588547240166, 'training/walltime': 5679.442299604416, 'training/entropy_loss': Array(0.01061718, dtype=float32), 'training/policy_loss': Array(-0.00013129, dtype=float32), 'training/total_loss': Array(0.12069133, dtype=float32), 'training/v_loss': Array(0.11020543, dtype=float32), 'eval/episode_distance_from_origin': Array(4696.263, dtype=float32), 'eval/episode_distance_reward': Array(12.262236, dtype=float32), 'eval/episode_forward_reward': Array(2043.6976, dtype=float32), 'eval/episode_reward': Array(1837.779, dtype=float32), 'eval/episode_reward_alive': Array(190.0664, dtype=float32), 'eval/episode_reward_linvel': Array(2043.6976, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.24725, dtype=float32), 'eval/episode_x_position': Array(4619.368, dtype=float32), 'eval/episode_x_velocity': Array(408.73956, dtype=float32), 'eval/episode_y_position': Array(-559.8529, dtype=float32), 'eval/episode_y_velocity': Array(-165.83305, dtype=float32), 'eval/episode_distance_from_origin_std': Array(439.70758, dtype=float32), 'eval/episode_distance_reward_std': Array(4.1905704, dtype=float32), 'eval/episode_forward_reward_std': Array(698.4234, dtype=float32), 'eval/episode_reward_std': Array(746.38367, dtype=float32), 'eval/episode_reward_alive_std': Array(48.837517, dtype=float32), 'eval/episode_reward_linvel_std': Array(698.4234, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.72609, dtype=float32), 'eval/episode_x_position_std': Array(427.34317, dtype=float32), 'eval/episode_x_velocity_std': Array(139.6847, dtype=float32), 'eval/episode_y_position_std': Array(296.5597, dtype=float32), 'eval/episode_y_velocity_std': Array(70.03437, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27005910873413, 'eval/sps': 939.3112532362286, 'num_steps': 16629760}
{'eval/walltime': 28025.0360789299, 'training/sps': 2944.763871119731, 'training/walltime': 5707.261168479919, 'training/entropy_loss': Array(0.01068469, dtype=float32), 'training/policy_loss': Array(0.00071058, dtype=float32), 'training/total_loss': Array(0.08750285, dtype=float32), 'training/v_loss': Array(0.07610758, dtype=float32), 'eval/episode_distance_from_origin': Array(4799.576, dtype=float32), 'eval/episode_distance_reward': Array(13.190184, dtype=float32), 'eval/episode_forward_reward': Array(2198.355, dtype=float32), 'eval/episode_reward': Array(2007.4993, dtype=float32), 'eval/episode_reward_alive': Array(199.54688, dtype=float32), 'eval/episode_reward_linvel': Array(2198.355, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.59274, dtype=float32), 'eval/episode_x_position': Array(4716.631, dtype=float32), 'eval/episode_x_velocity': Array(439.671, dtype=float32), 'eval/episode_y_position': Array(-632.3966, dtype=float32), 'eval/episode_y_velocity': Array(-181.60597, dtype=float32), 'eval/episode_distance_from_origin_std': Array(449.17215, dtype=float32), 'eval/episode_distance_reward_std': Array(4.446782, dtype=float32), 'eval/episode_forward_reward_std': Array(741.12555, dtype=float32), 'eval/episode_reward_std': Array(795.14514, dtype=float32), 'eval/episode_reward_alive_std': Array(53.969006, dtype=float32), 'eval/episode_reward_linvel_std': Array(741.12555, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.945797, dtype=float32), 'eval/episode_x_position_std': Array(438.1386, dtype=float32), 'eval/episode_x_velocity_std': Array(148.22508, dtype=float32), 'eval/episode_y_position_std': Array(244.5975, dtype=float32), 'eval/episode_y_velocity_std': Array(59.159256, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1088547706604, 'eval/sps': 940.423752853379, 'num_steps': 16711680}
{'eval/walltime': 28161.814912080765, 'training/sps': 2947.3593888921155, 'training/walltime': 5735.055539369583, 'training/entropy_loss': Array(0.01103926, dtype=float32), 'training/policy_loss': Array(0.00098919, dtype=float32), 'training/total_loss': Array(0.07727722, dtype=float32), 'training/v_loss': Array(0.06524877, dtype=float32), 'eval/episode_distance_from_origin': Array(4795.3027, dtype=float32), 'eval/episode_distance_reward': Array(13.163776, dtype=float32), 'eval/episode_forward_reward': Array(2193.954, dtype=float32), 'eval/episode_reward': Array(2021.4031, dtype=float32), 'eval/episode_reward_alive': Array(202.97266, dtype=float32), 'eval/episode_reward_linvel': Array(2193.954, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.6874, dtype=float32), 'eval/episode_x_position': Array(4716.8438, dtype=float32), 'eval/episode_x_velocity': Array(438.79077, dtype=float32), 'eval/episode_y_position': Array(-571.723, dtype=float32), 'eval/episode_y_velocity': Array(-166.4732, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.6208, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8031178, dtype=float32), 'eval/episode_forward_reward_std': Array(800.51465, dtype=float32), 'eval/episode_reward_std': Array(851.6165, dtype=float32), 'eval/episode_reward_alive_std': Array(59.528202, dtype=float32), 'eval/episode_reward_linvel_std': Array(800.51465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.528292, dtype=float32), 'eval/episode_x_position_std': Array(476.10532, dtype=float32), 'eval/episode_x_velocity_std': Array(160.1029, dtype=float32), 'eval/episode_y_position_std': Array(313.15887, dtype=float32), 'eval/episode_y_velocity_std': Array(80.12252, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.77883315086365, 'eval/sps': 935.8173121627613, 'num_steps': 16793600}
{'eval/walltime': 28298.237644910812, 'training/sps': 2943.2866378266353, 'training/walltime': 5762.888370513916, 'training/entropy_loss': Array(0.00971444, dtype=float32), 'training/policy_loss': Array(0.00037336, dtype=float32), 'training/total_loss': Array(0.06074939, dtype=float32), 'training/v_loss': Array(0.05066158, dtype=float32), 'eval/episode_distance_from_origin': Array(4691.7324, dtype=float32), 'eval/episode_distance_reward': Array(11.960778, dtype=float32), 'eval/episode_forward_reward': Array(1993.4556, dtype=float32), 'eval/episode_reward': Array(1816.5354, dtype=float32), 'eval/episode_reward_alive': Array(191.92969, dtype=float32), 'eval/episode_reward_linvel': Array(1993.4556, dtype=float32), 'eval/episode_reward_quadctrl': Array(-380.8104, dtype=float32), 'eval/episode_x_position': Array(4614.5, dtype=float32), 'eval/episode_x_velocity': Array(398.6911, dtype=float32), 'eval/episode_y_position': Array(-567.10297, dtype=float32), 'eval/episode_y_velocity': Array(-155.98807, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.5558, dtype=float32), 'eval/episode_distance_reward_std': Array(4.017049, dtype=float32), 'eval/episode_forward_reward_std': Array(669.5035, dtype=float32), 'eval/episode_reward_std': Array(708.5259, dtype=float32), 'eval/episode_reward_alive_std': Array(62.56115, dtype=float32), 'eval/episode_reward_linvel_std': Array(669.5035, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.572487, dtype=float32), 'eval/episode_x_position_std': Array(437.98776, dtype=float32), 'eval/episode_x_velocity_std': Array(133.90068, dtype=float32), 'eval/episode_y_position_std': Array(299.17993, dtype=float32), 'eval/episode_y_velocity_std': Array(70.846405, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4227328300476, 'eval/sps': 938.2600490745156, 'num_steps': 16875520}
{'eval/walltime': 28434.559380292892, 'training/sps': 2946.403472398948, 'training/walltime': 5790.6917588710785, 'training/entropy_loss': Array(0.00546215, dtype=float32), 'training/policy_loss': Array(-0.00148145, dtype=float32), 'training/total_loss': Array(0.07155439, dtype=float32), 'training/v_loss': Array(0.06757369, dtype=float32), 'eval/episode_distance_from_origin': Array(4658.2705, dtype=float32), 'eval/episode_distance_reward': Array(12.252531, dtype=float32), 'eval/episode_forward_reward': Array(2042.0807, dtype=float32), 'eval/episode_reward': Array(1874.2601, dtype=float32), 'eval/episode_reward_alive': Array(193.79297, dtype=float32), 'eval/episode_reward_linvel': Array(2042.0807, dtype=float32), 'eval/episode_reward_quadctrl': Array(-373.8657, dtype=float32), 'eval/episode_x_position': Array(4584.541, dtype=float32), 'eval/episode_x_velocity': Array(408.4161, dtype=float32), 'eval/episode_y_position': Array(-519.5372, dtype=float32), 'eval/episode_y_velocity': Array(-149.84186, dtype=float32), 'eval/episode_distance_from_origin_std': Array(433.86005, dtype=float32), 'eval/episode_distance_reward_std': Array(3.8720553, dtype=float32), 'eval/episode_forward_reward_std': Array(645.33777, dtype=float32), 'eval/episode_reward_std': Array(681.06506, dtype=float32), 'eval/episode_reward_alive_std': Array(48.831165, dtype=float32), 'eval/episode_reward_linvel_std': Array(645.33777, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.297657, dtype=float32), 'eval/episode_x_position_std': Array(419.36368, dtype=float32), 'eval/episode_x_velocity_std': Array(129.06761, dtype=float32), 'eval/episode_y_position_std': Array(330.28195, dtype=float32), 'eval/episode_y_velocity_std': Array(72.356575, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32173538208008, 'eval/sps': 938.9551830545872, 'num_steps': 16957440}
{'eval/walltime': 28571.014963150024, 'training/sps': 2938.832673088812, 'training/walltime': 5818.566772222519, 'training/entropy_loss': Array(0.01012678, dtype=float32), 'training/policy_loss': Array(-0.00048784, dtype=float32), 'training/total_loss': Array(0.15642548, dtype=float32), 'training/v_loss': Array(0.14678654, dtype=float32), 'eval/episode_distance_from_origin': Array(4780.335, dtype=float32), 'eval/episode_distance_reward': Array(12.999549, dtype=float32), 'eval/episode_forward_reward': Array(2166.5825, dtype=float32), 'eval/episode_reward': Array(1983.0132, dtype=float32), 'eval/episode_reward_alive': Array(192.21875, dtype=float32), 'eval/episode_reward_linvel': Array(2166.5825, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.78766, dtype=float32), 'eval/episode_x_position': Array(4702.5176, dtype=float32), 'eval/episode_x_velocity': Array(433.3165, dtype=float32), 'eval/episode_y_position': Array(-549.9772, dtype=float32), 'eval/episode_y_velocity': Array(-159.45126, dtype=float32), 'eval/episode_distance_from_origin_std': Array(467.89868, dtype=float32), 'eval/episode_distance_reward_std': Array(4.437927, dtype=float32), 'eval/episode_forward_reward_std': Array(739.64935, dtype=float32), 'eval/episode_reward_std': Array(776.74927, dtype=float32), 'eval/episode_reward_alive_std': Array(53.339485, dtype=float32), 'eval/episode_reward_linvel_std': Array(739.64935, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.151154, dtype=float32), 'eval/episode_x_position_std': Array(454.0439, dtype=float32), 'eval/episode_x_velocity_std': Array(147.92986, dtype=float32), 'eval/episode_y_position_std': Array(346.57742, dtype=float32), 'eval/episode_y_velocity_std': Array(77.135086, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45558285713196, 'eval/sps': 938.0341743438604, 'num_steps': 17039360}
{'eval/walltime': 28707.40732550621, 'training/sps': 2946.931143914924, 'training/walltime': 5846.365182161331, 'training/entropy_loss': Array(0.00961933, dtype=float32), 'training/policy_loss': Array(0.00128689, dtype=float32), 'training/total_loss': Array(0.12850565, dtype=float32), 'training/v_loss': Array(0.11759943, dtype=float32), 'eval/episode_distance_from_origin': Array(4903.3823, dtype=float32), 'eval/episode_distance_reward': Array(13.927561, dtype=float32), 'eval/episode_forward_reward': Array(2321.25, dtype=float32), 'eval/episode_reward': Array(2147.9175, dtype=float32), 'eval/episode_reward_alive': Array(206.02734, dtype=float32), 'eval/episode_reward_linvel': Array(2321.25, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.28772, dtype=float32), 'eval/episode_x_position': Array(4824.5854, dtype=float32), 'eval/episode_x_velocity': Array(464.25, dtype=float32), 'eval/episode_y_position': Array(-598.3593, dtype=float32), 'eval/episode_y_velocity': Array(-172.10791, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.65887, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2154093, dtype=float32), 'eval/episode_forward_reward_std': Array(702.56396, dtype=float32), 'eval/episode_reward_std': Array(743.3089, dtype=float32), 'eval/episode_reward_alive_std': Array(48.399353, dtype=float32), 'eval/episode_reward_linvel_std': Array(702.56396, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.93454, dtype=float32), 'eval/episode_x_position_std': Array(430.13126, dtype=float32), 'eval/episode_x_velocity_std': Array(140.51279, dtype=float32), 'eval/episode_y_position_std': Array(280.16745, dtype=float32), 'eval/episode_y_velocity_std': Array(63.81176, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3923623561859, 'eval/sps': 938.4689713470215, 'num_steps': 17121280}
{'eval/walltime': 28843.815108299255, 'training/sps': 2939.94371145701, 'training/walltime': 5874.229661226273, 'training/entropy_loss': Array(0.00964869, dtype=float32), 'training/policy_loss': Array(0.00206381, dtype=float32), 'training/total_loss': Array(0.10025938, dtype=float32), 'training/v_loss': Array(0.08854689, dtype=float32), 'eval/episode_distance_from_origin': Array(4913.052, dtype=float32), 'eval/episode_distance_reward': Array(13.889991, dtype=float32), 'eval/episode_forward_reward': Array(2314.989, dtype=float32), 'eval/episode_reward': Array(2153.3743, dtype=float32), 'eval/episode_reward_alive': Array(208.95312, dtype=float32), 'eval/episode_reward_linvel': Array(2314.989, dtype=float32), 'eval/episode_reward_quadctrl': Array(-384.4576, dtype=float32), 'eval/episode_x_position': Array(4835.766, dtype=float32), 'eval/episode_x_velocity': Array(462.9978, dtype=float32), 'eval/episode_y_position': Array(-568.5817, dtype=float32), 'eval/episode_y_velocity': Array(-159.33444, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.70297, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4860797, dtype=float32), 'eval/episode_forward_reward_std': Array(747.67554, dtype=float32), 'eval/episode_reward_std': Array(780.1044, dtype=float32), 'eval/episode_reward_alive_std': Array(56.373867, dtype=float32), 'eval/episode_reward_linvel_std': Array(747.67554, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.303432, dtype=float32), 'eval/episode_x_position_std': Array(466.1855, dtype=float32), 'eval/episode_x_velocity_std': Array(149.5351, dtype=float32), 'eval/episode_y_position_std': Array(335.32132, dtype=float32), 'eval/episode_y_velocity_std': Array(81.40622, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40778279304504, 'eval/sps': 938.3628806150955, 'num_steps': 17203200}
{'eval/walltime': 28980.32465362549, 'training/sps': 2944.7066834269403, 'training/walltime': 5902.049070358276, 'training/entropy_loss': Array(0.00891239, dtype=float32), 'training/policy_loss': Array(0.00096908, dtype=float32), 'training/total_loss': Array(0.07088469, dtype=float32), 'training/v_loss': Array(0.06100322, dtype=float32), 'eval/episode_distance_from_origin': Array(4853.835, dtype=float32), 'eval/episode_distance_reward': Array(13.475283, dtype=float32), 'eval/episode_forward_reward': Array(2245.871, dtype=float32), 'eval/episode_reward': Array(2082.3113, dtype=float32), 'eval/episode_reward_alive': Array(202.10938, dtype=float32), 'eval/episode_reward_linvel': Array(2245.871, dtype=float32), 'eval/episode_reward_quadctrl': Array(-379.14438, dtype=float32), 'eval/episode_x_position': Array(4778.2227, dtype=float32), 'eval/episode_x_velocity': Array(449.17426, dtype=float32), 'eval/episode_y_position': Array(-555.083, dtype=float32), 'eval/episode_y_velocity': Array(-155.88617, dtype=float32), 'eval/episode_distance_from_origin_std': Array(456.66022, dtype=float32), 'eval/episode_distance_reward_std': Array(4.144823, dtype=float32), 'eval/episode_forward_reward_std': Array(690.8, dtype=float32), 'eval/episode_reward_std': Array(727.16785, dtype=float32), 'eval/episode_reward_alive_std': Array(51.79979, dtype=float32), 'eval/episode_reward_linvel_std': Array(690.8, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.59794, dtype=float32), 'eval/episode_x_position_std': Array(445.31793, dtype=float32), 'eval/episode_x_velocity_std': Array(138.15999, dtype=float32), 'eval/episode_y_position_std': Array(325.55814, dtype=float32), 'eval/episode_y_velocity_std': Array(76.6312, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5095453262329, 'eval/sps': 937.6633677454814, 'num_steps': 17285120}
{'eval/walltime': 29116.764308691025, 'training/sps': 2954.194137549685, 'training/walltime': 5929.779136896133, 'training/entropy_loss': Array(0.00805171, dtype=float32), 'training/policy_loss': Array(0.00320114, dtype=float32), 'training/total_loss': Array(0.06204198, dtype=float32), 'training/v_loss': Array(0.05078912, dtype=float32), 'eval/episode_distance_from_origin': Array(4772.695, dtype=float32), 'eval/episode_distance_reward': Array(12.855678, dtype=float32), 'eval/episode_forward_reward': Array(2142.6035, dtype=float32), 'eval/episode_reward': Array(1982.9783, dtype=float32), 'eval/episode_reward_alive': Array(196.6211, dtype=float32), 'eval/episode_reward_linvel': Array(2142.6035, dtype=float32), 'eval/episode_reward_quadctrl': Array(-369.10214, dtype=float32), 'eval/episode_x_position': Array(4702.107, dtype=float32), 'eval/episode_x_velocity': Array(428.52075, dtype=float32), 'eval/episode_y_position': Array(-501.92548, dtype=float32), 'eval/episode_y_velocity': Array(-148.75806, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.88055, dtype=float32), 'eval/episode_distance_reward_std': Array(3.9817538, dtype=float32), 'eval/episode_forward_reward_std': Array(663.6209, dtype=float32), 'eval/episode_reward_std': Array(696.95593, dtype=float32), 'eval/episode_reward_alive_std': Array(56.343143, dtype=float32), 'eval/episode_reward_linvel_std': Array(663.6209, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.97738, dtype=float32), 'eval/episode_x_position_std': Array(449.15103, dtype=float32), 'eval/episode_x_velocity_std': Array(132.72421, dtype=float32), 'eval/episode_y_position_std': Array(341.70892, dtype=float32), 'eval/episode_y_velocity_std': Array(81.555305, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4396550655365, 'eval/sps': 938.1436792589174, 'num_steps': 17367040}
{'eval/walltime': 29253.296863794327, 'training/sps': 2957.407615210452, 'training/walltime': 5957.479072332382, 'training/entropy_loss': Array(0.00622004, dtype=float32), 'training/policy_loss': Array(-0.00094088, dtype=float32), 'training/total_loss': Array(0.05899157, dtype=float32), 'training/v_loss': Array(0.05371241, dtype=float32), 'eval/episode_distance_from_origin': Array(4733.362, dtype=float32), 'eval/episode_distance_reward': Array(12.112016, dtype=float32), 'eval/episode_forward_reward': Array(2018.6603, dtype=float32), 'eval/episode_reward': Array(1857.6912, dtype=float32), 'eval/episode_reward_alive': Array(191.4414, dtype=float32), 'eval/episode_reward_linvel': Array(2018.6603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-364.52246, dtype=float32), 'eval/episode_x_position': Array(4665.457, dtype=float32), 'eval/episode_x_velocity': Array(403.73206, dtype=float32), 'eval/episode_y_position': Array(-489.2566, dtype=float32), 'eval/episode_y_velocity': Array(-137.45386, dtype=float32), 'eval/episode_distance_from_origin_std': Array(371.61826, dtype=float32), 'eval/episode_distance_reward_std': Array(3.4355884, dtype=float32), 'eval/episode_forward_reward_std': Array(572.5938, dtype=float32), 'eval/episode_reward_std': Array(611.4329, dtype=float32), 'eval/episode_reward_alive_std': Array(57.62177, dtype=float32), 'eval/episode_reward_linvel_std': Array(572.5938, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.74793, dtype=float32), 'eval/episode_x_position_std': Array(358.1032, dtype=float32), 'eval/episode_x_velocity_std': Array(114.51879, dtype=float32), 'eval/episode_y_position_std': Array(317.05783, dtype=float32), 'eval/episode_y_velocity_std': Array(71.39663, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.532555103302, 'eval/sps': 937.5053437120093, 'num_steps': 17448960}
{'eval/walltime': 29389.75998520851, 'training/sps': 2946.716297316779, 'training/walltime': 5985.279509067535, 'training/entropy_loss': Array(0.0097671, dtype=float32), 'training/policy_loss': Array(0.00012451, dtype=float32), 'training/total_loss': Array(0.1511032, dtype=float32), 'training/v_loss': Array(0.14121158, dtype=float32), 'eval/episode_distance_from_origin': Array(4818.774, dtype=float32), 'eval/episode_distance_reward': Array(12.643459, dtype=float32), 'eval/episode_forward_reward': Array(2107.234, dtype=float32), 'eval/episode_reward': Array(1942.4548, dtype=float32), 'eval/episode_reward_alive': Array(191.39062, dtype=float32), 'eval/episode_reward_linvel': Array(2107.234, dtype=float32), 'eval/episode_reward_quadctrl': Array(-368.81342, dtype=float32), 'eval/episode_x_position': Array(4738.2095, dtype=float32), 'eval/episode_x_velocity': Array(421.44678, dtype=float32), 'eval/episode_y_position': Array(-611.0439, dtype=float32), 'eval/episode_y_velocity': Array(-165.66232, dtype=float32), 'eval/episode_distance_from_origin_std': Array(407.79272, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3237367, dtype=float32), 'eval/episode_forward_reward_std': Array(553.95276, dtype=float32), 'eval/episode_reward_std': Array(581.22266, dtype=float32), 'eval/episode_reward_alive_std': Array(50.79562, dtype=float32), 'eval/episode_reward_linvel_std': Array(553.95276, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.471268, dtype=float32), 'eval/episode_x_position_std': Array(393.79996, dtype=float32), 'eval/episode_x_velocity_std': Array(110.79063, dtype=float32), 'eval/episode_y_position_std': Array(289.03354, dtype=float32), 'eval/episode_y_velocity_std': Array(64.70767, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46312141418457, 'eval/sps': 937.9823550386348, 'num_steps': 17530880}
{'eval/walltime': 29526.110661506653, 'training/sps': 2949.2029120184357, 'training/walltime': 6013.056505918503, 'training/entropy_loss': Array(0.0095332, dtype=float32), 'training/policy_loss': Array(0.00468779, dtype=float32), 'training/total_loss': Array(0.1335916, dtype=float32), 'training/v_loss': Array(0.11937061, dtype=float32), 'eval/episode_distance_from_origin': Array(4754.8403, dtype=float32), 'eval/episode_distance_reward': Array(12.210911, dtype=float32), 'eval/episode_forward_reward': Array(2035.1431, dtype=float32), 'eval/episode_reward': Array(1873.3246, dtype=float32), 'eval/episode_reward_alive': Array(194.2461, dtype=float32), 'eval/episode_reward_linvel': Array(2035.1431, dtype=float32), 'eval/episode_reward_quadctrl': Array(-368.27542, dtype=float32), 'eval/episode_x_position': Array(4681.9023, dtype=float32), 'eval/episode_x_velocity': Array(407.02856, dtype=float32), 'eval/episode_y_position': Array(-540.556, dtype=float32), 'eval/episode_y_velocity': Array(-151.56949, dtype=float32), 'eval/episode_distance_from_origin_std': Array(432.82562, dtype=float32), 'eval/episode_distance_reward_std': Array(3.6828213, dtype=float32), 'eval/episode_forward_reward_std': Array(613.7995, dtype=float32), 'eval/episode_reward_std': Array(640.03796, dtype=float32), 'eval/episode_reward_alive_std': Array(53.09959, dtype=float32), 'eval/episode_reward_linvel_std': Array(613.7995, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.925667, dtype=float32), 'eval/episode_x_position_std': Array(421.53198, dtype=float32), 'eval/episode_x_velocity_std': Array(122.75986, dtype=float32), 'eval/episode_y_position_std': Array(300.5763, dtype=float32), 'eval/episode_y_velocity_std': Array(71.30129, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35067629814148, 'eval/sps': 938.755886476998, 'num_steps': 17612800}
{'eval/walltime': 29662.310267925262, 'training/sps': 2944.560897668051, 'training/walltime': 6040.877292394638, 'training/entropy_loss': Array(0.0077351, dtype=float32), 'training/policy_loss': Array(0.00412268, dtype=float32), 'training/total_loss': Array(0.07400959, dtype=float32), 'training/v_loss': Array(0.06215181, dtype=float32), 'eval/episode_distance_from_origin': Array(4782.7544, dtype=float32), 'eval/episode_distance_reward': Array(12.173317, dtype=float32), 'eval/episode_forward_reward': Array(2028.877, dtype=float32), 'eval/episode_reward': Array(1864.9172, dtype=float32), 'eval/episode_reward_alive': Array(189.66797, dtype=float32), 'eval/episode_reward_linvel': Array(2028.877, dtype=float32), 'eval/episode_reward_quadctrl': Array(-365.80133, dtype=float32), 'eval/episode_x_position': Array(4710.0234, dtype=float32), 'eval/episode_x_velocity': Array(405.7754, dtype=float32), 'eval/episode_y_position': Array(-547.673, dtype=float32), 'eval/episode_y_velocity': Array(-144.71133, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.2184, dtype=float32), 'eval/episode_distance_reward_std': Array(3.8164592, dtype=float32), 'eval/episode_forward_reward_std': Array(636.07166, dtype=float32), 'eval/episode_reward_std': Array(664.39465, dtype=float32), 'eval/episode_reward_alive_std': Array(67.1518, dtype=float32), 'eval/episode_reward_linvel_std': Array(636.07166, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.943226, dtype=float32), 'eval/episode_x_position_std': Array(432.4684, dtype=float32), 'eval/episode_x_velocity_std': Array(127.21439, dtype=float32), 'eval/episode_y_position_std': Array(308.96933, dtype=float32), 'eval/episode_y_velocity_std': Array(75.468315, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.19960641860962, 'eval/sps': 939.7971357317427, 'num_steps': 17694720}
{'eval/walltime': 29798.617193698883, 'training/sps': 2952.441685545982, 'training/walltime': 6068.623818397522, 'training/entropy_loss': Array(0.00532452, dtype=float32), 'training/policy_loss': Array(0.00496019, dtype=float32), 'training/total_loss': Array(0.04699335, dtype=float32), 'training/v_loss': Array(0.03670864, dtype=float32), 'eval/episode_distance_from_origin': Array(4598.593, dtype=float32), 'eval/episode_distance_reward': Array(10.629658, dtype=float32), 'eval/episode_forward_reward': Array(1771.603, dtype=float32), 'eval/episode_reward': Array(1619.5674, dtype=float32), 'eval/episode_reward_alive': Array(174.03906, dtype=float32), 'eval/episode_reward_linvel': Array(1771.603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-336.70435, dtype=float32), 'eval/episode_x_position': Array(4537.7617, dtype=float32), 'eval/episode_x_velocity': Array(354.3206, dtype=float32), 'eval/episode_y_position': Array(-452.2698, dtype=float32), 'eval/episode_y_velocity': Array(-114.61257, dtype=float32), 'eval/episode_distance_from_origin_std': Array(393.53925, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3082492, dtype=float32), 'eval/episode_forward_reward_std': Array(551.371, dtype=float32), 'eval/episode_reward_std': Array(573.1004, dtype=float32), 'eval/episode_reward_alive_std': Array(71.68318, dtype=float32), 'eval/episode_reward_linvel_std': Array(551.371, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.78517, dtype=float32), 'eval/episode_x_position_std': Array(383.75525, dtype=float32), 'eval/episode_x_velocity_std': Array(110.274216, dtype=float32), 'eval/episode_y_position_std': Array(276.50287, dtype=float32), 'eval/episode_y_velocity_std': Array(66.86406, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3069257736206, 'eval/sps': 939.0571995775416, 'num_steps': 17776640}
{'eval/walltime': 29934.789850711823, 'training/sps': 2949.415057954945, 'training/walltime': 6096.3988173007965, 'training/entropy_loss': Array(0.00410627, dtype=float32), 'training/policy_loss': Array(-0.00352637, dtype=float32), 'training/total_loss': Array(0.02726325, dtype=float32), 'training/v_loss': Array(0.02668335, dtype=float32), 'eval/episode_distance_from_origin': Array(4563.0024, dtype=float32), 'eval/episode_distance_reward': Array(10.099539, dtype=float32), 'eval/episode_forward_reward': Array(1683.25, dtype=float32), 'eval/episode_reward': Array(1522.7084, dtype=float32), 'eval/episode_reward_alive': Array(162.98828, dtype=float32), 'eval/episode_reward_linvel': Array(1683.25, dtype=float32), 'eval/episode_reward_quadctrl': Array(-333.62952, dtype=float32), 'eval/episode_x_position': Array(4504.3525, dtype=float32), 'eval/episode_x_velocity': Array(336.65002, dtype=float32), 'eval/episode_y_position': Array(-417.67163, dtype=float32), 'eval/episode_y_velocity': Array(-103.6374, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.825, dtype=float32), 'eval/episode_distance_reward_std': Array(3.6214201, dtype=float32), 'eval/episode_forward_reward_std': Array(603.56586, dtype=float32), 'eval/episode_reward_std': Array(623.3744, dtype=float32), 'eval/episode_reward_alive_std': Array(68.8313, dtype=float32), 'eval/episode_reward_linvel_std': Array(603.56586, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.433815, dtype=float32), 'eval/episode_x_position_std': Array(437.2001, dtype=float32), 'eval/episode_x_velocity_std': Array(120.71316, dtype=float32), 'eval/episode_y_position_std': Array(307.32166, dtype=float32), 'eval/episode_y_velocity_std': Array(71.0806, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.17265701293945, 'eval/sps': 939.9831273604152, 'num_steps': 17858560}
{'eval/walltime': 30071.368575811386, 'training/sps': 2951.811006369895, 'training/walltime': 6124.15127158165, 'training/entropy_loss': Array(0.00294457, dtype=float32), 'training/policy_loss': Array(0.00119147, dtype=float32), 'training/total_loss': Array(0.02965052, dtype=float32), 'training/v_loss': Array(0.02551448, dtype=float32), 'eval/episode_distance_from_origin': Array(4398.3037, dtype=float32), 'eval/episode_distance_reward': Array(8.659307, dtype=float32), 'eval/episode_forward_reward': Array(1443.213, dtype=float32), 'eval/episode_reward': Array(1326.475, dtype=float32), 'eval/episode_reward_alive': Array(191.9961, dtype=float32), 'eval/episode_reward_linvel': Array(1443.213, dtype=float32), 'eval/episode_reward_quadctrl': Array(-317.3933, dtype=float32), 'eval/episode_x_position': Array(4349.4126, dtype=float32), 'eval/episode_x_velocity': Array(288.6426, dtype=float32), 'eval/episode_y_position': Array(-336.32275, dtype=float32), 'eval/episode_y_velocity': Array(-79.25023, dtype=float32), 'eval/episode_distance_from_origin_std': Array(370.44177, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8553376, dtype=float32), 'eval/episode_forward_reward_std': Array(475.8855, dtype=float32), 'eval/episode_reward_std': Array(485.14633, dtype=float32), 'eval/episode_reward_alive_std': Array(111.73716, dtype=float32), 'eval/episode_reward_linvel_std': Array(475.8855, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.482666, dtype=float32), 'eval/episode_x_position_std': Array(364.9453, dtype=float32), 'eval/episode_x_velocity_std': Array(95.17707, dtype=float32), 'eval/episode_y_position_std': Array(249.29372, dtype=float32), 'eval/episode_y_velocity_std': Array(54.80815, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5787250995636, 'eval/sps': 937.1884230628903, 'num_steps': 17940480}
{'eval/walltime': 30207.663559675217, 'training/sps': 2935.598841861555, 'training/walltime': 6152.056991815567, 'training/entropy_loss': Array(0.00951806, dtype=float32), 'training/policy_loss': Array(0.0008648, dtype=float32), 'training/total_loss': Array(0.14580914, dtype=float32), 'training/v_loss': Array(0.13542628, dtype=float32), 'eval/episode_distance_from_origin': Array(4532.788, dtype=float32), 'eval/episode_distance_reward': Array(9.682692, dtype=float32), 'eval/episode_forward_reward': Array(1613.7761, dtype=float32), 'eval/episode_reward': Array(1481.8167, dtype=float32), 'eval/episode_reward_alive': Array(191.91016, dtype=float32), 'eval/episode_reward_linvel': Array(1613.7761, dtype=float32), 'eval/episode_reward_quadctrl': Array(-333.55237, dtype=float32), 'eval/episode_x_position': Array(4474.3086, dtype=float32), 'eval/episode_x_velocity': Array(322.7552, dtype=float32), 'eval/episode_y_position': Array(-395.78033, dtype=float32), 'eval/episode_y_velocity': Array(-97.39154, dtype=float32), 'eval/episode_distance_from_origin_std': Array(419.46, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2617826, dtype=float32), 'eval/episode_forward_reward_std': Array(543.62616, dtype=float32), 'eval/episode_reward_std': Array(562.4986, dtype=float32), 'eval/episode_reward_alive_std': Array(101.21644, dtype=float32), 'eval/episode_reward_linvel_std': Array(543.62616, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.723373, dtype=float32), 'eval/episode_x_position_std': Array(406.8523, dtype=float32), 'eval/episode_x_velocity_std': Array(108.72523, dtype=float32), 'eval/episode_y_position_std': Array(325.06052, dtype=float32), 'eval/episode_y_velocity_std': Array(76.77511, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29498386383057, 'eval/sps': 939.1394780007612, 'num_steps': 18022400}
{'eval/walltime': 30343.877222537994, 'training/sps': 2949.2405289882554, 'training/walltime': 6179.833634376526, 'training/entropy_loss': Array(0.00752571, dtype=float32), 'training/policy_loss': Array(0.00647935, dtype=float32), 'training/total_loss': Array(0.11830198, dtype=float32), 'training/v_loss': Array(0.10429692, dtype=float32), 'eval/episode_distance_from_origin': Array(4498.9375, dtype=float32), 'eval/episode_distance_reward': Array(9.573675, dtype=float32), 'eval/episode_forward_reward': Array(1595.6067, dtype=float32), 'eval/episode_reward': Array(1465.9517, dtype=float32), 'eval/episode_reward_alive': Array(192.72656, dtype=float32), 'eval/episode_reward_linvel': Array(1595.6067, dtype=float32), 'eval/episode_reward_quadctrl': Array(-331.9552, dtype=float32), 'eval/episode_x_position': Array(4437.2266, dtype=float32), 'eval/episode_x_velocity': Array(319.12134, dtype=float32), 'eval/episode_y_position': Array(-428.95038, dtype=float32), 'eval/episode_y_velocity': Array(-104.51836, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.2519, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2151718, dtype=float32), 'eval/episode_forward_reward_std': Array(535.85736, dtype=float32), 'eval/episode_reward_std': Array(540.5888, dtype=float32), 'eval/episode_reward_alive_std': Array(96.4584, dtype=float32), 'eval/episode_reward_linvel_std': Array(535.85736, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.529892, dtype=float32), 'eval/episode_x_position_std': Array(363.19507, dtype=float32), 'eval/episode_x_velocity_std': Array(107.17148, dtype=float32), 'eval/episode_y_position_std': Array(315.70816, dtype=float32), 'eval/episode_y_velocity_std': Array(72.904305, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2136628627777, 'eval/sps': 939.7001542271704, 'num_steps': 18104320}
{'eval/walltime': 30480.065093040466, 'training/sps': 2942.632973445267, 'training/walltime': 6207.672648191452, 'training/entropy_loss': Array(0.00440768, dtype=float32), 'training/policy_loss': Array(0.04548938, dtype=float32), 'training/total_loss': Array(0.09111129, dtype=float32), 'training/v_loss': Array(0.04121423, dtype=float32), 'eval/episode_distance_from_origin': Array(4589.2227, dtype=float32), 'eval/episode_distance_reward': Array(10.1525755, dtype=float32), 'eval/episode_forward_reward': Array(1692.0897, dtype=float32), 'eval/episode_reward': Array(1587.5535, dtype=float32), 'eval/episode_reward_alive': Array(222.96094, dtype=float32), 'eval/episode_reward_linvel': Array(1692.0897, dtype=float32), 'eval/episode_reward_quadctrl': Array(-337.64954, dtype=float32), 'eval/episode_x_position': Array(4534.0205, dtype=float32), 'eval/episode_x_velocity': Array(338.4179, dtype=float32), 'eval/episode_y_position': Array(-397.91565, dtype=float32), 'eval/episode_y_velocity': Array(-97.971054, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.3403, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2554061, dtype=float32), 'eval/episode_forward_reward_std': Array(542.5635, dtype=float32), 'eval/episode_reward_std': Array(542.0226, dtype=float32), 'eval/episode_reward_alive_std': Array(111.99436, dtype=float32), 'eval/episode_reward_linvel_std': Array(542.5635, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.109016, dtype=float32), 'eval/episode_x_position_std': Array(402.67853, dtype=float32), 'eval/episode_x_velocity_std': Array(108.51267, dtype=float32), 'eval/episode_y_position_std': Array(270.50455, dtype=float32), 'eval/episode_y_velocity_std': Array(64.9377, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.18787050247192, 'eval/sps': 939.8781222420002, 'num_steps': 18186240}
{'eval/walltime': 30616.419553756714, 'training/sps': 2945.1275671662197, 'training/walltime': 6235.488081693649, 'training/entropy_loss': Array(0.00223122, dtype=float32), 'training/policy_loss': Array(-0.00274541, dtype=float32), 'training/total_loss': Array(0.01620624, dtype=float32), 'training/v_loss': Array(0.01672043, dtype=float32), 'eval/episode_distance_from_origin': Array(4425.463, dtype=float32), 'eval/episode_distance_reward': Array(8.770021, dtype=float32), 'eval/episode_forward_reward': Array(1461.666, dtype=float32), 'eval/episode_reward': Array(1363.0569, dtype=float32), 'eval/episode_reward_alive': Array(212.71094, dtype=float32), 'eval/episode_reward_linvel': Array(1461.666, dtype=float32), 'eval/episode_reward_quadctrl': Array(-320.09, dtype=float32), 'eval/episode_x_position': Array(4372.55, dtype=float32), 'eval/episode_x_velocity': Array(292.3332, dtype=float32), 'eval/episode_y_position': Array(-375.29633, dtype=float32), 'eval/episode_y_velocity': Array(-88.141235, dtype=float32), 'eval/episode_distance_from_origin_std': Array(336.27997, dtype=float32), 'eval/episode_distance_reward_std': Array(2.556628, dtype=float32), 'eval/episode_forward_reward_std': Array(426.101, dtype=float32), 'eval/episode_reward_std': Array(423.7772, dtype=float32), 'eval/episode_reward_alive_std': Array(117.535545, dtype=float32), 'eval/episode_reward_linvel_std': Array(426.101, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.441998, dtype=float32), 'eval/episode_x_position_std': Array(325.90463, dtype=float32), 'eval/episode_x_velocity_std': Array(85.22022, dtype=float32), 'eval/episode_y_position_std': Array(258.00537, dtype=float32), 'eval/episode_y_velocity_std': Array(59.947792, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35446071624756, 'eval/sps': 938.7298319954995, 'num_steps': 18268160}
{'eval/walltime': 30752.601952552795, 'training/sps': 2953.4824830422313, 'training/walltime': 6263.224829912186, 'training/entropy_loss': Array(0.00137677, dtype=float32), 'training/policy_loss': Array(0.00251819, dtype=float32), 'training/total_loss': Array(0.01225718, dtype=float32), 'training/v_loss': Array(0.00836222, dtype=float32), 'eval/episode_distance_from_origin': Array(4356.7476, dtype=float32), 'eval/episode_distance_reward': Array(8.361084, dtype=float32), 'eval/episode_forward_reward': Array(1393.5104, dtype=float32), 'eval/episode_reward': Array(1278.4089, dtype=float32), 'eval/episode_reward_alive': Array(203.23047, dtype=float32), 'eval/episode_reward_linvel': Array(1393.5104, dtype=float32), 'eval/episode_reward_quadctrl': Array(-326.69302, dtype=float32), 'eval/episode_x_position': Array(4305.904, dtype=float32), 'eval/episode_x_velocity': Array(278.70203, dtype=float32), 'eval/episode_y_position': Array(-348.81174, dtype=float32), 'eval/episode_y_velocity': Array(-83.63799, dtype=float32), 'eval/episode_distance_from_origin_std': Array(371.8994, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8257225, dtype=float32), 'eval/episode_forward_reward_std': Array(470.9506, dtype=float32), 'eval/episode_reward_std': Array(474.04764, dtype=float32), 'eval/episode_reward_alive_std': Array(109.85745, dtype=float32), 'eval/episode_reward_linvel_std': Array(470.9506, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.22097, dtype=float32), 'eval/episode_x_position_std': Array(363.50076, dtype=float32), 'eval/episode_x_velocity_std': Array(94.19006, dtype=float32), 'eval/episode_y_position_std': Array(246.36423, dtype=float32), 'eval/episode_y_velocity_std': Array(58.15478, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.18239879608154, 'eval/sps': 939.9158858382734, 'num_steps': 18350080}
{'eval/walltime': 30888.94847011566, 'training/sps': 2954.5609036333644, 'training/walltime': 6290.951454162598, 'training/entropy_loss': Array(0.0010027, dtype=float32), 'training/policy_loss': Array(-0.0073194, dtype=float32), 'training/total_loss': Array(-0.00164151, dtype=float32), 'training/v_loss': Array(0.00467519, dtype=float32), 'eval/episode_distance_from_origin': Array(4301.293, dtype=float32), 'eval/episode_distance_reward': Array(8.086313, dtype=float32), 'eval/episode_forward_reward': Array(1347.7153, dtype=float32), 'eval/episode_reward': Array(1269.7856, dtype=float32), 'eval/episode_reward_alive': Array(223.44922, dtype=float32), 'eval/episode_reward_linvel': Array(1347.7153, dtype=float32), 'eval/episode_reward_quadctrl': Array(-309.46558, dtype=float32), 'eval/episode_x_position': Array(4255.205, dtype=float32), 'eval/episode_x_velocity': Array(269.5431, dtype=float32), 'eval/episode_y_position': Array(-308.0711, dtype=float32), 'eval/episode_y_velocity': Array(-73.78378, dtype=float32), 'eval/episode_distance_from_origin_std': Array(353.16428, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0248418, dtype=float32), 'eval/episode_forward_reward_std': Array(504.13693, dtype=float32), 'eval/episode_reward_std': Array(513.00006, dtype=float32), 'eval/episode_reward_alive_std': Array(125.11554, dtype=float32), 'eval/episode_reward_linvel_std': Array(504.13693, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.19611, dtype=float32), 'eval/episode_x_position_std': Array(344.84143, dtype=float32), 'eval/episode_x_velocity_std': Array(100.82742, dtype=float32), 'eval/episode_y_position_std': Array(224.5692, dtype=float32), 'eval/episode_y_velocity_std': Array(52.083183, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3465175628662, 'eval/sps': 938.7845196778287, 'num_steps': 18432000}
{'eval/walltime': 31025.107934474945, 'training/sps': 2954.4308053107106, 'training/walltime': 6318.679299354553, 'training/entropy_loss': Array(0.00700107, dtype=float32), 'training/policy_loss': Array(-0.00118429, dtype=float32), 'training/total_loss': Array(0.08960149, dtype=float32), 'training/v_loss': Array(0.08378471, dtype=float32), 'eval/episode_distance_from_origin': Array(4488.323, dtype=float32), 'eval/episode_distance_reward': Array(9.292654, dtype=float32), 'eval/episode_forward_reward': Array(1548.771, dtype=float32), 'eval/episode_reward': Array(1445.7012, dtype=float32), 'eval/episode_reward_alive': Array(207.80469, dtype=float32), 'eval/episode_reward_linvel': Array(1548.771, dtype=float32), 'eval/episode_reward_quadctrl': Array(-320.16718, dtype=float32), 'eval/episode_x_position': Array(4434.401, dtype=float32), 'eval/episode_x_velocity': Array(309.7542, dtype=float32), 'eval/episode_y_position': Array(-377.70734, dtype=float32), 'eval/episode_y_velocity': Array(-92.70347, dtype=float32), 'eval/episode_distance_from_origin_std': Array(366.0336, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8463247, dtype=float32), 'eval/episode_forward_reward_std': Array(474.3838, dtype=float32), 'eval/episode_reward_std': Array(479.3945, dtype=float32), 'eval/episode_reward_alive_std': Array(98.35744, dtype=float32), 'eval/episode_reward_linvel_std': Array(474.3838, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.47189, dtype=float32), 'eval/episode_x_position_std': Array(356.93964, dtype=float32), 'eval/episode_x_velocity_std': Array(94.876724, dtype=float32), 'eval/episode_y_position_std': Array(268.33887, dtype=float32), 'eval/episode_y_velocity_std': Array(63.31337, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.15946435928345, 'eval/sps': 940.074203451968, 'num_steps': 18513920}
{'eval/walltime': 31161.31385755539, 'training/sps': 2963.719916364153, 'training/walltime': 6346.320237874985, 'training/entropy_loss': Array(0.00916542, dtype=float32), 'training/policy_loss': Array(0.01218785, dtype=float32), 'training/total_loss': Array(0.16891882, dtype=float32), 'training/v_loss': Array(0.14756554, dtype=float32), 'eval/episode_distance_from_origin': Array(4458.0425, dtype=float32), 'eval/episode_distance_reward': Array(9.144903, dtype=float32), 'eval/episode_forward_reward': Array(1524.1455, dtype=float32), 'eval/episode_reward': Array(1420.1133, dtype=float32), 'eval/episode_reward_alive': Array(208.35547, dtype=float32), 'eval/episode_reward_linvel': Array(1524.1455, dtype=float32), 'eval/episode_reward_quadctrl': Array(-321.5326, dtype=float32), 'eval/episode_x_position': Array(4406.8955, dtype=float32), 'eval/episode_x_velocity': Array(304.8291, dtype=float32), 'eval/episode_y_position': Array(-342.77747, dtype=float32), 'eval/episode_y_velocity': Array(-84.357834, dtype=float32), 'eval/episode_distance_from_origin_std': Array(358.16864, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8060207, dtype=float32), 'eval/episode_forward_reward_std': Array(467.66608, dtype=float32), 'eval/episode_reward_std': Array(470.15668, dtype=float32), 'eval/episode_reward_alive_std': Array(106.07852, dtype=float32), 'eval/episode_reward_linvel_std': Array(467.66608, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.59388, dtype=float32), 'eval/episode_x_position_std': Array(350.6999, dtype=float32), 'eval/episode_x_velocity_std': Array(93.53322, dtype=float32), 'eval/episode_y_position_std': Array(271.71475, dtype=float32), 'eval/episode_y_velocity_std': Array(62.6522, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20592308044434, 'eval/sps': 939.7535518657448, 'num_steps': 18595840}
{'eval/walltime': 31297.47884464264, 'training/sps': 2957.4115352804497, 'training/walltime': 6374.020136594772, 'training/entropy_loss': Array(0.0054625, dtype=float32), 'training/policy_loss': Array(0.00922901, dtype=float32), 'training/total_loss': Array(0.0634522, dtype=float32), 'training/v_loss': Array(0.0487607, dtype=float32), 'eval/episode_distance_from_origin': Array(4446.107, dtype=float32), 'eval/episode_distance_reward': Array(8.975609, dtype=float32), 'eval/episode_forward_reward': Array(1495.9303, dtype=float32), 'eval/episode_reward': Array(1419.9232, dtype=float32), 'eval/episode_reward_alive': Array(235.4336, dtype=float32), 'eval/episode_reward_linvel': Array(1495.9303, dtype=float32), 'eval/episode_reward_quadctrl': Array(-320.41632, dtype=float32), 'eval/episode_x_position': Array(4388.696, dtype=float32), 'eval/episode_x_velocity': Array(299.18604, dtype=float32), 'eval/episode_y_position': Array(-402.6582, dtype=float32), 'eval/episode_y_velocity': Array(-96.20879, dtype=float32), 'eval/episode_distance_from_origin_std': Array(386.91718, dtype=float32), 'eval/episode_distance_reward_std': Array(3.1573913, dtype=float32), 'eval/episode_forward_reward_std': Array(526.2282, dtype=float32), 'eval/episode_reward_std': Array(523.81274, dtype=float32), 'eval/episode_reward_alive_std': Array(116.33768, dtype=float32), 'eval/episode_reward_linvel_std': Array(526.2282, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.212284, dtype=float32), 'eval/episode_x_position_std': Array(380.89377, dtype=float32), 'eval/episode_x_velocity_std': Array(105.2456, dtype=float32), 'eval/episode_y_position_std': Array(273.45926, dtype=float32), 'eval/episode_y_velocity_std': Array(62.945404, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.16498708724976, 'eval/sps': 940.0360748977421, 'num_steps': 18677760}
{'eval/walltime': 31433.679752588272, 'training/sps': 2965.1384625355226, 'training/walltime': 6401.647851467133, 'training/entropy_loss': Array(0.00242508, dtype=float32), 'training/policy_loss': Array(0.02225054, dtype=float32), 'training/total_loss': Array(0.04236271, dtype=float32), 'training/v_loss': Array(0.01768708, dtype=float32), 'eval/episode_distance_from_origin': Array(4324.96, dtype=float32), 'eval/episode_distance_reward': Array(8.041838, dtype=float32), 'eval/episode_forward_reward': Array(1340.3025, dtype=float32), 'eval/episode_reward': Array(1269.949, dtype=float32), 'eval/episode_reward_alive': Array(237.08984, dtype=float32), 'eval/episode_reward_linvel': Array(1340.3025, dtype=float32), 'eval/episode_reward_quadctrl': Array(-315.48523, dtype=float32), 'eval/episode_x_position': Array(4276.132, dtype=float32), 'eval/episode_x_velocity': Array(268.06052, dtype=float32), 'eval/episode_y_position': Array(-312.24936, dtype=float32), 'eval/episode_y_velocity': Array(-75.217575, dtype=float32), 'eval/episode_distance_from_origin_std': Array(355.62186, dtype=float32), 'eval/episode_distance_reward_std': Array(2.677009, dtype=float32), 'eval/episode_forward_reward_std': Array(446.16452, dtype=float32), 'eval/episode_reward_std': Array(447.94226, dtype=float32), 'eval/episode_reward_alive_std': Array(122.41403, dtype=float32), 'eval/episode_reward_linvel_std': Array(446.16452, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.52136, dtype=float32), 'eval/episode_x_position_std': Array(348.90125, dtype=float32), 'eval/episode_x_velocity_std': Array(89.2329, dtype=float32), 'eval/episode_y_position_std': Array(259.03058, dtype=float32), 'eval/episode_y_velocity_std': Array(59.485397, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20090794563293, 'eval/sps': 939.7881550914002, 'num_steps': 18759680}
{'eval/walltime': 31569.826449632645, 'training/sps': 2956.974715066079, 'training/walltime': 6429.351842164993, 'training/entropy_loss': Array(0.0014326, dtype=float32), 'training/policy_loss': Array(-0.00594639, dtype=float32), 'training/total_loss': Array(0.00318776, dtype=float32), 'training/v_loss': Array(0.00770156, dtype=float32), 'eval/episode_distance_from_origin': Array(4308.3994, dtype=float32), 'eval/episode_distance_reward': Array(7.8989067, dtype=float32), 'eval/episode_forward_reward': Array(1316.481, dtype=float32), 'eval/episode_reward': Array(1273.3335, dtype=float32), 'eval/episode_reward_alive': Array(256.67188, dtype=float32), 'eval/episode_reward_linvel': Array(1316.481, dtype=float32), 'eval/episode_reward_quadctrl': Array(-307.71832, dtype=float32), 'eval/episode_x_position': Array(4258.902, dtype=float32), 'eval/episode_x_velocity': Array(263.2962, dtype=float32), 'eval/episode_y_position': Array(-333.0217, dtype=float32), 'eval/episode_y_velocity': Array(-76.87103, dtype=float32), 'eval/episode_distance_from_origin_std': Array(415.90292, dtype=float32), 'eval/episode_distance_reward_std': Array(3.1608624, dtype=float32), 'eval/episode_forward_reward_std': Array(526.807, dtype=float32), 'eval/episode_reward_std': Array(525.8173, dtype=float32), 'eval/episode_reward_alive_std': Array(129.0287, dtype=float32), 'eval/episode_reward_linvel_std': Array(526.807, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.51703, dtype=float32), 'eval/episode_x_position_std': Array(409.54544, dtype=float32), 'eval/episode_x_velocity_std': Array(105.36148, dtype=float32), 'eval/episode_y_position_std': Array(243.93639, dtype=float32), 'eval/episode_y_velocity_std': Array(55.412045, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.14669704437256, 'eval/sps': 940.1623600040961, 'num_steps': 18841600}
{'eval/walltime': 31706.104946374893, 'training/sps': 2964.1268192164944, 'training/walltime': 6456.988986253738, 'training/entropy_loss': Array(0.00106489, dtype=float32), 'training/policy_loss': Array(-0.00725332, dtype=float32), 'training/total_loss': Array(-0.00276112, dtype=float32), 'training/v_loss': Array(0.00342731, dtype=float32), 'eval/episode_distance_from_origin': Array(4234.6953, dtype=float32), 'eval/episode_distance_reward': Array(7.298018, dtype=float32), 'eval/episode_forward_reward': Array(1216.3335, dtype=float32), 'eval/episode_reward': Array(1217.8865, dtype=float32), 'eval/episode_reward_alive': Array(296.01562, dtype=float32), 'eval/episode_reward_linvel': Array(1216.3335, dtype=float32), 'eval/episode_reward_quadctrl': Array(-301.7608, dtype=float32), 'eval/episode_x_position': Array(4188.3545, dtype=float32), 'eval/episode_x_velocity': Array(243.26671, dtype=float32), 'eval/episode_y_position': Array(-320.51086, dtype=float32), 'eval/episode_y_velocity': Array(-72.50289, dtype=float32), 'eval/episode_distance_from_origin_std': Array(350.3583, dtype=float32), 'eval/episode_distance_reward_std': Array(2.462454, dtype=float32), 'eval/episode_forward_reward_std': Array(410.40628, dtype=float32), 'eval/episode_reward_std': Array(420.56628, dtype=float32), 'eval/episode_reward_alive_std': Array(136.75569, dtype=float32), 'eval/episode_reward_linvel_std': Array(410.40628, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.797037, dtype=float32), 'eval/episode_x_position_std': Array(346.42526, dtype=float32), 'eval/episode_x_velocity_std': Array(82.08128, dtype=float32), 'eval/episode_y_position_std': Array(188.97006, dtype=float32), 'eval/episode_y_velocity_std': Array(41.84798, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27849674224854, 'eval/sps': 939.2530961219352, 'num_steps': 18923520}
{'eval/walltime': 31842.373783111572, 'training/sps': 2949.518180003632, 'training/walltime': 6484.76301407814, 'training/entropy_loss': Array(0.00382135, dtype=float32), 'training/policy_loss': Array(-0.00334452, dtype=float32), 'training/total_loss': Array(0.0527137, dtype=float32), 'training/v_loss': Array(0.05223688, dtype=float32), 'eval/episode_distance_from_origin': Array(4347.5586, dtype=float32), 'eval/episode_distance_reward': Array(8.071704, dtype=float32), 'eval/episode_forward_reward': Array(1345.2802, dtype=float32), 'eval/episode_reward': Array(1357.5239, dtype=float32), 'eval/episode_reward_alive': Array(307.40234, dtype=float32), 'eval/episode_reward_linvel': Array(1345.2802, dtype=float32), 'eval/episode_reward_quadctrl': Array(-303.23044, dtype=float32), 'eval/episode_x_position': Array(4301.468, dtype=float32), 'eval/episode_x_velocity': Array(269.05603, dtype=float32), 'eval/episode_y_position': Array(-330.70312, dtype=float32), 'eval/episode_y_velocity': Array(-74.28914, dtype=float32), 'eval/episode_distance_from_origin_std': Array(358.38556, dtype=float32), 'eval/episode_distance_reward_std': Array(2.6061025, dtype=float32), 'eval/episode_forward_reward_std': Array(434.34705, dtype=float32), 'eval/episode_reward_std': Array(430.7518, dtype=float32), 'eval/episode_reward_alive_std': Array(134.32808, dtype=float32), 'eval/episode_reward_linvel_std': Array(434.34705, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.655716, dtype=float32), 'eval/episode_x_position_std': Array(352.6693, dtype=float32), 'eval/episode_x_velocity_std': Array(86.869415, dtype=float32), 'eval/episode_y_position_std': Array(191.01614, dtype=float32), 'eval/episode_y_velocity_std': Array(43.489025, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26883673667908, 'eval/sps': 939.3196791379568, 'num_steps': 19005440}
{'eval/walltime': 31978.599431037903, 'training/sps': 2961.756107871151, 'training/walltime': 6512.422280073166, 'training/entropy_loss': Array(0.01051445, dtype=float32), 'training/policy_loss': Array(0.00943336, dtype=float32), 'training/total_loss': Array(0.14116982, dtype=float32), 'training/v_loss': Array(0.12122202, dtype=float32), 'eval/episode_distance_from_origin': Array(4392.6606, dtype=float32), 'eval/episode_distance_reward': Array(8.488271, dtype=float32), 'eval/episode_forward_reward': Array(1414.7075, dtype=float32), 'eval/episode_reward': Array(1398.0881, dtype=float32), 'eval/episode_reward_alive': Array(284.39844, dtype=float32), 'eval/episode_reward_linvel': Array(1414.7075, dtype=float32), 'eval/episode_reward_quadctrl': Array(-309.50595, dtype=float32), 'eval/episode_x_position': Array(4343.054, dtype=float32), 'eval/episode_x_velocity': Array(282.94147, dtype=float32), 'eval/episode_y_position': Array(-346.5179, dtype=float32), 'eval/episode_y_velocity': Array(-81.0586, dtype=float32), 'eval/episode_distance_from_origin_std': Array(386.50186, dtype=float32), 'eval/episode_distance_reward_std': Array(2.891152, dtype=float32), 'eval/episode_forward_reward_std': Array(481.85468, dtype=float32), 'eval/episode_reward_std': Array(473.70987, dtype=float32), 'eval/episode_reward_alive_std': Array(125.38214, dtype=float32), 'eval/episode_reward_linvel_std': Array(481.85468, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.76498, dtype=float32), 'eval/episode_x_position_std': Array(380.95367, dtype=float32), 'eval/episode_x_velocity_std': Array(96.3709, dtype=float32), 'eval/episode_y_position_std': Array(234.01839, dtype=float32), 'eval/episode_y_velocity_std': Array(54.74037, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22564792633057, 'eval/sps': 939.6174798832382, 'num_steps': 19087360}
{'eval/walltime': 32114.902183294296, 'training/sps': 2945.0549924209254, 'training/walltime': 6540.238399028778, 'training/entropy_loss': Array(0.00468399, dtype=float32), 'training/policy_loss': Array(0.00785146, dtype=float32), 'training/total_loss': Array(0.06107589, dtype=float32), 'training/v_loss': Array(0.04854044, dtype=float32), 'eval/episode_distance_from_origin': Array(4372.237, dtype=float32), 'eval/episode_distance_reward': Array(8.285318, dtype=float32), 'eval/episode_forward_reward': Array(1380.8828, dtype=float32), 'eval/episode_reward': Array(1383.0715, dtype=float32), 'eval/episode_reward_alive': Array(298.42188, dtype=float32), 'eval/episode_reward_linvel': Array(1380.8828, dtype=float32), 'eval/episode_reward_quadctrl': Array(-304.51852, dtype=float32), 'eval/episode_x_position': Array(4322.366, dtype=float32), 'eval/episode_x_velocity': Array(276.17657, dtype=float32), 'eval/episode_y_position': Array(-359.46857, dtype=float32), 'eval/episode_y_velocity': Array(-82.79996, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.3925, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9082434, dtype=float32), 'eval/episode_forward_reward_std': Array(484.70428, dtype=float32), 'eval/episode_reward_std': Array(495.77185, dtype=float32), 'eval/episode_reward_alive_std': Array(130.47064, dtype=float32), 'eval/episode_reward_linvel_std': Array(484.70428, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.147953, dtype=float32), 'eval/episode_x_position_std': Array(390.11862, dtype=float32), 'eval/episode_x_velocity_std': Array(96.940834, dtype=float32), 'eval/episode_y_position_std': Array(212.26941, dtype=float32), 'eval/episode_y_velocity_std': Array(49.423874, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30275225639343, 'eval/sps': 939.0859530057363, 'num_steps': 19169280}
{'eval/walltime': 32251.130111932755, 'training/sps': 2936.6606003708152, 'training/walltime': 6568.134029865265, 'training/entropy_loss': Array(0.00226975, dtype=float32), 'training/policy_loss': Array(0.00054987, dtype=float32), 'training/total_loss': Array(0.01764024, dtype=float32), 'training/v_loss': Array(0.01482063, dtype=float32), 'eval/episode_distance_from_origin': Array(4281.1426, dtype=float32), 'eval/episode_distance_reward': Array(7.7412252, dtype=float32), 'eval/episode_forward_reward': Array(1290.2012, dtype=float32), 'eval/episode_reward': Array(1321.3892, dtype=float32), 'eval/episode_reward_alive': Array(326.89844, dtype=float32), 'eval/episode_reward_linvel': Array(1290.2012, dtype=float32), 'eval/episode_reward_quadctrl': Array(-303.4516, dtype=float32), 'eval/episode_x_position': Array(4229.4307, dtype=float32), 'eval/episode_x_velocity': Array(258.04022, dtype=float32), 'eval/episode_y_position': Array(-344.07373, dtype=float32), 'eval/episode_y_velocity': Array(-78.085754, dtype=float32), 'eval/episode_distance_from_origin_std': Array(366.49762, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8240135, dtype=float32), 'eval/episode_forward_reward_std': Array(470.66556, dtype=float32), 'eval/episode_reward_std': Array(477.83655, dtype=float32), 'eval/episode_reward_alive_std': Array(132.04501, dtype=float32), 'eval/episode_reward_linvel_std': Array(470.66556, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.745113, dtype=float32), 'eval/episode_x_position_std': Array(357.29407, dtype=float32), 'eval/episode_x_velocity_std': Array(94.133125, dtype=float32), 'eval/episode_y_position_std': Array(248.82607, dtype=float32), 'eval/episode_y_velocity_std': Array(57.98652, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22792863845825, 'eval/sps': 939.6017489167383, 'num_steps': 19251200}
{'eval/walltime': 32387.294272899628, 'training/sps': 2943.395458839055, 'training/walltime': 6595.96583199501, 'training/entropy_loss': Array(0.00150414, dtype=float32), 'training/policy_loss': Array(-0.00682083, dtype=float32), 'training/total_loss': Array(0.00076801, dtype=float32), 'training/v_loss': Array(0.0060847, dtype=float32), 'eval/episode_distance_from_origin': Array(4304.6533, dtype=float32), 'eval/episode_distance_reward': Array(7.9170523, dtype=float32), 'eval/episode_forward_reward': Array(1319.5059, dtype=float32), 'eval/episode_reward': Array(1384.572, dtype=float32), 'eval/episode_reward_alive': Array(356.54297, dtype=float32), 'eval/episode_reward_linvel': Array(1319.5059, dtype=float32), 'eval/episode_reward_quadctrl': Array(-299.3938, dtype=float32), 'eval/episode_x_position': Array(4256.072, dtype=float32), 'eval/episode_x_velocity': Array(263.90112, dtype=float32), 'eval/episode_y_position': Array(-341.42007, dtype=float32), 'eval/episode_y_velocity': Array(-77.13686, dtype=float32), 'eval/episode_distance_from_origin_std': Array(366.87817, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9493706, dtype=float32), 'eval/episode_forward_reward_std': Array(491.5591, dtype=float32), 'eval/episode_reward_std': Array(470.20673, dtype=float32), 'eval/episode_reward_alive_std': Array(122.45166, dtype=float32), 'eval/episode_reward_linvel_std': Array(491.5591, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.247524, dtype=float32), 'eval/episode_x_position_std': Array(358.42258, dtype=float32), 'eval/episode_x_velocity_std': Array(98.31176, dtype=float32), 'eval/episode_y_position_std': Array(204.41428, dtype=float32), 'eval/episode_y_velocity_std': Array(48.707886, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.16416096687317, 'eval/sps': 940.0417781822972, 'num_steps': 19333120}
{'eval/walltime': 32523.514052152634, 'training/sps': 2943.3197925886025, 'training/walltime': 6623.798349618912, 'training/entropy_loss': Array(0.00119373, dtype=float32), 'training/policy_loss': Array(-0.0080262, dtype=float32), 'training/total_loss': Array(-0.00326466, dtype=float32), 'training/v_loss': Array(0.00356781, dtype=float32), 'eval/episode_distance_from_origin': Array(4206.7227, dtype=float32), 'eval/episode_distance_reward': Array(7.143656, dtype=float32), 'eval/episode_forward_reward': Array(1190.6067, dtype=float32), 'eval/episode_reward': Array(1253.6274, dtype=float32), 'eval/episode_reward_alive': Array(354.84766, dtype=float32), 'eval/episode_reward_linvel': Array(1190.6067, dtype=float32), 'eval/episode_reward_quadctrl': Array(-298.9706, dtype=float32), 'eval/episode_x_position': Array(4160.2695, dtype=float32), 'eval/episode_x_velocity': Array(238.12138, dtype=float32), 'eval/episode_y_position': Array(-317.17136, dtype=float32), 'eval/episode_y_velocity': Array(-70.51521, dtype=float32), 'eval/episode_distance_from_origin_std': Array(383.6651, dtype=float32), 'eval/episode_distance_reward_std': Array(2.750225, dtype=float32), 'eval/episode_forward_reward_std': Array(458.36774, dtype=float32), 'eval/episode_reward_std': Array(456.8627, dtype=float32), 'eval/episode_reward_alive_std': Array(121.93116, dtype=float32), 'eval/episode_reward_linvel_std': Array(458.36774, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.48029, dtype=float32), 'eval/episode_x_position_std': Array(377.77795, dtype=float32), 'eval/episode_x_velocity_std': Array(91.67361, dtype=float32), 'eval/episode_y_position_std': Array(188.7976, dtype=float32), 'eval/episode_y_velocity_std': Array(44.91375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21977925300598, 'eval/sps': 939.6579608476748, 'num_steps': 19415040}
{'eval/walltime': 32659.664308309555, 'training/sps': 2944.4092725775504, 'training/walltime': 6651.620568752289, 'training/entropy_loss': Array(0.00268895, dtype=float32), 'training/policy_loss': Array(-0.00397986, dtype=float32), 'training/total_loss': Array(0.02217453, dtype=float32), 'training/v_loss': Array(0.02346544, dtype=float32), 'eval/episode_distance_from_origin': Array(4198.373, dtype=float32), 'eval/episode_distance_reward': Array(7.0410504, dtype=float32), 'eval/episode_forward_reward': Array(1173.5062, dtype=float32), 'eval/episode_reward': Array(1246.2075, dtype=float32), 'eval/episode_reward_alive': Array(363.3047, dtype=float32), 'eval/episode_reward_linvel': Array(1173.5062, dtype=float32), 'eval/episode_reward_quadctrl': Array(-297.64465, dtype=float32), 'eval/episode_x_position': Array(4152.46, dtype=float32), 'eval/episode_x_velocity': Array(234.7013, dtype=float32), 'eval/episode_y_position': Array(-288.27722, dtype=float32), 'eval/episode_y_velocity': Array(-65.02655, dtype=float32), 'eval/episode_distance_from_origin_std': Array(341.6473, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4508853, dtype=float32), 'eval/episode_forward_reward_std': Array(408.47855, dtype=float32), 'eval/episode_reward_std': Array(413.55334, dtype=float32), 'eval/episode_reward_alive_std': Array(117.14317, dtype=float32), 'eval/episode_reward_linvel_std': Array(408.47855, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.031076, dtype=float32), 'eval/episode_x_position_std': Array(336.9421, dtype=float32), 'eval/episode_x_velocity_std': Array(81.695755, dtype=float32), 'eval/episode_y_position_std': Array(212.37202, dtype=float32), 'eval/episode_y_velocity_std': Array(48.97024, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1502561569214, 'eval/sps': 940.1377831597487, 'num_steps': 19496960}
{'eval/walltime': 32795.900611400604, 'training/sps': 2944.3772286678095, 'training/walltime': 6679.443090677261, 'training/entropy_loss': Array(0.00956835, dtype=float32), 'training/policy_loss': Array(0.00977963, dtype=float32), 'training/total_loss': Array(0.1406945, dtype=float32), 'training/v_loss': Array(0.12134652, dtype=float32), 'eval/episode_distance_from_origin': Array(4334.162, dtype=float32), 'eval/episode_distance_reward': Array(8.078342, dtype=float32), 'eval/episode_forward_reward': Array(1346.3872, dtype=float32), 'eval/episode_reward': Array(1408.3774, dtype=float32), 'eval/episode_reward_alive': Array(353.38672, dtype=float32), 'eval/episode_reward_linvel': Array(1346.3872, dtype=float32), 'eval/episode_reward_quadctrl': Array(-299.4748, dtype=float32), 'eval/episode_x_position': Array(4284.5312, dtype=float32), 'eval/episode_x_velocity': Array(269.2774, dtype=float32), 'eval/episode_y_position': Array(-341.73248, dtype=float32), 'eval/episode_y_velocity': Array(-79.41139, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.84308, dtype=float32), 'eval/episode_distance_reward_std': Array(3.326356, dtype=float32), 'eval/episode_forward_reward_std': Array(554.3885, dtype=float32), 'eval/episode_reward_std': Array(537.3443, dtype=float32), 'eval/episode_reward_alive_std': Array(113.29863, dtype=float32), 'eval/episode_reward_linvel_std': Array(554.3885, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.124863, dtype=float32), 'eval/episode_x_position_std': Array(422.43948, dtype=float32), 'eval/episode_x_velocity_std': Array(110.87774, dtype=float32), 'eval/episode_y_position_std': Array(224.67557, dtype=float32), 'eval/episode_y_velocity_std': Array(54.37744, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2363030910492, 'eval/sps': 939.5439915486791, 'num_steps': 19578880}
{'eval/walltime': 32932.06568813324, 'training/sps': 2941.3294612496325, 'training/walltime': 6707.2944419384, 'training/entropy_loss': Array(0.00462758, dtype=float32), 'training/policy_loss': Array(0.01208735, dtype=float32), 'training/total_loss': Array(0.06813762, dtype=float32), 'training/v_loss': Array(0.05142269, dtype=float32), 'eval/episode_distance_from_origin': Array(4320.2314, dtype=float32), 'eval/episode_distance_reward': Array(7.8884163, dtype=float32), 'eval/episode_forward_reward': Array(1314.7329, dtype=float32), 'eval/episode_reward': Array(1396.3225, dtype=float32), 'eval/episode_reward_alive': Array(376.27734, dtype=float32), 'eval/episode_reward_linvel': Array(1314.7329, dtype=float32), 'eval/episode_reward_quadctrl': Array(-302.57617, dtype=float32), 'eval/episode_x_position': Array(4271.213, dtype=float32), 'eval/episode_x_velocity': Array(262.9466, dtype=float32), 'eval/episode_y_position': Array(-327.77213, dtype=float32), 'eval/episode_y_velocity': Array(-75.31886, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.54724, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9257572, dtype=float32), 'eval/episode_forward_reward_std': Array(487.62286, dtype=float32), 'eval/episode_reward_std': Array(459.63913, dtype=float32), 'eval/episode_reward_alive_std': Array(101.55188, dtype=float32), 'eval/episode_reward_linvel_std': Array(487.62286, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.389103, dtype=float32), 'eval/episode_x_position_std': Array(400.19052, dtype=float32), 'eval/episode_x_velocity_std': Array(97.52458, dtype=float32), 'eval/episode_y_position_std': Array(236.74379, dtype=float32), 'eval/episode_y_velocity_std': Array(55.327755, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1650767326355, 'eval/sps': 940.0354560173466, 'num_steps': 19660800}
{'eval/walltime': 33068.28395318985, 'training/sps': 2946.6396768653963, 'training/walltime': 6735.095601558685, 'training/entropy_loss': Array(0.0023325, dtype=float32), 'training/policy_loss': Array(0.00088085, dtype=float32), 'training/total_loss': Array(0.01836153, dtype=float32), 'training/v_loss': Array(0.01514819, dtype=float32), 'eval/episode_distance_from_origin': Array(4261.9844, dtype=float32), 'eval/episode_distance_reward': Array(7.5865045, dtype=float32), 'eval/episode_forward_reward': Array(1264.4147, dtype=float32), 'eval/episode_reward': Array(1339.5562, dtype=float32), 'eval/episode_reward_alive': Array(372.8672, dtype=float32), 'eval/episode_reward_linvel': Array(1264.4147, dtype=float32), 'eval/episode_reward_quadctrl': Array(-305.31235, dtype=float32), 'eval/episode_x_position': Array(4213.4004, dtype=float32), 'eval/episode_x_velocity': Array(252.88293, dtype=float32), 'eval/episode_y_position': Array(-297.2875, dtype=float32), 'eval/episode_y_velocity': Array(-68.507034, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.30945, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2277412, dtype=float32), 'eval/episode_forward_reward_std': Array(537.95355, dtype=float32), 'eval/episode_reward_std': Array(528.5359, dtype=float32), 'eval/episode_reward_alive_std': Array(119.20081, dtype=float32), 'eval/episode_reward_linvel_std': Array(537.95355, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.310993, dtype=float32), 'eval/episode_x_position_std': Array(387.73218, dtype=float32), 'eval/episode_x_velocity_std': Array(107.590706, dtype=float32), 'eval/episode_y_position_std': Array(250.53299, dtype=float32), 'eval/episode_y_velocity_std': Array(58.44326, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2182650566101, 'eval/sps': 939.6684060452926, 'num_steps': 19742720}
{'eval/walltime': 33204.46213746071, 'training/sps': 2940.6306095138375, 'training/walltime': 6762.953571796417, 'training/entropy_loss': Array(0.0016822, dtype=float32), 'training/policy_loss': Array(-0.00211146, dtype=float32), 'training/total_loss': Array(0.0062067, dtype=float32), 'training/v_loss': Array(0.00663596, dtype=float32), 'eval/episode_distance_from_origin': Array(4201.471, dtype=float32), 'eval/episode_distance_reward': Array(7.059775, dtype=float32), 'eval/episode_forward_reward': Array(1176.6267, dtype=float32), 'eval/episode_reward': Array(1255.211, dtype=float32), 'eval/episode_reward_alive': Array(377.8203, dtype=float32), 'eval/episode_reward_linvel': Array(1176.6267, dtype=float32), 'eval/episode_reward_quadctrl': Array(-306.29578, dtype=float32), 'eval/episode_x_position': Array(4154.4883, dtype=float32), 'eval/episode_x_velocity': Array(235.32533, dtype=float32), 'eval/episode_y_position': Array(-319.67313, dtype=float32), 'eval/episode_y_velocity': Array(-71.20599, dtype=float32), 'eval/episode_distance_from_origin_std': Array(375.4998, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7785451, dtype=float32), 'eval/episode_forward_reward_std': Array(463.0874, dtype=float32), 'eval/episode_reward_std': Array(450.47705, dtype=float32), 'eval/episode_reward_alive_std': Array(112.027, dtype=float32), 'eval/episode_reward_linvel_std': Array(463.0874, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.513527, dtype=float32), 'eval/episode_x_position_std': Array(371.59598, dtype=float32), 'eval/episode_x_velocity_std': Array(92.61749, dtype=float32), 'eval/episode_y_position_std': Array(183.21721, dtype=float32), 'eval/episode_y_velocity_std': Array(42.616787, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.17818427085876, 'eval/sps': 939.9449749264365, 'num_steps': 19824640}
{'eval/walltime': 33340.69567990303, 'training/sps': 2950.7324886777233, 'training/walltime': 6790.716169834137, 'training/entropy_loss': Array(0.00142511, dtype=float32), 'training/policy_loss': Array(-0.00484701, dtype=float32), 'training/total_loss': Array(-0.00079191, dtype=float32), 'training/v_loss': Array(0.00262999, dtype=float32), 'eval/episode_distance_from_origin': Array(4222.6445, dtype=float32), 'eval/episode_distance_reward': Array(7.219741, dtype=float32), 'eval/episode_forward_reward': Array(1203.2883, dtype=float32), 'eval/episode_reward': Array(1287.0448, dtype=float32), 'eval/episode_reward_alive': Array(382.05078, dtype=float32), 'eval/episode_reward_linvel': Array(1203.2883, dtype=float32), 'eval/episode_reward_quadctrl': Array(-305.51404, dtype=float32), 'eval/episode_x_position': Array(4172.8506, dtype=float32), 'eval/episode_x_velocity': Array(240.65765, dtype=float32), 'eval/episode_y_position': Array(-355.83063, dtype=float32), 'eval/episode_y_velocity': Array(-80.15875, dtype=float32), 'eval/episode_distance_from_origin_std': Array(394.37714, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8922317, dtype=float32), 'eval/episode_forward_reward_std': Array(482.03653, dtype=float32), 'eval/episode_reward_std': Array(470.1395, dtype=float32), 'eval/episode_reward_alive_std': Array(107.33903, dtype=float32), 'eval/episode_reward_linvel_std': Array(482.03653, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.809395, dtype=float32), 'eval/episode_x_position_std': Array(387.49338, dtype=float32), 'eval/episode_x_velocity_std': Array(96.40729, dtype=float32), 'eval/episode_y_position_std': Array(174.09595, dtype=float32), 'eval/episode_y_velocity_std': Array(45.851738, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23354244232178, 'eval/sps': 939.563030552423, 'num_steps': 19906560}
{'eval/walltime': 33476.87265896797, 'training/sps': 2948.3471700765813, 'training/walltime': 6818.501228809357, 'training/entropy_loss': Array(0.00172337, dtype=float32), 'training/policy_loss': Array(-0.00766524, dtype=float32), 'training/total_loss': Array(0.00101747, dtype=float32), 'training/v_loss': Array(0.00695934, dtype=float32), 'eval/episode_distance_from_origin': Array(4237.248, dtype=float32), 'eval/episode_distance_reward': Array(7.284057, dtype=float32), 'eval/episode_forward_reward': Array(1214.0076, dtype=float32), 'eval/episode_reward': Array(1311.8822, dtype=float32), 'eval/episode_reward_alive': Array(392.54688, dtype=float32), 'eval/episode_reward_linvel': Array(1214.0076, dtype=float32), 'eval/episode_reward_quadctrl': Array(-301.95636, dtype=float32), 'eval/episode_x_position': Array(4190.4365, dtype=float32), 'eval/episode_x_velocity': Array(242.80148, dtype=float32), 'eval/episode_y_position': Array(-282.25455, dtype=float32), 'eval/episode_y_velocity': Array(-64.697845, dtype=float32), 'eval/episode_distance_from_origin_std': Array(380.59863, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7849853, dtype=float32), 'eval/episode_forward_reward_std': Array(464.16168, dtype=float32), 'eval/episode_reward_std': Array(444.6101, dtype=float32), 'eval/episode_reward_alive_std': Array(101.53352, dtype=float32), 'eval/episode_reward_linvel_std': Array(464.16168, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.658627, dtype=float32), 'eval/episode_x_position_std': Array(376.80936, dtype=float32), 'eval/episode_x_velocity_std': Array(92.83229, dtype=float32), 'eval/episode_y_position_std': Array(232.7744, dtype=float32), 'eval/episode_y_velocity_std': Array(53.48335, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1769790649414, 'eval/sps': 939.9532937131621, 'num_steps': 19988480}
{'eval/walltime': 33613.087721824646, 'training/sps': 2958.7110509655035, 'training/walltime': 6846.188961267471, 'training/entropy_loss': Array(0.0100481, dtype=float32), 'training/policy_loss': Array(0.00601375, dtype=float32), 'training/total_loss': Array(0.13005978, dtype=float32), 'training/v_loss': Array(0.11399792, dtype=float32), 'eval/episode_distance_from_origin': Array(4261.817, dtype=float32), 'eval/episode_distance_reward': Array(7.4928207, dtype=float32), 'eval/episode_forward_reward': Array(1248.8016, dtype=float32), 'eval/episode_reward': Array(1330.4738, dtype=float32), 'eval/episode_reward_alive': Array(378.3086, dtype=float32), 'eval/episode_reward_linvel': Array(1248.8016, dtype=float32), 'eval/episode_reward_quadctrl': Array(-304.1293, dtype=float32), 'eval/episode_x_position': Array(4215.443, dtype=float32), 'eval/episode_x_velocity': Array(249.7603, dtype=float32), 'eval/episode_y_position': Array(-270.37958, dtype=float32), 'eval/episode_y_velocity': Array(-62.325397, dtype=float32), 'eval/episode_distance_from_origin_std': Array(383.48917, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8558261, dtype=float32), 'eval/episode_forward_reward_std': Array(475.9687, dtype=float32), 'eval/episode_reward_std': Array(469.99835, dtype=float32), 'eval/episode_reward_alive_std': Array(104.71585, dtype=float32), 'eval/episode_reward_linvel_std': Array(475.9687, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.099113, dtype=float32), 'eval/episode_x_position_std': Array(378.4175, dtype=float32), 'eval/episode_x_velocity_std': Array(95.19372, dtype=float32), 'eval/episode_y_position_std': Array(249.34941, dtype=float32), 'eval/episode_y_velocity_std': Array(56.164913, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2150628566742, 'eval/sps': 939.6904961581371, 'num_steps': 20070400}
{'eval/walltime': 33749.275371313095, 'training/sps': 2936.0041554174527, 'training/walltime': 6874.090829133987, 'training/entropy_loss': Array(0.00630014, dtype=float32), 'training/policy_loss': Array(0.01717324, dtype=float32), 'training/total_loss': Array(0.09746865, dtype=float32), 'training/v_loss': Array(0.07399527, dtype=float32), 'eval/episode_distance_from_origin': Array(4300.2705, dtype=float32), 'eval/episode_distance_reward': Array(7.6670275, dtype=float32), 'eval/episode_forward_reward': Array(1277.8358, dtype=float32), 'eval/episode_reward': Array(1367.5781, dtype=float32), 'eval/episode_reward_alive': Array(389.57812, dtype=float32), 'eval/episode_reward_linvel': Array(1277.8358, dtype=float32), 'eval/episode_reward_quadctrl': Array(-307.50272, dtype=float32), 'eval/episode_x_position': Array(4248.9844, dtype=float32), 'eval/episode_x_velocity': Array(255.56715, dtype=float32), 'eval/episode_y_position': Array(-360.33807, dtype=float32), 'eval/episode_y_velocity': Array(-80.80409, dtype=float32), 'eval/episode_distance_from_origin_std': Array(328.3841, dtype=float32), 'eval/episode_distance_reward_std': Array(2.3900497, dtype=float32), 'eval/episode_forward_reward_std': Array(398.33875, dtype=float32), 'eval/episode_reward_std': Array(385.05405, dtype=float32), 'eval/episode_reward_alive_std': Array(104.20573, dtype=float32), 'eval/episode_reward_linvel_std': Array(398.33875, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.675186, dtype=float32), 'eval/episode_x_position_std': Array(321.87177, dtype=float32), 'eval/episode_x_velocity_std': Array(79.66778, dtype=float32), 'eval/episode_y_position_std': Array(208.61215, dtype=float32), 'eval/episode_y_velocity_std': Array(49.040718, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1876494884491, 'eval/sps': 939.8796475362948, 'num_steps': 20152320}
{'eval/walltime': 33885.51169323921, 'training/sps': 2945.5001149233854, 'training/walltime': 6901.9027445316315, 'training/entropy_loss': Array(0.00327987, dtype=float32), 'training/policy_loss': Array(0.00606246, dtype=float32), 'training/total_loss': Array(0.02587975, dtype=float32), 'training/v_loss': Array(0.01653742, dtype=float32), 'eval/episode_distance_from_origin': Array(4229.142, dtype=float32), 'eval/episode_distance_reward': Array(7.2371645, dtype=float32), 'eval/episode_forward_reward': Array(1206.1921, dtype=float32), 'eval/episode_reward': Array(1292.5198, dtype=float32), 'eval/episode_reward_alive': Array(388.65234, dtype=float32), 'eval/episode_reward_linvel': Array(1206.1921, dtype=float32), 'eval/episode_reward_quadctrl': Array(-309.56207, dtype=float32), 'eval/episode_x_position': Array(4174.879, dtype=float32), 'eval/episode_x_velocity': Array(241.23846, dtype=float32), 'eval/episode_y_position': Array(-348.8482, dtype=float32), 'eval/episode_y_velocity': Array(-78.48554, dtype=float32), 'eval/episode_distance_from_origin_std': Array(346.15085, dtype=float32), 'eval/episode_distance_reward_std': Array(2.6375728, dtype=float32), 'eval/episode_forward_reward_std': Array(439.59375, dtype=float32), 'eval/episode_reward_std': Array(434.63077, dtype=float32), 'eval/episode_reward_alive_std': Array(101.80547, dtype=float32), 'eval/episode_reward_linvel_std': Array(439.59375, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.75144, dtype=float32), 'eval/episode_x_position_std': Array(338.08105, dtype=float32), 'eval/episode_x_velocity_std': Array(87.91876, dtype=float32), 'eval/episode_y_position_std': Array(260.4764, dtype=float32), 'eval/episode_y_velocity_std': Array(60.06475, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23632192611694, 'eval/sps': 939.5438616539896, 'num_steps': 20234240}
{'eval/walltime': 34021.673248291016, 'training/sps': 2940.22789233002, 'training/walltime': 6929.764530420303, 'training/entropy_loss': Array(0.00210936, dtype=float32), 'training/policy_loss': Array(-0.00458204, dtype=float32), 'training/total_loss': Array(0.00256388, dtype=float32), 'training/v_loss': Array(0.00503656, dtype=float32), 'eval/episode_distance_from_origin': Array(4138.0723, dtype=float32), 'eval/episode_distance_reward': Array(6.615226, dtype=float32), 'eval/episode_forward_reward': Array(1102.5361, dtype=float32), 'eval/episode_reward': Array(1211.0219, dtype=float32), 'eval/episode_reward_alive': Array(400.39453, dtype=float32), 'eval/episode_reward_linvel': Array(1102.5361, dtype=float32), 'eval/episode_reward_quadctrl': Array(-298.5243, dtype=float32), 'eval/episode_x_position': Array(4090.989, dtype=float32), 'eval/episode_x_velocity': Array(220.50726, dtype=float32), 'eval/episode_y_position': Array(-308.85733, dtype=float32), 'eval/episode_y_velocity': Array(-66.62061, dtype=float32), 'eval/episode_distance_from_origin_std': Array(316.1255, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2102938, dtype=float32), 'eval/episode_forward_reward_std': Array(368.38086, dtype=float32), 'eval/episode_reward_std': Array(362.39316, dtype=float32), 'eval/episode_reward_alive_std': Array(93.89253, dtype=float32), 'eval/episode_reward_linvel_std': Array(368.38086, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.950443, dtype=float32), 'eval/episode_x_position_std': Array(308.72205, dtype=float32), 'eval/episode_x_velocity_std': Array(73.6762, dtype=float32), 'eval/episode_y_position_std': Array(193.3113, dtype=float32), 'eval/episode_y_velocity_std': Array(43.977562, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1615550518036, 'eval/sps': 940.059769083142, 'num_steps': 20316160}
{'eval/walltime': 34157.981018066406, 'training/sps': 2937.756282327642, 'training/walltime': 6957.649757146835, 'training/entropy_loss': Array(0.00174229, dtype=float32), 'training/policy_loss': Array(-0.00990676, dtype=float32), 'training/total_loss': Array(-0.00619929, dtype=float32), 'training/v_loss': Array(0.00196518, dtype=float32), 'eval/episode_distance_from_origin': Array(4198.1494, dtype=float32), 'eval/episode_distance_reward': Array(7.078598, dtype=float32), 'eval/episode_forward_reward': Array(1179.7645, dtype=float32), 'eval/episode_reward': Array(1301.1598, dtype=float32), 'eval/episode_reward_alive': Array(409.71094, dtype=float32), 'eval/episode_reward_linvel': Array(1179.7645, dtype=float32), 'eval/episode_reward_quadctrl': Array(-295.39423, dtype=float32), 'eval/episode_x_position': Array(4148.092, dtype=float32), 'eval/episode_x_velocity': Array(235.95288, dtype=float32), 'eval/episode_y_position': Array(-349.8444, dtype=float32), 'eval/episode_y_velocity': Array(-77.304794, dtype=float32), 'eval/episode_distance_from_origin_std': Array(357.42484, dtype=float32), 'eval/episode_distance_reward_std': Array(2.636623, dtype=float32), 'eval/episode_forward_reward_std': Array(439.43494, dtype=float32), 'eval/episode_reward_std': Array(425.29935, dtype=float32), 'eval/episode_reward_alive_std': Array(77.302635, dtype=float32), 'eval/episode_reward_linvel_std': Array(439.43494, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.575794, dtype=float32), 'eval/episode_x_position_std': Array(349.37335, dtype=float32), 'eval/episode_x_velocity_std': Array(87.88699, dtype=float32), 'eval/episode_y_position_std': Array(185.6065, dtype=float32), 'eval/episode_y_velocity_std': Array(44.82313, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30776977539062, 'eval/sps': 939.0513850451794, 'num_steps': 20398080}
{'eval/walltime': 34294.15896511078, 'training/sps': 2959.58118196443, 'training/walltime': 6985.329349279404, 'training/entropy_loss': Array(0.00168961, dtype=float32), 'training/policy_loss': Array(-0.01529738, dtype=float32), 'training/total_loss': Array(-0.01200414, dtype=float32), 'training/v_loss': Array(0.00160363, dtype=float32), 'eval/episode_distance_from_origin': Array(4021.0586, dtype=float32), 'eval/episode_distance_reward': Array(5.906083, dtype=float32), 'eval/episode_forward_reward': Array(984.346, dtype=float32), 'eval/episode_reward': Array(1102.9873, dtype=float32), 'eval/episode_reward_alive': Array(399.6797, dtype=float32), 'eval/episode_reward_linvel': Array(984.346, dtype=float32), 'eval/episode_reward_quadctrl': Array(-286.9445, dtype=float32), 'eval/episode_x_position': Array(3977.4758, dtype=float32), 'eval/episode_x_velocity': Array(196.86923, dtype=float32), 'eval/episode_y_position': Array(-255.74199, dtype=float32), 'eval/episode_y_velocity': Array(-55.087845, dtype=float32), 'eval/episode_distance_from_origin_std': Array(276.41592, dtype=float32), 'eval/episode_distance_reward_std': Array(2.04051, dtype=float32), 'eval/episode_forward_reward_std': Array(340.0838, dtype=float32), 'eval/episode_reward_std': Array(373.1137, dtype=float32), 'eval/episode_reward_alive_std': Array(104.35122, dtype=float32), 'eval/episode_reward_linvel_std': Array(340.0838, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.399158, dtype=float32), 'eval/episode_x_position_std': Array(270.78732, dtype=float32), 'eval/episode_x_velocity_std': Array(68.016754, dtype=float32), 'eval/episode_y_position_std': Array(178.66652, dtype=float32), 'eval/episode_y_velocity_std': Array(43.206894, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.17794704437256, 'eval/sps': 939.9466123416603, 'num_steps': 20480000}
{'eval/walltime': 34430.48516917229, 'training/sps': 2955.9606486720936, 'training/walltime': 7013.042844057083, 'training/entropy_loss': Array(0.00729496, dtype=float32), 'training/policy_loss': Array(-0.00164297, dtype=float32), 'training/total_loss': Array(0.08385815, dtype=float32), 'training/v_loss': Array(0.07820617, dtype=float32), 'eval/episode_distance_from_origin': Array(4147.82, dtype=float32), 'eval/episode_distance_reward': Array(6.6552, dtype=float32), 'eval/episode_forward_reward': Array(1109.1986, dtype=float32), 'eval/episode_reward': Array(1218.8641, dtype=float32), 'eval/episode_reward_alive': Array(391.83984, dtype=float32), 'eval/episode_reward_linvel': Array(1109.1986, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.82977, dtype=float32), 'eval/episode_x_position': Array(4098.4434, dtype=float32), 'eval/episode_x_velocity': Array(221.83972, dtype=float32), 'eval/episode_y_position': Array(-327.0977, dtype=float32), 'eval/episode_y_velocity': Array(-71.407616, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.6544, dtype=float32), 'eval/episode_distance_reward_std': Array(2.716167, dtype=float32), 'eval/episode_forward_reward_std': Array(452.6928, dtype=float32), 'eval/episode_reward_std': Array(447.50064, dtype=float32), 'eval/episode_reward_alive_std': Array(106.25989, dtype=float32), 'eval/episode_reward_linvel_std': Array(452.6928, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.893646, dtype=float32), 'eval/episode_x_position_std': Array(378.00522, dtype=float32), 'eval/episode_x_velocity_std': Array(90.53856, dtype=float32), 'eval/episode_y_position_std': Array(214.80614, dtype=float32), 'eval/episode_y_velocity_std': Array(50.40332, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32620406150818, 'eval/sps': 938.9244047479564, 'num_steps': 20561920}
{'eval/walltime': 34566.64992642403, 'training/sps': 2942.8763873988464, 'training/walltime': 7040.879555225372, 'training/entropy_loss': Array(0.00828445, dtype=float32), 'training/policy_loss': Array(0.00399845, dtype=float32), 'training/total_loss': Array(0.09103169, dtype=float32), 'training/v_loss': Array(0.07874878, dtype=float32), 'eval/episode_distance_from_origin': Array(4195.6997, dtype=float32), 'eval/episode_distance_reward': Array(7.1214924, dtype=float32), 'eval/episode_forward_reward': Array(1186.9137, dtype=float32), 'eval/episode_reward': Array(1306.752, dtype=float32), 'eval/episode_reward_alive': Array(407.27344, dtype=float32), 'eval/episode_reward_linvel': Array(1186.9137, dtype=float32), 'eval/episode_reward_quadctrl': Array(-294.55673, dtype=float32), 'eval/episode_x_position': Array(4145.6406, dtype=float32), 'eval/episode_x_velocity': Array(237.38275, dtype=float32), 'eval/episode_y_position': Array(-338.9934, dtype=float32), 'eval/episode_y_velocity': Array(-76.76851, dtype=float32), 'eval/episode_distance_from_origin_std': Array(394.84763, dtype=float32), 'eval/episode_distance_reward_std': Array(3.112708, dtype=float32), 'eval/episode_forward_reward_std': Array(518.7823, dtype=float32), 'eval/episode_reward_std': Array(490.17798, dtype=float32), 'eval/episode_reward_alive_std': Array(91.5292, dtype=float32), 'eval/episode_reward_linvel_std': Array(518.7823, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.577507, dtype=float32), 'eval/episode_x_position_std': Array(383.7048, dtype=float32), 'eval/episode_x_velocity_std': Array(103.756485, dtype=float32), 'eval/episode_y_position_std': Array(208.08377, dtype=float32), 'eval/episode_y_velocity_std': Array(52.709576, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1647572517395, 'eval/sps': 940.0376616054577, 'num_steps': 20643840}
{'eval/walltime': 34702.97146034241, 'training/sps': 2945.767717708188, 'training/walltime': 7068.688944101334, 'training/entropy_loss': Array(0.00328956, dtype=float32), 'training/policy_loss': Array(0.00109303, dtype=float32), 'training/total_loss': Array(0.0275008, dtype=float32), 'training/v_loss': Array(0.02311821, dtype=float32), 'eval/episode_distance_from_origin': Array(4187.8877, dtype=float32), 'eval/episode_distance_reward': Array(7.00216, dtype=float32), 'eval/episode_forward_reward': Array(1167.025, dtype=float32), 'eval/episode_reward': Array(1302.6082, dtype=float32), 'eval/episode_reward_alive': Array(417.89844, dtype=float32), 'eval/episode_reward_linvel': Array(1167.025, dtype=float32), 'eval/episode_reward_quadctrl': Array(-289.31747, dtype=float32), 'eval/episode_x_position': Array(4142.42, dtype=float32), 'eval/episode_x_velocity': Array(233.40503, dtype=float32), 'eval/episode_y_position': Array(-282.35873, dtype=float32), 'eval/episode_y_velocity': Array(-62.325966, dtype=float32), 'eval/episode_distance_from_origin_std': Array(370.72873, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8829272, dtype=float32), 'eval/episode_forward_reward_std': Array(480.4853, dtype=float32), 'eval/episode_reward_std': Array(462.74792, dtype=float32), 'eval/episode_reward_alive_std': Array(92.53855, dtype=float32), 'eval/episode_reward_linvel_std': Array(480.4853, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.3367, dtype=float32), 'eval/episode_x_position_std': Array(365.46967, dtype=float32), 'eval/episode_x_velocity_std': Array(96.09705, dtype=float32), 'eval/episode_y_position_std': Array(204.17279, dtype=float32), 'eval/episode_y_velocity_std': Array(47.592846, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32153391838074, 'eval/sps': 938.9565706958443, 'num_steps': 20725760}
{'eval/walltime': 34839.12764215469, 'training/sps': 2942.5685856213736, 'training/walltime': 7096.528567075729, 'training/entropy_loss': Array(0.00196273, dtype=float32), 'training/policy_loss': Array(-0.00499545, dtype=float32), 'training/total_loss': Array(0.00099622, dtype=float32), 'training/v_loss': Array(0.00402893, dtype=float32), 'eval/episode_distance_from_origin': Array(4073.7046, dtype=float32), 'eval/episode_distance_reward': Array(6.150816, dtype=float32), 'eval/episode_forward_reward': Array(1025.135, dtype=float32), 'eval/episode_reward': Array(1189.5726, dtype=float32), 'eval/episode_reward_alive': Array(438.4375, dtype=float32), 'eval/episode_reward_linvel': Array(1025.135, dtype=float32), 'eval/episode_reward_quadctrl': Array(-280.1507, dtype=float32), 'eval/episode_x_position': Array(4031.1665, dtype=float32), 'eval/episode_x_velocity': Array(205.02701, dtype=float32), 'eval/episode_y_position': Array(-270.23273, dtype=float32), 'eval/episode_y_velocity': Array(-57.31253, dtype=float32), 'eval/episode_distance_from_origin_std': Array(296.30096, dtype=float32), 'eval/episode_distance_reward_std': Array(2.1759472, dtype=float32), 'eval/episode_forward_reward_std': Array(362.65656, dtype=float32), 'eval/episode_reward_std': Array(352.73254, dtype=float32), 'eval/episode_reward_alive_std': Array(60.42554, dtype=float32), 'eval/episode_reward_linvel_std': Array(362.65656, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.320675, dtype=float32), 'eval/episode_x_position_std': Array(291.99472, dtype=float32), 'eval/episode_x_velocity_std': Array(72.531334, dtype=float32), 'eval/episode_y_position_std': Array(142.63829, dtype=float32), 'eval/episode_y_velocity_std': Array(31.212585, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.15618181228638, 'eval/sps': 940.0968674082606, 'num_steps': 20807680}
{'eval/walltime': 34975.45064711571, 'training/sps': 2948.724050354944, 'training/walltime': 7124.310074806213, 'training/entropy_loss': Array(0.0017634, dtype=float32), 'training/policy_loss': Array(-0.01540627, dtype=float32), 'training/total_loss': Array(-0.0125912, dtype=float32), 'training/v_loss': Array(0.00105168, dtype=float32), 'eval/episode_distance_from_origin': Array(4029.061, dtype=float32), 'eval/episode_distance_reward': Array(5.985261, dtype=float32), 'eval/episode_forward_reward': Array(997.54236, dtype=float32), 'eval/episode_reward': Array(1138.5303, dtype=float32), 'eval/episode_reward_alive': Array(423.0664, dtype=float32), 'eval/episode_reward_linvel': Array(997.54236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.06372, dtype=float32), 'eval/episode_x_position': Array(3984.7092, dtype=float32), 'eval/episode_x_velocity': Array(199.50847, dtype=float32), 'eval/episode_y_position': Array(-272.20667, dtype=float32), 'eval/episode_y_velocity': Array(-59.265377, dtype=float32), 'eval/episode_distance_from_origin_std': Array(307.7149, dtype=float32), 'eval/episode_distance_reward_std': Array(2.6112568, dtype=float32), 'eval/episode_forward_reward_std': Array(435.20712, dtype=float32), 'eval/episode_reward_std': Array(430.38013, dtype=float32), 'eval/episode_reward_alive_std': Array(88.70514, dtype=float32), 'eval/episode_reward_linvel_std': Array(435.20712, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.123, dtype=float32), 'eval/episode_x_position_std': Array(299.55334, dtype=float32), 'eval/episode_x_velocity_std': Array(87.04146, dtype=float32), 'eval/episode_y_position_std': Array(169.67973, dtype=float32), 'eval/episode_y_velocity_std': Array(40.116222, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3230049610138, 'eval/sps': 938.9464385457609, 'num_steps': 20889600}
{'eval/walltime': 35111.70550465584, 'training/sps': 2950.067737282104, 'training/walltime': 7152.07892870903, 'training/entropy_loss': Array(0.00173856, dtype=float32), 'training/policy_loss': Array(-0.02494285, dtype=float32), 'training/total_loss': Array(-0.02256547, dtype=float32), 'training/v_loss': Array(0.00063882, dtype=float32), 'eval/episode_distance_from_origin': Array(3919.274, dtype=float32), 'eval/episode_distance_reward': Array(5.2669177, dtype=float32), 'eval/episode_forward_reward': Array(877.8188, dtype=float32), 'eval/episode_reward': Array(1035.4343, dtype=float32), 'eval/episode_reward_alive': Array(436.2422, dtype=float32), 'eval/episode_reward_linvel': Array(877.8188, dtype=float32), 'eval/episode_reward_quadctrl': Array(-283.89365, dtype=float32), 'eval/episode_x_position': Array(3877.1406, dtype=float32), 'eval/episode_x_velocity': Array(175.56375, dtype=float32), 'eval/episode_y_position': Array(-229.12263, dtype=float32), 'eval/episode_y_velocity': Array(-49.35619, dtype=float32), 'eval/episode_distance_from_origin_std': Array(218.4866, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7910331, dtype=float32), 'eval/episode_forward_reward_std': Array(298.5042, dtype=float32), 'eval/episode_reward_std': Array(308.28125, dtype=float32), 'eval/episode_reward_alive_std': Array(80.01155, dtype=float32), 'eval/episode_reward_linvel_std': Array(298.5042, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.147022, dtype=float32), 'eval/episode_x_position_std': Array(217.02512, dtype=float32), 'eval/episode_x_velocity_std': Array(59.70086, dtype=float32), 'eval/episode_y_position_std': Array(151.81573, dtype=float32), 'eval/episode_y_velocity_std': Array(34.96832, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25485754013062, 'eval/sps': 939.416049532771, 'num_steps': 20971520}
{'eval/walltime': 35248.10883831978, 'training/sps': 2942.66356809941, 'training/walltime': 7179.917653083801, 'training/entropy_loss': Array(0.00647816, dtype=float32), 'training/policy_loss': Array(0.00183403, dtype=float32), 'training/total_loss': Array(0.07052335, dtype=float32), 'training/v_loss': Array(0.06221118, dtype=float32), 'eval/episode_distance_from_origin': Array(4020.4229, dtype=float32), 'eval/episode_distance_reward': Array(5.9051704, dtype=float32), 'eval/episode_forward_reward': Array(984.19385, dtype=float32), 'eval/episode_reward': Array(1122.8757, dtype=float32), 'eval/episode_reward_alive': Array(421.13672, dtype=float32), 'eval/episode_reward_linvel': Array(984.19385, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.35995, dtype=float32), 'eval/episode_x_position': Array(3973.441, dtype=float32), 'eval/episode_x_velocity': Array(196.83878, dtype=float32), 'eval/episode_y_position': Array(-292.21014, dtype=float32), 'eval/episode_y_velocity': Array(-62.395603, dtype=float32), 'eval/episode_distance_from_origin_std': Array(314.8336, dtype=float32), 'eval/episode_distance_reward_std': Array(2.6064415, dtype=float32), 'eval/episode_forward_reward_std': Array(434.40488, dtype=float32), 'eval/episode_reward_std': Array(426.35577, dtype=float32), 'eval/episode_reward_alive_std': Array(91.759254, dtype=float32), 'eval/episode_reward_linvel_std': Array(434.40488, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.735844, dtype=float32), 'eval/episode_x_position_std': Array(305.02548, dtype=float32), 'eval/episode_x_velocity_std': Array(86.88098, dtype=float32), 'eval/episode_y_position_std': Array(189.74094, dtype=float32), 'eval/episode_y_velocity_std': Array(47.118626, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40333366394043, 'eval/sps': 938.393487620736, 'num_steps': 21053440}
{'eval/walltime': 35384.503121852875, 'training/sps': 2953.6392588203616, 'training/walltime': 7207.652929067612, 'training/entropy_loss': Array(0.01036558, dtype=float32), 'training/policy_loss': Array(0.00361729, dtype=float32), 'training/total_loss': Array(0.10275203, dtype=float32), 'training/v_loss': Array(0.08876916, dtype=float32), 'eval/episode_distance_from_origin': Array(4002.5925, dtype=float32), 'eval/episode_distance_reward': Array(5.72252, dtype=float32), 'eval/episode_forward_reward': Array(953.75244, dtype=float32), 'eval/episode_reward': Array(1113.8276, dtype=float32), 'eval/episode_reward_alive': Array(438.97266, dtype=float32), 'eval/episode_reward_linvel': Array(953.75244, dtype=float32), 'eval/episode_reward_quadctrl': Array(-284.6203, dtype=float32), 'eval/episode_x_position': Array(3957.3975, dtype=float32), 'eval/episode_x_velocity': Array(190.75046, dtype=float32), 'eval/episode_y_position': Array(-280.44778, dtype=float32), 'eval/episode_y_velocity': Array(-60.56119, dtype=float32), 'eval/episode_distance_from_origin_std': Array(251.12268, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8529016, dtype=float32), 'eval/episode_forward_reward_std': Array(308.81607, dtype=float32), 'eval/episode_reward_std': Array(308.3551, dtype=float32), 'eval/episode_reward_alive_std': Array(77.56117, dtype=float32), 'eval/episode_reward_linvel_std': Array(308.81607, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.35046, dtype=float32), 'eval/episode_x_position_std': Array(246.87471, dtype=float32), 'eval/episode_x_velocity_std': Array(61.76319, dtype=float32), 'eval/episode_y_position_std': Array(158.54007, dtype=float32), 'eval/episode_y_velocity_std': Array(36.82267, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3942835330963, 'eval/sps': 938.4557525751479, 'num_steps': 21135360}
{'eval/walltime': 35520.87866663933, 'training/sps': 2958.002973969221, 'training/walltime': 7235.347289323807, 'training/entropy_loss': Array(0.00387421, dtype=float32), 'training/policy_loss': Array(-0.00032033, dtype=float32), 'training/total_loss': Array(0.02255899, dtype=float32), 'training/v_loss': Array(0.01900511, dtype=float32), 'eval/episode_distance_from_origin': Array(3991.1035, dtype=float32), 'eval/episode_distance_reward': Array(5.694281, dtype=float32), 'eval/episode_forward_reward': Array(949.04553, dtype=float32), 'eval/episode_reward': Array(1105.3594, dtype=float32), 'eval/episode_reward_alive': Array(435.90234, dtype=float32), 'eval/episode_reward_linvel': Array(949.04553, dtype=float32), 'eval/episode_reward_quadctrl': Array(-285.2827, dtype=float32), 'eval/episode_x_position': Array(3947.601, dtype=float32), 'eval/episode_x_velocity': Array(189.80913, dtype=float32), 'eval/episode_y_position': Array(-247.71976, dtype=float32), 'eval/episode_y_velocity': Array(-52.90674, dtype=float32), 'eval/episode_distance_from_origin_std': Array(315.41077, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4839869, dtype=float32), 'eval/episode_forward_reward_std': Array(413.99576, dtype=float32), 'eval/episode_reward_std': Array(422.02475, dtype=float32), 'eval/episode_reward_alive_std': Array(78.66804, dtype=float32), 'eval/episode_reward_linvel_std': Array(413.99576, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.556595, dtype=float32), 'eval/episode_x_position_std': Array(311.35715, dtype=float32), 'eval/episode_x_velocity_std': Array(82.79918, dtype=float32), 'eval/episode_y_position_std': Array(176.23056, dtype=float32), 'eval/episode_y_velocity_std': Array(39.037403, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37554478645325, 'eval/sps': 938.5847015345142, 'num_steps': 21217280}
{'eval/walltime': 35657.30103611946, 'training/sps': 2956.427720152333, 'training/walltime': 7263.0564057827, 'training/entropy_loss': Array(0.00256253, dtype=float32), 'training/policy_loss': Array(-0.00327495, dtype=float32), 'training/total_loss': Array(0.00455412, dtype=float32), 'training/v_loss': Array(0.00526654, dtype=float32), 'eval/episode_distance_from_origin': Array(4022.8638, dtype=float32), 'eval/episode_distance_reward': Array(5.93888, dtype=float32), 'eval/episode_forward_reward': Array(989.812, dtype=float32), 'eval/episode_reward': Array(1155.4929, dtype=float32), 'eval/episode_reward_alive': Array(435.19922, dtype=float32), 'eval/episode_reward_linvel': Array(989.812, dtype=float32), 'eval/episode_reward_quadctrl': Array(-275.45718, dtype=float32), 'eval/episode_x_position': Array(3980.4248, dtype=float32), 'eval/episode_x_velocity': Array(197.9624, dtype=float32), 'eval/episode_y_position': Array(-235.4434, dtype=float32), 'eval/episode_y_velocity': Array(-51.118256, dtype=float32), 'eval/episode_distance_from_origin_std': Array(308.87128, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4468572, dtype=float32), 'eval/episode_forward_reward_std': Array(407.80737, dtype=float32), 'eval/episode_reward_std': Array(405.7052, dtype=float32), 'eval/episode_reward_alive_std': Array(84.715454, dtype=float32), 'eval/episode_reward_linvel_std': Array(407.80737, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.595623, dtype=float32), 'eval/episode_x_position_std': Array(306.17795, dtype=float32), 'eval/episode_x_velocity_std': Array(81.56149, dtype=float32), 'eval/episode_y_position_std': Array(172.36713, dtype=float32), 'eval/episode_y_velocity_std': Array(39.368233, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42236948013306, 'eval/sps': 938.2625480540448, 'num_steps': 21299200}
{'eval/walltime': 35793.656279563904, 'training/sps': 2969.1495895050307, 'training/walltime': 7290.646797418594, 'training/entropy_loss': Array(0.00229218, dtype=float32), 'training/policy_loss': Array(-0.00469604, dtype=float32), 'training/total_loss': Array(-3.8886268e-05, dtype=float32), 'training/v_loss': Array(0.00236498, dtype=float32), 'eval/episode_distance_from_origin': Array(3974.803, dtype=float32), 'eval/episode_distance_reward': Array(5.7700768, dtype=float32), 'eval/episode_forward_reward': Array(961.6786, dtype=float32), 'eval/episode_reward': Array(1125.5901, dtype=float32), 'eval/episode_reward_alive': Array(435.3203, dtype=float32), 'eval/episode_reward_linvel': Array(961.6786, dtype=float32), 'eval/episode_reward_quadctrl': Array(-277.17883, dtype=float32), 'eval/episode_x_position': Array(3934.7183, dtype=float32), 'eval/episode_x_velocity': Array(192.33572, dtype=float32), 'eval/episode_y_position': Array(-185.97818, dtype=float32), 'eval/episode_y_velocity': Array(-40.326126, dtype=float32), 'eval/episode_distance_from_origin_std': Array(300.29733, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7554603, dtype=float32), 'eval/episode_forward_reward_std': Array(459.24182, dtype=float32), 'eval/episode_reward_std': Array(459.39957, dtype=float32), 'eval/episode_reward_alive_std': Array(86.53137, dtype=float32), 'eval/episode_reward_linvel_std': Array(459.24182, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.901085, dtype=float32), 'eval/episode_x_position_std': Array(296.11307, dtype=float32), 'eval/episode_x_velocity_std': Array(91.84833, dtype=float32), 'eval/episode_y_position_std': Array(170.74321, dtype=float32), 'eval/episode_y_velocity_std': Array(43.366837, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35524344444275, 'eval/sps': 938.7244433482526, 'num_steps': 21381120}
{'eval/walltime': 35930.26377129555, 'training/sps': 2960.505110821959, 'training/walltime': 7318.317751169205, 'training/entropy_loss': Array(0.00216444, dtype=float32), 'training/policy_loss': Array(-0.01401642, dtype=float32), 'training/total_loss': Array(-0.01090223, dtype=float32), 'training/v_loss': Array(0.00094975, dtype=float32), 'eval/episode_distance_from_origin': Array(3905.2192, dtype=float32), 'eval/episode_distance_reward': Array(5.2361026, dtype=float32), 'eval/episode_forward_reward': Array(872.68384, dtype=float32), 'eval/episode_reward': Array(1060.1987, dtype=float32), 'eval/episode_reward_alive': Array(450.6289, dtype=float32), 'eval/episode_reward_linvel': Array(872.68384, dtype=float32), 'eval/episode_reward_quadctrl': Array(-268.35007, dtype=float32), 'eval/episode_x_position': Array(3868.558, dtype=float32), 'eval/episode_x_velocity': Array(174.53671, dtype=float32), 'eval/episode_y_position': Array(-128.48477, dtype=float32), 'eval/episode_y_velocity': Array(-28.045343, dtype=float32), 'eval/episode_distance_from_origin_std': Array(200.92416, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8769891, dtype=float32), 'eval/episode_forward_reward_std': Array(312.83078, dtype=float32), 'eval/episode_reward_std': Array(310.89276, dtype=float32), 'eval/episode_reward_alive_std': Array(68.44743, dtype=float32), 'eval/episode_reward_linvel_std': Array(312.83078, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.017788, dtype=float32), 'eval/episode_x_position_std': Array(199.75876, dtype=float32), 'eval/episode_x_velocity_std': Array(62.566116, dtype=float32), 'eval/episode_y_position_std': Array(135.42737, dtype=float32), 'eval/episode_y_velocity_std': Array(32.198334, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60749173164368, 'eval/sps': 936.9910711152465, 'num_steps': 21463040}
{'eval/walltime': 36066.63381195068, 'training/sps': 2965.826151925377, 'training/walltime': 7345.939059972763, 'training/entropy_loss': Array(0.00443859, dtype=float32), 'training/policy_loss': Array(-0.00560205, dtype=float32), 'training/total_loss': Array(0.01234754, dtype=float32), 'training/v_loss': Array(0.01351101, dtype=float32), 'eval/episode_distance_from_origin': Array(3986.5464, dtype=float32), 'eval/episode_distance_reward': Array(5.5690923, dtype=float32), 'eval/episode_forward_reward': Array(928.18176, dtype=float32), 'eval/episode_reward': Array(1127.6825, dtype=float32), 'eval/episode_reward_alive': Array(456.16016, dtype=float32), 'eval/episode_reward_linvel': Array(928.18176, dtype=float32), 'eval/episode_reward_quadctrl': Array(-262.2285, dtype=float32), 'eval/episode_x_position': Array(3947.9644, dtype=float32), 'eval/episode_x_velocity': Array(185.63635, dtype=float32), 'eval/episode_y_position': Array(-193.40411, dtype=float32), 'eval/episode_y_velocity': Array(-40.67973, dtype=float32), 'eval/episode_distance_from_origin_std': Array(268.34122, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9846903, dtype=float32), 'eval/episode_forward_reward_std': Array(330.78027, dtype=float32), 'eval/episode_reward_std': Array(330.541, dtype=float32), 'eval/episode_reward_alive_std': Array(60.97745, dtype=float32), 'eval/episode_reward_linvel_std': Array(330.78027, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.185453, dtype=float32), 'eval/episode_x_position_std': Array(265.80014, dtype=float32), 'eval/episode_x_velocity_std': Array(66.15607, dtype=float32), 'eval/episode_y_position_std': Array(136.96745, dtype=float32), 'eval/episode_y_velocity_std': Array(28.475952, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3700406551361, 'eval/sps': 938.6225844406473, 'num_steps': 21544960}
{'eval/walltime': 36203.24193882942, 'training/sps': 2961.1298137222298, 'training/walltime': 7373.604176044464, 'training/entropy_loss': Array(0.01099239, dtype=float32), 'training/policy_loss': Array(0.00552574, dtype=float32), 'training/total_loss': Array(0.10823236, dtype=float32), 'training/v_loss': Array(0.09171423, dtype=float32), 'eval/episode_distance_from_origin': Array(4105.9316, dtype=float32), 'eval/episode_distance_reward': Array(6.4858427, dtype=float32), 'eval/episode_forward_reward': Array(1080.9725, dtype=float32), 'eval/episode_reward': Array(1266.1305, dtype=float32), 'eval/episode_reward_alive': Array(442.88672, dtype=float32), 'eval/episode_reward_linvel': Array(1080.9725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-264.21454, dtype=float32), 'eval/episode_x_position': Array(4066.3003, dtype=float32), 'eval/episode_x_velocity': Array(216.19449, dtype=float32), 'eval/episode_y_position': Array(-206.24872, dtype=float32), 'eval/episode_y_velocity': Array(-46.710426, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.37503, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0514789, dtype=float32), 'eval/episode_forward_reward_std': Array(508.57687, dtype=float32), 'eval/episode_reward_std': Array(491.6138, dtype=float32), 'eval/episode_reward_alive_std': Array(75.90751, dtype=float32), 'eval/episode_reward_linvel_std': Array(508.57687, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.351166, dtype=float32), 'eval/episode_x_position_std': Array(372.31964, dtype=float32), 'eval/episode_x_velocity_std': Array(101.71534, dtype=float32), 'eval/episode_y_position_std': Array(162.78548, dtype=float32), 'eval/episode_y_velocity_std': Array(39.18807, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6081268787384, 'eval/sps': 936.9867146602522, 'num_steps': 21626880}
{'eval/walltime': 36339.61558556557, 'training/sps': 2966.424546794046, 'training/walltime': 7401.219913005829, 'training/entropy_loss': Array(0.00419355, dtype=float32), 'training/policy_loss': Array(0.00088991, dtype=float32), 'training/total_loss': Array(0.03141288, dtype=float32), 'training/v_loss': Array(0.02632941, dtype=float32), 'eval/episode_distance_from_origin': Array(4019.0525, dtype=float32), 'eval/episode_distance_reward': Array(5.928868, dtype=float32), 'eval/episode_forward_reward': Array(988.1439, dtype=float32), 'eval/episode_reward': Array(1191.823, dtype=float32), 'eval/episode_reward_alive': Array(460.78906, dtype=float32), 'eval/episode_reward_linvel': Array(988.1439, dtype=float32), 'eval/episode_reward_quadctrl': Array(-263.0388, dtype=float32), 'eval/episode_x_position': Array(3979.0786, dtype=float32), 'eval/episode_x_velocity': Array(197.62875, dtype=float32), 'eval/episode_y_position': Array(-193.35632, dtype=float32), 'eval/episode_y_velocity': Array(-42.924137, dtype=float32), 'eval/episode_distance_from_origin_std': Array(321.8553, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7861605, dtype=float32), 'eval/episode_forward_reward_std': Array(464.35782, dtype=float32), 'eval/episode_reward_std': Array(436.4449, dtype=float32), 'eval/episode_reward_alive_std': Array(61.705055, dtype=float32), 'eval/episode_reward_linvel_std': Array(464.35782, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.314598, dtype=float32), 'eval/episode_x_position_std': Array(316.07047, dtype=float32), 'eval/episode_x_velocity_std': Array(92.87152, dtype=float32), 'eval/episode_y_position_std': Array(174.3019, dtype=float32), 'eval/episode_y_velocity_std': Array(40.404026, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37364673614502, 'eval/sps': 938.5977647694184, 'num_steps': 21708800}
{'eval/walltime': 36476.21867728233, 'training/sps': 2961.4315565723405, 'training/walltime': 7428.882210254669, 'training/entropy_loss': Array(0.00274509, dtype=float32), 'training/policy_loss': Array(0.00592896, dtype=float32), 'training/total_loss': Array(0.01771904, dtype=float32), 'training/v_loss': Array(0.00904498, dtype=float32), 'eval/episode_distance_from_origin': Array(4036.0083, dtype=float32), 'eval/episode_distance_reward': Array(6.1310916, dtype=float32), 'eval/episode_forward_reward': Array(1021.8481, dtype=float32), 'eval/episode_reward': Array(1233.9988, dtype=float32), 'eval/episode_reward_alive': Array(468., dtype=float32), 'eval/episode_reward_linvel': Array(1021.8481, dtype=float32), 'eval/episode_reward_quadctrl': Array(-261.98026, dtype=float32), 'eval/episode_x_position': Array(3996.1167, dtype=float32), 'eval/episode_x_velocity': Array(204.36957, dtype=float32), 'eval/episode_y_position': Array(-181.48843, dtype=float32), 'eval/episode_y_velocity': Array(-41.3042, dtype=float32), 'eval/episode_distance_from_origin_std': Array(326.81042, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9787464, dtype=float32), 'eval/episode_forward_reward_std': Array(496.45578, dtype=float32), 'eval/episode_reward_std': Array(467.61588, dtype=float32), 'eval/episode_reward_alive_std': Array(25.845997, dtype=float32), 'eval/episode_reward_linvel_std': Array(496.45578, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.819336, dtype=float32), 'eval/episode_x_position_std': Array(321.83075, dtype=float32), 'eval/episode_x_velocity_std': Array(99.29113, dtype=float32), 'eval/episode_y_position_std': Array(172.7358, dtype=float32), 'eval/episode_y_velocity_std': Array(44.09331, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60309171676636, 'eval/sps': 937.0212517985752, 'num_steps': 21790720}
{'eval/walltime': 36612.52976560593, 'training/sps': 2949.584847321295, 'training/walltime': 7456.655610322952, 'training/entropy_loss': Array(0.00254024, dtype=float32), 'training/policy_loss': Array(-0.00214672, dtype=float32), 'training/total_loss': Array(0.00387491, dtype=float32), 'training/v_loss': Array(0.00348139, dtype=float32), 'eval/episode_distance_from_origin': Array(3993.2231, dtype=float32), 'eval/episode_distance_reward': Array(5.9644566, dtype=float32), 'eval/episode_forward_reward': Array(994.07556, dtype=float32), 'eval/episode_reward': Array(1202.6256, dtype=float32), 'eval/episode_reward_alive': Array(469.48047, dtype=float32), 'eval/episode_reward_linvel': Array(994.07556, dtype=float32), 'eval/episode_reward_quadctrl': Array(-266.89496, dtype=float32), 'eval/episode_x_position': Array(3954.814, dtype=float32), 'eval/episode_x_velocity': Array(198.8151, dtype=float32), 'eval/episode_y_position': Array(-128.6766, dtype=float32), 'eval/episode_y_velocity': Array(-33.171688, dtype=float32), 'eval/episode_distance_from_origin_std': Array(335.14648, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2752213, dtype=float32), 'eval/episode_forward_reward_std': Array(545.8679, dtype=float32), 'eval/episode_reward_std': Array(516.9894, dtype=float32), 'eval/episode_reward_alive_std': Array(41.404133, dtype=float32), 'eval/episode_reward_linvel_std': Array(545.8679, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.69952, dtype=float32), 'eval/episode_x_position_std': Array(332.41833, dtype=float32), 'eval/episode_x_velocity_std': Array(109.17359, dtype=float32), 'eval/episode_y_position_std': Array(180.25945, dtype=float32), 'eval/episode_y_velocity_std': Array(47.95918, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31108832359314, 'eval/sps': 939.0285234619859, 'num_steps': 21872640}
{'eval/walltime': 36749.05903315544, 'training/sps': 2951.7748199268344, 'training/walltime': 7484.408404827118, 'training/entropy_loss': Array(0.00246743, dtype=float32), 'training/policy_loss': Array(-0.01282364, dtype=float32), 'training/total_loss': Array(-0.00867389, dtype=float32), 'training/v_loss': Array(0.00168231, dtype=float32), 'eval/episode_distance_from_origin': Array(4008.729, dtype=float32), 'eval/episode_distance_reward': Array(6.0807223, dtype=float32), 'eval/episode_forward_reward': Array(1013.45294, dtype=float32), 'eval/episode_reward': Array(1230.713, dtype=float32), 'eval/episode_reward_alive': Array(471.01953, dtype=float32), 'eval/episode_reward_linvel': Array(1013.45294, dtype=float32), 'eval/episode_reward_quadctrl': Array(-259.84027, dtype=float32), 'eval/episode_x_position': Array(3970.6519, dtype=float32), 'eval/episode_x_velocity': Array(202.69061, dtype=float32), 'eval/episode_y_position': Array(-112.00838, dtype=float32), 'eval/episode_y_velocity': Array(-28.061665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(408.62802, dtype=float32), 'eval/episode_distance_reward_std': Array(3.5701854, dtype=float32), 'eval/episode_forward_reward_std': Array(595.0269, dtype=float32), 'eval/episode_reward_std': Array(558.13367, dtype=float32), 'eval/episode_reward_alive_std': Array(24.777401, dtype=float32), 'eval/episode_reward_linvel_std': Array(595.0269, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.89617, dtype=float32), 'eval/episode_x_position_std': Array(403.62094, dtype=float32), 'eval/episode_x_velocity_std': Array(119.00541, dtype=float32), 'eval/episode_y_position_std': Array(184.75276, dtype=float32), 'eval/episode_y_velocity_std': Array(47.026676, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52926754951477, 'eval/sps': 937.5279183533195, 'num_steps': 21954560}
{'eval/walltime': 36885.55660510063, 'training/sps': 2958.959068853616, 'training/walltime': 7512.093816518784, 'training/entropy_loss': Array(0.00265845, dtype=float32), 'training/policy_loss': Array(-0.0080647, dtype=float32), 'training/total_loss': Array(0.00570226, dtype=float32), 'training/v_loss': Array(0.0111085, dtype=float32), 'eval/episode_distance_from_origin': Array(4140.0166, dtype=float32), 'eval/episode_distance_reward': Array(7.3750057, dtype=float32), 'eval/episode_forward_reward': Array(1229.166, dtype=float32), 'eval/episode_reward': Array(1431.13, dtype=float32), 'eval/episode_reward_alive': Array(460.54688, dtype=float32), 'eval/episode_reward_linvel': Array(1229.166, dtype=float32), 'eval/episode_reward_quadctrl': Array(-265.95767, dtype=float32), 'eval/episode_x_position': Array(4100.658, dtype=float32), 'eval/episode_x_velocity': Array(245.83319, dtype=float32), 'eval/episode_y_position': Array(-140.9316, dtype=float32), 'eval/episode_y_velocity': Array(-38.09175, dtype=float32), 'eval/episode_distance_from_origin_std': Array(415.314, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2723126, dtype=float32), 'eval/episode_forward_reward_std': Array(712.04767, dtype=float32), 'eval/episode_reward_std': Array(660.8873, dtype=float32), 'eval/episode_reward_alive_std': Array(50.039803, dtype=float32), 'eval/episode_reward_linvel_std': Array(712.04767, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.17954, dtype=float32), 'eval/episode_x_position_std': Array(412.358, dtype=float32), 'eval/episode_x_velocity_std': Array(142.4095, dtype=float32), 'eval/episode_y_position_std': Array(196.49556, dtype=float32), 'eval/episode_y_velocity_std': Array(55.248486, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49757194519043, 'eval/sps': 937.7456182985983, 'num_steps': 22036480}
{'eval/walltime': 37022.074180841446, 'training/sps': 2950.6514783215675, 'training/walltime': 7539.857176780701, 'training/entropy_loss': Array(0.01083214, dtype=float32), 'training/policy_loss': Array(0.00359151, dtype=float32), 'training/total_loss': Array(0.10653748, dtype=float32), 'training/v_loss': Array(0.09211382, dtype=float32), 'eval/episode_distance_from_origin': Array(4341.248, dtype=float32), 'eval/episode_distance_reward': Array(8.82337, dtype=float32), 'eval/episode_forward_reward': Array(1470.5585, dtype=float32), 'eval/episode_reward': Array(1653.7043, dtype=float32), 'eval/episode_reward_alive': Array(451.80078, dtype=float32), 'eval/episode_reward_linvel': Array(1470.5585, dtype=float32), 'eval/episode_reward_quadctrl': Array(-277.47833, dtype=float32), 'eval/episode_x_position': Array(4301.3564, dtype=float32), 'eval/episode_x_velocity': Array(294.1117, dtype=float32), 'eval/episode_y_position': Array(-188.69572, dtype=float32), 'eval/episode_y_velocity': Array(-52.144615, dtype=float32), 'eval/episode_distance_from_origin_std': Array(520.2783, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7013984, dtype=float32), 'eval/episode_forward_reward_std': Array(783.5614, dtype=float32), 'eval/episode_reward_std': Array(723.88855, dtype=float32), 'eval/episode_reward_alive_std': Array(49.40538, dtype=float32), 'eval/episode_reward_linvel_std': Array(783.5614, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.87596, dtype=float32), 'eval/episode_x_position_std': Array(515.86487, dtype=float32), 'eval/episode_x_velocity_std': Array(156.71234, dtype=float32), 'eval/episode_y_position_std': Array(200.031, dtype=float32), 'eval/episode_y_velocity_std': Array(55.92213, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5175757408142, 'eval/sps': 937.6082112900593, 'num_steps': 22118400}
{'eval/walltime': 37158.54465460777, 'training/sps': 2950.4888628888198, 'training/walltime': 7567.6220672130585, 'training/entropy_loss': Array(0.00578383, dtype=float32), 'training/policy_loss': Array(0.01036555, dtype=float32), 'training/total_loss': Array(0.07239707, dtype=float32), 'training/v_loss': Array(0.05624769, dtype=float32), 'eval/episode_distance_from_origin': Array(4210.679, dtype=float32), 'eval/episode_distance_reward': Array(8.130899, dtype=float32), 'eval/episode_forward_reward': Array(1355.1475, dtype=float32), 'eval/episode_reward': Array(1549.1465, dtype=float32), 'eval/episode_reward_alive': Array(460.375, dtype=float32), 'eval/episode_reward_linvel': Array(1355.1475, dtype=float32), 'eval/episode_reward_quadctrl': Array(-274.50684, dtype=float32), 'eval/episode_x_position': Array(4171.0894, dtype=float32), 'eval/episode_x_velocity': Array(271.02942, dtype=float32), 'eval/episode_y_position': Array(-140.1658, dtype=float32), 'eval/episode_y_velocity': Array(-43.172398, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.96625, dtype=float32), 'eval/episode_distance_reward_std': Array(4.562757, dtype=float32), 'eval/episode_forward_reward_std': Array(760.45447, dtype=float32), 'eval/episode_reward_std': Array(705.17456, dtype=float32), 'eval/episode_reward_alive_std': Array(32.26005, dtype=float32), 'eval/episode_reward_linvel_std': Array(760.45447, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.549526, dtype=float32), 'eval/episode_x_position_std': Array(428.64682, dtype=float32), 'eval/episode_x_velocity_std': Array(152.09087, dtype=float32), 'eval/episode_y_position_std': Array(200.0972, dtype=float32), 'eval/episode_y_velocity_std': Array(56.515102, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4704737663269, 'eval/sps': 937.9318212023609, 'num_steps': 22200320}
{'eval/walltime': 37295.06990599632, 'training/sps': 2956.6733199780633, 'training/walltime': 7595.328881978989, 'training/entropy_loss': Array(0.00391699, dtype=float32), 'training/policy_loss': Array(0.00350751, dtype=float32), 'training/total_loss': Array(0.03719056, dtype=float32), 'training/v_loss': Array(0.02976606, dtype=float32), 'eval/episode_distance_from_origin': Array(4303.792, dtype=float32), 'eval/episode_distance_reward': Array(8.574135, dtype=float32), 'eval/episode_forward_reward': Array(1429.019, dtype=float32), 'eval/episode_reward': Array(1625.0103, dtype=float32), 'eval/episode_reward_alive': Array(461.3828, dtype=float32), 'eval/episode_reward_linvel': Array(1429.019, dtype=float32), 'eval/episode_reward_quadctrl': Array(-273.9659, dtype=float32), 'eval/episode_x_position': Array(4265.796, dtype=float32), 'eval/episode_x_velocity': Array(285.80383, dtype=float32), 'eval/episode_y_position': Array(-142.63391, dtype=float32), 'eval/episode_y_velocity': Array(-38.582047, dtype=float32), 'eval/episode_distance_from_origin_std': Array(514.2289, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6988826, dtype=float32), 'eval/episode_forward_reward_std': Array(783.14215, dtype=float32), 'eval/episode_reward_std': Array(722.84393, dtype=float32), 'eval/episode_reward_alive_std': Array(35.72412, dtype=float32), 'eval/episode_reward_linvel_std': Array(783.14215, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.007, dtype=float32), 'eval/episode_x_position_std': Array(512.42444, dtype=float32), 'eval/episode_x_velocity_std': Array(156.62846, dtype=float32), 'eval/episode_y_position_std': Array(191.90749, dtype=float32), 'eval/episode_y_velocity_std': Array(49.507565, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5252513885498, 'eval/sps': 937.5554975959209, 'num_steps': 22282240}
{'eval/walltime': 37431.53480219841, 'training/sps': 2956.7799271735084, 'training/walltime': 7623.034697771072, 'training/entropy_loss': Array(0.00342378, dtype=float32), 'training/policy_loss': Array(0.01021056, dtype=float32), 'training/total_loss': Array(0.02907179, dtype=float32), 'training/v_loss': Array(0.01543745, dtype=float32), 'eval/episode_distance_from_origin': Array(4431.302, dtype=float32), 'eval/episode_distance_reward': Array(10.569513, dtype=float32), 'eval/episode_forward_reward': Array(1761.5803, dtype=float32), 'eval/episode_reward': Array(1906.6987, dtype=float32), 'eval/episode_reward_alive': Array(440.21875, dtype=float32), 'eval/episode_reward_linvel': Array(1761.5803, dtype=float32), 'eval/episode_reward_quadctrl': Array(-305.66968, dtype=float32), 'eval/episode_x_position': Array(4389.454, dtype=float32), 'eval/episode_x_velocity': Array(352.31604, dtype=float32), 'eval/episode_y_position': Array(-114.26596, dtype=float32), 'eval/episode_y_velocity': Array(-41.40214, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.17215, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7043495, dtype=float32), 'eval/episode_forward_reward_std': Array(784.05194, dtype=float32), 'eval/episode_reward_std': Array(726.0248, dtype=float32), 'eval/episode_reward_alive_std': Array(51.182987, dtype=float32), 'eval/episode_reward_linvel_std': Array(784.05194, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.413265, dtype=float32), 'eval/episode_x_position_std': Array(462.40762, dtype=float32), 'eval/episode_x_velocity_std': Array(156.8104, dtype=float32), 'eval/episode_y_position_std': Array(255.35188, dtype=float32), 'eval/episode_y_velocity_std': Array(80.971695, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4648962020874, 'eval/sps': 937.9701561524514, 'num_steps': 22364160}
{'eval/walltime': 37568.05507135391, 'training/sps': 2951.7170553202463, 'training/walltime': 7650.788035392761, 'training/entropy_loss': Array(0.00328874, dtype=float32), 'training/policy_loss': Array(-0.00118329, dtype=float32), 'training/total_loss': Array(0.01732346, dtype=float32), 'training/v_loss': Array(0.01521802, dtype=float32), 'eval/episode_distance_from_origin': Array(4432.9414, dtype=float32), 'eval/episode_distance_reward': Array(10.731416, dtype=float32), 'eval/episode_forward_reward': Array(1788.5627, dtype=float32), 'eval/episode_reward': Array(1940.1857, dtype=float32), 'eval/episode_reward_alive': Array(443.6836, dtype=float32), 'eval/episode_reward_linvel': Array(1788.5627, dtype=float32), 'eval/episode_reward_quadctrl': Array(-302.7922, dtype=float32), 'eval/episode_x_position': Array(4393.1064, dtype=float32), 'eval/episode_x_velocity': Array(357.71252, dtype=float32), 'eval/episode_y_position': Array(-135.12846, dtype=float32), 'eval/episode_y_velocity': Array(-50.79898, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.40332, dtype=float32), 'eval/episode_distance_reward_std': Array(4.89814, dtype=float32), 'eval/episode_forward_reward_std': Array(816.3501, dtype=float32), 'eval/episode_reward_std': Array(751.11707, dtype=float32), 'eval/episode_reward_alive_std': Array(37.049843, dtype=float32), 'eval/episode_reward_linvel_std': Array(816.3501, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.82477, dtype=float32), 'eval/episode_x_position_std': Array(476.0475, dtype=float32), 'eval/episode_x_velocity_std': Array(163.27007, dtype=float32), 'eval/episode_y_position_std': Array(214.8134, dtype=float32), 'eval/episode_y_velocity_std': Array(72.435616, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52026915550232, 'eval/sps': 937.5897131744051, 'num_steps': 22446080}
{'eval/walltime': 37704.5255086422, 'training/sps': 2954.347940608625, 'training/walltime': 7678.516658306122, 'training/entropy_loss': Array(0.00329027, dtype=float32), 'training/policy_loss': Array(0.01542787, dtype=float32), 'training/total_loss': Array(0.03151999, dtype=float32), 'training/v_loss': Array(0.01280185, dtype=float32), 'eval/episode_distance_from_origin': Array(4464.3022, dtype=float32), 'eval/episode_distance_reward': Array(11.585108, dtype=float32), 'eval/episode_forward_reward': Array(1930.8431, dtype=float32), 'eval/episode_reward': Array(2039.3192, dtype=float32), 'eval/episode_reward_alive': Array(431.1836, dtype=float32), 'eval/episode_reward_linvel': Array(1930.8431, dtype=float32), 'eval/episode_reward_quadctrl': Array(-334.2927, dtype=float32), 'eval/episode_x_position': Array(4423.636, dtype=float32), 'eval/episode_x_velocity': Array(386.16864, dtype=float32), 'eval/episode_y_position': Array(-67.91258, dtype=float32), 'eval/episode_y_velocity': Array(-30.768997, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.70554, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7315536, dtype=float32), 'eval/episode_forward_reward_std': Array(788.5858, dtype=float32), 'eval/episode_reward_std': Array(729.75793, dtype=float32), 'eval/episode_reward_alive_std': Array(40.082233, dtype=float32), 'eval/episode_reward_linvel_std': Array(788.5858, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.716663, dtype=float32), 'eval/episode_x_position_std': Array(426.22092, dtype=float32), 'eval/episode_x_velocity_std': Array(157.71718, dtype=float32), 'eval/episode_y_position_std': Array(236.66826, dtype=float32), 'eval/episode_y_velocity_std': Array(78.75551, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4704372882843, 'eval/sps': 937.9320719080639, 'num_steps': 22528000}
{'eval/walltime': 37841.04168510437, 'training/sps': 2958.538324216543, 'training/walltime': 7706.206007242203, 'training/entropy_loss': Array(0.0078792, dtype=float32), 'training/policy_loss': Array(0.00216734, dtype=float32), 'training/total_loss': Array(0.10003497, dtype=float32), 'training/v_loss': Array(0.08998844, dtype=float32), 'eval/episode_distance_from_origin': Array(4580.299, dtype=float32), 'eval/episode_distance_reward': Array(12.28696, dtype=float32), 'eval/episode_forward_reward': Array(2047.8176, dtype=float32), 'eval/episode_reward': Array(2155.038, dtype=float32), 'eval/episode_reward_alive': Array(429.84766, dtype=float32), 'eval/episode_reward_linvel': Array(2047.8176, dtype=float32), 'eval/episode_reward_quadctrl': Array(-334.91412, dtype=float32), 'eval/episode_x_position': Array(4539.205, dtype=float32), 'eval/episode_x_velocity': Array(409.56348, dtype=float32), 'eval/episode_y_position': Array(-81.490616, dtype=float32), 'eval/episode_y_velocity': Array(-31.239365, dtype=float32), 'eval/episode_distance_from_origin_std': Array(405.78677, dtype=float32), 'eval/episode_distance_reward_std': Array(4.57658, dtype=float32), 'eval/episode_forward_reward_std': Array(762.7564, dtype=float32), 'eval/episode_reward_std': Array(698.7285, dtype=float32), 'eval/episode_reward_alive_std': Array(31.739145, dtype=float32), 'eval/episode_reward_linvel_std': Array(762.7564, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.568512, dtype=float32), 'eval/episode_x_position_std': Array(404.57166, dtype=float32), 'eval/episode_x_velocity_std': Array(152.5513, dtype=float32), 'eval/episode_y_position_std': Array(255.51941, dtype=float32), 'eval/episode_y_velocity_std': Array(86.30574, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51617646217346, 'eval/sps': 937.617821690654, 'num_steps': 22609920}
{'eval/walltime': 37977.52368426323, 'training/sps': 2960.8232081844326, 'training/walltime': 7733.87398815155, 'training/entropy_loss': Array(0.00986042, dtype=float32), 'training/policy_loss': Array(0.00512338, dtype=float32), 'training/total_loss': Array(0.15042922, dtype=float32), 'training/v_loss': Array(0.13544545, dtype=float32), 'eval/episode_distance_from_origin': Array(4547.793, dtype=float32), 'eval/episode_distance_reward': Array(12.313019, dtype=float32), 'eval/episode_forward_reward': Array(2052.1614, dtype=float32), 'eval/episode_reward': Array(2169.7195, dtype=float32), 'eval/episode_reward_alive': Array(436.54688, dtype=float32), 'eval/episode_reward_linvel': Array(2052.1614, dtype=float32), 'eval/episode_reward_quadctrl': Array(-331.30164, dtype=float32), 'eval/episode_x_position': Array(4507.378, dtype=float32), 'eval/episode_x_velocity': Array(410.43225, dtype=float32), 'eval/episode_y_position': Array(-93.10457, dtype=float32), 'eval/episode_y_velocity': Array(-29.220387, dtype=float32), 'eval/episode_distance_from_origin_std': Array(426.32553, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9583316, dtype=float32), 'eval/episode_forward_reward_std': Array(826.38245, dtype=float32), 'eval/episode_reward_std': Array(767.916, dtype=float32), 'eval/episode_reward_alive_std': Array(29.704365, dtype=float32), 'eval/episode_reward_linvel_std': Array(826.38245, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.57028, dtype=float32), 'eval/episode_x_position_std': Array(426.20032, dtype=float32), 'eval/episode_x_velocity_std': Array(165.27644, dtype=float32), 'eval/episode_y_position_std': Array(231.82013, dtype=float32), 'eval/episode_y_velocity_std': Array(83.886375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48199915885925, 'eval/sps': 937.852616380666, 'num_steps': 22691840}
{'eval/walltime': 38114.04520511627, 'training/sps': 2962.690055449029, 'training/walltime': 7761.52453494072, 'training/entropy_loss': Array(0.00844442, dtype=float32), 'training/policy_loss': Array(0.07003677, dtype=float32), 'training/total_loss': Array(0.17005304, dtype=float32), 'training/v_loss': Array(0.09157184, dtype=float32), 'eval/episode_distance_from_origin': Array(4678.825, dtype=float32), 'eval/episode_distance_reward': Array(12.942255, dtype=float32), 'eval/episode_forward_reward': Array(2157.034, dtype=float32), 'eval/episode_reward': Array(2252.4165, dtype=float32), 'eval/episode_reward_alive': Array(425.78906, dtype=float32), 'eval/episode_reward_linvel': Array(2157.034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-343.3485, dtype=float32), 'eval/episode_x_position': Array(4639.8667, dtype=float32), 'eval/episode_x_velocity': Array(431.4068, dtype=float32), 'eval/episode_y_position': Array(-52.767174, dtype=float32), 'eval/episode_y_velocity': Array(-17.262674, dtype=float32), 'eval/episode_distance_from_origin_std': Array(422.77026, dtype=float32), 'eval/episode_distance_reward_std': Array(5.02846, dtype=float32), 'eval/episode_forward_reward_std': Array(838.0703, dtype=float32), 'eval/episode_reward_std': Array(779.0444, dtype=float32), 'eval/episode_reward_alive_std': Array(45.95228, dtype=float32), 'eval/episode_reward_linvel_std': Array(838.0703, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.78353, dtype=float32), 'eval/episode_x_position_std': Array(422.85306, dtype=float32), 'eval/episode_x_velocity_std': Array(167.61409, dtype=float32), 'eval/episode_y_position_std': Array(241.67862, dtype=float32), 'eval/episode_y_velocity_std': Array(83.28658, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5215208530426, 'eval/sps': 937.5811168832823, 'num_steps': 22773760}
{'eval/walltime': 38250.49826216698, 'training/sps': 2968.4919026207326, 'training/walltime': 7789.121039390564, 'training/entropy_loss': Array(0.00855984, dtype=float32), 'training/policy_loss': Array(0.00733594, dtype=float32), 'training/total_loss': Array(0.0968893, dtype=float32), 'training/v_loss': Array(0.08099353, dtype=float32), 'eval/episode_distance_from_origin': Array(4754.726, dtype=float32), 'eval/episode_distance_reward': Array(13.613127, dtype=float32), 'eval/episode_forward_reward': Array(2268.8447, dtype=float32), 'eval/episode_reward': Array(2362.3142, dtype=float32), 'eval/episode_reward_alive': Array(424.4414, dtype=float32), 'eval/episode_reward_linvel': Array(2268.8447, dtype=float32), 'eval/episode_reward_quadctrl': Array(-344.58478, dtype=float32), 'eval/episode_x_position': Array(4712.709, dtype=float32), 'eval/episode_x_velocity': Array(453.76892, dtype=float32), 'eval/episode_y_position': Array(9.789408, dtype=float32), 'eval/episode_y_velocity': Array(6.172034, dtype=float32), 'eval/episode_distance_from_origin_std': Array(394.76483, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8937182, dtype=float32), 'eval/episode_forward_reward_std': Array(815.6129, dtype=float32), 'eval/episode_reward_std': Array(761.443, dtype=float32), 'eval/episode_reward_alive_std': Array(42.12874, dtype=float32), 'eval/episode_reward_linvel_std': Array(815.6129, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.54852, dtype=float32), 'eval/episode_x_position_std': Array(394.09735, dtype=float32), 'eval/episode_x_velocity_std': Array(163.1226, dtype=float32), 'eval/episode_y_position_std': Array(295.36157, dtype=float32), 'eval/episode_y_velocity_std': Array(103.12851, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45305705070496, 'eval/sps': 938.0515377712361, 'num_steps': 22855680}
{'eval/walltime': 38387.16054391861, 'training/sps': 2961.1251437376077, 'training/walltime': 7816.786199092865, 'training/entropy_loss': Array(0.00894829, dtype=float32), 'training/policy_loss': Array(0.00737029, dtype=float32), 'training/total_loss': Array(0.10900574, dtype=float32), 'training/v_loss': Array(0.09268714, dtype=float32), 'eval/episode_distance_from_origin': Array(4751.241, dtype=float32), 'eval/episode_distance_reward': Array(13.715588, dtype=float32), 'eval/episode_forward_reward': Array(2285.9214, dtype=float32), 'eval/episode_reward': Array(2371.747, dtype=float32), 'eval/episode_reward_alive': Array(421.33203, dtype=float32), 'eval/episode_reward_linvel': Array(2285.9214, dtype=float32), 'eval/episode_reward_quadctrl': Array(-349.22168, dtype=float32), 'eval/episode_x_position': Array(4711.6577, dtype=float32), 'eval/episode_x_velocity': Array(457.18423, dtype=float32), 'eval/episode_y_position': Array(21.27636, dtype=float32), 'eval/episode_y_velocity': Array(2.469101, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.8185, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8954544, dtype=float32), 'eval/episode_forward_reward_std': Array(815.9025, dtype=float32), 'eval/episode_reward_std': Array(763.09485, dtype=float32), 'eval/episode_reward_alive_std': Array(48.76503, dtype=float32), 'eval/episode_reward_linvel_std': Array(815.9025, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.49798, dtype=float32), 'eval/episode_x_position_std': Array(411.3623, dtype=float32), 'eval/episode_x_velocity_std': Array(163.18048, dtype=float32), 'eval/episode_y_position_std': Array(264.58926, dtype=float32), 'eval/episode_y_velocity_std': Array(90.14341, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6622817516327, 'eval/sps': 936.6154169196783, 'num_steps': 22937600}
{'eval/walltime': 38523.70062828064, 'training/sps': 2966.127444417102, 'training/walltime': 7844.4047021865845, 'training/entropy_loss': Array(0.00859005, dtype=float32), 'training/policy_loss': Array(0.01279012, dtype=float32), 'training/total_loss': Array(0.13158798, dtype=float32), 'training/v_loss': Array(0.11020783, dtype=float32), 'eval/episode_distance_from_origin': Array(4742.45, dtype=float32), 'eval/episode_distance_reward': Array(13.920631, dtype=float32), 'eval/episode_forward_reward': Array(2320.0957, dtype=float32), 'eval/episode_reward': Array(2394.3198, dtype=float32), 'eval/episode_reward_alive': Array(415.66797, dtype=float32), 'eval/episode_reward_linvel': Array(2320.0957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-355.3642, dtype=float32), 'eval/episode_x_position': Array(4699.9375, dtype=float32), 'eval/episode_x_velocity': Array(464.0191, dtype=float32), 'eval/episode_y_position': Array(-24.943893, dtype=float32), 'eval/episode_y_velocity': Array(-9.808717, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.09787, dtype=float32), 'eval/episode_distance_reward_std': Array(4.531375, dtype=float32), 'eval/episode_forward_reward_std': Array(755.2231, dtype=float32), 'eval/episode_reward_std': Array(716.8448, dtype=float32), 'eval/episode_reward_alive_std': Array(47.828278, dtype=float32), 'eval/episode_reward_linvel_std': Array(755.2231, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.65379, dtype=float32), 'eval/episode_x_position_std': Array(388.48257, dtype=float32), 'eval/episode_x_velocity_std': Array(151.0446, dtype=float32), 'eval/episode_y_position_std': Array(292.37415, dtype=float32), 'eval/episode_y_velocity_std': Array(100.028656, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54008436203003, 'eval/sps': 937.4536466567109, 'num_steps': 23019520}
{'eval/walltime': 38660.32565689087, 'training/sps': 2950.476929679415, 'training/walltime': 7872.169704914093, 'training/entropy_loss': Array(0.00700097, dtype=float32), 'training/policy_loss': Array(0.00141284, dtype=float32), 'training/total_loss': Array(0.085201, dtype=float32), 'training/v_loss': Array(0.07678718, dtype=float32), 'eval/episode_distance_from_origin': Array(4809.7505, dtype=float32), 'eval/episode_distance_reward': Array(13.845592, dtype=float32), 'eval/episode_forward_reward': Array(2307.589, dtype=float32), 'eval/episode_reward': Array(2401.2268, dtype=float32), 'eval/episode_reward_alive': Array(421.6836, dtype=float32), 'eval/episode_reward_linvel': Array(2307.589, dtype=float32), 'eval/episode_reward_quadctrl': Array(-341.89175, dtype=float32), 'eval/episode_x_position': Array(4768.416, dtype=float32), 'eval/episode_x_velocity': Array(461.51785, dtype=float32), 'eval/episode_y_position': Array(-36.883717, dtype=float32), 'eval/episode_y_velocity': Array(-22.41096, dtype=float32), 'eval/episode_distance_from_origin_std': Array(369.45132, dtype=float32), 'eval/episode_distance_reward_std': Array(4.433808, dtype=float32), 'eval/episode_forward_reward_std': Array(738.9619, dtype=float32), 'eval/episode_reward_std': Array(692.1834, dtype=float32), 'eval/episode_reward_alive_std': Array(40.94484, dtype=float32), 'eval/episode_reward_linvel_std': Array(738.9619, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.879128, dtype=float32), 'eval/episode_x_position_std': Array(368.75482, dtype=float32), 'eval/episode_x_velocity_std': Array(147.79236, dtype=float32), 'eval/episode_y_position_std': Array(292.166, dtype=float32), 'eval/episode_y_velocity_std': Array(97.86848, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6250286102295, 'eval/sps': 936.8708010679699, 'num_steps': 23101440}
{'eval/walltime': 38796.80603313446, 'training/sps': 2959.127155566366, 'training/walltime': 7899.853543996811, 'training/entropy_loss': Array(0.01245625, dtype=float32), 'training/policy_loss': Array(0.01740811, dtype=float32), 'training/total_loss': Array(0.15779895, dtype=float32), 'training/v_loss': Array(0.12793459, dtype=float32), 'eval/episode_distance_from_origin': Array(4859.552, dtype=float32), 'eval/episode_distance_reward': Array(14.406074, dtype=float32), 'eval/episode_forward_reward': Array(2401.0017, dtype=float32), 'eval/episode_reward': Array(2495.4272, dtype=float32), 'eval/episode_reward_alive': Array(422.89453, dtype=float32), 'eval/episode_reward_linvel': Array(2401.0017, dtype=float32), 'eval/episode_reward_quadctrl': Array(-342.8753, dtype=float32), 'eval/episode_x_position': Array(4818.008, dtype=float32), 'eval/episode_x_velocity': Array(480.20035, dtype=float32), 'eval/episode_y_position': Array(-30.342516, dtype=float32), 'eval/episode_y_velocity': Array(-19.853123, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.66437, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9318256, dtype=float32), 'eval/episode_forward_reward_std': Array(821.9641, dtype=float32), 'eval/episode_reward_std': Array(760.3526, dtype=float32), 'eval/episode_reward_alive_std': Array(34.65402, dtype=float32), 'eval/episode_reward_linvel_std': Array(821.9641, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.410427, dtype=float32), 'eval/episode_x_position_std': Array(419.58502, dtype=float32), 'eval/episode_x_velocity_std': Array(164.39285, dtype=float32), 'eval/episode_y_position_std': Array(306.62842, dtype=float32), 'eval/episode_y_velocity_std': Array(94.62532, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4803762435913, 'eval/sps': 937.8637685724469, 'num_steps': 23183360}
{'eval/walltime': 38933.3273665905, 'training/sps': 2956.661031385015, 'training/walltime': 7927.560473918915, 'training/entropy_loss': Array(0.01013927, dtype=float32), 'training/policy_loss': Array(0.01378856, dtype=float32), 'training/total_loss': Array(0.13287285, dtype=float32), 'training/v_loss': Array(0.10894503, dtype=float32), 'eval/episode_distance_from_origin': Array(4838.4917, dtype=float32), 'eval/episode_distance_reward': Array(14.83564, dtype=float32), 'eval/episode_forward_reward': Array(2472.595, dtype=float32), 'eval/episode_reward': Array(2546.0413, dtype=float32), 'eval/episode_reward_alive': Array(411.6914, dtype=float32), 'eval/episode_reward_linvel': Array(2472.595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-353.08075, dtype=float32), 'eval/episode_x_position': Array(4795.149, dtype=float32), 'eval/episode_x_velocity': Array(494.51898, dtype=float32), 'eval/episode_y_position': Array(-27.523579, dtype=float32), 'eval/episode_y_velocity': Array(-18.316462, dtype=float32), 'eval/episode_distance_from_origin_std': Array(405.24136, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7176003, dtype=float32), 'eval/episode_forward_reward_std': Array(786.26056, dtype=float32), 'eval/episode_reward_std': Array(737.0043, dtype=float32), 'eval/episode_reward_alive_std': Array(36.69879, dtype=float32), 'eval/episode_reward_linvel_std': Array(786.26056, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.10956, dtype=float32), 'eval/episode_x_position_std': Array(404.48282, dtype=float32), 'eval/episode_x_velocity_std': Array(157.25206, dtype=float32), 'eval/episode_y_position_std': Array(314.235, dtype=float32), 'eval/episode_y_velocity_std': Array(106.85628, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52133345603943, 'eval/sps': 937.5824038608343, 'num_steps': 23265280}
{'eval/walltime': 39069.95408010483, 'training/sps': 2965.989540715612, 'training/walltime': 7955.180261135101, 'training/entropy_loss': Array(0.00926535, dtype=float32), 'training/policy_loss': Array(0.02410661, dtype=float32), 'training/total_loss': Array(0.12857251, dtype=float32), 'training/v_loss': Array(0.09520054, dtype=float32), 'eval/episode_distance_from_origin': Array(4805.294, dtype=float32), 'eval/episode_distance_reward': Array(13.693693, dtype=float32), 'eval/episode_forward_reward': Array(2282.272, dtype=float32), 'eval/episode_reward': Array(2384.0962, dtype=float32), 'eval/episode_reward_alive': Array(418.3711, dtype=float32), 'eval/episode_reward_linvel': Array(2282.272, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.2406, dtype=float32), 'eval/episode_x_position': Array(4767.416, dtype=float32), 'eval/episode_x_velocity': Array(456.45438, dtype=float32), 'eval/episode_y_position': Array(-124.71099, dtype=float32), 'eval/episode_y_velocity': Array(-45.37327, dtype=float32), 'eval/episode_distance_from_origin_std': Array(400.34653, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6873794, dtype=float32), 'eval/episode_forward_reward_std': Array(781.2232, dtype=float32), 'eval/episode_reward_std': Array(724.02527, dtype=float32), 'eval/episode_reward_alive_std': Array(43.088764, dtype=float32), 'eval/episode_reward_linvel_std': Array(781.2232, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.209488, dtype=float32), 'eval/episode_x_position_std': Array(397.84146, dtype=float32), 'eval/episode_x_velocity_std': Array(156.24466, dtype=float32), 'eval/episode_y_position_std': Array(220.56184, dtype=float32), 'eval/episode_y_velocity_std': Array(75.588005, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.626713514328, 'eval/sps': 936.8592474163311, 'num_steps': 23347200}
{'eval/walltime': 39206.47292423248, 'training/sps': 2955.5931790789823, 'training/walltime': 7982.897201538086, 'training/entropy_loss': Array(0.00854649, dtype=float32), 'training/policy_loss': Array(0.00615907, dtype=float32), 'training/total_loss': Array(0.1220403, dtype=float32), 'training/v_loss': Array(0.10733473, dtype=float32), 'eval/episode_distance_from_origin': Array(4776.4443, dtype=float32), 'eval/episode_distance_reward': Array(12.916687, dtype=float32), 'eval/episode_forward_reward': Array(2152.7727, dtype=float32), 'eval/episode_reward': Array(2259.379, dtype=float32), 'eval/episode_reward_alive': Array(419.28125, dtype=float32), 'eval/episode_reward_linvel': Array(2152.7727, dtype=float32), 'eval/episode_reward_quadctrl': Array(-325.59186, dtype=float32), 'eval/episode_x_position': Array(4735.036, dtype=float32), 'eval/episode_x_velocity': Array(430.55457, dtype=float32), 'eval/episode_y_position': Array(-134.32062, dtype=float32), 'eval/episode_y_velocity': Array(-53.630585, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.84995, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4475417, dtype=float32), 'eval/episode_forward_reward_std': Array(741.2501, dtype=float32), 'eval/episode_reward_std': Array(688.6462, dtype=float32), 'eval/episode_reward_alive_std': Array(42.453503, dtype=float32), 'eval/episode_reward_linvel_std': Array(741.2501, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.21266, dtype=float32), 'eval/episode_x_position_std': Array(409.07025, dtype=float32), 'eval/episode_x_velocity_std': Array(148.25002, dtype=float32), 'eval/episode_y_position_std': Array(269.10083, dtype=float32), 'eval/episode_y_velocity_std': Array(85.44298, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51884412765503, 'eval/sps': 937.599500039062, 'num_steps': 23429120}
{'eval/walltime': 39343.00748920441, 'training/sps': 2963.5287374517625, 'training/walltime': 8010.539923191071, 'training/entropy_loss': Array(0.00793245, dtype=float32), 'training/policy_loss': Array(0.00854249, dtype=float32), 'training/total_loss': Array(0.09128483, dtype=float32), 'training/v_loss': Array(0.07480989, dtype=float32), 'eval/episode_distance_from_origin': Array(4871.33, dtype=float32), 'eval/episode_distance_reward': Array(14.150293, dtype=float32), 'eval/episode_forward_reward': Array(2358.3726, dtype=float32), 'eval/episode_reward': Array(2462.4106, dtype=float32), 'eval/episode_reward_alive': Array(422.05078, dtype=float32), 'eval/episode_reward_linvel': Array(2358.3726, dtype=float32), 'eval/episode_reward_quadctrl': Array(-332.1629, dtype=float32), 'eval/episode_x_position': Array(4830.066, dtype=float32), 'eval/episode_x_velocity': Array(471.6745, dtype=float32), 'eval/episode_y_position': Array(-58.57258, dtype=float32), 'eval/episode_y_velocity': Array(-30.082924, dtype=float32), 'eval/episode_distance_from_origin_std': Array(403.08597, dtype=float32), 'eval/episode_distance_reward_std': Array(5.051346, dtype=float32), 'eval/episode_forward_reward_std': Array(841.88434, dtype=float32), 'eval/episode_reward_std': Array(781.1361, dtype=float32), 'eval/episode_reward_alive_std': Array(34.36442, dtype=float32), 'eval/episode_reward_linvel_std': Array(841.88434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(57.305412, dtype=float32), 'eval/episode_x_position_std': Array(401.88855, dtype=float32), 'eval/episode_x_velocity_std': Array(168.37686, dtype=float32), 'eval/episode_y_position_std': Array(303.10477, dtype=float32), 'eval/episode_y_velocity_std': Array(93.957436, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53456497192383, 'eval/sps': 937.491543085234, 'num_steps': 23511040}
{'eval/walltime': 39479.65648698807, 'training/sps': 2951.11152520892, 'training/walltime': 8038.298955440521, 'training/entropy_loss': Array(0.00669299, dtype=float32), 'training/policy_loss': Array(0.0055893, dtype=float32), 'training/total_loss': Array(0.07386133, dtype=float32), 'training/v_loss': Array(0.06157904, dtype=float32), 'eval/episode_distance_from_origin': Array(4831.545, dtype=float32), 'eval/episode_distance_reward': Array(13.55674, dtype=float32), 'eval/episode_forward_reward': Array(2259.448, dtype=float32), 'eval/episode_reward': Array(2360.1719, dtype=float32), 'eval/episode_reward_alive': Array(414.36328, dtype=float32), 'eval/episode_reward_linvel': Array(2259.448, dtype=float32), 'eval/episode_reward_quadctrl': Array(-327.19556, dtype=float32), 'eval/episode_x_position': Array(4792.8047, dtype=float32), 'eval/episode_x_velocity': Array(451.8896, dtype=float32), 'eval/episode_y_position': Array(-12.740218, dtype=float32), 'eval/episode_y_velocity': Array(-26.36774, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.5886, dtype=float32), 'eval/episode_distance_reward_std': Array(4.827553, dtype=float32), 'eval/episode_forward_reward_std': Array(804.5854, dtype=float32), 'eval/episode_reward_std': Array(750.7816, dtype=float32), 'eval/episode_reward_alive_std': Array(43.519604, dtype=float32), 'eval/episode_reward_linvel_std': Array(804.5854, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(57.111263, dtype=float32), 'eval/episode_x_position_std': Array(386.51517, dtype=float32), 'eval/episode_x_velocity_std': Array(160.91705, dtype=float32), 'eval/episode_y_position_std': Array(275.592, dtype=float32), 'eval/episode_y_velocity_std': Array(87.70249, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6489977836609, 'eval/sps': 936.7064674901329, 'num_steps': 23592960}
{'eval/walltime': 39616.18790960312, 'training/sps': 2962.2592595769706, 'training/walltime': 8065.953523397446, 'training/entropy_loss': Array(0.01334742, dtype=float32), 'training/policy_loss': Array(0.0116648, dtype=float32), 'training/total_loss': Array(0.13768063, dtype=float32), 'training/v_loss': Array(0.11266842, dtype=float32), 'eval/episode_distance_from_origin': Array(4852.4434, dtype=float32), 'eval/episode_distance_reward': Array(13.976211, dtype=float32), 'eval/episode_forward_reward': Array(2329.359, dtype=float32), 'eval/episode_reward': Array(2413.603, dtype=float32), 'eval/episode_reward_alive': Array(404.83984, dtype=float32), 'eval/episode_reward_linvel': Array(2329.359, dtype=float32), 'eval/episode_reward_quadctrl': Array(-334.5721, dtype=float32), 'eval/episode_x_position': Array(4813.092, dtype=float32), 'eval/episode_x_velocity': Array(465.87177, dtype=float32), 'eval/episode_y_position': Array(-58.132565, dtype=float32), 'eval/episode_y_velocity': Array(-46.50826, dtype=float32), 'eval/episode_distance_from_origin_std': Array(401.97287, dtype=float32), 'eval/episode_distance_reward_std': Array(5.20112, dtype=float32), 'eval/episode_forward_reward_std': Array(866.84674, dtype=float32), 'eval/episode_reward_std': Array(813.1359, dtype=float32), 'eval/episode_reward_alive_std': Array(50.792313, dtype=float32), 'eval/episode_reward_linvel_std': Array(866.84674, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.203342, dtype=float32), 'eval/episode_x_position_std': Array(400.07892, dtype=float32), 'eval/episode_x_velocity_std': Array(173.36931, dtype=float32), 'eval/episode_y_position_std': Array(269.6307, dtype=float32), 'eval/episode_y_velocity_std': Array(80.168686, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53142261505127, 'eval/sps': 937.5131200448594, 'num_steps': 23674880}
{'eval/walltime': 39752.821607112885, 'training/sps': 2959.7282804035535, 'training/walltime': 8093.631739854813, 'training/entropy_loss': Array(0.00966621, dtype=float32), 'training/policy_loss': Array(0.00395718, dtype=float32), 'training/total_loss': Array(0.10055351, dtype=float32), 'training/v_loss': Array(0.08693011, dtype=float32), 'eval/episode_distance_from_origin': Array(4869.1353, dtype=float32), 'eval/episode_distance_reward': Array(13.9115095, dtype=float32), 'eval/episode_forward_reward': Array(2318.5747, dtype=float32), 'eval/episode_reward': Array(2396.9683, dtype=float32), 'eval/episode_reward_alive': Array(402.42578, dtype=float32), 'eval/episode_reward_linvel': Array(2318.5747, dtype=float32), 'eval/episode_reward_quadctrl': Array(-337.94366, dtype=float32), 'eval/episode_x_position': Array(4828.867, dtype=float32), 'eval/episode_x_velocity': Array(463.71497, dtype=float32), 'eval/episode_y_position': Array(-58.957893, dtype=float32), 'eval/episode_y_velocity': Array(-38.246796, dtype=float32), 'eval/episode_distance_from_origin_std': Array(349.89124, dtype=float32), 'eval/episode_distance_reward_std': Array(4.586205, dtype=float32), 'eval/episode_forward_reward_std': Array(764.3609, dtype=float32), 'eval/episode_reward_std': Array(722.7765, dtype=float32), 'eval/episode_reward_alive_std': Array(54.06041, dtype=float32), 'eval/episode_reward_linvel_std': Array(764.3609, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.432182, dtype=float32), 'eval/episode_x_position_std': Array(345.33585, dtype=float32), 'eval/episode_x_velocity_std': Array(152.87225, dtype=float32), 'eval/episode_y_position_std': Array(288.3125, dtype=float32), 'eval/episode_y_velocity_std': Array(86.715294, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63369750976562, 'eval/sps': 936.811360102814, 'num_steps': 23756800}
{'eval/walltime': 39889.36847496033, 'training/sps': 2965.2470629267414, 'training/walltime': 8121.258442878723, 'training/entropy_loss': Array(0.00827555, dtype=float32), 'training/policy_loss': Array(0.00439282, dtype=float32), 'training/total_loss': Array(0.07651193, dtype=float32), 'training/v_loss': Array(0.06384356, dtype=float32), 'eval/episode_distance_from_origin': Array(4879.0005, dtype=float32), 'eval/episode_distance_reward': Array(13.98364, dtype=float32), 'eval/episode_forward_reward': Array(2330.5967, dtype=float32), 'eval/episode_reward': Array(2427.2678, dtype=float32), 'eval/episode_reward_alive': Array(413.64062, dtype=float32), 'eval/episode_reward_linvel': Array(2330.5967, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.95343, dtype=float32), 'eval/episode_x_position': Array(4842.135, dtype=float32), 'eval/episode_x_velocity': Array(466.11935, dtype=float32), 'eval/episode_y_position': Array(-28.80112, dtype=float32), 'eval/episode_y_velocity': Array(-38.373116, dtype=float32), 'eval/episode_distance_from_origin_std': Array(382.81842, dtype=float32), 'eval/episode_distance_reward_std': Array(4.800367, dtype=float32), 'eval/episode_forward_reward_std': Array(800.05444, dtype=float32), 'eval/episode_reward_std': Array(751.2614, dtype=float32), 'eval/episode_reward_alive_std': Array(46.657574, dtype=float32), 'eval/episode_reward_linvel_std': Array(800.05444, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.17661, dtype=float32), 'eval/episode_x_position_std': Array(381.48422, dtype=float32), 'eval/episode_x_velocity_std': Array(160.0109, dtype=float32), 'eval/episode_y_position_std': Array(237.50148, dtype=float32), 'eval/episode_y_velocity_std': Array(74.32515, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54686784744263, 'eval/sps': 937.4070750784878, 'num_steps': 23838720}
{'eval/walltime': 40026.0191822052, 'training/sps': 2959.530937303763, 'training/walltime': 8148.938504934311, 'training/entropy_loss': Array(0.0079717, dtype=float32), 'training/policy_loss': Array(0.00587934, dtype=float32), 'training/total_loss': Array(0.07539976, dtype=float32), 'training/v_loss': Array(0.06154872, dtype=float32), 'eval/episode_distance_from_origin': Array(4959.399, dtype=float32), 'eval/episode_distance_reward': Array(14.69318, dtype=float32), 'eval/episode_forward_reward': Array(2448.853, dtype=float32), 'eval/episode_reward': Array(2534.6895, dtype=float32), 'eval/episode_reward_alive': Array(406.42578, dtype=float32), 'eval/episode_reward_linvel': Array(2448.853, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.28265, dtype=float32), 'eval/episode_x_position': Array(4917.8066, dtype=float32), 'eval/episode_x_velocity': Array(489.77063, dtype=float32), 'eval/episode_y_position': Array(-91.49335, dtype=float32), 'eval/episode_y_velocity': Array(-48.751827, dtype=float32), 'eval/episode_distance_from_origin_std': Array(422.8363, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9516115, dtype=float32), 'eval/episode_forward_reward_std': Array(825.2621, dtype=float32), 'eval/episode_reward_std': Array(772.0799, dtype=float32), 'eval/episode_reward_alive_std': Array(46.711094, dtype=float32), 'eval/episode_reward_linvel_std': Array(825.2621, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.47324, dtype=float32), 'eval/episode_x_position_std': Array(417.7607, dtype=float32), 'eval/episode_x_velocity_std': Array(165.05241, dtype=float32), 'eval/episode_y_position_std': Array(305.44437, dtype=float32), 'eval/episode_y_velocity_std': Array(88.18294, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65070724487305, 'eval/sps': 936.6947495604886, 'num_steps': 23920640}
{'eval/walltime': 40162.55776309967, 'training/sps': 2957.947817339856, 'training/walltime': 8176.633381605148, 'training/entropy_loss': Array(0.0077844, dtype=float32), 'training/policy_loss': Array(0.00344462, dtype=float32), 'training/total_loss': Array(0.0739677, dtype=float32), 'training/v_loss': Array(0.06273867, dtype=float32), 'eval/episode_distance_from_origin': Array(4978.081, dtype=float32), 'eval/episode_distance_reward': Array(14.782995, dtype=float32), 'eval/episode_forward_reward': Array(2463.8223, dtype=float32), 'eval/episode_reward': Array(2544.5334, dtype=float32), 'eval/episode_reward_alive': Array(401.3164, dtype=float32), 'eval/episode_reward_linvel': Array(2463.8223, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.38803, dtype=float32), 'eval/episode_x_position': Array(4939.012, dtype=float32), 'eval/episode_x_velocity': Array(492.76443, dtype=float32), 'eval/episode_y_position': Array(-18.83316, dtype=float32), 'eval/episode_y_velocity': Array(-37.35635, dtype=float32), 'eval/episode_distance_from_origin_std': Array(363.69635, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2364273, dtype=float32), 'eval/episode_forward_reward_std': Array(706.0648, dtype=float32), 'eval/episode_reward_std': Array(669.2936, dtype=float32), 'eval/episode_reward_alive_std': Array(54.198486, dtype=float32), 'eval/episode_reward_linvel_std': Array(706.0648, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.647503, dtype=float32), 'eval/episode_x_position_std': Array(360.86774, dtype=float32), 'eval/episode_x_velocity_std': Array(141.21292, dtype=float32), 'eval/episode_y_position_std': Array(284.16086, dtype=float32), 'eval/episode_y_velocity_std': Array(81.35399, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53858089447021, 'eval/sps': 937.4639692420003, 'num_steps': 24002560}
{'eval/walltime': 40299.186954021454, 'training/sps': 2956.5627771986938, 'training/walltime': 8204.341232299805, 'training/entropy_loss': Array(0.00627153, dtype=float32), 'training/policy_loss': Array(0.0061268, dtype=float32), 'training/total_loss': Array(0.06083922, dtype=float32), 'training/v_loss': Array(0.04844089, dtype=float32), 'eval/episode_distance_from_origin': Array(4909.503, dtype=float32), 'eval/episode_distance_reward': Array(13.918533, dtype=float32), 'eval/episode_forward_reward': Array(2319.7463, dtype=float32), 'eval/episode_reward': Array(2413.3354, dtype=float32), 'eval/episode_reward_alive': Array(406.90234, dtype=float32), 'eval/episode_reward_linvel': Array(2319.7463, dtype=float32), 'eval/episode_reward_quadctrl': Array(-327.2317, dtype=float32), 'eval/episode_x_position': Array(4869.6143, dtype=float32), 'eval/episode_x_velocity': Array(463.94925, dtype=float32), 'eval/episode_y_position': Array(-11.067295, dtype=float32), 'eval/episode_y_velocity': Array(-39.948715, dtype=float32), 'eval/episode_distance_from_origin_std': Array(412.07816, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9426217, dtype=float32), 'eval/episode_forward_reward_std': Array(823.7636, dtype=float32), 'eval/episode_reward_std': Array(771.78174, dtype=float32), 'eval/episode_reward_alive_std': Array(46.42602, dtype=float32), 'eval/episode_reward_linvel_std': Array(823.7636, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.714855, dtype=float32), 'eval/episode_x_position_std': Array(412.52246, dtype=float32), 'eval/episode_x_velocity_std': Array(164.75272, dtype=float32), 'eval/episode_y_position_std': Array(283.10355, dtype=float32), 'eval/episode_y_velocity_std': Array(84.0446, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62919092178345, 'eval/sps': 936.8422599624158, 'num_steps': 24084480}
{'eval/walltime': 40435.72023558617, 'training/sps': 2953.3969044537453, 'training/walltime': 8232.078784227371, 'training/entropy_loss': Array(0.01169087, dtype=float32), 'training/policy_loss': Array(0.01489046, dtype=float32), 'training/total_loss': Array(0.1687926, dtype=float32), 'training/v_loss': Array(0.14221126, dtype=float32), 'eval/episode_distance_from_origin': Array(4968.987, dtype=float32), 'eval/episode_distance_reward': Array(14.3848, dtype=float32), 'eval/episode_forward_reward': Array(2397.457, dtype=float32), 'eval/episode_reward': Array(2476.5964, dtype=float32), 'eval/episode_reward_alive': Array(402.8789, dtype=float32), 'eval/episode_reward_linvel': Array(2397.457, dtype=float32), 'eval/episode_reward_quadctrl': Array(-338.12405, dtype=float32), 'eval/episode_x_position': Array(4928.141, dtype=float32), 'eval/episode_x_velocity': Array(479.49133, dtype=float32), 'eval/episode_y_position': Array(13.282983, dtype=float32), 'eval/episode_y_velocity': Array(-32.537777, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.4752, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9961567, dtype=float32), 'eval/episode_forward_reward_std': Array(832.6863, dtype=float32), 'eval/episode_reward_std': Array(781.3671, dtype=float32), 'eval/episode_reward_alive_std': Array(47.729206, dtype=float32), 'eval/episode_reward_linvel_std': Array(832.6863, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.0239, dtype=float32), 'eval/episode_x_position_std': Array(423.94934, dtype=float32), 'eval/episode_x_velocity_std': Array(166.53728, dtype=float32), 'eval/episode_y_position_std': Array(307.92056, dtype=float32), 'eval/episode_y_velocity_std': Array(92.06759, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53328156471252, 'eval/sps': 937.5003554670441, 'num_steps': 24166400}
{'eval/walltime': 40572.36202931404, 'training/sps': 2968.760416272456, 'training/walltime': 8259.672792673111, 'training/entropy_loss': Array(0.01279886, dtype=float32), 'training/policy_loss': Array(0.02810281, dtype=float32), 'training/total_loss': Array(0.1463967, dtype=float32), 'training/v_loss': Array(0.10549504, dtype=float32), 'eval/episode_distance_from_origin': Array(4884.8223, dtype=float32), 'eval/episode_distance_reward': Array(13.521778, dtype=float32), 'eval/episode_forward_reward': Array(2253.621, dtype=float32), 'eval/episode_reward': Array(2356.1826, dtype=float32), 'eval/episode_reward_alive': Array(413.14062, dtype=float32), 'eval/episode_reward_linvel': Array(2253.621, dtype=float32), 'eval/episode_reward_quadctrl': Array(-324.1004, dtype=float32), 'eval/episode_x_position': Array(4844.2485, dtype=float32), 'eval/episode_x_velocity': Array(450.72424, dtype=float32), 'eval/episode_y_position': Array(73.3272, dtype=float32), 'eval/episode_y_velocity': Array(-15.395292, dtype=float32), 'eval/episode_distance_from_origin_std': Array(389.51767, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6823077, dtype=float32), 'eval/episode_forward_reward_std': Array(780.3785, dtype=float32), 'eval/episode_reward_std': Array(724.0137, dtype=float32), 'eval/episode_reward_alive_std': Array(45.22595, dtype=float32), 'eval/episode_reward_linvel_std': Array(780.3785, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.252373, dtype=float32), 'eval/episode_x_position_std': Array(388.29932, dtype=float32), 'eval/episode_x_velocity_std': Array(156.07567, dtype=float32), 'eval/episode_y_position_std': Array(294.20407, dtype=float32), 'eval/episode_y_velocity_std': Array(83.37449, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64179372787476, 'eval/sps': 936.7558527145429, 'num_steps': 24248320}
{'eval/walltime': 40708.98225545883, 'training/sps': 2976.903030552814, 'training/walltime': 8287.191324234009, 'training/entropy_loss': Array(0.00884424, dtype=float32), 'training/policy_loss': Array(0.03730465, dtype=float32), 'training/total_loss': Array(0.11261038, dtype=float32), 'training/v_loss': Array(0.06646148, dtype=float32), 'eval/episode_distance_from_origin': Array(4988.0083, dtype=float32), 'eval/episode_distance_reward': Array(14.927666, dtype=float32), 'eval/episode_forward_reward': Array(2487.934, dtype=float32), 'eval/episode_reward': Array(2547.52, dtype=float32), 'eval/episode_reward_alive': Array(388.29297, dtype=float32), 'eval/episode_reward_linvel': Array(2487.934, dtype=float32), 'eval/episode_reward_quadctrl': Array(-343.63467, dtype=float32), 'eval/episode_x_position': Array(4947.1494, dtype=float32), 'eval/episode_x_velocity': Array(497.58682, dtype=float32), 'eval/episode_y_position': Array(45.885307, dtype=float32), 'eval/episode_y_velocity': Array(-33.66636, dtype=float32), 'eval/episode_distance_from_origin_std': Array(462.8648, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5462384, dtype=float32), 'eval/episode_forward_reward_std': Array(924.36615, dtype=float32), 'eval/episode_reward_std': Array(882.009, dtype=float32), 'eval/episode_reward_alive_std': Array(62.482136, dtype=float32), 'eval/episode_reward_linvel_std': Array(924.36615, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(57.45699, dtype=float32), 'eval/episode_x_position_std': Array(461.72516, dtype=float32), 'eval/episode_x_velocity_std': Array(184.87326, dtype=float32), 'eval/episode_y_position_std': Array(298.98193, dtype=float32), 'eval/episode_y_velocity_std': Array(77.73239, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62022614479065, 'eval/sps': 936.9037338903619, 'num_steps': 24330240}
{'eval/walltime': 40845.490917921066, 'training/sps': 2960.7050840148254, 'training/walltime': 8314.860409021378, 'training/entropy_loss': Array(0.00819699, dtype=float32), 'training/policy_loss': Array(0.0038914, dtype=float32), 'training/total_loss': Array(0.07462838, dtype=float32), 'training/v_loss': Array(0.06253999, dtype=float32), 'eval/episode_distance_from_origin': Array(4920.748, dtype=float32), 'eval/episode_distance_reward': Array(14.355913, dtype=float32), 'eval/episode_forward_reward': Array(2392.642, dtype=float32), 'eval/episode_reward': Array(2472.2852, dtype=float32), 'eval/episode_reward_alive': Array(401.4336, dtype=float32), 'eval/episode_reward_linvel': Array(2392.642, dtype=float32), 'eval/episode_reward_quadctrl': Array(-336.14636, dtype=float32), 'eval/episode_x_position': Array(4879.135, dtype=float32), 'eval/episode_x_velocity': Array(478.52844, dtype=float32), 'eval/episode_y_position': Array(48.173615, dtype=float32), 'eval/episode_y_velocity': Array(-27.64139, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.6411, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1467624, dtype=float32), 'eval/episode_forward_reward_std': Array(857.78723, dtype=float32), 'eval/episode_reward_std': Array(800.8806, dtype=float32), 'eval/episode_reward_alive_std': Array(53.723915, dtype=float32), 'eval/episode_reward_linvel_std': Array(857.78723, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.74358, dtype=float32), 'eval/episode_x_position_std': Array(408.4499, dtype=float32), 'eval/episode_x_velocity_std': Array(171.5575, dtype=float32), 'eval/episode_y_position_std': Array(300.25888, dtype=float32), 'eval/episode_y_velocity_std': Array(93.634155, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5086624622345, 'eval/sps': 937.6694320436372, 'num_steps': 24412160}
{'eval/walltime': 40982.089747428894, 'training/sps': 2962.5216148248883, 'training/walltime': 8342.512527942657, 'training/entropy_loss': Array(0.0079281, dtype=float32), 'training/policy_loss': Array(0.00223563, dtype=float32), 'training/total_loss': Array(0.07092428, dtype=float32), 'training/v_loss': Array(0.06076056, dtype=float32), 'eval/episode_distance_from_origin': Array(4995.0225, dtype=float32), 'eval/episode_distance_reward': Array(14.936519, dtype=float32), 'eval/episode_forward_reward': Array(2489.41, dtype=float32), 'eval/episode_reward': Array(2547.1643, dtype=float32), 'eval/episode_reward_alive': Array(390.59766, dtype=float32), 'eval/episode_reward_linvel': Array(2489.41, dtype=float32), 'eval/episode_reward_quadctrl': Array(-347.7799, dtype=float32), 'eval/episode_x_position': Array(4954.7437, dtype=float32), 'eval/episode_x_velocity': Array(497.88202, dtype=float32), 'eval/episode_y_position': Array(9.92705, dtype=float32), 'eval/episode_y_velocity': Array(-46.144325, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.2098, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1008353, dtype=float32), 'eval/episode_forward_reward_std': Array(850.1333, dtype=float32), 'eval/episode_reward_std': Array(812.6588, dtype=float32), 'eval/episode_reward_alive_std': Array(50.63634, dtype=float32), 'eval/episode_reward_linvel_std': Array(850.1333, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.702263, dtype=float32), 'eval/episode_x_position_std': Array(448.55032, dtype=float32), 'eval/episode_x_velocity_std': Array(170.02672, dtype=float32), 'eval/episode_y_position_std': Array(281.61334, dtype=float32), 'eval/episode_y_velocity_std': Array(78.57673, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59882950782776, 'eval/sps': 937.0504890941617, 'num_steps': 24494080}
{'eval/walltime': 41118.60166621208, 'training/sps': 2960.1585444041807, 'training/walltime': 8370.18672132492, 'training/entropy_loss': Array(0.00726576, dtype=float32), 'training/policy_loss': Array(0.0025536, dtype=float32), 'training/total_loss': Array(0.06090143, dtype=float32), 'training/v_loss': Array(0.05108207, dtype=float32), 'eval/episode_distance_from_origin': Array(5001.797, dtype=float32), 'eval/episode_distance_reward': Array(15.386843, dtype=float32), 'eval/episode_forward_reward': Array(2564.4626, dtype=float32), 'eval/episode_reward': Array(2629.7756, dtype=float32), 'eval/episode_reward_alive': Array(395.64844, dtype=float32), 'eval/episode_reward_linvel': Array(2564.4626, dtype=float32), 'eval/episode_reward_quadctrl': Array(-345.7226, dtype=float32), 'eval/episode_x_position': Array(4960.3203, dtype=float32), 'eval/episode_x_velocity': Array(512.8925, dtype=float32), 'eval/episode_y_position': Array(48.568916, dtype=float32), 'eval/episode_y_velocity': Array(-24.429314, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.56207, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4089346, dtype=float32), 'eval/episode_forward_reward_std': Array(901.4822, dtype=float32), 'eval/episode_reward_std': Array(854.492, dtype=float32), 'eval/episode_reward_alive_std': Array(44.236195, dtype=float32), 'eval/episode_reward_linvel_std': Array(901.4822, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.92903, dtype=float32), 'eval/episode_x_position_std': Array(422.58923, dtype=float32), 'eval/episode_x_velocity_std': Array(180.29652, dtype=float32), 'eval/episode_y_position_std': Array(309.01904, dtype=float32), 'eval/episode_y_velocity_std': Array(91.49235, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51191878318787, 'eval/sps': 937.6470651129977, 'num_steps': 24576000}
{'eval/walltime': 41255.1893286705, 'training/sps': 2965.0860843705273, 'training/walltime': 8397.814924240112, 'training/entropy_loss': Array(0.01039318, dtype=float32), 'training/policy_loss': Array(0.0104677, dtype=float32), 'training/total_loss': Array(0.10162469, dtype=float32), 'training/v_loss': Array(0.08076382, dtype=float32), 'eval/episode_distance_from_origin': Array(5024.3545, dtype=float32), 'eval/episode_distance_reward': Array(15.2828245, dtype=float32), 'eval/episode_forward_reward': Array(2547.126, dtype=float32), 'eval/episode_reward': Array(2603.2314, dtype=float32), 'eval/episode_reward_alive': Array(389.29297, dtype=float32), 'eval/episode_reward_linvel': Array(2547.126, dtype=float32), 'eval/episode_reward_quadctrl': Array(-348.47028, dtype=float32), 'eval/episode_x_position': Array(4984.68, dtype=float32), 'eval/episode_x_velocity': Array(509.42517, dtype=float32), 'eval/episode_y_position': Array(44.052773, dtype=float32), 'eval/episode_y_velocity': Array(-37.271793, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.32718, dtype=float32), 'eval/episode_distance_reward_std': Array(5.018071, dtype=float32), 'eval/episode_forward_reward_std': Array(836.3385, dtype=float32), 'eval/episode_reward_std': Array(778.0935, dtype=float32), 'eval/episode_reward_alive_std': Array(49.325512, dtype=float32), 'eval/episode_reward_linvel_std': Array(836.3385, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.636257, dtype=float32), 'eval/episode_x_position_std': Array(413.8995, dtype=float32), 'eval/episode_x_velocity_std': Array(167.26762, dtype=float32), 'eval/episode_y_position_std': Array(265.7082, dtype=float32), 'eval/episode_y_velocity_std': Array(84.32639, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5876624584198, 'eval/sps': 937.127099886975, 'num_steps': 24657920}
{'eval/walltime': 41391.71547842026, 'training/sps': 2957.556457888762, 'training/walltime': 8425.513465642929, 'training/entropy_loss': Array(0.01336278, dtype=float32), 'training/policy_loss': Array(0.14555962, dtype=float32), 'training/total_loss': Array(0.26227552, dtype=float32), 'training/v_loss': Array(0.10335314, dtype=float32), 'eval/episode_distance_from_origin': Array(5050.169, dtype=float32), 'eval/episode_distance_reward': Array(15.5624485, dtype=float32), 'eval/episode_forward_reward': Array(2593.7295, dtype=float32), 'eval/episode_reward': Array(2587.6995, dtype=float32), 'eval/episode_reward_alive': Array(379.6875, dtype=float32), 'eval/episode_reward_linvel': Array(2593.7295, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.27997, dtype=float32), 'eval/episode_x_position': Array(5005.995, dtype=float32), 'eval/episode_x_velocity': Array(518.746, dtype=float32), 'eval/episode_y_position': Array(138.03357, dtype=float32), 'eval/episode_y_velocity': Array(-10.200596, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.81482, dtype=float32), 'eval/episode_distance_reward_std': Array(4.816145, dtype=float32), 'eval/episode_forward_reward_std': Array(802.68506, dtype=float32), 'eval/episode_reward_std': Array(786.48773, dtype=float32), 'eval/episode_reward_alive_std': Array(65.016045, dtype=float32), 'eval/episode_reward_linvel_std': Array(802.68506, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.247448, dtype=float32), 'eval/episode_x_position_std': Array(428.52625, dtype=float32), 'eval/episode_x_velocity_std': Array(160.53702, dtype=float32), 'eval/episode_y_position_std': Array(305.44345, dtype=float32), 'eval/episode_y_velocity_std': Array(89.570984, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52614974975586, 'eval/sps': 937.5493283493032, 'num_steps': 24739840}
{'eval/walltime': 41528.25094008446, 'training/sps': 2960.667888333476, 'training/walltime': 8453.182898044586, 'training/entropy_loss': Array(0.01226815, dtype=float32), 'training/policy_loss': Array(0.01027798, dtype=float32), 'training/total_loss': Array(0.12524608, dtype=float32), 'training/v_loss': Array(0.10269994, dtype=float32), 'eval/episode_distance_from_origin': Array(4895.427, dtype=float32), 'eval/episode_distance_reward': Array(13.651204, dtype=float32), 'eval/episode_forward_reward': Array(2275.1914, dtype=float32), 'eval/episode_reward': Array(2301.975, dtype=float32), 'eval/episode_reward_alive': Array(392.09375, dtype=float32), 'eval/episode_reward_linvel': Array(2275.1914, dtype=float32), 'eval/episode_reward_quadctrl': Array(-378.96106, dtype=float32), 'eval/episode_x_position': Array(4852.6294, dtype=float32), 'eval/episode_x_velocity': Array(455.03824, dtype=float32), 'eval/episode_y_position': Array(160.24887, dtype=float32), 'eval/episode_y_velocity': Array(-6.026914, dtype=float32), 'eval/episode_distance_from_origin_std': Array(419.63477, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7595696, dtype=float32), 'eval/episode_forward_reward_std': Array(793.25586, dtype=float32), 'eval/episode_reward_std': Array(767.23566, dtype=float32), 'eval/episode_reward_alive_std': Array(56.065243, dtype=float32), 'eval/episode_reward_linvel_std': Array(793.25586, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.17969, dtype=float32), 'eval/episode_x_position_std': Array(421.99704, dtype=float32), 'eval/episode_x_velocity_std': Array(158.65112, dtype=float32), 'eval/episode_y_position_std': Array(259.96594, dtype=float32), 'eval/episode_y_velocity_std': Array(84.48521, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53546166419983, 'eval/sps': 937.48538613952, 'num_steps': 24821760}
{'eval/walltime': 41664.781693935394, 'training/sps': 2956.9789648071383, 'training/walltime': 8480.886848926544, 'training/entropy_loss': Array(0.01289029, dtype=float32), 'training/policy_loss': Array(0.0078169, dtype=float32), 'training/total_loss': Array(0.14056781, dtype=float32), 'training/v_loss': Array(0.11986063, dtype=float32), 'eval/episode_distance_from_origin': Array(5056.3174, dtype=float32), 'eval/episode_distance_reward': Array(15.704612, dtype=float32), 'eval/episode_forward_reward': Array(2617.4236, dtype=float32), 'eval/episode_reward': Array(2609.543, dtype=float32), 'eval/episode_reward_alive': Array(378.98438, dtype=float32), 'eval/episode_reward_linvel': Array(2617.4236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-402.5698, dtype=float32), 'eval/episode_x_position': Array(5008.491, dtype=float32), 'eval/episode_x_velocity': Array(523.48474, dtype=float32), 'eval/episode_y_position': Array(149.3097, dtype=float32), 'eval/episode_y_velocity': Array(-12.662082, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.85156, dtype=float32), 'eval/episode_distance_reward_std': Array(5.445993, dtype=float32), 'eval/episode_forward_reward_std': Array(907.65906, dtype=float32), 'eval/episode_reward_std': Array(892.47577, dtype=float32), 'eval/episode_reward_alive_std': Array(67.73007, dtype=float32), 'eval/episode_reward_linvel_std': Array(907.65906, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.055565, dtype=float32), 'eval/episode_x_position_std': Array(450.2598, dtype=float32), 'eval/episode_x_velocity_std': Array(181.53183, dtype=float32), 'eval/episode_y_position_std': Array(338.70972, dtype=float32), 'eval/episode_y_velocity_std': Array(103.826904, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5307538509369, 'eval/sps': 937.5177122346319, 'num_steps': 24903680}
{'eval/walltime': 41801.339079618454, 'training/sps': 2947.647129396629, 'training/walltime': 8508.678506612778, 'training/entropy_loss': Array(0.01219149, dtype=float32), 'training/policy_loss': Array(0.00563553, dtype=float32), 'training/total_loss': Array(0.11732665, dtype=float32), 'training/v_loss': Array(0.09949963, dtype=float32), 'eval/episode_distance_from_origin': Array(5020.3994, dtype=float32), 'eval/episode_distance_reward': Array(15.163368, dtype=float32), 'eval/episode_forward_reward': Array(2527.2168, dtype=float32), 'eval/episode_reward': Array(2532.9482, dtype=float32), 'eval/episode_reward_alive': Array(387.71875, dtype=float32), 'eval/episode_reward_linvel': Array(2527.2168, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.15106, dtype=float32), 'eval/episode_x_position': Array(4978.6987, dtype=float32), 'eval/episode_x_velocity': Array(505.4433, dtype=float32), 'eval/episode_y_position': Array(82.59521, dtype=float32), 'eval/episode_y_velocity': Array(-28.355572, dtype=float32), 'eval/episode_distance_from_origin_std': Array(442.4929, dtype=float32), 'eval/episode_distance_reward_std': Array(5.149711, dtype=float32), 'eval/episode_forward_reward_std': Array(858.27924, dtype=float32), 'eval/episode_reward_std': Array(833.0508, dtype=float32), 'eval/episode_reward_alive_std': Array(54.895737, dtype=float32), 'eval/episode_reward_linvel_std': Array(858.27924, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.666145, dtype=float32), 'eval/episode_x_position_std': Array(443.04648, dtype=float32), 'eval/episode_x_velocity_std': Array(171.65582, dtype=float32), 'eval/episode_y_position_std': Array(269.9588, dtype=float32), 'eval/episode_y_velocity_std': Array(84.95056, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5573856830597, 'eval/sps': 937.3348747103229, 'num_steps': 24985600}
{'eval/walltime': 41937.756289720535, 'training/sps': 2946.8902496299206, 'training/walltime': 8536.477302312851, 'training/entropy_loss': Array(0.01070054, dtype=float32), 'training/policy_loss': Array(0.02818575, dtype=float32), 'training/total_loss': Array(0.11415994, dtype=float32), 'training/v_loss': Array(0.07527365, dtype=float32), 'eval/episode_distance_from_origin': Array(5075.409, dtype=float32), 'eval/episode_distance_reward': Array(15.279272, dtype=float32), 'eval/episode_forward_reward': Array(2546.5347, dtype=float32), 'eval/episode_reward': Array(2554.062, dtype=float32), 'eval/episode_reward_alive': Array(382.97266, dtype=float32), 'eval/episode_reward_linvel': Array(2546.5347, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.72418, dtype=float32), 'eval/episode_x_position': Array(5034.871, dtype=float32), 'eval/episode_x_velocity': Array(509.30685, dtype=float32), 'eval/episode_y_position': Array(93.707504, dtype=float32), 'eval/episode_y_velocity': Array(-23.139996, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.33673, dtype=float32), 'eval/episode_distance_reward_std': Array(4.776967, dtype=float32), 'eval/episode_forward_reward_std': Array(796.15607, dtype=float32), 'eval/episode_reward_std': Array(770.23596, dtype=float32), 'eval/episode_reward_alive_std': Array(61.642437, dtype=float32), 'eval/episode_reward_linvel_std': Array(796.15607, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.48661, dtype=float32), 'eval/episode_x_position_std': Array(439.26483, dtype=float32), 'eval/episode_x_velocity_std': Array(159.23114, dtype=float32), 'eval/episode_y_position_std': Array(265.73477, dtype=float32), 'eval/episode_y_velocity_std': Array(79.15571, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4172101020813, 'eval/sps': 938.2980336881052, 'num_steps': 25067520}
{'eval/walltime': 42074.24625372887, 'training/sps': 2949.3324237371808, 'training/walltime': 8564.253079414368, 'training/entropy_loss': Array(0.00800246, dtype=float32), 'training/policy_loss': Array(0.00329303, dtype=float32), 'training/total_loss': Array(0.07564112, dtype=float32), 'training/v_loss': Array(0.06434563, dtype=float32), 'eval/episode_distance_from_origin': Array(5000.949, dtype=float32), 'eval/episode_distance_reward': Array(14.602676, dtype=float32), 'eval/episode_forward_reward': Array(2433.7686, dtype=float32), 'eval/episode_reward': Array(2434.3816, dtype=float32), 'eval/episode_reward_alive': Array(380.33203, dtype=float32), 'eval/episode_reward_linvel': Array(2433.7686, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.32156, dtype=float32), 'eval/episode_x_position': Array(4956.3857, dtype=float32), 'eval/episode_x_velocity': Array(486.75366, dtype=float32), 'eval/episode_y_position': Array(109.231064, dtype=float32), 'eval/episode_y_velocity': Array(-28.845127, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.2316, dtype=float32), 'eval/episode_distance_reward_std': Array(5.138355, dtype=float32), 'eval/episode_forward_reward_std': Array(856.3863, dtype=float32), 'eval/episode_reward_std': Array(837.1631, dtype=float32), 'eval/episode_reward_alive_std': Array(63.799286, dtype=float32), 'eval/episode_reward_linvel_std': Array(856.3863, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.564533, dtype=float32), 'eval/episode_x_position_std': Array(452.17807, dtype=float32), 'eval/episode_x_velocity_std': Array(171.27722, dtype=float32), 'eval/episode_y_position_std': Array(305.1034, dtype=float32), 'eval/episode_y_velocity_std': Array(89.912056, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4899640083313, 'eval/sps': 937.7978881449989, 'num_steps': 25149440}
{'eval/walltime': 42210.65897607803, 'training/sps': 2954.7488690711484, 'training/walltime': 8591.977939844131, 'training/entropy_loss': Array(0.01782466, dtype=float32), 'training/policy_loss': Array(0.02431571, dtype=float32), 'training/total_loss': Array(0.16856477, dtype=float32), 'training/v_loss': Array(0.1264244, dtype=float32), 'eval/episode_distance_from_origin': Array(5048.289, dtype=float32), 'eval/episode_distance_reward': Array(15.208395, dtype=float32), 'eval/episode_forward_reward': Array(2534.7212, dtype=float32), 'eval/episode_reward': Array(2525.1074, dtype=float32), 'eval/episode_reward_alive': Array(366.98047, dtype=float32), 'eval/episode_reward_linvel': Array(2534.7212, dtype=float32), 'eval/episode_reward_quadctrl': Array(-391.8031, dtype=float32), 'eval/episode_x_position': Array(5005.337, dtype=float32), 'eval/episode_x_velocity': Array(506.9443, dtype=float32), 'eval/episode_y_position': Array(57.44342, dtype=float32), 'eval/episode_y_velocity': Array(-39.163372, dtype=float32), 'eval/episode_distance_from_origin_std': Array(467.4488, dtype=float32), 'eval/episode_distance_reward_std': Array(5.334178, dtype=float32), 'eval/episode_forward_reward_std': Array(889.0234, dtype=float32), 'eval/episode_reward_std': Array(873.48035, dtype=float32), 'eval/episode_reward_alive_std': Array(63.8921, dtype=float32), 'eval/episode_reward_linvel_std': Array(889.0234, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.251274, dtype=float32), 'eval/episode_x_position_std': Array(465.42557, dtype=float32), 'eval/episode_x_velocity_std': Array(177.8047, dtype=float32), 'eval/episode_y_position_std': Array(288.98734, dtype=float32), 'eval/episode_y_velocity_std': Array(91.83548, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41272234916687, 'eval/sps': 938.328902141302, 'num_steps': 25231360}
{'eval/walltime': 42347.15939831734, 'training/sps': 2950.0583656663825, 'training/walltime': 8619.746881961823, 'training/entropy_loss': Array(0.01587669, dtype=float32), 'training/policy_loss': Array(0.00639427, dtype=float32), 'training/total_loss': Array(0.1553899, dtype=float32), 'training/v_loss': Array(0.13311894, dtype=float32), 'eval/episode_distance_from_origin': Array(4987.1104, dtype=float32), 'eval/episode_distance_reward': Array(14.311195, dtype=float32), 'eval/episode_forward_reward': Array(2385.1892, dtype=float32), 'eval/episode_reward': Array(2375.811, dtype=float32), 'eval/episode_reward_alive': Array(362.91016, dtype=float32), 'eval/episode_reward_linvel': Array(2385.1892, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.59973, dtype=float32), 'eval/episode_x_position': Array(4942.5303, dtype=float32), 'eval/episode_x_velocity': Array(477.03787, dtype=float32), 'eval/episode_y_position': Array(92.59755, dtype=float32), 'eval/episode_y_velocity': Array(-38.632736, dtype=float32), 'eval/episode_distance_from_origin_std': Array(431.86768, dtype=float32), 'eval/episode_distance_reward_std': Array(4.610825, dtype=float32), 'eval/episode_forward_reward_std': Array(768.4648, dtype=float32), 'eval/episode_reward_std': Array(737.6131, dtype=float32), 'eval/episode_reward_alive_std': Array(68.58023, dtype=float32), 'eval/episode_reward_linvel_std': Array(768.4648, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.648586, dtype=float32), 'eval/episode_x_position_std': Array(430.75192, dtype=float32), 'eval/episode_x_velocity_std': Array(153.69304, dtype=float32), 'eval/episode_y_position_std': Array(302.99127, dtype=float32), 'eval/episode_y_velocity_std': Array(95.1923, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5004222393036, 'eval/sps': 937.726037034514, 'num_steps': 25313280}
{'eval/walltime': 42483.56704378128, 'training/sps': 2950.857801227829, 'training/walltime': 8647.508301019669, 'training/entropy_loss': Array(0.01429923, dtype=float32), 'training/policy_loss': Array(0.00444474, dtype=float32), 'training/total_loss': Array(0.12268734, dtype=float32), 'training/v_loss': Array(0.10394338, dtype=float32), 'eval/episode_distance_from_origin': Array(5041.3257, dtype=float32), 'eval/episode_distance_reward': Array(14.922979, dtype=float32), 'eval/episode_forward_reward': Array(2487.1523, dtype=float32), 'eval/episode_reward': Array(2474.0571, dtype=float32), 'eval/episode_reward_alive': Array(371.42188, dtype=float32), 'eval/episode_reward_linvel': Array(2487.1523, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.44022, dtype=float32), 'eval/episode_x_position': Array(4998.073, dtype=float32), 'eval/episode_x_velocity': Array(497.43042, dtype=float32), 'eval/episode_y_position': Array(64.912384, dtype=float32), 'eval/episode_y_velocity': Array(-42.19316, dtype=float32), 'eval/episode_distance_from_origin_std': Array(433.4328, dtype=float32), 'eval/episode_distance_reward_std': Array(5.308617, dtype=float32), 'eval/episode_forward_reward_std': Array(884.7633, dtype=float32), 'eval/episode_reward_std': Array(871.79614, dtype=float32), 'eval/episode_reward_alive_std': Array(61.308468, dtype=float32), 'eval/episode_reward_linvel_std': Array(884.7633, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.61798, dtype=float32), 'eval/episode_x_position_std': Array(433.9649, dtype=float32), 'eval/episode_x_velocity_std': Array(176.95268, dtype=float32), 'eval/episode_y_position_std': Array(295.59293, dtype=float32), 'eval/episode_y_velocity_std': Array(83.90496, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40764546394348, 'eval/sps': 938.3638253167718, 'num_steps': 25395200}
{'eval/walltime': 42620.10516285896, 'training/sps': 2945.8807633678825, 'training/walltime': 8675.31662273407, 'training/entropy_loss': Array(0.01218154, dtype=float32), 'training/policy_loss': Array(0.00496397, dtype=float32), 'training/total_loss': Array(0.08820935, dtype=float32), 'training/v_loss': Array(0.07106384, dtype=float32), 'eval/episode_distance_from_origin': Array(4926.365, dtype=float32), 'eval/episode_distance_reward': Array(13.561112, dtype=float32), 'eval/episode_forward_reward': Array(2260.1758, dtype=float32), 'eval/episode_reward': Array(2265.4263, dtype=float32), 'eval/episode_reward_alive': Array(370.8711, dtype=float32), 'eval/episode_reward_linvel': Array(2260.1758, dtype=float32), 'eval/episode_reward_quadctrl': Array(-379.18176, dtype=float32), 'eval/episode_x_position': Array(4884.935, dtype=float32), 'eval/episode_x_velocity': Array(452.03513, dtype=float32), 'eval/episode_y_position': Array(79.99748, dtype=float32), 'eval/episode_y_velocity': Array(-30.876678, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.5188, dtype=float32), 'eval/episode_distance_reward_std': Array(4.422924, dtype=float32), 'eval/episode_forward_reward_std': Array(737.148, dtype=float32), 'eval/episode_reward_std': Array(711.4647, dtype=float32), 'eval/episode_reward_alive_std': Array(64.714165, dtype=float32), 'eval/episode_reward_linvel_std': Array(737.148, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.60504, dtype=float32), 'eval/episode_x_position_std': Array(451.2865, dtype=float32), 'eval/episode_x_velocity_std': Array(147.42957, dtype=float32), 'eval/episode_y_position_std': Array(264.24997, dtype=float32), 'eval/episode_y_velocity_std': Array(79.63143, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5381190776825, 'eval/sps': 937.4671400532127, 'num_steps': 25477120}
{'eval/walltime': 42756.641297101974, 'training/sps': 2948.946985150789, 'training/walltime': 8703.09603023529, 'training/entropy_loss': Array(0.01033815, dtype=float32), 'training/policy_loss': Array(0.00581888, dtype=float32), 'training/total_loss': Array(0.07932849, dtype=float32), 'training/v_loss': Array(0.06317146, dtype=float32), 'eval/episode_distance_from_origin': Array(4947.42, dtype=float32), 'eval/episode_distance_reward': Array(13.6889, dtype=float32), 'eval/episode_forward_reward': Array(2281.474, dtype=float32), 'eval/episode_reward': Array(2287.501, dtype=float32), 'eval/episode_reward_alive': Array(369.86328, dtype=float32), 'eval/episode_reward_linvel': Array(2281.474, dtype=float32), 'eval/episode_reward_quadctrl': Array(-377.52512, dtype=float32), 'eval/episode_x_position': Array(4904.712, dtype=float32), 'eval/episode_x_velocity': Array(456.29477, dtype=float32), 'eval/episode_y_position': Array(17.842186, dtype=float32), 'eval/episode_y_velocity': Array(-48.2582, dtype=float32), 'eval/episode_distance_from_origin_std': Array(426.64496, dtype=float32), 'eval/episode_distance_reward_std': Array(4.487734, dtype=float32), 'eval/episode_forward_reward_std': Array(747.95026, dtype=float32), 'eval/episode_reward_std': Array(725.8162, dtype=float32), 'eval/episode_reward_alive_std': Array(69.36094, dtype=float32), 'eval/episode_reward_linvel_std': Array(747.95026, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.420193, dtype=float32), 'eval/episode_x_position_std': Array(427.20593, dtype=float32), 'eval/episode_x_velocity_std': Array(149.59004, dtype=float32), 'eval/episode_y_position_std': Array(278.41925, dtype=float32), 'eval/episode_y_velocity_std': Array(90.17085, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53613424301147, 'eval/sps': 937.48076807405, 'num_steps': 25559040}
{'eval/walltime': 42893.16748762131, 'training/sps': 2959.808285658751, 'training/walltime': 8730.773498535156, 'training/entropy_loss': Array(0.00828897, dtype=float32), 'training/policy_loss': Array(0.00039161, dtype=float32), 'training/total_loss': Array(0.04715467, dtype=float32), 'training/v_loss': Array(0.03847409, dtype=float32), 'eval/episode_distance_from_origin': Array(4964.859, dtype=float32), 'eval/episode_distance_reward': Array(14.094619, dtype=float32), 'eval/episode_forward_reward': Array(2349.093, dtype=float32), 'eval/episode_reward': Array(2341.6074, dtype=float32), 'eval/episode_reward_alive': Array(370.4297, dtype=float32), 'eval/episode_reward_linvel': Array(2349.093, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.00995, dtype=float32), 'eval/episode_x_position': Array(4921.3506, dtype=float32), 'eval/episode_x_velocity': Array(469.81854, dtype=float32), 'eval/episode_y_position': Array(113.51395, dtype=float32), 'eval/episode_y_velocity': Array(-27.640518, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.48712, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4372873, dtype=float32), 'eval/episode_forward_reward_std': Array(906.208, dtype=float32), 'eval/episode_reward_std': Array(876.3795, dtype=float32), 'eval/episode_reward_alive_std': Array(62.563957, dtype=float32), 'eval/episode_reward_linvel_std': Array(906.208, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.24744, dtype=float32), 'eval/episode_x_position_std': Array(482.62405, dtype=float32), 'eval/episode_x_velocity_std': Array(181.24158, dtype=float32), 'eval/episode_y_position_std': Array(291.86, dtype=float32), 'eval/episode_y_velocity_std': Array(89.366295, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52619051933289, 'eval/sps': 937.5490483774574, 'num_steps': 25640960}
{'eval/walltime': 43029.83665513992, 'training/sps': 2955.19690151266, 'training/walltime': 8758.49415564537, 'training/entropy_loss': Array(0.0179049, dtype=float32), 'training/policy_loss': Array(0.01249038, dtype=float32), 'training/total_loss': Array(0.14790198, dtype=float32), 'training/v_loss': Array(0.1175067, dtype=float32), 'eval/episode_distance_from_origin': Array(4942.3047, dtype=float32), 'eval/episode_distance_reward': Array(13.580442, dtype=float32), 'eval/episode_forward_reward': Array(2263.3967, dtype=float32), 'eval/episode_reward': Array(2257.624, dtype=float32), 'eval/episode_reward_alive': Array(368.55078, dtype=float32), 'eval/episode_reward_linvel': Array(2263.3967, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.90414, dtype=float32), 'eval/episode_x_position': Array(4899.314, dtype=float32), 'eval/episode_x_velocity': Array(452.67944, dtype=float32), 'eval/episode_y_position': Array(140.36841, dtype=float32), 'eval/episode_y_velocity': Array(-18.275623, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.41095, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4624505, dtype=float32), 'eval/episode_forward_reward_std': Array(743.73627, dtype=float32), 'eval/episode_reward_std': Array(724.5378, dtype=float32), 'eval/episode_reward_alive_std': Array(70.31138, dtype=float32), 'eval/episode_reward_linvel_std': Array(743.73627, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.001564, dtype=float32), 'eval/episode_x_position_std': Array(395.8056, dtype=float32), 'eval/episode_x_velocity_std': Array(148.74722, dtype=float32), 'eval/episode_y_position_std': Array(264.6678, dtype=float32), 'eval/episode_y_velocity_std': Array(80.93306, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66916751861572, 'eval/sps': 936.5682276696762, 'num_steps': 25722880}
{'eval/walltime': 43166.40692734718, 'training/sps': 2955.7308550517046, 'training/walltime': 8786.20980501175, 'training/entropy_loss': Array(0.01496163, dtype=float32), 'training/policy_loss': Array(0.01060167, dtype=float32), 'training/total_loss': Array(0.15409774, dtype=float32), 'training/v_loss': Array(0.12853444, dtype=float32), 'eval/episode_distance_from_origin': Array(5027.9443, dtype=float32), 'eval/episode_distance_reward': Array(14.216429, dtype=float32), 'eval/episode_forward_reward': Array(2369.3938, dtype=float32), 'eval/episode_reward': Array(2348.8086, dtype=float32), 'eval/episode_reward_alive': Array(361.89844, dtype=float32), 'eval/episode_reward_linvel': Array(2369.3938, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.70026, dtype=float32), 'eval/episode_x_position': Array(4986.2925, dtype=float32), 'eval/episode_x_velocity': Array(473.87878, dtype=float32), 'eval/episode_y_position': Array(80.2659, dtype=float32), 'eval/episode_y_velocity': Array(-40.375706, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.5906, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3188157, dtype=float32), 'eval/episode_forward_reward_std': Array(719.7972, dtype=float32), 'eval/episode_reward_std': Array(717.9468, dtype=float32), 'eval/episode_reward_alive_std': Array(73.08453, dtype=float32), 'eval/episode_reward_linvel_std': Array(719.7972, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.90727, dtype=float32), 'eval/episode_x_position_std': Array(439.04407, dtype=float32), 'eval/episode_x_velocity_std': Array(143.95943, dtype=float32), 'eval/episode_y_position_std': Array(250.2635, dtype=float32), 'eval/episode_y_velocity_std': Array(84.62834, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57027220726013, 'eval/sps': 937.2464294846405, 'num_steps': 25804800}
{'eval/walltime': 43302.9345638752, 'training/sps': 2951.5821363528626, 'training/walltime': 8813.964411258698, 'training/entropy_loss': Array(0.01414711, dtype=float32), 'training/policy_loss': Array(0.00503667, dtype=float32), 'training/total_loss': Array(0.13152786, dtype=float32), 'training/v_loss': Array(0.11234407, dtype=float32), 'eval/episode_distance_from_origin': Array(5004.9697, dtype=float32), 'eval/episode_distance_reward': Array(14.39306, dtype=float32), 'eval/episode_forward_reward': Array(2398.832, dtype=float32), 'eval/episode_reward': Array(2394.6353, dtype=float32), 'eval/episode_reward_alive': Array(367.73438, dtype=float32), 'eval/episode_reward_linvel': Array(2398.832, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.3239, dtype=float32), 'eval/episode_x_position': Array(4960.2285, dtype=float32), 'eval/episode_x_velocity': Array(479.76645, dtype=float32), 'eval/episode_y_position': Array(119.918724, dtype=float32), 'eval/episode_y_velocity': Array(-29.090046, dtype=float32), 'eval/episode_distance_from_origin_std': Array(391.87927, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2299705, dtype=float32), 'eval/episode_forward_reward_std': Array(704.9902, dtype=float32), 'eval/episode_reward_std': Array(695.23206, dtype=float32), 'eval/episode_reward_alive_std': Array(69.78678, dtype=float32), 'eval/episode_reward_linvel_std': Array(704.9902, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.889355, dtype=float32), 'eval/episode_x_position_std': Array(391.593, dtype=float32), 'eval/episode_x_velocity_std': Array(140.99803, dtype=float32), 'eval/episode_y_position_std': Array(288.55594, dtype=float32), 'eval/episode_y_velocity_std': Array(87.53227, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52763652801514, 'eval/sps': 937.5391184900114, 'num_steps': 25886720}
{'eval/walltime': 43439.46532845497, 'training/sps': 2954.844080479489, 'training/walltime': 8841.688378334045, 'training/entropy_loss': Array(0.0126566, dtype=float32), 'training/policy_loss': Array(0.05438894, dtype=float32), 'training/total_loss': Array(0.15047961, dtype=float32), 'training/v_loss': Array(0.08343408, dtype=float32), 'eval/episode_distance_from_origin': Array(4959.424, dtype=float32), 'eval/episode_distance_reward': Array(14.049535, dtype=float32), 'eval/episode_forward_reward': Array(2341.5774, dtype=float32), 'eval/episode_reward': Array(2293.1648, dtype=float32), 'eval/episode_reward_alive': Array(365.70312, dtype=float32), 'eval/episode_reward_linvel': Array(2341.5774, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.16544, dtype=float32), 'eval/episode_x_position': Array(4914.5356, dtype=float32), 'eval/episode_x_velocity': Array(468.3155, dtype=float32), 'eval/episode_y_position': Array(145.04063, dtype=float32), 'eval/episode_y_velocity': Array(-30.77399, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.95694, dtype=float32), 'eval/episode_distance_reward_std': Array(4.509396, dtype=float32), 'eval/episode_forward_reward_std': Array(751.5598, dtype=float32), 'eval/episode_reward_std': Array(734.20874, dtype=float32), 'eval/episode_reward_alive_std': Array(61.886562, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.5598, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.520134, dtype=float32), 'eval/episode_x_position_std': Array(427.7245, dtype=float32), 'eval/episode_x_velocity_std': Array(150.31197, dtype=float32), 'eval/episode_y_position_std': Array(277.80884, dtype=float32), 'eval/episode_y_velocity_std': Array(83.52213, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53076457977295, 'eval/sps': 937.5176385627831, 'num_steps': 25968640}
{'eval/walltime': 43576.09034347534, 'training/sps': 2952.3431788598796, 'training/walltime': 8869.435830116272, 'training/entropy_loss': Array(0.01192647, dtype=float32), 'training/policy_loss': Array(0.02778021, dtype=float32), 'training/total_loss': Array(0.09311829, dtype=float32), 'training/v_loss': Array(0.05341161, dtype=float32), 'eval/episode_distance_from_origin': Array(4998.7627, dtype=float32), 'eval/episode_distance_reward': Array(14.395024, dtype=float32), 'eval/episode_forward_reward': Array(2399.1592, dtype=float32), 'eval/episode_reward': Array(2363.9722, dtype=float32), 'eval/episode_reward_alive': Array(375.0625, dtype=float32), 'eval/episode_reward_linvel': Array(2399.1592, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.64484, dtype=float32), 'eval/episode_x_position': Array(4955.1494, dtype=float32), 'eval/episode_x_velocity': Array(479.83188, dtype=float32), 'eval/episode_y_position': Array(98.08695, dtype=float32), 'eval/episode_y_velocity': Array(-43.471455, dtype=float32), 'eval/episode_distance_from_origin_std': Array(427.4176, dtype=float32), 'eval/episode_distance_reward_std': Array(4.367521, dtype=float32), 'eval/episode_forward_reward_std': Array(727.91425, dtype=float32), 'eval/episode_reward_std': Array(707.4207, dtype=float32), 'eval/episode_reward_alive_std': Array(59.337982, dtype=float32), 'eval/episode_reward_linvel_std': Array(727.91425, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.06181, dtype=float32), 'eval/episode_x_position_std': Array(427.3375, dtype=float32), 'eval/episode_x_velocity_std': Array(145.58289, dtype=float32), 'eval/episode_y_position_std': Array(258.9523, dtype=float32), 'eval/episode_y_velocity_std': Array(84.23402, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62501502037048, 'eval/sps': 936.8708942569227, 'num_steps': 26050560}
{'eval/walltime': 43712.64222621918, 'training/sps': 2947.980983833513, 'training/walltime': 8897.224340438843, 'training/entropy_loss': Array(0.00924097, dtype=float32), 'training/policy_loss': Array(0.06938244, dtype=float32), 'training/total_loss': Array(0.11509238, dtype=float32), 'training/v_loss': Array(0.03646897, dtype=float32), 'eval/episode_distance_from_origin': Array(5002.5967, dtype=float32), 'eval/episode_distance_reward': Array(14.309561, dtype=float32), 'eval/episode_forward_reward': Array(2384.9155, dtype=float32), 'eval/episode_reward': Array(2349.0376, dtype=float32), 'eval/episode_reward_alive': Array(376.98438, dtype=float32), 'eval/episode_reward_linvel': Array(2384.9155, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.17194, dtype=float32), 'eval/episode_x_position': Array(4958.662, dtype=float32), 'eval/episode_x_velocity': Array(476.9831, dtype=float32), 'eval/episode_y_position': Array(105.936584, dtype=float32), 'eval/episode_y_velocity': Array(-38.728355, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.0059, dtype=float32), 'eval/episode_distance_reward_std': Array(4.825433, dtype=float32), 'eval/episode_forward_reward_std': Array(804.2327, dtype=float32), 'eval/episode_reward_std': Array(788.8739, dtype=float32), 'eval/episode_reward_alive_std': Array(57.962536, dtype=float32), 'eval/episode_reward_linvel_std': Array(804.2327, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.081894, dtype=float32), 'eval/episode_x_position_std': Array(465.47424, dtype=float32), 'eval/episode_x_velocity_std': Array(160.84648, dtype=float32), 'eval/episode_y_position_std': Array(270.73013, dtype=float32), 'eval/episode_y_velocity_std': Array(87.23002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55188274383545, 'eval/sps': 937.3726486080141, 'num_steps': 26132480}
{'eval/walltime': 43849.31464600563, 'training/sps': 2949.8691730786672, 'training/walltime': 8924.99506354332, 'training/entropy_loss': Array(0.01494356, dtype=float32), 'training/policy_loss': Array(0.00499462, dtype=float32), 'training/total_loss': Array(0.14904106, dtype=float32), 'training/v_loss': Array(0.12910289, dtype=float32), 'eval/episode_distance_from_origin': Array(4905.784, dtype=float32), 'eval/episode_distance_reward': Array(13.350678, dtype=float32), 'eval/episode_forward_reward': Array(2225.1033, dtype=float32), 'eval/episode_reward': Array(2207.4795, dtype=float32), 'eval/episode_reward_alive': Array(381.73047, dtype=float32), 'eval/episode_reward_linvel': Array(2225.1033, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.70483, dtype=float32), 'eval/episode_x_position': Array(4863.6196, dtype=float32), 'eval/episode_x_velocity': Array(445.02063, dtype=float32), 'eval/episode_y_position': Array(95.85867, dtype=float32), 'eval/episode_y_velocity': Array(-38.081493, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.0771, dtype=float32), 'eval/episode_distance_reward_std': Array(4.212385, dtype=float32), 'eval/episode_forward_reward_std': Array(702.059, dtype=float32), 'eval/episode_reward_std': Array(661.70776, dtype=float32), 'eval/episode_reward_alive_std': Array(55.26534, dtype=float32), 'eval/episode_reward_linvel_std': Array(702.059, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(73.09049, dtype=float32), 'eval/episode_x_position_std': Array(375.52438, dtype=float32), 'eval/episode_x_velocity_std': Array(140.41176, dtype=float32), 'eval/episode_y_position_std': Array(243.92603, dtype=float32), 'eval/episode_y_velocity_std': Array(79.03803, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67241978645325, 'eval/sps': 936.5459410171879, 'num_steps': 26214400}
{'eval/walltime': 43985.811957359314, 'training/sps': 2948.8587334605077, 'training/walltime': 8952.775302410126, 'training/entropy_loss': Array(0.02506144, dtype=float32), 'training/policy_loss': Array(0.07030677, dtype=float32), 'training/total_loss': Array(0.23786071, dtype=float32), 'training/v_loss': Array(0.1424925, dtype=float32), 'eval/episode_distance_from_origin': Array(5059.6655, dtype=float32), 'eval/episode_distance_reward': Array(14.971565, dtype=float32), 'eval/episode_forward_reward': Array(2495.248, dtype=float32), 'eval/episode_reward': Array(2433.6372, dtype=float32), 'eval/episode_reward_alive': Array(385.29297, dtype=float32), 'eval/episode_reward_linvel': Array(2495.248, dtype=float32), 'eval/episode_reward_quadctrl': Array(-461.87558, dtype=float32), 'eval/episode_x_position': Array(5015.152, dtype=float32), 'eval/episode_x_velocity': Array(499.04956, dtype=float32), 'eval/episode_y_position': Array(89.00925, dtype=float32), 'eval/episode_y_velocity': Array(-60.141758, dtype=float32), 'eval/episode_distance_from_origin_std': Array(362.8179, dtype=float32), 'eval/episode_distance_reward_std': Array(3.6689155, dtype=float32), 'eval/episode_forward_reward_std': Array(611.4819, dtype=float32), 'eval/episode_reward_std': Array(605.5532, dtype=float32), 'eval/episode_reward_alive_std': Array(46.720978, dtype=float32), 'eval/episode_reward_linvel_std': Array(611.4819, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.472736, dtype=float32), 'eval/episode_x_position_std': Array(363.6541, dtype=float32), 'eval/episode_x_velocity_std': Array(122.29632, dtype=float32), 'eval/episode_y_position_std': Array(249.55603, dtype=float32), 'eval/episode_y_velocity_std': Array(83.92962, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49731135368347, 'eval/sps': 937.7474085796038, 'num_steps': 26296320}
{'eval/walltime': 44122.34873819351, 'training/sps': 2945.5463491290943, 'training/walltime': 8980.586781263351, 'training/entropy_loss': Array(0.02173854, dtype=float32), 'training/policy_loss': Array(0.0625983, dtype=float32), 'training/total_loss': Array(0.20205311, dtype=float32), 'training/v_loss': Array(0.11771628, dtype=float32), 'eval/episode_distance_from_origin': Array(4859.9087, dtype=float32), 'eval/episode_distance_reward': Array(13.884158, dtype=float32), 'eval/episode_forward_reward': Array(2314.017, dtype=float32), 'eval/episode_reward': Array(2311.5796, dtype=float32), 'eval/episode_reward_alive': Array(397.92578, dtype=float32), 'eval/episode_reward_linvel': Array(2314.017, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.24725, dtype=float32), 'eval/episode_x_position': Array(4813.744, dtype=float32), 'eval/episode_x_velocity': Array(462.80328, dtype=float32), 'eval/episode_y_position': Array(150.0005, dtype=float32), 'eval/episode_y_velocity': Array(-27.190514, dtype=float32), 'eval/episode_distance_from_origin_std': Array(502.60132, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4238667, dtype=float32), 'eval/episode_forward_reward_std': Array(903.97186, dtype=float32), 'eval/episode_reward_std': Array(883.97797, dtype=float32), 'eval/episode_reward_alive_std': Array(40.057873, dtype=float32), 'eval/episode_reward_linvel_std': Array(903.97186, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.949192, dtype=float32), 'eval/episode_x_position_std': Array(499.7538, dtype=float32), 'eval/episode_x_velocity_std': Array(180.79428, dtype=float32), 'eval/episode_y_position_std': Array(285.02914, dtype=float32), 'eval/episode_y_velocity_std': Array(90.43887, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.536780834198, 'eval/sps': 937.4763284878926, 'num_steps': 26378240}
{'eval/walltime': 44258.82233476639, 'training/sps': 2952.060481134708, 'training/walltime': 9008.336890220642, 'training/entropy_loss': Array(0.01654679, dtype=float32), 'training/policy_loss': Array(0.15631068, dtype=float32), 'training/total_loss': Array(0.2468755, dtype=float32), 'training/v_loss': Array(0.07401805, dtype=float32), 'eval/episode_distance_from_origin': Array(4814.5464, dtype=float32), 'eval/episode_distance_reward': Array(13.723172, dtype=float32), 'eval/episode_forward_reward': Array(2287.1855, dtype=float32), 'eval/episode_reward': Array(2318.0872, dtype=float32), 'eval/episode_reward_alive': Array(393.92188, dtype=float32), 'eval/episode_reward_linvel': Array(2287.1855, dtype=float32), 'eval/episode_reward_quadctrl': Array(-376.7437, dtype=float32), 'eval/episode_x_position': Array(4771.6704, dtype=float32), 'eval/episode_x_velocity': Array(457.43716, dtype=float32), 'eval/episode_y_position': Array(103.90442, dtype=float32), 'eval/episode_y_velocity': Array(-28.367342, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.62363, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4184117, dtype=float32), 'eval/episode_forward_reward_std': Array(903.0621, dtype=float32), 'eval/episode_reward_std': Array(875.59283, dtype=float32), 'eval/episode_reward_alive_std': Array(41.554955, dtype=float32), 'eval/episode_reward_linvel_std': Array(903.0621, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.860928, dtype=float32), 'eval/episode_x_position_std': Array(451.99646, dtype=float32), 'eval/episode_x_velocity_std': Array(180.61247, dtype=float32), 'eval/episode_y_position_std': Array(266.4119, dtype=float32), 'eval/episode_y_velocity_std': Array(88.4429, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47359657287598, 'eval/sps': 937.9103593246981, 'num_steps': 26460160}
{'eval/walltime': 44395.378789663315, 'training/sps': 2960.230131214406, 'training/walltime': 9036.010414361954, 'training/entropy_loss': Array(0.01257665, dtype=float32), 'training/policy_loss': Array(0.00174773, dtype=float32), 'training/total_loss': Array(0.05852172, dtype=float32), 'training/v_loss': Array(0.04419734, dtype=float32), 'eval/episode_distance_from_origin': Array(4855.062, dtype=float32), 'eval/episode_distance_reward': Array(14.098322, dtype=float32), 'eval/episode_forward_reward': Array(2349.7104, dtype=float32), 'eval/episode_reward': Array(2367.7788, dtype=float32), 'eval/episode_reward_alive': Array(385.46875, dtype=float32), 'eval/episode_reward_linvel': Array(2349.7104, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.4984, dtype=float32), 'eval/episode_x_position': Array(4811.5576, dtype=float32), 'eval/episode_x_velocity': Array(469.94208, dtype=float32), 'eval/episode_y_position': Array(102.13924, dtype=float32), 'eval/episode_y_velocity': Array(-37.284267, dtype=float32), 'eval/episode_distance_from_origin_std': Array(462.51483, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3458834, dtype=float32), 'eval/episode_forward_reward_std': Array(890.975, dtype=float32), 'eval/episode_reward_std': Array(862.0598, dtype=float32), 'eval/episode_reward_alive_std': Array(47.840504, dtype=float32), 'eval/episode_reward_linvel_std': Array(890.975, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.162563, dtype=float32), 'eval/episode_x_position_std': Array(458.5451, dtype=float32), 'eval/episode_x_velocity_std': Array(178.19495, dtype=float32), 'eval/episode_y_position_std': Array(274.11752, dtype=float32), 'eval/episode_y_velocity_std': Array(85.98882, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55645489692688, 'eval/sps': 937.3412637038263, 'num_steps': 26542080}
{'eval/walltime': 44531.86746263504, 'training/sps': 2956.8829796216887, 'training/walltime': 9063.715264558792, 'training/entropy_loss': Array(0.01124528, dtype=float32), 'training/policy_loss': Array(-0.00150418, dtype=float32), 'training/total_loss': Array(0.04039885, dtype=float32), 'training/v_loss': Array(0.03065776, dtype=float32), 'eval/episode_distance_from_origin': Array(4885.4907, dtype=float32), 'eval/episode_distance_reward': Array(14.218258, dtype=float32), 'eval/episode_forward_reward': Array(2369.6992, dtype=float32), 'eval/episode_reward': Array(2393.1963, dtype=float32), 'eval/episode_reward_alive': Array(394.8789, dtype=float32), 'eval/episode_reward_linvel': Array(2369.6992, dtype=float32), 'eval/episode_reward_quadctrl': Array(-385.60046, dtype=float32), 'eval/episode_x_position': Array(4842.6484, dtype=float32), 'eval/episode_x_velocity': Array(473.93988, dtype=float32), 'eval/episode_y_position': Array(103.15575, dtype=float32), 'eval/episode_y_velocity': Array(-38.475258, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.84396, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1669717, dtype=float32), 'eval/episode_forward_reward_std': Array(861.1563, dtype=float32), 'eval/episode_reward_std': Array(833.83075, dtype=float32), 'eval/episode_reward_alive_std': Array(44.13601, dtype=float32), 'eval/episode_reward_linvel_std': Array(861.1563, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.29875, dtype=float32), 'eval/episode_x_position_std': Array(436.73694, dtype=float32), 'eval/episode_x_velocity_std': Array(172.23123, dtype=float32), 'eval/episode_y_position_std': Array(253.60088, dtype=float32), 'eval/episode_y_velocity_std': Array(82.33395, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48867297172546, 'eval/sps': 937.8067587082194, 'num_steps': 26624000}
{'eval/walltime': 44668.397404909134, 'training/sps': 2965.1059658498484, 'training/walltime': 9091.343282222748, 'training/entropy_loss': Array(0.01177759, dtype=float32), 'training/policy_loss': Array(0.0034659, dtype=float32), 'training/total_loss': Array(0.09117816, dtype=float32), 'training/v_loss': Array(0.07593466, dtype=float32), 'eval/episode_distance_from_origin': Array(4875.613, dtype=float32), 'eval/episode_distance_reward': Array(13.871488, dtype=float32), 'eval/episode_forward_reward': Array(2311.9058, dtype=float32), 'eval/episode_reward': Array(2327.9937, dtype=float32), 'eval/episode_reward_alive': Array(392.51953, dtype=float32), 'eval/episode_reward_linvel': Array(2311.9058, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.30298, dtype=float32), 'eval/episode_x_position': Array(4832.195, dtype=float32), 'eval/episode_x_velocity': Array(462.38116, dtype=float32), 'eval/episode_y_position': Array(152.29028, dtype=float32), 'eval/episode_y_velocity': Array(-23.484821, dtype=float32), 'eval/episode_distance_from_origin_std': Array(447.8447, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2789817, dtype=float32), 'eval/episode_forward_reward_std': Array(879.8241, dtype=float32), 'eval/episode_reward_std': Array(859.8303, dtype=float32), 'eval/episode_reward_alive_std': Array(53.582928, dtype=float32), 'eval/episode_reward_linvel_std': Array(879.8241, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.363586, dtype=float32), 'eval/episode_x_position_std': Array(446.98386, dtype=float32), 'eval/episode_x_velocity_std': Array(175.96481, dtype=float32), 'eval/episode_y_position_std': Array(249.08409, dtype=float32), 'eval/episode_y_velocity_std': Array(83.38224, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52994227409363, 'eval/sps': 937.5232851342663, 'num_steps': 26705920}
{'eval/walltime': 44804.912652254105, 'training/sps': 2959.4169180783406, 'training/walltime': 9119.02441072464, 'training/entropy_loss': Array(0.01480069, dtype=float32), 'training/policy_loss': Array(0.00280812, dtype=float32), 'training/total_loss': Array(0.15587667, dtype=float32), 'training/v_loss': Array(0.13826784, dtype=float32), 'eval/episode_distance_from_origin': Array(4900.968, dtype=float32), 'eval/episode_distance_reward': Array(13.87305, dtype=float32), 'eval/episode_forward_reward': Array(2312.165, dtype=float32), 'eval/episode_reward': Array(2331.6882, dtype=float32), 'eval/episode_reward_alive': Array(392.64453, dtype=float32), 'eval/episode_reward_linvel': Array(2312.165, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.9943, dtype=float32), 'eval/episode_x_position': Array(4858.5986, dtype=float32), 'eval/episode_x_velocity': Array(462.433, dtype=float32), 'eval/episode_y_position': Array(114.14832, dtype=float32), 'eval/episode_y_velocity': Array(-32.77652, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.4037, dtype=float32), 'eval/episode_distance_reward_std': Array(4.833314, dtype=float32), 'eval/episode_forward_reward_std': Array(805.54663, dtype=float32), 'eval/episode_reward_std': Array(780.0975, dtype=float32), 'eval/episode_reward_alive_std': Array(42.38307, dtype=float32), 'eval/episode_reward_linvel_std': Array(805.54663, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.802135, dtype=float32), 'eval/episode_x_position_std': Array(446.63416, dtype=float32), 'eval/episode_x_velocity_std': Array(161.1093, dtype=float32), 'eval/episode_y_position_std': Array(252.1374, dtype=float32), 'eval/episode_y_velocity_std': Array(79.87456, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5152473449707, 'eval/sps': 937.6242030792877, 'num_steps': 26787840}
{'eval/walltime': 44941.46459889412, 'training/sps': 2961.061909002531, 'training/walltime': 9146.69016122818, 'training/entropy_loss': Array(0.01311172, dtype=float32), 'training/policy_loss': Array(0.00143915, dtype=float32), 'training/total_loss': Array(0.11870259, dtype=float32), 'training/v_loss': Array(0.10415173, dtype=float32), 'eval/episode_distance_from_origin': Array(4950.1924, dtype=float32), 'eval/episode_distance_reward': Array(14.821299, dtype=float32), 'eval/episode_forward_reward': Array(2470.2065, dtype=float32), 'eval/episode_reward': Array(2498.3918, dtype=float32), 'eval/episode_reward_alive': Array(394.64062, dtype=float32), 'eval/episode_reward_linvel': Array(2470.2065, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.276, dtype=float32), 'eval/episode_x_position': Array(4907.7793, dtype=float32), 'eval/episode_x_velocity': Array(494.0412, dtype=float32), 'eval/episode_y_position': Array(76.04976, dtype=float32), 'eval/episode_y_velocity': Array(-44.610916, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.38794, dtype=float32), 'eval/episode_distance_reward_std': Array(5.93292, dtype=float32), 'eval/episode_forward_reward_std': Array(988.8134, dtype=float32), 'eval/episode_reward_std': Array(956.5086, dtype=float32), 'eval/episode_reward_alive_std': Array(47.37384, dtype=float32), 'eval/episode_reward_linvel_std': Array(988.8134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.358112, dtype=float32), 'eval/episode_x_position_std': Array(483.3482, dtype=float32), 'eval/episode_x_velocity_std': Array(197.76265, dtype=float32), 'eval/episode_y_position_std': Array(260.118, dtype=float32), 'eval/episode_y_velocity_std': Array(89.52826, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55194664001465, 'eval/sps': 937.3722099871653, 'num_steps': 26869760}
{'eval/walltime': 45077.974314689636, 'training/sps': 2966.590204265278, 'training/walltime': 9174.304356098175, 'training/entropy_loss': Array(0.01272537, dtype=float32), 'training/policy_loss': Array(0.0011951, dtype=float32), 'training/total_loss': Array(0.09791323, dtype=float32), 'training/v_loss': Array(0.08399276, dtype=float32), 'eval/episode_distance_from_origin': Array(4891.387, dtype=float32), 'eval/episode_distance_reward': Array(14.289626, dtype=float32), 'eval/episode_forward_reward': Array(2381.5947, dtype=float32), 'eval/episode_reward': Array(2397.0142, dtype=float32), 'eval/episode_reward_alive': Array(385.9336, dtype=float32), 'eval/episode_reward_linvel': Array(2381.5947, dtype=float32), 'eval/episode_reward_quadctrl': Array(-384.8036, dtype=float32), 'eval/episode_x_position': Array(4848.17, dtype=float32), 'eval/episode_x_velocity': Array(476.3189, dtype=float32), 'eval/episode_y_position': Array(71.889496, dtype=float32), 'eval/episode_y_velocity': Array(-46.062477, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.35153, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8601255, dtype=float32), 'eval/episode_forward_reward_std': Array(976.68134, dtype=float32), 'eval/episode_reward_std': Array(954.38983, dtype=float32), 'eval/episode_reward_alive_std': Array(52.625607, dtype=float32), 'eval/episode_reward_linvel_std': Array(976.68134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.613705, dtype=float32), 'eval/episode_x_position_std': Array(476.45856, dtype=float32), 'eval/episode_x_velocity_std': Array(195.33617, dtype=float32), 'eval/episode_y_position_std': Array(271.25735, dtype=float32), 'eval/episode_y_velocity_std': Array(85.606125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50971579551697, 'eval/sps': 937.66219681928, 'num_steps': 26951680}
{'eval/walltime': 45214.52775931358, 'training/sps': 2963.5962696905563, 'training/walltime': 9201.946447849274, 'training/entropy_loss': Array(0.01178068, dtype=float32), 'training/policy_loss': Array(0.00123404, dtype=float32), 'training/total_loss': Array(0.08178747, dtype=float32), 'training/v_loss': Array(0.06877273, dtype=float32), 'eval/episode_distance_from_origin': Array(4889.0557, dtype=float32), 'eval/episode_distance_reward': Array(14.316037, dtype=float32), 'eval/episode_forward_reward': Array(2385.996, dtype=float32), 'eval/episode_reward': Array(2411.6436, dtype=float32), 'eval/episode_reward_alive': Array(394.8203, dtype=float32), 'eval/episode_reward_linvel': Array(2385.996, dtype=float32), 'eval/episode_reward_quadctrl': Array(-383.48904, dtype=float32), 'eval/episode_x_position': Array(4845.951, dtype=float32), 'eval/episode_x_velocity': Array(477.19922, dtype=float32), 'eval/episode_y_position': Array(106.206345, dtype=float32), 'eval/episode_y_velocity': Array(-34.49719, dtype=float32), 'eval/episode_distance_from_origin_std': Array(500.71915, dtype=float32), 'eval/episode_distance_reward_std': Array(5.567999, dtype=float32), 'eval/episode_forward_reward_std': Array(927.99347, dtype=float32), 'eval/episode_reward_std': Array(894.24066, dtype=float32), 'eval/episode_reward_alive_std': Array(50.67859, dtype=float32), 'eval/episode_reward_linvel_std': Array(927.99347, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.785522, dtype=float32), 'eval/episode_x_position_std': Array(500.75974, dtype=float32), 'eval/episode_x_velocity_std': Array(185.59865, dtype=float32), 'eval/episode_y_position_std': Array(261.11572, dtype=float32), 'eval/episode_y_velocity_std': Array(93.56621, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55344462394714, 'eval/sps': 937.3619270645104, 'num_steps': 27033600}
{'eval/walltime': 45351.017058610916, 'training/sps': 2956.9478681818405, 'training/walltime': 9229.650690078735, 'training/entropy_loss': Array(0.01079247, dtype=float32), 'training/policy_loss': Array(0.00026822, dtype=float32), 'training/total_loss': Array(0.06582741, dtype=float32), 'training/v_loss': Array(0.05476671, dtype=float32), 'eval/episode_distance_from_origin': Array(5030.121, dtype=float32), 'eval/episode_distance_reward': Array(15.678662, dtype=float32), 'eval/episode_forward_reward': Array(2613.0986, dtype=float32), 'eval/episode_reward': Array(2633.0684, dtype=float32), 'eval/episode_reward_alive': Array(391.71484, dtype=float32), 'eval/episode_reward_linvel': Array(2613.0986, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.42337, dtype=float32), 'eval/episode_x_position': Array(4988.36, dtype=float32), 'eval/episode_x_velocity': Array(522.6197, dtype=float32), 'eval/episode_y_position': Array(98.04862, dtype=float32), 'eval/episode_y_velocity': Array(-44.715237, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.19727, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4632597, dtype=float32), 'eval/episode_forward_reward_std': Array(910.5368, dtype=float32), 'eval/episode_reward_std': Array(890.7154, dtype=float32), 'eval/episode_reward_alive_std': Array(45.804897, dtype=float32), 'eval/episode_reward_linvel_std': Array(910.5368, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.702507, dtype=float32), 'eval/episode_x_position_std': Array(471.6918, dtype=float32), 'eval/episode_x_velocity_std': Array(182.1074, dtype=float32), 'eval/episode_y_position_std': Array(247.98671, dtype=float32), 'eval/episode_y_velocity_std': Array(84.64069, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48929929733276, 'eval/sps': 937.8024552764433, 'num_steps': 27115520}
{'eval/walltime': 45487.56447863579, 'training/sps': 2956.6593776484074, 'training/walltime': 9257.357635498047, 'training/entropy_loss': Array(0.00844032, dtype=float32), 'training/policy_loss': Array(-0.0008212, dtype=float32), 'training/total_loss': Array(0.05524419, dtype=float32), 'training/v_loss': Array(0.04762507, dtype=float32), 'eval/episode_distance_from_origin': Array(5015.18, dtype=float32), 'eval/episode_distance_reward': Array(15.4066925, dtype=float32), 'eval/episode_forward_reward': Array(2567.7715, dtype=float32), 'eval/episode_reward': Array(2586.0513, dtype=float32), 'eval/episode_reward_alive': Array(389.33203, dtype=float32), 'eval/episode_reward_linvel': Array(2567.7715, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.4588, dtype=float32), 'eval/episode_x_position': Array(4972.4907, dtype=float32), 'eval/episode_x_velocity': Array(513.55426, dtype=float32), 'eval/episode_y_position': Array(87.199066, dtype=float32), 'eval/episode_y_velocity': Array(-39.459282, dtype=float32), 'eval/episode_distance_from_origin_std': Array(493.5269, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7110243, dtype=float32), 'eval/episode_forward_reward_std': Array(951.831, dtype=float32), 'eval/episode_reward_std': Array(925.79944, dtype=float32), 'eval/episode_reward_alive_std': Array(45.567142, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.831, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.694878, dtype=float32), 'eval/episode_x_position_std': Array(493.10797, dtype=float32), 'eval/episode_x_velocity_std': Array(190.3662, dtype=float32), 'eval/episode_y_position_std': Array(272.8646, dtype=float32), 'eval/episode_y_velocity_std': Array(90.33243, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54742002487183, 'eval/sps': 937.4032843438937, 'num_steps': 27197440}
{'eval/walltime': 45624.05020022392, 'training/sps': 2948.14441065102, 'training/walltime': 9285.144605398178, 'training/entropy_loss': Array(0.01645363, dtype=float32), 'training/policy_loss': Array(0.00690469, dtype=float32), 'training/total_loss': Array(0.13437186, dtype=float32), 'training/v_loss': Array(0.11101355, dtype=float32), 'eval/episode_distance_from_origin': Array(4948.0923, dtype=float32), 'eval/episode_distance_reward': Array(14.7392025, dtype=float32), 'eval/episode_forward_reward': Array(2456.5227, dtype=float32), 'eval/episode_reward': Array(2464.9255, dtype=float32), 'eval/episode_reward_alive': Array(391.8711, dtype=float32), 'eval/episode_reward_linvel': Array(2456.5227, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.20737, dtype=float32), 'eval/episode_x_position': Array(4905.921, dtype=float32), 'eval/episode_x_velocity': Array(491.30457, dtype=float32), 'eval/episode_y_position': Array(69.92504, dtype=float32), 'eval/episode_y_velocity': Array(-47.891296, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.61655, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3790774, dtype=float32), 'eval/episode_forward_reward_std': Array(896.50684, dtype=float32), 'eval/episode_reward_std': Array(876.5403, dtype=float32), 'eval/episode_reward_alive_std': Array(48.81363, dtype=float32), 'eval/episode_reward_linvel_std': Array(896.50684, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.918636, dtype=float32), 'eval/episode_x_position_std': Array(453.56693, dtype=float32), 'eval/episode_x_velocity_std': Array(179.30139, dtype=float32), 'eval/episode_y_position_std': Array(257.69406, dtype=float32), 'eval/episode_y_velocity_std': Array(84.14591, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48572158813477, 'eval/sps': 937.827037953892, 'num_steps': 27279360}
{'eval/walltime': 45760.60361504555, 'training/sps': 2940.39795919424, 'training/walltime': 9313.004779815674, 'training/entropy_loss': Array(0.01367419, dtype=float32), 'training/policy_loss': Array(0.00373, dtype=float32), 'training/total_loss': Array(0.1280509, dtype=float32), 'training/v_loss': Array(0.11064669, dtype=float32), 'eval/episode_distance_from_origin': Array(5001.123, dtype=float32), 'eval/episode_distance_reward': Array(15.119913, dtype=float32), 'eval/episode_forward_reward': Array(2519.9736, dtype=float32), 'eval/episode_reward': Array(2535.8042, dtype=float32), 'eval/episode_reward_alive': Array(384.51562, dtype=float32), 'eval/episode_reward_linvel': Array(2519.9736, dtype=float32), 'eval/episode_reward_quadctrl': Array(-383.80542, dtype=float32), 'eval/episode_x_position': Array(4959.177, dtype=float32), 'eval/episode_x_velocity': Array(503.99472, dtype=float32), 'eval/episode_y_position': Array(0.08046532, dtype=float32), 'eval/episode_y_velocity': Array(-69.035416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.75027, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0978026, dtype=float32), 'eval/episode_forward_reward_std': Array(849.6279, dtype=float32), 'eval/episode_reward_std': Array(828.6921, dtype=float32), 'eval/episode_reward_alive_std': Array(47.036465, dtype=float32), 'eval/episode_reward_linvel_std': Array(849.6279, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.27788, dtype=float32), 'eval/episode_x_position_std': Array(451.63937, dtype=float32), 'eval/episode_x_velocity_std': Array(169.92564, dtype=float32), 'eval/episode_y_position_std': Array(248.93004, dtype=float32), 'eval/episode_y_velocity_std': Array(86.238716, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55341482162476, 'eval/sps': 937.3621316405906, 'num_steps': 27361280}
{'eval/walltime': 45897.09552884102, 'training/sps': 2936.78810919287, 'training/walltime': 9340.899199485779, 'training/entropy_loss': Array(0.01357974, dtype=float32), 'training/policy_loss': Array(0.00228814, dtype=float32), 'training/total_loss': Array(0.12294398, dtype=float32), 'training/v_loss': Array(0.10707611, dtype=float32), 'eval/episode_distance_from_origin': Array(5043.894, dtype=float32), 'eval/episode_distance_reward': Array(15.595097, dtype=float32), 'eval/episode_forward_reward': Array(2599.1719, dtype=float32), 'eval/episode_reward': Array(2597.9722, dtype=float32), 'eval/episode_reward_alive': Array(377.9453, dtype=float32), 'eval/episode_reward_linvel': Array(2599.1719, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.74057, dtype=float32), 'eval/episode_x_position': Array(5002.4995, dtype=float32), 'eval/episode_x_velocity': Array(519.8345, dtype=float32), 'eval/episode_y_position': Array(0.02772355, dtype=float32), 'eval/episode_y_velocity': Array(-71.75763, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.75824, dtype=float32), 'eval/episode_distance_reward_std': Array(5.301762, dtype=float32), 'eval/episode_forward_reward_std': Array(883.62085, dtype=float32), 'eval/episode_reward_std': Array(866.45026, dtype=float32), 'eval/episode_reward_alive_std': Array(51.450603, dtype=float32), 'eval/episode_reward_linvel_std': Array(883.62085, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.905357, dtype=float32), 'eval/episode_x_position_std': Array(452.5218, dtype=float32), 'eval/episode_x_velocity_std': Array(176.72418, dtype=float32), 'eval/episode_y_position_std': Array(242.18895, dtype=float32), 'eval/episode_y_velocity_std': Array(79.224, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4919137954712, 'eval/sps': 937.7844917011271, 'num_steps': 27443200}
{'eval/walltime': 46033.619736909866, 'training/sps': 2933.8156184964173, 'training/walltime': 9368.82188129425, 'training/entropy_loss': Array(0.01244882, dtype=float32), 'training/policy_loss': Array(0.01146488, dtype=float32), 'training/total_loss': Array(0.10584004, dtype=float32), 'training/v_loss': Array(0.08192635, dtype=float32), 'eval/episode_distance_from_origin': Array(4862.054, dtype=float32), 'eval/episode_distance_reward': Array(13.680195, dtype=float32), 'eval/episode_forward_reward': Array(2280.0227, dtype=float32), 'eval/episode_reward': Array(2295.601, dtype=float32), 'eval/episode_reward_alive': Array(401.73438, dtype=float32), 'eval/episode_reward_linvel': Array(2280.0227, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.83643, dtype=float32), 'eval/episode_x_position': Array(4819.6377, dtype=float32), 'eval/episode_x_velocity': Array(456.00458, dtype=float32), 'eval/episode_y_position': Array(39.33776, dtype=float32), 'eval/episode_y_velocity': Array(-53.584763, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.09656, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2070036, dtype=float32), 'eval/episode_forward_reward_std': Array(867.82733, dtype=float32), 'eval/episode_reward_std': Array(839.3444, dtype=float32), 'eval/episode_reward_alive_std': Array(48.74943, dtype=float32), 'eval/episode_reward_linvel_std': Array(867.82733, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.866257, dtype=float32), 'eval/episode_x_position_std': Array(436.69705, dtype=float32), 'eval/episode_x_velocity_std': Array(173.56549, dtype=float32), 'eval/episode_y_position_std': Array(244.01566, dtype=float32), 'eval/episode_y_velocity_std': Array(88.57199, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52420806884766, 'eval/sps': 937.562662406736, 'num_steps': 27525120}
{'eval/walltime': 46170.079461336136, 'training/sps': 2945.5264765755483, 'training/walltime': 9396.633547782898, 'training/entropy_loss': Array(0.01220708, dtype=float32), 'training/policy_loss': Array(0.00542597, dtype=float32), 'training/total_loss': Array(0.08397298, dtype=float32), 'training/v_loss': Array(0.06633992, dtype=float32), 'eval/episode_distance_from_origin': Array(4897.2, dtype=float32), 'eval/episode_distance_reward': Array(13.551006, dtype=float32), 'eval/episode_forward_reward': Array(2258.4922, dtype=float32), 'eval/episode_reward': Array(2269.1401, dtype=float32), 'eval/episode_reward_alive': Array(405.89453, dtype=float32), 'eval/episode_reward_linvel': Array(2258.4922, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.7971, dtype=float32), 'eval/episode_x_position': Array(4854.751, dtype=float32), 'eval/episode_x_velocity': Array(451.69836, dtype=float32), 'eval/episode_y_position': Array(-4.039409, dtype=float32), 'eval/episode_y_velocity': Array(-62.146614, dtype=float32), 'eval/episode_distance_from_origin_std': Array(432.28, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5469713, dtype=float32), 'eval/episode_forward_reward_std': Array(757.8233, dtype=float32), 'eval/episode_reward_std': Array(724.9673, dtype=float32), 'eval/episode_reward_alive_std': Array(45.306446, dtype=float32), 'eval/episode_reward_linvel_std': Array(757.8233, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.332485, dtype=float32), 'eval/episode_x_position_std': Array(432.73993, dtype=float32), 'eval/episode_x_velocity_std': Array(151.5646, dtype=float32), 'eval/episode_y_position_std': Array(238.15828, dtype=float32), 'eval/episode_y_velocity_std': Array(80.35185, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45972442626953, 'eval/sps': 938.0057048932383, 'num_steps': 27607040}
{'eval/walltime': 46306.63929796219, 'training/sps': 2937.6900732866916, 'training/walltime': 9424.519402980804, 'training/entropy_loss': Array(0.00952262, dtype=float32), 'training/policy_loss': Array(0.00148917, dtype=float32), 'training/total_loss': Array(0.05775245, dtype=float32), 'training/v_loss': Array(0.04674066, dtype=float32), 'eval/episode_distance_from_origin': Array(4890.152, dtype=float32), 'eval/episode_distance_reward': Array(13.639209, dtype=float32), 'eval/episode_forward_reward': Array(2273.1914, dtype=float32), 'eval/episode_reward': Array(2292.4858, dtype=float32), 'eval/episode_reward_alive': Array(402.2422, dtype=float32), 'eval/episode_reward_linvel': Array(2273.1914, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.5873, dtype=float32), 'eval/episode_x_position': Array(4846.0293, dtype=float32), 'eval/episode_x_velocity': Array(454.6384, dtype=float32), 'eval/episode_y_position': Array(34.831207, dtype=float32), 'eval/episode_y_velocity': Array(-58.85025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(405.69287, dtype=float32), 'eval/episode_distance_reward_std': Array(4.691392, dtype=float32), 'eval/episode_forward_reward_std': Array(781.89264, dtype=float32), 'eval/episode_reward_std': Array(751.9377, dtype=float32), 'eval/episode_reward_alive_std': Array(48.557793, dtype=float32), 'eval/episode_reward_linvel_std': Array(781.89264, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.57665, dtype=float32), 'eval/episode_x_position_std': Array(402.72595, dtype=float32), 'eval/episode_x_velocity_std': Array(156.37854, dtype=float32), 'eval/episode_y_position_std': Array(270.23434, dtype=float32), 'eval/episode_y_velocity_std': Array(90.46048, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55983662605286, 'eval/sps': 937.3180516501891, 'num_steps': 27688960}
{'eval/walltime': 46443.12558555603, 'training/sps': 2944.3618629774046, 'training/walltime': 9452.342070102692, 'training/entropy_loss': Array(0.01715595, dtype=float32), 'training/policy_loss': Array(0.00732292, dtype=float32), 'training/total_loss': Array(0.12263128, dtype=float32), 'training/v_loss': Array(0.09815241, dtype=float32), 'eval/episode_distance_from_origin': Array(4924.473, dtype=float32), 'eval/episode_distance_reward': Array(13.705389, dtype=float32), 'eval/episode_forward_reward': Array(2284.2217, dtype=float32), 'eval/episode_reward': Array(2301.7317, dtype=float32), 'eval/episode_reward_alive': Array(400.95312, dtype=float32), 'eval/episode_reward_linvel': Array(2284.2217, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.14825, dtype=float32), 'eval/episode_x_position': Array(4880.5415, dtype=float32), 'eval/episode_x_velocity': Array(456.8443, dtype=float32), 'eval/episode_y_position': Array(41.5901, dtype=float32), 'eval/episode_y_velocity': Array(-51.319298, dtype=float32), 'eval/episode_distance_from_origin_std': Array(437.42914, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7558527, dtype=float32), 'eval/episode_forward_reward_std': Array(792.6361, dtype=float32), 'eval/episode_reward_std': Array(759.78973, dtype=float32), 'eval/episode_reward_alive_std': Array(53.59452, dtype=float32), 'eval/episode_reward_linvel_std': Array(792.6361, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.69049, dtype=float32), 'eval/episode_x_position_std': Array(436.50778, dtype=float32), 'eval/episode_x_velocity_std': Array(158.52716, dtype=float32), 'eval/episode_y_position_std': Array(269.64523, dtype=float32), 'eval/episode_y_velocity_std': Array(97.1979, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48628759384155, 'eval/sps': 937.8231488052836, 'num_steps': 27770880}
{'eval/walltime': 46579.676522254944, 'training/sps': 2941.380650931981, 'training/walltime': 9480.19293665886, 'training/entropy_loss': Array(0.01336426, dtype=float32), 'training/policy_loss': Array(0.00206837, dtype=float32), 'training/total_loss': Array(0.09496382, dtype=float32), 'training/v_loss': Array(0.07953118, dtype=float32), 'eval/episode_distance_from_origin': Array(4902.6514, dtype=float32), 'eval/episode_distance_reward': Array(13.700462, dtype=float32), 'eval/episode_forward_reward': Array(2283.4, dtype=float32), 'eval/episode_reward': Array(2293.9106, dtype=float32), 'eval/episode_reward_alive': Array(398.42578, dtype=float32), 'eval/episode_reward_linvel': Array(2283.4, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.61572, dtype=float32), 'eval/episode_x_position': Array(4858.4326, dtype=float32), 'eval/episode_x_velocity': Array(456.68, dtype=float32), 'eval/episode_y_position': Array(0.61845183, dtype=float32), 'eval/episode_y_velocity': Array(-70.109344, dtype=float32), 'eval/episode_distance_from_origin_std': Array(371.27487, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5821033, dtype=float32), 'eval/episode_forward_reward_std': Array(763.67773, dtype=float32), 'eval/episode_reward_std': Array(729.8784, dtype=float32), 'eval/episode_reward_alive_std': Array(47.498356, dtype=float32), 'eval/episode_reward_linvel_std': Array(763.67773, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.22204, dtype=float32), 'eval/episode_x_position_std': Array(369.7949, dtype=float32), 'eval/episode_x_velocity_std': Array(152.73555, dtype=float32), 'eval/episode_y_position_std': Array(258.53238, dtype=float32), 'eval/episode_y_velocity_std': Array(90.95011, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55093669891357, 'eval/sps': 937.3791428632389, 'num_steps': 27852800}
{'eval/walltime': 46716.1490278244, 'training/sps': 2924.81298700401, 'training/walltime': 9508.201565027237, 'training/entropy_loss': Array(0.01400192, dtype=float32), 'training/policy_loss': Array(0.00273629, dtype=float32), 'training/total_loss': Array(0.09010493, dtype=float32), 'training/v_loss': Array(0.07336673, dtype=float32), 'eval/episode_distance_from_origin': Array(4916.917, dtype=float32), 'eval/episode_distance_reward': Array(13.361868, dtype=float32), 'eval/episode_forward_reward': Array(2226.9692, dtype=float32), 'eval/episode_reward': Array(2244.3774, dtype=float32), 'eval/episode_reward_alive': Array(402.22656, dtype=float32), 'eval/episode_reward_linvel': Array(2226.9692, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.18048, dtype=float32), 'eval/episode_x_position': Array(4873.8613, dtype=float32), 'eval/episode_x_velocity': Array(445.39383, dtype=float32), 'eval/episode_y_position': Array(-10.657841, dtype=float32), 'eval/episode_y_velocity': Array(-64.09587, dtype=float32), 'eval/episode_distance_from_origin_std': Array(410.0629, dtype=float32), 'eval/episode_distance_reward_std': Array(4.755156, dtype=float32), 'eval/episode_forward_reward_std': Array(792.5199, dtype=float32), 'eval/episode_reward_std': Array(768.5911, dtype=float32), 'eval/episode_reward_alive_std': Array(53.831074, dtype=float32), 'eval/episode_reward_linvel_std': Array(792.5199, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.727085, dtype=float32), 'eval/episode_x_position_std': Array(409.7278, dtype=float32), 'eval/episode_x_velocity_std': Array(158.50392, dtype=float32), 'eval/episode_y_position_std': Array(253.22906, dtype=float32), 'eval/episode_y_velocity_std': Array(88.022736, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.472505569458, 'eval/sps': 937.9178572701891, 'num_steps': 27934720}
{'eval/walltime': 46852.709742069244, 'training/sps': 2937.0538048761823, 'training/walltime': 9536.0934612751, 'training/entropy_loss': Array(0.01331327, dtype=float32), 'training/policy_loss': Array(0.01431162, dtype=float32), 'training/total_loss': Array(0.08735522, dtype=float32), 'training/v_loss': Array(0.05973032, dtype=float32), 'eval/episode_distance_from_origin': Array(4909.092, dtype=float32), 'eval/episode_distance_reward': Array(13.540423, dtype=float32), 'eval/episode_forward_reward': Array(2256.7273, dtype=float32), 'eval/episode_reward': Array(2265.8489, dtype=float32), 'eval/episode_reward_alive': Array(396.07422, dtype=float32), 'eval/episode_reward_linvel': Array(2256.7273, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.49292, dtype=float32), 'eval/episode_x_position': Array(4866.4785, dtype=float32), 'eval/episode_x_velocity': Array(451.34546, dtype=float32), 'eval/episode_y_position': Array(-30.051739, dtype=float32), 'eval/episode_y_velocity': Array(-72.67533, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.58163, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6335735, dtype=float32), 'eval/episode_forward_reward_std': Array(772.25574, dtype=float32), 'eval/episode_reward_std': Array(747.7125, dtype=float32), 'eval/episode_reward_alive_std': Array(53.407562, dtype=float32), 'eval/episode_reward_linvel_std': Array(772.25574, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.96358, dtype=float32), 'eval/episode_x_position_std': Array(421.05008, dtype=float32), 'eval/episode_x_velocity_std': Array(154.45125, dtype=float32), 'eval/episode_y_position_std': Array(233.75095, dtype=float32), 'eval/episode_y_velocity_std': Array(84.0745, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56071424484253, 'eval/sps': 937.3120278977609, 'num_steps': 28016640}
{'eval/walltime': 46989.21040511131, 'training/sps': 2944.3762194221395, 'training/walltime': 9563.915992736816, 'training/entropy_loss': Array(0.01274084, dtype=float32), 'training/policy_loss': Array(0.00404752, dtype=float32), 'training/total_loss': Array(0.0737264, dtype=float32), 'training/v_loss': Array(0.05693805, dtype=float32), 'eval/episode_distance_from_origin': Array(4927.1787, dtype=float32), 'eval/episode_distance_reward': Array(13.6079855, dtype=float32), 'eval/episode_forward_reward': Array(2267.9878, dtype=float32), 'eval/episode_reward': Array(2266.3755, dtype=float32), 'eval/episode_reward_alive': Array(393.08984, dtype=float32), 'eval/episode_reward_linvel': Array(2267.9878, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.31012, dtype=float32), 'eval/episode_x_position': Array(4881.806, dtype=float32), 'eval/episode_x_velocity': Array(453.5976, dtype=float32), 'eval/episode_y_position': Array(-62.222916, dtype=float32), 'eval/episode_y_velocity': Array(-84.87999, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.1162, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5254784, dtype=float32), 'eval/episode_forward_reward_std': Array(754.2413, dtype=float32), 'eval/episode_reward_std': Array(737.47736, dtype=float32), 'eval/episode_reward_alive_std': Array(51.39497, dtype=float32), 'eval/episode_reward_linvel_std': Array(754.2413, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.386765, dtype=float32), 'eval/episode_x_position_std': Array(418.14014, dtype=float32), 'eval/episode_x_velocity_std': Array(150.84822, dtype=float32), 'eval/episode_y_position_std': Array(252.08894, dtype=float32), 'eval/episode_y_velocity_std': Array(87.2505, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50066304206848, 'eval/sps': 937.7243827786489, 'num_steps': 28098560}
{'eval/walltime': 47125.757135391235, 'training/sps': 2941.521261766078, 'training/walltime': 9591.765527963638, 'training/entropy_loss': Array(0.01027576, dtype=float32), 'training/policy_loss': Array(0.00711771, dtype=float32), 'training/total_loss': Array(0.0531191, dtype=float32), 'training/v_loss': Array(0.03572563, dtype=float32), 'eval/episode_distance_from_origin': Array(4983.8057, dtype=float32), 'eval/episode_distance_reward': Array(14.36927, dtype=float32), 'eval/episode_forward_reward': Array(2394.8684, dtype=float32), 'eval/episode_reward': Array(2402.7173, dtype=float32), 'eval/episode_reward_alive': Array(389.08594, dtype=float32), 'eval/episode_reward_linvel': Array(2394.8684, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.6065, dtype=float32), 'eval/episode_x_position': Array(4939.3643, dtype=float32), 'eval/episode_x_velocity': Array(478.97363, dtype=float32), 'eval/episode_y_position': Array(-63.991615, dtype=float32), 'eval/episode_y_velocity': Array(-88.735535, dtype=float32), 'eval/episode_distance_from_origin_std': Array(474.42282, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0932946, dtype=float32), 'eval/episode_forward_reward_std': Array(848.8754, dtype=float32), 'eval/episode_reward_std': Array(823.1591, dtype=float32), 'eval/episode_reward_alive_std': Array(53.12482, dtype=float32), 'eval/episode_reward_linvel_std': Array(848.8754, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.820652, dtype=float32), 'eval/episode_x_position_std': Array(473.28772, dtype=float32), 'eval/episode_x_velocity_std': Array(169.77509, dtype=float32), 'eval/episode_y_position_std': Array(255.00232, dtype=float32), 'eval/episode_y_velocity_std': Array(87.9734, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54673027992249, 'eval/sps': 937.4080194933882, 'num_steps': 28180480}
{'eval/walltime': 47262.27506828308, 'training/sps': 2954.049366478398, 'training/walltime': 9619.496953487396, 'training/entropy_loss': Array(0.01243423, dtype=float32), 'training/policy_loss': Array(0.00208004, dtype=float32), 'training/total_loss': Array(0.09876023, dtype=float32), 'training/v_loss': Array(0.08424596, dtype=float32), 'eval/episode_distance_from_origin': Array(5004.7188, dtype=float32), 'eval/episode_distance_reward': Array(14.520447, dtype=float32), 'eval/episode_forward_reward': Array(2420.0635, dtype=float32), 'eval/episode_reward': Array(2409.3142, dtype=float32), 'eval/episode_reward_alive': Array(383.21875, dtype=float32), 'eval/episode_reward_linvel': Array(2420.0635, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.48807, dtype=float32), 'eval/episode_x_position': Array(4960.7725, dtype=float32), 'eval/episode_x_velocity': Array(484.0127, dtype=float32), 'eval/episode_y_position': Array(-63.368683, dtype=float32), 'eval/episode_y_velocity': Array(-91.80745, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.605, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5001516, dtype=float32), 'eval/episode_forward_reward_std': Array(750.01886, dtype=float32), 'eval/episode_reward_std': Array(731.1261, dtype=float32), 'eval/episode_reward_alive_std': Array(51.431984, dtype=float32), 'eval/episode_reward_linvel_std': Array(750.01886, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.12964, dtype=float32), 'eval/episode_x_position_std': Array(428.97818, dtype=float32), 'eval/episode_x_velocity_std': Array(150.00377, dtype=float32), 'eval/episode_y_position_std': Array(236.22664, dtype=float32), 'eval/episode_y_velocity_std': Array(83.26513, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5179328918457, 'eval/sps': 937.6057583688005, 'num_steps': 28262400}
{'eval/walltime': 47398.936972141266, 'training/sps': 2936.6746810177365, 'training/walltime': 9647.39245057106, 'training/entropy_loss': Array(0.01495791, dtype=float32), 'training/policy_loss': Array(0.00476144, dtype=float32), 'training/total_loss': Array(0.14061433, dtype=float32), 'training/v_loss': Array(0.12089499, dtype=float32), 'eval/episode_distance_from_origin': Array(5000.0977, dtype=float32), 'eval/episode_distance_reward': Array(14.130031, dtype=float32), 'eval/episode_forward_reward': Array(2354.9946, dtype=float32), 'eval/episode_reward': Array(2353.2622, dtype=float32), 'eval/episode_reward_alive': Array(388.60156, dtype=float32), 'eval/episode_reward_linvel': Array(2354.9946, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.46423, dtype=float32), 'eval/episode_x_position': Array(4955.666, dtype=float32), 'eval/episode_x_velocity': Array(470.99896, dtype=float32), 'eval/episode_y_position': Array(-47.275185, dtype=float32), 'eval/episode_y_velocity': Array(-81.951416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(408.4983, dtype=float32), 'eval/episode_distance_reward_std': Array(4.373224, dtype=float32), 'eval/episode_forward_reward_std': Array(728.86505, dtype=float32), 'eval/episode_reward_std': Array(704.8723, dtype=float32), 'eval/episode_reward_alive_std': Array(56.523964, dtype=float32), 'eval/episode_reward_linvel_std': Array(728.86505, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.163, dtype=float32), 'eval/episode_x_position_std': Array(406.15073, dtype=float32), 'eval/episode_x_velocity_std': Array(145.77296, dtype=float32), 'eval/episode_y_position_std': Array(262.98798, dtype=float32), 'eval/episode_y_velocity_std': Array(91.2435, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66190385818481, 'eval/sps': 936.6180068208815, 'num_steps': 28344320}
{'eval/walltime': 47535.478078603745, 'training/sps': 2944.200823033786, 'training/walltime': 9675.216639518738, 'training/entropy_loss': Array(0.01447604, dtype=float32), 'training/policy_loss': Array(0.02309499, dtype=float32), 'training/total_loss': Array(0.13202068, dtype=float32), 'training/v_loss': Array(0.09444965, dtype=float32), 'eval/episode_distance_from_origin': Array(4949.615, dtype=float32), 'eval/episode_distance_reward': Array(13.73883, dtype=float32), 'eval/episode_forward_reward': Array(2289.7947, dtype=float32), 'eval/episode_reward': Array(2304.7854, dtype=float32), 'eval/episode_reward_alive': Array(393.98438, dtype=float32), 'eval/episode_reward_linvel': Array(2289.7947, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.7328, dtype=float32), 'eval/episode_x_position': Array(4903.0005, dtype=float32), 'eval/episode_x_velocity': Array(457.95892, dtype=float32), 'eval/episode_y_position': Array(-17.646633, dtype=float32), 'eval/episode_y_velocity': Array(-69.570206, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.16223, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5772905, dtype=float32), 'eval/episode_forward_reward_std': Array(762.8756, dtype=float32), 'eval/episode_reward_std': Array(725.71045, dtype=float32), 'eval/episode_reward_alive_std': Array(56.597534, dtype=float32), 'eval/episode_reward_linvel_std': Array(762.8756, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.856754, dtype=float32), 'eval/episode_x_position_std': Array(393.17438, dtype=float32), 'eval/episode_x_velocity_std': Array(152.57515, dtype=float32), 'eval/episode_y_position_std': Array(305.62015, dtype=float32), 'eval/episode_y_velocity_std': Array(101.502945, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54110646247864, 'eval/sps': 937.4466291964192, 'num_steps': 28426240}
{'eval/walltime': 47672.11536741257, 'training/sps': 2936.227981209536, 'training/walltime': 9703.11638045311, 'training/entropy_loss': Array(0.01365469, dtype=float32), 'training/policy_loss': Array(0.00465482, dtype=float32), 'training/total_loss': Array(0.09804182, dtype=float32), 'training/v_loss': Array(0.0797323, dtype=float32), 'eval/episode_distance_from_origin': Array(5042.0244, dtype=float32), 'eval/episode_distance_reward': Array(14.64164, dtype=float32), 'eval/episode_forward_reward': Array(2440.2632, dtype=float32), 'eval/episode_reward': Array(2444.6865, dtype=float32), 'eval/episode_reward_alive': Array(393.04688, dtype=float32), 'eval/episode_reward_linvel': Array(2440.2632, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.2653, dtype=float32), 'eval/episode_x_position': Array(4996.461, dtype=float32), 'eval/episode_x_velocity': Array(488.05255, dtype=float32), 'eval/episode_y_position': Array(9.9833975, dtype=float32), 'eval/episode_y_velocity': Array(-63.350693, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.48212, dtype=float32), 'eval/episode_distance_reward_std': Array(5.32043, dtype=float32), 'eval/episode_forward_reward_std': Array(886.7319, dtype=float32), 'eval/episode_reward_std': Array(858.2678, dtype=float32), 'eval/episode_reward_alive_std': Array(54.218323, dtype=float32), 'eval/episode_reward_linvel_std': Array(886.7319, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.793285, dtype=float32), 'eval/episode_x_position_std': Array(459.64636, dtype=float32), 'eval/episode_x_velocity_std': Array(177.34636, dtype=float32), 'eval/episode_y_position_std': Array(306.82275, dtype=float32), 'eval/episode_y_velocity_std': Array(97.76418, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63728880882263, 'eval/sps': 936.78673747027, 'num_steps': 28508160}
{'eval/walltime': 47808.64922165871, 'training/sps': 2946.9190119937944, 'training/walltime': 9730.91490483284, 'training/entropy_loss': Array(0.01297662, dtype=float32), 'training/policy_loss': Array(0.00197368, dtype=float32), 'training/total_loss': Array(0.06949872, dtype=float32), 'training/v_loss': Array(0.05454842, dtype=float32), 'eval/episode_distance_from_origin': Array(5050.312, dtype=float32), 'eval/episode_distance_reward': Array(14.410379, dtype=float32), 'eval/episode_forward_reward': Array(2401.7192, dtype=float32), 'eval/episode_reward': Array(2405.5618, dtype=float32), 'eval/episode_reward_alive': Array(384.5586, dtype=float32), 'eval/episode_reward_linvel': Array(2401.7192, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.12646, dtype=float32), 'eval/episode_x_position': Array(5008.578, dtype=float32), 'eval/episode_x_velocity': Array(480.34387, dtype=float32), 'eval/episode_y_position': Array(-27.97715, dtype=float32), 'eval/episode_y_velocity': Array(-73.739265, dtype=float32), 'eval/episode_distance_from_origin_std': Array(404.18597, dtype=float32), 'eval/episode_distance_reward_std': Array(4.281018, dtype=float32), 'eval/episode_forward_reward_std': Array(713.49664, dtype=float32), 'eval/episode_reward_std': Array(684.5849, dtype=float32), 'eval/episode_reward_alive_std': Array(59.820095, dtype=float32), 'eval/episode_reward_linvel_std': Array(713.49664, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.47412, dtype=float32), 'eval/episode_x_position_std': Array(403.6535, dtype=float32), 'eval/episode_x_velocity_std': Array(142.69937, dtype=float32), 'eval/episode_y_position_std': Array(242.54088, dtype=float32), 'eval/episode_y_velocity_std': Array(90.52317, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53385424613953, 'eval/sps': 937.4964231892632, 'num_steps': 28590080}
{'eval/walltime': 47945.333939790726, 'training/sps': 2937.9288015407997, 'training/walltime': 9758.79849410057, 'training/entropy_loss': Array(0.01224838, dtype=float32), 'training/policy_loss': Array(0.00433516, dtype=float32), 'training/total_loss': Array(0.05663577, dtype=float32), 'training/v_loss': Array(0.04005222, dtype=float32), 'eval/episode_distance_from_origin': Array(4979.549, dtype=float32), 'eval/episode_distance_reward': Array(13.893345, dtype=float32), 'eval/episode_forward_reward': Array(2315.5469, dtype=float32), 'eval/episode_reward': Array(2316.4258, dtype=float32), 'eval/episode_reward_alive': Array(391.34766, dtype=float32), 'eval/episode_reward_linvel': Array(2315.5469, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.36255, dtype=float32), 'eval/episode_x_position': Array(4937.5947, dtype=float32), 'eval/episode_x_velocity': Array(463.10944, dtype=float32), 'eval/episode_y_position': Array(-32.63699, dtype=float32), 'eval/episode_y_velocity': Array(-73.06219, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.34912, dtype=float32), 'eval/episode_distance_reward_std': Array(4.655278, dtype=float32), 'eval/episode_forward_reward_std': Array(775.87354, dtype=float32), 'eval/episode_reward_std': Array(753.8695, dtype=float32), 'eval/episode_reward_alive_std': Array(59.03146, dtype=float32), 'eval/episode_reward_linvel_std': Array(775.87354, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.311737, dtype=float32), 'eval/episode_x_position_std': Array(427.44415, dtype=float32), 'eval/episode_x_velocity_std': Array(155.17467, dtype=float32), 'eval/episode_y_position_std': Array(235.68709, dtype=float32), 'eval/episode_y_velocity_std': Array(87.30345, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.68471813201904, 'eval/sps': 936.4616743502315, 'num_steps': 28672000}
{'eval/walltime': 48081.8900039196, 'training/sps': 2947.6777778293463, 'training/walltime': 9786.589862823486, 'training/entropy_loss': Array(0.01157888, dtype=float32), 'training/policy_loss': Array(0.00328592, dtype=float32), 'training/total_loss': Array(0.11446758, dtype=float32), 'training/v_loss': Array(0.09960277, dtype=float32), 'eval/episode_distance_from_origin': Array(5046.298, dtype=float32), 'eval/episode_distance_reward': Array(14.368752, dtype=float32), 'eval/episode_forward_reward': Array(2394.7808, dtype=float32), 'eval/episode_reward': Array(2390.4526, dtype=float32), 'eval/episode_reward_alive': Array(386.23828, dtype=float32), 'eval/episode_reward_linvel': Array(2394.7808, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.9348, dtype=float32), 'eval/episode_x_position': Array(5001.4375, dtype=float32), 'eval/episode_x_velocity': Array(478.95612, dtype=float32), 'eval/episode_y_position': Array(-59.098354, dtype=float32), 'eval/episode_y_velocity': Array(-90.55413, dtype=float32), 'eval/episode_distance_from_origin_std': Array(399.2701, dtype=float32), 'eval/episode_distance_reward_std': Array(4.249541, dtype=float32), 'eval/episode_forward_reward_std': Array(708.2514, dtype=float32), 'eval/episode_reward_std': Array(688.6544, dtype=float32), 'eval/episode_reward_alive_std': Array(58.73793, dtype=float32), 'eval/episode_reward_linvel_std': Array(708.2514, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.451454, dtype=float32), 'eval/episode_x_position_std': Array(395.9054, dtype=float32), 'eval/episode_x_velocity_std': Array(141.65036, dtype=float32), 'eval/episode_y_position_std': Array(264.65637, dtype=float32), 'eval/episode_y_velocity_std': Array(95.23683, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55606412887573, 'eval/sps': 937.343945994219, 'num_steps': 28753920}
{'eval/walltime': 48218.528071165085, 'training/sps': 2925.0441735685736, 'training/walltime': 9814.596277475357, 'training/entropy_loss': Array(0.01491181, dtype=float32), 'training/policy_loss': Array(0.00350045, dtype=float32), 'training/total_loss': Array(0.13953018, dtype=float32), 'training/v_loss': Array(0.12111793, dtype=float32), 'eval/episode_distance_from_origin': Array(5021.2783, dtype=float32), 'eval/episode_distance_reward': Array(13.847617, dtype=float32), 'eval/episode_forward_reward': Array(2307.926, dtype=float32), 'eval/episode_reward': Array(2316.6582, dtype=float32), 'eval/episode_reward_alive': Array(390.20312, dtype=float32), 'eval/episode_reward_linvel': Array(2307.926, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.31833, dtype=float32), 'eval/episode_x_position': Array(4979.128, dtype=float32), 'eval/episode_x_velocity': Array(461.5852, dtype=float32), 'eval/episode_y_position': Array(-41.245064, dtype=float32), 'eval/episode_y_velocity': Array(-76.392624, dtype=float32), 'eval/episode_distance_from_origin_std': Array(383.0841, dtype=float32), 'eval/episode_distance_reward_std': Array(3.890334, dtype=float32), 'eval/episode_forward_reward_std': Array(648.3835, dtype=float32), 'eval/episode_reward_std': Array(620.072, dtype=float32), 'eval/episode_reward_alive_std': Array(61.60279, dtype=float32), 'eval/episode_reward_linvel_std': Array(648.3835, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.675915, dtype=float32), 'eval/episode_x_position_std': Array(380.4844, dtype=float32), 'eval/episode_x_velocity_std': Array(129.67673, dtype=float32), 'eval/episode_y_position_std': Array(245.92935, dtype=float32), 'eval/episode_y_velocity_std': Array(87.36881, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6380672454834, 'eval/sps': 936.7814005304665, 'num_steps': 28835840}
{'eval/walltime': 48355.03009366989, 'training/sps': 2936.483386517902, 'training/walltime': 9842.49359178543, 'training/entropy_loss': Array(0.0136664, dtype=float32), 'training/policy_loss': Array(0.00229662, dtype=float32), 'training/total_loss': Array(0.08871108, dtype=float32), 'training/v_loss': Array(0.07274805, dtype=float32), 'eval/episode_distance_from_origin': Array(5080.5063, dtype=float32), 'eval/episode_distance_reward': Array(14.538158, dtype=float32), 'eval/episode_forward_reward': Array(2423.015, dtype=float32), 'eval/episode_reward': Array(2425.955, dtype=float32), 'eval/episode_reward_alive': Array(383.46875, dtype=float32), 'eval/episode_reward_linvel': Array(2423.015, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.06668, dtype=float32), 'eval/episode_x_position': Array(5034.1587, dtype=float32), 'eval/episode_x_velocity': Array(484.60294, dtype=float32), 'eval/episode_y_position': Array(-90.23628, dtype=float32), 'eval/episode_y_velocity': Array(-95.574875, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.1748, dtype=float32), 'eval/episode_distance_reward_std': Array(4.373859, dtype=float32), 'eval/episode_forward_reward_std': Array(728.9697, dtype=float32), 'eval/episode_reward_std': Array(698.48914, dtype=float32), 'eval/episode_reward_alive_std': Array(58.01161, dtype=float32), 'eval/episode_reward_linvel_std': Array(728.9697, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.239334, dtype=float32), 'eval/episode_x_position_std': Array(413.6486, dtype=float32), 'eval/episode_x_velocity_std': Array(145.794, dtype=float32), 'eval/episode_y_position_std': Array(273.64786, dtype=float32), 'eval/episode_y_velocity_std': Array(95.601685, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50202250480652, 'eval/sps': 937.7150437129446, 'num_steps': 28917760}
{'eval/walltime': 48491.46029281616, 'training/sps': 2929.166666709292, 'training/walltime': 9870.460590362549, 'training/entropy_loss': Array(0.01372352, dtype=float32), 'training/policy_loss': Array(0.0049873, dtype=float32), 'training/total_loss': Array(0.07854766, dtype=float32), 'training/v_loss': Array(0.05983685, dtype=float32), 'eval/episode_distance_from_origin': Array(5092.8564, dtype=float32), 'eval/episode_distance_reward': Array(14.6897335, dtype=float32), 'eval/episode_forward_reward': Array(2448.2776, dtype=float32), 'eval/episode_reward': Array(2446.919, dtype=float32), 'eval/episode_reward_alive': Array(388.80078, dtype=float32), 'eval/episode_reward_linvel': Array(2448.2776, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.8491, dtype=float32), 'eval/episode_x_position': Array(5048.4106, dtype=float32), 'eval/episode_x_velocity': Array(489.65552, dtype=float32), 'eval/episode_y_position': Array(-83.49034, dtype=float32), 'eval/episode_y_velocity': Array(-84.57847, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.2884, dtype=float32), 'eval/episode_distance_reward_std': Array(4.718994, dtype=float32), 'eval/episode_forward_reward_std': Array(786.4928, dtype=float32), 'eval/episode_reward_std': Array(762.0161, dtype=float32), 'eval/episode_reward_alive_std': Array(60.557224, dtype=float32), 'eval/episode_reward_linvel_std': Array(786.4928, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.959908, dtype=float32), 'eval/episode_x_position_std': Array(426.48734, dtype=float32), 'eval/episode_x_velocity_std': Array(157.29858, dtype=float32), 'eval/episode_y_position_std': Array(255.13596, dtype=float32), 'eval/episode_y_velocity_std': Array(84.71964, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43019914627075, 'eval/sps': 938.208701599618, 'num_steps': 28999680}
{'eval/walltime': 48628.100999593735, 'training/sps': 2946.02844801388, 'training/walltime': 9898.267518043518, 'training/entropy_loss': Array(0.01343525, dtype=float32), 'training/policy_loss': Array(0.00553594, dtype=float32), 'training/total_loss': Array(0.06734839, dtype=float32), 'training/v_loss': Array(0.0483772, dtype=float32), 'eval/episode_distance_from_origin': Array(5054.3926, dtype=float32), 'eval/episode_distance_reward': Array(14.605702, dtype=float32), 'eval/episode_forward_reward': Array(2434.272, dtype=float32), 'eval/episode_reward': Array(2448.02, dtype=float32), 'eval/episode_reward_alive': Array(391.58984, dtype=float32), 'eval/episode_reward_linvel': Array(2434.272, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.4472, dtype=float32), 'eval/episode_x_position': Array(5009.7617, dtype=float32), 'eval/episode_x_velocity': Array(486.85428, dtype=float32), 'eval/episode_y_position': Array(-74.842384, dtype=float32), 'eval/episode_y_velocity': Array(-89.84341, dtype=float32), 'eval/episode_distance_from_origin_std': Array(379.53088, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5609355, dtype=float32), 'eval/episode_forward_reward_std': Array(760.1497, dtype=float32), 'eval/episode_reward_std': Array(730.444, dtype=float32), 'eval/episode_reward_alive_std': Array(51.001358, dtype=float32), 'eval/episode_reward_linvel_std': Array(760.1497, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.27322, dtype=float32), 'eval/episode_x_position_std': Array(378.13275, dtype=float32), 'eval/episode_x_velocity_std': Array(152.03, dtype=float32), 'eval/episode_y_position_std': Array(261.0495, dtype=float32), 'eval/episode_y_velocity_std': Array(92.81225, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64070677757263, 'eval/sps': 936.7633044255384, 'num_steps': 29081600}
{'eval/walltime': 48764.516283750534, 'training/sps': 2950.9975961983373, 'training/walltime': 9926.027621984482, 'training/entropy_loss': Array(0.01247815, dtype=float32), 'training/policy_loss': Array(0.00261833, dtype=float32), 'training/total_loss': Array(0.05295188, dtype=float32), 'training/v_loss': Array(0.0378554, dtype=float32), 'eval/episode_distance_from_origin': Array(5155.327, dtype=float32), 'eval/episode_distance_reward': Array(15.261572, dtype=float32), 'eval/episode_forward_reward': Array(2543.583, dtype=float32), 'eval/episode_reward': Array(2547.636, dtype=float32), 'eval/episode_reward_alive': Array(388.32812, dtype=float32), 'eval/episode_reward_linvel': Array(2543.583, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.53687, dtype=float32), 'eval/episode_x_position': Array(5106.8945, dtype=float32), 'eval/episode_x_velocity': Array(508.7166, dtype=float32), 'eval/episode_y_position': Array(-101.75194, dtype=float32), 'eval/episode_y_velocity': Array(-101.573235, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.87686, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7821302, dtype=float32), 'eval/episode_forward_reward_std': Array(797.01544, dtype=float32), 'eval/episode_reward_std': Array(771.4477, dtype=float32), 'eval/episode_reward_alive_std': Array(56.56272, dtype=float32), 'eval/episode_reward_linvel_std': Array(797.01544, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.56907, dtype=float32), 'eval/episode_x_position_std': Array(477.74155, dtype=float32), 'eval/episode_x_velocity_std': Array(159.40308, dtype=float32), 'eval/episode_y_position_std': Array(299.8625, dtype=float32), 'eval/episode_y_velocity_std': Array(98.07364, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41528415679932, 'eval/sps': 938.3112808156704, 'num_steps': 29163520}
{'eval/walltime': 48901.13343334198, 'training/sps': 2960.548705175295, 'training/walltime': 9953.69816827774, 'training/entropy_loss': Array(0.0094525, dtype=float32), 'training/policy_loss': Array(0.01474249, dtype=float32), 'training/total_loss': Array(0.10116395, dtype=float32), 'training/v_loss': Array(0.07696896, dtype=float32), 'eval/episode_distance_from_origin': Array(5103.384, dtype=float32), 'eval/episode_distance_reward': Array(14.6834755, dtype=float32), 'eval/episode_forward_reward': Array(2447.2354, dtype=float32), 'eval/episode_reward': Array(2445.7998, dtype=float32), 'eval/episode_reward_alive': Array(385.17578, dtype=float32), 'eval/episode_reward_linvel': Array(2447.2354, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.29492, dtype=float32), 'eval/episode_x_position': Array(5056.7085, dtype=float32), 'eval/episode_x_velocity': Array(489.44708, dtype=float32), 'eval/episode_y_position': Array(-155.2666, dtype=float32), 'eval/episode_y_velocity': Array(-108.62433, dtype=float32), 'eval/episode_distance_from_origin_std': Array(381.88956, dtype=float32), 'eval/episode_distance_reward_std': Array(4.089767, dtype=float32), 'eval/episode_forward_reward_std': Array(681.6212, dtype=float32), 'eval/episode_reward_std': Array(661.2442, dtype=float32), 'eval/episode_reward_alive_std': Array(57.311295, dtype=float32), 'eval/episode_reward_linvel_std': Array(681.6212, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.540787, dtype=float32), 'eval/episode_x_position_std': Array(377.46292, dtype=float32), 'eval/episode_x_velocity_std': Array(136.3243, dtype=float32), 'eval/episode_y_position_std': Array(242.47766, dtype=float32), 'eval/episode_y_velocity_std': Array(89.27254, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.61714959144592, 'eval/sps': 936.9248325176192, 'num_steps': 29245440}
{'eval/walltime': 49037.56290602684, 'training/sps': 2943.9394576125524, 'training/walltime': 9981.524827480316, 'training/entropy_loss': Array(0.01614195, dtype=float32), 'training/policy_loss': Array(0.00783469, dtype=float32), 'training/total_loss': Array(0.12289264, dtype=float32), 'training/v_loss': Array(0.098916, dtype=float32), 'eval/episode_distance_from_origin': Array(5142.1924, dtype=float32), 'eval/episode_distance_reward': Array(14.915577, dtype=float32), 'eval/episode_forward_reward': Array(2485.9177, dtype=float32), 'eval/episode_reward': Array(2499.81, dtype=float32), 'eval/episode_reward_alive': Array(396.48438, dtype=float32), 'eval/episode_reward_linvel': Array(2485.9177, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.50754, dtype=float32), 'eval/episode_x_position': Array(5098.506, dtype=float32), 'eval/episode_x_velocity': Array(497.18353, dtype=float32), 'eval/episode_y_position': Array(-86.50675, dtype=float32), 'eval/episode_y_velocity': Array(-88.2063, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.03314, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2692, dtype=float32), 'eval/episode_forward_reward_std': Array(711.52747, dtype=float32), 'eval/episode_reward_std': Array(681.24725, dtype=float32), 'eval/episode_reward_alive_std': Array(51.01868, dtype=float32), 'eval/episode_reward_linvel_std': Array(711.52747, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.85706, dtype=float32), 'eval/episode_x_position_std': Array(426.93353, dtype=float32), 'eval/episode_x_velocity_std': Array(142.3054, dtype=float32), 'eval/episode_y_position_std': Array(249.38326, dtype=float32), 'eval/episode_y_velocity_std': Array(83.95344, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42947268486023, 'eval/sps': 938.2136973853769, 'num_steps': 29327360}
{'eval/walltime': 49174.18534517288, 'training/sps': 2954.1325954112995, 'training/walltime': 10009.25547170639, 'training/entropy_loss': Array(0.01323472, dtype=float32), 'training/policy_loss': Array(0.00067717, dtype=float32), 'training/total_loss': Array(0.09511012, dtype=float32), 'training/v_loss': Array(0.08119823, dtype=float32), 'eval/episode_distance_from_origin': Array(5161.3135, dtype=float32), 'eval/episode_distance_reward': Array(15.247086, dtype=float32), 'eval/episode_forward_reward': Array(2541.1694, dtype=float32), 'eval/episode_reward': Array(2541.5522, dtype=float32), 'eval/episode_reward_alive': Array(385.16797, dtype=float32), 'eval/episode_reward_linvel': Array(2541.1694, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.03162, dtype=float32), 'eval/episode_x_position': Array(5110.7944, dtype=float32), 'eval/episode_x_velocity': Array(508.23395, dtype=float32), 'eval/episode_y_position': Array(-201.28311, dtype=float32), 'eval/episode_y_velocity': Array(-120.41424, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.8124, dtype=float32), 'eval/episode_distance_reward_std': Array(4.63972, dtype=float32), 'eval/episode_forward_reward_std': Array(773.28, dtype=float32), 'eval/episode_reward_std': Array(755.1871, dtype=float32), 'eval/episode_reward_alive_std': Array(55.769417, dtype=float32), 'eval/episode_reward_linvel_std': Array(773.28, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.199333, dtype=float32), 'eval/episode_x_position_std': Array(414.41058, dtype=float32), 'eval/episode_x_velocity_std': Array(154.656, dtype=float32), 'eval/episode_y_position_std': Array(268.0877, dtype=float32), 'eval/episode_y_velocity_std': Array(95.478806, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62243914604187, 'eval/sps': 936.8885579855228, 'num_steps': 29409280}
{'eval/walltime': 49310.64175581932, 'training/sps': 2954.148164847434, 'training/walltime': 10036.985969781876, 'training/entropy_loss': Array(0.0137221, dtype=float32), 'training/policy_loss': Array(0.00337899, dtype=float32), 'training/total_loss': Array(0.09513347, dtype=float32), 'training/v_loss': Array(0.07803239, dtype=float32), 'eval/episode_distance_from_origin': Array(5150.763, dtype=float32), 'eval/episode_distance_reward': Array(15.255612, dtype=float32), 'eval/episode_forward_reward': Array(2542.5908, dtype=float32), 'eval/episode_reward': Array(2554.6572, dtype=float32), 'eval/episode_reward_alive': Array(390.30078, dtype=float32), 'eval/episode_reward_linvel': Array(2542.5908, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.49, dtype=float32), 'eval/episode_x_position': Array(5106.5684, dtype=float32), 'eval/episode_x_velocity': Array(508.5182, dtype=float32), 'eval/episode_y_position': Array(-130.06148, dtype=float32), 'eval/episode_y_velocity': Array(-102.79081, dtype=float32), 'eval/episode_distance_from_origin_std': Array(415.64276, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5191684, dtype=float32), 'eval/episode_forward_reward_std': Array(753.18823, dtype=float32), 'eval/episode_reward_std': Array(721.80707, dtype=float32), 'eval/episode_reward_alive_std': Array(56.583916, dtype=float32), 'eval/episode_reward_linvel_std': Array(753.18823, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.595425, dtype=float32), 'eval/episode_x_position_std': Array(412.00934, dtype=float32), 'eval/episode_x_velocity_std': Array(150.63768, dtype=float32), 'eval/episode_y_position_std': Array(234.01428, dtype=float32), 'eval/episode_y_velocity_std': Array(86.140434, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4564106464386, 'eval/sps': 938.028483921145, 'num_steps': 29491200}
{'eval/walltime': 49447.19633817673, 'training/sps': 2952.4496516069994, 'training/walltime': 10064.732420921326, 'training/entropy_loss': Array(0.0132467, dtype=float32), 'training/policy_loss': Array(0.00181213, dtype=float32), 'training/total_loss': Array(0.07423694, dtype=float32), 'training/v_loss': Array(0.05917811, dtype=float32), 'eval/episode_distance_from_origin': Array(5220.385, dtype=float32), 'eval/episode_distance_reward': Array(16.168238, dtype=float32), 'eval/episode_forward_reward': Array(2694.6934, dtype=float32), 'eval/episode_reward': Array(2695.9111, dtype=float32), 'eval/episode_reward_alive': Array(380.89844, dtype=float32), 'eval/episode_reward_linvel': Array(2694.6934, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.84894, dtype=float32), 'eval/episode_x_position': Array(5175.6455, dtype=float32), 'eval/episode_x_velocity': Array(538.9387, dtype=float32), 'eval/episode_y_position': Array(-146.2173, dtype=float32), 'eval/episode_y_velocity': Array(-113.03458, dtype=float32), 'eval/episode_distance_from_origin_std': Array(413.993, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7033806, dtype=float32), 'eval/episode_forward_reward_std': Array(783.8895, dtype=float32), 'eval/episode_reward_std': Array(756.7978, dtype=float32), 'eval/episode_reward_alive_std': Array(63.061237, dtype=float32), 'eval/episode_reward_linvel_std': Array(783.8895, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.136314, dtype=float32), 'eval/episode_x_position_std': Array(411.40262, dtype=float32), 'eval/episode_x_velocity_std': Array(156.77792, dtype=float32), 'eval/episode_y_position_std': Array(236.97786, dtype=float32), 'eval/episode_y_velocity_std': Array(85.868774, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55458235740662, 'eval/sps': 937.3541172348463, 'num_steps': 29573120}
{'eval/walltime': 49583.71843004227, 'training/sps': 2944.5364963037946, 'training/walltime': 10092.553437948227, 'training/entropy_loss': Array(0.0129343, dtype=float32), 'training/policy_loss': Array(0.00153726, dtype=float32), 'training/total_loss': Array(0.06209888, dtype=float32), 'training/v_loss': Array(0.04762732, dtype=float32), 'eval/episode_distance_from_origin': Array(5273.6035, dtype=float32), 'eval/episode_distance_reward': Array(16.430908, dtype=float32), 'eval/episode_forward_reward': Array(2738.472, dtype=float32), 'eval/episode_reward': Array(2728.164, dtype=float32), 'eval/episode_reward_alive': Array(374.97266, dtype=float32), 'eval/episode_reward_linvel': Array(2738.472, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.71136, dtype=float32), 'eval/episode_x_position': Array(5225.744, dtype=float32), 'eval/episode_x_velocity': Array(547.69434, dtype=float32), 'eval/episode_y_position': Array(-161.31915, dtype=float32), 'eval/episode_y_velocity': Array(-120.72478, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.5748, dtype=float32), 'eval/episode_distance_reward_std': Array(5.269419, dtype=float32), 'eval/episode_forward_reward_std': Array(878.22894, dtype=float32), 'eval/episode_reward_std': Array(852.1528, dtype=float32), 'eval/episode_reward_alive_std': Array(67.2376, dtype=float32), 'eval/episode_reward_linvel_std': Array(878.22894, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.62649, dtype=float32), 'eval/episode_x_position_std': Array(487.57678, dtype=float32), 'eval/episode_x_velocity_std': Array(175.64578, dtype=float32), 'eval/episode_y_position_std': Array(260.65237, dtype=float32), 'eval/episode_y_velocity_std': Array(96.85447, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52209186553955, 'eval/sps': 937.5771953894982, 'num_steps': 29655040}
{'eval/walltime': 49720.29903292656, 'training/sps': 2953.9366580544774, 'training/walltime': 10120.285921573639, 'training/entropy_loss': Array(0.00996675, dtype=float32), 'training/policy_loss': Array(0.00022035, dtype=float32), 'training/total_loss': Array(0.04940403, dtype=float32), 'training/v_loss': Array(0.03921694, dtype=float32), 'eval/episode_distance_from_origin': Array(5325.6885, dtype=float32), 'eval/episode_distance_reward': Array(16.922184, dtype=float32), 'eval/episode_forward_reward': Array(2820.3499, dtype=float32), 'eval/episode_reward': Array(2817.594, dtype=float32), 'eval/episode_reward_alive': Array(377.5039, dtype=float32), 'eval/episode_reward_linvel': Array(2820.3499, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.182, dtype=float32), 'eval/episode_x_position': Array(5279.51, dtype=float32), 'eval/episode_x_velocity': Array(564.07, dtype=float32), 'eval/episode_y_position': Array(-143.99545, dtype=float32), 'eval/episode_y_velocity': Array(-122.73984, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.97263, dtype=float32), 'eval/episode_distance_reward_std': Array(5.186325, dtype=float32), 'eval/episode_forward_reward_std': Array(864.38086, dtype=float32), 'eval/episode_reward_std': Array(841.92834, dtype=float32), 'eval/episode_reward_alive_std': Array(57.363068, dtype=float32), 'eval/episode_reward_linvel_std': Array(864.38086, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.852924, dtype=float32), 'eval/episode_x_position_std': Array(467.58572, dtype=float32), 'eval/episode_x_velocity_std': Array(172.87622, dtype=float32), 'eval/episode_y_position_std': Array(249.97823, dtype=float32), 'eval/episode_y_velocity_std': Array(86.65417, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5806028842926, 'eval/sps': 937.1755380845561, 'num_steps': 29736960}
{'eval/walltime': 49856.80678796768, 'training/sps': 2944.270075871744, 'training/walltime': 10148.109456062317, 'training/entropy_loss': Array(0.016209, dtype=float32), 'training/policy_loss': Array(0.00558568, dtype=float32), 'training/total_loss': Array(0.15285653, dtype=float32), 'training/v_loss': Array(0.13106185, dtype=float32), 'eval/episode_distance_from_origin': Array(5426.8047, dtype=float32), 'eval/episode_distance_reward': Array(18.108028, dtype=float32), 'eval/episode_forward_reward': Array(3017.9902, dtype=float32), 'eval/episode_reward': Array(3010.941, dtype=float32), 'eval/episode_reward_alive': Array(368.77344, dtype=float32), 'eval/episode_reward_linvel': Array(3017.9902, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.93048, dtype=float32), 'eval/episode_x_position': Array(5375.8955, dtype=float32), 'eval/episode_x_velocity': Array(603.5979, dtype=float32), 'eval/episode_y_position': Array(-234.20724, dtype=float32), 'eval/episode_y_velocity': Array(-141.99985, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.2515, dtype=float32), 'eval/episode_distance_reward_std': Array(4.951143, dtype=float32), 'eval/episode_forward_reward_std': Array(825.18353, dtype=float32), 'eval/episode_reward_std': Array(801.4385, dtype=float32), 'eval/episode_reward_alive_std': Array(63.703255, dtype=float32), 'eval/episode_reward_linvel_std': Array(825.18353, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.712563, dtype=float32), 'eval/episode_x_position_std': Array(413.05597, dtype=float32), 'eval/episode_x_velocity_std': Array(165.0367, dtype=float32), 'eval/episode_y_position_std': Array(248.73976, dtype=float32), 'eval/episode_y_velocity_std': Array(90.998146, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50775504112244, 'eval/sps': 937.6756651037188, 'num_steps': 29818880}
{'eval/walltime': 49993.369760513306, 'training/sps': 2942.6735480418283, 'training/walltime': 10175.94808602333, 'training/entropy_loss': Array(0.01300521, dtype=float32), 'training/policy_loss': Array(0.00469087, dtype=float32), 'training/total_loss': Array(0.10739601, dtype=float32), 'training/v_loss': Array(0.08969992, dtype=float32), 'eval/episode_distance_from_origin': Array(5336.539, dtype=float32), 'eval/episode_distance_reward': Array(16.950323, dtype=float32), 'eval/episode_forward_reward': Array(2825.0393, dtype=float32), 'eval/episode_reward': Array(2822.2375, dtype=float32), 'eval/episode_reward_alive': Array(377.97656, dtype=float32), 'eval/episode_reward_linvel': Array(2825.0393, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.7285, dtype=float32), 'eval/episode_x_position': Array(5289.5645, dtype=float32), 'eval/episode_x_velocity': Array(565.0078, dtype=float32), 'eval/episode_y_position': Array(-199.00974, dtype=float32), 'eval/episode_y_velocity': Array(-125.20273, dtype=float32), 'eval/episode_distance_from_origin_std': Array(384.19427, dtype=float32), 'eval/episode_distance_reward_std': Array(4.349931, dtype=float32), 'eval/episode_forward_reward_std': Array(724.9836, dtype=float32), 'eval/episode_reward_std': Array(702.1389, dtype=float32), 'eval/episode_reward_alive_std': Array(56.493217, dtype=float32), 'eval/episode_reward_linvel_std': Array(724.9836, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.182266, dtype=float32), 'eval/episode_x_position_std': Array(381.7813, dtype=float32), 'eval/episode_x_velocity_std': Array(144.9967, dtype=float32), 'eval/episode_y_position_std': Array(239.57803, dtype=float32), 'eval/episode_y_velocity_std': Array(84.16103, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56297254562378, 'eval/sps': 937.2965278508198, 'num_steps': 29900800}
{'eval/walltime': 50129.8845603466, 'training/sps': 2947.5459081197305, 'training/walltime': 10203.740698099136, 'training/entropy_loss': Array(0.01298435, dtype=float32), 'training/policy_loss': Array(0.00303563, dtype=float32), 'training/total_loss': Array(0.09483266, dtype=float32), 'training/v_loss': Array(0.07881267, dtype=float32), 'eval/episode_distance_from_origin': Array(5354.365, dtype=float32), 'eval/episode_distance_reward': Array(17.501556, dtype=float32), 'eval/episode_forward_reward': Array(2916.9111, dtype=float32), 'eval/episode_reward': Array(2912.4614, dtype=float32), 'eval/episode_reward_alive': Array(369.3203, dtype=float32), 'eval/episode_reward_linvel': Array(2916.9111, dtype=float32), 'eval/episode_reward_quadctrl': Array(-391.2715, dtype=float32), 'eval/episode_x_position': Array(5303.6304, dtype=float32), 'eval/episode_x_velocity': Array(583.38226, dtype=float32), 'eval/episode_y_position': Array(-207.94824, dtype=float32), 'eval/episode_y_velocity': Array(-136.50854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.30582, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7332664, dtype=float32), 'eval/episode_forward_reward_std': Array(788.8705, dtype=float32), 'eval/episode_reward_std': Array(766.3003, dtype=float32), 'eval/episode_reward_alive_std': Array(67.793106, dtype=float32), 'eval/episode_reward_linvel_std': Array(788.8705, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.307377, dtype=float32), 'eval/episode_x_position_std': Array(394.10178, dtype=float32), 'eval/episode_x_velocity_std': Array(157.77415, dtype=float32), 'eval/episode_y_position_std': Array(272.00186, dtype=float32), 'eval/episode_y_velocity_std': Array(95.728966, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51479983329773, 'eval/sps': 937.627276722411, 'num_steps': 29982720}
{'eval/walltime': 50266.44993829727, 'training/sps': 2943.2469287335643, 'training/walltime': 10231.573904752731, 'training/entropy_loss': Array(0.01263484, dtype=float32), 'training/policy_loss': Array(0.00206897, dtype=float32), 'training/total_loss': Array(0.08111904, dtype=float32), 'training/v_loss': Array(0.06641522, dtype=float32), 'eval/episode_distance_from_origin': Array(5365.616, dtype=float32), 'eval/episode_distance_reward': Array(17.092396, dtype=float32), 'eval/episode_forward_reward': Array(2848.7188, dtype=float32), 'eval/episode_reward': Array(2846.122, dtype=float32), 'eval/episode_reward_alive': Array(379.28516, dtype=float32), 'eval/episode_reward_linvel': Array(2848.7188, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.9744, dtype=float32), 'eval/episode_x_position': Array(5317.421, dtype=float32), 'eval/episode_x_velocity': Array(569.7439, dtype=float32), 'eval/episode_y_position': Array(-138.46909, dtype=float32), 'eval/episode_y_velocity': Array(-116.1869, dtype=float32), 'eval/episode_distance_from_origin_std': Array(448.90067, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6743746, dtype=float32), 'eval/episode_forward_reward_std': Array(779.0559, dtype=float32), 'eval/episode_reward_std': Array(754.9451, dtype=float32), 'eval/episode_reward_alive_std': Array(61.76362, dtype=float32), 'eval/episode_reward_linvel_std': Array(779.0559, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.507153, dtype=float32), 'eval/episode_x_position_std': Array(448.4341, dtype=float32), 'eval/episode_x_velocity_std': Array(155.81125, dtype=float32), 'eval/episode_y_position_std': Array(293.75903, dtype=float32), 'eval/episode_y_velocity_std': Array(100.94341, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56537795066833, 'eval/sps': 937.2800187045767, 'num_steps': 30064640}
{'eval/walltime': 50403.0042719841, 'training/sps': 2931.6567059828485, 'training/walltime': 10259.517149209976, 'training/entropy_loss': Array(0.01272051, dtype=float32), 'training/policy_loss': Array(0.0052316, dtype=float32), 'training/total_loss': Array(0.07495287, dtype=float32), 'training/v_loss': Array(0.05700076, dtype=float32), 'eval/episode_distance_from_origin': Array(5423.8574, dtype=float32), 'eval/episode_distance_reward': Array(18.492193, dtype=float32), 'eval/episode_forward_reward': Array(3082.0164, dtype=float32), 'eval/episode_reward': Array(3077.643, dtype=float32), 'eval/episode_reward_alive': Array(369.1875, dtype=float32), 'eval/episode_reward_linvel': Array(3082.0164, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.0526, dtype=float32), 'eval/episode_x_position': Array(5374.14, dtype=float32), 'eval/episode_x_velocity': Array(616.4032, dtype=float32), 'eval/episode_y_position': Array(-187.09435, dtype=float32), 'eval/episode_y_velocity': Array(-138.3263, dtype=float32), 'eval/episode_distance_from_origin_std': Array(439.97516, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9726763, dtype=float32), 'eval/episode_forward_reward_std': Array(828.77405, dtype=float32), 'eval/episode_reward_std': Array(818.115, dtype=float32), 'eval/episode_reward_alive_std': Array(57.62378, dtype=float32), 'eval/episode_reward_linvel_std': Array(828.77405, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.354755, dtype=float32), 'eval/episode_x_position_std': Array(439.47708, dtype=float32), 'eval/episode_x_velocity_std': Array(165.75484, dtype=float32), 'eval/episode_y_position_std': Array(274.25708, dtype=float32), 'eval/episode_y_velocity_std': Array(99.281235, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5543336868286, 'eval/sps': 937.3558241919515, 'num_steps': 30146560}
{'eval/walltime': 50539.557500362396, 'training/sps': 2929.461081033083, 'training/walltime': 10287.481337070465, 'training/entropy_loss': Array(0.0109678, dtype=float32), 'training/policy_loss': Array(0.00093852, dtype=float32), 'training/total_loss': Array(0.05433092, dtype=float32), 'training/v_loss': Array(0.04242459, dtype=float32), 'eval/episode_distance_from_origin': Array(5544.3594, dtype=float32), 'eval/episode_distance_reward': Array(19.270731, dtype=float32), 'eval/episode_forward_reward': Array(3211.772, dtype=float32), 'eval/episode_reward': Array(3210.9277, dtype=float32), 'eval/episode_reward_alive': Array(373.60547, dtype=float32), 'eval/episode_reward_linvel': Array(3211.772, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.72058, dtype=float32), 'eval/episode_x_position': Array(5494.635, dtype=float32), 'eval/episode_x_velocity': Array(642.3544, dtype=float32), 'eval/episode_y_position': Array(-198.64838, dtype=float32), 'eval/episode_y_velocity': Array(-141.44852, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.35257, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1181173, dtype=float32), 'eval/episode_forward_reward_std': Array(853.013, dtype=float32), 'eval/episode_reward_std': Array(837.18286, dtype=float32), 'eval/episode_reward_alive_std': Array(59.08659, dtype=float32), 'eval/episode_reward_linvel_std': Array(853.013, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.79266, dtype=float32), 'eval/episode_x_position_std': Array(456.6151, dtype=float32), 'eval/episode_x_velocity_std': Array(170.6026, dtype=float32), 'eval/episode_y_position_std': Array(260.25864, dtype=float32), 'eval/episode_y_velocity_std': Array(93.16634, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5532283782959, 'eval/sps': 937.3634114705752, 'num_steps': 30228480}
{'eval/walltime': 50676.09190630913, 'training/sps': 2929.642668950373, 'training/walltime': 10315.443791627884, 'training/entropy_loss': Array(0.01247688, dtype=float32), 'training/policy_loss': Array(0.00317053, dtype=float32), 'training/total_loss': Array(0.10396028, dtype=float32), 'training/v_loss': Array(0.08831288, dtype=float32), 'eval/episode_distance_from_origin': Array(5437.6426, dtype=float32), 'eval/episode_distance_reward': Array(17.751095, dtype=float32), 'eval/episode_forward_reward': Array(2958.5002, dtype=float32), 'eval/episode_reward': Array(2974.2686, dtype=float32), 'eval/episode_reward_alive': Array(390.4922, dtype=float32), 'eval/episode_reward_linvel': Array(2958.5002, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.47546, dtype=float32), 'eval/episode_x_position': Array(5389.6333, dtype=float32), 'eval/episode_x_velocity': Array(591.70013, dtype=float32), 'eval/episode_y_position': Array(-148.22363, dtype=float32), 'eval/episode_y_velocity': Array(-116.86722, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.61658, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2309604, dtype=float32), 'eval/episode_forward_reward_std': Array(871.8204, dtype=float32), 'eval/episode_reward_std': Array(855.6603, dtype=float32), 'eval/episode_reward_alive_std': Array(61.06151, dtype=float32), 'eval/episode_reward_linvel_std': Array(871.8204, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.95092, dtype=float32), 'eval/episode_x_position_std': Array(480.32263, dtype=float32), 'eval/episode_x_velocity_std': Array(174.36403, dtype=float32), 'eval/episode_y_position_std': Array(292.5789, dtype=float32), 'eval/episode_y_velocity_std': Array(101.1048, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53440594673157, 'eval/sps': 937.4926350061446, 'num_steps': 30310400}
{'eval/walltime': 50812.65026926994, 'training/sps': 2923.7242250495487, 'training/walltime': 10343.462850093842, 'training/entropy_loss': Array(0.01476819, dtype=float32), 'training/policy_loss': Array(0.00543411, dtype=float32), 'training/total_loss': Array(0.16454315, dtype=float32), 'training/v_loss': Array(0.14434084, dtype=float32), 'eval/episode_distance_from_origin': Array(5421.1274, dtype=float32), 'eval/episode_distance_reward': Array(17.84788, dtype=float32), 'eval/episode_forward_reward': Array(2974.6313, dtype=float32), 'eval/episode_reward': Array(2979.5134, dtype=float32), 'eval/episode_reward_alive': Array(383.08594, dtype=float32), 'eval/episode_reward_linvel': Array(2974.6313, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.05154, dtype=float32), 'eval/episode_x_position': Array(5374.5015, dtype=float32), 'eval/episode_x_velocity': Array(594.9263, dtype=float32), 'eval/episode_y_position': Array(-151.16992, dtype=float32), 'eval/episode_y_velocity': Array(-123.062836, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.77637, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5309453, dtype=float32), 'eval/episode_forward_reward_std': Array(921.8174, dtype=float32), 'eval/episode_reward_std': Array(913.3688, dtype=float32), 'eval/episode_reward_alive_std': Array(61.018475, dtype=float32), 'eval/episode_reward_linvel_std': Array(921.8174, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.7355, dtype=float32), 'eval/episode_x_position_std': Array(488.3194, dtype=float32), 'eval/episode_x_velocity_std': Array(184.36346, dtype=float32), 'eval/episode_y_position_std': Array(265.44647, dtype=float32), 'eval/episode_y_velocity_std': Array(94.668846, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55836296081543, 'eval/sps': 937.3281666881786, 'num_steps': 30392320}
{'eval/walltime': 50949.17584347725, 'training/sps': 2925.230493955237, 'training/walltime': 10371.467480897903, 'training/entropy_loss': Array(0.01341872, dtype=float32), 'training/policy_loss': Array(0.00337704, dtype=float32), 'training/total_loss': Array(0.11354794, dtype=float32), 'training/v_loss': Array(0.09675217, dtype=float32), 'eval/episode_distance_from_origin': Array(5450.23, dtype=float32), 'eval/episode_distance_reward': Array(17.752457, dtype=float32), 'eval/episode_forward_reward': Array(2958.7283, dtype=float32), 'eval/episode_reward': Array(2970.9578, dtype=float32), 'eval/episode_reward_alive': Array(387.58594, dtype=float32), 'eval/episode_reward_linvel': Array(2958.7283, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.10907, dtype=float32), 'eval/episode_x_position': Array(5401.159, dtype=float32), 'eval/episode_x_velocity': Array(591.74567, dtype=float32), 'eval/episode_y_position': Array(-159.56915, dtype=float32), 'eval/episode_y_velocity': Array(-120.05644, dtype=float32), 'eval/episode_distance_from_origin_std': Array(402.88864, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7690296, dtype=float32), 'eval/episode_forward_reward_std': Array(794.8312, dtype=float32), 'eval/episode_reward_std': Array(780.39014, dtype=float32), 'eval/episode_reward_alive_std': Array(62.226, dtype=float32), 'eval/episode_reward_linvel_std': Array(794.8312, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.51076, dtype=float32), 'eval/episode_x_position_std': Array(401.25494, dtype=float32), 'eval/episode_x_velocity_std': Array(158.96631, dtype=float32), 'eval/episode_y_position_std': Array(290.5451, dtype=float32), 'eval/episode_y_velocity_std': Array(102.58895, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5255742073059, 'eval/sps': 937.5532807182313, 'num_steps': 30474240}
{'eval/walltime': 51085.73295497894, 'training/sps': 2924.2399463358734, 'training/walltime': 10399.48159790039, 'training/entropy_loss': Array(0.01307642, dtype=float32), 'training/policy_loss': Array(0.0064549, dtype=float32), 'training/total_loss': Array(0.11038275, dtype=float32), 'training/v_loss': Array(0.09085143, dtype=float32), 'eval/episode_distance_from_origin': Array(5501.922, dtype=float32), 'eval/episode_distance_reward': Array(18.370527, dtype=float32), 'eval/episode_forward_reward': Array(3061.74, dtype=float32), 'eval/episode_reward': Array(3072.0273, dtype=float32), 'eval/episode_reward_alive': Array(387.17578, dtype=float32), 'eval/episode_reward_linvel': Array(3061.74, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.25882, dtype=float32), 'eval/episode_x_position': Array(5452.2056, dtype=float32), 'eval/episode_x_velocity': Array(612.348, dtype=float32), 'eval/episode_y_position': Array(-202.13507, dtype=float32), 'eval/episode_y_velocity': Array(-137.84863, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.47922, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1874304, dtype=float32), 'eval/episode_forward_reward_std': Array(864.56494, dtype=float32), 'eval/episode_reward_std': Array(849.08545, dtype=float32), 'eval/episode_reward_alive_std': Array(59.810104, dtype=float32), 'eval/episode_reward_linvel_std': Array(864.56494, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.330853, dtype=float32), 'eval/episode_x_position_std': Array(477.59842, dtype=float32), 'eval/episode_x_velocity_std': Array(172.91295, dtype=float32), 'eval/episode_y_position_std': Array(260.21216, dtype=float32), 'eval/episode_y_velocity_std': Array(90.33057, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55711150169373, 'eval/sps': 937.3367567049952, 'num_steps': 30556160}
{'eval/walltime': 51222.30302000046, 'training/sps': 2923.094289692675, 'training/walltime': 10427.506694555283, 'training/entropy_loss': Array(0.01293215, dtype=float32), 'training/policy_loss': Array(0.03891325, dtype=float32), 'training/total_loss': Array(0.1271603, dtype=float32), 'training/v_loss': Array(0.07531489, dtype=float32), 'eval/episode_distance_from_origin': Array(5539.71, dtype=float32), 'eval/episode_distance_reward': Array(18.856964, dtype=float32), 'eval/episode_forward_reward': Array(3142.8123, dtype=float32), 'eval/episode_reward': Array(3152.1965, dtype=float32), 'eval/episode_reward_alive': Array(383.94922, dtype=float32), 'eval/episode_reward_linvel': Array(3142.8123, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.42203, dtype=float32), 'eval/episode_x_position': Array(5488.544, dtype=float32), 'eval/episode_x_velocity': Array(628.5624, dtype=float32), 'eval/episode_y_position': Array(-196.31519, dtype=float32), 'eval/episode_y_velocity': Array(-137.26678, dtype=float32), 'eval/episode_distance_from_origin_std': Array(424.5489, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3677177, dtype=float32), 'eval/episode_forward_reward_std': Array(727.94727, dtype=float32), 'eval/episode_reward_std': Array(714.0593, dtype=float32), 'eval/episode_reward_alive_std': Array(59.937363, dtype=float32), 'eval/episode_reward_linvel_std': Array(727.94727, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.432953, dtype=float32), 'eval/episode_x_position_std': Array(420.89136, dtype=float32), 'eval/episode_x_velocity_std': Array(145.58946, dtype=float32), 'eval/episode_y_position_std': Array(293.33856, dtype=float32), 'eval/episode_y_velocity_std': Array(96.45762, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5700650215149, 'eval/sps': 937.247851348941, 'num_steps': 30638080}
{'eval/walltime': 51358.852405548096, 'training/sps': 2944.3501558923595, 'training/walltime': 10455.32947230339, 'training/entropy_loss': Array(0.01326241, dtype=float32), 'training/policy_loss': Array(0.00238602, dtype=float32), 'training/total_loss': Array(0.08752723, dtype=float32), 'training/v_loss': Array(0.07187881, dtype=float32), 'eval/episode_distance_from_origin': Array(5595.703, dtype=float32), 'eval/episode_distance_reward': Array(20.023495, dtype=float32), 'eval/episode_forward_reward': Array(3337.2334, dtype=float32), 'eval/episode_reward': Array(3346.2139, dtype=float32), 'eval/episode_reward_alive': Array(378.1797, dtype=float32), 'eval/episode_reward_linvel': Array(3337.2334, dtype=float32), 'eval/episode_reward_quadctrl': Array(-389.22256, dtype=float32), 'eval/episode_x_position': Array(5547., dtype=float32), 'eval/episode_x_velocity': Array(667.4466, dtype=float32), 'eval/episode_y_position': Array(-146.99057, dtype=float32), 'eval/episode_y_velocity': Array(-138.95741, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.48315, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4724054, dtype=float32), 'eval/episode_forward_reward_std': Array(912.0603, dtype=float32), 'eval/episode_reward_std': Array(900.6452, dtype=float32), 'eval/episode_reward_alive_std': Array(60.76375, dtype=float32), 'eval/episode_reward_linvel_std': Array(912.0603, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.011814, dtype=float32), 'eval/episode_x_position_std': Array(478.10742, dtype=float32), 'eval/episode_x_velocity_std': Array(182.41205, dtype=float32), 'eval/episode_y_position_std': Array(286.7458, dtype=float32), 'eval/episode_y_velocity_std': Array(99.158295, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54938554763794, 'eval/sps': 937.3897911488198, 'num_steps': 30720000}
{'eval/walltime': 51495.41151857376, 'training/sps': 2940.4151959486726, 'training/walltime': 10483.18948340416, 'training/entropy_loss': Array(0.01042495, dtype=float32), 'training/policy_loss': Array(0.00192372, dtype=float32), 'training/total_loss': Array(0.09752129, dtype=float32), 'training/v_loss': Array(0.08517262, dtype=float32), 'eval/episode_distance_from_origin': Array(5642.508, dtype=float32), 'eval/episode_distance_reward': Array(20.31291, dtype=float32), 'eval/episode_forward_reward': Array(3385.4685, dtype=float32), 'eval/episode_reward': Array(3394.747, dtype=float32), 'eval/episode_reward_alive': Array(374.8203, dtype=float32), 'eval/episode_reward_linvel': Array(3385.4685, dtype=float32), 'eval/episode_reward_quadctrl': Array(-385.85443, dtype=float32), 'eval/episode_x_position': Array(5591.9053, dtype=float32), 'eval/episode_x_velocity': Array(677.09375, dtype=float32), 'eval/episode_y_position': Array(-168.73096, dtype=float32), 'eval/episode_y_velocity': Array(-137.84912, dtype=float32), 'eval/episode_distance_from_origin_std': Array(386.67822, dtype=float32), 'eval/episode_distance_reward_std': Array(4.725476, dtype=float32), 'eval/episode_forward_reward_std': Array(787.57324, dtype=float32), 'eval/episode_reward_std': Array(764.60956, dtype=float32), 'eval/episode_reward_alive_std': Array(61.67717, dtype=float32), 'eval/episode_reward_linvel_std': Array(787.57324, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.616644, dtype=float32), 'eval/episode_x_position_std': Array(384.67392, dtype=float32), 'eval/episode_x_velocity_std': Array(157.51457, dtype=float32), 'eval/episode_y_position_std': Array(311.64075, dtype=float32), 'eval/episode_y_velocity_std': Array(103.428314, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55911302566528, 'eval/sps': 937.3230183176669, 'num_steps': 30801920}
{'eval/walltime': 51632.00938487053, 'training/sps': 2944.221384101008, 'training/walltime': 10511.013478040695, 'training/entropy_loss': Array(0.01394433, dtype=float32), 'training/policy_loss': Array(0.00910281, dtype=float32), 'training/total_loss': Array(0.16754791, dtype=float32), 'training/v_loss': Array(0.14450076, dtype=float32), 'eval/episode_distance_from_origin': Array(5608.168, dtype=float32), 'eval/episode_distance_reward': Array(19.951488, dtype=float32), 'eval/episode_forward_reward': Array(3325.2317, dtype=float32), 'eval/episode_reward': Array(3336.129, dtype=float32), 'eval/episode_reward_alive': Array(379.5039, dtype=float32), 'eval/episode_reward_linvel': Array(3325.2317, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.55823, dtype=float32), 'eval/episode_x_position': Array(5558.7383, dtype=float32), 'eval/episode_x_velocity': Array(665.04626, dtype=float32), 'eval/episode_y_position': Array(-181.68524, dtype=float32), 'eval/episode_y_velocity': Array(-140.54639, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.98743, dtype=float32), 'eval/episode_distance_reward_std': Array(5.092967, dtype=float32), 'eval/episode_forward_reward_std': Array(848.8201, dtype=float32), 'eval/episode_reward_std': Array(831.91974, dtype=float32), 'eval/episode_reward_alive_std': Array(62.56916, dtype=float32), 'eval/episode_reward_linvel_std': Array(848.8201, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.49405, dtype=float32), 'eval/episode_x_position_std': Array(425.07172, dtype=float32), 'eval/episode_x_velocity_std': Array(169.7641, dtype=float32), 'eval/episode_y_position_std': Array(282.55435, dtype=float32), 'eval/episode_y_velocity_std': Array(95.73887, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5978662967682, 'eval/sps': 937.057096645355, 'num_steps': 30883840}
{'eval/walltime': 51768.44719696045, 'training/sps': 2937.3869463308306, 'training/walltime': 10538.902210950851, 'training/entropy_loss': Array(0.01308434, dtype=float32), 'training/policy_loss': Array(0.00355859, dtype=float32), 'training/total_loss': Array(0.12975642, dtype=float32), 'training/v_loss': Array(0.11311349, dtype=float32), 'eval/episode_distance_from_origin': Array(5618.2734, dtype=float32), 'eval/episode_distance_reward': Array(19.76447, dtype=float32), 'eval/episode_forward_reward': Array(3294.0625, dtype=float32), 'eval/episode_reward': Array(3307.1387, dtype=float32), 'eval/episode_reward_alive': Array(385.60156, dtype=float32), 'eval/episode_reward_linvel': Array(3294.0625, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.2897, dtype=float32), 'eval/episode_x_position': Array(5568.7935, dtype=float32), 'eval/episode_x_velocity': Array(658.8125, dtype=float32), 'eval/episode_y_position': Array(-145.14352, dtype=float32), 'eval/episode_y_velocity': Array(-128.02603, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.5482, dtype=float32), 'eval/episode_distance_reward_std': Array(5.140092, dtype=float32), 'eval/episode_forward_reward_std': Array(856.67554, dtype=float32), 'eval/episode_reward_std': Array(842.35034, dtype=float32), 'eval/episode_reward_alive_std': Array(59.885513, dtype=float32), 'eval/episode_reward_linvel_std': Array(856.67554, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.506702, dtype=float32), 'eval/episode_x_position_std': Array(441.39856, dtype=float32), 'eval/episode_x_velocity_std': Array(171.33496, dtype=float32), 'eval/episode_y_position_std': Array(311.4302, dtype=float32), 'eval/episode_y_velocity_std': Array(107.96784, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43781208992004, 'eval/sps': 938.1563515225599, 'num_steps': 30965760}
{'eval/walltime': 51904.99928355217, 'training/sps': 2949.5584382968364, 'training/walltime': 10566.675859689713, 'training/entropy_loss': Array(0.01309975, dtype=float32), 'training/policy_loss': Array(0.00253496, dtype=float32), 'training/total_loss': Array(0.10544425, dtype=float32), 'training/v_loss': Array(0.08980955, dtype=float32), 'eval/episode_distance_from_origin': Array(5646.92, dtype=float32), 'eval/episode_distance_reward': Array(20.108696, dtype=float32), 'eval/episode_forward_reward': Array(3351.433, dtype=float32), 'eval/episode_reward': Array(3358.1245, dtype=float32), 'eval/episode_reward_alive': Array(374.96094, dtype=float32), 'eval/episode_reward_linvel': Array(3351.433, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.37793, dtype=float32), 'eval/episode_x_position': Array(5598.397, dtype=float32), 'eval/episode_x_velocity': Array(670.2865, dtype=float32), 'eval/episode_y_position': Array(-176.55661, dtype=float32), 'eval/episode_y_velocity': Array(-146.0542, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.91736, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3146205, dtype=float32), 'eval/episode_forward_reward_std': Array(885.76263, dtype=float32), 'eval/episode_reward_std': Array(865.0524, dtype=float32), 'eval/episode_reward_alive_std': Array(66.61813, dtype=float32), 'eval/episode_reward_linvel_std': Array(885.76263, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.331549, dtype=float32), 'eval/episode_x_position_std': Array(458.4311, dtype=float32), 'eval/episode_x_velocity_std': Array(177.15253, dtype=float32), 'eval/episode_y_position_std': Array(262.10413, dtype=float32), 'eval/episode_y_velocity_std': Array(100.864944, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55208659172058, 'eval/sps': 937.3712492780091, 'num_steps': 31047680}
{'eval/walltime': 52041.56157517433, 'training/sps': 2932.8760260791, 'training/walltime': 10594.607486963272, 'training/entropy_loss': Array(0.01304284, dtype=float32), 'training/policy_loss': Array(0.00241521, dtype=float32), 'training/total_loss': Array(0.0971836, dtype=float32), 'training/v_loss': Array(0.08172555, dtype=float32), 'eval/episode_distance_from_origin': Array(5688.7515, dtype=float32), 'eval/episode_distance_reward': Array(20.36217, dtype=float32), 'eval/episode_forward_reward': Array(3393.6787, dtype=float32), 'eval/episode_reward': Array(3409.419, dtype=float32), 'eval/episode_reward_alive': Array(386.36328, dtype=float32), 'eval/episode_reward_linvel': Array(3393.6787, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.98486, dtype=float32), 'eval/episode_x_position': Array(5640.5103, dtype=float32), 'eval/episode_x_velocity': Array(678.73566, dtype=float32), 'eval/episode_y_position': Array(-128.34633, dtype=float32), 'eval/episode_y_velocity': Array(-128.17105, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.3674, dtype=float32), 'eval/episode_distance_reward_std': Array(5.120751, dtype=float32), 'eval/episode_forward_reward_std': Array(853.45105, dtype=float32), 'eval/episode_reward_std': Array(837.79504, dtype=float32), 'eval/episode_reward_alive_std': Array(60.661705, dtype=float32), 'eval/episode_reward_linvel_std': Array(853.45105, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.96923, dtype=float32), 'eval/episode_x_position_std': Array(472.0333, dtype=float32), 'eval/episode_x_velocity_std': Array(170.69022, dtype=float32), 'eval/episode_y_position_std': Array(292.91977, dtype=float32), 'eval/episode_y_velocity_std': Array(98.56536, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56229162216187, 'eval/sps': 937.3012013751801, 'num_steps': 31129600}
{'eval/walltime': 52178.14827775955, 'training/sps': 2947.8659559796183, 'training/walltime': 10622.39708161354, 'training/entropy_loss': Array(0.01318979, dtype=float32), 'training/policy_loss': Array(0.00253077, dtype=float32), 'training/total_loss': Array(0.10197242, dtype=float32), 'training/v_loss': Array(0.08625187, dtype=float32), 'eval/episode_distance_from_origin': Array(5688.754, dtype=float32), 'eval/episode_distance_reward': Array(20.23457, dtype=float32), 'eval/episode_forward_reward': Array(3372.411, dtype=float32), 'eval/episode_reward': Array(3384.5896, dtype=float32), 'eval/episode_reward_alive': Array(379.1836, dtype=float32), 'eval/episode_reward_linvel': Array(3372.411, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.24, dtype=float32), 'eval/episode_x_position': Array(5638.343, dtype=float32), 'eval/episode_x_velocity': Array(674.4823, dtype=float32), 'eval/episode_y_position': Array(-157.082, dtype=float32), 'eval/episode_y_velocity': Array(-137.04482, dtype=float32), 'eval/episode_distance_from_origin_std': Array(459.4478, dtype=float32), 'eval/episode_distance_reward_std': Array(4.850368, dtype=float32), 'eval/episode_forward_reward_std': Array(808.3886, dtype=float32), 'eval/episode_reward_std': Array(791.5565, dtype=float32), 'eval/episode_reward_alive_std': Array(63.32835, dtype=float32), 'eval/episode_reward_linvel_std': Array(808.3886, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.25008, dtype=float32), 'eval/episode_x_position_std': Array(459.01624, dtype=float32), 'eval/episode_x_velocity_std': Array(161.67776, dtype=float32), 'eval/episode_y_position_std': Array(306.8544, dtype=float32), 'eval/episode_y_velocity_std': Array(100.71359, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58670258522034, 'eval/sps': 937.1336856172887, 'num_steps': 31211520}
{'eval/walltime': 52314.67781877518, 'training/sps': 2938.371119012676, 'training/walltime': 10650.276473522186, 'training/entropy_loss': Array(0.0096631, dtype=float32), 'training/policy_loss': Array(0.00192281, dtype=float32), 'training/total_loss': Array(0.06845634, dtype=float32), 'training/v_loss': Array(0.05687043, dtype=float32), 'eval/episode_distance_from_origin': Array(5636.3975, dtype=float32), 'eval/episode_distance_reward': Array(20.258041, dtype=float32), 'eval/episode_forward_reward': Array(3376.3228, dtype=float32), 'eval/episode_reward': Array(3387.6233, dtype=float32), 'eval/episode_reward_alive': Array(377.13672, dtype=float32), 'eval/episode_reward_linvel': Array(3376.3228, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.09363, dtype=float32), 'eval/episode_x_position': Array(5583.0566, dtype=float32), 'eval/episode_x_velocity': Array(675.26447, dtype=float32), 'eval/episode_y_position': Array(-207.0708, dtype=float32), 'eval/episode_y_velocity': Array(-152.49948, dtype=float32), 'eval/episode_distance_from_origin_std': Array(515.40094, dtype=float32), 'eval/episode_distance_reward_std': Array(5.582488, dtype=float32), 'eval/episode_forward_reward_std': Array(930.4081, dtype=float32), 'eval/episode_reward_std': Array(914.0569, dtype=float32), 'eval/episode_reward_alive_std': Array(62.80033, dtype=float32), 'eval/episode_reward_linvel_std': Array(930.4081, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.570024, dtype=float32), 'eval/episode_x_position_std': Array(513.4161, dtype=float32), 'eval/episode_x_velocity_std': Array(186.08148, dtype=float32), 'eval/episode_y_position_std': Array(301.41974, dtype=float32), 'eval/episode_y_velocity_std': Array(105.08453, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.529541015625, 'eval/sps': 937.5260405024811, 'num_steps': 31293440}
{'eval/walltime': 52451.27602934837, 'training/sps': 2942.493768241449, 'training/walltime': 10678.116804361343, 'training/entropy_loss': Array(0.01495751, dtype=float32), 'training/policy_loss': Array(0.00957198, dtype=float32), 'training/total_loss': Array(0.15451474, dtype=float32), 'training/v_loss': Array(0.12998524, dtype=float32), 'eval/episode_distance_from_origin': Array(5620.062, dtype=float32), 'eval/episode_distance_reward': Array(19.789377, dtype=float32), 'eval/episode_forward_reward': Array(3298.2134, dtype=float32), 'eval/episode_reward': Array(3310.4004, dtype=float32), 'eval/episode_reward_alive': Array(382.83594, dtype=float32), 'eval/episode_reward_linvel': Array(3298.2134, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.43802, dtype=float32), 'eval/episode_x_position': Array(5566.587, dtype=float32), 'eval/episode_x_velocity': Array(659.64264, dtype=float32), 'eval/episode_y_position': Array(-235.27908, dtype=float32), 'eval/episode_y_velocity': Array(-158.53625, dtype=float32), 'eval/episode_distance_from_origin_std': Array(415.59177, dtype=float32), 'eval/episode_distance_reward_std': Array(4.662772, dtype=float32), 'eval/episode_forward_reward_std': Array(777.12225, dtype=float32), 'eval/episode_reward_std': Array(767.3231, dtype=float32), 'eval/episode_reward_alive_std': Array(55.448177, dtype=float32), 'eval/episode_reward_linvel_std': Array(777.12225, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.186396, dtype=float32), 'eval/episode_x_position_std': Array(410.8675, dtype=float32), 'eval/episode_x_velocity_std': Array(155.42448, dtype=float32), 'eval/episode_y_position_std': Array(263.50302, dtype=float32), 'eval/episode_y_velocity_std': Array(91.3548, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5982105731964, 'eval/sps': 937.0547349257621, 'num_steps': 31375360}
{'eval/walltime': 52587.83826303482, 'training/sps': 2937.9955237809545, 'training/walltime': 10705.999760389328, 'training/entropy_loss': Array(0.01386057, dtype=float32), 'training/policy_loss': Array(0.00628977, dtype=float32), 'training/total_loss': Array(0.15401018, dtype=float32), 'training/v_loss': Array(0.13385984, dtype=float32), 'eval/episode_distance_from_origin': Array(5675.261, dtype=float32), 'eval/episode_distance_reward': Array(20.130116, dtype=float32), 'eval/episode_forward_reward': Array(3355.0015, dtype=float32), 'eval/episode_reward': Array(3367.2622, dtype=float32), 'eval/episode_reward_alive': Array(380.98828, dtype=float32), 'eval/episode_reward_linvel': Array(3355.0015, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.8579, dtype=float32), 'eval/episode_x_position': Array(5622.4585, dtype=float32), 'eval/episode_x_velocity': Array(671.00037, dtype=float32), 'eval/episode_y_position': Array(-237.77577, dtype=float32), 'eval/episode_y_velocity': Array(-157.04562, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.50342, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9070835, dtype=float32), 'eval/episode_forward_reward_std': Array(817.84094, dtype=float32), 'eval/episode_reward_std': Array(795.84717, dtype=float32), 'eval/episode_reward_alive_std': Array(60.896507, dtype=float32), 'eval/episode_reward_linvel_std': Array(817.84094, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.817894, dtype=float32), 'eval/episode_x_position_std': Array(448.66122, dtype=float32), 'eval/episode_x_velocity_std': Array(163.56818, dtype=float32), 'eval/episode_y_position_std': Array(259.65308, dtype=float32), 'eval/episode_y_velocity_std': Array(90.534706, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56223368644714, 'eval/sps': 937.3015990196352, 'num_steps': 31457280}
{'eval/walltime': 52724.42161941528, 'training/sps': 2930.495833947767, 'training/walltime': 10733.954074144363, 'training/entropy_loss': Array(0.01277698, dtype=float32), 'training/policy_loss': Array(0.00364947, dtype=float32), 'training/total_loss': Array(0.12795268, dtype=float32), 'training/v_loss': Array(0.11152624, dtype=float32), 'eval/episode_distance_from_origin': Array(5665.0337, dtype=float32), 'eval/episode_distance_reward': Array(20.17333, dtype=float32), 'eval/episode_forward_reward': Array(3362.2048, dtype=float32), 'eval/episode_reward': Array(3376.8716, dtype=float32), 'eval/episode_reward_alive': Array(376.53125, dtype=float32), 'eval/episode_reward_linvel': Array(3362.2048, dtype=float32), 'eval/episode_reward_quadctrl': Array(-382.03717, dtype=float32), 'eval/episode_x_position': Array(5609.491, dtype=float32), 'eval/episode_x_velocity': Array(672.441, dtype=float32), 'eval/episode_y_position': Array(-237.95596, dtype=float32), 'eval/episode_y_velocity': Array(-159.01208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(424.313, dtype=float32), 'eval/episode_distance_reward_std': Array(4.606257, dtype=float32), 'eval/episode_forward_reward_std': Array(767.70306, dtype=float32), 'eval/episode_reward_std': Array(752.628, dtype=float32), 'eval/episode_reward_alive_std': Array(63.364296, dtype=float32), 'eval/episode_reward_linvel_std': Array(767.70306, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.15986, dtype=float32), 'eval/episode_x_position_std': Array(419.13202, dtype=float32), 'eval/episode_x_velocity_std': Array(153.54059, dtype=float32), 'eval/episode_y_position_std': Array(309.33545, dtype=float32), 'eval/episode_y_velocity_std': Array(103.34866, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58335638046265, 'eval/sps': 937.1566447924072, 'num_steps': 31539200}
{'eval/walltime': 52861.079151153564, 'training/sps': 2933.7514406101473, 'training/walltime': 10761.877366781235, 'training/entropy_loss': Array(0.01270004, dtype=float32), 'training/policy_loss': Array(0.00239074, dtype=float32), 'training/total_loss': Array(0.11096501, dtype=float32), 'training/v_loss': Array(0.09587422, dtype=float32), 'eval/episode_distance_from_origin': Array(5628.841, dtype=float32), 'eval/episode_distance_reward': Array(20.166042, dtype=float32), 'eval/episode_forward_reward': Array(3360.9902, dtype=float32), 'eval/episode_reward': Array(3369.8965, dtype=float32), 'eval/episode_reward_alive': Array(370.2578, dtype=float32), 'eval/episode_reward_linvel': Array(3360.9902, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.51688, dtype=float32), 'eval/episode_x_position': Array(5572.19, dtype=float32), 'eval/episode_x_velocity': Array(672.198, dtype=float32), 'eval/episode_y_position': Array(-246.16933, dtype=float32), 'eval/episode_y_velocity': Array(-170.99998, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.75995, dtype=float32), 'eval/episode_distance_reward_std': Array(4.389329, dtype=float32), 'eval/episode_forward_reward_std': Array(731.5487, dtype=float32), 'eval/episode_reward_std': Array(715.3713, dtype=float32), 'eval/episode_reward_alive_std': Array(60.026882, dtype=float32), 'eval/episode_reward_linvel_std': Array(731.5487, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.492336, dtype=float32), 'eval/episode_x_position_std': Array(411.1464, dtype=float32), 'eval/episode_x_velocity_std': Array(146.30981, dtype=float32), 'eval/episode_y_position_std': Array(266.12756, dtype=float32), 'eval/episode_y_velocity_std': Array(90.7952, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65753173828125, 'eval/sps': 936.6479722840182, 'num_steps': 31621120}
{'eval/walltime': 52997.66739273071, 'training/sps': 2939.7496768689134, 'training/walltime': 10789.743685007095, 'training/entropy_loss': Array(0.01266379, dtype=float32), 'training/policy_loss': Array(0.01482302, dtype=float32), 'training/total_loss': Array(0.12038454, dtype=float32), 'training/v_loss': Array(0.09289773, dtype=float32), 'eval/episode_distance_from_origin': Array(5720.918, dtype=float32), 'eval/episode_distance_reward': Array(20.965174, dtype=float32), 'eval/episode_forward_reward': Array(3494.1782, dtype=float32), 'eval/episode_reward': Array(3514.6118, dtype=float32), 'eval/episode_reward_alive': Array(389.05078, dtype=float32), 'eval/episode_reward_linvel': Array(3494.1782, dtype=float32), 'eval/episode_reward_quadctrl': Array(-389.5829, dtype=float32), 'eval/episode_x_position': Array(5669.955, dtype=float32), 'eval/episode_x_velocity': Array(698.83575, dtype=float32), 'eval/episode_y_position': Array(-186.34958, dtype=float32), 'eval/episode_y_velocity': Array(-145.8667, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.9885, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9863577, dtype=float32), 'eval/episode_forward_reward_std': Array(831.0525, dtype=float32), 'eval/episode_reward_std': Array(815.7877, dtype=float32), 'eval/episode_reward_alive_std': Array(55.285652, dtype=float32), 'eval/episode_reward_linvel_std': Array(831.0525, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.609993, dtype=float32), 'eval/episode_x_position_std': Array(454.0008, dtype=float32), 'eval/episode_x_velocity_std': Array(166.21053, dtype=float32), 'eval/episode_y_position_std': Array(298.40244, dtype=float32), 'eval/episode_y_velocity_std': Array(97.91405, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58824157714844, 'eval/sps': 937.1231265738377, 'num_steps': 31703040}
{'eval/walltime': 53134.212137937546, 'training/sps': 2941.775901305441, 'training/walltime': 10817.590809583664, 'training/entropy_loss': Array(0.0097571, dtype=float32), 'training/policy_loss': Array(0.00859776, dtype=float32), 'training/total_loss': Array(0.07870704, dtype=float32), 'training/v_loss': Array(0.06035218, dtype=float32), 'eval/episode_distance_from_origin': Array(5668.0107, dtype=float32), 'eval/episode_distance_reward': Array(20.77373, dtype=float32), 'eval/episode_forward_reward': Array(3462.2715, dtype=float32), 'eval/episode_reward': Array(3483.2275, dtype=float32), 'eval/episode_reward_alive': Array(388.5547, dtype=float32), 'eval/episode_reward_linvel': Array(3462.2715, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.3722, dtype=float32), 'eval/episode_x_position': Array(5616.7, dtype=float32), 'eval/episode_x_velocity': Array(692.4542, dtype=float32), 'eval/episode_y_position': Array(-231.60971, dtype=float32), 'eval/episode_y_velocity': Array(-153.2489, dtype=float32), 'eval/episode_distance_from_origin_std': Array(459.75052, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2817163, dtype=float32), 'eval/episode_forward_reward_std': Array(880.2789, dtype=float32), 'eval/episode_reward_std': Array(864.9762, dtype=float32), 'eval/episode_reward_alive_std': Array(51.854824, dtype=float32), 'eval/episode_reward_linvel_std': Array(880.2789, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.431252, dtype=float32), 'eval/episode_x_position_std': Array(456.5132, dtype=float32), 'eval/episode_x_velocity_std': Array(176.0557, dtype=float32), 'eval/episode_y_position_std': Array(255.88205, dtype=float32), 'eval/episode_y_velocity_std': Array(90.3671, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54474520683289, 'eval/sps': 937.4216474322053, 'num_steps': 31784960}
{'eval/walltime': 53270.74046707153, 'training/sps': 2952.5490787684566, 'training/walltime': 10845.336326360703, 'training/entropy_loss': Array(0.01482214, dtype=float32), 'training/policy_loss': Array(0.00564908, dtype=float32), 'training/total_loss': Array(0.13209105, dtype=float32), 'training/v_loss': Array(0.11161982, dtype=float32), 'eval/episode_distance_from_origin': Array(5667.104, dtype=float32), 'eval/episode_distance_reward': Array(19.858707, dtype=float32), 'eval/episode_forward_reward': Array(3309.7683, dtype=float32), 'eval/episode_reward': Array(3338.3892, dtype=float32), 'eval/episode_reward_alive': Array(399.17188, dtype=float32), 'eval/episode_reward_linvel': Array(3309.7683, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.4093, dtype=float32), 'eval/episode_x_position': Array(5618.334, dtype=float32), 'eval/episode_x_velocity': Array(661.9536, dtype=float32), 'eval/episode_y_position': Array(-165.11736, dtype=float32), 'eval/episode_y_velocity': Array(-124.77735, dtype=float32), 'eval/episode_distance_from_origin_std': Array(484.5985, dtype=float32), 'eval/episode_distance_reward_std': Array(5.588285, dtype=float32), 'eval/episode_forward_reward_std': Array(931.373, dtype=float32), 'eval/episode_reward_std': Array(911.339, dtype=float32), 'eval/episode_reward_alive_std': Array(58.448242, dtype=float32), 'eval/episode_reward_linvel_std': Array(931.373, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.01275, dtype=float32), 'eval/episode_x_position_std': Array(482.92188, dtype=float32), 'eval/episode_x_velocity_std': Array(186.27457, dtype=float32), 'eval/episode_y_position_std': Array(295.5693, dtype=float32), 'eval/episode_y_velocity_std': Array(101.85013, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52832913398743, 'eval/sps': 937.534362369455, 'num_steps': 31866880}
{'eval/walltime': 53407.28917479515, 'training/sps': 2946.261055465759, 'training/walltime': 10873.141058683395, 'training/entropy_loss': Array(0.01337792, dtype=float32), 'training/policy_loss': Array(0.00405983, dtype=float32), 'training/total_loss': Array(0.14942366, dtype=float32), 'training/v_loss': Array(0.1319859, dtype=float32), 'eval/episode_distance_from_origin': Array(5753.8633, dtype=float32), 'eval/episode_distance_reward': Array(20.926857, dtype=float32), 'eval/episode_forward_reward': Array(3487.7927, dtype=float32), 'eval/episode_reward': Array(3505.0242, dtype=float32), 'eval/episode_reward_alive': Array(393.84766, dtype=float32), 'eval/episode_reward_linvel': Array(3487.7927, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.54315, dtype=float32), 'eval/episode_x_position': Array(5706.583, dtype=float32), 'eval/episode_x_velocity': Array(697.5586, dtype=float32), 'eval/episode_y_position': Array(-167.03737, dtype=float32), 'eval/episode_y_velocity': Array(-132.02283, dtype=float32), 'eval/episode_distance_from_origin_std': Array(455.70175, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2820377, dtype=float32), 'eval/episode_forward_reward_std': Array(880.3318, dtype=float32), 'eval/episode_reward_std': Array(871.3271, dtype=float32), 'eval/episode_reward_alive_std': Array(54.829586, dtype=float32), 'eval/episode_reward_linvel_std': Array(880.3318, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.78285, dtype=float32), 'eval/episode_x_position_std': Array(452.95828, dtype=float32), 'eval/episode_x_velocity_std': Array(176.06633, dtype=float32), 'eval/episode_y_position_std': Array(280.45554, dtype=float32), 'eval/episode_y_velocity_std': Array(94.797615, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54870772361755, 'eval/sps': 937.3944443258985, 'num_steps': 31948800}
{'eval/walltime': 53543.79580593109, 'training/sps': 2949.223618953081, 'training/walltime': 10900.917860507965, 'training/entropy_loss': Array(0.01289693, dtype=float32), 'training/policy_loss': Array(0.00513935, dtype=float32), 'training/total_loss': Array(0.13438793, dtype=float32), 'training/v_loss': Array(0.11635163, dtype=float32), 'eval/episode_distance_from_origin': Array(5672.5967, dtype=float32), 'eval/episode_distance_reward': Array(20.606487, dtype=float32), 'eval/episode_forward_reward': Array(3434.398, dtype=float32), 'eval/episode_reward': Array(3460.0527, dtype=float32), 'eval/episode_reward_alive': Array(392.76172, dtype=float32), 'eval/episode_reward_linvel': Array(3434.398, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.7133, dtype=float32), 'eval/episode_x_position': Array(5620.3774, dtype=float32), 'eval/episode_x_velocity': Array(686.8795, dtype=float32), 'eval/episode_y_position': Array(-179.919, dtype=float32), 'eval/episode_y_velocity': Array(-137.5781, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.31882, dtype=float32), 'eval/episode_distance_reward_std': Array(5.544456, dtype=float32), 'eval/episode_forward_reward_std': Array(924.0688, dtype=float32), 'eval/episode_reward_std': Array(904.962, dtype=float32), 'eval/episode_reward_alive_std': Array(54.106228, dtype=float32), 'eval/episode_reward_linvel_std': Array(924.0688, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.99702, dtype=float32), 'eval/episode_x_position_std': Array(480.37073, dtype=float32), 'eval/episode_x_velocity_std': Array(184.81375, dtype=float32), 'eval/episode_y_position_std': Array(318.92856, dtype=float32), 'eval/episode_y_velocity_std': Array(107.70465, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50663113594055, 'eval/sps': 937.6833853040501, 'num_steps': 32030720}
{'eval/walltime': 53680.24427008629, 'training/sps': 2946.171701364605, 'training/walltime': 10928.723436117172, 'training/entropy_loss': Array(0.01295757, dtype=float32), 'training/policy_loss': Array(0.0019116, dtype=float32), 'training/total_loss': Array(0.1300867, dtype=float32), 'training/v_loss': Array(0.11521754, dtype=float32), 'eval/episode_distance_from_origin': Array(5805.5146, dtype=float32), 'eval/episode_distance_reward': Array(21.692343, dtype=float32), 'eval/episode_forward_reward': Array(3615.3726, dtype=float32), 'eval/episode_reward': Array(3636.651, dtype=float32), 'eval/episode_reward_alive': Array(389.59375, dtype=float32), 'eval/episode_reward_linvel': Array(3615.3726, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.00787, dtype=float32), 'eval/episode_x_position': Array(5755.6895, dtype=float32), 'eval/episode_x_velocity': Array(723.0745, dtype=float32), 'eval/episode_y_position': Array(-216.04726, dtype=float32), 'eval/episode_y_velocity': Array(-147.58458, dtype=float32), 'eval/episode_distance_from_origin_std': Array(504.1529, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7803745, dtype=float32), 'eval/episode_forward_reward_std': Array(963.3878, dtype=float32), 'eval/episode_reward_std': Array(943.5342, dtype=float32), 'eval/episode_reward_alive_std': Array(60.06818, dtype=float32), 'eval/episode_reward_linvel_std': Array(963.3878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.332567, dtype=float32), 'eval/episode_x_position_std': Array(505.15912, dtype=float32), 'eval/episode_x_velocity_std': Array(192.67766, dtype=float32), 'eval/episode_y_position_std': Array(274.75964, dtype=float32), 'eval/episode_y_velocity_std': Array(95.98008, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44846415519714, 'eval/sps': 938.0831128623931, 'num_steps': 32112640}
{'eval/walltime': 53816.76204943657, 'training/sps': 2952.20487976719, 'training/walltime': 10956.472187757492, 'training/entropy_loss': Array(0.01330413, dtype=float32), 'training/policy_loss': Array(0.00423683, dtype=float32), 'training/total_loss': Array(0.107136, dtype=float32), 'training/v_loss': Array(0.08959503, dtype=float32), 'eval/episode_distance_from_origin': Array(5765.9556, dtype=float32), 'eval/episode_distance_reward': Array(21.329494, dtype=float32), 'eval/episode_forward_reward': Array(3554.8984, dtype=float32), 'eval/episode_reward': Array(3568.2534, dtype=float32), 'eval/episode_reward_alive': Array(384.65625, dtype=float32), 'eval/episode_reward_linvel': Array(3554.8984, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.63046, dtype=float32), 'eval/episode_x_position': Array(5713.4375, dtype=float32), 'eval/episode_x_velocity': Array(710.9797, dtype=float32), 'eval/episode_y_position': Array(-224.2684, dtype=float32), 'eval/episode_y_velocity': Array(-152.30383, dtype=float32), 'eval/episode_distance_from_origin_std': Array(437.65863, dtype=float32), 'eval/episode_distance_reward_std': Array(4.946067, dtype=float32), 'eval/episode_forward_reward_std': Array(824.3372, dtype=float32), 'eval/episode_reward_std': Array(803.73645, dtype=float32), 'eval/episode_reward_alive_std': Array(56.44251, dtype=float32), 'eval/episode_reward_linvel_std': Array(824.3372, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.138973, dtype=float32), 'eval/episode_x_position_std': Array(433.4671, dtype=float32), 'eval/episode_x_velocity_std': Array(164.86739, dtype=float32), 'eval/episode_y_position_std': Array(289.01694, dtype=float32), 'eval/episode_y_velocity_std': Array(97.95374, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51777935028076, 'eval/sps': 937.606812894124, 'num_steps': 32194560}
{'eval/walltime': 53953.19293117523, 'training/sps': 2942.985203284054, 'training/walltime': 10984.307869672775, 'training/entropy_loss': Array(0.01137491, dtype=float32), 'training/policy_loss': Array(0.01552967, dtype=float32), 'training/total_loss': Array(0.08580223, dtype=float32), 'training/v_loss': Array(0.05889765, dtype=float32), 'eval/episode_distance_from_origin': Array(5709.141, dtype=float32), 'eval/episode_distance_reward': Array(20.800236, dtype=float32), 'eval/episode_forward_reward': Array(3466.6895, dtype=float32), 'eval/episode_reward': Array(3481.1348, dtype=float32), 'eval/episode_reward_alive': Array(393.59375, dtype=float32), 'eval/episode_reward_linvel': Array(3466.6895, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.94846, dtype=float32), 'eval/episode_x_position': Array(5657.2266, dtype=float32), 'eval/episode_x_velocity': Array(693.3379, dtype=float32), 'eval/episode_y_position': Array(-212.17355, dtype=float32), 'eval/episode_y_velocity': Array(-143.48761, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.17343, dtype=float32), 'eval/episode_distance_reward_std': Array(5.395737, dtype=float32), 'eval/episode_forward_reward_std': Array(899.2816, dtype=float32), 'eval/episode_reward_std': Array(890.0684, dtype=float32), 'eval/episode_reward_alive_std': Array(57.57294, dtype=float32), 'eval/episode_reward_linvel_std': Array(899.2816, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.524796, dtype=float32), 'eval/episode_x_position_std': Array(449.94354, dtype=float32), 'eval/episode_x_velocity_std': Array(179.85637, dtype=float32), 'eval/episode_y_position_std': Array(300.28094, dtype=float32), 'eval/episode_y_velocity_std': Array(101.27565, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43088173866272, 'eval/sps': 938.204007544184, 'num_steps': 32276480}
{'eval/walltime': 54089.76594376564, 'training/sps': 2953.136035872178, 'training/walltime': 11012.04787182808, 'training/entropy_loss': Array(0.0124205, dtype=float32), 'training/policy_loss': Array(0.00396681, dtype=float32), 'training/total_loss': Array(0.1024131, dtype=float32), 'training/v_loss': Array(0.08602579, dtype=float32), 'eval/episode_distance_from_origin': Array(5784.92, dtype=float32), 'eval/episode_distance_reward': Array(21.413607, dtype=float32), 'eval/episode_forward_reward': Array(3568.9158, dtype=float32), 'eval/episode_reward': Array(3581.277, dtype=float32), 'eval/episode_reward_alive': Array(384.0547, dtype=float32), 'eval/episode_reward_linvel': Array(3568.9158, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.1073, dtype=float32), 'eval/episode_x_position': Array(5731.755, dtype=float32), 'eval/episode_x_velocity': Array(713.78314, dtype=float32), 'eval/episode_y_position': Array(-246.0481, dtype=float32), 'eval/episode_y_velocity': Array(-155.17984, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.21448, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6170144, dtype=float32), 'eval/episode_forward_reward_std': Array(936.1606, dtype=float32), 'eval/episode_reward_std': Array(922.7393, dtype=float32), 'eval/episode_reward_alive_std': Array(59.53988, dtype=float32), 'eval/episode_reward_linvel_std': Array(936.1606, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.329702, dtype=float32), 'eval/episode_x_position_std': Array(490.67804, dtype=float32), 'eval/episode_x_velocity_std': Array(187.23201, dtype=float32), 'eval/episode_y_position_std': Array(293.23315, dtype=float32), 'eval/episode_y_velocity_std': Array(96.13988, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57301259040833, 'eval/sps': 937.2276233217513, 'num_steps': 32358400}
{'eval/walltime': 54226.204612493515, 'training/sps': 2940.6188062477327, 'training/walltime': 11039.905953884125, 'training/entropy_loss': Array(0.0147597, dtype=float32), 'training/policy_loss': Array(0.00502042, dtype=float32), 'training/total_loss': Array(0.17805697, dtype=float32), 'training/v_loss': Array(0.15827686, dtype=float32), 'eval/episode_distance_from_origin': Array(5828.547, dtype=float32), 'eval/episode_distance_reward': Array(21.55947, dtype=float32), 'eval/episode_forward_reward': Array(3593.2285, dtype=float32), 'eval/episode_reward': Array(3611.497, dtype=float32), 'eval/episode_reward_alive': Array(392.04688, dtype=float32), 'eval/episode_reward_linvel': Array(3593.2285, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.33707, dtype=float32), 'eval/episode_x_position': Array(5779.918, dtype=float32), 'eval/episode_x_velocity': Array(718.64557, dtype=float32), 'eval/episode_y_position': Array(-197.18945, dtype=float32), 'eval/episode_y_velocity': Array(-138.15926, dtype=float32), 'eval/episode_distance_from_origin_std': Array(477.19882, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3805127, dtype=float32), 'eval/episode_forward_reward_std': Array(896.74445, dtype=float32), 'eval/episode_reward_std': Array(879.7071, dtype=float32), 'eval/episode_reward_alive_std': Array(59.52538, dtype=float32), 'eval/episode_reward_linvel_std': Array(896.74445, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.23099, dtype=float32), 'eval/episode_x_position_std': Array(473.89703, dtype=float32), 'eval/episode_x_velocity_std': Array(179.34892, dtype=float32), 'eval/episode_y_position_std': Array(290.99588, dtype=float32), 'eval/episode_y_velocity_std': Array(95.9128, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43866872787476, 'eval/sps': 938.1504612544587, 'num_steps': 32440320}
{'eval/walltime': 54362.71325659752, 'training/sps': 2935.025553709258, 'training/walltime': 11067.817124843597, 'training/entropy_loss': Array(0.01348389, dtype=float32), 'training/policy_loss': Array(0.00444508, dtype=float32), 'training/total_loss': Array(0.11834376, dtype=float32), 'training/v_loss': Array(0.10041478, dtype=float32), 'eval/episode_distance_from_origin': Array(5705.3716, dtype=float32), 'eval/episode_distance_reward': Array(20.895912, dtype=float32), 'eval/episode_forward_reward': Array(3482.6343, dtype=float32), 'eval/episode_reward': Array(3502.0024, dtype=float32), 'eval/episode_reward_alive': Array(388.73828, dtype=float32), 'eval/episode_reward_linvel': Array(3482.6343, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.26642, dtype=float32), 'eval/episode_x_position': Array(5656.093, dtype=float32), 'eval/episode_x_velocity': Array(696.5269, dtype=float32), 'eval/episode_y_position': Array(-228.9417, dtype=float32), 'eval/episode_y_velocity': Array(-152.77298, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.9288, dtype=float32), 'eval/episode_distance_reward_std': Array(5.596326, dtype=float32), 'eval/episode_forward_reward_std': Array(932.713, dtype=float32), 'eval/episode_reward_std': Array(913.02826, dtype=float32), 'eval/episode_reward_alive_std': Array(59.06984, dtype=float32), 'eval/episode_reward_linvel_std': Array(932.713, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.96529, dtype=float32), 'eval/episode_x_position_std': Array(457.44186, dtype=float32), 'eval/episode_x_velocity_std': Array(186.54254, dtype=float32), 'eval/episode_y_position_std': Array(236.68138, dtype=float32), 'eval/episode_y_velocity_std': Array(91.45214, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5086441040039, 'eval/sps': 937.6695581451875, 'num_steps': 32522240}
{'eval/walltime': 54499.15591931343, 'training/sps': 2937.918150379358, 'training/walltime': 11095.700815200806, 'training/entropy_loss': Array(0.0138038, dtype=float32), 'training/policy_loss': Array(0.00432081, dtype=float32), 'training/total_loss': Array(0.12507653, dtype=float32), 'training/v_loss': Array(0.10695193, dtype=float32), 'eval/episode_distance_from_origin': Array(5810.6475, dtype=float32), 'eval/episode_distance_reward': Array(21.493416, dtype=float32), 'eval/episode_forward_reward': Array(3582.2188, dtype=float32), 'eval/episode_reward': Array(3596.0505, dtype=float32), 'eval/episode_reward_alive': Array(388.34375, dtype=float32), 'eval/episode_reward_linvel': Array(3582.2188, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.00555, dtype=float32), 'eval/episode_x_position': Array(5759.2983, dtype=float32), 'eval/episode_x_velocity': Array(716.4437, dtype=float32), 'eval/episode_y_position': Array(-221.07724, dtype=float32), 'eval/episode_y_velocity': Array(-150.62607, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.9542, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3467546, dtype=float32), 'eval/episode_forward_reward_std': Array(891.1187, dtype=float32), 'eval/episode_reward_std': Array(884.61774, dtype=float32), 'eval/episode_reward_alive_std': Array(54.15158, dtype=float32), 'eval/episode_reward_linvel_std': Array(891.1187, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.73326, dtype=float32), 'eval/episode_x_position_std': Array(451.26556, dtype=float32), 'eval/episode_x_velocity_std': Array(178.22371, dtype=float32), 'eval/episode_y_position_std': Array(285.1682, dtype=float32), 'eval/episode_y_velocity_std': Array(101.13862, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44266271591187, 'eval/sps': 938.1229994500299, 'num_steps': 32604160}
{'eval/walltime': 54635.74173998833, 'training/sps': 2946.260474406598, 'training/walltime': 11123.505553007126, 'training/entropy_loss': Array(0.01367737, dtype=float32), 'training/policy_loss': Array(0.00252899, dtype=float32), 'training/total_loss': Array(0.11539817, dtype=float32), 'training/v_loss': Array(0.09919181, dtype=float32), 'eval/episode_distance_from_origin': Array(5819.282, dtype=float32), 'eval/episode_distance_reward': Array(22.313423, dtype=float32), 'eval/episode_forward_reward': Array(3718.8853, dtype=float32), 'eval/episode_reward': Array(3735.0046, dtype=float32), 'eval/episode_reward_alive': Array(386.54297, dtype=float32), 'eval/episode_reward_linvel': Array(3718.8853, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.73666, dtype=float32), 'eval/episode_x_position': Array(5767.864, dtype=float32), 'eval/episode_x_velocity': Array(743.77704, dtype=float32), 'eval/episode_y_position': Array(-201.8021, dtype=float32), 'eval/episode_y_velocity': Array(-151.09969, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.81537, dtype=float32), 'eval/episode_distance_reward_std': Array(5.391482, dtype=float32), 'eval/episode_forward_reward_std': Array(898.57355, dtype=float32), 'eval/episode_reward_std': Array(883.07996, dtype=float32), 'eval/episode_reward_alive_std': Array(54.92111, dtype=float32), 'eval/episode_reward_linvel_std': Array(898.57355, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.247568, dtype=float32), 'eval/episode_x_position_std': Array(474.87082, dtype=float32), 'eval/episode_x_velocity_std': Array(179.71463, dtype=float32), 'eval/episode_y_position_std': Array(299.5583, dtype=float32), 'eval/episode_y_velocity_std': Array(95.853935, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58582067489624, 'eval/sps': 937.139736522634, 'num_steps': 32686080}
{'eval/walltime': 54772.31689167023, 'training/sps': 2932.229904857717, 'training/walltime': 11151.443335056305, 'training/entropy_loss': Array(0.01346403, dtype=float32), 'training/policy_loss': Array(0.0040013, dtype=float32), 'training/total_loss': Array(0.101487, dtype=float32), 'training/v_loss': Array(0.08402167, dtype=float32), 'eval/episode_distance_from_origin': Array(5870.94, dtype=float32), 'eval/episode_distance_reward': Array(22.47816, dtype=float32), 'eval/episode_forward_reward': Array(3746.3416, dtype=float32), 'eval/episode_reward': Array(3761.5986, dtype=float32), 'eval/episode_reward_alive': Array(384.17188, dtype=float32), 'eval/episode_reward_linvel': Array(3746.3416, dtype=float32), 'eval/episode_reward_quadctrl': Array(-391.3924, dtype=float32), 'eval/episode_x_position': Array(5821.5312, dtype=float32), 'eval/episode_x_velocity': Array(749.26825, dtype=float32), 'eval/episode_y_position': Array(-197.07742, dtype=float32), 'eval/episode_y_velocity': Array(-153.76068, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.3321, dtype=float32), 'eval/episode_distance_reward_std': Array(5.425756, dtype=float32), 'eval/episode_forward_reward_std': Array(904.2851, dtype=float32), 'eval/episode_reward_std': Array(884.5178, dtype=float32), 'eval/episode_reward_alive_std': Array(59.42522, dtype=float32), 'eval/episode_reward_linvel_std': Array(904.2851, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.0962, dtype=float32), 'eval/episode_x_position_std': Array(452.24738, dtype=float32), 'eval/episode_x_velocity_std': Array(180.85696, dtype=float32), 'eval/episode_y_position_std': Array(264.17422, dtype=float32), 'eval/episode_y_velocity_std': Array(93.91131, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57515168190002, 'eval/sps': 937.2129441095362, 'num_steps': 32768000}
{'eval/walltime': 54908.91067671776, 'training/sps': 2947.8620358833214, 'training/walltime': 11179.232966661453, 'training/entropy_loss': Array(0.01203007, dtype=float32), 'training/policy_loss': Array(0.004905, dtype=float32), 'training/total_loss': Array(0.09863778, dtype=float32), 'training/v_loss': Array(0.08170271, dtype=float32), 'eval/episode_distance_from_origin': Array(5942.9863, dtype=float32), 'eval/episode_distance_reward': Array(22.428532, dtype=float32), 'eval/episode_forward_reward': Array(3738.0698, dtype=float32), 'eval/episode_reward': Array(3747.3696, dtype=float32), 'eval/episode_reward_alive': Array(385.83203, dtype=float32), 'eval/episode_reward_linvel': Array(3738.0698, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.96136, dtype=float32), 'eval/episode_x_position': Array(5889.0303, dtype=float32), 'eval/episode_x_velocity': Array(747.614, dtype=float32), 'eval/episode_y_position': Array(-277.57196, dtype=float32), 'eval/episode_y_velocity': Array(-161.16174, dtype=float32), 'eval/episode_distance_from_origin_std': Array(433.86765, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9339542, dtype=float32), 'eval/episode_forward_reward_std': Array(822.3191, dtype=float32), 'eval/episode_reward_std': Array(799.08203, dtype=float32), 'eval/episode_reward_alive_std': Array(55.781075, dtype=float32), 'eval/episode_reward_linvel_std': Array(822.3191, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.487404, dtype=float32), 'eval/episode_x_position_std': Array(430.45166, dtype=float32), 'eval/episode_x_velocity_std': Array(164.46378, dtype=float32), 'eval/episode_y_position_std': Array(291.70364, dtype=float32), 'eval/episode_y_velocity_std': Array(93.5525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59378504753113, 'eval/sps': 937.0850947241801, 'num_steps': 32849920}
{'eval/walltime': 55045.458020448685, 'training/sps': 2941.1439293209996, 'training/walltime': 11207.086074829102, 'training/entropy_loss': Array(0.01471629, dtype=float32), 'training/policy_loss': Array(0.00727774, dtype=float32), 'training/total_loss': Array(0.17498231, dtype=float32), 'training/v_loss': Array(0.15298827, dtype=float32), 'eval/episode_distance_from_origin': Array(5850.83, dtype=float32), 'eval/episode_distance_reward': Array(22.171246, dtype=float32), 'eval/episode_forward_reward': Array(3695.1892, dtype=float32), 'eval/episode_reward': Array(3705.1123, dtype=float32), 'eval/episode_reward_alive': Array(385.13672, dtype=float32), 'eval/episode_reward_linvel': Array(3695.1892, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.38474, dtype=float32), 'eval/episode_x_position': Array(5798.5293, dtype=float32), 'eval/episode_x_velocity': Array(739.0377, dtype=float32), 'eval/episode_y_position': Array(-260.1646, dtype=float32), 'eval/episode_y_velocity': Array(-159.91075, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.8491, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4224024, dtype=float32), 'eval/episode_forward_reward_std': Array(903.72577, dtype=float32), 'eval/episode_reward_std': Array(890.3369, dtype=float32), 'eval/episode_reward_alive_std': Array(54.569397, dtype=float32), 'eval/episode_reward_linvel_std': Array(903.72577, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.520103, dtype=float32), 'eval/episode_x_position_std': Array(452.2897, dtype=float32), 'eval/episode_x_velocity_std': Array(180.74524, dtype=float32), 'eval/episode_y_position_std': Array(267.70874, dtype=float32), 'eval/episode_y_velocity_std': Array(86.747765, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5473437309265, 'eval/sps': 937.4038081050519, 'num_steps': 32931840}
{'eval/walltime': 55182.038974285126, 'training/sps': 2961.0370037303833, 'training/walltime': 11234.752058029175, 'training/entropy_loss': Array(0.01385278, dtype=float32), 'training/policy_loss': Array(0.00525594, dtype=float32), 'training/total_loss': Array(0.13931765, dtype=float32), 'training/v_loss': Array(0.12020894, dtype=float32), 'eval/episode_distance_from_origin': Array(5819.6035, dtype=float32), 'eval/episode_distance_reward': Array(21.720116, dtype=float32), 'eval/episode_forward_reward': Array(3620.0017, dtype=float32), 'eval/episode_reward': Array(3627.3438, dtype=float32), 'eval/episode_reward_alive': Array(382.8047, dtype=float32), 'eval/episode_reward_linvel': Array(3620.0017, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.1829, dtype=float32), 'eval/episode_x_position': Array(5761.9653, dtype=float32), 'eval/episode_x_velocity': Array(724.00037, dtype=float32), 'eval/episode_y_position': Array(-321.60394, dtype=float32), 'eval/episode_y_velocity': Array(-176.8087, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.6197, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4052367, dtype=float32), 'eval/episode_forward_reward_std': Array(900.86456, dtype=float32), 'eval/episode_reward_std': Array(879.42224, dtype=float32), 'eval/episode_reward_alive_std': Array(55.535328, dtype=float32), 'eval/episode_reward_linvel_std': Array(900.86456, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.383417, dtype=float32), 'eval/episode_x_position_std': Array(487.224, dtype=float32), 'eval/episode_x_velocity_std': Array(180.17291, dtype=float32), 'eval/episode_y_position_std': Array(277.51065, dtype=float32), 'eval/episode_y_velocity_std': Array(94.21467, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58095383644104, 'eval/sps': 937.17312996132, 'num_steps': 33013760}
{'eval/walltime': 55318.56360769272, 'training/sps': 2964.9663149734797, 'training/walltime': 11262.381376981735, 'training/entropy_loss': Array(0.01450566, dtype=float32), 'training/policy_loss': Array(0.00368167, dtype=float32), 'training/total_loss': Array(0.13927847, dtype=float32), 'training/v_loss': Array(0.12109116, dtype=float32), 'eval/episode_distance_from_origin': Array(5842.9365, dtype=float32), 'eval/episode_distance_reward': Array(21.927586, dtype=float32), 'eval/episode_forward_reward': Array(3654.58, dtype=float32), 'eval/episode_reward': Array(3672.3958, dtype=float32), 'eval/episode_reward_alive': Array(395.22656, dtype=float32), 'eval/episode_reward_linvel': Array(3654.58, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.33826, dtype=float32), 'eval/episode_x_position': Array(5791.3765, dtype=float32), 'eval/episode_x_velocity': Array(730.916, dtype=float32), 'eval/episode_y_position': Array(-225.42712, dtype=float32), 'eval/episode_y_velocity': Array(-148.64757, dtype=float32), 'eval/episode_distance_from_origin_std': Array(526.1561, dtype=float32), 'eval/episode_distance_reward_std': Array(6.13848, dtype=float32), 'eval/episode_forward_reward_std': Array(1023.07214, dtype=float32), 'eval/episode_reward_std': Array(1005.95496, dtype=float32), 'eval/episode_reward_alive_std': Array(56.940033, dtype=float32), 'eval/episode_reward_linvel_std': Array(1023.07214, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.5109, dtype=float32), 'eval/episode_x_position_std': Array(523.70496, dtype=float32), 'eval/episode_x_velocity_std': Array(204.61443, dtype=float32), 'eval/episode_y_position_std': Array(303.51544, dtype=float32), 'eval/episode_y_velocity_std': Array(99.085526, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52463340759277, 'eval/sps': 937.5597414560157, 'num_steps': 33095680}
{'eval/walltime': 55455.1398127079, 'training/sps': 2948.8427894970996, 'training/walltime': 11290.161766052246, 'training/entropy_loss': Array(0.01452531, dtype=float32), 'training/policy_loss': Array(0.00423588, dtype=float32), 'training/total_loss': Array(0.13461465, dtype=float32), 'training/v_loss': Array(0.11585346, dtype=float32), 'eval/episode_distance_from_origin': Array(5740.648, dtype=float32), 'eval/episode_distance_reward': Array(21.442448, dtype=float32), 'eval/episode_forward_reward': Array(3573.7227, dtype=float32), 'eval/episode_reward': Array(3584.3203, dtype=float32), 'eval/episode_reward_alive': Array(384.8086, dtype=float32), 'eval/episode_reward_linvel': Array(3573.7227, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.65366, dtype=float32), 'eval/episode_x_position': Array(5683.8438, dtype=float32), 'eval/episode_x_velocity': Array(714.74457, dtype=float32), 'eval/episode_y_position': Array(-288.02673, dtype=float32), 'eval/episode_y_velocity': Array(-164.74332, dtype=float32), 'eval/episode_distance_from_origin_std': Array(557.1629, dtype=float32), 'eval/episode_distance_reward_std': Array(6.324784, dtype=float32), 'eval/episode_forward_reward_std': Array(1054.1217, dtype=float32), 'eval/episode_reward_std': Array(1036.71, dtype=float32), 'eval/episode_reward_alive_std': Array(60.003223, dtype=float32), 'eval/episode_reward_linvel_std': Array(1054.1217, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.23587, dtype=float32), 'eval/episode_x_position_std': Array(553.20294, dtype=float32), 'eval/episode_x_velocity_std': Array(210.82426, dtype=float32), 'eval/episode_y_position_std': Array(298.92822, dtype=float32), 'eval/episode_y_velocity_std': Array(102.56525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5762050151825, 'eval/sps': 937.2057159281214, 'num_steps': 33177600}
{'eval/walltime': 55591.655348300934, 'training/sps': 2947.68794353937, 'training/walltime': 11317.953038930893, 'training/entropy_loss': Array(0.01464752, dtype=float32), 'training/policy_loss': Array(0.00569083, dtype=float32), 'training/total_loss': Array(0.12778339, dtype=float32), 'training/v_loss': Array(0.10744504, dtype=float32), 'eval/episode_distance_from_origin': Array(5834.2617, dtype=float32), 'eval/episode_distance_reward': Array(22.292465, dtype=float32), 'eval/episode_forward_reward': Array(3715.3928, dtype=float32), 'eval/episode_reward': Array(3730.9429, dtype=float32), 'eval/episode_reward_alive': Array(390.3672, dtype=float32), 'eval/episode_reward_linvel': Array(3715.3928, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.10974, dtype=float32), 'eval/episode_x_position': Array(5779.7627, dtype=float32), 'eval/episode_x_velocity': Array(743.07855, dtype=float32), 'eval/episode_y_position': Array(-261.40393, dtype=float32), 'eval/episode_y_velocity': Array(-164.29787, dtype=float32), 'eval/episode_distance_from_origin_std': Array(523.8018, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9204435, dtype=float32), 'eval/episode_forward_reward_std': Array(986.7326, dtype=float32), 'eval/episode_reward_std': Array(974.20404, dtype=float32), 'eval/episode_reward_alive_std': Array(55.447098, dtype=float32), 'eval/episode_reward_linvel_std': Array(986.7326, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.843735, dtype=float32), 'eval/episode_x_position_std': Array(522.01154, dtype=float32), 'eval/episode_x_velocity_std': Array(197.34651, dtype=float32), 'eval/episode_y_position_std': Array(294.77008, dtype=float32), 'eval/episode_y_velocity_std': Array(94.9341, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51553559303284, 'eval/sps': 937.6222233166301, 'num_steps': 33259520}
{'eval/walltime': 55728.25129342079, 'training/sps': 2963.619505377626, 'training/walltime': 11345.594913959503, 'training/entropy_loss': Array(0.01044088, dtype=float32), 'training/policy_loss': Array(0.0006332, dtype=float32), 'training/total_loss': Array(0.05765728, dtype=float32), 'training/v_loss': Array(0.04658321, dtype=float32), 'eval/episode_distance_from_origin': Array(5848.038, dtype=float32), 'eval/episode_distance_reward': Array(22.184938, dtype=float32), 'eval/episode_forward_reward': Array(3697.4707, dtype=float32), 'eval/episode_reward': Array(3707.5996, dtype=float32), 'eval/episode_reward_alive': Array(382.66016, dtype=float32), 'eval/episode_reward_linvel': Array(3697.4707, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.71664, dtype=float32), 'eval/episode_x_position': Array(5795.3267, dtype=float32), 'eval/episode_x_velocity': Array(739.49414, dtype=float32), 'eval/episode_y_position': Array(-265.5354, dtype=float32), 'eval/episode_y_velocity': Array(-168.6252, dtype=float32), 'eval/episode_distance_from_origin_std': Array(466.1939, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2968516, dtype=float32), 'eval/episode_forward_reward_std': Array(882.8012, dtype=float32), 'eval/episode_reward_std': Array(863.5944, dtype=float32), 'eval/episode_reward_alive_std': Array(59.74898, dtype=float32), 'eval/episode_reward_linvel_std': Array(882.8012, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.503145, dtype=float32), 'eval/episode_x_position_std': Array(464.44318, dtype=float32), 'eval/episode_x_velocity_std': Array(176.56026, dtype=float32), 'eval/episode_y_position_std': Array(257.608, dtype=float32), 'eval/episode_y_velocity_std': Array(92.12159, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5959451198578, 'eval/sps': 937.0702760443206, 'num_steps': 33341440}
{'eval/walltime': 55864.775019168854, 'training/sps': 2957.715245018876, 'training/walltime': 11373.291968345642, 'training/entropy_loss': Array(0.01572216, dtype=float32), 'training/policy_loss': Array(0.00785233, dtype=float32), 'training/total_loss': Array(0.15712716, dtype=float32), 'training/v_loss': Array(0.13355267, dtype=float32), 'eval/episode_distance_from_origin': Array(5818.9917, dtype=float32), 'eval/episode_distance_reward': Array(22.004814, dtype=float32), 'eval/episode_forward_reward': Array(3667.4507, dtype=float32), 'eval/episode_reward': Array(3687.9775, dtype=float32), 'eval/episode_reward_alive': Array(394.58594, dtype=float32), 'eval/episode_reward_linvel': Array(3667.4507, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.06372, dtype=float32), 'eval/episode_x_position': Array(5762.4536, dtype=float32), 'eval/episode_x_velocity': Array(733.4901, dtype=float32), 'eval/episode_y_position': Array(-314.96704, dtype=float32), 'eval/episode_y_velocity': Array(-169.31714, dtype=float32), 'eval/episode_distance_from_origin_std': Array(447.78067, dtype=float32), 'eval/episode_distance_reward_std': Array(5.226103, dtype=float32), 'eval/episode_forward_reward_std': Array(871.0099, dtype=float32), 'eval/episode_reward_std': Array(851.48236, dtype=float32), 'eval/episode_reward_alive_std': Array(51.24524, dtype=float32), 'eval/episode_reward_linvel_std': Array(871.0099, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.470798, dtype=float32), 'eval/episode_x_position_std': Array(444.91608, dtype=float32), 'eval/episode_x_velocity_std': Array(174.20193, dtype=float32), 'eval/episode_y_position_std': Array(272.97324, dtype=float32), 'eval/episode_y_velocity_std': Array(89.93308, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52372574806213, 'eval/sps': 937.565974695185, 'num_steps': 33423360}
{'eval/walltime': 56001.337619781494, 'training/sps': 2966.564744879274, 'training/walltime': 11400.906400203705, 'training/entropy_loss': Array(0.01551126, dtype=float32), 'training/policy_loss': Array(0.0079982, dtype=float32), 'training/total_loss': Array(0.14514978, dtype=float32), 'training/v_loss': Array(0.12164033, dtype=float32), 'eval/episode_distance_from_origin': Array(5803.665, dtype=float32), 'eval/episode_distance_reward': Array(21.586208, dtype=float32), 'eval/episode_forward_reward': Array(3597.6836, dtype=float32), 'eval/episode_reward': Array(3622.3606, dtype=float32), 'eval/episode_reward_alive': Array(397.1797, dtype=float32), 'eval/episode_reward_linvel': Array(3597.6836, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.08884, dtype=float32), 'eval/episode_x_position': Array(5751.17, dtype=float32), 'eval/episode_x_velocity': Array(719.53674, dtype=float32), 'eval/episode_y_position': Array(-230.60184, dtype=float32), 'eval/episode_y_velocity': Array(-153.07346, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.4263, dtype=float32), 'eval/episode_distance_reward_std': Array(5.735419, dtype=float32), 'eval/episode_forward_reward_std': Array(955.8941, dtype=float32), 'eval/episode_reward_std': Array(931.21075, dtype=float32), 'eval/episode_reward_alive_std': Array(57.49962, dtype=float32), 'eval/episode_reward_linvel_std': Array(955.8941, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.871706, dtype=float32), 'eval/episode_x_position_std': Array(465.19333, dtype=float32), 'eval/episode_x_velocity_std': Array(191.17886, dtype=float32), 'eval/episode_y_position_std': Array(308.52853, dtype=float32), 'eval/episode_y_velocity_std': Array(109.619484, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56260061264038, 'eval/sps': 937.2990806104507, 'num_steps': 33505280}
{'eval/walltime': 56137.8541033268, 'training/sps': 2952.417330976365, 'training/walltime': 11428.653155088425, 'training/entropy_loss': Array(0.01452967, dtype=float32), 'training/policy_loss': Array(0.00927764, dtype=float32), 'training/total_loss': Array(0.13721287, dtype=float32), 'training/v_loss': Array(0.11340557, dtype=float32), 'eval/episode_distance_from_origin': Array(5915.7783, dtype=float32), 'eval/episode_distance_reward': Array(23.16219, dtype=float32), 'eval/episode_forward_reward': Array(3860.3445, dtype=float32), 'eval/episode_reward': Array(3872.6475, dtype=float32), 'eval/episode_reward_alive': Array(387.8203, dtype=float32), 'eval/episode_reward_linvel': Array(3860.3445, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.68024, dtype=float32), 'eval/episode_x_position': Array(5860.959, dtype=float32), 'eval/episode_x_velocity': Array(772.06885, dtype=float32), 'eval/episode_y_position': Array(-272.1748, dtype=float32), 'eval/episode_y_velocity': Array(-169.97073, dtype=float32), 'eval/episode_distance_from_origin_std': Array(434.1655, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1256337, dtype=float32), 'eval/episode_forward_reward_std': Array(854.2655, dtype=float32), 'eval/episode_reward_std': Array(844.5006, dtype=float32), 'eval/episode_reward_alive_std': Array(52.630184, dtype=float32), 'eval/episode_reward_linvel_std': Array(854.2655, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.618683, dtype=float32), 'eval/episode_x_position_std': Array(433.0233, dtype=float32), 'eval/episode_x_velocity_std': Array(170.85312, dtype=float32), 'eval/episode_y_position_std': Array(307.2857, dtype=float32), 'eval/episode_y_velocity_std': Array(92.28628, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51648354530334, 'eval/sps': 937.6157125928523, 'num_steps': 33587200}
{'eval/walltime': 56274.40595269203, 'training/sps': 2961.732569510824, 'training/walltime': 11456.31264090538, 'training/entropy_loss': Array(0.01483203, dtype=float32), 'training/policy_loss': Array(0.00360512, dtype=float32), 'training/total_loss': Array(0.11224843, dtype=float32), 'training/v_loss': Array(0.09381129, dtype=float32), 'eval/episode_distance_from_origin': Array(5856.8438, dtype=float32), 'eval/episode_distance_reward': Array(22.748816, dtype=float32), 'eval/episode_forward_reward': Array(3791.4495, dtype=float32), 'eval/episode_reward': Array(3808.9697, dtype=float32), 'eval/episode_reward_alive': Array(387.27344, dtype=float32), 'eval/episode_reward_linvel': Array(3791.4495, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.50204, dtype=float32), 'eval/episode_x_position': Array(5797.6104, dtype=float32), 'eval/episode_x_velocity': Array(758.2899, dtype=float32), 'eval/episode_y_position': Array(-348.41943, dtype=float32), 'eval/episode_y_velocity': Array(-191.41612, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.20358, dtype=float32), 'eval/episode_distance_reward_std': Array(5.722594, dtype=float32), 'eval/episode_forward_reward_std': Array(953.7572, dtype=float32), 'eval/episode_reward_std': Array(933.1754, dtype=float32), 'eval/episode_reward_alive_std': Array(57.30827, dtype=float32), 'eval/episode_reward_linvel_std': Array(953.7572, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.627848, dtype=float32), 'eval/episode_x_position_std': Array(504.6225, dtype=float32), 'eval/episode_x_velocity_std': Array(190.75153, dtype=float32), 'eval/episode_y_position_std': Array(262.61993, dtype=float32), 'eval/episode_y_velocity_std': Array(81.0549, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55184936523438, 'eval/sps': 937.3728777384714, 'num_steps': 33669120}
{'eval/walltime': 56410.92410039902, 'training/sps': 2953.948162147954, 'training/walltime': 11484.045016527176, 'training/entropy_loss': Array(0.01472517, dtype=float32), 'training/policy_loss': Array(0.0047499, dtype=float32), 'training/total_loss': Array(0.12313902, dtype=float32), 'training/v_loss': Array(0.10366396, dtype=float32), 'eval/episode_distance_from_origin': Array(5960.2363, dtype=float32), 'eval/episode_distance_reward': Array(23.538979, dtype=float32), 'eval/episode_forward_reward': Array(3923.143, dtype=float32), 'eval/episode_reward': Array(3946.6423, dtype=float32), 'eval/episode_reward_alive': Array(394.54688, dtype=float32), 'eval/episode_reward_linvel': Array(3923.143, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.58673, dtype=float32), 'eval/episode_x_position': Array(5902.5103, dtype=float32), 'eval/episode_x_velocity': Array(784.62866, dtype=float32), 'eval/episode_y_position': Array(-329.75305, dtype=float32), 'eval/episode_y_velocity': Array(-181.48782, dtype=float32), 'eval/episode_distance_from_origin_std': Array(404.9384, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1438246, dtype=float32), 'eval/episode_forward_reward_std': Array(857.29724, dtype=float32), 'eval/episode_reward_std': Array(848.8048, dtype=float32), 'eval/episode_reward_alive_std': Array(52.013535, dtype=float32), 'eval/episode_reward_linvel_std': Array(857.29724, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.98919, dtype=float32), 'eval/episode_x_position_std': Array(403.9307, dtype=float32), 'eval/episode_x_velocity_std': Array(171.4595, dtype=float32), 'eval/episode_y_position_std': Array(283.77377, dtype=float32), 'eval/episode_y_velocity_std': Array(91.28705, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51814770698547, 'eval/sps': 937.6042830198054, 'num_steps': 33751040}
{'eval/walltime': 56547.60091423988, 'training/sps': 2962.6602691342123, 'training/walltime': 11511.695841312408, 'training/entropy_loss': Array(0.01116609, dtype=float32), 'training/policy_loss': Array(2.0999316e-05, dtype=float32), 'training/total_loss': Array(0.06912901, dtype=float32), 'training/v_loss': Array(0.05794192, dtype=float32), 'eval/episode_distance_from_origin': Array(5993.502, dtype=float32), 'eval/episode_distance_reward': Array(24.757511, dtype=float32), 'eval/episode_forward_reward': Array(4126.2295, dtype=float32), 'eval/episode_reward': Array(4137.2397, dtype=float32), 'eval/episode_reward_alive': Array(374.125, dtype=float32), 'eval/episode_reward_linvel': Array(4126.2295, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.87238, dtype=float32), 'eval/episode_x_position': Array(5937.0747, dtype=float32), 'eval/episode_x_velocity': Array(825.2458, dtype=float32), 'eval/episode_y_position': Array(-289.81317, dtype=float32), 'eval/episode_y_velocity': Array(-186.44162, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.96292, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4502416, dtype=float32), 'eval/episode_forward_reward_std': Array(908.3658, dtype=float32), 'eval/episode_reward_std': Array(897.13855, dtype=float32), 'eval/episode_reward_alive_std': Array(52.42461, dtype=float32), 'eval/episode_reward_linvel_std': Array(908.3658, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.78142, dtype=float32), 'eval/episode_x_position_std': Array(459.63162, dtype=float32), 'eval/episode_x_velocity_std': Array(181.6731, dtype=float32), 'eval/episode_y_position_std': Array(299.2323, dtype=float32), 'eval/episode_y_velocity_std': Array(97.8485, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6768138408661, 'eval/sps': 936.5158317857148, 'num_steps': 33832960}
{'eval/walltime': 56684.131049871445, 'training/sps': 2960.5430421732826, 'training/walltime': 11539.366440534592, 'training/entropy_loss': Array(0.0162283, dtype=float32), 'training/policy_loss': Array(0.00747763, dtype=float32), 'training/total_loss': Array(0.12102527, dtype=float32), 'training/v_loss': Array(0.09731933, dtype=float32), 'eval/episode_distance_from_origin': Array(6015.137, dtype=float32), 'eval/episode_distance_reward': Array(24.360422, dtype=float32), 'eval/episode_forward_reward': Array(4060.048, dtype=float32), 'eval/episode_reward': Array(4077.0342, dtype=float32), 'eval/episode_reward_alive': Array(381.84375, dtype=float32), 'eval/episode_reward_linvel': Array(4060.048, dtype=float32), 'eval/episode_reward_quadctrl': Array(-389.2188, dtype=float32), 'eval/episode_x_position': Array(5956.2573, dtype=float32), 'eval/episode_x_velocity': Array(812.00964, dtype=float32), 'eval/episode_y_position': Array(-348.5185, dtype=float32), 'eval/episode_y_velocity': Array(-191.70726, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.23587, dtype=float32), 'eval/episode_distance_reward_std': Array(5.318455, dtype=float32), 'eval/episode_forward_reward_std': Array(886.4022, dtype=float32), 'eval/episode_reward_std': Array(875.3975, dtype=float32), 'eval/episode_reward_alive_std': Array(45.92388, dtype=float32), 'eval/episode_reward_linvel_std': Array(886.4022, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.710396, dtype=float32), 'eval/episode_x_position_std': Array(461.2789, dtype=float32), 'eval/episode_x_velocity_std': Array(177.28049, dtype=float32), 'eval/episode_y_position_std': Array(269.45706, dtype=float32), 'eval/episode_y_velocity_std': Array(95.3493, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53013563156128, 'eval/sps': 937.5219573898278, 'num_steps': 33914880}
{'eval/walltime': 56820.64221072197, 'training/sps': 2958.2395392784065, 'training/walltime': 11567.058586120605, 'training/entropy_loss': Array(0.01408796, dtype=float32), 'training/policy_loss': Array(0.00999373, dtype=float32), 'training/total_loss': Array(0.16328424, dtype=float32), 'training/v_loss': Array(0.13920254, dtype=float32), 'eval/episode_distance_from_origin': Array(5939.779, dtype=float32), 'eval/episode_distance_reward': Array(23.62608, dtype=float32), 'eval/episode_forward_reward': Array(3937.66, dtype=float32), 'eval/episode_reward': Array(3945.4644, dtype=float32), 'eval/episode_reward_alive': Array(374.5664, dtype=float32), 'eval/episode_reward_linvel': Array(3937.66, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.3875, dtype=float32), 'eval/episode_x_position': Array(5882.6167, dtype=float32), 'eval/episode_x_velocity': Array(787.53186, dtype=float32), 'eval/episode_y_position': Array(-312.29205, dtype=float32), 'eval/episode_y_velocity': Array(-188.74008, dtype=float32), 'eval/episode_distance_from_origin_std': Array(403.1677, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6168976, dtype=float32), 'eval/episode_forward_reward_std': Array(769.4773, dtype=float32), 'eval/episode_reward_std': Array(760.98206, dtype=float32), 'eval/episode_reward_alive_std': Array(57.196323, dtype=float32), 'eval/episode_reward_linvel_std': Array(769.4773, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.55453, dtype=float32), 'eval/episode_x_position_std': Array(402.84006, dtype=float32), 'eval/episode_x_velocity_std': Array(153.89532, dtype=float32), 'eval/episode_y_position_std': Array(263.42422, dtype=float32), 'eval/episode_y_velocity_std': Array(82.18147, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5111608505249, 'eval/sps': 937.6522710854072, 'num_steps': 33996800}
{'eval/walltime': 56957.087446689606, 'training/sps': 2952.7455679518725, 'training/walltime': 11594.802256584167, 'training/entropy_loss': Array(0.01360939, dtype=float32), 'training/policy_loss': Array(0.12409414, dtype=float32), 'training/total_loss': Array(0.25490075, dtype=float32), 'training/v_loss': Array(0.11719723, dtype=float32), 'eval/episode_distance_from_origin': Array(5691.8687, dtype=float32), 'eval/episode_distance_reward': Array(20.696968, dtype=float32), 'eval/episode_forward_reward': Array(3449.4768, dtype=float32), 'eval/episode_reward': Array(3453.0884, dtype=float32), 'eval/episode_reward_alive': Array(394.34375, dtype=float32), 'eval/episode_reward_linvel': Array(3449.4768, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.42914, dtype=float32), 'eval/episode_x_position': Array(5639.0186, dtype=float32), 'eval/episode_x_velocity': Array(689.89526, dtype=float32), 'eval/episode_y_position': Array(-217.07849, dtype=float32), 'eval/episode_y_velocity': Array(-154.60654, dtype=float32), 'eval/episode_distance_from_origin_std': Array(573.78265, dtype=float32), 'eval/episode_distance_reward_std': Array(6.417063, dtype=float32), 'eval/episode_forward_reward_std': Array(1069.5032, dtype=float32), 'eval/episode_reward_std': Array(1054.4868, dtype=float32), 'eval/episode_reward_alive_std': Array(51.425983, dtype=float32), 'eval/episode_reward_linvel_std': Array(1069.5032, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.622028, dtype=float32), 'eval/episode_x_position_std': Array(568.7209, dtype=float32), 'eval/episode_x_velocity_std': Array(213.90057, dtype=float32), 'eval/episode_y_position_std': Array(285.52, dtype=float32), 'eval/episode_y_velocity_std': Array(103.83069, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4452359676361, 'eval/sps': 938.1053071751127, 'num_steps': 34078720}
{'eval/walltime': 57093.5982735157, 'training/sps': 2960.024102153932, 'training/walltime': 11622.47770690918, 'training/entropy_loss': Array(0.0147225, dtype=float32), 'training/policy_loss': Array(0.01417429, dtype=float32), 'training/total_loss': Array(0.14743271, dtype=float32), 'training/v_loss': Array(0.11853591, dtype=float32), 'eval/episode_distance_from_origin': Array(5815.415, dtype=float32), 'eval/episode_distance_reward': Array(22.293339, dtype=float32), 'eval/episode_forward_reward': Array(3715.5369, dtype=float32), 'eval/episode_reward': Array(3714.1472, dtype=float32), 'eval/episode_reward_alive': Array(384.16797, dtype=float32), 'eval/episode_reward_linvel': Array(3715.5369, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.8509, dtype=float32), 'eval/episode_x_position': Array(5760.4546, dtype=float32), 'eval/episode_x_velocity': Array(743.1073, dtype=float32), 'eval/episode_y_position': Array(-252.97269, dtype=float32), 'eval/episode_y_velocity': Array(-173.99654, dtype=float32), 'eval/episode_distance_from_origin_std': Array(525.7051, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6727314, dtype=float32), 'eval/episode_forward_reward_std': Array(945.44885, dtype=float32), 'eval/episode_reward_std': Array(935.97943, dtype=float32), 'eval/episode_reward_alive_std': Array(50.426044, dtype=float32), 'eval/episode_reward_linvel_std': Array(945.44885, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.263893, dtype=float32), 'eval/episode_x_position_std': Array(521.6344, dtype=float32), 'eval/episode_x_velocity_std': Array(189.08969, dtype=float32), 'eval/episode_y_position_std': Array(283.48602, dtype=float32), 'eval/episode_y_velocity_std': Array(95.391365, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51082682609558, 'eval/sps': 937.6545653998731, 'num_steps': 34160640}
{'eval/walltime': 57230.054261446, 'training/sps': 2950.5229908803412, 'training/walltime': 11650.242276191711, 'training/entropy_loss': Array(0.01436177, dtype=float32), 'training/policy_loss': Array(0.00409682, dtype=float32), 'training/total_loss': Array(0.1493647, dtype=float32), 'training/v_loss': Array(0.1309061, dtype=float32), 'eval/episode_distance_from_origin': Array(5762.83, dtype=float32), 'eval/episode_distance_reward': Array(21.21592, dtype=float32), 'eval/episode_forward_reward': Array(3535.969, dtype=float32), 'eval/episode_reward': Array(3547.5488, dtype=float32), 'eval/episode_reward_alive': Array(397.51562, dtype=float32), 'eval/episode_reward_linvel': Array(3535.969, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.15125, dtype=float32), 'eval/episode_x_position': Array(5710.755, dtype=float32), 'eval/episode_x_velocity': Array(707.19385, dtype=float32), 'eval/episode_y_position': Array(-228.83571, dtype=float32), 'eval/episode_y_velocity': Array(-161.55225, dtype=float32), 'eval/episode_distance_from_origin_std': Array(494.75626, dtype=float32), 'eval/episode_distance_reward_std': Array(5.759898, dtype=float32), 'eval/episode_forward_reward_std': Array(959.9755, dtype=float32), 'eval/episode_reward_std': Array(946.61847, dtype=float32), 'eval/episode_reward_alive_std': Array(45.82, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.9755, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.761786, dtype=float32), 'eval/episode_x_position_std': Array(489.02896, dtype=float32), 'eval/episode_x_velocity_std': Array(191.99501, dtype=float32), 'eval/episode_y_position_std': Array(264.8231, dtype=float32), 'eval/episode_y_velocity_std': Array(98.68084, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45598793029785, 'eval/sps': 938.0313897649021, 'num_steps': 34242560}
{'eval/walltime': 57366.56637144089, 'training/sps': 2959.6030800951266, 'training/walltime': 11677.92166352272, 'training/entropy_loss': Array(0.01239306, dtype=float32), 'training/policy_loss': Array(0.00243564, dtype=float32), 'training/total_loss': Array(0.11177219, dtype=float32), 'training/v_loss': Array(0.09694349, dtype=float32), 'eval/episode_distance_from_origin': Array(5921.5757, dtype=float32), 'eval/episode_distance_reward': Array(22.803967, dtype=float32), 'eval/episode_forward_reward': Array(3800.641, dtype=float32), 'eval/episode_reward': Array(3805.1277, dtype=float32), 'eval/episode_reward_alive': Array(387.44922, dtype=float32), 'eval/episode_reward_linvel': Array(3800.641, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.7663, dtype=float32), 'eval/episode_x_position': Array(5866.95, dtype=float32), 'eval/episode_x_velocity': Array(760.1282, dtype=float32), 'eval/episode_y_position': Array(-296.10278, dtype=float32), 'eval/episode_y_velocity': Array(-176.27826, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.3632, dtype=float32), 'eval/episode_distance_reward_std': Array(5.886185, dtype=float32), 'eval/episode_forward_reward_std': Array(981.02277, dtype=float32), 'eval/episode_reward_std': Array(971.1896, dtype=float32), 'eval/episode_reward_alive_std': Array(53.087704, dtype=float32), 'eval/episode_reward_linvel_std': Array(981.02277, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.745533, dtype=float32), 'eval/episode_x_position_std': Array(478.78522, dtype=float32), 'eval/episode_x_velocity_std': Array(196.20467, dtype=float32), 'eval/episode_y_position_std': Array(237.97687, dtype=float32), 'eval/episode_y_velocity_std': Array(90.84529, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5121099948883, 'eval/sps': 937.645751756331, 'num_steps': 34324480}
{'eval/walltime': 57502.99839305878, 'training/sps': 2963.2075541325266, 'training/walltime': 11705.567381381989, 'training/entropy_loss': Array(0.01395259, dtype=float32), 'training/policy_loss': Array(0.00413939, dtype=float32), 'training/total_loss': Array(0.11894848, dtype=float32), 'training/v_loss': Array(0.10085651, dtype=float32), 'eval/episode_distance_from_origin': Array(5878.2656, dtype=float32), 'eval/episode_distance_reward': Array(22.784527, dtype=float32), 'eval/episode_forward_reward': Array(3797.4, dtype=float32), 'eval/episode_reward': Array(3802.384, dtype=float32), 'eval/episode_reward_alive': Array(390.71875, dtype=float32), 'eval/episode_reward_linvel': Array(3797.4, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.5197, dtype=float32), 'eval/episode_x_position': Array(5824.788, dtype=float32), 'eval/episode_x_velocity': Array(759.4801, dtype=float32), 'eval/episode_y_position': Array(-262.85388, dtype=float32), 'eval/episode_y_velocity': Array(-171.52664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.9696, dtype=float32), 'eval/episode_distance_reward_std': Array(6.105083, dtype=float32), 'eval/episode_forward_reward_std': Array(1017.50635, dtype=float32), 'eval/episode_reward_std': Array(1006.5855, dtype=float32), 'eval/episode_reward_alive_std': Array(51.37419, dtype=float32), 'eval/episode_reward_linvel_std': Array(1017.50635, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.94764, dtype=float32), 'eval/episode_x_position_std': Array(503.79117, dtype=float32), 'eval/episode_x_velocity_std': Array(203.50134, dtype=float32), 'eval/episode_y_position_std': Array(254.97144, dtype=float32), 'eval/episode_y_velocity_std': Array(92.60493, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4320216178894, 'eval/sps': 938.196168920627, 'num_steps': 34406400}
{'eval/walltime': 57639.50946140289, 'training/sps': 2961.2370232667267, 'training/walltime': 11733.231495857239, 'training/entropy_loss': Array(0.01857593, dtype=float32), 'training/policy_loss': Array(0.01086502, dtype=float32), 'training/total_loss': Array(0.18109244, dtype=float32), 'training/v_loss': Array(0.15165149, dtype=float32), 'eval/episode_distance_from_origin': Array(5918.0635, dtype=float32), 'eval/episode_distance_reward': Array(23.32827, dtype=float32), 'eval/episode_forward_reward': Array(3888.0237, dtype=float32), 'eval/episode_reward': Array(3896.373, dtype=float32), 'eval/episode_reward_alive': Array(392.42578, dtype=float32), 'eval/episode_reward_linvel': Array(3888.0237, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.40472, dtype=float32), 'eval/episode_x_position': Array(5860.2246, dtype=float32), 'eval/episode_x_velocity': Array(777.6048, dtype=float32), 'eval/episode_y_position': Array(-270.71262, dtype=float32), 'eval/episode_y_velocity': Array(-183.31659, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.2571, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0515337, dtype=float32), 'eval/episode_forward_reward_std': Array(1008.581, dtype=float32), 'eval/episode_reward_std': Array(1005.90015, dtype=float32), 'eval/episode_reward_alive_std': Array(47.32637, dtype=float32), 'eval/episode_reward_linvel_std': Array(1008.581, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.569132, dtype=float32), 'eval/episode_x_position_std': Array(530.4995, dtype=float32), 'eval/episode_x_velocity_std': Array(201.71616, dtype=float32), 'eval/episode_y_position_std': Array(269.43613, dtype=float32), 'eval/episode_y_velocity_std': Array(90.90719, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5110683441162, 'eval/sps': 937.6529064832929, 'num_steps': 34488320}
{'eval/walltime': 57775.93997812271, 'training/sps': 2954.203941858038, 'training/walltime': 11760.961470365524, 'training/entropy_loss': Array(0.01477497, dtype=float32), 'training/policy_loss': Array(0.01733037, dtype=float32), 'training/total_loss': Array(0.11753307, dtype=float32), 'training/v_loss': Array(0.08542772, dtype=float32), 'eval/episode_distance_from_origin': Array(5865.0195, dtype=float32), 'eval/episode_distance_reward': Array(22.716085, dtype=float32), 'eval/episode_forward_reward': Array(3785.994, dtype=float32), 'eval/episode_reward': Array(3796.766, dtype=float32), 'eval/episode_reward_alive': Array(393.65625, dtype=float32), 'eval/episode_reward_linvel': Array(3785.994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.6001, dtype=float32), 'eval/episode_x_position': Array(5809.3613, dtype=float32), 'eval/episode_x_velocity': Array(757.1987, dtype=float32), 'eval/episode_y_position': Array(-251.6485, dtype=float32), 'eval/episode_y_velocity': Array(-179.54312, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.13422, dtype=float32), 'eval/episode_distance_reward_std': Array(5.557594, dtype=float32), 'eval/episode_forward_reward_std': Array(926.25806, dtype=float32), 'eval/episode_reward_std': Array(923.05286, dtype=float32), 'eval/episode_reward_alive_std': Array(48.748745, dtype=float32), 'eval/episode_reward_linvel_std': Array(926.25806, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.422699, dtype=float32), 'eval/episode_x_position_std': Array(467.2454, dtype=float32), 'eval/episode_x_velocity_std': Array(185.25166, dtype=float32), 'eval/episode_y_position_std': Array(265.84003, dtype=float32), 'eval/episode_y_velocity_std': Array(96.869286, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43051671981812, 'eval/sps': 938.2065177021096, 'num_steps': 34570240}
{'eval/walltime': 57912.44764328003, 'training/sps': 2956.9321674337552, 'training/walltime': 11788.66585969925, 'training/entropy_loss': Array(0.0154353, dtype=float32), 'training/policy_loss': Array(0.00481451, dtype=float32), 'training/total_loss': Array(0.11603492, dtype=float32), 'training/v_loss': Array(0.09578511, dtype=float32), 'eval/episode_distance_from_origin': Array(5912.474, dtype=float32), 'eval/episode_distance_reward': Array(23.190136, dtype=float32), 'eval/episode_forward_reward': Array(3865.002, dtype=float32), 'eval/episode_reward': Array(3879.3125, dtype=float32), 'eval/episode_reward_alive': Array(398.71094, dtype=float32), 'eval/episode_reward_linvel': Array(3865.002, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.59076, dtype=float32), 'eval/episode_x_position': Array(5858.4385, dtype=float32), 'eval/episode_x_velocity': Array(773.0005, dtype=float32), 'eval/episode_y_position': Array(-199.46442, dtype=float32), 'eval/episode_y_velocity': Array(-159.25198, dtype=float32), 'eval/episode_distance_from_origin_std': Array(570.21027, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5980873, dtype=float32), 'eval/episode_forward_reward_std': Array(1099.6724, dtype=float32), 'eval/episode_reward_std': Array(1091.234, dtype=float32), 'eval/episode_reward_alive_std': Array(45.790993, dtype=float32), 'eval/episode_reward_linvel_std': Array(1099.6724, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.727045, dtype=float32), 'eval/episode_x_position_std': Array(568.41223, dtype=float32), 'eval/episode_x_velocity_std': Array(219.93465, dtype=float32), 'eval/episode_y_position_std': Array(303.30682, dtype=float32), 'eval/episode_y_velocity_std': Array(102.69596, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50766515731812, 'eval/sps': 937.6762825185424, 'num_steps': 34652160}
{'eval/walltime': 58048.87054228783, 'training/sps': 2950.3572228879707, 'training/walltime': 11816.431988954544, 'training/entropy_loss': Array(0.01480205, dtype=float32), 'training/policy_loss': Array(0.00336324, dtype=float32), 'training/total_loss': Array(0.110342, dtype=float32), 'training/v_loss': Array(0.09217672, dtype=float32), 'eval/episode_distance_from_origin': Array(6045.3223, dtype=float32), 'eval/episode_distance_reward': Array(24.839106, dtype=float32), 'eval/episode_forward_reward': Array(4139.8286, dtype=float32), 'eval/episode_reward': Array(4147.2925, dtype=float32), 'eval/episode_reward_alive': Array(389.92188, dtype=float32), 'eval/episode_reward_linvel': Array(4139.8286, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.29718, dtype=float32), 'eval/episode_x_position': Array(5989.5464, dtype=float32), 'eval/episode_x_velocity': Array(827.96564, dtype=float32), 'eval/episode_y_position': Array(-255.52475, dtype=float32), 'eval/episode_y_velocity': Array(-176.49689, dtype=float32), 'eval/episode_distance_from_origin_std': Array(565.80914, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4262147, dtype=float32), 'eval/episode_forward_reward_std': Array(1071.028, dtype=float32), 'eval/episode_reward_std': Array(1064.3048, dtype=float32), 'eval/episode_reward_alive_std': Array(51.733593, dtype=float32), 'eval/episode_reward_linvel_std': Array(1071.028, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.242823, dtype=float32), 'eval/episode_x_position_std': Array(563.2343, dtype=float32), 'eval/episode_x_velocity_std': Array(214.20558, dtype=float32), 'eval/episode_y_position_std': Array(299.42722, dtype=float32), 'eval/episode_y_velocity_std': Array(97.40682, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42289900779724, 'eval/sps': 938.2589061729598, 'num_steps': 34734080}
{'eval/walltime': 58185.43022155762, 'training/sps': 2958.354002693345, 'training/walltime': 11844.123063087463, 'training/entropy_loss': Array(0.01509129, dtype=float32), 'training/policy_loss': Array(0.00189885, dtype=float32), 'training/total_loss': Array(0.11636254, dtype=float32), 'training/v_loss': Array(0.09937239, dtype=float32), 'eval/episode_distance_from_origin': Array(5844.832, dtype=float32), 'eval/episode_distance_reward': Array(22.813635, dtype=float32), 'eval/episode_forward_reward': Array(3802.252, dtype=float32), 'eval/episode_reward': Array(3810.775, dtype=float32), 'eval/episode_reward_alive': Array(393.375, dtype=float32), 'eval/episode_reward_linvel': Array(3802.252, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.66577, dtype=float32), 'eval/episode_x_position': Array(5789.8984, dtype=float32), 'eval/episode_x_velocity': Array(760.45044, dtype=float32), 'eval/episode_y_position': Array(-262.40234, dtype=float32), 'eval/episode_y_velocity': Array(-179.8646, dtype=float32), 'eval/episode_distance_from_origin_std': Array(580.249, dtype=float32), 'eval/episode_distance_reward_std': Array(6.424984, dtype=float32), 'eval/episode_forward_reward_std': Array(1070.8231, dtype=float32), 'eval/episode_reward_std': Array(1065.059, dtype=float32), 'eval/episode_reward_alive_std': Array(51.312843, dtype=float32), 'eval/episode_reward_linvel_std': Array(1070.8231, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.594736, dtype=float32), 'eval/episode_x_position_std': Array(576.9032, dtype=float32), 'eval/episode_x_velocity_std': Array(214.16461, dtype=float32), 'eval/episode_y_position_std': Array(264.68878, dtype=float32), 'eval/episode_y_velocity_std': Array(97.25047, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55967926979065, 'eval/sps': 937.3191317117848, 'num_steps': 34816000}
{'eval/walltime': 58321.936499118805, 'training/sps': 2952.072782241872, 'training/walltime': 11871.873056411743, 'training/entropy_loss': Array(0.0133833, dtype=float32), 'training/policy_loss': Array(0.00735109, dtype=float32), 'training/total_loss': Array(0.1106566, dtype=float32), 'training/v_loss': Array(0.08992222, dtype=float32), 'eval/episode_distance_from_origin': Array(5920.627, dtype=float32), 'eval/episode_distance_reward': Array(23.01656, dtype=float32), 'eval/episode_forward_reward': Array(3836.0728, dtype=float32), 'eval/episode_reward': Array(3847.3174, dtype=float32), 'eval/episode_reward_alive': Array(395.73047, dtype=float32), 'eval/episode_reward_linvel': Array(3836.0728, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.5025, dtype=float32), 'eval/episode_x_position': Array(5866.6245, dtype=float32), 'eval/episode_x_velocity': Array(767.2145, dtype=float32), 'eval/episode_y_position': Array(-268.0354, dtype=float32), 'eval/episode_y_velocity': Array(-170.04665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(584.48645, dtype=float32), 'eval/episode_distance_reward_std': Array(6.388731, dtype=float32), 'eval/episode_forward_reward_std': Array(1064.7802, dtype=float32), 'eval/episode_reward_std': Array(1058.6124, dtype=float32), 'eval/episode_reward_alive_std': Array(52.505985, dtype=float32), 'eval/episode_reward_linvel_std': Array(1064.7802, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.026468, dtype=float32), 'eval/episode_x_position_std': Array(580.8713, dtype=float32), 'eval/episode_x_velocity_std': Array(212.95604, dtype=float32), 'eval/episode_y_position_std': Array(280.57825, dtype=float32), 'eval/episode_y_velocity_std': Array(95.76974, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50627756118774, 'eval/sps': 937.6858140654017, 'num_steps': 34897920}
{'eval/walltime': 58458.48251461983, 'training/sps': 2961.853022458689, 'training/walltime': 11899.531417369843, 'training/entropy_loss': Array(0.01790402, dtype=float32), 'training/policy_loss': Array(0.01774304, dtype=float32), 'training/total_loss': Array(0.17265563, dtype=float32), 'training/v_loss': Array(0.13700856, dtype=float32), 'eval/episode_distance_from_origin': Array(5979.6367, dtype=float32), 'eval/episode_distance_reward': Array(23.29544, dtype=float32), 'eval/episode_forward_reward': Array(3882.5522, dtype=float32), 'eval/episode_reward': Array(3888.83, dtype=float32), 'eval/episode_reward_alive': Array(396.27734, dtype=float32), 'eval/episode_reward_linvel': Array(3882.5522, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.2952, dtype=float32), 'eval/episode_x_position': Array(5925.3184, dtype=float32), 'eval/episode_x_velocity': Array(776.51056, dtype=float32), 'eval/episode_y_position': Array(-236.36064, dtype=float32), 'eval/episode_y_velocity': Array(-161.05025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(540.96893, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0160103, dtype=float32), 'eval/episode_forward_reward_std': Array(1002.66016, dtype=float32), 'eval/episode_reward_std': Array(998.9701, dtype=float32), 'eval/episode_reward_alive_std': Array(46.51457, dtype=float32), 'eval/episode_reward_linvel_std': Array(1002.66016, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.64062, dtype=float32), 'eval/episode_x_position_std': Array(537.9955, dtype=float32), 'eval/episode_x_velocity_std': Array(200.53203, dtype=float32), 'eval/episode_y_position_std': Array(304.66623, dtype=float32), 'eval/episode_y_velocity_std': Array(101.940994, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54601550102234, 'eval/sps': 937.4129265532589, 'num_steps': 34979840}
{'eval/walltime': 58595.00688648224, 'training/sps': 2951.740789757663, 'training/walltime': 11927.284531831741, 'training/entropy_loss': Array(0.01383967, dtype=float32), 'training/policy_loss': Array(0.00785659, dtype=float32), 'training/total_loss': Array(0.09907682, dtype=float32), 'training/v_loss': Array(0.07738058, dtype=float32), 'eval/episode_distance_from_origin': Array(5993.84, dtype=float32), 'eval/episode_distance_reward': Array(23.896128, dtype=float32), 'eval/episode_forward_reward': Array(3982.6665, dtype=float32), 'eval/episode_reward': Array(3990.741, dtype=float32), 'eval/episode_reward_alive': Array(394.1914, dtype=float32), 'eval/episode_reward_linvel': Array(3982.6665, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.0134, dtype=float32), 'eval/episode_x_position': Array(5940.715, dtype=float32), 'eval/episode_x_velocity': Array(796.5334, dtype=float32), 'eval/episode_y_position': Array(-250.40414, dtype=float32), 'eval/episode_y_velocity': Array(-170.97491, dtype=float32), 'eval/episode_distance_from_origin_std': Array(540.4474, dtype=float32), 'eval/episode_distance_reward_std': Array(6.232529, dtype=float32), 'eval/episode_forward_reward_std': Array(1038.7457, dtype=float32), 'eval/episode_reward_std': Array(1034.3246, dtype=float32), 'eval/episode_reward_alive_std': Array(48.154297, dtype=float32), 'eval/episode_reward_linvel_std': Array(1038.7457, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.371433, dtype=float32), 'eval/episode_x_position_std': Array(536.62213, dtype=float32), 'eval/episode_x_velocity_std': Array(207.74919, dtype=float32), 'eval/episode_y_position_std': Array(259.02496, dtype=float32), 'eval/episode_y_velocity_std': Array(96.265816, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5243718624115, 'eval/sps': 937.5615375765851, 'num_steps': 35061760}
{'eval/walltime': 58731.5733628273, 'training/sps': 2952.696925309046, 'training/walltime': 11955.02865934372, 'training/entropy_loss': Array(0.01466923, dtype=float32), 'training/policy_loss': Array(0.00214302, dtype=float32), 'training/total_loss': Array(0.11811149, dtype=float32), 'training/v_loss': Array(0.10129924, dtype=float32), 'eval/episode_distance_from_origin': Array(5973.3857, dtype=float32), 'eval/episode_distance_reward': Array(23.995266, dtype=float32), 'eval/episode_forward_reward': Array(3999.1897, dtype=float32), 'eval/episode_reward': Array(4005.7725, dtype=float32), 'eval/episode_reward_alive': Array(394.1211, dtype=float32), 'eval/episode_reward_linvel': Array(3999.1897, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.53333, dtype=float32), 'eval/episode_x_position': Array(5921.6836, dtype=float32), 'eval/episode_x_velocity': Array(799.8379, dtype=float32), 'eval/episode_y_position': Array(-206.66547, dtype=float32), 'eval/episode_y_velocity': Array(-163.96887, dtype=float32), 'eval/episode_distance_from_origin_std': Array(577.3721, dtype=float32), 'eval/episode_distance_reward_std': Array(6.8727884, dtype=float32), 'eval/episode_forward_reward_std': Array(1145.4556, dtype=float32), 'eval/episode_reward_std': Array(1138.6816, dtype=float32), 'eval/episode_reward_alive_std': Array(46.39764, dtype=float32), 'eval/episode_reward_linvel_std': Array(1145.4556, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.88086, dtype=float32), 'eval/episode_x_position_std': Array(574.18335, dtype=float32), 'eval/episode_x_velocity_std': Array(229.09114, dtype=float32), 'eval/episode_y_position_std': Array(281.10724, dtype=float32), 'eval/episode_y_velocity_std': Array(99.964325, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56647634506226, 'eval/sps': 937.272480228476, 'num_steps': 35143680}
{'eval/walltime': 58868.0999147892, 'training/sps': 2963.417400329363, 'training/walltime': 11982.672419548035, 'training/entropy_loss': Array(0.01500192, dtype=float32), 'training/policy_loss': Array(0.0071603, dtype=float32), 'training/total_loss': Array(0.1466536, dtype=float32), 'training/v_loss': Array(0.12449138, dtype=float32), 'eval/episode_distance_from_origin': Array(6064.1562, dtype=float32), 'eval/episode_distance_reward': Array(25.216774, dtype=float32), 'eval/episode_forward_reward': Array(4202.7725, dtype=float32), 'eval/episode_reward': Array(4217.0195, dtype=float32), 'eval/episode_reward_alive': Array(394.92578, dtype=float32), 'eval/episode_reward_linvel': Array(4202.7725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.89612, dtype=float32), 'eval/episode_x_position': Array(6010.6685, dtype=float32), 'eval/episode_x_velocity': Array(840.5546, dtype=float32), 'eval/episode_y_position': Array(-247.94257, dtype=float32), 'eval/episode_y_velocity': Array(-185.71024, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.20502, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0518875, dtype=float32), 'eval/episode_forward_reward_std': Array(1008.64026, dtype=float32), 'eval/episode_reward_std': Array(1007.7441, dtype=float32), 'eval/episode_reward_alive_std': Array(40.659702, dtype=float32), 'eval/episode_reward_linvel_std': Array(1008.64026, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.171545, dtype=float32), 'eval/episode_x_position_std': Array(504.94785, dtype=float32), 'eval/episode_x_velocity_std': Array(201.72806, dtype=float32), 'eval/episode_y_position_std': Array(234.69226, dtype=float32), 'eval/episode_y_velocity_std': Array(82.40785, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5265519618988, 'eval/sps': 937.5465662951896, 'num_steps': 35225600}
{'eval/walltime': 59004.69183969498, 'training/sps': 2971.6810364596645, 'training/walltime': 12010.23930811882, 'training/entropy_loss': Array(0.0146825, dtype=float32), 'training/policy_loss': Array(0.00250535, dtype=float32), 'training/total_loss': Array(0.14178573, dtype=float32), 'training/v_loss': Array(0.12459788, dtype=float32), 'eval/episode_distance_from_origin': Array(6120.163, dtype=float32), 'eval/episode_distance_reward': Array(25.524536, dtype=float32), 'eval/episode_forward_reward': Array(4254.0654, dtype=float32), 'eval/episode_reward': Array(4261.2007, dtype=float32), 'eval/episode_reward_alive': Array(386.02344, dtype=float32), 'eval/episode_reward_linvel': Array(4254.0654, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.41315, dtype=float32), 'eval/episode_x_position': Array(6064.455, dtype=float32), 'eval/episode_x_velocity': Array(850.8131, dtype=float32), 'eval/episode_y_position': Array(-268.86755, dtype=float32), 'eval/episode_y_velocity': Array(-192.47928, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.7494, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0558443, dtype=float32), 'eval/episode_forward_reward_std': Array(842.6339, dtype=float32), 'eval/episode_reward_std': Array(842.57153, dtype=float32), 'eval/episode_reward_alive_std': Array(44.69737, dtype=float32), 'eval/episode_reward_linvel_std': Array(842.6339, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.802652, dtype=float32), 'eval/episode_x_position_std': Array(437.55118, dtype=float32), 'eval/episode_x_velocity_std': Array(168.52686, dtype=float32), 'eval/episode_y_position_std': Array(279.14465, dtype=float32), 'eval/episode_y_velocity_std': Array(94.010124, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59192490577698, 'eval/sps': 937.0978561748522, 'num_steps': 35307520}
{'eval/walltime': 59141.22047138214, 'training/sps': 2968.5135224682504, 'training/walltime': 12037.835611581802, 'training/entropy_loss': Array(0.01133668, dtype=float32), 'training/policy_loss': Array(0.00745654, dtype=float32), 'training/total_loss': Array(0.09375563, dtype=float32), 'training/v_loss': Array(0.07496241, dtype=float32), 'eval/episode_distance_from_origin': Array(6167.872, dtype=float32), 'eval/episode_distance_reward': Array(26.148115, dtype=float32), 'eval/episode_forward_reward': Array(4357.9956, dtype=float32), 'eval/episode_reward': Array(4360.8, dtype=float32), 'eval/episode_reward_alive': Array(382.51172, dtype=float32), 'eval/episode_reward_linvel': Array(4357.9956, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.85486, dtype=float32), 'eval/episode_x_position': Array(6114.4883, dtype=float32), 'eval/episode_x_velocity': Array(871.59906, dtype=float32), 'eval/episode_y_position': Array(-262.87952, dtype=float32), 'eval/episode_y_velocity': Array(-189.47627, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.16623, dtype=float32), 'eval/episode_distance_reward_std': Array(5.703026, dtype=float32), 'eval/episode_forward_reward_std': Array(950.49677, dtype=float32), 'eval/episode_reward_std': Array(956.91034, dtype=float32), 'eval/episode_reward_alive_std': Array(41.415363, dtype=float32), 'eval/episode_reward_linvel_std': Array(950.49677, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.7457, dtype=float32), 'eval/episode_x_position_std': Array(473.44806, dtype=float32), 'eval/episode_x_velocity_std': Array(190.09932, dtype=float32), 'eval/episode_y_position_std': Array(251.17575, dtype=float32), 'eval/episode_y_velocity_std': Array(88.35309, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5286316871643, 'eval/sps': 937.5322847539669, 'num_steps': 35389440}
{'eval/walltime': 59277.78868341446, 'training/sps': 2975.0924994125967, 'training/walltime': 12065.370889902115, 'training/entropy_loss': Array(0.01708437, dtype=float32), 'training/policy_loss': Array(0.0056691, dtype=float32), 'training/total_loss': Array(0.12588134, dtype=float32), 'training/v_loss': Array(0.10312788, dtype=float32), 'eval/episode_distance_from_origin': Array(6223.066, dtype=float32), 'eval/episode_distance_reward': Array(26.759491, dtype=float32), 'eval/episode_forward_reward': Array(4459.89, dtype=float32), 'eval/episode_reward': Array(4465.882, dtype=float32), 'eval/episode_reward_alive': Array(380.02734, dtype=float32), 'eval/episode_reward_linvel': Array(4459.89, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.79477, dtype=float32), 'eval/episode_x_position': Array(6169.998, dtype=float32), 'eval/episode_x_velocity': Array(891.978, dtype=float32), 'eval/episode_y_position': Array(-249.98999, dtype=float32), 'eval/episode_y_velocity': Array(-187.07405, dtype=float32), 'eval/episode_distance_from_origin_std': Array(486.22092, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5079966, dtype=float32), 'eval/episode_forward_reward_std': Array(917.9924, dtype=float32), 'eval/episode_reward_std': Array(917.9252, dtype=float32), 'eval/episode_reward_alive_std': Array(45.17195, dtype=float32), 'eval/episode_reward_linvel_std': Array(917.9924, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.408554, dtype=float32), 'eval/episode_x_position_std': Array(487.01953, dtype=float32), 'eval/episode_x_velocity_std': Array(183.59848, dtype=float32), 'eval/episode_y_position_std': Array(274.72745, dtype=float32), 'eval/episode_y_velocity_std': Array(91.75411, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56821203231812, 'eval/sps': 937.2605681453126, 'num_steps': 35471360}
{'eval/walltime': 59414.21425175667, 'training/sps': 2964.7656378492043, 'training/walltime': 12093.00207901001, 'training/entropy_loss': Array(0.01580582, dtype=float32), 'training/policy_loss': Array(0.00551971, dtype=float32), 'training/total_loss': Array(0.13203561, dtype=float32), 'training/v_loss': Array(0.11071008, dtype=float32), 'eval/episode_distance_from_origin': Array(6161.1973, dtype=float32), 'eval/episode_distance_reward': Array(26.108582, dtype=float32), 'eval/episode_forward_reward': Array(4351.4062, dtype=float32), 'eval/episode_reward': Array(4358.6816, dtype=float32), 'eval/episode_reward_alive': Array(382.16797, dtype=float32), 'eval/episode_reward_linvel': Array(4351.4062, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.00143, dtype=float32), 'eval/episode_x_position': Array(6108.2324, dtype=float32), 'eval/episode_x_velocity': Array(870.28125, dtype=float32), 'eval/episode_y_position': Array(-245.22008, dtype=float32), 'eval/episode_y_velocity': Array(-189.74338, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.97476, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3196244, dtype=float32), 'eval/episode_forward_reward_std': Array(886.5979, dtype=float32), 'eval/episode_reward_std': Array(891.1956, dtype=float32), 'eval/episode_reward_alive_std': Array(41.138786, dtype=float32), 'eval/episode_reward_linvel_std': Array(886.5979, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.863167, dtype=float32), 'eval/episode_x_position_std': Array(468.7523, dtype=float32), 'eval/episode_x_velocity_std': Array(177.31961, dtype=float32), 'eval/episode_y_position_std': Array(252.6279, dtype=float32), 'eval/episode_y_velocity_std': Array(82.54101, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42556834220886, 'eval/sps': 938.2405479809017, 'num_steps': 35553280}
{'eval/walltime': 59550.74870920181, 'training/sps': 2962.588973449586, 'training/walltime': 12120.653569221497, 'training/entropy_loss': Array(0.0144853, dtype=float32), 'training/policy_loss': Array(0.00623228, dtype=float32), 'training/total_loss': Array(0.13102679, dtype=float32), 'training/v_loss': Array(0.11030921, dtype=float32), 'eval/episode_distance_from_origin': Array(6177.1626, dtype=float32), 'eval/episode_distance_reward': Array(26.302647, dtype=float32), 'eval/episode_forward_reward': Array(4383.7505, dtype=float32), 'eval/episode_reward': Array(4392.6377, dtype=float32), 'eval/episode_reward_alive': Array(379.34375, dtype=float32), 'eval/episode_reward_linvel': Array(4383.7505, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.75922, dtype=float32), 'eval/episode_x_position': Array(6124.6514, dtype=float32), 'eval/episode_x_velocity': Array(876.7502, dtype=float32), 'eval/episode_y_position': Array(-228.60416, dtype=float32), 'eval/episode_y_velocity': Array(-175.87608, dtype=float32), 'eval/episode_distance_from_origin_std': Array(475.54364, dtype=float32), 'eval/episode_distance_reward_std': Array(5.666627, dtype=float32), 'eval/episode_forward_reward_std': Array(944.4306, dtype=float32), 'eval/episode_reward_std': Array(940.51385, dtype=float32), 'eval/episode_reward_alive_std': Array(50.750374, dtype=float32), 'eval/episode_reward_linvel_std': Array(944.4306, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.111988, dtype=float32), 'eval/episode_x_position_std': Array(472.79852, dtype=float32), 'eval/episode_x_velocity_std': Array(188.88622, dtype=float32), 'eval/episode_y_position_std': Array(277.49286, dtype=float32), 'eval/episode_y_velocity_std': Array(94.055214, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53445744514465, 'eval/sps': 937.4922814002939, 'num_steps': 35635200}
{'eval/walltime': 59687.17686533928, 'training/sps': 2967.33517437329, 'training/walltime': 12148.260831356049, 'training/entropy_loss': Array(0.01449726, dtype=float32), 'training/policy_loss': Array(0.00355944, dtype=float32), 'training/total_loss': Array(0.14173843, dtype=float32), 'training/v_loss': Array(0.12368172, dtype=float32), 'eval/episode_distance_from_origin': Array(6173.962, dtype=float32), 'eval/episode_distance_reward': Array(25.850801, dtype=float32), 'eval/episode_forward_reward': Array(4308.4434, dtype=float32), 'eval/episode_reward': Array(4315.633, dtype=float32), 'eval/episode_reward_alive': Array(384.73438, dtype=float32), 'eval/episode_reward_linvel': Array(4308.4434, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.39545, dtype=float32), 'eval/episode_x_position': Array(6121.4287, dtype=float32), 'eval/episode_x_velocity': Array(861.68866, dtype=float32), 'eval/episode_y_position': Array(-213.90662, dtype=float32), 'eval/episode_y_velocity': Array(-171.81181, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.01776, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0666156, dtype=float32), 'eval/episode_forward_reward_std': Array(1011.0946, dtype=float32), 'eval/episode_reward_std': Array(1006.5772, dtype=float32), 'eval/episode_reward_alive_std': Array(47.052948, dtype=float32), 'eval/episode_reward_linvel_std': Array(1011.0946, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.088417, dtype=float32), 'eval/episode_x_position_std': Array(478.6318, dtype=float32), 'eval/episode_x_velocity_std': Array(202.219, dtype=float32), 'eval/episode_y_position_std': Array(290.94693, dtype=float32), 'eval/episode_y_velocity_std': Array(92.20407, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42815613746643, 'eval/sps': 938.2227512554364, 'num_steps': 35717120}
{'eval/walltime': 59823.83020544052, 'training/sps': 2967.8778560740516, 'training/walltime': 12175.863045454025, 'training/entropy_loss': Array(0.01443682, dtype=float32), 'training/policy_loss': Array(0.0176732, dtype=float32), 'training/total_loss': Array(0.1940454, dtype=float32), 'training/v_loss': Array(0.16193536, dtype=float32), 'eval/episode_distance_from_origin': Array(6211.685, dtype=float32), 'eval/episode_distance_reward': Array(26.316227, dtype=float32), 'eval/episode_forward_reward': Array(4386.0137, dtype=float32), 'eval/episode_reward': Array(4388.5205, dtype=float32), 'eval/episode_reward_alive': Array(376.82422, dtype=float32), 'eval/episode_reward_linvel': Array(4386.0137, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.63342, dtype=float32), 'eval/episode_x_position': Array(6159.7505, dtype=float32), 'eval/episode_x_velocity': Array(877.2027, dtype=float32), 'eval/episode_y_position': Array(-213.99579, dtype=float32), 'eval/episode_y_velocity': Array(-177.45807, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.22015, dtype=float32), 'eval/episode_distance_reward_std': Array(5.461882, dtype=float32), 'eval/episode_forward_reward_std': Array(910.30554, dtype=float32), 'eval/episode_reward_std': Array(907.2747, dtype=float32), 'eval/episode_reward_alive_std': Array(48.612534, dtype=float32), 'eval/episode_reward_linvel_std': Array(910.30554, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.731014, dtype=float32), 'eval/episode_x_position_std': Array(443.70648, dtype=float32), 'eval/episode_x_velocity_std': Array(182.06114, dtype=float32), 'eval/episode_y_position_std': Array(292.8406, dtype=float32), 'eval/episode_y_velocity_std': Array(91.15599, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65334010124207, 'eval/sps': 936.6767025611589, 'num_steps': 35799040}
{'eval/walltime': 59960.257088661194, 'training/sps': 2964.3573064384823, 'training/walltime': 12203.498040676117, 'training/entropy_loss': Array(0.01199225, dtype=float32), 'training/policy_loss': Array(0.00609988, dtype=float32), 'training/total_loss': Array(0.10903915, dtype=float32), 'training/v_loss': Array(0.09094702, dtype=float32), 'eval/episode_distance_from_origin': Array(6217.6055, dtype=float32), 'eval/episode_distance_reward': Array(26.596249, dtype=float32), 'eval/episode_forward_reward': Array(4432.6836, dtype=float32), 'eval/episode_reward': Array(4438.7627, dtype=float32), 'eval/episode_reward_alive': Array(377.73438, dtype=float32), 'eval/episode_reward_linvel': Array(4432.6836, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.25195, dtype=float32), 'eval/episode_x_position': Array(6166.385, dtype=float32), 'eval/episode_x_velocity': Array(886.5368, dtype=float32), 'eval/episode_y_position': Array(-246.11433, dtype=float32), 'eval/episode_y_velocity': Array(-183.93631, dtype=float32), 'eval/episode_distance_from_origin_std': Array(454.92548, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2943525, dtype=float32), 'eval/episode_forward_reward_std': Array(882.38525, dtype=float32), 'eval/episode_reward_std': Array(872.9709, dtype=float32), 'eval/episode_reward_alive_std': Array(48.7866, dtype=float32), 'eval/episode_reward_linvel_std': Array(882.38525, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.027304, dtype=float32), 'eval/episode_x_position_std': Array(456.30368, dtype=float32), 'eval/episode_x_velocity_std': Array(176.47697, dtype=float32), 'eval/episode_y_position_std': Array(231.77477, dtype=float32), 'eval/episode_y_velocity_std': Array(74.959526, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4268832206726, 'eval/sps': 938.2315052448864, 'num_steps': 35880960}
{'eval/walltime': 60096.85121846199, 'training/sps': 2969.685594416527, 'training/walltime': 12231.08345246315, 'training/entropy_loss': Array(0.01715933, dtype=float32), 'training/policy_loss': Array(0.00920169, dtype=float32), 'training/total_loss': Array(0.1172585, dtype=float32), 'training/v_loss': Array(0.09089749, dtype=float32), 'eval/episode_distance_from_origin': Array(6205.4414, dtype=float32), 'eval/episode_distance_reward': Array(27.271448, dtype=float32), 'eval/episode_forward_reward': Array(4545.216, dtype=float32), 'eval/episode_reward': Array(4552.914, dtype=float32), 'eval/episode_reward_alive': Array(374.98828, dtype=float32), 'eval/episode_reward_linvel': Array(4545.216, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.5609, dtype=float32), 'eval/episode_x_position': Array(6153.461, dtype=float32), 'eval/episode_x_velocity': Array(909.0431, dtype=float32), 'eval/episode_y_position': Array(-221.78754, dtype=float32), 'eval/episode_y_velocity': Array(-189.32324, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.03088, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2018547, dtype=float32), 'eval/episode_forward_reward_std': Array(866.96893, dtype=float32), 'eval/episode_reward_std': Array(865.1821, dtype=float32), 'eval/episode_reward_alive_std': Array(43.10744, dtype=float32), 'eval/episode_reward_linvel_std': Array(866.96893, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.070711, dtype=float32), 'eval/episode_x_position_std': Array(444.94952, dtype=float32), 'eval/episode_x_velocity_std': Array(173.39378, dtype=float32), 'eval/episode_y_position_std': Array(247.4572, dtype=float32), 'eval/episode_y_velocity_std': Array(76.28041, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5941298007965, 'eval/sps': 937.0827295921878, 'num_steps': 35962880}
{'eval/walltime': 60233.284752845764, 'training/sps': 2962.978804269761, 'training/walltime': 12258.731304645538, 'training/entropy_loss': Array(0.01415628, dtype=float32), 'training/policy_loss': Array(0.00465432, dtype=float32), 'training/total_loss': Array(0.1362136, dtype=float32), 'training/v_loss': Array(0.11740299, dtype=float32), 'eval/episode_distance_from_origin': Array(6281.506, dtype=float32), 'eval/episode_distance_reward': Array(27.219, dtype=float32), 'eval/episode_forward_reward': Array(4536.4746, dtype=float32), 'eval/episode_reward': Array(4540.1875, dtype=float32), 'eval/episode_reward_alive': Array(376.1172, dtype=float32), 'eval/episode_reward_linvel': Array(4536.4746, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.62372, dtype=float32), 'eval/episode_x_position': Array(6227.67, dtype=float32), 'eval/episode_x_velocity': Array(907.29486, dtype=float32), 'eval/episode_y_position': Array(-284.3556, dtype=float32), 'eval/episode_y_velocity': Array(-191.88103, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.81766, dtype=float32), 'eval/episode_distance_reward_std': Array(4.882263, dtype=float32), 'eval/episode_forward_reward_std': Array(813.70435, dtype=float32), 'eval/episode_reward_std': Array(807.5124, dtype=float32), 'eval/episode_reward_alive_std': Array(49.8144, dtype=float32), 'eval/episode_reward_linvel_std': Array(813.70435, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.432966, dtype=float32), 'eval/episode_x_position_std': Array(420.27988, dtype=float32), 'eval/episode_x_velocity_std': Array(162.7408, dtype=float32), 'eval/episode_y_position_std': Array(248.57727, dtype=float32), 'eval/episode_y_velocity_std': Array(78.46302, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4335343837738, 'eval/sps': 938.1857662643913, 'num_steps': 36044800}
{'eval/walltime': 60369.81173348427, 'training/sps': 2972.031360324854, 'training/walltime': 12286.29494380951, 'training/entropy_loss': Array(0.01415498, dtype=float32), 'training/policy_loss': Array(0.00492246, dtype=float32), 'training/total_loss': Array(0.12796974, dtype=float32), 'training/v_loss': Array(0.10889229, dtype=float32), 'eval/episode_distance_from_origin': Array(6341.279, dtype=float32), 'eval/episode_distance_reward': Array(27.777739, dtype=float32), 'eval/episode_forward_reward': Array(4629.596, dtype=float32), 'eval/episode_reward': Array(4631.0137, dtype=float32), 'eval/episode_reward_alive': Array(374.23828, dtype=float32), 'eval/episode_reward_linvel': Array(4629.596, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.5988, dtype=float32), 'eval/episode_x_position': Array(6289.2817, dtype=float32), 'eval/episode_x_velocity': Array(925.9194, dtype=float32), 'eval/episode_y_position': Array(-262.03323, dtype=float32), 'eval/episode_y_velocity': Array(-188.24335, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.41315, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0735, dtype=float32), 'eval/episode_forward_reward_std': Array(845.57666, dtype=float32), 'eval/episode_reward_std': Array(843.45184, dtype=float32), 'eval/episode_reward_alive_std': Array(48.08874, dtype=float32), 'eval/episode_reward_linvel_std': Array(845.57666, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.034887, dtype=float32), 'eval/episode_x_position_std': Array(444.94562, dtype=float32), 'eval/episode_x_velocity_std': Array(169.1154, dtype=float32), 'eval/episode_y_position_std': Array(255.9573, dtype=float32), 'eval/episode_y_velocity_std': Array(79.26903, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52698063850403, 'eval/sps': 937.5436225233622, 'num_steps': 36126720}
{'eval/walltime': 60506.249505996704, 'training/sps': 2961.5897390029177, 'training/walltime': 12313.955763578415, 'training/entropy_loss': Array(0.01461084, dtype=float32), 'training/policy_loss': Array(0.00327979, dtype=float32), 'training/total_loss': Array(0.15957329, dtype=float32), 'training/v_loss': Array(0.14168265, dtype=float32), 'eval/episode_distance_from_origin': Array(6332.8555, dtype=float32), 'eval/episode_distance_reward': Array(28.127993, dtype=float32), 'eval/episode_forward_reward': Array(4687.972, dtype=float32), 'eval/episode_reward': Array(4693.9766, dtype=float32), 'eval/episode_reward_alive': Array(378.5586, dtype=float32), 'eval/episode_reward_linvel': Array(4687.972, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.68213, dtype=float32), 'eval/episode_x_position': Array(6280.8906, dtype=float32), 'eval/episode_x_velocity': Array(937.5945, dtype=float32), 'eval/episode_y_position': Array(-252.74655, dtype=float32), 'eval/episode_y_velocity': Array(-184.34438, dtype=float32), 'eval/episode_distance_from_origin_std': Array(530.554, dtype=float32), 'eval/episode_distance_reward_std': Array(5.874914, dtype=float32), 'eval/episode_forward_reward_std': Array(979.1448, dtype=float32), 'eval/episode_reward_std': Array(972.6248, dtype=float32), 'eval/episode_reward_alive_std': Array(48.238327, dtype=float32), 'eval/episode_reward_linvel_std': Array(979.1448, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.199934, dtype=float32), 'eval/episode_x_position_std': Array(530.3925, dtype=float32), 'eval/episode_x_velocity_std': Array(195.829, dtype=float32), 'eval/episode_y_position_std': Array(260.69058, dtype=float32), 'eval/episode_y_velocity_std': Array(80.58379, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4377725124359, 'eval/sps': 938.1566236603076, 'num_steps': 36208640}
{'eval/walltime': 60642.78904604912, 'training/sps': 2958.5034246530818, 'training/walltime': 12341.64543914795, 'training/entropy_loss': Array(0.01477298, dtype=float32), 'training/policy_loss': Array(0.00238112, dtype=float32), 'training/total_loss': Array(0.19240475, dtype=float32), 'training/v_loss': Array(0.17525065, dtype=float32), 'eval/episode_distance_from_origin': Array(6405.707, dtype=float32), 'eval/episode_distance_reward': Array(28.742273, dtype=float32), 'eval/episode_forward_reward': Array(4790.3516, dtype=float32), 'eval/episode_reward': Array(4798.511, dtype=float32), 'eval/episode_reward_alive': Array(377.05078, dtype=float32), 'eval/episode_reward_linvel': Array(4790.3516, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.63336, dtype=float32), 'eval/episode_x_position': Array(6353.429, dtype=float32), 'eval/episode_x_velocity': Array(958.0704, dtype=float32), 'eval/episode_y_position': Array(-251.17862, dtype=float32), 'eval/episode_y_velocity': Array(-186.61064, dtype=float32), 'eval/episode_distance_from_origin_std': Array(424.60046, dtype=float32), 'eval/episode_distance_reward_std': Array(4.537998, dtype=float32), 'eval/episode_forward_reward_std': Array(756.32715, dtype=float32), 'eval/episode_reward_std': Array(753.56445, dtype=float32), 'eval/episode_reward_alive_std': Array(40.302605, dtype=float32), 'eval/episode_reward_linvel_std': Array(756.32715, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.990837, dtype=float32), 'eval/episode_x_position_std': Array(427.00827, dtype=float32), 'eval/episode_x_velocity_std': Array(151.2654, dtype=float32), 'eval/episode_y_position_std': Array(247.17384, dtype=float32), 'eval/episode_y_velocity_std': Array(72.9488, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53954005241394, 'eval/sps': 937.457383779557, 'num_steps': 36290560}
{'eval/walltime': 60779.21851539612, 'training/sps': 2969.0342635298066, 'training/walltime': 12369.236902475357, 'training/entropy_loss': Array(0.01295523, dtype=float32), 'training/policy_loss': Array(0.00285522, dtype=float32), 'training/total_loss': Array(0.1461997, dtype=float32), 'training/v_loss': Array(0.13038924, dtype=float32), 'eval/episode_distance_from_origin': Array(6418.592, dtype=float32), 'eval/episode_distance_reward': Array(28.486986, dtype=float32), 'eval/episode_forward_reward': Array(4747.804, dtype=float32), 'eval/episode_reward': Array(4744.4424, dtype=float32), 'eval/episode_reward_alive': Array(371.53516, dtype=float32), 'eval/episode_reward_linvel': Array(4747.804, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.38345, dtype=float32), 'eval/episode_x_position': Array(6364.2935, dtype=float32), 'eval/episode_x_velocity': Array(949.5608, dtype=float32), 'eval/episode_y_position': Array(-286.0284, dtype=float32), 'eval/episode_y_velocity': Array(-191.32692, dtype=float32), 'eval/episode_distance_from_origin_std': Array(442.8397, dtype=float32), 'eval/episode_distance_reward_std': Array(5.073634, dtype=float32), 'eval/episode_forward_reward_std': Array(845.59875, dtype=float32), 'eval/episode_reward_std': Array(848.5061, dtype=float32), 'eval/episode_reward_alive_std': Array(47.850155, dtype=float32), 'eval/episode_reward_linvel_std': Array(845.59875, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.300316, dtype=float32), 'eval/episode_x_position_std': Array(441.809, dtype=float32), 'eval/episode_x_velocity_std': Array(169.11978, dtype=float32), 'eval/episode_y_position_std': Array(280.8176, dtype=float32), 'eval/episode_y_velocity_std': Array(88.012115, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42946934700012, 'eval/sps': 938.2137203395531, 'num_steps': 36372480}
{'eval/walltime': 60915.74240541458, 'training/sps': 2967.8784969622893, 'training/walltime': 12396.83911061287, 'training/entropy_loss': Array(0.01492955, dtype=float32), 'training/policy_loss': Array(0.00557653, dtype=float32), 'training/total_loss': Array(0.10650621, dtype=float32), 'training/v_loss': Array(0.08600013, dtype=float32), 'eval/episode_distance_from_origin': Array(6417.2793, dtype=float32), 'eval/episode_distance_reward': Array(28.611858, dtype=float32), 'eval/episode_forward_reward': Array(4768.615, dtype=float32), 'eval/episode_reward': Array(4767.8623, dtype=float32), 'eval/episode_reward_alive': Array(375.2461, dtype=float32), 'eval/episode_reward_linvel': Array(4768.615, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.61148, dtype=float32), 'eval/episode_x_position': Array(6362.6685, dtype=float32), 'eval/episode_x_velocity': Array(953.72314, dtype=float32), 'eval/episode_y_position': Array(-290.19135, dtype=float32), 'eval/episode_y_velocity': Array(-197.13208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.47495, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1681366, dtype=float32), 'eval/episode_forward_reward_std': Array(861.3486, dtype=float32), 'eval/episode_reward_std': Array(859.42566, dtype=float32), 'eval/episode_reward_alive_std': Array(48.46237, dtype=float32), 'eval/episode_reward_linvel_std': Array(861.3486, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.48614, dtype=float32), 'eval/episode_x_position_std': Array(416.80872, dtype=float32), 'eval/episode_x_velocity_std': Array(172.26979, dtype=float32), 'eval/episode_y_position_std': Array(279.00546, dtype=float32), 'eval/episode_y_velocity_std': Array(81.98915, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52389001846313, 'eval/sps': 937.5648465824524, 'num_steps': 36454400}
{'eval/walltime': 61052.17896556854, 'training/sps': 2960.844971613674, 'training/walltime': 12424.506888151169, 'training/entropy_loss': Array(0.01698509, dtype=float32), 'training/policy_loss': Array(0.0078495, dtype=float32), 'training/total_loss': Array(0.17841199, dtype=float32), 'training/v_loss': Array(0.15357739, dtype=float32), 'eval/episode_distance_from_origin': Array(6358.243, dtype=float32), 'eval/episode_distance_reward': Array(27.615063, dtype=float32), 'eval/episode_forward_reward': Array(4602.4844, dtype=float32), 'eval/episode_reward': Array(4599.011, dtype=float32), 'eval/episode_reward_alive': Array(374.33594, dtype=float32), 'eval/episode_reward_linvel': Array(4602.4844, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.4245, dtype=float32), 'eval/episode_x_position': Array(6303.2285, dtype=float32), 'eval/episode_x_velocity': Array(920.49695, dtype=float32), 'eval/episode_y_position': Array(-296.70383, dtype=float32), 'eval/episode_y_velocity': Array(-193.31238, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.6739, dtype=float32), 'eval/episode_distance_reward_std': Array(5.415823, dtype=float32), 'eval/episode_forward_reward_std': Array(902.63, dtype=float32), 'eval/episode_reward_std': Array(902.86487, dtype=float32), 'eval/episode_reward_alive_std': Array(45.103096, dtype=float32), 'eval/episode_reward_linvel_std': Array(902.63, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.12116, dtype=float32), 'eval/episode_x_position_std': Array(484.4985, dtype=float32), 'eval/episode_x_velocity_std': Array(180.52611, dtype=float32), 'eval/episode_y_position_std': Array(251.55415, dtype=float32), 'eval/episode_y_velocity_std': Array(76.68109, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43656015396118, 'eval/sps': 938.1649600045546, 'num_steps': 36536320}
{'eval/walltime': 61188.70417261124, 'training/sps': 2946.598866476977, 'training/walltime': 12452.30843281746, 'training/entropy_loss': Array(0.014141, dtype=float32), 'training/policy_loss': Array(0.00625943, dtype=float32), 'training/total_loss': Array(0.11984906, dtype=float32), 'training/v_loss': Array(0.09944864, dtype=float32), 'eval/episode_distance_from_origin': Array(6378.1562, dtype=float32), 'eval/episode_distance_reward': Array(28.067516, dtype=float32), 'eval/episode_forward_reward': Array(4677.8926, dtype=float32), 'eval/episode_reward': Array(4681.0186, dtype=float32), 'eval/episode_reward_alive': Array(379.98438, dtype=float32), 'eval/episode_reward_linvel': Array(4677.8926, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.925, dtype=float32), 'eval/episode_x_position': Array(6322.321, dtype=float32), 'eval/episode_x_velocity': Array(935.5784, dtype=float32), 'eval/episode_y_position': Array(-265.7786, dtype=float32), 'eval/episode_y_velocity': Array(-192.11661, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.79855, dtype=float32), 'eval/episode_distance_reward_std': Array(5.242646, dtype=float32), 'eval/episode_forward_reward_std': Array(873.7675, dtype=float32), 'eval/episode_reward_std': Array(877.8481, dtype=float32), 'eval/episode_reward_alive_std': Array(50.926296, dtype=float32), 'eval/episode_reward_linvel_std': Array(873.7675, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.222502, dtype=float32), 'eval/episode_x_position_std': Array(456.252, dtype=float32), 'eval/episode_x_velocity_std': Array(174.75357, dtype=float32), 'eval/episode_y_position_std': Array(302.3756, dtype=float32), 'eval/episode_y_velocity_std': Array(91.31579, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5252070426941, 'eval/sps': 937.5558021308981, 'num_steps': 36618240}
{'eval/walltime': 61325.223888635635, 'training/sps': 2942.180251973455, 'training/walltime': 12480.151730298996, 'training/entropy_loss': Array(0.01493795, dtype=float32), 'training/policy_loss': Array(0.00367196, dtype=float32), 'training/total_loss': Array(0.16475362, dtype=float32), 'training/v_loss': Array(0.1461437, dtype=float32), 'eval/episode_distance_from_origin': Array(6426.5415, dtype=float32), 'eval/episode_distance_reward': Array(29.01791, dtype=float32), 'eval/episode_forward_reward': Array(4836.29, dtype=float32), 'eval/episode_reward': Array(4837.755, dtype=float32), 'eval/episode_reward_alive': Array(380.30078, dtype=float32), 'eval/episode_reward_linvel': Array(4836.29, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.8537, dtype=float32), 'eval/episode_x_position': Array(6373.205, dtype=float32), 'eval/episode_x_velocity': Array(967.2582, dtype=float32), 'eval/episode_y_position': Array(-224.56195, dtype=float32), 'eval/episode_y_velocity': Array(-186.07687, dtype=float32), 'eval/episode_distance_from_origin_std': Array(398.33112, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7232594, dtype=float32), 'eval/episode_forward_reward_std': Array(787.2034, dtype=float32), 'eval/episode_reward_std': Array(789.80963, dtype=float32), 'eval/episode_reward_alive_std': Array(45.29191, dtype=float32), 'eval/episode_reward_linvel_std': Array(787.2034, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.264137, dtype=float32), 'eval/episode_x_position_std': Array(400.38528, dtype=float32), 'eval/episode_x_velocity_std': Array(157.4407, dtype=float32), 'eval/episode_y_position_std': Array(307.9784, dtype=float32), 'eval/episode_y_velocity_std': Array(93.05026, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5197160243988, 'eval/sps': 937.5935119666074, 'num_steps': 36700160}
{'eval/walltime': 61461.75529909134, 'training/sps': 2938.4738471740966, 'training/walltime': 12508.03014755249, 'training/entropy_loss': Array(0.01436416, dtype=float32), 'training/policy_loss': Array(0.00240447, dtype=float32), 'training/total_loss': Array(0.18114665, dtype=float32), 'training/v_loss': Array(0.16437802, dtype=float32), 'eval/episode_distance_from_origin': Array(6537.8896, dtype=float32), 'eval/episode_distance_reward': Array(29.958126, dtype=float32), 'eval/episode_forward_reward': Array(4992.992, dtype=float32), 'eval/episode_reward': Array(4991.173, dtype=float32), 'eval/episode_reward_alive': Array(380.30078, dtype=float32), 'eval/episode_reward_linvel': Array(4992.992, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.07822, dtype=float32), 'eval/episode_x_position': Array(6486.5933, dtype=float32), 'eval/episode_x_velocity': Array(998.5984, dtype=float32), 'eval/episode_y_position': Array(-246.27573, dtype=float32), 'eval/episode_y_velocity': Array(-189.62453, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.11163, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6091247, dtype=float32), 'eval/episode_forward_reward_std': Array(934.8465, dtype=float32), 'eval/episode_reward_std': Array(935.94824, dtype=float32), 'eval/episode_reward_alive_std': Array(44.100796, dtype=float32), 'eval/episode_reward_linvel_std': Array(934.8465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.872272, dtype=float32), 'eval/episode_x_position_std': Array(477.6267, dtype=float32), 'eval/episode_x_velocity_std': Array(186.96933, dtype=float32), 'eval/episode_y_position_std': Array(243.56184, dtype=float32), 'eval/episode_y_velocity_std': Array(84.45286, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53141045570374, 'eval/sps': 937.5132035388174, 'num_steps': 36782080}
{'eval/walltime': 61598.20207285881, 'training/sps': 2940.137218172952, 'training/walltime': 12535.892792701721, 'training/entropy_loss': Array(0.01481705, dtype=float32), 'training/policy_loss': Array(0.00302931, dtype=float32), 'training/total_loss': Array(0.2072646, dtype=float32), 'training/v_loss': Array(0.18941824, dtype=float32), 'eval/episode_distance_from_origin': Array(6470.0566, dtype=float32), 'eval/episode_distance_reward': Array(29.789795, dtype=float32), 'eval/episode_forward_reward': Array(4964.936, dtype=float32), 'eval/episode_reward': Array(4971.9062, dtype=float32), 'eval/episode_reward_alive': Array(380.78125, dtype=float32), 'eval/episode_reward_linvel': Array(4964.936, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.6018, dtype=float32), 'eval/episode_x_position': Array(6420.722, dtype=float32), 'eval/episode_x_velocity': Array(992.9874, dtype=float32), 'eval/episode_y_position': Array(-148.63002, dtype=float32), 'eval/episode_y_velocity': Array(-167.00597, dtype=float32), 'eval/episode_distance_from_origin_std': Array(437.97226, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9827676, dtype=float32), 'eval/episode_forward_reward_std': Array(830.4549, dtype=float32), 'eval/episode_reward_std': Array(831.8947, dtype=float32), 'eval/episode_reward_alive_std': Array(42.016308, dtype=float32), 'eval/episode_reward_linvel_std': Array(830.4549, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.75828, dtype=float32), 'eval/episode_x_position_std': Array(440.5831, dtype=float32), 'eval/episode_x_velocity_std': Array(166.09102, dtype=float32), 'eval/episode_y_position_std': Array(301.53537, dtype=float32), 'eval/episode_y_velocity_std': Array(93.29663, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4467737674713, 'eval/sps': 938.0947344210126, 'num_steps': 36864000}
{'eval/walltime': 61734.69552588463, 'training/sps': 2939.096325355719, 'training/walltime': 12563.765305519104, 'training/entropy_loss': Array(0.01414189, dtype=float32), 'training/policy_loss': Array(0.00578615, dtype=float32), 'training/total_loss': Array(0.09014703, dtype=float32), 'training/v_loss': Array(0.07021898, dtype=float32), 'eval/episode_distance_from_origin': Array(6375.4346, dtype=float32), 'eval/episode_distance_reward': Array(28.891182, dtype=float32), 'eval/episode_forward_reward': Array(4815.1704, dtype=float32), 'eval/episode_reward': Array(4815.355, dtype=float32), 'eval/episode_reward_alive': Array(376.09766, dtype=float32), 'eval/episode_reward_linvel': Array(4815.1704, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.80338, dtype=float32), 'eval/episode_x_position': Array(6319.167, dtype=float32), 'eval/episode_x_velocity': Array(963.034, dtype=float32), 'eval/episode_y_position': Array(-294.9823, dtype=float32), 'eval/episode_y_velocity': Array(-206.45267, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.8139, dtype=float32), 'eval/episode_distance_reward_std': Array(4.430374, dtype=float32), 'eval/episode_forward_reward_std': Array(738.3898, dtype=float32), 'eval/episode_reward_std': Array(736.5526, dtype=float32), 'eval/episode_reward_alive_std': Array(42.848892, dtype=float32), 'eval/episode_reward_linvel_std': Array(738.3898, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.222666, dtype=float32), 'eval/episode_x_position_std': Array(388.4541, dtype=float32), 'eval/episode_x_velocity_std': Array(147.67789, dtype=float32), 'eval/episode_y_position_std': Array(260.7069, dtype=float32), 'eval/episode_y_velocity_std': Array(73.36248, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49345302581787, 'eval/sps': 937.7739163488573, 'num_steps': 36945920}
{'eval/walltime': 61871.14812064171, 'training/sps': 2944.4058663020464, 'training/walltime': 12591.58755683899, 'training/entropy_loss': Array(0.01662388, dtype=float32), 'training/policy_loss': Array(0.00892575, dtype=float32), 'training/total_loss': Array(0.17409289, dtype=float32), 'training/v_loss': Array(0.14854325, dtype=float32), 'eval/episode_distance_from_origin': Array(6467.891, dtype=float32), 'eval/episode_distance_reward': Array(29.505844, dtype=float32), 'eval/episode_forward_reward': Array(4917.613, dtype=float32), 'eval/episode_reward': Array(4926.0024, dtype=float32), 'eval/episode_reward_alive': Array(382.64453, dtype=float32), 'eval/episode_reward_linvel': Array(4917.613, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.76044, dtype=float32), 'eval/episode_x_position': Array(6412.7573, dtype=float32), 'eval/episode_x_velocity': Array(983.52246, dtype=float32), 'eval/episode_y_position': Array(-263.6925, dtype=float32), 'eval/episode_y_velocity': Array(-198.81522, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.17447, dtype=float32), 'eval/episode_distance_reward_std': Array(4.490234, dtype=float32), 'eval/episode_forward_reward_std': Array(748.36664, dtype=float32), 'eval/episode_reward_std': Array(745.9451, dtype=float32), 'eval/episode_reward_alive_std': Array(37.337208, dtype=float32), 'eval/episode_reward_linvel_std': Array(748.36664, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.317963, dtype=float32), 'eval/episode_x_position_std': Array(419.3115, dtype=float32), 'eval/episode_x_velocity_std': Array(149.67337, dtype=float32), 'eval/episode_y_position_std': Array(275.6667, dtype=float32), 'eval/episode_y_velocity_std': Array(81.61351, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45259475708008, 'eval/sps': 938.0547158364571, 'num_steps': 37027840}
{'eval/walltime': 62007.66843342781, 'training/sps': 2952.180376913822, 'training/walltime': 12619.336538791656, 'training/entropy_loss': Array(0.01419478, dtype=float32), 'training/policy_loss': Array(0.00621214, dtype=float32), 'training/total_loss': Array(0.15028164, dtype=float32), 'training/v_loss': Array(0.12987474, dtype=float32), 'eval/episode_distance_from_origin': Array(6368.8237, dtype=float32), 'eval/episode_distance_reward': Array(28.375803, dtype=float32), 'eval/episode_forward_reward': Array(4729.2725, dtype=float32), 'eval/episode_reward': Array(4740.826, dtype=float32), 'eval/episode_reward_alive': Array(390.875, dtype=float32), 'eval/episode_reward_linvel': Array(4729.2725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.6972, dtype=float32), 'eval/episode_x_position': Array(6316.6396, dtype=float32), 'eval/episode_x_velocity': Array(945.8545, dtype=float32), 'eval/episode_y_position': Array(-233.76472, dtype=float32), 'eval/episode_y_velocity': Array(-180.62267, dtype=float32), 'eval/episode_distance_from_origin_std': Array(549.4638, dtype=float32), 'eval/episode_distance_reward_std': Array(6.338247, dtype=float32), 'eval/episode_forward_reward_std': Array(1056.3672, dtype=float32), 'eval/episode_reward_std': Array(1059.4418, dtype=float32), 'eval/episode_reward_alive_std': Array(43.051113, dtype=float32), 'eval/episode_reward_linvel_std': Array(1056.3672, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.953451, dtype=float32), 'eval/episode_x_position_std': Array(549.684, dtype=float32), 'eval/episode_x_velocity_std': Array(211.27333, dtype=float32), 'eval/episode_y_position_std': Array(272.03842, dtype=float32), 'eval/episode_y_velocity_std': Array(90.77873, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5203127861023, 'eval/sps': 937.5894135296058, 'num_steps': 37109760}
{'eval/walltime': 62144.10426187515, 'training/sps': 2937.0882755355806, 'training/walltime': 12647.228107690811, 'training/entropy_loss': Array(0.01511555, dtype=float32), 'training/policy_loss': Array(0.00705691, dtype=float32), 'training/total_loss': Array(0.16267619, dtype=float32), 'training/v_loss': Array(0.14050372, dtype=float32), 'eval/episode_distance_from_origin': Array(6487.67, dtype=float32), 'eval/episode_distance_reward': Array(29.204275, dtype=float32), 'eval/episode_forward_reward': Array(4867.351, dtype=float32), 'eval/episode_reward': Array(4873.715, dtype=float32), 'eval/episode_reward_alive': Array(386.09766, dtype=float32), 'eval/episode_reward_linvel': Array(4867.351, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.93817, dtype=float32), 'eval/episode_x_position': Array(6434.6167, dtype=float32), 'eval/episode_x_velocity': Array(973.4703, dtype=float32), 'eval/episode_y_position': Array(-257.66705, dtype=float32), 'eval/episode_y_velocity': Array(-194.92862, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.0328, dtype=float32), 'eval/episode_distance_reward_std': Array(5.051043, dtype=float32), 'eval/episode_forward_reward_std': Array(841.8333, dtype=float32), 'eval/episode_reward_std': Array(848.87787, dtype=float32), 'eval/episode_reward_alive_std': Array(42.63641, dtype=float32), 'eval/episode_reward_linvel_std': Array(841.8333, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.9544, dtype=float32), 'eval/episode_x_position_std': Array(448.78122, dtype=float32), 'eval/episode_x_velocity_std': Array(168.36682, dtype=float32), 'eval/episode_y_position_std': Array(272.17328, dtype=float32), 'eval/episode_y_velocity_std': Array(80.058464, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43582844734192, 'eval/sps': 938.1699913919769, 'num_steps': 37191680}
{'eval/walltime': 62280.81254506111, 'training/sps': 2947.2942884432864, 'training/walltime': 12675.023092508316, 'training/entropy_loss': Array(0.01456384, dtype=float32), 'training/policy_loss': Array(0.00514969, dtype=float32), 'training/total_loss': Array(0.1863532, dtype=float32), 'training/v_loss': Array(0.16663967, dtype=float32), 'eval/episode_distance_from_origin': Array(6531.851, dtype=float32), 'eval/episode_distance_reward': Array(29.942415, dtype=float32), 'eval/episode_forward_reward': Array(4990.374, dtype=float32), 'eval/episode_reward': Array(5008.6357, dtype=float32), 'eval/episode_reward_alive': Array(395.5039, dtype=float32), 'eval/episode_reward_linvel': Array(4990.374, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.1858, dtype=float32), 'eval/episode_x_position': Array(6478.454, dtype=float32), 'eval/episode_x_velocity': Array(998.0748, dtype=float32), 'eval/episode_y_position': Array(-229.7695, dtype=float32), 'eval/episode_y_velocity': Array(-185.13354, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.66617, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5930653, dtype=float32), 'eval/episode_forward_reward_std': Array(765.5047, dtype=float32), 'eval/episode_reward_std': Array(767.0751, dtype=float32), 'eval/episode_reward_alive_std': Array(38.94936, dtype=float32), 'eval/episode_reward_linvel_std': Array(765.5047, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.668636, dtype=float32), 'eval/episode_x_position_std': Array(417.8154, dtype=float32), 'eval/episode_x_velocity_std': Array(153.101, dtype=float32), 'eval/episode_y_position_std': Array(292.0899, dtype=float32), 'eval/episode_y_velocity_std': Array(85.44992, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70828318595886, 'eval/sps': 936.3002520182824, 'num_steps': 37273600}
{'eval/walltime': 62417.35433912277, 'training/sps': 2941.140782353514, 'training/walltime': 12702.876230478287, 'training/entropy_loss': Array(0.01482225, dtype=float32), 'training/policy_loss': Array(0.00368413, dtype=float32), 'training/total_loss': Array(0.19961107, dtype=float32), 'training/v_loss': Array(0.18110467, dtype=float32), 'eval/episode_distance_from_origin': Array(6518.3496, dtype=float32), 'eval/episode_distance_reward': Array(29.79969, dtype=float32), 'eval/episode_forward_reward': Array(4966.5874, dtype=float32), 'eval/episode_reward': Array(4977.493, dtype=float32), 'eval/episode_reward_alive': Array(391.63672, dtype=float32), 'eval/episode_reward_linvel': Array(4966.5874, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.52985, dtype=float32), 'eval/episode_x_position': Array(6466.207, dtype=float32), 'eval/episode_x_velocity': Array(993.3174, dtype=float32), 'eval/episode_y_position': Array(-197.87894, dtype=float32), 'eval/episode_y_velocity': Array(-176.92639, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.03647, dtype=float32), 'eval/episode_distance_reward_std': Array(5.148455, dtype=float32), 'eval/episode_forward_reward_std': Array(858.07007, dtype=float32), 'eval/episode_reward_std': Array(862.4152, dtype=float32), 'eval/episode_reward_alive_std': Array(37.867043, dtype=float32), 'eval/episode_reward_linvel_std': Array(858.07007, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.869873, dtype=float32), 'eval/episode_x_position_std': Array(450.29758, dtype=float32), 'eval/episode_x_velocity_std': Array(171.61388, dtype=float32), 'eval/episode_y_position_std': Array(304.35156, dtype=float32), 'eval/episode_y_velocity_std': Array(95.734955, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54179406166077, 'eval/sps': 937.4419083888455, 'num_steps': 37355520}
{'eval/walltime': 62553.91189265251, 'training/sps': 2937.014514834545, 'training/walltime': 12730.768499851227, 'training/entropy_loss': Array(0.0118395, dtype=float32), 'training/policy_loss': Array(0.00776446, dtype=float32), 'training/total_loss': Array(0.09959425, dtype=float32), 'training/v_loss': Array(0.07999028, dtype=float32), 'eval/episode_distance_from_origin': Array(6430.6543, dtype=float32), 'eval/episode_distance_reward': Array(28.794975, dtype=float32), 'eval/episode_forward_reward': Array(4799.1357, dtype=float32), 'eval/episode_reward': Array(4814.3535, dtype=float32), 'eval/episode_reward_alive': Array(397.72656, dtype=float32), 'eval/episode_reward_linvel': Array(4799.1357, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.30362, dtype=float32), 'eval/episode_x_position': Array(6380.0234, dtype=float32), 'eval/episode_x_velocity': Array(959.827, dtype=float32), 'eval/episode_y_position': Array(-212.74893, dtype=float32), 'eval/episode_y_velocity': Array(-181.75992, dtype=float32), 'eval/episode_distance_from_origin_std': Array(412.61145, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0223064, dtype=float32), 'eval/episode_forward_reward_std': Array(837.0446, dtype=float32), 'eval/episode_reward_std': Array(840.9727, dtype=float32), 'eval/episode_reward_alive_std': Array(40.51769, dtype=float32), 'eval/episode_reward_linvel_std': Array(837.0446, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.449774, dtype=float32), 'eval/episode_x_position_std': Array(410.50037, dtype=float32), 'eval/episode_x_velocity_std': Array(167.40889, dtype=float32), 'eval/episode_y_position_std': Array(274.49966, dtype=float32), 'eval/episode_y_velocity_std': Array(84.09455, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55755352973938, 'eval/sps': 937.3337226060094, 'num_steps': 37437440}
{'eval/walltime': 62690.36472630501, 'training/sps': 2943.765122080651, 'training/walltime': 12758.596807003021, 'training/entropy_loss': Array(0.01803211, dtype=float32), 'training/policy_loss': Array(0.01180423, dtype=float32), 'training/total_loss': Array(0.13458392, dtype=float32), 'training/v_loss': Array(0.10474758, dtype=float32), 'eval/episode_distance_from_origin': Array(6437.7676, dtype=float32), 'eval/episode_distance_reward': Array(29.58781, dtype=float32), 'eval/episode_forward_reward': Array(4931.2734, dtype=float32), 'eval/episode_reward': Array(4950.6777, dtype=float32), 'eval/episode_reward_alive': Array(396.35156, dtype=float32), 'eval/episode_reward_linvel': Array(4931.2734, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.5349, dtype=float32), 'eval/episode_x_position': Array(6384.707, dtype=float32), 'eval/episode_x_velocity': Array(986.25476, dtype=float32), 'eval/episode_y_position': Array(-211.10312, dtype=float32), 'eval/episode_y_velocity': Array(-189.66478, dtype=float32), 'eval/episode_distance_from_origin_std': Array(410.98596, dtype=float32), 'eval/episode_distance_reward_std': Array(4.729733, dtype=float32), 'eval/episode_forward_reward_std': Array(788.2821, dtype=float32), 'eval/episode_reward_std': Array(789.56555, dtype=float32), 'eval/episode_reward_alive_std': Array(39.96216, dtype=float32), 'eval/episode_reward_linvel_std': Array(788.2821, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.75015, dtype=float32), 'eval/episode_x_position_std': Array(411.6681, dtype=float32), 'eval/episode_x_velocity_std': Array(157.6563, dtype=float32), 'eval/episode_y_position_std': Array(277.86884, dtype=float32), 'eval/episode_y_velocity_std': Array(79.48341, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45283365249634, 'eval/sps': 938.0530735329168, 'num_steps': 37519360}
{'eval/walltime': 62826.90330338478, 'training/sps': 2944.1110893204864, 'training/walltime': 12786.421844005585, 'training/entropy_loss': Array(0.01632303, dtype=float32), 'training/policy_loss': Array(0.0103143, dtype=float32), 'training/total_loss': Array(0.15010445, dtype=float32), 'training/v_loss': Array(0.12346712, dtype=float32), 'eval/episode_distance_from_origin': Array(6498.6006, dtype=float32), 'eval/episode_distance_reward': Array(30.011837, dtype=float32), 'eval/episode_forward_reward': Array(5001.9453, dtype=float32), 'eval/episode_reward': Array(5010.1426, dtype=float32), 'eval/episode_reward_alive': Array(388.85938, dtype=float32), 'eval/episode_reward_linvel': Array(5001.9453, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.67346, dtype=float32), 'eval/episode_x_position': Array(6444.5693, dtype=float32), 'eval/episode_x_velocity': Array(1000.3889, dtype=float32), 'eval/episode_y_position': Array(-191.29883, dtype=float32), 'eval/episode_y_velocity': Array(-176.46762, dtype=float32), 'eval/episode_distance_from_origin_std': Array(486.09964, dtype=float32), 'eval/episode_distance_reward_std': Array(5.545929, dtype=float32), 'eval/episode_forward_reward_std': Array(924.31445, dtype=float32), 'eval/episode_reward_std': Array(930.327, dtype=float32), 'eval/episode_reward_alive_std': Array(42.338707, dtype=float32), 'eval/episode_reward_linvel_std': Array(924.31445, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.74345, dtype=float32), 'eval/episode_x_position_std': Array(485.49768, dtype=float32), 'eval/episode_x_velocity_std': Array(184.86282, dtype=float32), 'eval/episode_y_position_std': Array(339.26172, dtype=float32), 'eval/episode_y_velocity_std': Array(101.48298, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53857707977295, 'eval/sps': 937.4639954334351, 'num_steps': 37601280}
{'eval/walltime': 62963.3531794548, 'training/sps': 2944.4761128670507, 'training/walltime': 12814.243431568146, 'training/entropy_loss': Array(0.0162435, dtype=float32), 'training/policy_loss': Array(0.01475598, dtype=float32), 'training/total_loss': Array(0.15154275, dtype=float32), 'training/v_loss': Array(0.12054326, dtype=float32), 'eval/episode_distance_from_origin': Array(6503.6016, dtype=float32), 'eval/episode_distance_reward': Array(29.801582, dtype=float32), 'eval/episode_forward_reward': Array(4966.9023, dtype=float32), 'eval/episode_reward': Array(4979.6855, dtype=float32), 'eval/episode_reward_alive': Array(389.40234, dtype=float32), 'eval/episode_reward_linvel': Array(4966.9023, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.42065, dtype=float32), 'eval/episode_x_position': Array(6449.37, dtype=float32), 'eval/episode_x_velocity': Array(993.38043, dtype=float32), 'eval/episode_y_position': Array(-248.55916, dtype=float32), 'eval/episode_y_velocity': Array(-190.35593, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.53232, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8179874, dtype=float32), 'eval/episode_forward_reward_std': Array(802.9923, dtype=float32), 'eval/episode_reward_std': Array(803.9104, dtype=float32), 'eval/episode_reward_alive_std': Array(39.174843, dtype=float32), 'eval/episode_reward_linvel_std': Array(802.9923, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.771433, dtype=float32), 'eval/episode_x_position_std': Array(463.33566, dtype=float32), 'eval/episode_x_velocity_std': Array(160.5985, dtype=float32), 'eval/episode_y_position_std': Array(280.0955, dtype=float32), 'eval/episode_y_velocity_std': Array(83.00863, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44987607002258, 'eval/sps': 938.0734060492197, 'num_steps': 37683200}
{'eval/walltime': 63099.861028671265, 'training/sps': 2947.4132917119264, 'training/walltime': 12842.037294149399, 'training/entropy_loss': Array(0.01574709, dtype=float32), 'training/policy_loss': Array(0.00834462, dtype=float32), 'training/total_loss': Array(0.19073549, dtype=float32), 'training/v_loss': Array(0.16664378, dtype=float32), 'eval/episode_distance_from_origin': Array(6530.057, dtype=float32), 'eval/episode_distance_reward': Array(30.153261, dtype=float32), 'eval/episode_forward_reward': Array(5025.5156, dtype=float32), 'eval/episode_reward': Array(5045.6113, dtype=float32), 'eval/episode_reward_alive': Array(395.4961, dtype=float32), 'eval/episode_reward_linvel': Array(5025.5156, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.5534, dtype=float32), 'eval/episode_x_position': Array(6479.043, dtype=float32), 'eval/episode_x_velocity': Array(1005.10297, dtype=float32), 'eval/episode_y_position': Array(-163.02902, dtype=float32), 'eval/episode_y_velocity': Array(-167.73004, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.2611, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4047937, dtype=float32), 'eval/episode_forward_reward_std': Array(734.126, dtype=float32), 'eval/episode_reward_std': Array(732.5526, dtype=float32), 'eval/episode_reward_alive_std': Array(40.218666, dtype=float32), 'eval/episode_reward_linvel_std': Array(734.126, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.615772, dtype=float32), 'eval/episode_x_position_std': Array(411.53592, dtype=float32), 'eval/episode_x_velocity_std': Array(146.8251, dtype=float32), 'eval/episode_y_position_std': Array(316.64008, dtype=float32), 'eval/episode_y_velocity_std': Array(86.54908, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50784921646118, 'eval/sps': 937.6750182110756, 'num_steps': 37765120}
{'eval/walltime': 63236.30820608139, 'training/sps': 2934.9572364676405, 'training/walltime': 12869.9491147995, 'training/entropy_loss': Array(0.01631252, dtype=float32), 'training/policy_loss': Array(0.00186774, dtype=float32), 'training/total_loss': Array(0.21666852, dtype=float32), 'training/v_loss': Array(0.19848827, dtype=float32), 'eval/episode_distance_from_origin': Array(6521.0337, dtype=float32), 'eval/episode_distance_reward': Array(30.251204, dtype=float32), 'eval/episode_forward_reward': Array(5041.8384, dtype=float32), 'eval/episode_reward': Array(5056.9404, dtype=float32), 'eval/episode_reward_alive': Array(390.0664, dtype=float32), 'eval/episode_reward_linvel': Array(5041.8384, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.2152, dtype=float32), 'eval/episode_x_position': Array(6469.1113, dtype=float32), 'eval/episode_x_velocity': Array(1008.36755, dtype=float32), 'eval/episode_y_position': Array(-206.33798, dtype=float32), 'eval/episode_y_velocity': Array(-179.0665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.6969, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3526945, dtype=float32), 'eval/episode_forward_reward_std': Array(725.4434, dtype=float32), 'eval/episode_reward_std': Array(723.6156, dtype=float32), 'eval/episode_reward_alive_std': Array(37.491997, dtype=float32), 'eval/episode_reward_linvel_std': Array(725.4434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.737045, dtype=float32), 'eval/episode_x_position_std': Array(419.35257, dtype=float32), 'eval/episode_x_velocity_std': Array(145.08867, dtype=float32), 'eval/episode_y_position_std': Array(289.29837, dtype=float32), 'eval/episode_y_velocity_std': Array(92.09248, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44717741012573, 'eval/sps': 938.0919593174459, 'num_steps': 37847040}
{'eval/walltime': 63372.8277528286, 'training/sps': 2955.4208924267546, 'training/walltime': 12897.667670965195, 'training/entropy_loss': Array(0.01276974, dtype=float32), 'training/policy_loss': Array(0.00477291, dtype=float32), 'training/total_loss': Array(0.12379608, dtype=float32), 'training/v_loss': Array(0.10625342, dtype=float32), 'eval/episode_distance_from_origin': Array(6480.294, dtype=float32), 'eval/episode_distance_reward': Array(29.897964, dtype=float32), 'eval/episode_forward_reward': Array(4982.9653, dtype=float32), 'eval/episode_reward': Array(5001.7373, dtype=float32), 'eval/episode_reward_alive': Array(395.34766, dtype=float32), 'eval/episode_reward_linvel': Array(4982.9653, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.47308, dtype=float32), 'eval/episode_x_position': Array(6427.9062, dtype=float32), 'eval/episode_x_velocity': Array(996.593, dtype=float32), 'eval/episode_y_position': Array(-192.55598, dtype=float32), 'eval/episode_y_velocity': Array(-184.56506, dtype=float32), 'eval/episode_distance_from_origin_std': Array(446.2497, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9170475, dtype=float32), 'eval/episode_forward_reward_std': Array(819.50183, dtype=float32), 'eval/episode_reward_std': Array(819.2143, dtype=float32), 'eval/episode_reward_alive_std': Array(37.63043, dtype=float32), 'eval/episode_reward_linvel_std': Array(819.50183, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.442307, dtype=float32), 'eval/episode_x_position_std': Array(448.43164, dtype=float32), 'eval/episode_x_velocity_std': Array(163.90045, dtype=float32), 'eval/episode_y_position_std': Array(288.5318, dtype=float32), 'eval/episode_y_velocity_std': Array(80.388435, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51954674720764, 'eval/sps': 937.594674534166, 'num_steps': 37928960}
{'eval/walltime': 63509.2607152462, 'training/sps': 2944.849303474414, 'training/walltime': 12925.485732793808, 'training/entropy_loss': Array(0.01806552, dtype=float32), 'training/policy_loss': Array(0.01328016, dtype=float32), 'training/total_loss': Array(0.12106253, dtype=float32), 'training/v_loss': Array(0.08971684, dtype=float32), 'eval/episode_distance_from_origin': Array(6385.0327, dtype=float32), 'eval/episode_distance_reward': Array(28.813568, dtype=float32), 'eval/episode_forward_reward': Array(4802.234, dtype=float32), 'eval/episode_reward': Array(4807.866, dtype=float32), 'eval/episode_reward_alive': Array(390.3672, dtype=float32), 'eval/episode_reward_linvel': Array(4802.234, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.54758, dtype=float32), 'eval/episode_x_position': Array(6330.133, dtype=float32), 'eval/episode_x_velocity': Array(960.4466, dtype=float32), 'eval/episode_y_position': Array(-251.40909, dtype=float32), 'eval/episode_y_velocity': Array(-184.88739, dtype=float32), 'eval/episode_distance_from_origin_std': Array(496.25262, dtype=float32), 'eval/episode_distance_reward_std': Array(5.993983, dtype=float32), 'eval/episode_forward_reward_std': Array(998.98956, dtype=float32), 'eval/episode_reward_std': Array(996.7604, dtype=float32), 'eval/episode_reward_alive_std': Array(43.11062, dtype=float32), 'eval/episode_reward_linvel_std': Array(998.98956, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.824133, dtype=float32), 'eval/episode_x_position_std': Array(494.93484, dtype=float32), 'eval/episode_x_velocity_std': Array(199.79787, dtype=float32), 'eval/episode_y_position_std': Array(301.74023, dtype=float32), 'eval/episode_y_velocity_std': Array(92.77436, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43296241760254, 'eval/sps': 938.189699408634, 'num_steps': 38010880}
{'eval/walltime': 63645.76316356659, 'training/sps': 2951.112640464068, 'training/walltime': 12953.244754552841, 'training/entropy_loss': Array(0.01539862, dtype=float32), 'training/policy_loss': Array(0.00858281, dtype=float32), 'training/total_loss': Array(0.1507745, dtype=float32), 'training/v_loss': Array(0.12679306, dtype=float32), 'eval/episode_distance_from_origin': Array(6353.888, dtype=float32), 'eval/episode_distance_reward': Array(28.813074, dtype=float32), 'eval/episode_forward_reward': Array(4802.1514, dtype=float32), 'eval/episode_reward': Array(4813.29, dtype=float32), 'eval/episode_reward_alive': Array(388.4961, dtype=float32), 'eval/episode_reward_linvel': Array(4802.1514, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.171, dtype=float32), 'eval/episode_x_position': Array(6298.1353, dtype=float32), 'eval/episode_x_velocity': Array(960.4303, dtype=float32), 'eval/episode_y_position': Array(-279.45795, dtype=float32), 'eval/episode_y_velocity': Array(-190.28778, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.68842, dtype=float32), 'eval/episode_distance_reward_std': Array(5.452074, dtype=float32), 'eval/episode_forward_reward_std': Array(908.6721, dtype=float32), 'eval/episode_reward_std': Array(905.94434, dtype=float32), 'eval/episode_reward_alive_std': Array(41.38819, dtype=float32), 'eval/episode_reward_linvel_std': Array(908.6721, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.874336, dtype=float32), 'eval/episode_x_position_std': Array(474.0788, dtype=float32), 'eval/episode_x_velocity_std': Array(181.73453, dtype=float32), 'eval/episode_y_position_std': Array(278.58694, dtype=float32), 'eval/episode_y_velocity_std': Array(93.43863, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5024483203888, 'eval/sps': 937.7121185370064, 'num_steps': 38092800}
{'eval/walltime': 63782.46949648857, 'training/sps': 2940.0851912428743, 'training/walltime': 12981.107892751694, 'training/entropy_loss': Array(0.01512406, dtype=float32), 'training/policy_loss': Array(0.00550038, dtype=float32), 'training/total_loss': Array(0.14660122, dtype=float32), 'training/v_loss': Array(0.12597677, dtype=float32), 'eval/episode_distance_from_origin': Array(6445.3623, dtype=float32), 'eval/episode_distance_reward': Array(29.607233, dtype=float32), 'eval/episode_forward_reward': Array(4934.5107, dtype=float32), 'eval/episode_reward': Array(4939.4316, dtype=float32), 'eval/episode_reward_alive': Array(382.23438, dtype=float32), 'eval/episode_reward_linvel': Array(4934.5107, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.92032, dtype=float32), 'eval/episode_x_position': Array(6391.4297, dtype=float32), 'eval/episode_x_velocity': Array(986.9022, dtype=float32), 'eval/episode_y_position': Array(-226.06534, dtype=float32), 'eval/episode_y_velocity': Array(-191.54388, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.8868, dtype=float32), 'eval/episode_distance_reward_std': Array(4.928116, dtype=float32), 'eval/episode_forward_reward_std': Array(821.3466, dtype=float32), 'eval/episode_reward_std': Array(813.6462, dtype=float32), 'eval/episode_reward_alive_std': Array(47.324795, dtype=float32), 'eval/episode_reward_linvel_std': Array(821.3466, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.828964, dtype=float32), 'eval/episode_x_position_std': Array(422.69193, dtype=float32), 'eval/episode_x_velocity_std': Array(164.26932, dtype=float32), 'eval/episode_y_position_std': Array(280.91147, dtype=float32), 'eval/episode_y_velocity_std': Array(82.280334, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7063329219818, 'eval/sps': 936.3136093559725, 'num_steps': 38174720}
{'eval/walltime': 63919.29837632179, 'training/sps': 2924.38091427244, 'training/walltime': 13009.120659351349, 'training/entropy_loss': Array(0.01540237, dtype=float32), 'training/policy_loss': Array(0.00328909, dtype=float32), 'training/total_loss': Array(0.20557705, dtype=float32), 'training/v_loss': Array(0.1868856, dtype=float32), 'eval/episode_distance_from_origin': Array(6483.7217, dtype=float32), 'eval/episode_distance_reward': Array(30.324692, dtype=float32), 'eval/episode_forward_reward': Array(5054.086, dtype=float32), 'eval/episode_reward': Array(5069.1924, dtype=float32), 'eval/episode_reward_alive': Array(389.20312, dtype=float32), 'eval/episode_reward_linvel': Array(5054.086, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.42133, dtype=float32), 'eval/episode_x_position': Array(6432.7397, dtype=float32), 'eval/episode_x_velocity': Array(1010.81714, dtype=float32), 'eval/episode_y_position': Array(-152.1634, dtype=float32), 'eval/episode_y_velocity': Array(-168.15874, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.4201, dtype=float32), 'eval/episode_distance_reward_std': Array(4.551212, dtype=float32), 'eval/episode_forward_reward_std': Array(758.52966, dtype=float32), 'eval/episode_reward_std': Array(763.5136, dtype=float32), 'eval/episode_reward_alive_std': Array(36.648266, dtype=float32), 'eval/episode_reward_linvel_std': Array(758.52966, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.59326, dtype=float32), 'eval/episode_x_position_std': Array(441.82028, dtype=float32), 'eval/episode_x_velocity_std': Array(151.70587, dtype=float32), 'eval/episode_y_position_std': Array(310.00253, dtype=float32), 'eval/episode_y_velocity_std': Array(98.62613, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.82887983322144, 'eval/sps': 935.4750265880798, 'num_steps': 38256640}
{'eval/walltime': 64056.215973854065, 'training/sps': 2931.398888363444, 'training/walltime': 13037.066361427307, 'training/entropy_loss': Array(0.01518262, dtype=float32), 'training/policy_loss': Array(0.00416883, dtype=float32), 'training/total_loss': Array(0.20115149, dtype=float32), 'training/v_loss': Array(0.18180004, dtype=float32), 'eval/episode_distance_from_origin': Array(6446.3936, dtype=float32), 'eval/episode_distance_reward': Array(29.656206, dtype=float32), 'eval/episode_forward_reward': Array(4942.6724, dtype=float32), 'eval/episode_reward': Array(4948.483, dtype=float32), 'eval/episode_reward_alive': Array(389.32812, dtype=float32), 'eval/episode_reward_linvel': Array(4942.6724, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.17352, dtype=float32), 'eval/episode_x_position': Array(6391.57, dtype=float32), 'eval/episode_x_velocity': Array(988.5344, dtype=float32), 'eval/episode_y_position': Array(-190.82047, dtype=float32), 'eval/episode_y_velocity': Array(-177.33217, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.94656, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0295386, dtype=float32), 'eval/episode_forward_reward_std': Array(838.2503, dtype=float32), 'eval/episode_reward_std': Array(846.9181, dtype=float32), 'eval/episode_reward_alive_std': Array(39.6334, dtype=float32), 'eval/episode_reward_linvel_std': Array(838.2503, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.904938, dtype=float32), 'eval/episode_x_position_std': Array(420.98914, dtype=float32), 'eval/episode_x_velocity_std': Array(167.65001, dtype=float32), 'eval/episode_y_position_std': Array(355.00696, dtype=float32), 'eval/episode_y_velocity_std': Array(105.62986, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.91759753227234, 'eval/sps': 934.8688722779378, 'num_steps': 38338560}
{'eval/walltime': 64193.23120236397, 'training/sps': 2946.0690910421936, 'training/walltime': 13064.872905492783, 'training/entropy_loss': Array(0.01318199, dtype=float32), 'training/policy_loss': Array(0.00667064, dtype=float32), 'training/total_loss': Array(0.19831997, dtype=float32), 'training/v_loss': Array(0.17846735, dtype=float32), 'eval/episode_distance_from_origin': Array(6468.6797, dtype=float32), 'eval/episode_distance_reward': Array(30.570686, dtype=float32), 'eval/episode_forward_reward': Array(5095.0845, dtype=float32), 'eval/episode_reward': Array(5112.501, dtype=float32), 'eval/episode_reward_alive': Array(393.8789, dtype=float32), 'eval/episode_reward_linvel': Array(5095.0845, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.03323, dtype=float32), 'eval/episode_x_position': Array(6415.2256, dtype=float32), 'eval/episode_x_velocity': Array(1019.01697, dtype=float32), 'eval/episode_y_position': Array(-202.06107, dtype=float32), 'eval/episode_y_velocity': Array(-184.25159, dtype=float32), 'eval/episode_distance_from_origin_std': Array(375.477, dtype=float32), 'eval/episode_distance_reward_std': Array(3.8235104, dtype=float32), 'eval/episode_forward_reward_std': Array(637.247, dtype=float32), 'eval/episode_reward_std': Array(639.2496, dtype=float32), 'eval/episode_reward_alive_std': Array(35.257908, dtype=float32), 'eval/episode_reward_linvel_std': Array(637.247, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.028484, dtype=float32), 'eval/episode_x_position_std': Array(377.0006, dtype=float32), 'eval/episode_x_velocity_std': Array(127.44953, dtype=float32), 'eval/episode_y_position_std': Array(322.16028, dtype=float32), 'eval/episode_y_velocity_std': Array(86.58617, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.01522850990295, 'eval/sps': 934.2027261644762, 'num_steps': 38420480}
{'eval/walltime': 64329.902752399445, 'training/sps': 2935.7313252914873, 'training/walltime': 13092.777366399765, 'training/entropy_loss': Array(0.01506049, dtype=float32), 'training/policy_loss': Array(0.00750586, dtype=float32), 'training/total_loss': Array(0.09082954, dtype=float32), 'training/v_loss': Array(0.06826319, dtype=float32), 'eval/episode_distance_from_origin': Array(6410.928, dtype=float32), 'eval/episode_distance_reward': Array(29.475418, dtype=float32), 'eval/episode_forward_reward': Array(4912.5425, dtype=float32), 'eval/episode_reward': Array(4929.959, dtype=float32), 'eval/episode_reward_alive': Array(399.53125, dtype=float32), 'eval/episode_reward_linvel': Array(4912.5425, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.58954, dtype=float32), 'eval/episode_x_position': Array(6358.235, dtype=float32), 'eval/episode_x_velocity': Array(982.5084, dtype=float32), 'eval/episode_y_position': Array(-186.79688, dtype=float32), 'eval/episode_y_velocity': Array(-173.08084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.1772, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7037616, dtype=float32), 'eval/episode_forward_reward_std': Array(950.6211, dtype=float32), 'eval/episode_reward_std': Array(952.8164, dtype=float32), 'eval/episode_reward_alive_std': Array(39.360153, dtype=float32), 'eval/episode_reward_linvel_std': Array(950.6211, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.831491, dtype=float32), 'eval/episode_x_position_std': Array(481.8599, dtype=float32), 'eval/episode_x_velocity_std': Array(190.12424, dtype=float32), 'eval/episode_y_position_std': Array(307.61212, dtype=float32), 'eval/episode_y_velocity_std': Array(96.43106, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67155003547668, 'eval/sps': 936.5519010121291, 'num_steps': 38502400}
{'eval/walltime': 64466.90661621094, 'training/sps': 2945.7063241144197, 'training/walltime': 13120.587334871292, 'training/entropy_loss': Array(0.01756342, dtype=float32), 'training/policy_loss': Array(0.01050202, dtype=float32), 'training/total_loss': Array(0.16849892, dtype=float32), 'training/v_loss': Array(0.14043349, dtype=float32), 'eval/episode_distance_from_origin': Array(6529.976, dtype=float32), 'eval/episode_distance_reward': Array(30.893051, dtype=float32), 'eval/episode_forward_reward': Array(5148.8125, dtype=float32), 'eval/episode_reward': Array(5153.758, dtype=float32), 'eval/episode_reward_alive': Array(381.01953, dtype=float32), 'eval/episode_reward_linvel': Array(5148.8125, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.96674, dtype=float32), 'eval/episode_x_position': Array(6476.9834, dtype=float32), 'eval/episode_x_velocity': Array(1029.7623, dtype=float32), 'eval/episode_y_position': Array(-183.57365, dtype=float32), 'eval/episode_y_velocity': Array(-180.85458, dtype=float32), 'eval/episode_distance_from_origin_std': Array(423.6368, dtype=float32), 'eval/episode_distance_reward_std': Array(4.663843, dtype=float32), 'eval/episode_forward_reward_std': Array(777.3018, dtype=float32), 'eval/episode_reward_std': Array(786.7864, dtype=float32), 'eval/episode_reward_alive_std': Array(39.368324, dtype=float32), 'eval/episode_reward_linvel_std': Array(777.3018, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.778336, dtype=float32), 'eval/episode_x_position_std': Array(425.855, dtype=float32), 'eval/episode_x_velocity_std': Array(155.4604, dtype=float32), 'eval/episode_y_position_std': Array(331.11493, dtype=float32), 'eval/episode_y_velocity_std': Array(99.748665, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.00386381149292, 'eval/sps': 934.2802198346642, 'num_steps': 38584320}
{'eval/walltime': 64603.56566119194, 'training/sps': 2928.4229654064025, 'training/walltime': 13148.561435937881, 'training/entropy_loss': Array(0.01533887, dtype=float32), 'training/policy_loss': Array(0.00841578, dtype=float32), 'training/total_loss': Array(0.13966754, dtype=float32), 'training/v_loss': Array(0.11591288, dtype=float32), 'eval/episode_distance_from_origin': Array(6475.2065, dtype=float32), 'eval/episode_distance_reward': Array(30.048538, dtype=float32), 'eval/episode_forward_reward': Array(5008.0605, dtype=float32), 'eval/episode_reward': Array(5008.8613, dtype=float32), 'eval/episode_reward_alive': Array(383.6211, dtype=float32), 'eval/episode_reward_linvel': Array(5008.0605, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.86853, dtype=float32), 'eval/episode_x_position': Array(6425.0293, dtype=float32), 'eval/episode_x_velocity': Array(1001.6121, dtype=float32), 'eval/episode_y_position': Array(-156.27893, dtype=float32), 'eval/episode_y_velocity': Array(-170.60245, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.02786, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8637724, dtype=float32), 'eval/episode_forward_reward_std': Array(810.6228, dtype=float32), 'eval/episode_reward_std': Array(810.8259, dtype=float32), 'eval/episode_reward_alive_std': Array(45.690052, dtype=float32), 'eval/episode_reward_linvel_std': Array(810.6228, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.074436, dtype=float32), 'eval/episode_x_position_std': Array(435.40158, dtype=float32), 'eval/episode_x_velocity_std': Array(162.12453, dtype=float32), 'eval/episode_y_position_std': Array(307.20712, dtype=float32), 'eval/episode_y_velocity_std': Array(100.32876, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6590449810028, 'eval/sps': 936.6376006637064, 'num_steps': 38666240}
{'eval/walltime': 64740.41708922386, 'training/sps': 2935.889684010846, 'training/walltime': 13176.464391708374, 'training/entropy_loss': Array(0.01598803, dtype=float32), 'training/policy_loss': Array(0.01006208, dtype=float32), 'training/total_loss': Array(0.18206641, dtype=float32), 'training/v_loss': Array(0.15601629, dtype=float32), 'eval/episode_distance_from_origin': Array(6532.4336, dtype=float32), 'eval/episode_distance_reward': Array(30.782505, dtype=float32), 'eval/episode_forward_reward': Array(5130.388, dtype=float32), 'eval/episode_reward': Array(5132.591, dtype=float32), 'eval/episode_reward_alive': Array(379.76172, dtype=float32), 'eval/episode_reward_linvel': Array(5130.388, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.34195, dtype=float32), 'eval/episode_x_position': Array(6478.397, dtype=float32), 'eval/episode_x_velocity': Array(1026.0776, dtype=float32), 'eval/episode_y_position': Array(-106.84717, dtype=float32), 'eval/episode_y_velocity': Array(-158.86035, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.55426, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2730846, dtype=float32), 'eval/episode_forward_reward_std': Array(712.1758, dtype=float32), 'eval/episode_reward_std': Array(711.6833, dtype=float32), 'eval/episode_reward_alive_std': Array(43.088886, dtype=float32), 'eval/episode_reward_linvel_std': Array(712.1758, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.008291, dtype=float32), 'eval/episode_x_position_std': Array(399.21133, dtype=float32), 'eval/episode_x_velocity_std': Array(142.43507, dtype=float32), 'eval/episode_y_position_std': Array(390.14603, dtype=float32), 'eval/episode_y_velocity_std': Array(117.28854, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8514280319214, 'eval/sps': 935.3208939123621, 'num_steps': 38748160}
{'eval/walltime': 64877.138451337814, 'training/sps': 2938.491262420351, 'training/walltime': 13204.342643737793, 'training/entropy_loss': Array(0.01571837, dtype=float32), 'training/policy_loss': Array(0.00716349, dtype=float32), 'training/total_loss': Array(0.21967882, dtype=float32), 'training/v_loss': Array(0.19679695, dtype=float32), 'eval/episode_distance_from_origin': Array(6532.869, dtype=float32), 'eval/episode_distance_reward': Array(30.782543, dtype=float32), 'eval/episode_forward_reward': Array(5130.395, dtype=float32), 'eval/episode_reward': Array(5134.1807, dtype=float32), 'eval/episode_reward_alive': Array(384.21094, dtype=float32), 'eval/episode_reward_linvel': Array(5130.395, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.2072, dtype=float32), 'eval/episode_x_position': Array(6482.6084, dtype=float32), 'eval/episode_x_velocity': Array(1026.079, dtype=float32), 'eval/episode_y_position': Array(-99.130936, dtype=float32), 'eval/episode_y_velocity': Array(-159.51337, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.13773, dtype=float32), 'eval/episode_distance_reward_std': Array(5.347803, dtype=float32), 'eval/episode_forward_reward_std': Array(891.295, dtype=float32), 'eval/episode_reward_std': Array(892.0382, dtype=float32), 'eval/episode_reward_alive_std': Array(43.07622, dtype=float32), 'eval/episode_reward_linvel_std': Array(891.295, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.425262, dtype=float32), 'eval/episode_x_position_std': Array(478.6949, dtype=float32), 'eval/episode_x_velocity_std': Array(178.25891, dtype=float32), 'eval/episode_y_position_std': Array(333.93912, dtype=float32), 'eval/episode_y_velocity_std': Array(101.64319, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.72136211395264, 'eval/sps': 936.2106844233773, 'num_steps': 38830080}
{'eval/walltime': 65013.8327255249, 'training/sps': 2937.070173944946, 'training/walltime': 13232.234384536743, 'training/entropy_loss': Array(0.01619307, dtype=float32), 'training/policy_loss': Array(0.01028993, dtype=float32), 'training/total_loss': Array(0.23371343, dtype=float32), 'training/v_loss': Array(0.20723042, dtype=float32), 'eval/episode_distance_from_origin': Array(6530.53, dtype=float32), 'eval/episode_distance_reward': Array(31.171478, dtype=float32), 'eval/episode_forward_reward': Array(5195.2163, dtype=float32), 'eval/episode_reward': Array(5195.503, dtype=float32), 'eval/episode_reward_alive': Array(378.40234, dtype=float32), 'eval/episode_reward_linvel': Array(5195.2163, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.28683, dtype=float32), 'eval/episode_x_position': Array(6479.8633, dtype=float32), 'eval/episode_x_velocity': Array(1039.0433, dtype=float32), 'eval/episode_y_position': Array(-130.5761, dtype=float32), 'eval/episode_y_velocity': Array(-162.10559, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.75577, dtype=float32), 'eval/episode_distance_reward_std': Array(5.293243, dtype=float32), 'eval/episode_forward_reward_std': Array(882.2009, dtype=float32), 'eval/episode_reward_std': Array(878.0251, dtype=float32), 'eval/episode_reward_alive_std': Array(39.901493, dtype=float32), 'eval/episode_reward_linvel_std': Array(882.2009, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.53915, dtype=float32), 'eval/episode_x_position_std': Array(472.4243, dtype=float32), 'eval/episode_x_velocity_std': Array(176.44026, dtype=float32), 'eval/episode_y_position_std': Array(341.89883, dtype=float32), 'eval/episode_y_velocity_std': Array(103.99765, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.694274187088, 'eval/sps': 936.3962079699951, 'num_steps': 38912000}
{'eval/walltime': 65150.4424738884, 'training/sps': 2933.2613564477, 'training/walltime': 13260.16234254837, 'training/entropy_loss': Array(0.01468239, dtype=float32), 'training/policy_loss': Array(0.00859311, dtype=float32), 'training/total_loss': Array(0.09426905, dtype=float32), 'training/v_loss': Array(0.07099356, dtype=float32), 'eval/episode_distance_from_origin': Array(6452.9277, dtype=float32), 'eval/episode_distance_reward': Array(29.967556, dtype=float32), 'eval/episode_forward_reward': Array(4994.564, dtype=float32), 'eval/episode_reward': Array(4987.9014, dtype=float32), 'eval/episode_reward_alive': Array(376.1172, dtype=float32), 'eval/episode_reward_linvel': Array(4994.564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.74707, dtype=float32), 'eval/episode_x_position': Array(6397.737, dtype=float32), 'eval/episode_x_velocity': Array(998.9127, dtype=float32), 'eval/episode_y_position': Array(-242.94196, dtype=float32), 'eval/episode_y_velocity': Array(-188.63892, dtype=float32), 'eval/episode_distance_from_origin_std': Array(397.5496, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6776943, dtype=float32), 'eval/episode_forward_reward_std': Array(779.6097, dtype=float32), 'eval/episode_reward_std': Array(781.64136, dtype=float32), 'eval/episode_reward_alive_std': Array(44.74378, dtype=float32), 'eval/episode_reward_linvel_std': Array(779.6097, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.21434, dtype=float32), 'eval/episode_x_position_std': Array(400.89938, dtype=float32), 'eval/episode_x_velocity_std': Array(155.92198, dtype=float32), 'eval/episode_y_position_std': Array(322.0294, dtype=float32), 'eval/episode_y_velocity_std': Array(91.09023, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60974836349487, 'eval/sps': 936.9755931283481, 'num_steps': 38993920}
{'eval/walltime': 65287.327073812485, 'training/sps': 2944.3609798966227, 'training/walltime': 13287.985018014908, 'training/entropy_loss': Array(0.01642764, dtype=float32), 'training/policy_loss': Array(0.01314346, dtype=float32), 'training/total_loss': Array(0.16111083, dtype=float32), 'training/v_loss': Array(0.13153973, dtype=float32), 'eval/episode_distance_from_origin': Array(6541.334, dtype=float32), 'eval/episode_distance_reward': Array(30.97543, dtype=float32), 'eval/episode_forward_reward': Array(5162.541, dtype=float32), 'eval/episode_reward': Array(5155.1377, dtype=float32), 'eval/episode_reward_alive': Array(372.01562, dtype=float32), 'eval/episode_reward_linvel': Array(5162.541, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.3945, dtype=float32), 'eval/episode_x_position': Array(6489.8633, dtype=float32), 'eval/episode_x_velocity': Array(1032.5082, dtype=float32), 'eval/episode_y_position': Array(-184.06665, dtype=float32), 'eval/episode_y_velocity': Array(-171.17886, dtype=float32), 'eval/episode_distance_from_origin_std': Array(432.37973, dtype=float32), 'eval/episode_distance_reward_std': Array(4.79544, dtype=float32), 'eval/episode_forward_reward_std': Array(799.2357, dtype=float32), 'eval/episode_reward_std': Array(802.87384, dtype=float32), 'eval/episode_reward_alive_std': Array(49.20774, dtype=float32), 'eval/episode_reward_linvel_std': Array(799.2357, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.37816, dtype=float32), 'eval/episode_x_position_std': Array(435.52744, dtype=float32), 'eval/episode_x_velocity_std': Array(159.84706, dtype=float32), 'eval/episode_y_position_std': Array(329.26337, dtype=float32), 'eval/episode_y_velocity_std': Array(105.847664, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.88459992408752, 'eval/sps': 935.0942331787894, 'num_steps': 39075840}
{'eval/walltime': 65423.93208909035, 'training/sps': 2933.4642276211407, 'training/walltime': 13315.911044597626, 'training/entropy_loss': Array(0.01498433, dtype=float32), 'training/policy_loss': Array(0.00605653, dtype=float32), 'training/total_loss': Array(0.13450508, dtype=float32), 'training/v_loss': Array(0.11346422, dtype=float32), 'eval/episode_distance_from_origin': Array(6523.1094, dtype=float32), 'eval/episode_distance_reward': Array(30.580765, dtype=float32), 'eval/episode_forward_reward': Array(5096.764, dtype=float32), 'eval/episode_reward': Array(5082.7007, dtype=float32), 'eval/episode_reward_alive': Array(372.98047, dtype=float32), 'eval/episode_reward_linvel': Array(5096.764, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.625, dtype=float32), 'eval/episode_x_position': Array(6471.1074, dtype=float32), 'eval/episode_x_velocity': Array(1019.35284, dtype=float32), 'eval/episode_y_position': Array(-230.39313, dtype=float32), 'eval/episode_y_velocity': Array(-182.298, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.95294, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1832404, dtype=float32), 'eval/episode_forward_reward_std': Array(863.86707, dtype=float32), 'eval/episode_reward_std': Array(869.0937, dtype=float32), 'eval/episode_reward_alive_std': Array(43.66104, dtype=float32), 'eval/episode_reward_linvel_std': Array(863.86707, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.61909, dtype=float32), 'eval/episode_x_position_std': Array(473.99823, dtype=float32), 'eval/episode_x_velocity_std': Array(172.77336, dtype=float32), 'eval/episode_y_position_std': Array(299.5182, dtype=float32), 'eval/episode_y_velocity_std': Array(92.48203, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60501527786255, 'eval/sps': 937.0080574248358, 'num_steps': 39157760}
{'eval/walltime': 65560.64739513397, 'training/sps': 2933.7726325290646, 'training/walltime': 13343.83413553238, 'training/entropy_loss': Array(0.0160711, dtype=float32), 'training/policy_loss': Array(0.00645835, dtype=float32), 'training/total_loss': Array(0.16422017, dtype=float32), 'training/v_loss': Array(0.14169072, dtype=float32), 'eval/episode_distance_from_origin': Array(6527.1924, dtype=float32), 'eval/episode_distance_reward': Array(31.134739, dtype=float32), 'eval/episode_forward_reward': Array(5189.0938, dtype=float32), 'eval/episode_reward': Array(5177.473, dtype=float32), 'eval/episode_reward_alive': Array(366.6211, dtype=float32), 'eval/episode_reward_linvel': Array(5189.0938, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.37662, dtype=float32), 'eval/episode_x_position': Array(6474.3945, dtype=float32), 'eval/episode_x_velocity': Array(1037.8188, dtype=float32), 'eval/episode_y_position': Array(-182.84436, dtype=float32), 'eval/episode_y_velocity': Array(-178.71664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(413.5019, dtype=float32), 'eval/episode_distance_reward_std': Array(4.602904, dtype=float32), 'eval/episode_forward_reward_std': Array(767.14465, dtype=float32), 'eval/episode_reward_std': Array(776.2169, dtype=float32), 'eval/episode_reward_alive_std': Array(44.80835, dtype=float32), 'eval/episode_reward_linvel_std': Array(767.14465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.903658, dtype=float32), 'eval/episode_x_position_std': Array(420.01965, dtype=float32), 'eval/episode_x_velocity_std': Array(153.4292, dtype=float32), 'eval/episode_y_position_std': Array(322.06223, dtype=float32), 'eval/episode_y_velocity_std': Array(91.94198, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.71530604362488, 'eval/sps': 936.2521556961304, 'num_steps': 39239680}
{'eval/walltime': 65697.32749843597, 'training/sps': 2924.1211645212284, 'training/walltime': 13371.849390506744, 'training/entropy_loss': Array(0.01583423, dtype=float32), 'training/policy_loss': Array(0.06195794, dtype=float32), 'training/total_loss': Array(0.25817573, dtype=float32), 'training/v_loss': Array(0.18038356, dtype=float32), 'eval/episode_distance_from_origin': Array(6649.678, dtype=float32), 'eval/episode_distance_reward': Array(31.904875, dtype=float32), 'eval/episode_forward_reward': Array(5317.448, dtype=float32), 'eval/episode_reward': Array(5309.786, dtype=float32), 'eval/episode_reward_alive': Array(371.64844, dtype=float32), 'eval/episode_reward_linvel': Array(5317.448, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.21524, dtype=float32), 'eval/episode_x_position': Array(6600.6655, dtype=float32), 'eval/episode_x_velocity': Array(1063.4896, dtype=float32), 'eval/episode_y_position': Array(-172.55872, dtype=float32), 'eval/episode_y_velocity': Array(-170.45262, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.64948, dtype=float32), 'eval/episode_distance_reward_std': Array(4.763141, dtype=float32), 'eval/episode_forward_reward_std': Array(793.8512, dtype=float32), 'eval/episode_reward_std': Array(788.6563, dtype=float32), 'eval/episode_reward_alive_std': Array(41.25593, dtype=float32), 'eval/episode_reward_linvel_std': Array(793.8512, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(15.341946, dtype=float32), 'eval/episode_x_position_std': Array(425.57437, dtype=float32), 'eval/episode_x_velocity_std': Array(158.77025, dtype=float32), 'eval/episode_y_position_std': Array(285.9432, dtype=float32), 'eval/episode_y_velocity_std': Array(89.25784, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.68010330200195, 'eval/sps': 936.4932927887623, 'num_steps': 39321600}
{'eval/walltime': 65834.21051740646, 'training/sps': 2949.5325614564167, 'training/walltime': 13399.623282909393, 'training/entropy_loss': Array(0.01601385, dtype=float32), 'training/policy_loss': Array(0.01062187, dtype=float32), 'training/total_loss': Array(0.24655364, dtype=float32), 'training/v_loss': Array(0.21991792, dtype=float32), 'eval/episode_distance_from_origin': Array(6715.661, dtype=float32), 'eval/episode_distance_reward': Array(32.76758, dtype=float32), 'eval/episode_forward_reward': Array(5461.2324, dtype=float32), 'eval/episode_reward': Array(5452.5, dtype=float32), 'eval/episode_reward_alive': Array(367.33594, dtype=float32), 'eval/episode_reward_linvel': Array(5461.2324, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.8354, dtype=float32), 'eval/episode_x_position': Array(6665.5, dtype=float32), 'eval/episode_x_velocity': Array(1092.2466, dtype=float32), 'eval/episode_y_position': Array(-115.636215, dtype=float32), 'eval/episode_y_velocity': Array(-167.25362, dtype=float32), 'eval/episode_distance_from_origin_std': Array(380.95944, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3721547, dtype=float32), 'eval/episode_forward_reward_std': Array(728.68665, dtype=float32), 'eval/episode_reward_std': Array(727.756, dtype=float32), 'eval/episode_reward_alive_std': Array(43.644207, dtype=float32), 'eval/episode_reward_linvel_std': Array(728.68665, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.125938, dtype=float32), 'eval/episode_x_position_std': Array(384.86945, dtype=float32), 'eval/episode_x_velocity_std': Array(145.73738, dtype=float32), 'eval/episode_y_position_std': Array(328.71808, dtype=float32), 'eval/episode_y_velocity_std': Array(107.56162, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8830189704895, 'eval/sps': 935.1050332079205, 'num_steps': 39403520}
{'eval/walltime': 65970.93383431435, 'training/sps': 2936.353319488954, 'training/walltime': 13427.521832942963, 'training/entropy_loss': Array(0.01232392, dtype=float32), 'training/policy_loss': Array(0.00333926, dtype=float32), 'training/total_loss': Array(0.10681415, dtype=float32), 'training/v_loss': Array(0.09115098, dtype=float32), 'eval/episode_distance_from_origin': Array(6715.267, dtype=float32), 'eval/episode_distance_reward': Array(32.53547, dtype=float32), 'eval/episode_forward_reward': Array(5422.546, dtype=float32), 'eval/episode_reward': Array(5415.687, dtype=float32), 'eval/episode_reward_alive': Array(371.3711, dtype=float32), 'eval/episode_reward_linvel': Array(5422.546, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.76578, dtype=float32), 'eval/episode_x_position': Array(6664.114, dtype=float32), 'eval/episode_x_velocity': Array(1084.5093, dtype=float32), 'eval/episode_y_position': Array(-93.9787, dtype=float32), 'eval/episode_y_velocity': Array(-147.09956, dtype=float32), 'eval/episode_distance_from_origin_std': Array(375.89087, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4341974, dtype=float32), 'eval/episode_forward_reward_std': Array(739.0279, dtype=float32), 'eval/episode_reward_std': Array(737.69507, dtype=float32), 'eval/episode_reward_alive_std': Array(45.421, dtype=float32), 'eval/episode_reward_linvel_std': Array(739.0279, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.35695, dtype=float32), 'eval/episode_x_position_std': Array(380.34412, dtype=float32), 'eval/episode_x_velocity_std': Array(147.80556, dtype=float32), 'eval/episode_y_position_std': Array(375.18842, dtype=float32), 'eval/episode_y_velocity_std': Array(111.03401, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7233169078827, 'eval/sps': 936.1972990037974, 'num_steps': 39485440}
{'eval/walltime': 66107.74419641495, 'training/sps': 2934.937531608369, 'training/walltime': 13455.433840990067, 'training/entropy_loss': Array(0.01789051, dtype=float32), 'training/policy_loss': Array(0.00687369, dtype=float32), 'training/total_loss': Array(0.13913709, dtype=float32), 'training/v_loss': Array(0.11437288, dtype=float32), 'eval/episode_distance_from_origin': Array(6769.2036, dtype=float32), 'eval/episode_distance_reward': Array(32.900185, dtype=float32), 'eval/episode_forward_reward': Array(5483.333, dtype=float32), 'eval/episode_reward': Array(5475.0757, dtype=float32), 'eval/episode_reward_alive': Array(368.57812, dtype=float32), 'eval/episode_reward_linvel': Array(5483.333, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.73547, dtype=float32), 'eval/episode_x_position': Array(6720.696, dtype=float32), 'eval/episode_x_velocity': Array(1096.6665, dtype=float32), 'eval/episode_y_position': Array(-108.63475, dtype=float32), 'eval/episode_y_velocity': Array(-157.08424, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.46402, dtype=float32), 'eval/episode_distance_reward_std': Array(4.59712, dtype=float32), 'eval/episode_forward_reward_std': Array(766.18134, dtype=float32), 'eval/episode_reward_std': Array(767.30457, dtype=float32), 'eval/episode_reward_alive_std': Array(45.678364, dtype=float32), 'eval/episode_reward_linvel_std': Array(766.18134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.43946, dtype=float32), 'eval/episode_x_position_std': Array(428.48593, dtype=float32), 'eval/episode_x_velocity_std': Array(153.23624, dtype=float32), 'eval/episode_y_position_std': Array(322.3185, dtype=float32), 'eval/episode_y_velocity_std': Array(98.50986, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8103621006012, 'eval/sps': 935.6016462106676, 'num_steps': 39567360}
{'eval/walltime': 66244.3517203331, 'training/sps': 2942.425405265666, 'training/walltime': 13483.274818658829, 'training/entropy_loss': Array(0.0162437, dtype=float32), 'training/policy_loss': Array(0.00740338, dtype=float32), 'training/total_loss': Array(0.17297032, dtype=float32), 'training/v_loss': Array(0.14932324, dtype=float32), 'eval/episode_distance_from_origin': Array(6705.9785, dtype=float32), 'eval/episode_distance_reward': Array(32.27097, dtype=float32), 'eval/episode_forward_reward': Array(5378.4634, dtype=float32), 'eval/episode_reward': Array(5368.1973, dtype=float32), 'eval/episode_reward_alive': Array(369.90625, dtype=float32), 'eval/episode_reward_linvel': Array(5378.4634, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.4433, dtype=float32), 'eval/episode_x_position': Array(6655.497, dtype=float32), 'eval/episode_x_velocity': Array(1075.6927, dtype=float32), 'eval/episode_y_position': Array(-106.13846, dtype=float32), 'eval/episode_y_velocity': Array(-151.19719, dtype=float32), 'eval/episode_distance_from_origin_std': Array(392.85916, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5111437, dtype=float32), 'eval/episode_forward_reward_std': Array(751.85205, dtype=float32), 'eval/episode_reward_std': Array(755.33765, dtype=float32), 'eval/episode_reward_alive_std': Array(45.233456, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.85205, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.950893, dtype=float32), 'eval/episode_x_position_std': Array(399.11606, dtype=float32), 'eval/episode_x_velocity_std': Array(150.3704, dtype=float32), 'eval/episode_y_position_std': Array(370.32886, dtype=float32), 'eval/episode_y_velocity_std': Array(119.79503, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60752391815186, 'eval/sps': 936.9908503479718, 'num_steps': 39649280}
{'eval/walltime': 66381.22242951393, 'training/sps': 2947.3073841471637, 'training/walltime': 13511.06967997551, 'training/entropy_loss': Array(0.01690696, dtype=float32), 'training/policy_loss': Array(0.0061651, dtype=float32), 'training/total_loss': Array(0.20568165, dtype=float32), 'training/v_loss': Array(0.1826096, dtype=float32), 'eval/episode_distance_from_origin': Array(6689.718, dtype=float32), 'eval/episode_distance_reward': Array(31.645891, dtype=float32), 'eval/episode_forward_reward': Array(5274.285, dtype=float32), 'eval/episode_reward': Array(5258.5977, dtype=float32), 'eval/episode_reward_alive': Array(362.35156, dtype=float32), 'eval/episode_reward_linvel': Array(5274.285, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.6844, dtype=float32), 'eval/episode_x_position': Array(6637.3564, dtype=float32), 'eval/episode_x_velocity': Array(1054.8568, dtype=float32), 'eval/episode_y_position': Array(-214.24365, dtype=float32), 'eval/episode_y_velocity': Array(-176.32857, dtype=float32), 'eval/episode_distance_from_origin_std': Array(438.28302, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7179713, dtype=float32), 'eval/episode_forward_reward_std': Array(786.3222, dtype=float32), 'eval/episode_reward_std': Array(786.385, dtype=float32), 'eval/episode_reward_alive_std': Array(46.47909, dtype=float32), 'eval/episode_reward_linvel_std': Array(786.3222, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.36825, dtype=float32), 'eval/episode_x_position_std': Array(440.53043, dtype=float32), 'eval/episode_x_velocity_std': Array(157.26447, dtype=float32), 'eval/episode_y_position_std': Array(332.64853, dtype=float32), 'eval/episode_y_velocity_std': Array(98.12081, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8707091808319, 'eval/sps': 935.1891340819164, 'num_steps': 39731200}
{'eval/walltime': 66517.84750461578, 'training/sps': 2935.414483552989, 'training/walltime': 13538.977152824402, 'training/entropy_loss': Array(0.01618419, dtype=float32), 'training/policy_loss': Array(0.00583325, dtype=float32), 'training/total_loss': Array(0.24247083, dtype=float32), 'training/v_loss': Array(0.2204534, dtype=float32), 'eval/episode_distance_from_origin': Array(6742.3315, dtype=float32), 'eval/episode_distance_reward': Array(32.478607, dtype=float32), 'eval/episode_forward_reward': Array(5413.071, dtype=float32), 'eval/episode_reward': Array(5394.2285, dtype=float32), 'eval/episode_reward_alive': Array(356.78125, dtype=float32), 'eval/episode_reward_linvel': Array(5413.071, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.10208, dtype=float32), 'eval/episode_x_position': Array(6690.497, dtype=float32), 'eval/episode_x_velocity': Array(1082.6141, dtype=float32), 'eval/episode_y_position': Array(-222.97118, dtype=float32), 'eval/episode_y_velocity': Array(-177.62653, dtype=float32), 'eval/episode_distance_from_origin_std': Array(392.8656, dtype=float32), 'eval/episode_distance_reward_std': Array(4.488781, dtype=float32), 'eval/episode_forward_reward_std': Array(748.1242, dtype=float32), 'eval/episode_reward_std': Array(746.8415, dtype=float32), 'eval/episode_reward_alive_std': Array(51.24671, dtype=float32), 'eval/episode_reward_linvel_std': Array(748.1242, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.865934, dtype=float32), 'eval/episode_x_position_std': Array(396.468, dtype=float32), 'eval/episode_x_velocity_std': Array(149.62482, dtype=float32), 'eval/episode_y_position_std': Array(315.15942, dtype=float32), 'eval/episode_y_velocity_std': Array(92.90418, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62507510185242, 'eval/sps': 936.8704822637973, 'num_steps': 39813120}
{'eval/walltime': 66654.61073875427, 'training/sps': 2940.2901648641637, 'training/walltime': 13566.83834862709, 'training/entropy_loss': Array(0.01645112, dtype=float32), 'training/policy_loss': Array(0.00528228, dtype=float32), 'training/total_loss': Array(0.25843498, dtype=float32), 'training/v_loss': Array(0.23670158, dtype=float32), 'eval/episode_distance_from_origin': Array(6817.284, dtype=float32), 'eval/episode_distance_reward': Array(33.00284, dtype=float32), 'eval/episode_forward_reward': Array(5500.442, dtype=float32), 'eval/episode_reward': Array(5480.5435, dtype=float32), 'eval/episode_reward_alive': Array(356.20312, dtype=float32), 'eval/episode_reward_linvel': Array(5500.442, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.1046, dtype=float32), 'eval/episode_x_position': Array(6768.3584, dtype=float32), 'eval/episode_x_velocity': Array(1100.0884, dtype=float32), 'eval/episode_y_position': Array(-224.89157, dtype=float32), 'eval/episode_y_velocity': Array(-170.34, dtype=float32), 'eval/episode_distance_from_origin_std': Array(427.02374, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5084796, dtype=float32), 'eval/episode_forward_reward_std': Array(751.40784, dtype=float32), 'eval/episode_reward_std': Array(744.61584, dtype=float32), 'eval/episode_reward_alive_std': Array(48.256046, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.40784, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.874792, dtype=float32), 'eval/episode_x_position_std': Array(429.88007, dtype=float32), 'eval/episode_x_velocity_std': Array(150.28151, dtype=float32), 'eval/episode_y_position_std': Array(288.62592, dtype=float32), 'eval/episode_y_velocity_std': Array(92.0177, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.76323413848877, 'eval/sps': 935.9240501024203, 'num_steps': 39895040}
{'eval/walltime': 66791.20020341873, 'training/sps': 2921.9116373177285, 'training/walltime': 13594.87478852272, 'training/entropy_loss': Array(0.01286583, dtype=float32), 'training/policy_loss': Array(0.00453564, dtype=float32), 'training/total_loss': Array(0.14668775, dtype=float32), 'training/v_loss': Array(0.12928626, dtype=float32), 'eval/episode_distance_from_origin': Array(6774.8164, dtype=float32), 'eval/episode_distance_reward': Array(32.450905, dtype=float32), 'eval/episode_forward_reward': Array(5408.453, dtype=float32), 'eval/episode_reward': Array(5376.13, dtype=float32), 'eval/episode_reward_alive': Array(349.45703, dtype=float32), 'eval/episode_reward_linvel': Array(5408.453, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.2309, dtype=float32), 'eval/episode_x_position': Array(6724.616, dtype=float32), 'eval/episode_x_velocity': Array(1081.6906, dtype=float32), 'eval/episode_y_position': Array(-248.89795, dtype=float32), 'eval/episode_y_velocity': Array(-184.90323, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.53467, dtype=float32), 'eval/episode_distance_reward_std': Array(4.656127, dtype=float32), 'eval/episode_forward_reward_std': Array(776.01556, dtype=float32), 'eval/episode_reward_std': Array(771.46295, dtype=float32), 'eval/episode_reward_alive_std': Array(53.896023, dtype=float32), 'eval/episode_reward_linvel_std': Array(776.01556, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.369785, dtype=float32), 'eval/episode_x_position_std': Array(423.17447, dtype=float32), 'eval/episode_x_velocity_std': Array(155.20317, dtype=float32), 'eval/episode_y_position_std': Array(262.9392, dtype=float32), 'eval/episode_y_velocity_std': Array(84.798416, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58946466445923, 'eval/sps': 937.1147351257302, 'num_steps': 39976960}
{'eval/walltime': 66927.84718942642, 'training/sps': 2939.828354127986, 'training/walltime': 13622.740360975266, 'training/entropy_loss': Array(0.01817251, dtype=float32), 'training/policy_loss': Array(0.00684323, dtype=float32), 'training/total_loss': Array(0.11932586, dtype=float32), 'training/v_loss': Array(0.09431011, dtype=float32), 'eval/episode_distance_from_origin': Array(6800.377, dtype=float32), 'eval/episode_distance_reward': Array(32.859116, dtype=float32), 'eval/episode_forward_reward': Array(5476.488, dtype=float32), 'eval/episode_reward': Array(5449.5615, dtype=float32), 'eval/episode_reward_alive': Array(353.33984, dtype=float32), 'eval/episode_reward_linvel': Array(5476.488, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.12497, dtype=float32), 'eval/episode_x_position': Array(6750.006, dtype=float32), 'eval/episode_x_velocity': Array(1095.2975, dtype=float32), 'eval/episode_y_position': Array(-209.3222, dtype=float32), 'eval/episode_y_velocity': Array(-169.2614, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.62204, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7110014, dtype=float32), 'eval/episode_forward_reward_std': Array(785.16156, dtype=float32), 'eval/episode_reward_std': Array(782.7984, dtype=float32), 'eval/episode_reward_alive_std': Array(51.083145, dtype=float32), 'eval/episode_reward_linvel_std': Array(785.16156, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.64523, dtype=float32), 'eval/episode_x_position_std': Array(428.78336, dtype=float32), 'eval/episode_x_velocity_std': Array(157.03223, dtype=float32), 'eval/episode_y_position_std': Array(319.55368, dtype=float32), 'eval/episode_y_velocity_std': Array(98.90039, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64698600769043, 'eval/sps': 936.7202580874797, 'num_steps': 40058880}
{'eval/walltime': 67064.53308272362, 'training/sps': 2919.16213257836, 'training/walltime': 13650.803207874298, 'training/entropy_loss': Array(0.01578646, dtype=float32), 'training/policy_loss': Array(0.00774712, dtype=float32), 'training/total_loss': Array(0.17278948, dtype=float32), 'training/v_loss': Array(0.1492559, dtype=float32), 'eval/episode_distance_from_origin': Array(6725.412, dtype=float32), 'eval/episode_distance_reward': Array(32.266815, dtype=float32), 'eval/episode_forward_reward': Array(5377.7715, dtype=float32), 'eval/episode_reward': Array(5363.21, dtype=float32), 'eval/episode_reward_alive': Array(363.5078, dtype=float32), 'eval/episode_reward_linvel': Array(5377.7715, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.33682, dtype=float32), 'eval/episode_x_position': Array(6672.7217, dtype=float32), 'eval/episode_x_velocity': Array(1075.5543, dtype=float32), 'eval/episode_y_position': Array(-232.06827, dtype=float32), 'eval/episode_y_velocity': Array(-181.18152, dtype=float32), 'eval/episode_distance_from_origin_std': Array(401.14514, dtype=float32), 'eval/episode_distance_reward_std': Array(4.575888, dtype=float32), 'eval/episode_forward_reward_std': Array(762.6427, dtype=float32), 'eval/episode_reward_std': Array(763.49554, dtype=float32), 'eval/episode_reward_alive_std': Array(49.46969, dtype=float32), 'eval/episode_reward_linvel_std': Array(762.6427, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.014715, dtype=float32), 'eval/episode_x_position_std': Array(404.8368, dtype=float32), 'eval/episode_x_velocity_std': Array(152.52844, dtype=float32), 'eval/episode_y_position_std': Array(322.79315, dtype=float32), 'eval/episode_y_velocity_std': Array(90.81185, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.68589329719543, 'eval/sps': 936.4536230647464, 'num_steps': 40140800}
{'eval/walltime': 67201.0845682621, 'training/sps': 2937.4947790249307, 'training/walltime': 13678.690917015076, 'training/entropy_loss': Array(0.01639896, dtype=float32), 'training/policy_loss': Array(0.00550028, dtype=float32), 'training/total_loss': Array(0.18460771, dtype=float32), 'training/v_loss': Array(0.16270846, dtype=float32), 'eval/episode_distance_from_origin': Array(6738.114, dtype=float32), 'eval/episode_distance_reward': Array(32.590767, dtype=float32), 'eval/episode_forward_reward': Array(5431.7627, dtype=float32), 'eval/episode_reward': Array(5415.812, dtype=float32), 'eval/episode_reward_alive': Array(361.16797, dtype=float32), 'eval/episode_reward_linvel': Array(5431.7627, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.70963, dtype=float32), 'eval/episode_x_position': Array(6686.8022, dtype=float32), 'eval/episode_x_velocity': Array(1086.3525, dtype=float32), 'eval/episode_y_position': Array(-157.68167, dtype=float32), 'eval/episode_y_velocity': Array(-168.71037, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.5537, dtype=float32), 'eval/episode_distance_reward_std': Array(5.530424, dtype=float32), 'eval/episode_forward_reward_std': Array(921.73145, dtype=float32), 'eval/episode_reward_std': Array(922.82733, dtype=float32), 'eval/episode_reward_alive_std': Array(50.737732, dtype=float32), 'eval/episode_reward_linvel_std': Array(921.73145, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.755407, dtype=float32), 'eval/episode_x_position_std': Array(489.5111, dtype=float32), 'eval/episode_x_velocity_std': Array(184.34631, dtype=float32), 'eval/episode_y_position_std': Array(351.49014, dtype=float32), 'eval/episode_y_velocity_std': Array(107.07441, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55148553848267, 'eval/sps': 937.3753752677212, 'num_steps': 40222720}
{'eval/walltime': 67337.5219078064, 'training/sps': 2935.737044269919, 'training/walltime': 13706.595323562622, 'training/entropy_loss': Array(0.01735266, dtype=float32), 'training/policy_loss': Array(0.00626723, dtype=float32), 'training/total_loss': Array(0.22443587, dtype=float32), 'training/v_loss': Array(0.20081598, dtype=float32), 'eval/episode_distance_from_origin': Array(6821.514, dtype=float32), 'eval/episode_distance_reward': Array(33.65776, dtype=float32), 'eval/episode_forward_reward': Array(5609.5957, dtype=float32), 'eval/episode_reward': Array(5605.1763, dtype=float32), 'eval/episode_reward_alive': Array(376.01172, dtype=float32), 'eval/episode_reward_linvel': Array(5609.5957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.08853, dtype=float32), 'eval/episode_x_position': Array(6772.0957, dtype=float32), 'eval/episode_x_velocity': Array(1121.919, dtype=float32), 'eval/episode_y_position': Array(-125.45801, dtype=float32), 'eval/episode_y_velocity': Array(-156.09248, dtype=float32), 'eval/episode_distance_from_origin_std': Array(401.13458, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7290535, dtype=float32), 'eval/episode_forward_reward_std': Array(788.1694, dtype=float32), 'eval/episode_reward_std': Array(786.5886, dtype=float32), 'eval/episode_reward_alive_std': Array(41.969364, dtype=float32), 'eval/episode_reward_linvel_std': Array(788.1694, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.000639, dtype=float32), 'eval/episode_x_position_std': Array(406.10736, dtype=float32), 'eval/episode_x_velocity_std': Array(157.63371, dtype=float32), 'eval/episode_y_position_std': Array(351.26346, dtype=float32), 'eval/episode_y_velocity_std': Array(101.57728, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43733954429626, 'eval/sps': 938.1596007920034, 'num_steps': 40304640}
{'eval/walltime': 67473.79177355766, 'training/sps': 2943.150673296241, 'training/walltime': 13734.429440498352, 'training/entropy_loss': Array(0.01736676, dtype=float32), 'training/policy_loss': Array(0.00492344, dtype=float32), 'training/total_loss': Array(0.25145394, dtype=float32), 'training/v_loss': Array(0.22916374, dtype=float32), 'eval/episode_distance_from_origin': Array(6746.3438, dtype=float32), 'eval/episode_distance_reward': Array(32.468414, dtype=float32), 'eval/episode_forward_reward': Array(5411.372, dtype=float32), 'eval/episode_reward': Array(5411.5444, dtype=float32), 'eval/episode_reward_alive': Array(379.95312, dtype=float32), 'eval/episode_reward_linvel': Array(5411.372, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.24847, dtype=float32), 'eval/episode_x_position': Array(6695.17, dtype=float32), 'eval/episode_x_velocity': Array(1082.2742, dtype=float32), 'eval/episode_y_position': Array(-160.57402, dtype=float32), 'eval/episode_y_velocity': Array(-166.112, dtype=float32), 'eval/episode_distance_from_origin_std': Array(437.25262, dtype=float32), 'eval/episode_distance_reward_std': Array(4.94904, dtype=float32), 'eval/episode_forward_reward_std': Array(824.83325, dtype=float32), 'eval/episode_reward_std': Array(826.5587, dtype=float32), 'eval/episode_reward_alive_std': Array(46.45299, dtype=float32), 'eval/episode_reward_linvel_std': Array(824.83325, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.326468, dtype=float32), 'eval/episode_x_position_std': Array(443.60593, dtype=float32), 'eval/episode_x_velocity_std': Array(164.96669, dtype=float32), 'eval/episode_y_position_std': Array(335.0964, dtype=float32), 'eval/episode_y_velocity_std': Array(104.3495, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26986575126648, 'eval/sps': 939.3125860536072, 'num_steps': 40386560}
{'eval/walltime': 67610.23885083199, 'training/sps': 2939.071989335775, 'training/walltime': 13762.30218410492, 'training/entropy_loss': Array(0.01500466, dtype=float32), 'training/policy_loss': Array(0.01132233, dtype=float32), 'training/total_loss': Array(0.1982392, dtype=float32), 'training/v_loss': Array(0.17191221, dtype=float32), 'eval/episode_distance_from_origin': Array(6836.911, dtype=float32), 'eval/episode_distance_reward': Array(33.527367, dtype=float32), 'eval/episode_forward_reward': Array(5587.8643, dtype=float32), 'eval/episode_reward': Array(5585.7124, dtype=float32), 'eval/episode_reward_alive': Array(375.71484, dtype=float32), 'eval/episode_reward_linvel': Array(5587.8643, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.39343, dtype=float32), 'eval/episode_x_position': Array(6789.7266, dtype=float32), 'eval/episode_x_velocity': Array(1117.5728, dtype=float32), 'eval/episode_y_position': Array(-109.06827, dtype=float32), 'eval/episode_y_velocity': Array(-147.63945, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.387, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4072065, dtype=float32), 'eval/episode_forward_reward_std': Array(734.5286, dtype=float32), 'eval/episode_reward_std': Array(731.93445, dtype=float32), 'eval/episode_reward_alive_std': Array(45.56669, dtype=float32), 'eval/episode_reward_linvel_std': Array(734.5286, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.122795, dtype=float32), 'eval/episode_x_position_std': Array(379.3358, dtype=float32), 'eval/episode_x_velocity_std': Array(146.90556, dtype=float32), 'eval/episode_y_position_std': Array(303.83472, dtype=float32), 'eval/episode_y_velocity_std': Array(104.61544, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4470772743225, 'eval/sps': 938.0926477645254, 'num_steps': 40468480}
{'eval/walltime': 67746.57676148415, 'training/sps': 2942.729144616549, 'training/walltime': 13790.140288114548, 'training/entropy_loss': Array(0.01584669, dtype=float32), 'training/policy_loss': Array(0.00808267, dtype=float32), 'training/total_loss': Array(0.10846761, dtype=float32), 'training/v_loss': Array(0.08453825, dtype=float32), 'eval/episode_distance_from_origin': Array(6880.817, dtype=float32), 'eval/episode_distance_reward': Array(33.803696, dtype=float32), 'eval/episode_forward_reward': Array(5633.917, dtype=float32), 'eval/episode_reward': Array(5622.7637, dtype=float32), 'eval/episode_reward_alive': Array(368.65234, dtype=float32), 'eval/episode_reward_linvel': Array(5633.917, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.60947, dtype=float32), 'eval/episode_x_position': Array(6832.3633, dtype=float32), 'eval/episode_x_velocity': Array(1126.7834, dtype=float32), 'eval/episode_y_position': Array(-153.37732, dtype=float32), 'eval/episode_y_velocity': Array(-150.33252, dtype=float32), 'eval/episode_distance_from_origin_std': Array(379.04764, dtype=float32), 'eval/episode_distance_reward_std': Array(4.672283, dtype=float32), 'eval/episode_forward_reward_std': Array(778.7076, dtype=float32), 'eval/episode_reward_std': Array(787.57416, dtype=float32), 'eval/episode_reward_alive_std': Array(45.854115, dtype=float32), 'eval/episode_reward_linvel_std': Array(778.7076, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.92325, dtype=float32), 'eval/episode_x_position_std': Array(382.66156, dtype=float32), 'eval/episode_x_velocity_std': Array(155.74156, dtype=float32), 'eval/episode_y_position_std': Array(348.03387, dtype=float32), 'eval/episode_y_velocity_std': Array(106.34941, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33791065216064, 'eval/sps': 938.843784445009, 'num_steps': 40550400}
{'eval/walltime': 67883.10347938538, 'training/sps': 2928.6872494146332, 'training/walltime': 13818.111864805222, 'training/entropy_loss': Array(0.01809785, dtype=float32), 'training/policy_loss': Array(0.00981807, dtype=float32), 'training/total_loss': Array(0.25042447, dtype=float32), 'training/v_loss': Array(0.22250856, dtype=float32), 'eval/episode_distance_from_origin': Array(6843.9434, dtype=float32), 'eval/episode_distance_reward': Array(33.407005, dtype=float32), 'eval/episode_forward_reward': Array(5567.8037, dtype=float32), 'eval/episode_reward': Array(5561.869, dtype=float32), 'eval/episode_reward_alive': Array(374.4922, dtype=float32), 'eval/episode_reward_linvel': Array(5567.8037, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.83325, dtype=float32), 'eval/episode_x_position': Array(6793.7207, dtype=float32), 'eval/episode_x_velocity': Array(1113.5608, dtype=float32), 'eval/episode_y_position': Array(-161.37021, dtype=float32), 'eval/episode_y_velocity': Array(-164.59279, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.63364, dtype=float32), 'eval/episode_distance_reward_std': Array(5.007102, dtype=float32), 'eval/episode_forward_reward_std': Array(834.5109, dtype=float32), 'eval/episode_reward_std': Array(834.67975, dtype=float32), 'eval/episode_reward_alive_std': Array(43.422882, dtype=float32), 'eval/episode_reward_linvel_std': Array(834.5109, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.887346, dtype=float32), 'eval/episode_x_position_std': Array(438.54062, dtype=float32), 'eval/episode_x_velocity_std': Array(166.90216, dtype=float32), 'eval/episode_y_position_std': Array(338.80005, dtype=float32), 'eval/episode_y_velocity_std': Array(100.7371, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52671790122986, 'eval/sps': 937.5454267684183, 'num_steps': 40632320}
{'eval/walltime': 68019.50678110123, 'training/sps': 2936.1407651290738, 'training/walltime': 13846.012434482574, 'training/entropy_loss': Array(0.01649415, dtype=float32), 'training/policy_loss': Array(0.00640628, dtype=float32), 'training/total_loss': Array(0.19912562, dtype=float32), 'training/v_loss': Array(0.17622519, dtype=float32), 'eval/episode_distance_from_origin': Array(6887.359, dtype=float32), 'eval/episode_distance_reward': Array(33.637142, dtype=float32), 'eval/episode_forward_reward': Array(5606.1587, dtype=float32), 'eval/episode_reward': Array(5596.4766, dtype=float32), 'eval/episode_reward_alive': Array(371.51953, dtype=float32), 'eval/episode_reward_linvel': Array(5606.1587, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.83905, dtype=float32), 'eval/episode_x_position': Array(6836.1157, dtype=float32), 'eval/episode_x_velocity': Array(1121.2317, dtype=float32), 'eval/episode_y_position': Array(-206.02892, dtype=float32), 'eval/episode_y_velocity': Array(-179.80954, dtype=float32), 'eval/episode_distance_from_origin_std': Array(393.6517, dtype=float32), 'eval/episode_distance_reward_std': Array(4.470833, dtype=float32), 'eval/episode_forward_reward_std': Array(745.13354, dtype=float32), 'eval/episode_reward_std': Array(747.7217, dtype=float32), 'eval/episode_reward_alive_std': Array(44.0061, dtype=float32), 'eval/episode_reward_linvel_std': Array(745.13354, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.140448, dtype=float32), 'eval/episode_x_position_std': Array(396.70996, dtype=float32), 'eval/episode_x_velocity_std': Array(149.02676, dtype=float32), 'eval/episode_y_position_std': Array(307.72403, dtype=float32), 'eval/episode_y_velocity_std': Array(82.76266, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40330171585083, 'eval/sps': 938.3937074092516, 'num_steps': 40714240}
{'eval/walltime': 68156.00727820396, 'training/sps': 2933.660839841945, 'training/walltime': 13873.936589479446, 'training/entropy_loss': Array(0.01783329, dtype=float32), 'training/policy_loss': Array(0.0064398, dtype=float32), 'training/total_loss': Array(0.24021786, dtype=float32), 'training/v_loss': Array(0.21594478, dtype=float32), 'eval/episode_distance_from_origin': Array(6911.6724, dtype=float32), 'eval/episode_distance_reward': Array(34.10804, dtype=float32), 'eval/episode_forward_reward': Array(5684.64, dtype=float32), 'eval/episode_reward': Array(5670.9316, dtype=float32), 'eval/episode_reward_alive': Array(364.8672, dtype=float32), 'eval/episode_reward_linvel': Array(5684.64, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.68378, dtype=float32), 'eval/episode_x_position': Array(6862.285, dtype=float32), 'eval/episode_x_velocity': Array(1136.9282, dtype=float32), 'eval/episode_y_position': Array(-175.84464, dtype=float32), 'eval/episode_y_velocity': Array(-175.12038, dtype=float32), 'eval/episode_distance_from_origin_std': Array(351.92804, dtype=float32), 'eval/episode_distance_reward_std': Array(4.0226674, dtype=float32), 'eval/episode_forward_reward_std': Array(670.4399, dtype=float32), 'eval/episode_reward_std': Array(663.8946, dtype=float32), 'eval/episode_reward_alive_std': Array(43.142635, dtype=float32), 'eval/episode_reward_linvel_std': Array(670.4399, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.491755, dtype=float32), 'eval/episode_x_position_std': Array(355.54462, dtype=float32), 'eval/episode_x_velocity_std': Array(134.08788, dtype=float32), 'eval/episode_y_position_std': Array(313.44916, dtype=float32), 'eval/episode_y_velocity_std': Array(92.36519, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50049710273743, 'eval/sps': 937.7255227404812, 'num_steps': 40796160}
{'eval/walltime': 68292.35397219658, 'training/sps': 2926.8222814952733, 'training/walltime': 13901.925989627838, 'training/entropy_loss': Array(0.0171571, dtype=float32), 'training/policy_loss': Array(0.00959817, dtype=float32), 'training/total_loss': Array(0.24919997, dtype=float32), 'training/v_loss': Array(0.2224447, dtype=float32), 'eval/episode_distance_from_origin': Array(6993.833, dtype=float32), 'eval/episode_distance_reward': Array(35.33245, dtype=float32), 'eval/episode_forward_reward': Array(5888.7085, dtype=float32), 'eval/episode_reward': Array(5882.2637, dtype=float32), 'eval/episode_reward_alive': Array(371.25, dtype=float32), 'eval/episode_reward_linvel': Array(5888.7085, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.02637, dtype=float32), 'eval/episode_x_position': Array(6943.635, dtype=float32), 'eval/episode_x_velocity': Array(1177.7415, dtype=float32), 'eval/episode_y_position': Array(-156.13518, dtype=float32), 'eval/episode_y_velocity': Array(-156.74854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(361.16754, dtype=float32), 'eval/episode_distance_reward_std': Array(3.9684727, dtype=float32), 'eval/episode_forward_reward_std': Array(661.4083, dtype=float32), 'eval/episode_reward_std': Array(662.79626, dtype=float32), 'eval/episode_reward_alive_std': Array(42.74552, dtype=float32), 'eval/episode_reward_linvel_std': Array(661.4083, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.7412, dtype=float32), 'eval/episode_x_position_std': Array(366.57828, dtype=float32), 'eval/episode_x_velocity_std': Array(132.28165, dtype=float32), 'eval/episode_y_position_std': Array(358.65854, dtype=float32), 'eval/episode_y_velocity_std': Array(112.94616, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34669399261475, 'eval/sps': 938.783304910445, 'num_steps': 40878080}
{'eval/walltime': 68428.87529420853, 'training/sps': 2932.8685408061274, 'training/walltime': 13929.857688188553, 'training/entropy_loss': Array(0.01731744, dtype=float32), 'training/policy_loss': Array(0.00773797, dtype=float32), 'training/total_loss': Array(0.24972321, dtype=float32), 'training/v_loss': Array(0.22466779, dtype=float32), 'eval/episode_distance_from_origin': Array(6813.8135, dtype=float32), 'eval/episode_distance_reward': Array(32.816383, dtype=float32), 'eval/episode_forward_reward': Array(5469.3667, dtype=float32), 'eval/episode_reward': Array(5462.0635, dtype=float32), 'eval/episode_reward_alive': Array(371.59375, dtype=float32), 'eval/episode_reward_linvel': Array(5469.3667, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.71353, dtype=float32), 'eval/episode_x_position': Array(6762.9463, dtype=float32), 'eval/episode_x_velocity': Array(1093.8733, dtype=float32), 'eval/episode_y_position': Array(-207.8044, dtype=float32), 'eval/episode_y_velocity': Array(-169.92323, dtype=float32), 'eval/episode_distance_from_origin_std': Array(359.4673, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6169734, dtype=float32), 'eval/episode_forward_reward_std': Array(769.48975, dtype=float32), 'eval/episode_reward_std': Array(769.95044, dtype=float32), 'eval/episode_reward_alive_std': Array(53.26664, dtype=float32), 'eval/episode_reward_linvel_std': Array(769.48975, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.801306, dtype=float32), 'eval/episode_x_position_std': Array(360.20926, dtype=float32), 'eval/episode_x_velocity_std': Array(153.89795, dtype=float32), 'eval/episode_y_position_std': Array(312.72433, dtype=float32), 'eval/episode_y_velocity_std': Array(98.82577, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52132201194763, 'eval/sps': 937.5824824549978, 'num_steps': 40960000}
{'eval/walltime': 68565.21964526176, 'training/sps': 2936.71755126968, 'training/walltime': 13957.752778053284, 'training/entropy_loss': Array(0.01461302, dtype=float32), 'training/policy_loss': Array(0.00817608, dtype=float32), 'training/total_loss': Array(0.08141625, dtype=float32), 'training/v_loss': Array(0.05862715, dtype=float32), 'eval/episode_distance_from_origin': Array(6862.089, dtype=float32), 'eval/episode_distance_reward': Array(33.579296, dtype=float32), 'eval/episode_forward_reward': Array(5596.5186, dtype=float32), 'eval/episode_reward': Array(5580.454, dtype=float32), 'eval/episode_reward_alive': Array(361.63672, dtype=float32), 'eval/episode_reward_linvel': Array(5596.5186, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.2796, dtype=float32), 'eval/episode_x_position': Array(6810.8896, dtype=float32), 'eval/episode_x_velocity': Array(1119.3035, dtype=float32), 'eval/episode_y_position': Array(-197.55234, dtype=float32), 'eval/episode_y_velocity': Array(-173.25507, dtype=float32), 'eval/episode_distance_from_origin_std': Array(349.30878, dtype=float32), 'eval/episode_distance_reward_std': Array(4.387535, dtype=float32), 'eval/episode_forward_reward_std': Array(731.2507, dtype=float32), 'eval/episode_reward_std': Array(733.86774, dtype=float32), 'eval/episode_reward_alive_std': Array(48.511467, dtype=float32), 'eval/episode_reward_linvel_std': Array(731.2507, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.444279, dtype=float32), 'eval/episode_x_position_std': Array(351.83963, dtype=float32), 'eval/episode_x_velocity_std': Array(146.25012, dtype=float32), 'eval/episode_y_position_std': Array(328.2447, dtype=float32), 'eval/episode_y_velocity_std': Array(107.253136, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34435105323792, 'eval/sps': 938.7994369493186, 'num_steps': 41041920}
{'eval/walltime': 68701.72566509247, 'training/sps': 2935.851478688401, 'training/walltime': 13985.656096935272, 'training/entropy_loss': Array(0.01665531, dtype=float32), 'training/policy_loss': Array(0.01111621, dtype=float32), 'training/total_loss': Array(0.17958213, dtype=float32), 'training/v_loss': Array(0.15181062, dtype=float32), 'eval/episode_distance_from_origin': Array(6855.8867, dtype=float32), 'eval/episode_distance_reward': Array(32.913376, dtype=float32), 'eval/episode_forward_reward': Array(5485.532, dtype=float32), 'eval/episode_reward': Array(5472.1772, dtype=float32), 'eval/episode_reward_alive': Array(366.78125, dtype=float32), 'eval/episode_reward_linvel': Array(5485.532, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.04877, dtype=float32), 'eval/episode_x_position': Array(6804.807, dtype=float32), 'eval/episode_x_velocity': Array(1097.1062, dtype=float32), 'eval/episode_y_position': Array(-191.92375, dtype=float32), 'eval/episode_y_velocity': Array(-167.21759, dtype=float32), 'eval/episode_distance_from_origin_std': Array(380.36548, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7782354, dtype=float32), 'eval/episode_forward_reward_std': Array(796.3665, dtype=float32), 'eval/episode_reward_std': Array(792.61316, dtype=float32), 'eval/episode_reward_alive_std': Array(51.227158, dtype=float32), 'eval/episode_reward_linvel_std': Array(796.3665, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.657354, dtype=float32), 'eval/episode_x_position_std': Array(381.9923, dtype=float32), 'eval/episode_x_velocity_std': Array(159.27335, dtype=float32), 'eval/episode_y_position_std': Array(321.0463, dtype=float32), 'eval/episode_y_velocity_std': Array(109.27456, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50601983070374, 'eval/sps': 937.6875844651174, 'num_steps': 41123840}
{'eval/walltime': 68838.09732437134, 'training/sps': 2935.0856504406474, 'training/walltime': 14013.56669640541, 'training/entropy_loss': Array(0.01580724, dtype=float32), 'training/policy_loss': Array(0.01156807, dtype=float32), 'training/total_loss': Array(0.15089756, dtype=float32), 'training/v_loss': Array(0.12352225, dtype=float32), 'eval/episode_distance_from_origin': Array(6883.534, dtype=float32), 'eval/episode_distance_reward': Array(33.560917, dtype=float32), 'eval/episode_forward_reward': Array(5593.4546, dtype=float32), 'eval/episode_reward': Array(5580.922, dtype=float32), 'eval/episode_reward_alive': Array(367.5, dtype=float32), 'eval/episode_reward_linvel': Array(5593.4546, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.59314, dtype=float32), 'eval/episode_x_position': Array(6830.4824, dtype=float32), 'eval/episode_x_velocity': Array(1118.6908, dtype=float32), 'eval/episode_y_position': Array(-221.39316, dtype=float32), 'eval/episode_y_velocity': Array(-171.64548, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.6186, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0704846, dtype=float32), 'eval/episode_forward_reward_std': Array(845.07465, dtype=float32), 'eval/episode_reward_std': Array(841.5625, dtype=float32), 'eval/episode_reward_alive_std': Array(50.54384, dtype=float32), 'eval/episode_reward_linvel_std': Array(845.07465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.095772, dtype=float32), 'eval/episode_x_position_std': Array(430.7188, dtype=float32), 'eval/episode_x_velocity_std': Array(169.01497, dtype=float32), 'eval/episode_y_position_std': Array(345.864, dtype=float32), 'eval/episode_y_velocity_std': Array(107.23213, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37165927886963, 'eval/sps': 938.6114437329663, 'num_steps': 41205760}
{'eval/walltime': 68974.6335799694, 'training/sps': 2933.676018900292, 'training/walltime': 14041.490706920624, 'training/entropy_loss': Array(0.01695124, dtype=float32), 'training/policy_loss': Array(0.0066679, dtype=float32), 'training/total_loss': Array(0.19143468, dtype=float32), 'training/v_loss': Array(0.16781555, dtype=float32), 'eval/episode_distance_from_origin': Array(6822.7705, dtype=float32), 'eval/episode_distance_reward': Array(33.138092, dtype=float32), 'eval/episode_forward_reward': Array(5522.9834, dtype=float32), 'eval/episode_reward': Array(5504.5693, dtype=float32), 'eval/episode_reward_alive': Array(358.0039, dtype=float32), 'eval/episode_reward_linvel': Array(5522.9834, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.55624, dtype=float32), 'eval/episode_x_position': Array(6772.7607, dtype=float32), 'eval/episode_x_velocity': Array(1104.5967, dtype=float32), 'eval/episode_y_position': Array(-206.93718, dtype=float32), 'eval/episode_y_velocity': Array(-173.86337, dtype=float32), 'eval/episode_distance_from_origin_std': Array(406.38416, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4806495, dtype=float32), 'eval/episode_forward_reward_std': Array(746.76917, dtype=float32), 'eval/episode_reward_std': Array(746.58405, dtype=float32), 'eval/episode_reward_alive_std': Array(52.563076, dtype=float32), 'eval/episode_reward_linvel_std': Array(746.76917, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.883726, dtype=float32), 'eval/episode_x_position_std': Array(410.8587, dtype=float32), 'eval/episode_x_velocity_std': Array(149.3538, dtype=float32), 'eval/episode_y_position_std': Array(301.6034, dtype=float32), 'eval/episode_y_velocity_std': Array(96.282394, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53625559806824, 'eval/sps': 937.4799348299324, 'num_steps': 41287680}
{'eval/walltime': 69110.99264717102, 'training/sps': 2941.592252177398, 'training/walltime': 14069.339570045471, 'training/entropy_loss': Array(0.01677757, dtype=float32), 'training/policy_loss': Array(0.00605171, dtype=float32), 'training/total_loss': Array(0.24462894, dtype=float32), 'training/v_loss': Array(0.22179966, dtype=float32), 'eval/episode_distance_from_origin': Array(6864.3726, dtype=float32), 'eval/episode_distance_reward': Array(33.671993, dtype=float32), 'eval/episode_forward_reward': Array(5611.967, dtype=float32), 'eval/episode_reward': Array(5592.3037, dtype=float32), 'eval/episode_reward_alive': Array(360.6289, dtype=float32), 'eval/episode_reward_linvel': Array(5611.967, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.96368, dtype=float32), 'eval/episode_x_position': Array(6813.9663, dtype=float32), 'eval/episode_x_velocity': Array(1122.3933, dtype=float32), 'eval/episode_y_position': Array(-199.5227, dtype=float32), 'eval/episode_y_velocity': Array(-177.45224, dtype=float32), 'eval/episode_distance_from_origin_std': Array(367.04138, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4588566, dtype=float32), 'eval/episode_forward_reward_std': Array(743.1369, dtype=float32), 'eval/episode_reward_std': Array(749.2492, dtype=float32), 'eval/episode_reward_alive_std': Array(46.170467, dtype=float32), 'eval/episode_reward_linvel_std': Array(743.1369, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.738375, dtype=float32), 'eval/episode_x_position_std': Array(372.1797, dtype=float32), 'eval/episode_x_velocity_std': Array(148.62744, dtype=float32), 'eval/episode_y_position_std': Array(291.8326, dtype=float32), 'eval/episode_y_velocity_std': Array(89.85327, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35906720161438, 'eval/sps': 938.6981198011935, 'num_steps': 41369600}
{'eval/walltime': 69247.53536748886, 'training/sps': 2934.05341677904, 'training/walltime': 14097.25998878479, 'training/entropy_loss': Array(0.01678433, dtype=float32), 'training/policy_loss': Array(0.01012553, dtype=float32), 'training/total_loss': Array(0.25799775, dtype=float32), 'training/v_loss': Array(0.23108788, dtype=float32), 'eval/episode_distance_from_origin': Array(6876.7544, dtype=float32), 'eval/episode_distance_reward': Array(33.612896, dtype=float32), 'eval/episode_forward_reward': Array(5602.118, dtype=float32), 'eval/episode_reward': Array(5575.0034, dtype=float32), 'eval/episode_reward_alive': Array(354.77734, dtype=float32), 'eval/episode_reward_linvel': Array(5602.118, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.50455, dtype=float32), 'eval/episode_x_position': Array(6825.5566, dtype=float32), 'eval/episode_x_velocity': Array(1120.4235, dtype=float32), 'eval/episode_y_position': Array(-248.9827, dtype=float32), 'eval/episode_y_velocity': Array(-185.01569, dtype=float32), 'eval/episode_distance_from_origin_std': Array(380.69513, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3440394, dtype=float32), 'eval/episode_forward_reward_std': Array(724.00104, dtype=float32), 'eval/episode_reward_std': Array(728.2033, dtype=float32), 'eval/episode_reward_alive_std': Array(48.274883, dtype=float32), 'eval/episode_reward_linvel_std': Array(724.00104, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.77455, dtype=float32), 'eval/episode_x_position_std': Array(384.47318, dtype=float32), 'eval/episode_x_velocity_std': Array(144.80023, dtype=float32), 'eval/episode_y_position_std': Array(267.17685, dtype=float32), 'eval/episode_y_velocity_std': Array(84.30175, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54272031784058, 'eval/sps': 937.4355491237097, 'num_steps': 41451520}
{'eval/walltime': 69383.92146897316, 'training/sps': 2944.201605105936, 'training/walltime': 14125.084170341492, 'training/entropy_loss': Array(0.01273611, dtype=float32), 'training/policy_loss': Array(0.00786551, dtype=float32), 'training/total_loss': Array(0.11010421, dtype=float32), 'training/v_loss': Array(0.08950259, dtype=float32), 'eval/episode_distance_from_origin': Array(6777.176, dtype=float32), 'eval/episode_distance_reward': Array(32.628944, dtype=float32), 'eval/episode_forward_reward': Array(5438.1274, dtype=float32), 'eval/episode_reward': Array(5416.0337, dtype=float32), 'eval/episode_reward_alive': Array(360.53516, dtype=float32), 'eval/episode_reward_linvel': Array(5438.1274, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.25754, dtype=float32), 'eval/episode_x_position': Array(6724.36, dtype=float32), 'eval/episode_x_velocity': Array(1087.6254, dtype=float32), 'eval/episode_y_position': Array(-237.89569, dtype=float32), 'eval/episode_y_velocity': Array(-180.62424, dtype=float32), 'eval/episode_distance_from_origin_std': Array(393.05835, dtype=float32), 'eval/episode_distance_reward_std': Array(4.509414, dtype=float32), 'eval/episode_forward_reward_std': Array(751.56287, dtype=float32), 'eval/episode_reward_std': Array(750.1086, dtype=float32), 'eval/episode_reward_alive_std': Array(47.46982, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.56287, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.244164, dtype=float32), 'eval/episode_x_position_std': Array(394.99722, dtype=float32), 'eval/episode_x_velocity_std': Array(150.31255, dtype=float32), 'eval/episode_y_position_std': Array(293.16272, dtype=float32), 'eval/episode_y_velocity_std': Array(104.11545, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3861014842987, 'eval/sps': 938.5120522323592, 'num_steps': 41533440}
{'eval/walltime': 69520.50034999847, 'training/sps': 2937.027820609522, 'training/walltime': 14152.976313352585, 'training/entropy_loss': Array(0.01812018, dtype=float32), 'training/policy_loss': Array(0.00692351, dtype=float32), 'training/total_loss': Array(0.12772322, dtype=float32), 'training/v_loss': Array(0.10267953, dtype=float32), 'eval/episode_distance_from_origin': Array(6861.8022, dtype=float32), 'eval/episode_distance_reward': Array(33.60444, dtype=float32), 'eval/episode_forward_reward': Array(5600.708, dtype=float32), 'eval/episode_reward': Array(5576.7876, dtype=float32), 'eval/episode_reward_alive': Array(357.90625, dtype=float32), 'eval/episode_reward_linvel': Array(5600.708, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.43164, dtype=float32), 'eval/episode_x_position': Array(6809.1846, dtype=float32), 'eval/episode_x_velocity': Array(1120.1416, dtype=float32), 'eval/episode_y_position': Array(-211.45218, dtype=float32), 'eval/episode_y_velocity': Array(-178.80038, dtype=float32), 'eval/episode_distance_from_origin_std': Array(400.6035, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5098877, dtype=float32), 'eval/episode_forward_reward_std': Array(751.6429, dtype=float32), 'eval/episode_reward_std': Array(752.88934, dtype=float32), 'eval/episode_reward_alive_std': Array(48.214478, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.6429, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.08192, dtype=float32), 'eval/episode_x_position_std': Array(404.37027, dtype=float32), 'eval/episode_x_velocity_std': Array(150.32854, dtype=float32), 'eval/episode_y_position_std': Array(320.26303, dtype=float32), 'eval/episode_y_velocity_std': Array(98.1679, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57888102531433, 'eval/sps': 937.1873531184937, 'num_steps': 41615360}
{'eval/walltime': 69656.87371587753, 'training/sps': 2940.2474921684293, 'training/walltime': 14180.837913513184, 'training/entropy_loss': Array(0.01656828, dtype=float32), 'training/policy_loss': Array(0.00878553, dtype=float32), 'training/total_loss': Array(0.19583656, dtype=float32), 'training/v_loss': Array(0.17048275, dtype=float32), 'eval/episode_distance_from_origin': Array(6839.7803, dtype=float32), 'eval/episode_distance_reward': Array(32.803085, dtype=float32), 'eval/episode_forward_reward': Array(5467.1504, dtype=float32), 'eval/episode_reward': Array(5447.542, dtype=float32), 'eval/episode_reward_alive': Array(362.16016, dtype=float32), 'eval/episode_reward_linvel': Array(5467.1504, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.57126, dtype=float32), 'eval/episode_x_position': Array(6790.0225, dtype=float32), 'eval/episode_x_velocity': Array(1093.4299, dtype=float32), 'eval/episode_y_position': Array(-213.18683, dtype=float32), 'eval/episode_y_velocity': Array(-176.2911, dtype=float32), 'eval/episode_distance_from_origin_std': Array(396.26035, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6178412, dtype=float32), 'eval/episode_forward_reward_std': Array(769.63477, dtype=float32), 'eval/episode_reward_std': Array(776.76056, dtype=float32), 'eval/episode_reward_alive_std': Array(44.97247, dtype=float32), 'eval/episode_reward_linvel_std': Array(769.63477, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.039604, dtype=float32), 'eval/episode_x_position_std': Array(396.8455, dtype=float32), 'eval/episode_x_velocity_std': Array(153.92688, dtype=float32), 'eval/episode_y_position_std': Array(288.66132, dtype=float32), 'eval/episode_y_velocity_std': Array(86.330986, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37336587905884, 'eval/sps': 938.5996977849424, 'num_steps': 41697280}
{'eval/walltime': 69793.43945884705, 'training/sps': 2934.69788554176, 'training/walltime': 14208.752200841904, 'training/entropy_loss': Array(0.01765596, dtype=float32), 'training/policy_loss': Array(0.00561985, dtype=float32), 'training/total_loss': Array(0.21750107, dtype=float32), 'training/v_loss': Array(0.19422527, dtype=float32), 'eval/episode_distance_from_origin': Array(6879.5166, dtype=float32), 'eval/episode_distance_reward': Array(33.515137, dtype=float32), 'eval/episode_forward_reward': Array(5585.825, dtype=float32), 'eval/episode_reward': Array(5554.952, dtype=float32), 'eval/episode_reward_alive': Array(354.42188, dtype=float32), 'eval/episode_reward_linvel': Array(5585.825, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.80994, dtype=float32), 'eval/episode_x_position': Array(6828.836, dtype=float32), 'eval/episode_x_velocity': Array(1117.1649, dtype=float32), 'eval/episode_y_position': Array(-204.06949, dtype=float32), 'eval/episode_y_velocity': Array(-172.56317, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.67133, dtype=float32), 'eval/episode_distance_reward_std': Array(4.476474, dtype=float32), 'eval/episode_forward_reward_std': Array(746.07367, dtype=float32), 'eval/episode_reward_std': Array(744.9256, dtype=float32), 'eval/episode_reward_alive_std': Array(48.812073, dtype=float32), 'eval/episode_reward_linvel_std': Array(746.07367, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.186516, dtype=float32), 'eval/episode_x_position_std': Array(390.06238, dtype=float32), 'eval/episode_x_velocity_std': Array(149.21466, dtype=float32), 'eval/episode_y_position_std': Array(319.95413, dtype=float32), 'eval/episode_y_velocity_std': Array(107.230995, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56574296951294, 'eval/sps': 937.2775135018658, 'num_steps': 41779200}
{'eval/walltime': 69929.83475542068, 'training/sps': 2933.843424775622, 'training/walltime': 14236.674618005753, 'training/entropy_loss': Array(0.01757651, dtype=float32), 'training/policy_loss': Array(0.00759282, dtype=float32), 'training/total_loss': Array(0.2805417, dtype=float32), 'training/v_loss': Array(0.25537235, dtype=float32), 'eval/episode_distance_from_origin': Array(6904.8, dtype=float32), 'eval/episode_distance_reward': Array(33.300976, dtype=float32), 'eval/episode_forward_reward': Array(5550.132, dtype=float32), 'eval/episode_reward': Array(5524.124, dtype=float32), 'eval/episode_reward_alive': Array(359.66016, dtype=float32), 'eval/episode_reward_linvel': Array(5550.132, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.96918, dtype=float32), 'eval/episode_x_position': Array(6853.0176, dtype=float32), 'eval/episode_x_velocity': Array(1110.0264, dtype=float32), 'eval/episode_y_position': Array(-154.7951, dtype=float32), 'eval/episode_y_velocity': Array(-161.52612, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.83304, dtype=float32), 'eval/episode_distance_reward_std': Array(4.928783, dtype=float32), 'eval/episode_forward_reward_std': Array(821.45746, dtype=float32), 'eval/episode_reward_std': Array(820.20166, dtype=float32), 'eval/episode_reward_alive_std': Array(49.40406, dtype=float32), 'eval/episode_reward_linvel_std': Array(821.45746, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.458925, dtype=float32), 'eval/episode_x_position_std': Array(436.17953, dtype=float32), 'eval/episode_x_velocity_std': Array(164.29149, dtype=float32), 'eval/episode_y_position_std': Array(370.36078, dtype=float32), 'eval/episode_y_velocity_std': Array(112.48123, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39529657363892, 'eval/sps': 938.4487824394564, 'num_steps': 41861120}
{'eval/walltime': 70066.36701655388, 'training/sps': 2933.003056236357, 'training/walltime': 14264.605035543442, 'training/entropy_loss': Array(0.01725426, dtype=float32), 'training/policy_loss': Array(0.00650755, dtype=float32), 'training/total_loss': Array(0.30264467, dtype=float32), 'training/v_loss': Array(0.27888283, dtype=float32), 'eval/episode_distance_from_origin': Array(6896.1064, dtype=float32), 'eval/episode_distance_reward': Array(34.083626, dtype=float32), 'eval/episode_forward_reward': Array(5680.572, dtype=float32), 'eval/episode_reward': Array(5658.809, dtype=float32), 'eval/episode_reward_alive': Array(360.14453, dtype=float32), 'eval/episode_reward_linvel': Array(5680.572, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.99164, dtype=float32), 'eval/episode_x_position': Array(6847.953, dtype=float32), 'eval/episode_x_velocity': Array(1136.1145, dtype=float32), 'eval/episode_y_position': Array(-145.24396, dtype=float32), 'eval/episode_y_velocity': Array(-157.91965, dtype=float32), 'eval/episode_distance_from_origin_std': Array(379.77057, dtype=float32), 'eval/episode_distance_reward_std': Array(4.1165605, dtype=float32), 'eval/episode_forward_reward_std': Array(686.0879, dtype=float32), 'eval/episode_reward_std': Array(681.66046, dtype=float32), 'eval/episode_reward_alive_std': Array(52.372803, dtype=float32), 'eval/episode_reward_linvel_std': Array(686.0879, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.69247, dtype=float32), 'eval/episode_x_position_std': Array(385.00656, dtype=float32), 'eval/episode_x_velocity_std': Array(137.21758, dtype=float32), 'eval/episode_y_position_std': Array(315.30124, dtype=float32), 'eval/episode_y_velocity_std': Array(98.45399, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53226113319397, 'eval/sps': 937.5073622719078, 'num_steps': 41943040}
{'eval/walltime': 70202.74626636505, 'training/sps': 2935.694754456228, 'training/walltime': 14292.509844064713, 'training/entropy_loss': Array(0.01376085, dtype=float32), 'training/policy_loss': Array(0.00531705, dtype=float32), 'training/total_loss': Array(0.16076648, dtype=float32), 'training/v_loss': Array(0.14168859, dtype=float32), 'eval/episode_distance_from_origin': Array(6859.296, dtype=float32), 'eval/episode_distance_reward': Array(33.88778, dtype=float32), 'eval/episode_forward_reward': Array(5647.9316, dtype=float32), 'eval/episode_reward': Array(5629.866, dtype=float32), 'eval/episode_reward_alive': Array(362.34375, dtype=float32), 'eval/episode_reward_linvel': Array(5647.9316, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.29663, dtype=float32), 'eval/episode_x_position': Array(6808.025, dtype=float32), 'eval/episode_x_velocity': Array(1129.5862, dtype=float32), 'eval/episode_y_position': Array(-75.58859, dtype=float32), 'eval/episode_y_velocity': Array(-141.69589, dtype=float32), 'eval/episode_distance_from_origin_std': Array(460.98215, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1632032, dtype=float32), 'eval/episode_forward_reward_std': Array(860.52795, dtype=float32), 'eval/episode_reward_std': Array(859.9611, dtype=float32), 'eval/episode_reward_alive_std': Array(50.868465, dtype=float32), 'eval/episode_reward_linvel_std': Array(860.52795, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.683056, dtype=float32), 'eval/episode_x_position_std': Array(464.82114, dtype=float32), 'eval/episode_x_velocity_std': Array(172.10567, dtype=float32), 'eval/episode_y_position_std': Array(386.23026, dtype=float32), 'eval/episode_y_velocity_std': Array(120.33185, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37924981117249, 'eval/sps': 938.5592029375862, 'num_steps': 42024960}
{'eval/walltime': 70339.2763311863, 'training/sps': 2935.620060478335, 'training/walltime': 14320.415362596512, 'training/entropy_loss': Array(0.01845124, dtype=float32), 'training/policy_loss': Array(0.0076482, dtype=float32), 'training/total_loss': Array(0.10969335, dtype=float32), 'training/v_loss': Array(0.0835939, dtype=float32), 'eval/episode_distance_from_origin': Array(6808.4663, dtype=float32), 'eval/episode_distance_reward': Array(33.14132, dtype=float32), 'eval/episode_forward_reward': Array(5523.5225, dtype=float32), 'eval/episode_reward': Array(5493.673, dtype=float32), 'eval/episode_reward_alive': Array(352.70312, dtype=float32), 'eval/episode_reward_linvel': Array(5523.5225, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.69336, dtype=float32), 'eval/episode_x_position': Array(6759.205, dtype=float32), 'eval/episode_x_velocity': Array(1104.7043, dtype=float32), 'eval/episode_y_position': Array(-165.21802, dtype=float32), 'eval/episode_y_velocity': Array(-173.89545, dtype=float32), 'eval/episode_distance_from_origin_std': Array(419.01285, dtype=float32), 'eval/episode_distance_reward_std': Array(4.705, dtype=float32), 'eval/episode_forward_reward_std': Array(784.16064, dtype=float32), 'eval/episode_reward_std': Array(786.3219, dtype=float32), 'eval/episode_reward_alive_std': Array(47.68149, dtype=float32), 'eval/episode_reward_linvel_std': Array(784.16064, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.167637, dtype=float32), 'eval/episode_x_position_std': Array(422.2325, dtype=float32), 'eval/episode_x_velocity_std': Array(156.83221, dtype=float32), 'eval/episode_y_position_std': Array(303.10437, dtype=float32), 'eval/episode_y_velocity_std': Array(91.32671, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5300648212433, 'eval/sps': 937.5224436287233, 'num_steps': 42106880}
{'eval/walltime': 70475.61357402802, 'training/sps': 2944.2723212824017, 'training/walltime': 14348.238875865936, 'training/entropy_loss': Array(0.01617163, dtype=float32), 'training/policy_loss': Array(0.0056483, dtype=float32), 'training/total_loss': Array(0.1913496, dtype=float32), 'training/v_loss': Array(0.16952965, dtype=float32), 'eval/episode_distance_from_origin': Array(6798.544, dtype=float32), 'eval/episode_distance_reward': Array(32.951057, dtype=float32), 'eval/episode_forward_reward': Array(5491.812, dtype=float32), 'eval/episode_reward': Array(5468.493, dtype=float32), 'eval/episode_reward_alive': Array(361.33984, dtype=float32), 'eval/episode_reward_linvel': Array(5491.812, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.6097, dtype=float32), 'eval/episode_x_position': Array(6750.058, dtype=float32), 'eval/episode_x_velocity': Array(1098.3624, dtype=float32), 'eval/episode_y_position': Array(-153.538, dtype=float32), 'eval/episode_y_velocity': Array(-165.51883, dtype=float32), 'eval/episode_distance_from_origin_std': Array(389.7539, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8781533, dtype=float32), 'eval/episode_forward_reward_std': Array(813.0188, dtype=float32), 'eval/episode_reward_std': Array(817.61993, dtype=float32), 'eval/episode_reward_alive_std': Array(46.374744, dtype=float32), 'eval/episode_reward_linvel_std': Array(813.0188, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.268356, dtype=float32), 'eval/episode_x_position_std': Array(392.49475, dtype=float32), 'eval/episode_x_velocity_std': Array(162.60374, dtype=float32), 'eval/episode_y_position_std': Array(298.02148, dtype=float32), 'eval/episode_y_velocity_std': Array(94.363106, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33724284172058, 'eval/sps': 938.8483831127521, 'num_steps': 42188800}
{'eval/walltime': 70612.14868164062, 'training/sps': 2944.372283370637, 'training/walltime': 14376.06144452095, 'training/entropy_loss': Array(0.01670094, dtype=float32), 'training/policy_loss': Array(0.01000166, dtype=float32), 'training/total_loss': Array(0.19211361, dtype=float32), 'training/v_loss': Array(0.16541101, dtype=float32), 'eval/episode_distance_from_origin': Array(6795.365, dtype=float32), 'eval/episode_distance_reward': Array(32.782814, dtype=float32), 'eval/episode_forward_reward': Array(5463.7725, dtype=float32), 'eval/episode_reward': Array(5436.0703, dtype=float32), 'eval/episode_reward_alive': Array(359.07812, dtype=float32), 'eval/episode_reward_linvel': Array(5463.7725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.56345, dtype=float32), 'eval/episode_x_position': Array(6742.9453, dtype=float32), 'eval/episode_x_velocity': Array(1092.7545, dtype=float32), 'eval/episode_y_position': Array(-179.01678, dtype=float32), 'eval/episode_y_velocity': Array(-167.37495, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.7684, dtype=float32), 'eval/episode_distance_reward_std': Array(5.51074, dtype=float32), 'eval/episode_forward_reward_std': Array(918.45056, dtype=float32), 'eval/episode_reward_std': Array(915.75543, dtype=float32), 'eval/episode_reward_alive_std': Array(49.477913, dtype=float32), 'eval/episode_reward_linvel_std': Array(918.45056, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.756163, dtype=float32), 'eval/episode_x_position_std': Array(456.63956, dtype=float32), 'eval/episode_x_velocity_std': Array(183.69022, dtype=float32), 'eval/episode_y_position_std': Array(330.9872, dtype=float32), 'eval/episode_y_velocity_std': Array(104.94561, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53510761260986, 'eval/sps': 937.4878171493704, 'num_steps': 42270720}
{'eval/walltime': 70748.50155687332, 'training/sps': 2941.6213897090634, 'training/walltime': 14403.910031795502, 'training/entropy_loss': Array(0.01743342, dtype=float32), 'training/policy_loss': Array(0.00714038, dtype=float32), 'training/total_loss': Array(0.23872754, dtype=float32), 'training/v_loss': Array(0.21415372, dtype=float32), 'eval/episode_distance_from_origin': Array(6860.63, dtype=float32), 'eval/episode_distance_reward': Array(33.367207, dtype=float32), 'eval/episode_forward_reward': Array(5561.1704, dtype=float32), 'eval/episode_reward': Array(5541.0464, dtype=float32), 'eval/episode_reward_alive': Array(362.09766, dtype=float32), 'eval/episode_reward_linvel': Array(5561.1704, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.5893, dtype=float32), 'eval/episode_x_position': Array(6806.914, dtype=float32), 'eval/episode_x_velocity': Array(1112.2341, dtype=float32), 'eval/episode_y_position': Array(-115.5467, dtype=float32), 'eval/episode_y_velocity': Array(-151.85081, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.29312, dtype=float32), 'eval/episode_distance_reward_std': Array(4.932752, dtype=float32), 'eval/episode_forward_reward_std': Array(822.11835, dtype=float32), 'eval/episode_reward_std': Array(820.48047, dtype=float32), 'eval/episode_reward_alive_std': Array(46.54505, dtype=float32), 'eval/episode_reward_linvel_std': Array(822.11835, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.450457, dtype=float32), 'eval/episode_x_position_std': Array(416.32663, dtype=float32), 'eval/episode_x_velocity_std': Array(164.42369, dtype=float32), 'eval/episode_y_position_std': Array(399.1942, dtype=float32), 'eval/episode_y_velocity_std': Array(123.23498, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35287523269653, 'eval/sps': 938.7407473554063, 'num_steps': 42352640}
{'eval/walltime': 70884.98199677467, 'training/sps': 2946.404558832584, 'training/walltime': 14431.713409900665, 'training/entropy_loss': Array(0.01788453, dtype=float32), 'training/policy_loss': Array(0.00531639, dtype=float32), 'training/total_loss': Array(0.22441556, dtype=float32), 'training/v_loss': Array(0.20121461, dtype=float32), 'eval/episode_distance_from_origin': Array(6760.9043, dtype=float32), 'eval/episode_distance_reward': Array(32.736004, dtype=float32), 'eval/episode_forward_reward': Array(5455.97, dtype=float32), 'eval/episode_reward': Array(5434.3135, dtype=float32), 'eval/episode_reward_alive': Array(361.5625, dtype=float32), 'eval/episode_reward_linvel': Array(5455.97, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.95572, dtype=float32), 'eval/episode_x_position': Array(6710.9487, dtype=float32), 'eval/episode_x_velocity': Array(1091.194, dtype=float32), 'eval/episode_y_position': Array(-142.3797, dtype=float32), 'eval/episode_y_velocity': Array(-165.6396, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.79205, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2541027, dtype=float32), 'eval/episode_forward_reward_std': Array(875.677, dtype=float32), 'eval/episode_reward_std': Array(872.2173, dtype=float32), 'eval/episode_reward_alive_std': Array(46.3289, dtype=float32), 'eval/episode_reward_linvel_std': Array(875.677, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.688562, dtype=float32), 'eval/episode_x_position_std': Array(478.0125, dtype=float32), 'eval/episode_x_velocity_std': Array(175.13539, dtype=float32), 'eval/episode_y_position_std': Array(312.1502, dtype=float32), 'eval/episode_y_velocity_std': Array(98.49319, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48043990135193, 'eval/sps': 937.8633311302222, 'num_steps': 42434560}
{'eval/walltime': 71021.23948740959, 'training/sps': 2939.5809675843025, 'training/walltime': 14459.581327438354, 'training/entropy_loss': Array(0.01557922, dtype=float32), 'training/policy_loss': Array(0.00923299, dtype=float32), 'training/total_loss': Array(0.20070635, dtype=float32), 'training/v_loss': Array(0.17589414, dtype=float32), 'eval/episode_distance_from_origin': Array(6781.49, dtype=float32), 'eval/episode_distance_reward': Array(33.083416, dtype=float32), 'eval/episode_forward_reward': Array(5513.871, dtype=float32), 'eval/episode_reward': Array(5493.9844, dtype=float32), 'eval/episode_reward_alive': Array(368.14062, dtype=float32), 'eval/episode_reward_linvel': Array(5513.871, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.11078, dtype=float32), 'eval/episode_x_position': Array(6729.1484, dtype=float32), 'eval/episode_x_velocity': Array(1102.7743, dtype=float32), 'eval/episode_y_position': Array(-87.14193, dtype=float32), 'eval/episode_y_velocity': Array(-150.86795, dtype=float32), 'eval/episode_distance_from_origin_std': Array(466.24222, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5201087, dtype=float32), 'eval/episode_forward_reward_std': Array(920.0119, dtype=float32), 'eval/episode_reward_std': Array(924.7974, dtype=float32), 'eval/episode_reward_alive_std': Array(43.28069, dtype=float32), 'eval/episode_reward_linvel_std': Array(920.0119, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.692228, dtype=float32), 'eval/episode_x_position_std': Array(470.35468, dtype=float32), 'eval/episode_x_velocity_std': Array(184.0023, dtype=float32), 'eval/episode_y_position_std': Array(377.81302, dtype=float32), 'eval/episode_y_velocity_std': Array(121.2383, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2574906349182, 'eval/sps': 939.3978958775709, 'num_steps': 42516480}
{'eval/walltime': 71157.68428945541, 'training/sps': 2934.737539751327, 'training/walltime': 14487.495237588882, 'training/entropy_loss': Array(0.0165088, dtype=float32), 'training/policy_loss': Array(0.01322692, dtype=float32), 'training/total_loss': Array(0.11009087, dtype=float32), 'training/v_loss': Array(0.08035515, dtype=float32), 'eval/episode_distance_from_origin': Array(6853.6963, dtype=float32), 'eval/episode_distance_reward': Array(33.708374, dtype=float32), 'eval/episode_forward_reward': Array(5618.031, dtype=float32), 'eval/episode_reward': Array(5604.668, dtype=float32), 'eval/episode_reward_alive': Array(369.27734, dtype=float32), 'eval/episode_reward_linvel': Array(5618.031, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.34827, dtype=float32), 'eval/episode_x_position': Array(6803.5674, dtype=float32), 'eval/episode_x_velocity': Array(1123.6061, dtype=float32), 'eval/episode_y_position': Array(-73.24814, dtype=float32), 'eval/episode_y_velocity': Array(-148.63483, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.99988, dtype=float32), 'eval/episode_distance_reward_std': Array(5.144619, dtype=float32), 'eval/episode_forward_reward_std': Array(857.4298, dtype=float32), 'eval/episode_reward_std': Array(852.69867, dtype=float32), 'eval/episode_reward_alive_std': Array(43.45507, dtype=float32), 'eval/episode_reward_linvel_std': Array(857.4298, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.983671, dtype=float32), 'eval/episode_x_position_std': Array(445.30765, dtype=float32), 'eval/episode_x_velocity_std': Array(171.48611, dtype=float32), 'eval/episode_y_position_std': Array(358.832, dtype=float32), 'eval/episode_y_velocity_std': Array(111.90937, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44480204582214, 'eval/sps': 938.1082905379852, 'num_steps': 42598400}
{'eval/walltime': 71293.95762777328, 'training/sps': 2936.2484310691634, 'training/walltime': 14515.394784212112, 'training/entropy_loss': Array(0.01862946, dtype=float32), 'training/policy_loss': Array(0.01687652, dtype=float32), 'training/total_loss': Array(0.21433336, dtype=float32), 'training/v_loss': Array(0.17882738, dtype=float32), 'eval/episode_distance_from_origin': Array(6825.6025, dtype=float32), 'eval/episode_distance_reward': Array(33.135483, dtype=float32), 'eval/episode_forward_reward': Array(5522.549, dtype=float32), 'eval/episode_reward': Array(5505.2295, dtype=float32), 'eval/episode_reward_alive': Array(367.32422, dtype=float32), 'eval/episode_reward_linvel': Array(5522.549, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.77844, dtype=float32), 'eval/episode_x_position': Array(6775.8613, dtype=float32), 'eval/episode_x_velocity': Array(1104.5098, dtype=float32), 'eval/episode_y_position': Array(-124.11018, dtype=float32), 'eval/episode_y_velocity': Array(-162.89111, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.95248, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8756833, dtype=float32), 'eval/episode_forward_reward_std': Array(812.6087, dtype=float32), 'eval/episode_reward_std': Array(807.41534, dtype=float32), 'eval/episode_reward_alive_std': Array(42.874023, dtype=float32), 'eval/episode_reward_linvel_std': Array(812.6087, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.150566, dtype=float32), 'eval/episode_x_position_std': Array(470.0689, dtype=float32), 'eval/episode_x_velocity_std': Array(162.52176, dtype=float32), 'eval/episode_y_position_std': Array(326.78165, dtype=float32), 'eval/episode_y_velocity_std': Array(92.81916, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2733383178711, 'eval/sps': 939.2886501497989, 'num_steps': 42680320}
{'eval/walltime': 71430.40439891815, 'training/sps': 2936.0795965276375, 'training/walltime': 14543.295935153961, 'training/entropy_loss': Array(0.01705075, dtype=float32), 'training/policy_loss': Array(0.00744568, dtype=float32), 'training/total_loss': Array(0.17342773, dtype=float32), 'training/v_loss': Array(0.1489313, dtype=float32), 'eval/episode_distance_from_origin': Array(6783.831, dtype=float32), 'eval/episode_distance_reward': Array(33.096397, dtype=float32), 'eval/episode_forward_reward': Array(5516.035, dtype=float32), 'eval/episode_reward': Array(5501.953, dtype=float32), 'eval/episode_reward_alive': Array(372.53906, dtype=float32), 'eval/episode_reward_linvel': Array(5516.035, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.71783, dtype=float32), 'eval/episode_x_position': Array(6734.4414, dtype=float32), 'eval/episode_x_velocity': Array(1103.207, dtype=float32), 'eval/episode_y_position': Array(-99.942764, dtype=float32), 'eval/episode_y_velocity': Array(-164.83041, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.39734, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3415847, dtype=float32), 'eval/episode_forward_reward_std': Array(890.25854, dtype=float32), 'eval/episode_reward_std': Array(884.9092, dtype=float32), 'eval/episode_reward_alive_std': Array(43.16124, dtype=float32), 'eval/episode_reward_linvel_std': Array(890.25854, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.446726, dtype=float32), 'eval/episode_x_position_std': Array(474.95056, dtype=float32), 'eval/episode_x_velocity_std': Array(178.05167, dtype=float32), 'eval/episode_y_position_std': Array(310.10458, dtype=float32), 'eval/episode_y_velocity_std': Array(94.89541, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44677114486694, 'eval/sps': 938.0947524518633, 'num_steps': 42762240}
{'eval/walltime': 71566.65401768684, 'training/sps': 2938.0066779450726, 'training/walltime': 14571.178785324097, 'training/entropy_loss': Array(0.01852725, dtype=float32), 'training/policy_loss': Array(0.00893951, dtype=float32), 'training/total_loss': Array(0.22214988, dtype=float32), 'training/v_loss': Array(0.19468312, dtype=float32), 'eval/episode_distance_from_origin': Array(6806.903, dtype=float32), 'eval/episode_distance_reward': Array(33.461155, dtype=float32), 'eval/episode_forward_reward': Array(5576.827, dtype=float32), 'eval/episode_reward': Array(5571.6426, dtype=float32), 'eval/episode_reward_alive': Array(381.7539, dtype=float32), 'eval/episode_reward_linvel': Array(5576.827, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.39996, dtype=float32), 'eval/episode_x_position': Array(6759.1826, dtype=float32), 'eval/episode_x_velocity': Array(1115.3655, dtype=float32), 'eval/episode_y_position': Array(-24.020826, dtype=float32), 'eval/episode_y_velocity': Array(-143.40701, dtype=float32), 'eval/episode_distance_from_origin_std': Array(397.53223, dtype=float32), 'eval/episode_distance_reward_std': Array(4.865549, dtype=float32), 'eval/episode_forward_reward_std': Array(810.91907, dtype=float32), 'eval/episode_reward_std': Array(813.9452, dtype=float32), 'eval/episode_reward_alive_std': Array(41.426327, dtype=float32), 'eval/episode_reward_linvel_std': Array(810.91907, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.743755, dtype=float32), 'eval/episode_x_position_std': Array(400.1275, dtype=float32), 'eval/episode_x_velocity_std': Array(162.18379, dtype=float32), 'eval/episode_y_position_std': Array(318.30612, dtype=float32), 'eval/episode_y_velocity_std': Array(93.746925, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24961876869202, 'eval/sps': 939.4521698978314, 'num_steps': 42844160}
{'eval/walltime': 71703.17320990562, 'training/sps': 2938.7953211490544, 'training/walltime': 14599.054152965546, 'training/entropy_loss': Array(0.01881269, dtype=float32), 'training/policy_loss': Array(0.00794522, dtype=float32), 'training/total_loss': Array(0.2688731, dtype=float32), 'training/v_loss': Array(0.2421152, dtype=float32), 'eval/episode_distance_from_origin': Array(6858.3193, dtype=float32), 'eval/episode_distance_reward': Array(33.648598, dtype=float32), 'eval/episode_forward_reward': Array(5608.0674, dtype=float32), 'eval/episode_reward': Array(5603.2725, dtype=float32), 'eval/episode_reward_alive': Array(382.21094, dtype=float32), 'eval/episode_reward_linvel': Array(5608.0674, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.6549, dtype=float32), 'eval/episode_x_position': Array(6809.309, dtype=float32), 'eval/episode_x_velocity': Array(1121.6135, dtype=float32), 'eval/episode_y_position': Array(-64.60624, dtype=float32), 'eval/episode_y_velocity': Array(-150.68208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(426.9143, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1310506, dtype=float32), 'eval/episode_forward_reward_std': Array(855.16956, dtype=float32), 'eval/episode_reward_std': Array(861.39246, dtype=float32), 'eval/episode_reward_alive_std': Array(37.80075, dtype=float32), 'eval/episode_reward_linvel_std': Array(855.16956, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.392683, dtype=float32), 'eval/episode_x_position_std': Array(428.2831, dtype=float32), 'eval/episode_x_velocity_std': Array(171.03392, dtype=float32), 'eval/episode_y_position_std': Array(341.21292, dtype=float32), 'eval/episode_y_velocity_std': Array(104.76178, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51919221878052, 'eval/sps': 937.5971093857047, 'num_steps': 42926080}
{'eval/walltime': 71839.49848818779, 'training/sps': 2943.555628960343, 'training/walltime': 14626.884440660477, 'training/entropy_loss': Array(0.01892176, dtype=float32), 'training/policy_loss': Array(0.00720054, dtype=float32), 'training/total_loss': Array(0.26673657, dtype=float32), 'training/v_loss': Array(0.24061428, dtype=float32), 'eval/episode_distance_from_origin': Array(6796.2656, dtype=float32), 'eval/episode_distance_reward': Array(33.29435, dtype=float32), 'eval/episode_forward_reward': Array(5549.028, dtype=float32), 'eval/episode_reward': Array(5535.388, dtype=float32), 'eval/episode_reward_alive': Array(373.5, dtype=float32), 'eval/episode_reward_linvel': Array(5549.028, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.4332, dtype=float32), 'eval/episode_x_position': Array(6744.888, dtype=float32), 'eval/episode_x_velocity': Array(1109.8055, dtype=float32), 'eval/episode_y_position': Array(-159.9236, dtype=float32), 'eval/episode_y_velocity': Array(-170.58983, dtype=float32), 'eval/episode_distance_from_origin_std': Array(434.2634, dtype=float32), 'eval/episode_distance_reward_std': Array(5.313188, dtype=float32), 'eval/episode_forward_reward_std': Array(885.5257, dtype=float32), 'eval/episode_reward_std': Array(882.24915, dtype=float32), 'eval/episode_reward_alive_std': Array(42.084225, dtype=float32), 'eval/episode_reward_linvel_std': Array(885.5257, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.721601, dtype=float32), 'eval/episode_x_position_std': Array(436.97745, dtype=float32), 'eval/episode_x_velocity_std': Array(177.1052, dtype=float32), 'eval/episode_y_position_std': Array(342.72223, dtype=float32), 'eval/episode_y_velocity_std': Array(108.6501, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32527828216553, 'eval/sps': 938.930780944867, 'num_steps': 43008000}
{'eval/walltime': 71976.01022386551, 'training/sps': 2933.6093925188925, 'training/walltime': 14654.80908536911, 'training/entropy_loss': Array(0.0154911, dtype=float32), 'training/policy_loss': Array(0.00561392, dtype=float32), 'training/total_loss': Array(0.07307017, dtype=float32), 'training/v_loss': Array(0.05196515, dtype=float32), 'eval/episode_distance_from_origin': Array(6820.676, dtype=float32), 'eval/episode_distance_reward': Array(33.081398, dtype=float32), 'eval/episode_forward_reward': Array(5513.535, dtype=float32), 'eval/episode_reward': Array(5504.8125, dtype=float32), 'eval/episode_reward_alive': Array(380.83594, dtype=float32), 'eval/episode_reward_linvel': Array(5513.535, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.63928, dtype=float32), 'eval/episode_x_position': Array(6770.8564, dtype=float32), 'eval/episode_x_velocity': Array(1102.707, dtype=float32), 'eval/episode_y_position': Array(-79.766884, dtype=float32), 'eval/episode_y_velocity': Array(-140.44974, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.89258, dtype=float32), 'eval/episode_distance_reward_std': Array(5.431994, dtype=float32), 'eval/episode_forward_reward_std': Array(905.32654, dtype=float32), 'eval/episode_reward_std': Array(906.45337, dtype=float32), 'eval/episode_reward_alive_std': Array(44.521328, dtype=float32), 'eval/episode_reward_linvel_std': Array(905.32654, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.703474, dtype=float32), 'eval/episode_x_position_std': Array(471.0652, dtype=float32), 'eval/episode_x_velocity_std': Array(181.06528, dtype=float32), 'eval/episode_y_position_std': Array(375.00458, dtype=float32), 'eval/episode_y_velocity_std': Array(116.3336, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51173567771912, 'eval/sps': 937.6483227946507, 'num_steps': 43089920}
{'eval/walltime': 72112.35587310791, 'training/sps': 2938.0466477286627, 'training/walltime': 14682.691556215286, 'training/entropy_loss': Array(0.01767994, dtype=float32), 'training/policy_loss': Array(0.01244783, dtype=float32), 'training/total_loss': Array(0.195002, dtype=float32), 'training/v_loss': Array(0.16487424, dtype=float32), 'eval/episode_distance_from_origin': Array(6782.998, dtype=float32), 'eval/episode_distance_reward': Array(32.887638, dtype=float32), 'eval/episode_forward_reward': Array(5481.2417, dtype=float32), 'eval/episode_reward': Array(5464.2466, dtype=float32), 'eval/episode_reward_alive': Array(371.89844, dtype=float32), 'eval/episode_reward_linvel': Array(5481.2417, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.781, dtype=float32), 'eval/episode_x_position': Array(6731.94, dtype=float32), 'eval/episode_x_velocity': Array(1096.2483, dtype=float32), 'eval/episode_y_position': Array(-123.5293, dtype=float32), 'eval/episode_y_velocity': Array(-160.62817, dtype=float32), 'eval/episode_distance_from_origin_std': Array(463.83365, dtype=float32), 'eval/episode_distance_reward_std': Array(5.535873, dtype=float32), 'eval/episode_forward_reward_std': Array(922.63904, dtype=float32), 'eval/episode_reward_std': Array(926.49176, dtype=float32), 'eval/episode_reward_alive_std': Array(44.496635, dtype=float32), 'eval/episode_reward_linvel_std': Array(922.63904, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.230429, dtype=float32), 'eval/episode_x_position_std': Array(465.75464, dtype=float32), 'eval/episode_x_velocity_std': Array(184.52774, dtype=float32), 'eval/episode_y_position_std': Array(353.1282, dtype=float32), 'eval/episode_y_velocity_std': Array(111.83598, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34564924240112, 'eval/sps': 938.7904983490608, 'num_steps': 43171840}
{'eval/walltime': 72249.05344724655, 'training/sps': 2939.8138659276215, 'training/walltime': 14710.557265996933, 'training/entropy_loss': Array(0.01686181, dtype=float32), 'training/policy_loss': Array(0.01006677, dtype=float32), 'training/total_loss': Array(0.1586889, dtype=float32), 'training/v_loss': Array(0.1317603, dtype=float32), 'eval/episode_distance_from_origin': Array(6795.83, dtype=float32), 'eval/episode_distance_reward': Array(32.74954, dtype=float32), 'eval/episode_forward_reward': Array(5458.2236, dtype=float32), 'eval/episode_reward': Array(5450.2485, dtype=float32), 'eval/episode_reward_alive': Array(381.375, dtype=float32), 'eval/episode_reward_linvel': Array(5458.2236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.1003, dtype=float32), 'eval/episode_x_position': Array(6742.284, dtype=float32), 'eval/episode_x_velocity': Array(1091.6449, dtype=float32), 'eval/episode_y_position': Array(-184.79866, dtype=float32), 'eval/episode_y_velocity': Array(-176.63284, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.4168, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0070124, dtype=float32), 'eval/episode_forward_reward_std': Array(834.49603, dtype=float32), 'eval/episode_reward_std': Array(832.13855, dtype=float32), 'eval/episode_reward_alive_std': Array(39.812008, dtype=float32), 'eval/episode_reward_linvel_std': Array(834.49603, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.778267, dtype=float32), 'eval/episode_x_position_std': Array(437.5025, dtype=float32), 'eval/episode_x_velocity_std': Array(166.89932, dtype=float32), 'eval/episode_y_position_std': Array(342.12344, dtype=float32), 'eval/episode_y_velocity_std': Array(96.69499, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69757413864136, 'eval/sps': 936.3736028715468, 'num_steps': 43253760}
{'eval/walltime': 72385.39265561104, 'training/sps': 2941.0260611045614, 'training/walltime': 14738.411490440369, 'training/entropy_loss': Array(0.01717985, dtype=float32), 'training/policy_loss': Array(0.00745779, dtype=float32), 'training/total_loss': Array(0.1946145, dtype=float32), 'training/v_loss': Array(0.16997686, dtype=float32), 'eval/episode_distance_from_origin': Array(6920.536, dtype=float32), 'eval/episode_distance_reward': Array(33.85684, dtype=float32), 'eval/episode_forward_reward': Array(5642.7744, dtype=float32), 'eval/episode_reward': Array(5625.196, dtype=float32), 'eval/episode_reward_alive': Array(370.15234, dtype=float32), 'eval/episode_reward_linvel': Array(5642.7744, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.58826, dtype=float32), 'eval/episode_x_position': Array(6869.8545, dtype=float32), 'eval/episode_x_velocity': Array(1128.5549, dtype=float32), 'eval/episode_y_position': Array(-195.70177, dtype=float32), 'eval/episode_y_velocity': Array(-173.40768, dtype=float32), 'eval/episode_distance_from_origin_std': Array(398.4287, dtype=float32), 'eval/episode_distance_reward_std': Array(4.502584, dtype=float32), 'eval/episode_forward_reward_std': Array(750.42554, dtype=float32), 'eval/episode_reward_std': Array(756.6154, dtype=float32), 'eval/episode_reward_alive_std': Array(43.782425, dtype=float32), 'eval/episode_reward_linvel_std': Array(750.42554, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.162071, dtype=float32), 'eval/episode_x_position_std': Array(400.50446, dtype=float32), 'eval/episode_x_velocity_std': Array(150.08513, dtype=float32), 'eval/episode_y_position_std': Array(309.68542, dtype=float32), 'eval/episode_y_velocity_std': Array(88.43527, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3392083644867, 'eval/sps': 938.8348482837541, 'num_steps': 43335680}
{'eval/walltime': 72521.97185897827, 'training/sps': 2949.7173300243135, 'training/walltime': 14766.183643102646, 'training/entropy_loss': Array(0.01700895, dtype=float32), 'training/policy_loss': Array(0.00692943, dtype=float32), 'training/total_loss': Array(0.23513944, dtype=float32), 'training/v_loss': Array(0.21120104, dtype=float32), 'eval/episode_distance_from_origin': Array(6860.2334, dtype=float32), 'eval/episode_distance_reward': Array(33.631104, dtype=float32), 'eval/episode_forward_reward': Array(5605.1523, dtype=float32), 'eval/episode_reward': Array(5589.8735, dtype=float32), 'eval/episode_reward_alive': Array(372.96094, dtype=float32), 'eval/episode_reward_linvel': Array(5605.1523, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.87094, dtype=float32), 'eval/episode_x_position': Array(6809.47, dtype=float32), 'eval/episode_x_velocity': Array(1121.0305, dtype=float32), 'eval/episode_y_position': Array(-117.18348, dtype=float32), 'eval/episode_y_velocity': Array(-161.89478, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.36865, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4918456, dtype=float32), 'eval/episode_forward_reward_std': Array(748.6353, dtype=float32), 'eval/episode_reward_std': Array(748.2102, dtype=float32), 'eval/episode_reward_alive_std': Array(38.294327, dtype=float32), 'eval/episode_reward_linvel_std': Array(748.6353, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.150581, dtype=float32), 'eval/episode_x_position_std': Array(420.89716, dtype=float32), 'eval/episode_x_velocity_std': Array(149.72707, dtype=float32), 'eval/episode_y_position_std': Array(345.08502, dtype=float32), 'eval/episode_y_velocity_std': Array(109.11028, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57920336723328, 'eval/sps': 937.1851412534193, 'num_steps': 43417600}
{'eval/walltime': 72658.24436807632, 'training/sps': 2949.663545473646, 'training/walltime': 14793.956302165985, 'training/entropy_loss': Array(0.01716684, dtype=float32), 'training/policy_loss': Array(0.01057972, dtype=float32), 'training/total_loss': Array(0.26622534, dtype=float32), 'training/v_loss': Array(0.23847876, dtype=float32), 'eval/episode_distance_from_origin': Array(6834.5654, dtype=float32), 'eval/episode_distance_reward': Array(33.11271, dtype=float32), 'eval/episode_forward_reward': Array(5518.753, dtype=float32), 'eval/episode_reward': Array(5509.286, dtype=float32), 'eval/episode_reward_alive': Array(384.26562, dtype=float32), 'eval/episode_reward_linvel': Array(5518.753, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.84528, dtype=float32), 'eval/episode_x_position': Array(6782.095, dtype=float32), 'eval/episode_x_velocity': Array(1103.7507, dtype=float32), 'eval/episode_y_position': Array(-165.13141, dtype=float32), 'eval/episode_y_velocity': Array(-167.08214, dtype=float32), 'eval/episode_distance_from_origin_std': Array(499.71503, dtype=float32), 'eval/episode_distance_reward_std': Array(5.980169, dtype=float32), 'eval/episode_forward_reward_std': Array(996.6884, dtype=float32), 'eval/episode_reward_std': Array(997.1484, dtype=float32), 'eval/episode_reward_alive_std': Array(43.058365, dtype=float32), 'eval/episode_reward_linvel_std': Array(996.6884, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.338165, dtype=float32), 'eval/episode_x_position_std': Array(500.6695, dtype=float32), 'eval/episode_x_velocity_std': Array(199.33763, dtype=float32), 'eval/episode_y_position_std': Array(358.31052, dtype=float32), 'eval/episode_y_velocity_std': Array(102.89266, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27250909805298, 'eval/sps': 939.2943657322651, 'num_steps': 43499520}
{'eval/walltime': 72794.7015838623, 'training/sps': 2954.832594817353, 'training/walltime': 14821.68037700653, 'training/entropy_loss': Array(0.01322937, dtype=float32), 'training/policy_loss': Array(0.00500225, dtype=float32), 'training/total_loss': Array(0.10194721, dtype=float32), 'training/v_loss': Array(0.08371559, dtype=float32), 'eval/episode_distance_from_origin': Array(6807.847, dtype=float32), 'eval/episode_distance_reward': Array(33.21027, dtype=float32), 'eval/episode_forward_reward': Array(5535.0137, dtype=float32), 'eval/episode_reward': Array(5517.6772, dtype=float32), 'eval/episode_reward_alive': Array(372.2461, dtype=float32), 'eval/episode_reward_linvel': Array(5535.0137, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.79294, dtype=float32), 'eval/episode_x_position': Array(6758.3467, dtype=float32), 'eval/episode_x_velocity': Array(1107.0027, dtype=float32), 'eval/episode_y_position': Array(-186.108, dtype=float32), 'eval/episode_y_velocity': Array(-172.15057, dtype=float32), 'eval/episode_distance_from_origin_std': Array(499.04102, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5322356, dtype=float32), 'eval/episode_forward_reward_std': Array(922.0351, dtype=float32), 'eval/episode_reward_std': Array(920.4354, dtype=float32), 'eval/episode_reward_alive_std': Array(45.88543, dtype=float32), 'eval/episode_reward_linvel_std': Array(922.0351, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.031635, dtype=float32), 'eval/episode_x_position_std': Array(500.02588, dtype=float32), 'eval/episode_x_velocity_std': Array(184.407, dtype=float32), 'eval/episode_y_position_std': Array(306.2001, dtype=float32), 'eval/episode_y_velocity_std': Array(83.129456, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45721578598022, 'eval/sps': 938.022949264592, 'num_steps': 43581440}
{'eval/walltime': 72930.95168590546, 'training/sps': 2962.574489937314, 'training/walltime': 14849.332002401352, 'training/entropy_loss': Array(0.01923677, dtype=float32), 'training/policy_loss': Array(0.01067563, dtype=float32), 'training/total_loss': Array(0.14373054, dtype=float32), 'training/v_loss': Array(0.11381814, dtype=float32), 'eval/episode_distance_from_origin': Array(6824.733, dtype=float32), 'eval/episode_distance_reward': Array(32.740013, dtype=float32), 'eval/episode_forward_reward': Array(5456.639, dtype=float32), 'eval/episode_reward': Array(5442.3555, dtype=float32), 'eval/episode_reward_alive': Array(378.32422, dtype=float32), 'eval/episode_reward_linvel': Array(5456.639, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.3473, dtype=float32), 'eval/episode_x_position': Array(6773.0083, dtype=float32), 'eval/episode_x_velocity': Array(1091.3275, dtype=float32), 'eval/episode_y_position': Array(-125.53465, dtype=float32), 'eval/episode_y_velocity': Array(-155.65541, dtype=float32), 'eval/episode_distance_from_origin_std': Array(504.376, dtype=float32), 'eval/episode_distance_reward_std': Array(5.748361, dtype=float32), 'eval/episode_forward_reward_std': Array(958.0538, dtype=float32), 'eval/episode_reward_std': Array(967.12665, dtype=float32), 'eval/episode_reward_alive_std': Array(47.19986, dtype=float32), 'eval/episode_reward_linvel_std': Array(958.0538, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.12834, dtype=float32), 'eval/episode_x_position_std': Array(505.9392, dtype=float32), 'eval/episode_x_velocity_std': Array(191.61078, dtype=float32), 'eval/episode_y_position_std': Array(372.96436, dtype=float32), 'eval/episode_y_velocity_std': Array(114.8557, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25010204315186, 'eval/sps': 939.4488376930613, 'num_steps': 43663360}
{'eval/walltime': 73067.39552617073, 'training/sps': 2946.370905027761, 'training/walltime': 14877.135698080063, 'training/entropy_loss': Array(0.01735236, dtype=float32), 'training/policy_loss': Array(0.01902046, dtype=float32), 'training/total_loss': Array(0.21862347, dtype=float32), 'training/v_loss': Array(0.18225065, dtype=float32), 'eval/episode_distance_from_origin': Array(6781.067, dtype=float32), 'eval/episode_distance_reward': Array(32.955067, dtype=float32), 'eval/episode_forward_reward': Array(5492.4795, dtype=float32), 'eval/episode_reward': Array(5490.399, dtype=float32), 'eval/episode_reward_alive': Array(388.11328, dtype=float32), 'eval/episode_reward_linvel': Array(5492.4795, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.1485, dtype=float32), 'eval/episode_x_position': Array(6726.9775, dtype=float32), 'eval/episode_x_velocity': Array(1098.4958, dtype=float32), 'eval/episode_y_position': Array(-192.89143, dtype=float32), 'eval/episode_y_velocity': Array(-173.31543, dtype=float32), 'eval/episode_distance_from_origin_std': Array(475.8251, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2093287, dtype=float32), 'eval/episode_forward_reward_std': Array(868.2158, dtype=float32), 'eval/episode_reward_std': Array(869.0009, dtype=float32), 'eval/episode_reward_alive_std': Array(38.359077, dtype=float32), 'eval/episode_reward_linvel_std': Array(868.2158, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.684404, dtype=float32), 'eval/episode_x_position_std': Array(476.13077, dtype=float32), 'eval/episode_x_velocity_std': Array(173.64311, dtype=float32), 'eval/episode_y_position_std': Array(353.9267, dtype=float32), 'eval/episode_y_velocity_std': Array(116.071526, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44384026527405, 'eval/sps': 938.1149031802569, 'num_steps': 43745280}
{'eval/walltime': 73203.65354990959, 'training/sps': 2955.82167990759, 'training/walltime': 14904.850495815277, 'training/entropy_loss': Array(0.01781111, dtype=float32), 'training/policy_loss': Array(0.00740927, dtype=float32), 'training/total_loss': Array(0.22729489, dtype=float32), 'training/v_loss': Array(0.20207453, dtype=float32), 'eval/episode_distance_from_origin': Array(6878.325, dtype=float32), 'eval/episode_distance_reward': Array(33.698967, dtype=float32), 'eval/episode_forward_reward': Array(5616.463, dtype=float32), 'eval/episode_reward': Array(5608.9854, dtype=float32), 'eval/episode_reward_alive': Array(384.26953, dtype=float32), 'eval/episode_reward_linvel': Array(5616.463, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.4458, dtype=float32), 'eval/episode_x_position': Array(6828.093, dtype=float32), 'eval/episode_x_velocity': Array(1123.2927, dtype=float32), 'eval/episode_y_position': Array(-162.91168, dtype=float32), 'eval/episode_y_velocity': Array(-156.28226, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.06363, dtype=float32), 'eval/episode_distance_reward_std': Array(5.032731, dtype=float32), 'eval/episode_forward_reward_std': Array(838.7833, dtype=float32), 'eval/episode_reward_std': Array(835.18317, dtype=float32), 'eval/episode_reward_alive_std': Array(44.384106, dtype=float32), 'eval/episode_reward_linvel_std': Array(838.7833, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.253866, dtype=float32), 'eval/episode_x_position_std': Array(437.94934, dtype=float32), 'eval/episode_x_velocity_std': Array(167.75667, dtype=float32), 'eval/episode_y_position_std': Array(335.97214, dtype=float32), 'eval/episode_y_velocity_std': Array(113.62302, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25802373886108, 'eval/sps': 939.3942205217389, 'num_steps': 43827200}
{'eval/walltime': 73340.20080947876, 'training/sps': 2927.2837306780657, 'training/walltime': 14932.835483789444, 'training/entropy_loss': Array(0.01761175, dtype=float32), 'training/policy_loss': Array(0.00784153, dtype=float32), 'training/total_loss': Array(0.23265897, dtype=float32), 'training/v_loss': Array(0.20720568, dtype=float32), 'eval/episode_distance_from_origin': Array(6893.7383, dtype=float32), 'eval/episode_distance_reward': Array(33.808754, dtype=float32), 'eval/episode_forward_reward': Array(5634.7603, dtype=float32), 'eval/episode_reward': Array(5630.426, dtype=float32), 'eval/episode_reward_alive': Array(385.0664, dtype=float32), 'eval/episode_reward_linvel': Array(5634.7603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.20987, dtype=float32), 'eval/episode_x_position': Array(6840.8984, dtype=float32), 'eval/episode_x_velocity': Array(1126.9521, dtype=float32), 'eval/episode_y_position': Array(-172.80832, dtype=float32), 'eval/episode_y_velocity': Array(-161.25357, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.41614, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6623883, dtype=float32), 'eval/episode_forward_reward_std': Array(943.7249, dtype=float32), 'eval/episode_reward_std': Array(953.5235, dtype=float32), 'eval/episode_reward_alive_std': Array(34.48847, dtype=float32), 'eval/episode_reward_linvel_std': Array(943.7249, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.945257, dtype=float32), 'eval/episode_x_position_std': Array(487.6301, dtype=float32), 'eval/episode_x_velocity_std': Array(188.74506, dtype=float32), 'eval/episode_y_position_std': Array(366.05, dtype=float32), 'eval/episode_y_velocity_std': Array(118.06764, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5472595691681, 'eval/sps': 937.4043858797586, 'num_steps': 43909120}
{'eval/walltime': 73476.55319356918, 'training/sps': 2934.4908337799156, 'training/walltime': 14960.751740694046, 'training/entropy_loss': Array(0.01805722, dtype=float32), 'training/policy_loss': Array(0.00768741, dtype=float32), 'training/total_loss': Array(0.25680354, dtype=float32), 'training/v_loss': Array(0.23105891, dtype=float32), 'eval/episode_distance_from_origin': Array(6855.0806, dtype=float32), 'eval/episode_distance_reward': Array(33.396408, dtype=float32), 'eval/episode_forward_reward': Array(5566.036, dtype=float32), 'eval/episode_reward': Array(5555.126, dtype=float32), 'eval/episode_reward_alive': Array(381.07812, dtype=float32), 'eval/episode_reward_linvel': Array(5566.036, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.38446, dtype=float32), 'eval/episode_x_position': Array(6802.447, dtype=float32), 'eval/episode_x_velocity': Array(1113.2073, dtype=float32), 'eval/episode_y_position': Array(-155.04138, dtype=float32), 'eval/episode_y_velocity': Array(-165.51395, dtype=float32), 'eval/episode_distance_from_origin_std': Array(444.07727, dtype=float32), 'eval/episode_distance_reward_std': Array(4.943363, dtype=float32), 'eval/episode_forward_reward_std': Array(823.8884, dtype=float32), 'eval/episode_reward_std': Array(824.7448, dtype=float32), 'eval/episode_reward_alive_std': Array(39.059822, dtype=float32), 'eval/episode_reward_linvel_std': Array(823.8884, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.534113, dtype=float32), 'eval/episode_x_position_std': Array(445.81018, dtype=float32), 'eval/episode_x_velocity_std': Array(164.77774, dtype=float32), 'eval/episode_y_position_std': Array(365.3714, dtype=float32), 'eval/episode_y_velocity_std': Array(118.72137, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35238409042358, 'eval/sps': 938.7441287063627, 'num_steps': 43991040}
{'eval/walltime': 73613.11923480034, 'training/sps': 2930.972493330238, 'training/walltime': 14988.701508283615, 'training/entropy_loss': Array(0.01465194, dtype=float32), 'training/policy_loss': Array(0.00557521, dtype=float32), 'training/total_loss': Array(0.15866432, dtype=float32), 'training/v_loss': Array(0.13843715, dtype=float32), 'eval/episode_distance_from_origin': Array(6781.374, dtype=float32), 'eval/episode_distance_reward': Array(32.501125, dtype=float32), 'eval/episode_forward_reward': Array(5416.823, dtype=float32), 'eval/episode_reward': Array(5399.559, dtype=float32), 'eval/episode_reward_alive': Array(382.26562, dtype=float32), 'eval/episode_reward_linvel': Array(5416.823, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.03214, dtype=float32), 'eval/episode_x_position': Array(6728.977, dtype=float32), 'eval/episode_x_velocity': Array(1083.3649, dtype=float32), 'eval/episode_y_position': Array(-103.45567, dtype=float32), 'eval/episode_y_velocity': Array(-154.15839, dtype=float32), 'eval/episode_distance_from_origin_std': Array(577.4953, dtype=float32), 'eval/episode_distance_reward_std': Array(6.591901, dtype=float32), 'eval/episode_forward_reward_std': Array(1098.6423, dtype=float32), 'eval/episode_reward_std': Array(1099.6819, dtype=float32), 'eval/episode_reward_alive_std': Array(44.661877, dtype=float32), 'eval/episode_reward_linvel_std': Array(1098.6423, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.19007, dtype=float32), 'eval/episode_x_position_std': Array(579.85376, dtype=float32), 'eval/episode_x_velocity_std': Array(219.72856, dtype=float32), 'eval/episode_y_position_std': Array(384.4472, dtype=float32), 'eval/episode_y_velocity_std': Array(122.49774, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5660412311554, 'eval/sps': 937.2754664781102, 'num_steps': 44072960}
{'eval/walltime': 73749.52145910263, 'training/sps': 2946.5737237973444, 'training/walltime': 15016.503290176392, 'training/entropy_loss': Array(0.0192796, dtype=float32), 'training/policy_loss': Array(0.01478373, dtype=float32), 'training/total_loss': Array(0.14466682, dtype=float32), 'training/v_loss': Array(0.1106035, dtype=float32), 'eval/episode_distance_from_origin': Array(6832.9385, dtype=float32), 'eval/episode_distance_reward': Array(33.33285, dtype=float32), 'eval/episode_forward_reward': Array(5555.4424, dtype=float32), 'eval/episode_reward': Array(5546.0215, dtype=float32), 'eval/episode_reward_alive': Array(384.26172, dtype=float32), 'eval/episode_reward_linvel': Array(5555.4424, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.01535, dtype=float32), 'eval/episode_x_position': Array(6781.054, dtype=float32), 'eval/episode_x_velocity': Array(1111.0884, dtype=float32), 'eval/episode_y_position': Array(-132.51393, dtype=float32), 'eval/episode_y_velocity': Array(-159.4282, dtype=float32), 'eval/episode_distance_from_origin_std': Array(459.45322, dtype=float32), 'eval/episode_distance_reward_std': Array(5.241874, dtype=float32), 'eval/episode_forward_reward_std': Array(873.6406, dtype=float32), 'eval/episode_reward_std': Array(876.5315, dtype=float32), 'eval/episode_reward_alive_std': Array(41.414677, dtype=float32), 'eval/episode_reward_linvel_std': Array(873.6406, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.12112, dtype=float32), 'eval/episode_x_position_std': Array(461.2146, dtype=float32), 'eval/episode_x_velocity_std': Array(174.72807, dtype=float32), 'eval/episode_y_position_std': Array(365.1691, dtype=float32), 'eval/episode_y_velocity_std': Array(125.85588, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40222430229187, 'eval/sps': 938.401119591195, 'num_steps': 44154880}
{'eval/walltime': 73886.04827165604, 'training/sps': 2929.0110798189303, 'training/walltime': 15044.471774339676, 'training/entropy_loss': Array(0.01715347, dtype=float32), 'training/policy_loss': Array(0.01200883, dtype=float32), 'training/total_loss': Array(0.19646728, dtype=float32), 'training/v_loss': Array(0.167305, dtype=float32), 'eval/episode_distance_from_origin': Array(6913.414, dtype=float32), 'eval/episode_distance_reward': Array(33.6547, dtype=float32), 'eval/episode_forward_reward': Array(5609.085, dtype=float32), 'eval/episode_reward': Array(5594.743, dtype=float32), 'eval/episode_reward_alive': Array(375.96484, dtype=float32), 'eval/episode_reward_linvel': Array(5609.085, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.96136, dtype=float32), 'eval/episode_x_position': Array(6858.712, dtype=float32), 'eval/episode_x_velocity': Array(1121.8169, dtype=float32), 'eval/episode_y_position': Array(-176.36938, dtype=float32), 'eval/episode_y_velocity': Array(-176.34756, dtype=float32), 'eval/episode_distance_from_origin_std': Array(469.4583, dtype=float32), 'eval/episode_distance_reward_std': Array(5.263724, dtype=float32), 'eval/episode_forward_reward_std': Array(877.2819, dtype=float32), 'eval/episode_reward_std': Array(882.24097, dtype=float32), 'eval/episode_reward_alive_std': Array(43.932972, dtype=float32), 'eval/episode_reward_linvel_std': Array(877.2819, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.870766, dtype=float32), 'eval/episode_x_position_std': Array(474.56845, dtype=float32), 'eval/episode_x_velocity_std': Array(175.45624, dtype=float32), 'eval/episode_y_position_std': Array(364.55606, dtype=float32), 'eval/episode_y_velocity_std': Array(111.736275, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52681255340576, 'eval/sps': 937.544776780969, 'num_steps': 44236800}
{'eval/walltime': 74022.33138895035, 'training/sps': 2943.4529990583533, 'training/walltime': 15072.303032398224, 'training/entropy_loss': Array(0.01762202, dtype=float32), 'training/policy_loss': Array(0.00593951, dtype=float32), 'training/total_loss': Array(0.16367976, dtype=float32), 'training/v_loss': Array(0.14011824, dtype=float32), 'eval/episode_distance_from_origin': Array(6888.223, dtype=float32), 'eval/episode_distance_reward': Array(33.34214, dtype=float32), 'eval/episode_forward_reward': Array(5556.9917, dtype=float32), 'eval/episode_reward': Array(5539.301, dtype=float32), 'eval/episode_reward_alive': Array(378.72266, dtype=float32), 'eval/episode_reward_linvel': Array(5556.9917, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.75626, dtype=float32), 'eval/episode_x_position': Array(6835.0103, dtype=float32), 'eval/episode_x_velocity': Array(1111.3982, dtype=float32), 'eval/episode_y_position': Array(-207.35596, dtype=float32), 'eval/episode_y_velocity': Array(-178.87807, dtype=float32), 'eval/episode_distance_from_origin_std': Array(469.54834, dtype=float32), 'eval/episode_distance_reward_std': Array(5.233028, dtype=float32), 'eval/episode_forward_reward_std': Array(872.16565, dtype=float32), 'eval/episode_reward_std': Array(874.4888, dtype=float32), 'eval/episode_reward_alive_std': Array(39.89918, dtype=float32), 'eval/episode_reward_linvel_std': Array(872.16565, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.11036, dtype=float32), 'eval/episode_x_position_std': Array(470.94174, dtype=float32), 'eval/episode_x_velocity_std': Array(174.4332, dtype=float32), 'eval/episode_y_position_std': Array(331.56558, dtype=float32), 'eval/episode_y_velocity_std': Array(92.746216, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28311729431152, 'eval/sps': 939.2212516211847, 'num_steps': 44318720}
{'eval/walltime': 74158.78857588768, 'training/sps': 2930.147611659088, 'training/walltime': 15100.26066827774, 'training/entropy_loss': Array(0.01730885, dtype=float32), 'training/policy_loss': Array(0.00842612, dtype=float32), 'training/total_loss': Array(0.21824354, dtype=float32), 'training/v_loss': Array(0.19250856, dtype=float32), 'eval/episode_distance_from_origin': Array(6804.263, dtype=float32), 'eval/episode_distance_reward': Array(33.026543, dtype=float32), 'eval/episode_forward_reward': Array(5504.3916, dtype=float32), 'eval/episode_reward': Array(5486.9834, dtype=float32), 'eval/episode_reward_alive': Array(377.1914, dtype=float32), 'eval/episode_reward_linvel': Array(5504.3916, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.62592, dtype=float32), 'eval/episode_x_position': Array(6751.25, dtype=float32), 'eval/episode_x_velocity': Array(1100.8783, dtype=float32), 'eval/episode_y_position': Array(-214.46524, dtype=float32), 'eval/episode_y_velocity': Array(-178.9161, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.37097, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1932044, dtype=float32), 'eval/episode_forward_reward_std': Array(865.5275, dtype=float32), 'eval/episode_reward_std': Array(875.42004, dtype=float32), 'eval/episode_reward_alive_std': Array(41.50316, dtype=float32), 'eval/episode_reward_linvel_std': Array(865.5275, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.243736, dtype=float32), 'eval/episode_x_position_std': Array(458.64236, dtype=float32), 'eval/episode_x_velocity_std': Array(173.10544, dtype=float32), 'eval/episode_y_position_std': Array(340.34705, dtype=float32), 'eval/episode_y_velocity_std': Array(94.91829, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45718693733215, 'eval/sps': 938.0231475736334, 'num_steps': 44400640}
{'eval/walltime': 74295.06359124184, 'training/sps': 2923.744899170792, 'training/walltime': 15128.279528617859, 'training/entropy_loss': Array(0.01778172, dtype=float32), 'training/policy_loss': Array(0.00717103, dtype=float32), 'training/total_loss': Array(0.25292173, dtype=float32), 'training/v_loss': Array(0.227969, dtype=float32), 'eval/episode_distance_from_origin': Array(6894.7676, dtype=float32), 'eval/episode_distance_reward': Array(33.548885, dtype=float32), 'eval/episode_forward_reward': Array(5591.45, dtype=float32), 'eval/episode_reward': Array(5579.927, dtype=float32), 'eval/episode_reward_alive': Array(376.34766, dtype=float32), 'eval/episode_reward_linvel': Array(5591.45, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.4195, dtype=float32), 'eval/episode_x_position': Array(6843.285, dtype=float32), 'eval/episode_x_velocity': Array(1118.29, dtype=float32), 'eval/episode_y_position': Array(-125.38075, dtype=float32), 'eval/episode_y_velocity': Array(-155.75453, dtype=float32), 'eval/episode_distance_from_origin_std': Array(510.82883, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9017434, dtype=float32), 'eval/episode_forward_reward_std': Array(983.61725, dtype=float32), 'eval/episode_reward_std': Array(979.12646, dtype=float32), 'eval/episode_reward_alive_std': Array(46.482803, dtype=float32), 'eval/episode_reward_linvel_std': Array(983.61725, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.538551, dtype=float32), 'eval/episode_x_position_std': Array(514.45636, dtype=float32), 'eval/episode_x_velocity_std': Array(196.72336, dtype=float32), 'eval/episode_y_position_std': Array(379.61642, dtype=float32), 'eval/episode_y_velocity_std': Array(114.89111, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2750153541565, 'eval/sps': 939.2770910159057, 'num_steps': 44482560}
{'eval/walltime': 74431.5166375637, 'training/sps': 2931.559956531358, 'training/walltime': 15156.223695278168, 'training/entropy_loss': Array(0.01555362, dtype=float32), 'training/policy_loss': Array(0.07602192, dtype=float32), 'training/total_loss': Array(0.2557788, dtype=float32), 'training/v_loss': Array(0.16420327, dtype=float32), 'eval/episode_distance_from_origin': Array(6805.0015, dtype=float32), 'eval/episode_distance_reward': Array(32.811626, dtype=float32), 'eval/episode_forward_reward': Array(5468.5737, dtype=float32), 'eval/episode_reward': Array(5455.536, dtype=float32), 'eval/episode_reward_alive': Array(378.22266, dtype=float32), 'eval/episode_reward_linvel': Array(5468.5737, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.07056, dtype=float32), 'eval/episode_x_position': Array(6752.6606, dtype=float32), 'eval/episode_x_velocity': Array(1093.7147, dtype=float32), 'eval/episode_y_position': Array(-197.38344, dtype=float32), 'eval/episode_y_velocity': Array(-172.05676, dtype=float32), 'eval/episode_distance_from_origin_std': Array(438.65976, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8400326, dtype=float32), 'eval/episode_forward_reward_std': Array(806.6659, dtype=float32), 'eval/episode_reward_std': Array(812.4336, dtype=float32), 'eval/episode_reward_alive_std': Array(45.518665, dtype=float32), 'eval/episode_reward_linvel_std': Array(806.6659, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.26621, dtype=float32), 'eval/episode_x_position_std': Array(440.59714, dtype=float32), 'eval/episode_x_velocity_std': Array(161.33333, dtype=float32), 'eval/episode_y_position_std': Array(357.27084, dtype=float32), 'eval/episode_y_velocity_std': Array(102.36893, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4530463218689, 'eval/sps': 938.0516115270183, 'num_steps': 44564480}
{'eval/walltime': 74567.8145160675, 'training/sps': 2952.3915815298487, 'training/walltime': 15183.970692157745, 'training/entropy_loss': Array(0.0165171, dtype=float32), 'training/policy_loss': Array(0.00666162, dtype=float32), 'training/total_loss': Array(0.08701447, dtype=float32), 'training/v_loss': Array(0.06383574, dtype=float32), 'eval/episode_distance_from_origin': Array(6883.454, dtype=float32), 'eval/episode_distance_reward': Array(33.173965, dtype=float32), 'eval/episode_forward_reward': Array(5528.964, dtype=float32), 'eval/episode_reward': Array(5520.7407, dtype=float32), 'eval/episode_reward_alive': Array(380.4922, dtype=float32), 'eval/episode_reward_linvel': Array(5528.964, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.88852, dtype=float32), 'eval/episode_x_position': Array(6830.871, dtype=float32), 'eval/episode_x_velocity': Array(1105.7926, dtype=float32), 'eval/episode_y_position': Array(-165.0492, dtype=float32), 'eval/episode_y_velocity': Array(-163.08577, dtype=float32), 'eval/episode_distance_from_origin_std': Array(524.24005, dtype=float32), 'eval/episode_distance_reward_std': Array(5.951355, dtype=float32), 'eval/episode_forward_reward_std': Array(991.8871, dtype=float32), 'eval/episode_reward_std': Array(989.2794, dtype=float32), 'eval/episode_reward_alive_std': Array(47.853252, dtype=float32), 'eval/episode_reward_linvel_std': Array(991.8871, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.892374, dtype=float32), 'eval/episode_x_position_std': Array(527.1274, dtype=float32), 'eval/episode_x_velocity_std': Array(198.37746, dtype=float32), 'eval/episode_y_position_std': Array(379.56387, dtype=float32), 'eval/episode_y_velocity_std': Array(111.79214, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29787850379944, 'eval/sps': 939.1195329311885, 'num_steps': 44646400}
{'eval/walltime': 74704.26668453217, 'training/sps': 2952.6884504376685, 'training/walltime': 15211.714899301529, 'training/entropy_loss': Array(0.01912435, dtype=float32), 'training/policy_loss': Array(0.00693832, dtype=float32), 'training/total_loss': Array(0.20312488, dtype=float32), 'training/v_loss': Array(0.17706221, dtype=float32), 'eval/episode_distance_from_origin': Array(6946.58, dtype=float32), 'eval/episode_distance_reward': Array(33.818787, dtype=float32), 'eval/episode_forward_reward': Array(5636.4326, dtype=float32), 'eval/episode_reward': Array(5628.1943, dtype=float32), 'eval/episode_reward_alive': Array(380.5, dtype=float32), 'eval/episode_reward_linvel': Array(5636.4326, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.55737, dtype=float32), 'eval/episode_x_position': Array(6892.863, dtype=float32), 'eval/episode_x_velocity': Array(1127.2865, dtype=float32), 'eval/episode_y_position': Array(-150.56264, dtype=float32), 'eval/episode_y_velocity': Array(-154.00659, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.93362, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2118235, dtype=float32), 'eval/episode_forward_reward_std': Array(868.6318, dtype=float32), 'eval/episode_reward_std': Array(872.5597, dtype=float32), 'eval/episode_reward_alive_std': Array(42.782837, dtype=float32), 'eval/episode_reward_linvel_std': Array(868.6318, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.25965, dtype=float32), 'eval/episode_x_position_std': Array(493.9626, dtype=float32), 'eval/episode_x_velocity_std': Array(173.72636, dtype=float32), 'eval/episode_y_position_std': Array(415.0761, dtype=float32), 'eval/episode_y_velocity_std': Array(127.13979, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45216846466064, 'eval/sps': 938.0576464283185, 'num_steps': 44728320}
{'eval/walltime': 74840.54350376129, 'training/sps': 2954.396739277309, 'training/walltime': 15239.443064212799, 'training/entropy_loss': Array(0.01717969, dtype=float32), 'training/policy_loss': Array(0.00577612, dtype=float32), 'training/total_loss': Array(0.18235347, dtype=float32), 'training/v_loss': Array(0.15939766, dtype=float32), 'eval/episode_distance_from_origin': Array(6865.1357, dtype=float32), 'eval/episode_distance_reward': Array(33.348145, dtype=float32), 'eval/episode_forward_reward': Array(5557.9917, dtype=float32), 'eval/episode_reward': Array(5556.57, dtype=float32), 'eval/episode_reward_alive': Array(387.38672, dtype=float32), 'eval/episode_reward_linvel': Array(5557.9917, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.1574, dtype=float32), 'eval/episode_x_position': Array(6811.2734, dtype=float32), 'eval/episode_x_velocity': Array(1111.5984, dtype=float32), 'eval/episode_y_position': Array(-177.81555, dtype=float32), 'eval/episode_y_velocity': Array(-165.97345, dtype=float32), 'eval/episode_distance_from_origin_std': Array(484.31552, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7563806, dtype=float32), 'eval/episode_forward_reward_std': Array(959.39075, dtype=float32), 'eval/episode_reward_std': Array(952.9576, dtype=float32), 'eval/episode_reward_alive_std': Array(41.29066, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.39075, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.54975, dtype=float32), 'eval/episode_x_position_std': Array(485.49634, dtype=float32), 'eval/episode_x_velocity_std': Array(191.87811, dtype=float32), 'eval/episode_y_position_std': Array(401.321, dtype=float32), 'eval/episode_y_velocity_std': Array(125.75265, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27681922912598, 'eval/sps': 939.2646579517685, 'num_steps': 44810240}
{'eval/walltime': 74977.00892186165, 'training/sps': 2949.646883802678, 'training/walltime': 15267.215880155563, 'training/entropy_loss': Array(0.01729645, dtype=float32), 'training/policy_loss': Array(0.00794612, dtype=float32), 'training/total_loss': Array(0.22489035, dtype=float32), 'training/v_loss': Array(0.19964778, dtype=float32), 'eval/episode_distance_from_origin': Array(6923.106, dtype=float32), 'eval/episode_distance_reward': Array(34.290207, dtype=float32), 'eval/episode_forward_reward': Array(5715.0034, dtype=float32), 'eval/episode_reward': Array(5708.5283, dtype=float32), 'eval/episode_reward_alive': Array(376.8164, dtype=float32), 'eval/episode_reward_linvel': Array(5715.0034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.58148, dtype=float32), 'eval/episode_x_position': Array(6870.3276, dtype=float32), 'eval/episode_x_velocity': Array(1143.0005, dtype=float32), 'eval/episode_y_position': Array(-155.5582, dtype=float32), 'eval/episode_y_velocity': Array(-160.71454, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.15897, dtype=float32), 'eval/episode_distance_reward_std': Array(5.221358, dtype=float32), 'eval/episode_forward_reward_std': Array(870.22107, dtype=float32), 'eval/episode_reward_std': Array(865.68384, dtype=float32), 'eval/episode_reward_alive_std': Array(39.4207, dtype=float32), 'eval/episode_reward_linvel_std': Array(870.22107, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.977916, dtype=float32), 'eval/episode_x_position_std': Array(476.12305, dtype=float32), 'eval/episode_x_velocity_std': Array(174.0442, dtype=float32), 'eval/episode_y_position_std': Array(392.45847, dtype=float32), 'eval/episode_y_velocity_std': Array(118.28903, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46541810035706, 'eval/sps': 937.9665689799041, 'num_steps': 44892160}
{'eval/walltime': 75113.34813117981, 'training/sps': 2958.7830518755172, 'training/walltime': 15294.902938842773, 'training/entropy_loss': Array(0.01758942, dtype=float32), 'training/policy_loss': Array(0.0070474, dtype=float32), 'training/total_loss': Array(0.24470732, dtype=float32), 'training/v_loss': Array(0.22007051, dtype=float32), 'eval/episode_distance_from_origin': Array(6899.019, dtype=float32), 'eval/episode_distance_reward': Array(33.987457, dtype=float32), 'eval/episode_forward_reward': Array(5664.545, dtype=float32), 'eval/episode_reward': Array(5660.11, dtype=float32), 'eval/episode_reward_alive': Array(383.60938, dtype=float32), 'eval/episode_reward_linvel': Array(5664.545, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.03046, dtype=float32), 'eval/episode_x_position': Array(6851.332, dtype=float32), 'eval/episode_x_velocity': Array(1132.9089, dtype=float32), 'eval/episode_y_position': Array(-119.191864, dtype=float32), 'eval/episode_y_velocity': Array(-156.41974, dtype=float32), 'eval/episode_distance_from_origin_std': Array(495.392, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9856057, dtype=float32), 'eval/episode_forward_reward_std': Array(997.5937, dtype=float32), 'eval/episode_reward_std': Array(996.33276, dtype=float32), 'eval/episode_reward_alive_std': Array(46.439766, dtype=float32), 'eval/episode_reward_linvel_std': Array(997.5937, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.13533, dtype=float32), 'eval/episode_x_position_std': Array(496.941, dtype=float32), 'eval/episode_x_velocity_std': Array(199.5188, dtype=float32), 'eval/episode_y_position_std': Array(332.68246, dtype=float32), 'eval/episode_y_velocity_std': Array(100.27938, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.339209318161, 'eval/sps': 938.8348417167314, 'num_steps': 44974080}
{'eval/walltime': 75249.90672492981, 'training/sps': 2945.931732725102, 'training/walltime': 15322.710779428482, 'training/entropy_loss': Array(0.018516, dtype=float32), 'training/policy_loss': Array(0.00463826, dtype=float32), 'training/total_loss': Array(0.24977843, dtype=float32), 'training/v_loss': Array(0.22662416, dtype=float32), 'eval/episode_distance_from_origin': Array(6914.9424, dtype=float32), 'eval/episode_distance_reward': Array(33.91646, dtype=float32), 'eval/episode_forward_reward': Array(5652.7114, dtype=float32), 'eval/episode_reward': Array(5649.9434, dtype=float32), 'eval/episode_reward_alive': Array(384.96875, dtype=float32), 'eval/episode_reward_linvel': Array(5652.7114, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.65317, dtype=float32), 'eval/episode_x_position': Array(6862.4062, dtype=float32), 'eval/episode_x_velocity': Array(1130.5422, dtype=float32), 'eval/episode_y_position': Array(-154.67899, dtype=float32), 'eval/episode_y_velocity': Array(-161.4721, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.219, dtype=float32), 'eval/episode_distance_reward_std': Array(4.967651, dtype=float32), 'eval/episode_forward_reward_std': Array(827.93677, dtype=float32), 'eval/episode_reward_std': Array(828.18195, dtype=float32), 'eval/episode_reward_alive_std': Array(40.14596, dtype=float32), 'eval/episode_reward_linvel_std': Array(827.93677, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.774593, dtype=float32), 'eval/episode_x_position_std': Array(422.41162, dtype=float32), 'eval/episode_x_velocity_std': Array(165.58731, dtype=float32), 'eval/episode_y_position_std': Array(386.21124, dtype=float32), 'eval/episode_y_velocity_std': Array(118.37889, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55859375, 'eval/sps': 937.3265825681513, 'num_steps': 45056000}
{'eval/walltime': 75386.24049568176, 'training/sps': 2953.438766513553, 'training/walltime': 15350.447938203812, 'training/entropy_loss': Array(0.01507065, dtype=float32), 'training/policy_loss': Array(0.00589695, dtype=float32), 'training/total_loss': Array(0.05564905, dtype=float32), 'training/v_loss': Array(0.03468145, dtype=float32), 'eval/episode_distance_from_origin': Array(6910.4946, dtype=float32), 'eval/episode_distance_reward': Array(33.72452, dtype=float32), 'eval/episode_forward_reward': Array(5620.7227, dtype=float32), 'eval/episode_reward': Array(5619.5703, dtype=float32), 'eval/episode_reward_alive': Array(387.10547, dtype=float32), 'eval/episode_reward_linvel': Array(5620.7227, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.9817, dtype=float32), 'eval/episode_x_position': Array(6858.0664, dtype=float32), 'eval/episode_x_velocity': Array(1124.1445, dtype=float32), 'eval/episode_y_position': Array(-228.51968, dtype=float32), 'eval/episode_y_velocity': Array(-177.74506, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.1658, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5093007, dtype=float32), 'eval/episode_forward_reward_std': Array(918.2101, dtype=float32), 'eval/episode_reward_std': Array(920.89374, dtype=float32), 'eval/episode_reward_alive_std': Array(41.859726, dtype=float32), 'eval/episode_reward_linvel_std': Array(918.2101, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.074509, dtype=float32), 'eval/episode_x_position_std': Array(485.3395, dtype=float32), 'eval/episode_x_velocity_std': Array(183.64206, dtype=float32), 'eval/episode_y_position_std': Array(334.83304, dtype=float32), 'eval/episode_y_velocity_std': Array(96.42489, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33377075195312, 'eval/sps': 938.8722932991001, 'num_steps': 45137920}
{'eval/walltime': 75522.92683768272, 'training/sps': 2950.879595801306, 'training/walltime': 15378.20915222168, 'training/entropy_loss': Array(0.01810408, dtype=float32), 'training/policy_loss': Array(0.00659343, dtype=float32), 'training/total_loss': Array(0.17593372, dtype=float32), 'training/v_loss': Array(0.1512362, dtype=float32), 'eval/episode_distance_from_origin': Array(6880.3467, dtype=float32), 'eval/episode_distance_reward': Array(33.12599, dtype=float32), 'eval/episode_forward_reward': Array(5520.9683, dtype=float32), 'eval/episode_reward': Array(5516.219, dtype=float32), 'eval/episode_reward_alive': Array(385.54297, dtype=float32), 'eval/episode_reward_linvel': Array(5520.9683, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.4181, dtype=float32), 'eval/episode_x_position': Array(6829.3936, dtype=float32), 'eval/episode_x_velocity': Array(1104.1937, dtype=float32), 'eval/episode_y_position': Array(-187.4277, dtype=float32), 'eval/episode_y_velocity': Array(-173.76154, dtype=float32), 'eval/episode_distance_from_origin_std': Array(496.5089, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7116227, dtype=float32), 'eval/episode_forward_reward_std': Array(951.9294, dtype=float32), 'eval/episode_reward_std': Array(948.3682, dtype=float32), 'eval/episode_reward_alive_std': Array(45.18089, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.9294, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.38182, dtype=float32), 'eval/episode_x_position_std': Array(498.05725, dtype=float32), 'eval/episode_x_velocity_std': Array(190.38596, dtype=float32), 'eval/episode_y_position_std': Array(326.8599, dtype=float32), 'eval/episode_y_velocity_std': Array(99.76869, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6863420009613, 'eval/sps': 936.4505489443839, 'num_steps': 45219840}
{'eval/walltime': 75659.32557320595, 'training/sps': 2932.7430242285427, 'training/walltime': 15406.14204621315, 'training/entropy_loss': Array(0.01784666, dtype=float32), 'training/policy_loss': Array(0.00795253, dtype=float32), 'training/total_loss': Array(0.17624465, dtype=float32), 'training/v_loss': Array(0.15044546, dtype=float32), 'eval/episode_distance_from_origin': Array(6869.739, dtype=float32), 'eval/episode_distance_reward': Array(32.984062, dtype=float32), 'eval/episode_forward_reward': Array(5497.3125, dtype=float32), 'eval/episode_reward': Array(5496.593, dtype=float32), 'eval/episode_reward_alive': Array(392.72266, dtype=float32), 'eval/episode_reward_linvel': Array(5497.3125, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.4266, dtype=float32), 'eval/episode_x_position': Array(6817.6416, dtype=float32), 'eval/episode_x_velocity': Array(1099.4626, dtype=float32), 'eval/episode_y_position': Array(-141.36406, dtype=float32), 'eval/episode_y_velocity': Array(-141.00333, dtype=float32), 'eval/episode_distance_from_origin_std': Array(499.95462, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5292416, dtype=float32), 'eval/episode_forward_reward_std': Array(921.5334, dtype=float32), 'eval/episode_reward_std': Array(923.65826, dtype=float32), 'eval/episode_reward_alive_std': Array(46.49617, dtype=float32), 'eval/episode_reward_linvel_std': Array(921.5334, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.8124, dtype=float32), 'eval/episode_x_position_std': Array(499.60526, dtype=float32), 'eval/episode_x_velocity_std': Array(184.30663, dtype=float32), 'eval/episode_y_position_std': Array(408.62314, dtype=float32), 'eval/episode_y_velocity_std': Array(140.09007, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39873552322388, 'eval/sps': 938.4251218238466, 'num_steps': 45301760}
{'eval/walltime': 75795.85245966911, 'training/sps': 2925.94783233728, 'training/walltime': 15434.13981127739, 'training/entropy_loss': Array(0.01838834, dtype=float32), 'training/policy_loss': Array(0.00838648, dtype=float32), 'training/total_loss': Array(0.2205837, dtype=float32), 'training/v_loss': Array(0.19380888, dtype=float32), 'eval/episode_distance_from_origin': Array(6962.97, dtype=float32), 'eval/episode_distance_reward': Array(34.139153, dtype=float32), 'eval/episode_forward_reward': Array(5689.8267, dtype=float32), 'eval/episode_reward': Array(5686.9854, dtype=float32), 'eval/episode_reward_alive': Array(384.90625, dtype=float32), 'eval/episode_reward_linvel': Array(5689.8267, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.88684, dtype=float32), 'eval/episode_x_position': Array(6911.9297, dtype=float32), 'eval/episode_x_velocity': Array(1137.9653, dtype=float32), 'eval/episode_y_position': Array(-194.14932, dtype=float32), 'eval/episode_y_velocity': Array(-162.1267, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.86038, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4175663, dtype=float32), 'eval/episode_forward_reward_std': Array(902.92175, dtype=float32), 'eval/episode_reward_std': Array(902.4106, dtype=float32), 'eval/episode_reward_alive_std': Array(46.105762, dtype=float32), 'eval/episode_reward_linvel_std': Array(902.92175, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.827576, dtype=float32), 'eval/episode_x_position_std': Array(467.1236, dtype=float32), 'eval/episode_x_velocity_std': Array(180.58437, dtype=float32), 'eval/episode_y_position_std': Array(353.84036, dtype=float32), 'eval/episode_y_velocity_std': Array(117.633766, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52688646316528, 'eval/sps': 937.5442692347209, 'num_steps': 45383680}
{'eval/walltime': 75932.21515083313, 'training/sps': 2936.5793569223415, 'training/walltime': 15462.036213874817, 'training/entropy_loss': Array(0.01821827, dtype=float32), 'training/policy_loss': Array(0.00735116, dtype=float32), 'training/total_loss': Array(0.24425021, dtype=float32), 'training/v_loss': Array(0.2186808, dtype=float32), 'eval/episode_distance_from_origin': Array(6888.079, dtype=float32), 'eval/episode_distance_reward': Array(33.173798, dtype=float32), 'eval/episode_forward_reward': Array(5528.935, dtype=float32), 'eval/episode_reward': Array(5525.9287, dtype=float32), 'eval/episode_reward_alive': Array(388.27734, dtype=float32), 'eval/episode_reward_linvel': Array(5528.935, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.45718, dtype=float32), 'eval/episode_x_position': Array(6835.772, dtype=float32), 'eval/episode_x_velocity': Array(1105.7871, dtype=float32), 'eval/episode_y_position': Array(-254.91876, dtype=float32), 'eval/episode_y_velocity': Array(-178.19504, dtype=float32), 'eval/episode_distance_from_origin_std': Array(455.51923, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9761333, dtype=float32), 'eval/episode_forward_reward_std': Array(829.34894, dtype=float32), 'eval/episode_reward_std': Array(825.33386, dtype=float32), 'eval/episode_reward_alive_std': Array(42.210354, dtype=float32), 'eval/episode_reward_linvel_std': Array(829.34894, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.777613, dtype=float32), 'eval/episode_x_position_std': Array(456.04556, dtype=float32), 'eval/episode_x_velocity_std': Array(165.86984, dtype=float32), 'eval/episode_y_position_std': Array(328.06982, dtype=float32), 'eval/episode_y_velocity_std': Array(109.20635, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.36269116401672, 'eval/sps': 938.6731730458583, 'num_steps': 45465600}
{'eval/walltime': 76068.89120364189, 'training/sps': 2925.9643768448045, 'training/walltime': 15490.03382062912, 'training/entropy_loss': Array(0.01806617, dtype=float32), 'training/policy_loss': Array(0.00970957, dtype=float32), 'training/total_loss': Array(0.2734444, dtype=float32), 'training/v_loss': Array(0.2456687, dtype=float32), 'eval/episode_distance_from_origin': Array(6908.6562, dtype=float32), 'eval/episode_distance_reward': Array(33.269226, dtype=float32), 'eval/episode_forward_reward': Array(5544.84, dtype=float32), 'eval/episode_reward': Array(5534.0244, dtype=float32), 'eval/episode_reward_alive': Array(383.76953, dtype=float32), 'eval/episode_reward_linvel': Array(5544.84, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.85382, dtype=float32), 'eval/episode_x_position': Array(6854.6846, dtype=float32), 'eval/episode_x_velocity': Array(1108.9678, dtype=float32), 'eval/episode_y_position': Array(-203.77005, dtype=float32), 'eval/episode_y_velocity': Array(-165.32024, dtype=float32), 'eval/episode_distance_from_origin_std': Array(496.49356, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8240385, dtype=float32), 'eval/episode_forward_reward_std': Array(970.6656, dtype=float32), 'eval/episode_reward_std': Array(974.85516, dtype=float32), 'eval/episode_reward_alive_std': Array(48.439995, dtype=float32), 'eval/episode_reward_linvel_std': Array(970.6656, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.34493, dtype=float32), 'eval/episode_x_position_std': Array(499.53397, dtype=float32), 'eval/episode_x_velocity_std': Array(194.13326, dtype=float32), 'eval/episode_y_position_std': Array(397.20605, dtype=float32), 'eval/episode_y_velocity_std': Array(124.480484, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6760528087616, 'eval/sps': 936.5210464418283, 'num_steps': 45547520}
{'eval/walltime': 76205.23620009422, 'training/sps': 2955.2769161570977, 'training/walltime': 15517.753727197647, 'training/entropy_loss': Array(0.01320748, dtype=float32), 'training/policy_loss': Array(0.06661144, dtype=float32), 'training/total_loss': Array(0.1497373, dtype=float32), 'training/v_loss': Array(0.06991836, dtype=float32), 'eval/episode_distance_from_origin': Array(7208.6943, dtype=float32), 'eval/episode_distance_reward': Array(36.419334, dtype=float32), 'eval/episode_forward_reward': Array(6069.8555, dtype=float32), 'eval/episode_reward': Array(6066.8516, dtype=float32), 'eval/episode_reward_alive': Array(374.0078, dtype=float32), 'eval/episode_reward_linvel': Array(6069.8555, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.43152, dtype=float32), 'eval/episode_x_position': Array(7160.8213, dtype=float32), 'eval/episode_x_velocity': Array(1213.971, dtype=float32), 'eval/episode_y_position': Array(-152.5716, dtype=float32), 'eval/episode_y_velocity': Array(-144.62802, dtype=float32), 'eval/episode_distance_from_origin_std': Array(419.00995, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1464505, dtype=float32), 'eval/episode_forward_reward_std': Array(857.73517, dtype=float32), 'eval/episode_reward_std': Array(860.3256, dtype=float32), 'eval/episode_reward_alive_std': Array(43.699257, dtype=float32), 'eval/episode_reward_linvel_std': Array(857.73517, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.078557, dtype=float32), 'eval/episode_x_position_std': Array(424.48972, dtype=float32), 'eval/episode_x_velocity_std': Array(171.5471, dtype=float32), 'eval/episode_y_position_std': Array(393.88803, dtype=float32), 'eval/episode_y_velocity_std': Array(123.78109, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34499645233154, 'eval/sps': 938.7949930729648, 'num_steps': 45629440}
