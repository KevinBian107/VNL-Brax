
{'eval/walltime': 170.31577563285828, 'eval/episode_distance_from_origin': Array(3040.6353, dtype=float32), 'eval/episode_distance_reward': Array(0.05001232, dtype=float32), 'eval/episode_forward_reward': Array(8.33539, dtype=float32), 'eval/episode_reward': Array(-202.40869, dtype=float32), 'eval/episode_reward_alive': Array(1.8320312, dtype=float32), 'eval/episode_reward_linvel': Array(8.33539, dtype=float32), 'eval/episode_reward_quadctrl': Array(-212.6261, dtype=float32), 'eval/episode_x_position': Array(3020.0205, dtype=float32), 'eval/episode_x_velocity': Array(1.6670766, dtype=float32), 'eval/episode_y_position': Array(-1.0245423, dtype=float32), 'eval/episode_y_velocity': Array(-1.7963622, dtype=float32), 'eval/episode_distance_from_origin_std': Array(52.553, dtype=float32), 'eval/episode_distance_reward_std': Array(0.37821695, dtype=float32), 'eval/episode_forward_reward_std': Array(63.036163, dtype=float32), 'eval/episode_reward_std': Array(63.247475, dtype=float32), 'eval/episode_reward_alive_std': Array(2.5975327, dtype=float32), 'eval/episode_reward_linvel_std': Array(63.036163, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.1968799, dtype=float32), 'eval/episode_x_position_std': Array(52.82417, dtype=float32), 'eval/episode_x_velocity_std': Array(12.607232, dtype=float32), 'eval/episode_y_position_std': Array(56.90352, dtype=float32), 'eval/episode_y_velocity_std': Array(12.41615, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 170.31577563285828, 'eval/sps': 751.5451785037435, 'num_steps': 0}
{'eval/walltime': 306.72169637680054, 'training/sps': 1488.8062159536705, 'training/walltime': 55.023950815200806, 'training/entropy_loss': Array(-0.00509988, dtype=float32), 'training/policy_loss': Array(-0.01965451, dtype=float32), 'training/total_loss': Array(-0.00082416, dtype=float32), 'training/v_loss': Array(0.02393024, dtype=float32), 'eval/episode_distance_from_origin': Array(3157.0508, dtype=float32), 'eval/episode_distance_reward': Array(0.60457665, dtype=float32), 'eval/episode_forward_reward': Array(100.76278, dtype=float32), 'eval/episode_reward': Array(-109.40407, dtype=float32), 'eval/episode_reward_alive': Array(2.0351562, dtype=float32), 'eval/episode_reward_linvel': Array(100.76278, dtype=float32), 'eval/episode_reward_quadctrl': Array(-212.80658, dtype=float32), 'eval/episode_x_position': Array(3136.0876, dtype=float32), 'eval/episode_x_velocity': Array(20.152554, dtype=float32), 'eval/episode_y_position': Array(1.6758246, dtype=float32), 'eval/episode_y_velocity': Array(-1.6064665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(53.605904, dtype=float32), 'eval/episode_distance_reward_std': Array(0.33467916, dtype=float32), 'eval/episode_forward_reward_std': Array(55.779858, dtype=float32), 'eval/episode_reward_std': Array(56.93495, dtype=float32), 'eval/episode_reward_alive_std': Array(4.043795, dtype=float32), 'eval/episode_reward_linvel_std': Array(55.779858, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.27003, dtype=float32), 'eval/episode_x_position_std': Array(53.56466, dtype=float32), 'eval/episode_x_velocity_std': Array(11.155969, dtype=float32), 'eval/episode_y_position_std': Array(96.89512, dtype=float32), 'eval/episode_y_velocity_std': Array(18.232498, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40592074394226, 'eval/sps': 938.3756900133269, 'num_steps': 81920}
{'eval/walltime': 443.06702613830566, 'training/sps': 2955.8873864743705, 'training/walltime': 82.73813247680664, 'training/entropy_loss': Array(-0.00498613, dtype=float32), 'training/policy_loss': Array(-0.05912998, dtype=float32), 'training/total_loss': Array(-0.05095282, dtype=float32), 'training/v_loss': Array(0.01316329, dtype=float32), 'eval/episode_distance_from_origin': Array(3179.6548, dtype=float32), 'eval/episode_distance_reward': Array(0.7566397, dtype=float32), 'eval/episode_forward_reward': Array(126.10663, dtype=float32), 'eval/episode_reward': Array(-84.78659, dtype=float32), 'eval/episode_reward_alive': Array(3.0117188, dtype=float32), 'eval/episode_reward_linvel': Array(126.10663, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.66158, dtype=float32), 'eval/episode_x_position': Array(3159.1138, dtype=float32), 'eval/episode_x_velocity': Array(25.221321, dtype=float32), 'eval/episode_y_position': Array(-34.59899, dtype=float32), 'eval/episode_y_velocity': Array(-7.719862, dtype=float32), 'eval/episode_distance_from_origin_std': Array(62.350643, dtype=float32), 'eval/episode_distance_reward_std': Array(0.35405394, dtype=float32), 'eval/episode_forward_reward_std': Array(59.009003, dtype=float32), 'eval/episode_reward_std': Array(61.000458, dtype=float32), 'eval/episode_reward_alive_std': Array(5.090764, dtype=float32), 'eval/episode_reward_linvel_std': Array(59.009003, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.067565, dtype=float32), 'eval/episode_x_position_std': Array(62.21786, dtype=float32), 'eval/episode_x_velocity_std': Array(11.801797, dtype=float32), 'eval/episode_y_position_std': Array(87.30769, dtype=float32), 'eval/episode_y_velocity_std': Array(16.130838, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34532976150513, 'eval/sps': 938.7926980989906, 'num_steps': 163840}
{'eval/walltime': 579.5691838264465, 'training/sps': 2969.670476770224, 'training/walltime': 110.32368469238281, 'training/entropy_loss': Array(-0.00478135, dtype=float32), 'training/policy_loss': Array(-0.04832844, dtype=float32), 'training/total_loss': Array(-0.03932086, dtype=float32), 'training/v_loss': Array(0.01378894, dtype=float32), 'eval/episode_distance_from_origin': Array(3159.1277, dtype=float32), 'eval/episode_distance_reward': Array(0.64932036, dtype=float32), 'eval/episode_forward_reward': Array(108.22006, dtype=float32), 'eval/episode_reward': Array(-104.45972, dtype=float32), 'eval/episode_reward_alive': Array(3.0351562, dtype=float32), 'eval/episode_reward_linvel': Array(108.22006, dtype=float32), 'eval/episode_reward_quadctrl': Array(-216.36424, dtype=float32), 'eval/episode_x_position': Array(3138.0796, dtype=float32), 'eval/episode_x_velocity': Array(21.644009, dtype=float32), 'eval/episode_y_position': Array(-58.95859, dtype=float32), 'eval/episode_y_velocity': Array(-12.375412, dtype=float32), 'eval/episode_distance_from_origin_std': Array(63.19086, dtype=float32), 'eval/episode_distance_reward_std': Array(0.34988073, dtype=float32), 'eval/episode_forward_reward_std': Array(58.313465, dtype=float32), 'eval/episode_reward_std': Array(59.641693, dtype=float32), 'eval/episode_reward_alive_std': Array(4.5983963, dtype=float32), 'eval/episode_reward_linvel_std': Array(58.313465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.3262072, dtype=float32), 'eval/episode_x_position_std': Array(62.77725, dtype=float32), 'eval/episode_x_velocity_std': Array(11.662691, dtype=float32), 'eval/episode_y_position_std': Array(83.29825, dtype=float32), 'eval/episode_y_velocity_std': Array(15.229034, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50215768814087, 'eval/sps': 937.714115057688, 'num_steps': 245760}
{'eval/walltime': 715.8597800731659, 'training/sps': 2949.265919719615, 'training/walltime': 138.10008811950684, 'training/entropy_loss': Array(-0.00452325, dtype=float32), 'training/policy_loss': Array(-0.04637373, dtype=float32), 'training/total_loss': Array(-0.04671864, dtype=float32), 'training/v_loss': Array(0.00417833, dtype=float32), 'eval/episode_distance_from_origin': Array(3112.6216, dtype=float32), 'eval/episode_distance_reward': Array(0.40919876, dtype=float32), 'eval/episode_forward_reward': Array(68.19978, dtype=float32), 'eval/episode_reward': Array(-148.80124, dtype=float32), 'eval/episode_reward_alive': Array(2.2695312, dtype=float32), 'eval/episode_reward_linvel': Array(68.19978, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.67975, dtype=float32), 'eval/episode_x_position': Array(3091.9082, dtype=float32), 'eval/episode_x_velocity': Array(13.63996, dtype=float32), 'eval/episode_y_position': Array(-51.318985, dtype=float32), 'eval/episode_y_velocity': Array(-10.9036, dtype=float32), 'eval/episode_distance_from_origin_std': Array(67.148575, dtype=float32), 'eval/episode_distance_reward_std': Array(0.36820942, dtype=float32), 'eval/episode_forward_reward_std': Array(61.368225, dtype=float32), 'eval/episode_reward_std': Array(66.16957, dtype=float32), 'eval/episode_reward_alive_std': Array(3.75047, dtype=float32), 'eval/episode_reward_linvel_std': Array(61.368225, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(15.176515, dtype=float32), 'eval/episode_x_position_std': Array(67.27048, dtype=float32), 'eval/episode_x_velocity_std': Array(12.273647, dtype=float32), 'eval/episode_y_position_std': Array(71.257355, dtype=float32), 'eval/episode_y_velocity_std': Array(13.088629, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29059624671936, 'eval/sps': 939.169711814076, 'num_steps': 327680}
{'eval/walltime': 852.3182847499847, 'training/sps': 2965.6574569124496, 'training/walltime': 165.72296810150146, 'training/entropy_loss': Array(-0.00419036, dtype=float32), 'training/policy_loss': Array(-0.05332772, dtype=float32), 'training/total_loss': Array(-0.05659205, dtype=float32), 'training/v_loss': Array(0.00092602, dtype=float32), 'eval/episode_distance_from_origin': Array(3082.233, dtype=float32), 'eval/episode_distance_reward': Array(0.27425313, dtype=float32), 'eval/episode_forward_reward': Array(45.708855, dtype=float32), 'eval/episode_reward': Array(-170.97333, dtype=float32), 'eval/episode_reward_alive': Array(2.890625, dtype=float32), 'eval/episode_reward_linvel': Array(45.708855, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.84706, dtype=float32), 'eval/episode_x_position': Array(3060.9233, dtype=float32), 'eval/episode_x_velocity': Array(9.141773, dtype=float32), 'eval/episode_y_position': Array(-51.23089, dtype=float32), 'eval/episode_y_velocity': Array(-10.425396, dtype=float32), 'eval/episode_distance_from_origin_std': Array(78.04211, dtype=float32), 'eval/episode_distance_reward_std': Array(0.44784695, dtype=float32), 'eval/episode_forward_reward_std': Array(74.64115, dtype=float32), 'eval/episode_reward_std': Array(80.612816, dtype=float32), 'eval/episode_reward_alive_std': Array(11.722363, dtype=float32), 'eval/episode_reward_linvel_std': Array(74.64115, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.191677, dtype=float32), 'eval/episode_x_position_std': Array(77.097305, dtype=float32), 'eval/episode_x_velocity_std': Array(14.928233, dtype=float32), 'eval/episode_y_position_std': Array(88.27201, dtype=float32), 'eval/episode_y_velocity_std': Array(16.594461, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45850467681885, 'eval/sps': 938.0140893610734, 'num_steps': 409600}
{'eval/walltime': 988.5115416049957, 'training/sps': 2964.4477926356085, 'training/walltime': 193.35711979866028, 'training/entropy_loss': Array(-0.00381768, dtype=float32), 'training/policy_loss': Array(-0.05144442, dtype=float32), 'training/total_loss': Array(-0.05486162, dtype=float32), 'training/v_loss': Array(0.00040047, dtype=float32), 'eval/episode_distance_from_origin': Array(3053.8896, dtype=float32), 'eval/episode_distance_reward': Array(0.13817042, dtype=float32), 'eval/episode_forward_reward': Array(23.0284, dtype=float32), 'eval/episode_reward': Array(-197.1033, dtype=float32), 'eval/episode_reward_alive': Array(3.1835938, dtype=float32), 'eval/episode_reward_linvel': Array(23.0284, dtype=float32), 'eval/episode_reward_quadctrl': Array(-223.45349, dtype=float32), 'eval/episode_x_position': Array(3032.4758, dtype=float32), 'eval/episode_x_velocity': Array(4.605678, dtype=float32), 'eval/episode_y_position': Array(-33.991035, dtype=float32), 'eval/episode_y_velocity': Array(-7.1464167, dtype=float32), 'eval/episode_distance_from_origin_std': Array(83.51541, dtype=float32), 'eval/episode_distance_reward_std': Array(0.48189923, dtype=float32), 'eval/episode_forward_reward_std': Array(80.31653, dtype=float32), 'eval/episode_reward_std': Array(94.26433, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4754467, dtype=float32), 'eval/episode_reward_linvel_std': Array(80.31653, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.166658, dtype=float32), 'eval/episode_x_position_std': Array(82.63847, dtype=float32), 'eval/episode_x_velocity_std': Array(16.0633, dtype=float32), 'eval/episode_y_position_std': Array(80.59029, dtype=float32), 'eval/episode_y_velocity_std': Array(15.724931, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.193256855011, 'eval/sps': 939.8409506886718, 'num_steps': 491520}
{'eval/walltime': 1125.0018072128296, 'training/sps': 2964.8727782473393, 'training/walltime': 220.9873104095459, 'training/entropy_loss': Array(-0.0033172, dtype=float32), 'training/policy_loss': Array(0.06198757, dtype=float32), 'training/total_loss': Array(0.09375972, dtype=float32), 'training/v_loss': Array(0.03508935, dtype=float32), 'eval/episode_distance_from_origin': Array(3102.4734, dtype=float32), 'eval/episode_distance_reward': Array(0.3974158, dtype=float32), 'eval/episode_forward_reward': Array(66.23596, dtype=float32), 'eval/episode_reward': Array(-138.11214, dtype=float32), 'eval/episode_reward_alive': Array(13.175781, dtype=float32), 'eval/episode_reward_linvel': Array(66.23596, dtype=float32), 'eval/episode_reward_quadctrl': Array(-217.9213, dtype=float32), 'eval/episode_x_position': Array(3079.86, dtype=float32), 'eval/episode_x_velocity': Array(13.247192, dtype=float32), 'eval/episode_y_position': Array(-58.114674, dtype=float32), 'eval/episode_y_velocity': Array(-10.925607, dtype=float32), 'eval/episode_distance_from_origin_std': Array(90.0621, dtype=float32), 'eval/episode_distance_reward_std': Array(0.51741654, dtype=float32), 'eval/episode_forward_reward_std': Array(86.236084, dtype=float32), 'eval/episode_reward_std': Array(112.49484, dtype=float32), 'eval/episode_reward_alive_std': Array(45.796577, dtype=float32), 'eval/episode_reward_linvel_std': Array(86.236084, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.9124742, dtype=float32), 'eval/episode_x_position_std': Array(87.931816, dtype=float32), 'eval/episode_x_velocity_std': Array(17.247217, dtype=float32), 'eval/episode_y_position_std': Array(100.60936, dtype=float32), 'eval/episode_y_velocity_std': Array(19.544744, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49026560783386, 'eval/sps': 937.7958159138745, 'num_steps': 573440}
{'eval/walltime': 1261.4211356639862, 'training/sps': 2969.271339326566, 'training/walltime': 248.57657074928284, 'training/entropy_loss': Array(-0.00371369, dtype=float32), 'training/policy_loss': Array(-0.02484784, dtype=float32), 'training/total_loss': Array(-0.0226924, dtype=float32), 'training/v_loss': Array(0.00586914, dtype=float32), 'eval/episode_distance_from_origin': Array(3131.9487, dtype=float32), 'eval/episode_distance_reward': Array(0.54248065, dtype=float32), 'eval/episode_forward_reward': Array(90.413445, dtype=float32), 'eval/episode_reward': Array(-118.0251, dtype=float32), 'eval/episode_reward_alive': Array(10.9765625, dtype=float32), 'eval/episode_reward_linvel': Array(90.413445, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.95758, dtype=float32), 'eval/episode_x_position': Array(3108.8127, dtype=float32), 'eval/episode_x_velocity': Array(18.082691, dtype=float32), 'eval/episode_y_position': Array(-90.112045, dtype=float32), 'eval/episode_y_velocity': Array(-16.844097, dtype=float32), 'eval/episode_distance_from_origin_std': Array(69.73642, dtype=float32), 'eval/episode_distance_reward_std': Array(0.37875858, dtype=float32), 'eval/episode_forward_reward_std': Array(63.126434, dtype=float32), 'eval/episode_reward_std': Array(79.51066, dtype=float32), 'eval/episode_reward_alive_std': Array(37.486187, dtype=float32), 'eval/episode_reward_linvel_std': Array(63.126434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.2246857, dtype=float32), 'eval/episode_x_position_std': Array(68.30593, dtype=float32), 'eval/episode_x_velocity_std': Array(12.625289, dtype=float32), 'eval/episode_y_position_std': Array(109.91432, dtype=float32), 'eval/episode_y_velocity_std': Array(20.292559, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41932845115662, 'eval/sps': 938.2834635916636, 'num_steps': 655360}
{'eval/walltime': 1398.3567008972168, 'training/sps': 2961.339927231498, 'training/walltime': 276.23972392082214, 'training/entropy_loss': Array(-0.00327095, dtype=float32), 'training/policy_loss': Array(-0.03671196, dtype=float32), 'training/total_loss': Array(-0.03880279, dtype=float32), 'training/v_loss': Array(0.00118013, dtype=float32), 'eval/episode_distance_from_origin': Array(3102.5981, dtype=float32), 'eval/episode_distance_reward': Array(0.38340932, dtype=float32), 'eval/episode_forward_reward': Array(63.901558, dtype=float32), 'eval/episode_reward': Array(-153.30309, dtype=float32), 'eval/episode_reward_alive': Array(4.4882812, dtype=float32), 'eval/episode_reward_linvel': Array(63.901558, dtype=float32), 'eval/episode_reward_quadctrl': Array(-222.07632, dtype=float32), 'eval/episode_x_position': Array(3080.5244, dtype=float32), 'eval/episode_x_velocity': Array(12.78031, dtype=float32), 'eval/episode_y_position': Array(-95.028275, dtype=float32), 'eval/episode_y_velocity': Array(-18.311714, dtype=float32), 'eval/episode_distance_from_origin_std': Array(65.193085, dtype=float32), 'eval/episode_distance_reward_std': Array(0.34891272, dtype=float32), 'eval/episode_forward_reward_std': Array(58.152115, dtype=float32), 'eval/episode_reward_std': Array(69.720184, dtype=float32), 'eval/episode_reward_alive_std': Array(10.326782, dtype=float32), 'eval/episode_reward_linvel_std': Array(58.152115, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.909622, dtype=float32), 'eval/episode_x_position_std': Array(64.33227, dtype=float32), 'eval/episode_x_velocity_std': Array(11.6304245, dtype=float32), 'eval/episode_y_position_std': Array(80.57972, dtype=float32), 'eval/episode_y_velocity_std': Array(14.698525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.9355652332306, 'eval/sps': 934.7462055017526, 'num_steps': 737280}
{'eval/walltime': 1534.8246235847473, 'training/sps': 2964.710305475342, 'training/walltime': 303.87142872810364, 'training/entropy_loss': Array(-0.00289711, dtype=float32), 'training/policy_loss': Array(-0.03883576, dtype=float32), 'training/total_loss': Array(-0.04115118, dtype=float32), 'training/v_loss': Array(0.00058169, dtype=float32), 'eval/episode_distance_from_origin': Array(3103.1968, dtype=float32), 'eval/episode_distance_reward': Array(0.3928075, dtype=float32), 'eval/episode_forward_reward': Array(65.46791, dtype=float32), 'eval/episode_reward': Array(-152.12292, dtype=float32), 'eval/episode_reward_alive': Array(3.0820312, dtype=float32), 'eval/episode_reward_linvel': Array(65.46791, dtype=float32), 'eval/episode_reward_quadctrl': Array(-221.06567, dtype=float32), 'eval/episode_x_position': Array(3081.5684, dtype=float32), 'eval/episode_x_velocity': Array(13.093582, dtype=float32), 'eval/episode_y_position': Array(-69.93165, dtype=float32), 'eval/episode_y_velocity': Array(-13.207336, dtype=float32), 'eval/episode_distance_from_origin_std': Array(72.61255, dtype=float32), 'eval/episode_distance_reward_std': Array(0.37842992, dtype=float32), 'eval/episode_forward_reward_std': Array(63.071636, dtype=float32), 'eval/episode_reward_std': Array(66.20194, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9072475, dtype=float32), 'eval/episode_reward_linvel_std': Array(63.071636, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.0865047, dtype=float32), 'eval/episode_x_position_std': Array(71.050354, dtype=float32), 'eval/episode_x_velocity_std': Array(12.614327, dtype=float32), 'eval/episode_y_position_std': Array(100.79157, dtype=float32), 'eval/episode_y_velocity_std': Array(18.439564, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46792268753052, 'eval/sps': 937.9493545386526, 'num_steps': 819200}
{'eval/walltime': 1671.7787861824036, 'training/sps': 2966.144907330401, 'training/walltime': 331.4897692203522, 'training/entropy_loss': Array(-0.00256358, dtype=float32), 'training/policy_loss': Array(-0.04356208, dtype=float32), 'training/total_loss': Array(-0.04579629, dtype=float32), 'training/v_loss': Array(0.00032937, dtype=float32), 'eval/episode_distance_from_origin': Array(3100.3142, dtype=float32), 'eval/episode_distance_reward': Array(0.36782032, dtype=float32), 'eval/episode_forward_reward': Array(61.3034, dtype=float32), 'eval/episode_reward': Array(-156.13272, dtype=float32), 'eval/episode_reward_alive': Array(1.9257812, dtype=float32), 'eval/episode_reward_linvel': Array(61.3034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.72975, dtype=float32), 'eval/episode_x_position': Array(3078.8164, dtype=float32), 'eval/episode_x_velocity': Array(12.260678, dtype=float32), 'eval/episode_y_position': Array(-81.2887, dtype=float32), 'eval/episode_y_velocity': Array(-15.25477, dtype=float32), 'eval/episode_distance_from_origin_std': Array(67.45002, dtype=float32), 'eval/episode_distance_reward_std': Array(0.35989, dtype=float32), 'eval/episode_forward_reward_std': Array(59.98167, dtype=float32), 'eval/episode_reward_std': Array(60.9571, dtype=float32), 'eval/episode_reward_alive_std': Array(2.589107, dtype=float32), 'eval/episode_reward_linvel_std': Array(59.98167, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.8114858, dtype=float32), 'eval/episode_x_position_std': Array(66.63967, dtype=float32), 'eval/episode_x_velocity_std': Array(11.996334, dtype=float32), 'eval/episode_y_position_std': Array(89.54706, dtype=float32), 'eval/episode_y_velocity_std': Array(16.051592, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.95416259765625, 'eval/sps': 934.6192738663827, 'num_steps': 901120}
{'eval/walltime': 1808.3679089546204, 'training/sps': 2936.8611305495397, 'training/walltime': 359.38349533081055, 'training/entropy_loss': Array(-0.00232065, dtype=float32), 'training/policy_loss': Array(-0.05004935, dtype=float32), 'training/total_loss': Array(-0.05205724, dtype=float32), 'training/v_loss': Array(0.00031276, dtype=float32), 'eval/episode_distance_from_origin': Array(3113.0063, dtype=float32), 'eval/episode_distance_reward': Array(0.41827813, dtype=float32), 'eval/episode_forward_reward': Array(69.713, dtype=float32), 'eval/episode_reward': Array(-142.57097, dtype=float32), 'eval/episode_reward_alive': Array(1.9101562, dtype=float32), 'eval/episode_reward_linvel': Array(69.713, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.6124, dtype=float32), 'eval/episode_x_position': Array(3089.7812, dtype=float32), 'eval/episode_x_velocity': Array(13.942603, dtype=float32), 'eval/episode_y_position': Array(-78.08078, dtype=float32), 'eval/episode_y_velocity': Array(-14.715149, dtype=float32), 'eval/episode_distance_from_origin_std': Array(75.75766, dtype=float32), 'eval/episode_distance_reward_std': Array(0.40641963, dtype=float32), 'eval/episode_forward_reward_std': Array(67.736595, dtype=float32), 'eval/episode_reward_std': Array(68.82328, dtype=float32), 'eval/episode_reward_alive_std': Array(3.3856509, dtype=float32), 'eval/episode_reward_linvel_std': Array(67.736595, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.703803, dtype=float32), 'eval/episode_x_position_std': Array(74.67195, dtype=float32), 'eval/episode_x_velocity_std': Array(13.54732, dtype=float32), 'eval/episode_y_position_std': Array(107.7539, dtype=float32), 'eval/episode_y_velocity_std': Array(19.354204, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5891227722168, 'eval/sps': 937.1170807902437, 'num_steps': 983040}
{'eval/walltime': 1944.7420234680176, 'training/sps': 2946.2756072829607, 'training/walltime': 387.18809032440186, 'training/entropy_loss': Array(-0.00200319, dtype=float32), 'training/policy_loss': Array(0.01764506, dtype=float32), 'training/total_loss': Array(0.04204268, dtype=float32), 'training/v_loss': Array(0.02640081, dtype=float32), 'eval/episode_distance_from_origin': Array(3173.622, dtype=float32), 'eval/episode_distance_reward': Array(0.73675495, dtype=float32), 'eval/episode_forward_reward': Array(122.792496, dtype=float32), 'eval/episode_reward': Array(-85.87448, dtype=float32), 'eval/episode_reward_alive': Array(5.2109375, dtype=float32), 'eval/episode_reward_linvel': Array(122.792496, dtype=float32), 'eval/episode_reward_quadctrl': Array(-214.61465, dtype=float32), 'eval/episode_x_position': Array(3149.0625, dtype=float32), 'eval/episode_x_velocity': Array(24.558493, dtype=float32), 'eval/episode_y_position': Array(-51.36543, dtype=float32), 'eval/episode_y_velocity': Array(-9.509768, dtype=float32), 'eval/episode_distance_from_origin_std': Array(71.25185, dtype=float32), 'eval/episode_distance_reward_std': Array(0.39255378, dtype=float32), 'eval/episode_forward_reward_std': Array(65.42565, dtype=float32), 'eval/episode_reward_std': Array(68.764244, dtype=float32), 'eval/episode_reward_alive_std': Array(9.771132, dtype=float32), 'eval/episode_reward_linvel_std': Array(65.42565, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.4053097, dtype=float32), 'eval/episode_x_position_std': Array(70.77559, dtype=float32), 'eval/episode_x_velocity_std': Array(13.085119, dtype=float32), 'eval/episode_y_position_std': Array(111.35181, dtype=float32), 'eval/episode_y_velocity_std': Array(20.461525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37411451339722, 'eval/sps': 938.5945452824586, 'num_steps': 1064960}
{'eval/walltime': 2081.322564601898, 'training/sps': 2972.8193702494495, 'training/walltime': 414.74442315101624, 'training/entropy_loss': Array(-0.00286631, dtype=float32), 'training/policy_loss': Array(-0.02300145, dtype=float32), 'training/total_loss': Array(-0.02017224, dtype=float32), 'training/v_loss': Array(0.00569552, dtype=float32), 'eval/episode_distance_from_origin': Array(3172.5242, dtype=float32), 'eval/episode_distance_reward': Array(0.7655609, dtype=float32), 'eval/episode_forward_reward': Array(127.59349, dtype=float32), 'eval/episode_reward': Array(-92.465775, dtype=float32), 'eval/episode_reward_alive': Array(3.4023438, dtype=float32), 'eval/episode_reward_linvel': Array(127.59349, dtype=float32), 'eval/episode_reward_quadctrl': Array(-224.22716, dtype=float32), 'eval/episode_x_position': Array(3145.7104, dtype=float32), 'eval/episode_x_velocity': Array(25.518696, dtype=float32), 'eval/episode_y_position': Array(-34.621532, dtype=float32), 'eval/episode_y_velocity': Array(-4.5216107, dtype=float32), 'eval/episode_distance_from_origin_std': Array(80.57301, dtype=float32), 'eval/episode_distance_reward_std': Array(0.4636621, dtype=float32), 'eval/episode_forward_reward_std': Array(77.27701, dtype=float32), 'eval/episode_reward_std': Array(77.8703, dtype=float32), 'eval/episode_reward_alive_std': Array(4.354891, dtype=float32), 'eval/episode_reward_linvel_std': Array(77.27701, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.9048195, dtype=float32), 'eval/episode_x_position_std': Array(80.53644, dtype=float32), 'eval/episode_x_velocity_std': Array(15.4553995, dtype=float32), 'eval/episode_y_position_std': Array(105.220955, dtype=float32), 'eval/episode_y_velocity_std': Array(20.512148, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58054113388062, 'eval/sps': 937.1759617977374, 'num_steps': 1146880}
{'eval/walltime': 2217.663383245468, 'training/sps': 2976.246545132671, 'training/walltime': 442.2690246105194, 'training/entropy_loss': Array(-0.00253608, dtype=float32), 'training/policy_loss': Array(-0.04742029, dtype=float32), 'training/total_loss': Array(-0.04797032, dtype=float32), 'training/v_loss': Array(0.00198605, dtype=float32), 'eval/episode_distance_from_origin': Array(3243.44, dtype=float32), 'eval/episode_distance_reward': Array(1.3533592, dtype=float32), 'eval/episode_forward_reward': Array(225.55988, dtype=float32), 'eval/episode_reward': Array(-6.275696, dtype=float32), 'eval/episode_reward_alive': Array(3.1445312, dtype=float32), 'eval/episode_reward_linvel': Array(225.55988, dtype=float32), 'eval/episode_reward_quadctrl': Array(-236.33348, dtype=float32), 'eval/episode_x_position': Array(3208.4136, dtype=float32), 'eval/episode_x_velocity': Array(45.111977, dtype=float32), 'eval/episode_y_position': Array(140.02875, dtype=float32), 'eval/episode_y_velocity': Array(53.605408, dtype=float32), 'eval/episode_distance_from_origin_std': Array(74.93128, dtype=float32), 'eval/episode_distance_reward_std': Array(0.5090833, dtype=float32), 'eval/episode_forward_reward_std': Array(84.84721, dtype=float32), 'eval/episode_reward_std': Array(86.96591, dtype=float32), 'eval/episode_reward_alive_std': Array(4.924093, dtype=float32), 'eval/episode_reward_linvel_std': Array(84.84721, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.4105887, dtype=float32), 'eval/episode_x_position_std': Array(76.163506, dtype=float32), 'eval/episode_x_velocity_std': Array(16.969439, dtype=float32), 'eval/episode_y_position_std': Array(131.09068, dtype=float32), 'eval/episode_y_velocity_std': Array(35.00993, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34081864356995, 'eval/sps': 938.8237599968136, 'num_steps': 1228800}
{'eval/walltime': 2354.235156059265, 'training/sps': 2954.340599355493, 'training/walltime': 469.99771642684937, 'training/entropy_loss': Array(-0.00095147, dtype=float32), 'training/policy_loss': Array(-0.01090474, dtype=float32), 'training/total_loss': Array(-0.00983507, dtype=float32), 'training/v_loss': Array(0.00202115, dtype=float32), 'eval/episode_distance_from_origin': Array(3267.0728, dtype=float32), 'eval/episode_distance_reward': Array(1.6299621, dtype=float32), 'eval/episode_forward_reward': Array(271.66034, dtype=float32), 'eval/episode_reward': Array(34.455765, dtype=float32), 'eval/episode_reward_alive': Array(4.3554688, dtype=float32), 'eval/episode_reward_linvel': Array(271.66034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-243.19003, dtype=float32), 'eval/episode_x_position': Array(3228.9521, dtype=float32), 'eval/episode_x_velocity': Array(54.33207, dtype=float32), 'eval/episode_y_position': Array(174.93839, dtype=float32), 'eval/episode_y_velocity': Array(61.052513, dtype=float32), 'eval/episode_distance_from_origin_std': Array(86.892456, dtype=float32), 'eval/episode_distance_reward_std': Array(0.6626792, dtype=float32), 'eval/episode_forward_reward_std': Array(110.44653, dtype=float32), 'eval/episode_reward_std': Array(110.92614, dtype=float32), 'eval/episode_reward_alive_std': Array(6.2693925, dtype=float32), 'eval/episode_reward_linvel_std': Array(110.44653, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.387643, dtype=float32), 'eval/episode_x_position_std': Array(89.63255, dtype=float32), 'eval/episode_x_velocity_std': Array(22.089306, dtype=float32), 'eval/episode_y_position_std': Array(144.99147, dtype=float32), 'eval/episode_y_velocity_std': Array(35.563328, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.571772813797, 'eval/sps': 937.2361313235363, 'num_steps': 1310720}
{'eval/walltime': 2490.5418128967285, 'training/sps': 2956.715580287861, 'training/walltime': 497.70413517951965, 'training/entropy_loss': Array(-0.00015319, dtype=float32), 'training/policy_loss': Array(0.04311073, dtype=float32), 'training/total_loss': Array(0.0459262, dtype=float32), 'training/v_loss': Array(0.00296866, dtype=float32), 'eval/episode_distance_from_origin': Array(3272.3555, dtype=float32), 'eval/episode_distance_reward': Array(1.6461766, dtype=float32), 'eval/episode_forward_reward': Array(274.36273, dtype=float32), 'eval/episode_reward': Array(30.494247, dtype=float32), 'eval/episode_reward_alive': Array(4.2890625, dtype=float32), 'eval/episode_reward_linvel': Array(274.36273, dtype=float32), 'eval/episode_reward_quadctrl': Array(-249.80374, dtype=float32), 'eval/episode_x_position': Array(3241.297, dtype=float32), 'eval/episode_x_velocity': Array(54.872543, dtype=float32), 'eval/episode_y_position': Array(57.9337, dtype=float32), 'eval/episode_y_velocity': Array(19.786308, dtype=float32), 'eval/episode_distance_from_origin_std': Array(94.18461, dtype=float32), 'eval/episode_distance_reward_std': Array(0.6529215, dtype=float32), 'eval/episode_forward_reward_std': Array(108.82023, dtype=float32), 'eval/episode_reward_std': Array(110.54906, dtype=float32), 'eval/episode_reward_alive_std': Array(6.2059727, dtype=float32), 'eval/episode_reward_linvel_std': Array(108.82023, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.602436, dtype=float32), 'eval/episode_x_position_std': Array(94.98286, dtype=float32), 'eval/episode_x_velocity_std': Array(21.764051, dtype=float32), 'eval/episode_y_position_std': Array(139.30269, dtype=float32), 'eval/episode_y_velocity_std': Array(28.571325, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30665683746338, 'eval/sps': 939.0590523589136, 'num_steps': 1392640}
{'eval/walltime': 2626.944475412369, 'training/sps': 2954.940060399056, 'training/walltime': 525.4272017478943, 'training/entropy_loss': Array(0.00078288, dtype=float32), 'training/policy_loss': Array(0.06658784, dtype=float32), 'training/total_loss': Array(0.0772412, dtype=float32), 'training/v_loss': Array(0.00987048, dtype=float32), 'eval/episode_distance_from_origin': Array(3378.371, dtype=float32), 'eval/episode_distance_reward': Array(2.6799831, dtype=float32), 'eval/episode_forward_reward': Array(446.66367, dtype=float32), 'eval/episode_reward': Array(186.57591, dtype=float32), 'eval/episode_reward_alive': Array(6.0820312, dtype=float32), 'eval/episode_reward_linvel': Array(446.66367, dtype=float32), 'eval/episode_reward_quadctrl': Array(-268.8498, dtype=float32), 'eval/episode_x_position': Array(3347.4895, dtype=float32), 'eval/episode_x_velocity': Array(89.33273, dtype=float32), 'eval/episode_y_position': Array(80.56389, dtype=float32), 'eval/episode_y_velocity': Array(23.39016, dtype=float32), 'eval/episode_distance_from_origin_std': Array(140.5249, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3843874, dtype=float32), 'eval/episode_forward_reward_std': Array(230.7309, dtype=float32), 'eval/episode_reward_std': Array(225.97969, dtype=float32), 'eval/episode_reward_alive_std': Array(7.6747293, dtype=float32), 'eval/episode_reward_linvel_std': Array(230.7309, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.645007, dtype=float32), 'eval/episode_x_position_std': Array(140.87726, dtype=float32), 'eval/episode_x_velocity_std': Array(46.146187, dtype=float32), 'eval/episode_y_position_std': Array(144.47368, dtype=float32), 'eval/episode_y_velocity_std': Array(32.60014, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40266251564026, 'eval/sps': 938.3981048414155, 'num_steps': 1474560}
{'eval/walltime': 2763.222722530365, 'training/sps': 2953.155655891798, 'training/walltime': 553.1670196056366, 'training/entropy_loss': Array(7.449669e-05, dtype=float32), 'training/policy_loss': Array(0.02433373, dtype=float32), 'training/total_loss': Array(0.04744988, dtype=float32), 'training/v_loss': Array(0.02304165, dtype=float32), 'eval/episode_distance_from_origin': Array(3488.731, dtype=float32), 'eval/episode_distance_reward': Array(3.9448755, dtype=float32), 'eval/episode_forward_reward': Array(657.47876, dtype=float32), 'eval/episode_reward': Array(387.43503, dtype=float32), 'eval/episode_reward_alive': Array(9.238281, dtype=float32), 'eval/episode_reward_linvel': Array(657.47876, dtype=float32), 'eval/episode_reward_quadctrl': Array(-283.22693, dtype=float32), 'eval/episode_x_position': Array(3453.8523, dtype=float32), 'eval/episode_x_velocity': Array(131.49576, dtype=float32), 'eval/episode_y_position': Array(119.23009, dtype=float32), 'eval/episode_y_velocity': Array(53.53821, dtype=float32), 'eval/episode_distance_from_origin_std': Array(112.37356, dtype=float32), 'eval/episode_distance_reward_std': Array(0.9884624, dtype=float32), 'eval/episode_forward_reward_std': Array(164.74321, dtype=float32), 'eval/episode_reward_std': Array(162.86523, dtype=float32), 'eval/episode_reward_alive_std': Array(9.753398, dtype=float32), 'eval/episode_reward_linvel_std': Array(164.74321, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.152291, dtype=float32), 'eval/episode_x_position_std': Array(115.31617, dtype=float32), 'eval/episode_x_velocity_std': Array(32.94863, dtype=float32), 'eval/episode_y_position_std': Array(172.94403, dtype=float32), 'eval/episode_y_velocity_std': Array(43.45986, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27824711799622, 'eval/sps': 939.2548165751757, 'num_steps': 1556480}
{'eval/walltime': 2899.5984477996826, 'training/sps': 2943.815110279358, 'training/walltime': 580.9948542118073, 'training/entropy_loss': Array(0.00167884, dtype=float32), 'training/policy_loss': Array(0.0615266, dtype=float32), 'training/total_loss': Array(0.09551245, dtype=float32), 'training/v_loss': Array(0.03230701, dtype=float32), 'eval/episode_distance_from_origin': Array(3373.4512, dtype=float32), 'eval/episode_distance_reward': Array(2.333587, dtype=float32), 'eval/episode_forward_reward': Array(388.93112, dtype=float32), 'eval/episode_reward': Array(147.1929, dtype=float32), 'eval/episode_reward_alive': Array(13.3828125, dtype=float32), 'eval/episode_reward_linvel': Array(388.93112, dtype=float32), 'eval/episode_reward_quadctrl': Array(-257.45465, dtype=float32), 'eval/episode_x_position': Array(3343.1611, dtype=float32), 'eval/episode_x_velocity': Array(77.786224, dtype=float32), 'eval/episode_y_position': Array(26.93203, dtype=float32), 'eval/episode_y_velocity': Array(13.777077, dtype=float32), 'eval/episode_distance_from_origin_std': Array(93.491516, dtype=float32), 'eval/episode_distance_reward_std': Array(0.7529216, dtype=float32), 'eval/episode_forward_reward_std': Array(125.48679, dtype=float32), 'eval/episode_reward_std': Array(122.981255, dtype=float32), 'eval/episode_reward_alive_std': Array(10.903605, dtype=float32), 'eval/episode_reward_linvel_std': Array(125.48679, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.971784, dtype=float32), 'eval/episode_x_position_std': Array(94.5852, dtype=float32), 'eval/episode_x_velocity_std': Array(25.097359, dtype=float32), 'eval/episode_y_position_std': Array(139.91003, dtype=float32), 'eval/episode_y_velocity_std': Array(32.284157, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37572526931763, 'eval/sps': 938.5834593892932, 'num_steps': 1638400}
{'eval/walltime': 3035.8811469078064, 'training/sps': 2948.656485674677, 'training/walltime': 608.7769985198975, 'training/entropy_loss': Array(0.00100254, dtype=float32), 'training/policy_loss': Array(0.01495139, dtype=float32), 'training/total_loss': Array(0.03813628, dtype=float32), 'training/v_loss': Array(0.02218235, dtype=float32), 'eval/episode_distance_from_origin': Array(3414.3137, dtype=float32), 'eval/episode_distance_reward': Array(2.81945, dtype=float32), 'eval/episode_forward_reward': Array(469.9083, dtype=float32), 'eval/episode_reward': Array(226.77022, dtype=float32), 'eval/episode_reward_alive': Array(12.386719, dtype=float32), 'eval/episode_reward_linvel': Array(469.9083, dtype=float32), 'eval/episode_reward_quadctrl': Array(-258.3443, dtype=float32), 'eval/episode_x_position': Array(3384.46, dtype=float32), 'eval/episode_x_velocity': Array(93.98164, dtype=float32), 'eval/episode_y_position': Array(-47.69756, dtype=float32), 'eval/episode_y_velocity': Array(2.538724, dtype=float32), 'eval/episode_distance_from_origin_std': Array(105.34322, dtype=float32), 'eval/episode_distance_reward_std': Array(0.87296385, dtype=float32), 'eval/episode_forward_reward_std': Array(145.49385, dtype=float32), 'eval/episode_reward_std': Array(146.39635, dtype=float32), 'eval/episode_reward_alive_std': Array(11.39922, dtype=float32), 'eval/episode_reward_linvel_std': Array(145.49385, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.670486, dtype=float32), 'eval/episode_x_position_std': Array(105.45119, dtype=float32), 'eval/episode_x_velocity_std': Array(29.098763, dtype=float32), 'eval/episode_y_position_std': Array(121.47781, dtype=float32), 'eval/episode_y_velocity_std': Array(30.357792, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28269910812378, 'eval/sps': 939.2241336403789, 'num_steps': 1720320}
{'eval/walltime': 3172.286086320877, 'training/sps': 2957.4956665601726, 'training/walltime': 636.4761092662811, 'training/entropy_loss': Array(0.00129855, dtype=float32), 'training/policy_loss': Array(0.01172955, dtype=float32), 'training/total_loss': Array(0.02977399, dtype=float32), 'training/v_loss': Array(0.0167459, dtype=float32), 'eval/episode_distance_from_origin': Array(3490.1077, dtype=float32), 'eval/episode_distance_reward': Array(4.0726595, dtype=float32), 'eval/episode_forward_reward': Array(678.776, dtype=float32), 'eval/episode_reward': Array(444.1859, dtype=float32), 'eval/episode_reward_alive': Array(20.132812, dtype=float32), 'eval/episode_reward_linvel': Array(678.776, dtype=float32), 'eval/episode_reward_quadctrl': Array(-258.7956, dtype=float32), 'eval/episode_x_position': Array(3459.3828, dtype=float32), 'eval/episode_x_velocity': Array(135.7552, dtype=float32), 'eval/episode_y_position': Array(-69.48892, dtype=float32), 'eval/episode_y_velocity': Array(3.8605258, dtype=float32), 'eval/episode_distance_from_origin_std': Array(99.25612, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1155397, dtype=float32), 'eval/episode_forward_reward_std': Array(185.92273, dtype=float32), 'eval/episode_reward_std': Array(191.88634, dtype=float32), 'eval/episode_reward_alive_std': Array(14.406417, dtype=float32), 'eval/episode_reward_linvel_std': Array(185.92273, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.2863364, dtype=float32), 'eval/episode_x_position_std': Array(99.033325, dtype=float32), 'eval/episode_x_velocity_std': Array(37.18455, dtype=float32), 'eval/episode_y_position_std': Array(134.23262, dtype=float32), 'eval/episode_y_velocity_std': Array(33.76009, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40493941307068, 'eval/sps': 938.3824409201321, 'num_steps': 1802240}
{'eval/walltime': 3308.665069580078, 'training/sps': 2944.905436617953, 'training/walltime': 664.2936408519745, 'training/entropy_loss': Array(0.00089123, dtype=float32), 'training/policy_loss': Array(0.0039272, dtype=float32), 'training/total_loss': Array(0.01869382, dtype=float32), 'training/v_loss': Array(0.01387538, dtype=float32), 'eval/episode_distance_from_origin': Array(3598.5432, dtype=float32), 'eval/episode_distance_reward': Array(5.3531837, dtype=float32), 'eval/episode_forward_reward': Array(892.19617, dtype=float32), 'eval/episode_reward': Array(674.5024, dtype=float32), 'eval/episode_reward_alive': Array(43.210938, dtype=float32), 'eval/episode_reward_linvel': Array(892.19617, dtype=float32), 'eval/episode_reward_quadctrl': Array(-266.2578, dtype=float32), 'eval/episode_x_position': Array(3566.8838, dtype=float32), 'eval/episode_x_velocity': Array(178.43922, dtype=float32), 'eval/episode_y_position': Array(-118.17498, dtype=float32), 'eval/episode_y_velocity': Array(-11.612244, dtype=float32), 'eval/episode_distance_from_origin_std': Array(126.84127, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1641841, dtype=float32), 'eval/episode_forward_reward_std': Array(194.03023, dtype=float32), 'eval/episode_reward_std': Array(207.69878, dtype=float32), 'eval/episode_reward_alive_std': Array(21.509045, dtype=float32), 'eval/episode_reward_linvel_std': Array(194.03023, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.463362, dtype=float32), 'eval/episode_x_position_std': Array(126.77333, dtype=float32), 'eval/episode_x_velocity_std': Array(38.80603, dtype=float32), 'eval/episode_y_position_std': Array(127.59077, dtype=float32), 'eval/episode_y_velocity_std': Array(32.766106, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37898325920105, 'eval/sps': 938.5610373463776, 'num_steps': 1884160}
{'eval/walltime': 3445.05263876915, 'training/sps': 2959.093490824906, 'training/walltime': 691.9777948856354, 'training/entropy_loss': Array(0.00121391, dtype=float32), 'training/policy_loss': Array(-0.00539417, dtype=float32), 'training/total_loss': Array(0.01537938, dtype=float32), 'training/v_loss': Array(0.01955965, dtype=float32), 'eval/episode_distance_from_origin': Array(3769.764, dtype=float32), 'eval/episode_distance_reward': Array(7.1829715, dtype=float32), 'eval/episode_forward_reward': Array(1197.16, dtype=float32), 'eval/episode_reward': Array(1010.9277, dtype=float32), 'eval/episode_reward_alive': Array(85.47656, dtype=float32), 'eval/episode_reward_linvel': Array(1197.16, dtype=float32), 'eval/episode_reward_quadctrl': Array(-278.89178, dtype=float32), 'eval/episode_x_position': Array(3735.7397, dtype=float32), 'eval/episode_x_velocity': Array(239.43198, dtype=float32), 'eval/episode_y_position': Array(-189.36627, dtype=float32), 'eval/episode_y_velocity': Array(-33.99415, dtype=float32), 'eval/episode_distance_from_origin_std': Array(115.847534, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3303872, dtype=float32), 'eval/episode_forward_reward_std': Array(221.73044, dtype=float32), 'eval/episode_reward_std': Array(244.81966, dtype=float32), 'eval/episode_reward_alive_std': Array(29.624395, dtype=float32), 'eval/episode_reward_linvel_std': Array(221.73044, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.138932, dtype=float32), 'eval/episode_x_position_std': Array(115.79144, dtype=float32), 'eval/episode_x_velocity_std': Array(44.346104, dtype=float32), 'eval/episode_y_position_std': Array(122.17449, dtype=float32), 'eval/episode_y_velocity_std': Array(35.684116, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38756918907166, 'eval/sps': 938.5019526417095, 'num_steps': 1966080}
{'eval/walltime': 3581.430413246155, 'training/sps': 2947.7219561883853, 'training/walltime': 719.7687470912933, 'training/entropy_loss': Array(0.00324953, dtype=float32), 'training/policy_loss': Array(0.10500934, dtype=float32), 'training/total_loss': Array(0.13988987, dtype=float32), 'training/v_loss': Array(0.03163099, dtype=float32), 'eval/episode_distance_from_origin': Array(3648.3787, dtype=float32), 'eval/episode_distance_reward': Array(4.9523044, dtype=float32), 'eval/episode_forward_reward': Array(825.3838, dtype=float32), 'eval/episode_reward': Array(629.13873, dtype=float32), 'eval/episode_reward_alive': Array(169.67578, dtype=float32), 'eval/episode_reward_linvel': Array(825.3838, dtype=float32), 'eval/episode_reward_quadctrl': Array(-370.87317, dtype=float32), 'eval/episode_x_position': Array(3612.4917, dtype=float32), 'eval/episode_x_velocity': Array(165.07674, dtype=float32), 'eval/episode_y_position': Array(116.10293, dtype=float32), 'eval/episode_y_velocity': Array(50.14753, dtype=float32), 'eval/episode_distance_from_origin_std': Array(115.58069, dtype=float32), 'eval/episode_distance_reward_std': Array(1.117987, dtype=float32), 'eval/episode_forward_reward_std': Array(186.3307, dtype=float32), 'eval/episode_reward_std': Array(186.54741, dtype=float32), 'eval/episode_reward_alive_std': Array(18.838497, dtype=float32), 'eval/episode_reward_linvel_std': Array(186.3307, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.507227, dtype=float32), 'eval/episode_x_position_std': Array(116.17871, dtype=float32), 'eval/episode_x_velocity_std': Array(37.266144, dtype=float32), 'eval/episode_y_position_std': Array(168.22667, dtype=float32), 'eval/episode_y_velocity_std': Array(38.458244, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.377774477005, 'eval/sps': 938.5693562669363, 'num_steps': 2048000}
{'eval/walltime': 3717.82377409935, 'training/sps': 2958.248580903747, 'training/walltime': 747.4608080387115, 'training/entropy_loss': Array(0.00192763, dtype=float32), 'training/policy_loss': Array(0.03178094, dtype=float32), 'training/total_loss': Array(0.078238, dtype=float32), 'training/v_loss': Array(0.04452943, dtype=float32), 'eval/episode_distance_from_origin': Array(3721.1934, dtype=float32), 'eval/episode_distance_reward': Array(5.564947, dtype=float32), 'eval/episode_forward_reward': Array(927.4904, dtype=float32), 'eval/episode_reward': Array(736.47107, dtype=float32), 'eval/episode_reward_alive': Array(163.07812, dtype=float32), 'eval/episode_reward_linvel': Array(927.4904, dtype=float32), 'eval/episode_reward_quadctrl': Array(-359.6625, dtype=float32), 'eval/episode_x_position': Array(3687.6853, dtype=float32), 'eval/episode_x_velocity': Array(185.49808, dtype=float32), 'eval/episode_y_position': Array(88.19617, dtype=float32), 'eval/episode_y_velocity': Array(47.1591, dtype=float32), 'eval/episode_distance_from_origin_std': Array(132.03787, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2377365, dtype=float32), 'eval/episode_forward_reward_std': Array(206.28877, dtype=float32), 'eval/episode_reward_std': Array(206.02367, dtype=float32), 'eval/episode_reward_alive_std': Array(24.153435, dtype=float32), 'eval/episode_reward_linvel_std': Array(206.28877, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.499615, dtype=float32), 'eval/episode_x_position_std': Array(131.24771, dtype=float32), 'eval/episode_x_velocity_std': Array(41.25772, dtype=float32), 'eval/episode_y_position_std': Array(153.92604, dtype=float32), 'eval/episode_y_velocity_std': Array(34.843067, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3933608531952, 'eval/sps': 938.4621010825501, 'num_steps': 2129920}
{'eval/walltime': 3854.0756125450134, 'training/sps': 2953.334329360656, 'training/walltime': 775.1989476680756, 'training/entropy_loss': Array(0.00497929, dtype=float32), 'training/policy_loss': Array(0.08630387, dtype=float32), 'training/total_loss': Array(0.12786102, dtype=float32), 'training/v_loss': Array(0.03657786, dtype=float32), 'eval/episode_distance_from_origin': Array(3797.5806, dtype=float32), 'eval/episode_distance_reward': Array(6.2727017, dtype=float32), 'eval/episode_forward_reward': Array(1045.4495, dtype=float32), 'eval/episode_reward': Array(847.8585, dtype=float32), 'eval/episode_reward_alive': Array(132.32812, dtype=float32), 'eval/episode_reward_linvel': Array(1045.4495, dtype=float32), 'eval/episode_reward_quadctrl': Array(-336.19165, dtype=float32), 'eval/episode_x_position': Array(3766.134, dtype=float32), 'eval/episode_x_velocity': Array(209.08989, dtype=float32), 'eval/episode_y_position': Array(27.834688, dtype=float32), 'eval/episode_y_velocity': Array(36.496475, dtype=float32), 'eval/episode_distance_from_origin_std': Array(145.90631, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3295352, dtype=float32), 'eval/episode_forward_reward_std': Array(221.58846, dtype=float32), 'eval/episode_reward_std': Array(232.8625, dtype=float32), 'eval/episode_reward_alive_std': Array(28.376337, dtype=float32), 'eval/episode_reward_linvel_std': Array(221.58846, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.019274, dtype=float32), 'eval/episode_x_position_std': Array(145.65071, dtype=float32), 'eval/episode_x_velocity_std': Array(44.317696, dtype=float32), 'eval/episode_y_position_std': Array(159.36852, dtype=float32), 'eval/episode_y_velocity_std': Array(40.444313, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25183844566345, 'eval/sps': 939.4368652944507, 'num_steps': 2211840}
{'eval/walltime': 3990.5180315971375, 'training/sps': 2951.3458486925883, 'training/walltime': 802.955775976181, 'training/entropy_loss': Array(0.00503305, dtype=float32), 'training/policy_loss': Array(0.02906409, dtype=float32), 'training/total_loss': Array(0.06794307, dtype=float32), 'training/v_loss': Array(0.03384593, dtype=float32), 'eval/episode_distance_from_origin': Array(3834.2073, dtype=float32), 'eval/episode_distance_reward': Array(6.6327076, dtype=float32), 'eval/episode_forward_reward': Array(1105.4502, dtype=float32), 'eval/episode_reward': Array(923.48315, dtype=float32), 'eval/episode_reward_alive': Array(153.03906, dtype=float32), 'eval/episode_reward_linvel': Array(1105.4502, dtype=float32), 'eval/episode_reward_quadctrl': Array(-341.6389, dtype=float32), 'eval/episode_x_position': Array(3803.0488, dtype=float32), 'eval/episode_x_velocity': Array(221.09006, dtype=float32), 'eval/episode_y_position': Array(45.16868, dtype=float32), 'eval/episode_y_velocity': Array(43.11719, dtype=float32), 'eval/episode_distance_from_origin_std': Array(151.04745, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3330973, dtype=float32), 'eval/episode_forward_reward_std': Array(222.18185, dtype=float32), 'eval/episode_reward_std': Array(235.1885, dtype=float32), 'eval/episode_reward_alive_std': Array(33.864193, dtype=float32), 'eval/episode_reward_linvel_std': Array(222.18185, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.373793, dtype=float32), 'eval/episode_x_position_std': Array(151.79883, dtype=float32), 'eval/episode_x_velocity_std': Array(44.43639, dtype=float32), 'eval/episode_y_position_std': Array(141.3116, dtype=float32), 'eval/episode_y_velocity_std': Array(37.230167, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44241905212402, 'eval/sps': 938.124674783882, 'num_steps': 2293760}
{'eval/walltime': 4126.881391763687, 'training/sps': 2956.3079878613207, 'training/walltime': 830.6660146713257, 'training/entropy_loss': Array(0.00642512, dtype=float32), 'training/policy_loss': Array(0.04406103, dtype=float32), 'training/total_loss': Array(0.08071071, dtype=float32), 'training/v_loss': Array(0.03022455, dtype=float32), 'eval/episode_distance_from_origin': Array(3856.3296, dtype=float32), 'eval/episode_distance_reward': Array(7.022498, dtype=float32), 'eval/episode_forward_reward': Array(1170.4149, dtype=float32), 'eval/episode_reward': Array(982.23755, dtype=float32), 'eval/episode_reward_alive': Array(138.71484, dtype=float32), 'eval/episode_reward_linvel': Array(1170.4149, dtype=float32), 'eval/episode_reward_quadctrl': Array(-333.9147, dtype=float32), 'eval/episode_x_position': Array(3825.4482, dtype=float32), 'eval/episode_x_velocity': Array(234.08295, dtype=float32), 'eval/episode_y_position': Array(36.210564, dtype=float32), 'eval/episode_y_velocity': Array(39.22838, dtype=float32), 'eval/episode_distance_from_origin_std': Array(156.52307, dtype=float32), 'eval/episode_distance_reward_std': Array(1.562823, dtype=float32), 'eval/episode_forward_reward_std': Array(260.46887, dtype=float32), 'eval/episode_reward_std': Array(286.56946, dtype=float32), 'eval/episode_reward_alive_std': Array(34.56333, dtype=float32), 'eval/episode_reward_linvel_std': Array(260.46887, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.53034, dtype=float32), 'eval/episode_x_position_std': Array(157.08453, dtype=float32), 'eval/episode_x_velocity_std': Array(52.093746, dtype=float32), 'eval/episode_y_position_std': Array(142.18683, dtype=float32), 'eval/episode_y_velocity_std': Array(42.51718, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.36336016654968, 'eval/sps': 938.6685678885079, 'num_steps': 2375680}
{'eval/walltime': 4263.282289505005, 'training/sps': 2950.6983305000344, 'training/walltime': 858.42893409729, 'training/entropy_loss': Array(0.00712307, dtype=float32), 'training/policy_loss': Array(0.03689635, dtype=float32), 'training/total_loss': Array(0.08139379, dtype=float32), 'training/v_loss': Array(0.03737437, dtype=float32), 'eval/episode_distance_from_origin': Array(3874.771, dtype=float32), 'eval/episode_distance_reward': Array(7.14777, dtype=float32), 'eval/episode_forward_reward': Array(1191.2935, dtype=float32), 'eval/episode_reward': Array(1012.5985, dtype=float32), 'eval/episode_reward_alive': Array(149.82812, dtype=float32), 'eval/episode_reward_linvel': Array(1191.2935, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.67072, dtype=float32), 'eval/episode_x_position': Array(3843.2344, dtype=float32), 'eval/episode_x_velocity': Array(238.25865, dtype=float32), 'eval/episode_y_position': Array(51.641968, dtype=float32), 'eval/episode_y_velocity': Array(39.429512, dtype=float32), 'eval/episode_distance_from_origin_std': Array(180.4077, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7092215, dtype=float32), 'eval/episode_forward_reward_std': Array(284.86856, dtype=float32), 'eval/episode_reward_std': Array(304.26678, dtype=float32), 'eval/episode_reward_alive_std': Array(29.469492, dtype=float32), 'eval/episode_reward_linvel_std': Array(284.86856, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.381641, dtype=float32), 'eval/episode_x_position_std': Array(181.14632, dtype=float32), 'eval/episode_x_velocity_std': Array(56.973698, dtype=float32), 'eval/episode_y_position_std': Array(155.62259, dtype=float32), 'eval/episode_y_velocity_std': Array(44.836147, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40089774131775, 'eval/sps': 938.410245970302, 'num_steps': 2457600}
{'eval/walltime': 4399.535154104233, 'training/sps': 2954.161270731657, 'training/walltime': 886.1593091487885, 'training/entropy_loss': Array(0.00729153, dtype=float32), 'training/policy_loss': Array(0.04600934, dtype=float32), 'training/total_loss': Array(0.0723504, dtype=float32), 'training/v_loss': Array(0.01904953, dtype=float32), 'eval/episode_distance_from_origin': Array(3860.5833, dtype=float32), 'eval/episode_distance_reward': Array(7.359913, dtype=float32), 'eval/episode_forward_reward': Array(1226.6501, dtype=float32), 'eval/episode_reward': Array(1052.7866, dtype=float32), 'eval/episode_reward_alive': Array(150.4375, dtype=float32), 'eval/episode_reward_linvel': Array(1226.6501, dtype=float32), 'eval/episode_reward_quadctrl': Array(-331.66098, dtype=float32), 'eval/episode_x_position': Array(3829.0425, dtype=float32), 'eval/episode_x_velocity': Array(245.33, dtype=float32), 'eval/episode_y_position': Array(3.3745828, dtype=float32), 'eval/episode_y_velocity': Array(27.131117, dtype=float32), 'eval/episode_distance_from_origin_std': Array(173.99739, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7041864, dtype=float32), 'eval/episode_forward_reward_std': Array(284.02914, dtype=float32), 'eval/episode_reward_std': Array(307.17435, dtype=float32), 'eval/episode_reward_alive_std': Array(31.864029, dtype=float32), 'eval/episode_reward_linvel_std': Array(284.02914, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.678005, dtype=float32), 'eval/episode_x_position_std': Array(174.83414, dtype=float32), 'eval/episode_x_velocity_std': Array(56.80582, dtype=float32), 'eval/episode_y_position_std': Array(157.44974, dtype=float32), 'eval/episode_y_velocity_std': Array(46.832943, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2528645992279, 'eval/sps': 939.4297901662269, 'num_steps': 2539520}
{'eval/walltime': 4535.926936864853, 'training/sps': 2944.3936542383517, 'training/walltime': 913.981675863266, 'training/entropy_loss': Array(0.00315004, dtype=float32), 'training/policy_loss': Array(0.00786362, dtype=float32), 'training/total_loss': Array(0.05283146, dtype=float32), 'training/v_loss': Array(0.0418178, dtype=float32), 'eval/episode_distance_from_origin': Array(3984.8027, dtype=float32), 'eval/episode_distance_reward': Array(8.294802, dtype=float32), 'eval/episode_forward_reward': Array(1382.4636, dtype=float32), 'eval/episode_reward': Array(1209.4167, dtype=float32), 'eval/episode_reward_alive': Array(148.89453, dtype=float32), 'eval/episode_reward_linvel': Array(1382.4636, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.23627, dtype=float32), 'eval/episode_x_position': Array(3953.4224, dtype=float32), 'eval/episode_x_velocity': Array(276.49274, dtype=float32), 'eval/episode_y_position': Array(63.33774, dtype=float32), 'eval/episode_y_velocity': Array(32.302525, dtype=float32), 'eval/episode_distance_from_origin_std': Array(170.71846, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8853469, dtype=float32), 'eval/episode_forward_reward_std': Array(314.22156, dtype=float32), 'eval/episode_reward_std': Array(347.58472, dtype=float32), 'eval/episode_reward_alive_std': Array(35.509884, dtype=float32), 'eval/episode_reward_linvel_std': Array(314.22156, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.839308, dtype=float32), 'eval/episode_x_position_std': Array(171.8592, dtype=float32), 'eval/episode_x_velocity_std': Array(62.84431, dtype=float32), 'eval/episode_y_position_std': Array(166.21652, dtype=float32), 'eval/episode_y_velocity_std': Array(52.599964, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39178276062012, 'eval/sps': 938.4729593618667, 'num_steps': 2621440}
{'eval/walltime': 4672.201342582703, 'training/sps': 2953.960174244055, 'training/walltime': 941.7139387130737, 'training/entropy_loss': Array(0.00445289, dtype=float32), 'training/policy_loss': Array(0.00345641, dtype=float32), 'training/total_loss': Array(0.03825274, dtype=float32), 'training/v_loss': Array(0.03034344, dtype=float32), 'eval/episode_distance_from_origin': Array(3994.2563, dtype=float32), 'eval/episode_distance_reward': Array(8.617422, dtype=float32), 'eval/episode_forward_reward': Array(1436.2328, dtype=float32), 'eval/episode_reward': Array(1272.0502, dtype=float32), 'eval/episode_reward_alive': Array(152.0664, dtype=float32), 'eval/episode_reward_linvel': Array(1436.2328, dtype=float32), 'eval/episode_reward_quadctrl': Array(-324.8665, dtype=float32), 'eval/episode_x_position': Array(3962.8516, dtype=float32), 'eval/episode_x_velocity': Array(287.24655, dtype=float32), 'eval/episode_y_position': Array(38.85542, dtype=float32), 'eval/episode_y_velocity': Array(20.367128, dtype=float32), 'eval/episode_distance_from_origin_std': Array(175.76814, dtype=float32), 'eval/episode_distance_reward_std': Array(2.0699358, dtype=float32), 'eval/episode_forward_reward_std': Array(344.98602, dtype=float32), 'eval/episode_reward_std': Array(379.10968, dtype=float32), 'eval/episode_reward_alive_std': Array(39.43623, dtype=float32), 'eval/episode_reward_linvel_std': Array(344.98602, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.619013, dtype=float32), 'eval/episode_x_position_std': Array(176.78993, dtype=float32), 'eval/episode_x_velocity_std': Array(68.997215, dtype=float32), 'eval/episode_y_position_std': Array(172.85262, dtype=float32), 'eval/episode_y_velocity_std': Array(54.71428, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27440571784973, 'eval/sps': 939.2812929598715, 'num_steps': 2703360}
{'eval/walltime': 4808.715479135513, 'training/sps': 2939.3221818398824, 'training/walltime': 969.5843098163605, 'training/entropy_loss': Array(0.00523987, dtype=float32), 'training/policy_loss': Array(0.00448252, dtype=float32), 'training/total_loss': Array(0.04483454, dtype=float32), 'training/v_loss': Array(0.03511215, dtype=float32), 'eval/episode_distance_from_origin': Array(4063.092, dtype=float32), 'eval/episode_distance_reward': Array(9.699724, dtype=float32), 'eval/episode_forward_reward': Array(1616.6143, dtype=float32), 'eval/episode_reward': Array(1470.8728, dtype=float32), 'eval/episode_reward_alive': Array(162.77734, dtype=float32), 'eval/episode_reward_linvel': Array(1616.6143, dtype=float32), 'eval/episode_reward_quadctrl': Array(-318.21832, dtype=float32), 'eval/episode_x_position': Array(4031.3394, dtype=float32), 'eval/episode_x_velocity': Array(323.32285, dtype=float32), 'eval/episode_y_position': Array(0.34498549, dtype=float32), 'eval/episode_y_velocity': Array(-3.725055, dtype=float32), 'eval/episode_distance_from_origin_std': Array(178.09811, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2014303, dtype=float32), 'eval/episode_forward_reward_std': Array(366.90143, dtype=float32), 'eval/episode_reward_std': Array(398.15594, dtype=float32), 'eval/episode_reward_alive_std': Array(36.98262, dtype=float32), 'eval/episode_reward_linvel_std': Array(366.90143, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.149048, dtype=float32), 'eval/episode_x_position_std': Array(178.88594, dtype=float32), 'eval/episode_x_velocity_std': Array(73.38029, dtype=float32), 'eval/episode_y_position_std': Array(190.04433, dtype=float32), 'eval/episode_y_velocity_std': Array(56.61756, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51413655281067, 'eval/sps': 937.6318323669215, 'num_steps': 2785280}
{'eval/walltime': 4945.561982393265, 'training/sps': 2950.1471957787367, 'training/walltime': 997.3524158000946, 'training/entropy_loss': Array(0.00559736, dtype=float32), 'training/policy_loss': Array(0.00812575, dtype=float32), 'training/total_loss': Array(0.04770932, dtype=float32), 'training/v_loss': Array(0.0339862, dtype=float32), 'eval/episode_distance_from_origin': Array(4072.081, dtype=float32), 'eval/episode_distance_reward': Array(9.678523, dtype=float32), 'eval/episode_forward_reward': Array(1613.081, dtype=float32), 'eval/episode_reward': Array(1466.8208, dtype=float32), 'eval/episode_reward_alive': Array(162.3164, dtype=float32), 'eval/episode_reward_linvel': Array(1613.081, dtype=float32), 'eval/episode_reward_quadctrl': Array(-318.25507, dtype=float32), 'eval/episode_x_position': Array(4040.95, dtype=float32), 'eval/episode_x_velocity': Array(322.6162, dtype=float32), 'eval/episode_y_position': Array(-19.562168, dtype=float32), 'eval/episode_y_velocity': Array(-7.2117367, dtype=float32), 'eval/episode_distance_from_origin_std': Array(191.29893, dtype=float32), 'eval/episode_distance_reward_std': Array(2.3536499, dtype=float32), 'eval/episode_forward_reward_std': Array(392.2709, dtype=float32), 'eval/episode_reward_std': Array(426.25153, dtype=float32), 'eval/episode_reward_alive_std': Array(41.26282, dtype=float32), 'eval/episode_reward_linvel_std': Array(392.2709, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.967937, dtype=float32), 'eval/episode_x_position_std': Array(191.97194, dtype=float32), 'eval/episode_x_velocity_std': Array(78.454216, dtype=float32), 'eval/episode_y_position_std': Array(172.60266, dtype=float32), 'eval/episode_y_velocity_std': Array(55.457706, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84650325775146, 'eval/sps': 935.3545538457128, 'num_steps': 2867200}
{'eval/walltime': 5083.032575368881, 'training/sps': 2938.9049917570187, 'training/walltime': 1025.226743221283, 'training/entropy_loss': Array(0.00594598, dtype=float32), 'training/policy_loss': Array(0.01901341, dtype=float32), 'training/total_loss': Array(0.06116014, dtype=float32), 'training/v_loss': Array(0.03620074, dtype=float32), 'eval/episode_distance_from_origin': Array(4109.4736, dtype=float32), 'eval/episode_distance_reward': Array(10.093391, dtype=float32), 'eval/episode_forward_reward': Array(1682.2251, dtype=float32), 'eval/episode_reward': Array(1543.5471, dtype=float32), 'eval/episode_reward_alive': Array(170.53516, dtype=float32), 'eval/episode_reward_linvel': Array(1682.2251, dtype=float32), 'eval/episode_reward_quadctrl': Array(-319.30634, dtype=float32), 'eval/episode_x_position': Array(4077.6843, dtype=float32), 'eval/episode_x_velocity': Array(336.445, dtype=float32), 'eval/episode_y_position': Array(-27.922134, dtype=float32), 'eval/episode_y_velocity': Array(-11.194802, dtype=float32), 'eval/episode_distance_from_origin_std': Array(164.5298, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2694697, dtype=float32), 'eval/episode_forward_reward_std': Array(378.24084, dtype=float32), 'eval/episode_reward_std': Array(401.75226, dtype=float32), 'eval/episode_reward_alive_std': Array(36.52916, dtype=float32), 'eval/episode_reward_linvel_std': Array(378.24084, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.444906, dtype=float32), 'eval/episode_x_position_std': Array(166.29819, dtype=float32), 'eval/episode_x_velocity_std': Array(75.64817, dtype=float32), 'eval/episode_y_position_std': Array(190.26303, dtype=float32), 'eval/episode_y_velocity_std': Array(56.491528, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.47059297561646, 'eval/sps': 931.1082263441151, 'num_steps': 2949120}
{'eval/walltime': 5219.787202835083, 'training/sps': 2925.530818066639, 'training/walltime': 1053.228499174118, 'training/entropy_loss': Array(0.00601492, dtype=float32), 'training/policy_loss': Array(0.02002554, dtype=float32), 'training/total_loss': Array(0.06250266, dtype=float32), 'training/v_loss': Array(0.0364622, dtype=float32), 'eval/episode_distance_from_origin': Array(4090.3154, dtype=float32), 'eval/episode_distance_reward': Array(9.605841, dtype=float32), 'eval/episode_forward_reward': Array(1600.9672, dtype=float32), 'eval/episode_reward': Array(1453.1841, dtype=float32), 'eval/episode_reward_alive': Array(167.1836, dtype=float32), 'eval/episode_reward_linvel': Array(1600.9672, dtype=float32), 'eval/episode_reward_quadctrl': Array(-324.57245, dtype=float32), 'eval/episode_x_position': Array(4058.7476, dtype=float32), 'eval/episode_x_velocity': Array(320.19345, dtype=float32), 'eval/episode_y_position': Array(12.079084, dtype=float32), 'eval/episode_y_velocity': Array(5.971305, dtype=float32), 'eval/episode_distance_from_origin_std': Array(180.73225, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4716966, dtype=float32), 'eval/episode_forward_reward_std': Array(411.9456, dtype=float32), 'eval/episode_reward_std': Array(440.95126, dtype=float32), 'eval/episode_reward_alive_std': Array(48.50036, dtype=float32), 'eval/episode_reward_linvel_std': Array(411.9456, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.190313, dtype=float32), 'eval/episode_x_position_std': Array(182.41983, dtype=float32), 'eval/episode_x_velocity_std': Array(82.389114, dtype=float32), 'eval/episode_y_position_std': Array(187.98517, dtype=float32), 'eval/episode_y_velocity_std': Array(55.201874, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.75462746620178, 'eval/sps': 935.9829526180717, 'num_steps': 3031040}
{'eval/walltime': 5356.556962251663, 'training/sps': 2948.243902215512, 'training/walltime': 1081.0145313739777, 'training/entropy_loss': Array(0.00583237, dtype=float32), 'training/policy_loss': Array(0.0325674, dtype=float32), 'training/total_loss': Array(0.08142971, dtype=float32), 'training/v_loss': Array(0.04302995, dtype=float32), 'eval/episode_distance_from_origin': Array(4176.4043, dtype=float32), 'eval/episode_distance_reward': Array(10.442835, dtype=float32), 'eval/episode_forward_reward': Array(1740.4647, dtype=float32), 'eval/episode_reward': Array(1608.3411, dtype=float32), 'eval/episode_reward_alive': Array(181.85156, dtype=float32), 'eval/episode_reward_linvel': Array(1740.4647, dtype=float32), 'eval/episode_reward_quadctrl': Array(-324.41797, dtype=float32), 'eval/episode_x_position': Array(4145.2124, dtype=float32), 'eval/episode_x_velocity': Array(348.0929, dtype=float32), 'eval/episode_y_position': Array(51.504234, dtype=float32), 'eval/episode_y_velocity': Array(6.684273, dtype=float32), 'eval/episode_distance_from_origin_std': Array(194.46538, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4891708, dtype=float32), 'eval/episode_forward_reward_std': Array(414.8577, dtype=float32), 'eval/episode_reward_std': Array(431.7082, dtype=float32), 'eval/episode_reward_alive_std': Array(42.598934, dtype=float32), 'eval/episode_reward_linvel_std': Array(414.8577, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.409578, dtype=float32), 'eval/episode_x_position_std': Array(195.36397, dtype=float32), 'eval/episode_x_velocity_std': Array(82.971504, dtype=float32), 'eval/episode_y_position_std': Array(180.06737, dtype=float32), 'eval/episode_y_velocity_std': Array(50.458958, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7697594165802, 'eval/sps': 935.8793972147832, 'num_steps': 3112960}
{'eval/walltime': 5493.5059633255005, 'training/sps': 2938.215155812273, 'training/walltime': 1108.8954031467438, 'training/entropy_loss': Array(0.00259089, dtype=float32), 'training/policy_loss': Array(-0.00236247, dtype=float32), 'training/total_loss': Array(0.02324262, dtype=float32), 'training/v_loss': Array(0.02301421, dtype=float32), 'eval/episode_distance_from_origin': Array(4163.0244, dtype=float32), 'eval/episode_distance_reward': Array(10.187554, dtype=float32), 'eval/episode_forward_reward': Array(1697.9183, dtype=float32), 'eval/episode_reward': Array(1566.0173, dtype=float32), 'eval/episode_reward_alive': Array(186.22656, dtype=float32), 'eval/episode_reward_linvel': Array(1697.9183, dtype=float32), 'eval/episode_reward_quadctrl': Array(-328.31494, dtype=float32), 'eval/episode_x_position': Array(4131.3887, dtype=float32), 'eval/episode_x_velocity': Array(339.58362, dtype=float32), 'eval/episode_y_position': Array(-15.76216, dtype=float32), 'eval/episode_y_velocity': Array(-6.732373, dtype=float32), 'eval/episode_distance_from_origin_std': Array(193.71544, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7597427, dtype=float32), 'eval/episode_forward_reward_std': Array(459.95288, dtype=float32), 'eval/episode_reward_std': Array(475.6009, dtype=float32), 'eval/episode_reward_alive_std': Array(56.376694, dtype=float32), 'eval/episode_reward_linvel_std': Array(459.95288, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.218103, dtype=float32), 'eval/episode_x_position_std': Array(194.44981, dtype=float32), 'eval/episode_x_velocity_std': Array(91.99056, dtype=float32), 'eval/episode_y_position_std': Array(190.62772, dtype=float32), 'eval/episode_y_velocity_std': Array(58.477444, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.94900107383728, 'eval/sps': 934.6544990933352, 'num_steps': 3194880}
{'eval/walltime': 5630.539432287216, 'training/sps': 2939.2701083192583, 'training/walltime': 1136.7662680149078, 'training/entropy_loss': Array(0.00589035, dtype=float32), 'training/policy_loss': Array(0.01114174, dtype=float32), 'training/total_loss': Array(0.05226473, dtype=float32), 'training/v_loss': Array(0.03523263, dtype=float32), 'eval/episode_distance_from_origin': Array(4130.759, dtype=float32), 'eval/episode_distance_reward': Array(9.533922, dtype=float32), 'eval/episode_forward_reward': Array(1588.9807, dtype=float32), 'eval/episode_reward': Array(1446.481, dtype=float32), 'eval/episode_reward_alive': Array(175.51953, dtype=float32), 'eval/episode_reward_linvel': Array(1588.9807, dtype=float32), 'eval/episode_reward_quadctrl': Array(-327.55304, dtype=float32), 'eval/episode_x_position': Array(4099.364, dtype=float32), 'eval/episode_x_velocity': Array(317.7961, dtype=float32), 'eval/episode_y_position': Array(14.211144, dtype=float32), 'eval/episode_y_velocity': Array(9.721025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(197.92793, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7442882, dtype=float32), 'eval/episode_forward_reward_std': Array(457.3766, dtype=float32), 'eval/episode_reward_std': Array(476.70065, dtype=float32), 'eval/episode_reward_alive_std': Array(50.52074, dtype=float32), 'eval/episode_reward_linvel_std': Array(457.3766, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.188251, dtype=float32), 'eval/episode_x_position_std': Array(197.9608, dtype=float32), 'eval/episode_x_velocity_std': Array(91.475296, dtype=float32), 'eval/episode_y_position_std': Array(180.22571, dtype=float32), 'eval/episode_y_velocity_std': Array(62.74127, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.0334689617157, 'eval/sps': 934.0783749389029, 'num_steps': 3276800}
{'eval/walltime': 5767.255861282349, 'training/sps': 2951.4757261649793, 'training/walltime': 1164.5218749046326, 'training/entropy_loss': Array(0.00510354, dtype=float32), 'training/policy_loss': Array(0.01307518, dtype=float32), 'training/total_loss': Array(0.0644718, dtype=float32), 'training/v_loss': Array(0.04629307, dtype=float32), 'eval/episode_distance_from_origin': Array(4143.4434, dtype=float32), 'eval/episode_distance_reward': Array(9.6531925, dtype=float32), 'eval/episode_forward_reward': Array(1608.859, dtype=float32), 'eval/episode_reward': Array(1472.597, dtype=float32), 'eval/episode_reward_alive': Array(189.15234, dtype=float32), 'eval/episode_reward_linvel': Array(1608.859, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.06763, dtype=float32), 'eval/episode_x_position': Array(4110.7627, dtype=float32), 'eval/episode_x_velocity': Array(321.77182, dtype=float32), 'eval/episode_y_position': Array(22.227312, dtype=float32), 'eval/episode_y_velocity': Array(12.848499, dtype=float32), 'eval/episode_distance_from_origin_std': Array(252.33417, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3088374, dtype=float32), 'eval/episode_forward_reward_std': Array(551.4679, dtype=float32), 'eval/episode_reward_std': Array(574.28046, dtype=float32), 'eval/episode_reward_alive_std': Array(67.04606, dtype=float32), 'eval/episode_reward_linvel_std': Array(551.4679, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.542084, dtype=float32), 'eval/episode_x_position_std': Array(254.28519, dtype=float32), 'eval/episode_x_velocity_std': Array(110.2936, dtype=float32), 'eval/episode_y_position_std': Array(197.88756, dtype=float32), 'eval/episode_y_velocity_std': Array(70.684425, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.71642899513245, 'eval/sps': 936.2444655759493, 'num_steps': 3358720}
{'eval/walltime': 5903.8800740242, 'training/sps': 2937.6777159357903, 'training/walltime': 1192.40784740448, 'training/entropy_loss': Array(0.00651061, dtype=float32), 'training/policy_loss': Array(0.03303193, dtype=float32), 'training/total_loss': Array(0.07606971, dtype=float32), 'training/v_loss': Array(0.03652718, dtype=float32), 'eval/episode_distance_from_origin': Array(4088.531, dtype=float32), 'eval/episode_distance_reward': Array(8.822907, dtype=float32), 'eval/episode_forward_reward': Array(1470.4792, dtype=float32), 'eval/episode_reward': Array(1320.6304, dtype=float32), 'eval/episode_reward_alive': Array(174.1914, dtype=float32), 'eval/episode_reward_linvel': Array(1470.4792, dtype=float32), 'eval/episode_reward_quadctrl': Array(-332.86313, dtype=float32), 'eval/episode_x_position': Array(4054.1118, dtype=float32), 'eval/episode_x_velocity': Array(294.09583, dtype=float32), 'eval/episode_y_position': Array(86.83101, dtype=float32), 'eval/episode_y_velocity': Array(43.10817, dtype=float32), 'eval/episode_distance_from_origin_std': Array(239.23848, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0322897, dtype=float32), 'eval/episode_forward_reward_std': Array(505.3771, dtype=float32), 'eval/episode_reward_std': Array(529.52966, dtype=float32), 'eval/episode_reward_alive_std': Array(67.02734, dtype=float32), 'eval/episode_reward_linvel_std': Array(505.3771, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.204693, dtype=float32), 'eval/episode_x_position_std': Array(242.3917, dtype=float32), 'eval/episode_x_velocity_std': Array(101.07542, dtype=float32), 'eval/episode_y_position_std': Array(201.40231, dtype=float32), 'eval/episode_y_velocity_std': Array(71.446396, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6242127418518, 'eval/sps': 936.8763957077867, 'num_steps': 3440640}
{'eval/walltime': 6040.403616905212, 'training/sps': 2951.255146590973, 'training/walltime': 1220.1655287742615, 'training/entropy_loss': Array(0.00676428, dtype=float32), 'training/policy_loss': Array(0.04857764, dtype=float32), 'training/total_loss': Array(0.08598894, dtype=float32), 'training/v_loss': Array(0.03064702, dtype=float32), 'eval/episode_distance_from_origin': Array(4108.326, dtype=float32), 'eval/episode_distance_reward': Array(8.791958, dtype=float32), 'eval/episode_forward_reward': Array(1465.321, dtype=float32), 'eval/episode_reward': Array(1339.6279, dtype=float32), 'eval/episode_reward_alive': Array(216.1914, dtype=float32), 'eval/episode_reward_linvel': Array(1465.321, dtype=float32), 'eval/episode_reward_quadctrl': Array(-350.67645, dtype=float32), 'eval/episode_x_position': Array(4072.2656, dtype=float32), 'eval/episode_x_velocity': Array(293.06415, dtype=float32), 'eval/episode_y_position': Array(82.217636, dtype=float32), 'eval/episode_y_velocity': Array(32.902115, dtype=float32), 'eval/episode_distance_from_origin_std': Array(259.48752, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3430016, dtype=float32), 'eval/episode_forward_reward_std': Array(557.1618, dtype=float32), 'eval/episode_reward_std': Array(561.8085, dtype=float32), 'eval/episode_reward_alive_std': Array(78.71795, dtype=float32), 'eval/episode_reward_linvel_std': Array(557.1618, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.7907, dtype=float32), 'eval/episode_x_position_std': Array(262.4935, dtype=float32), 'eval/episode_x_velocity_std': Array(111.432335, dtype=float32), 'eval/episode_y_position_std': Array(228.03073, dtype=float32), 'eval/episode_y_velocity_std': Array(71.03602, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52354288101196, 'eval/sps': 937.5672305219862, 'num_steps': 3522560}
{'eval/walltime': 6177.268951654434, 'training/sps': 2934.726961848524, 'training/walltime': 1248.0795395374298, 'training/entropy_loss': Array(0.00759501, dtype=float32), 'training/policy_loss': Array(0.117635, dtype=float32), 'training/total_loss': Array(0.16567731, dtype=float32), 'training/v_loss': Array(0.04044729, dtype=float32), 'eval/episode_distance_from_origin': Array(4061.5486, dtype=float32), 'eval/episode_distance_reward': Array(7.5707717, dtype=float32), 'eval/episode_forward_reward': Array(1261.7927, dtype=float32), 'eval/episode_reward': Array(1070.8229, dtype=float32), 'eval/episode_reward_alive': Array(131.9375, dtype=float32), 'eval/episode_reward_linvel': Array(1261.7927, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.4781, dtype=float32), 'eval/episode_x_position': Array(4030.5303, dtype=float32), 'eval/episode_x_velocity': Array(252.35854, dtype=float32), 'eval/episode_y_position': Array(82.20835, dtype=float32), 'eval/episode_y_velocity': Array(31.592165, dtype=float32), 'eval/episode_distance_from_origin_std': Array(172.85657, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2203639, dtype=float32), 'eval/episode_forward_reward_std': Array(370.0573, dtype=float32), 'eval/episode_reward_std': Array(397.93423, dtype=float32), 'eval/episode_reward_alive_std': Array(53.893486, dtype=float32), 'eval/episode_reward_linvel_std': Array(370.0573, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.699348, dtype=float32), 'eval/episode_x_position_std': Array(173.45103, dtype=float32), 'eval/episode_x_velocity_std': Array(74.01146, dtype=float32), 'eval/episode_y_position_std': Array(173.5872, dtype=float32), 'eval/episode_y_velocity_std': Array(53.23498, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8653347492218, 'eval/sps': 935.2258571137407, 'num_steps': 3604480}
{'eval/walltime': 6313.771224737167, 'training/sps': 2946.851378364207, 'training/walltime': 1275.8787019252777, 'training/entropy_loss': Array(0.00277348, dtype=float32), 'training/policy_loss': Array(0.00376477, dtype=float32), 'training/total_loss': Array(0.04589649, dtype=float32), 'training/v_loss': Array(0.03935824, dtype=float32), 'eval/episode_distance_from_origin': Array(4068.3613, dtype=float32), 'eval/episode_distance_reward': Array(7.6207485, dtype=float32), 'eval/episode_forward_reward': Array(1270.1221, dtype=float32), 'eval/episode_reward': Array(1084.9283, dtype=float32), 'eval/episode_reward_alive': Array(144.01172, dtype=float32), 'eval/episode_reward_linvel': Array(1270.1221, dtype=float32), 'eval/episode_reward_quadctrl': Array(-336.8263, dtype=float32), 'eval/episode_x_position': Array(4036.9868, dtype=float32), 'eval/episode_x_velocity': Array(254.02441, dtype=float32), 'eval/episode_y_position': Array(121.12548, dtype=float32), 'eval/episode_y_velocity': Array(39.42208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(201.38252, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4043875, dtype=float32), 'eval/episode_forward_reward_std': Array(400.72818, dtype=float32), 'eval/episode_reward_std': Array(425.34607, dtype=float32), 'eval/episode_reward_alive_std': Array(64.66408, dtype=float32), 'eval/episode_reward_linvel_std': Array(400.72818, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.586933, dtype=float32), 'eval/episode_x_position_std': Array(204.17395, dtype=float32), 'eval/episode_x_velocity_std': Array(80.14563, dtype=float32), 'eval/episode_y_position_std': Array(162.41734, dtype=float32), 'eval/episode_y_velocity_std': Array(45.737354, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50227308273315, 'eval/sps': 937.7133223446032, 'num_steps': 3686400}
{'eval/walltime': 6450.47270989418, 'training/sps': 2940.1615215188176, 'training/walltime': 1303.7411167621613, 'training/entropy_loss': Array(0.00511098, dtype=float32), 'training/policy_loss': Array(-0.00064546, dtype=float32), 'training/total_loss': Array(0.03119439, dtype=float32), 'training/v_loss': Array(0.02672887, dtype=float32), 'eval/episode_distance_from_origin': Array(4073.8828, dtype=float32), 'eval/episode_distance_reward': Array(7.54893, dtype=float32), 'eval/episode_forward_reward': Array(1258.1528, dtype=float32), 'eval/episode_reward': Array(1074.9336, dtype=float32), 'eval/episode_reward_alive': Array(143.63281, dtype=float32), 'eval/episode_reward_linvel': Array(1258.1528, dtype=float32), 'eval/episode_reward_quadctrl': Array(-334.40125, dtype=float32), 'eval/episode_x_position': Array(4042.1848, dtype=float32), 'eval/episode_x_velocity': Array(251.6306, dtype=float32), 'eval/episode_y_position': Array(113.10633, dtype=float32), 'eval/episode_y_velocity': Array(36.934097, dtype=float32), 'eval/episode_distance_from_origin_std': Array(169.35725, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9007008, dtype=float32), 'eval/episode_forward_reward_std': Array(316.78107, dtype=float32), 'eval/episode_reward_std': Array(333.4293, dtype=float32), 'eval/episode_reward_alive_std': Array(49.769566, dtype=float32), 'eval/episode_reward_linvel_std': Array(316.78107, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.185148, dtype=float32), 'eval/episode_x_position_std': Array(171.20592, dtype=float32), 'eval/episode_x_velocity_std': Array(63.35623, dtype=float32), 'eval/episode_y_position_std': Array(175.9716, dtype=float32), 'eval/episode_y_velocity_std': Array(47.00109, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70148515701294, 'eval/sps': 936.3468132989296, 'num_steps': 3768320}
{'eval/walltime': 6587.247317075729, 'training/sps': 2929.85770614765, 'training/walltime': 1331.7015190124512, 'training/entropy_loss': Array(0.00533739, dtype=float32), 'training/policy_loss': Array(0.0121288, dtype=float32), 'training/total_loss': Array(0.06109996, dtype=float32), 'training/v_loss': Array(0.04363376, dtype=float32), 'eval/episode_distance_from_origin': Array(4068.6196, dtype=float32), 'eval/episode_distance_reward': Array(7.430171, dtype=float32), 'eval/episode_forward_reward': Array(1238.3593, dtype=float32), 'eval/episode_reward': Array(1059.373, dtype=float32), 'eval/episode_reward_alive': Array(156.30078, dtype=float32), 'eval/episode_reward_linvel': Array(1238.3593, dtype=float32), 'eval/episode_reward_quadctrl': Array(-342.71735, dtype=float32), 'eval/episode_x_position': Array(4035.2732, dtype=float32), 'eval/episode_x_velocity': Array(247.67184, dtype=float32), 'eval/episode_y_position': Array(133.36436, dtype=float32), 'eval/episode_y_velocity': Array(45.12185, dtype=float32), 'eval/episode_distance_from_origin_std': Array(189.91133, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2606122, dtype=float32), 'eval/episode_forward_reward_std': Array(376.7658, dtype=float32), 'eval/episode_reward_std': Array(398.6174, dtype=float32), 'eval/episode_reward_alive_std': Array(73.7002, dtype=float32), 'eval/episode_reward_linvel_std': Array(376.7658, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.4801, dtype=float32), 'eval/episode_x_position_std': Array(192.23276, dtype=float32), 'eval/episode_x_velocity_std': Array(75.35314, dtype=float32), 'eval/episode_y_position_std': Array(186.85783, dtype=float32), 'eval/episode_y_velocity_std': Array(50.320316, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.77460718154907, 'eval/sps': 935.8462264131966, 'num_steps': 3850240}
{'eval/walltime': 6723.919704914093, 'training/sps': 2933.76271286933, 'training/walltime': 1359.624704360962, 'training/entropy_loss': Array(0.00716641, dtype=float32), 'training/policy_loss': Array(0.04886902, dtype=float32), 'training/total_loss': Array(0.09366859, dtype=float32), 'training/v_loss': Array(0.03763315, dtype=float32), 'eval/episode_distance_from_origin': Array(4079.523, dtype=float32), 'eval/episode_distance_reward': Array(7.3165007, dtype=float32), 'eval/episode_forward_reward': Array(1219.415, dtype=float32), 'eval/episode_reward': Array(1038.1409, dtype=float32), 'eval/episode_reward_alive': Array(158.91797, dtype=float32), 'eval/episode_reward_linvel': Array(1219.415, dtype=float32), 'eval/episode_reward_quadctrl': Array(-347.5087, dtype=float32), 'eval/episode_x_position': Array(4047.5784, dtype=float32), 'eval/episode_x_velocity': Array(243.88303, dtype=float32), 'eval/episode_y_position': Array(105.43807, dtype=float32), 'eval/episode_y_velocity': Array(37.12529, dtype=float32), 'eval/episode_distance_from_origin_std': Array(173.90741, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8994049, dtype=float32), 'eval/episode_forward_reward_std': Array(316.5656, dtype=float32), 'eval/episode_reward_std': Array(339.58466, dtype=float32), 'eval/episode_reward_alive_std': Array(71.34976, dtype=float32), 'eval/episode_reward_linvel_std': Array(316.5656, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.10428, dtype=float32), 'eval/episode_x_position_std': Array(176.05338, dtype=float32), 'eval/episode_x_velocity_std': Array(63.31316, dtype=float32), 'eval/episode_y_position_std': Array(174.66977, dtype=float32), 'eval/episode_y_velocity_std': Array(50.727253, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67238783836365, 'eval/sps': 936.5461599410987, 'num_steps': 3932160}
{'eval/walltime': 6860.5875787734985, 'training/sps': 2939.125438603229, 'training/walltime': 1387.4969410896301, 'training/entropy_loss': Array(0.00699066, dtype=float32), 'training/policy_loss': Array(0.28252926, dtype=float32), 'training/total_loss': Array(0.31790575, dtype=float32), 'training/v_loss': Array(0.02838581, dtype=float32), 'eval/episode_distance_from_origin': Array(3947.4932, dtype=float32), 'eval/episode_distance_reward': Array(6.968725, dtype=float32), 'eval/episode_forward_reward': Array(1161.4521, dtype=float32), 'eval/episode_reward': Array(1096.1958, dtype=float32), 'eval/episode_reward_alive': Array(273.26172, dtype=float32), 'eval/episode_reward_linvel': Array(1161.4521, dtype=float32), 'eval/episode_reward_quadctrl': Array(-345.48676, dtype=float32), 'eval/episode_x_position': Array(3906.8223, dtype=float32), 'eval/episode_x_velocity': Array(232.29044, dtype=float32), 'eval/episode_y_position': Array(-166.33853, dtype=float32), 'eval/episode_y_velocity': Array(-51.847404, dtype=float32), 'eval/episode_distance_from_origin_std': Array(154.36894, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4161247, dtype=float32), 'eval/episode_forward_reward_std': Array(236.01958, dtype=float32), 'eval/episode_reward_std': Array(225.94283, dtype=float32), 'eval/episode_reward_alive_std': Array(50.797886, dtype=float32), 'eval/episode_reward_linvel_std': Array(236.01958, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.40462, dtype=float32), 'eval/episode_x_position_std': Array(153.65305, dtype=float32), 'eval/episode_x_velocity_std': Array(47.20394, dtype=float32), 'eval/episode_y_position_std': Array(183.19122, dtype=float32), 'eval/episode_y_velocity_std': Array(52.38107, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66787385940552, 'eval/sps': 936.5770929580538, 'num_steps': 4014080}
{'eval/walltime': 6997.503719568253, 'training/sps': 2933.405374311053, 'training/walltime': 1415.423527956009, 'training/entropy_loss': Array(0.00740799, dtype=float32), 'training/policy_loss': Array(0.09145296, dtype=float32), 'training/total_loss': Array(0.12874614, dtype=float32), 'training/v_loss': Array(0.0298852, dtype=float32), 'eval/episode_distance_from_origin': Array(3844.081, dtype=float32), 'eval/episode_distance_reward': Array(6.3209987, dtype=float32), 'eval/episode_forward_reward': Array(1053.4982, dtype=float32), 'eval/episode_reward': Array(1010.5687, dtype=float32), 'eval/episode_reward_alive': Array(268.70703, dtype=float32), 'eval/episode_reward_linvel': Array(1053.4982, dtype=float32), 'eval/episode_reward_quadctrl': Array(-317.9573, dtype=float32), 'eval/episode_x_position': Array(3802.5024, dtype=float32), 'eval/episode_x_velocity': Array(210.69962, dtype=float32), 'eval/episode_y_position': Array(-197.0326, dtype=float32), 'eval/episode_y_velocity': Array(-52.412304, dtype=float32), 'eval/episode_distance_from_origin_std': Array(142.95424, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2302723, dtype=float32), 'eval/episode_forward_reward_std': Array(205.04533, dtype=float32), 'eval/episode_reward_std': Array(191.85567, dtype=float32), 'eval/episode_reward_alive_std': Array(50.955807, dtype=float32), 'eval/episode_reward_linvel_std': Array(205.04533, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.312113, dtype=float32), 'eval/episode_x_position_std': Array(141.98738, dtype=float32), 'eval/episode_x_velocity_std': Array(41.009075, dtype=float32), 'eval/episode_y_position_std': Array(156.75638, dtype=float32), 'eval/episode_y_velocity_std': Array(45.300663, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.91614079475403, 'eval/sps': 934.8788189398364, 'num_steps': 4096000}
{'eval/walltime': 7134.143122911453, 'training/sps': 2939.3738045870937, 'training/walltime': 1443.2934095859528, 'training/entropy_loss': Array(0.00438493, dtype=float32), 'training/policy_loss': Array(0.0654731, dtype=float32), 'training/total_loss': Array(0.1194098, dtype=float32), 'training/v_loss': Array(0.04955176, dtype=float32), 'eval/episode_distance_from_origin': Array(3847.5396, dtype=float32), 'eval/episode_distance_reward': Array(6.5117083, dtype=float32), 'eval/episode_forward_reward': Array(1085.2827, dtype=float32), 'eval/episode_reward': Array(1035.9132, dtype=float32), 'eval/episode_reward_alive': Array(263.52734, dtype=float32), 'eval/episode_reward_linvel': Array(1085.2827, dtype=float32), 'eval/episode_reward_quadctrl': Array(-319.40866, dtype=float32), 'eval/episode_x_position': Array(3802.877, dtype=float32), 'eval/episode_x_velocity': Array(217.05655, dtype=float32), 'eval/episode_y_position': Array(-212.36455, dtype=float32), 'eval/episode_y_velocity': Array(-55.310474, dtype=float32), 'eval/episode_distance_from_origin_std': Array(140.57838, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3180298, dtype=float32), 'eval/episode_forward_reward_std': Array(219.67079, dtype=float32), 'eval/episode_reward_std': Array(213.53908, dtype=float32), 'eval/episode_reward_alive_std': Array(43.808815, dtype=float32), 'eval/episode_reward_linvel_std': Array(219.67079, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.308748, dtype=float32), 'eval/episode_x_position_std': Array(140.6319, dtype=float32), 'eval/episode_x_velocity_std': Array(43.934177, dtype=float32), 'eval/episode_y_position_std': Array(179.65607, dtype=float32), 'eval/episode_y_velocity_std': Array(54.102486, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63940334320068, 'eval/sps': 936.7722404239363, 'num_steps': 4177920}
{'eval/walltime': 7270.991782426834, 'training/sps': 2932.527663415772, 'training/walltime': 1471.2283549308777, 'training/entropy_loss': Array(0.00465629, dtype=float32), 'training/policy_loss': Array(0.10066886, dtype=float32), 'training/total_loss': Array(0.15778722, dtype=float32), 'training/v_loss': Array(0.05246207, dtype=float32), 'eval/episode_distance_from_origin': Array(3839.855, dtype=float32), 'eval/episode_distance_reward': Array(7.0429935, dtype=float32), 'eval/episode_forward_reward': Array(1173.8302, dtype=float32), 'eval/episode_reward': Array(1124.7322, dtype=float32), 'eval/episode_reward_alive': Array(265.32812, dtype=float32), 'eval/episode_reward_linvel': Array(1173.8302, dtype=float32), 'eval/episode_reward_quadctrl': Array(-321.4691, dtype=float32), 'eval/episode_x_position': Array(3792.1548, dtype=float32), 'eval/episode_x_velocity': Array(234.76604, dtype=float32), 'eval/episode_y_position': Array(-254.32433, dtype=float32), 'eval/episode_y_velocity': Array(-69.21157, dtype=float32), 'eval/episode_distance_from_origin_std': Array(138.16035, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3917396, dtype=float32), 'eval/episode_forward_reward_std': Array(231.95569, dtype=float32), 'eval/episode_reward_std': Array(233.66258, dtype=float32), 'eval/episode_reward_alive_std': Array(35.76663, dtype=float32), 'eval/episode_reward_linvel_std': Array(231.95569, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.129528, dtype=float32), 'eval/episode_x_position_std': Array(137.92819, dtype=float32), 'eval/episode_x_velocity_std': Array(46.39112, dtype=float32), 'eval/episode_y_position_std': Array(179.44818, dtype=float32), 'eval/episode_y_velocity_std': Array(50.61515, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84865951538086, 'eval/sps': 935.3398159198897, 'num_steps': 4259840}
{'eval/walltime': 7407.431080579758, 'training/sps': 2939.02291627334, 'training/walltime': 1499.1015639305115, 'training/entropy_loss': Array(0.00556212, dtype=float32), 'training/policy_loss': Array(0.04394411, dtype=float32), 'training/total_loss': Array(0.11750882, dtype=float32), 'training/v_loss': Array(0.06800259, dtype=float32), 'eval/episode_distance_from_origin': Array(3878.9602, dtype=float32), 'eval/episode_distance_reward': Array(7.603894, dtype=float32), 'eval/episode_forward_reward': Array(1267.3132, dtype=float32), 'eval/episode_reward': Array(1203.102, dtype=float32), 'eval/episode_reward_alive': Array(259.125, dtype=float32), 'eval/episode_reward_linvel': Array(1267.3132, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.94, dtype=float32), 'eval/episode_x_position': Array(3830.8623, dtype=float32), 'eval/episode_x_velocity': Array(253.46265, dtype=float32), 'eval/episode_y_position': Array(-249.55234, dtype=float32), 'eval/episode_y_velocity': Array(-70.99602, dtype=float32), 'eval/episode_distance_from_origin_std': Array(138.60371, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3650612, dtype=float32), 'eval/episode_forward_reward_std': Array(227.50885, dtype=float32), 'eval/episode_reward_std': Array(231.68318, dtype=float32), 'eval/episode_reward_alive_std': Array(34.894985, dtype=float32), 'eval/episode_reward_linvel_std': Array(227.50885, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.108412, dtype=float32), 'eval/episode_x_position_std': Array(141.5543, dtype=float32), 'eval/episode_x_velocity_std': Array(45.50174, dtype=float32), 'eval/episode_y_position_std': Array(191.56161, dtype=float32), 'eval/episode_y_velocity_std': Array(61.91416, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43929815292358, 'eval/sps': 938.1461333562074, 'num_steps': 4341760}
{'eval/walltime': 7544.398213863373, 'training/sps': 2931.368452469755, 'training/walltime': 1527.0475561618805, 'training/entropy_loss': Array(0.00568468, dtype=float32), 'training/policy_loss': Array(0.05254272, dtype=float32), 'training/total_loss': Array(0.10599116, dtype=float32), 'training/v_loss': Array(0.04776376, dtype=float32), 'eval/episode_distance_from_origin': Array(3928.0098, dtype=float32), 'eval/episode_distance_reward': Array(8.205345, dtype=float32), 'eval/episode_forward_reward': Array(1367.5543, dtype=float32), 'eval/episode_reward': Array(1305.5714, dtype=float32), 'eval/episode_reward_alive': Array(265.0664, dtype=float32), 'eval/episode_reward_linvel': Array(1367.5543, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.2545, dtype=float32), 'eval/episode_x_position': Array(3878.902, dtype=float32), 'eval/episode_x_velocity': Array(273.51083, dtype=float32), 'eval/episode_y_position': Array(-256.59155, dtype=float32), 'eval/episode_y_velocity': Array(-77.06813, dtype=float32), 'eval/episode_distance_from_origin_std': Array(139.96558, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3989664, dtype=float32), 'eval/episode_forward_reward_std': Array(233.15909, dtype=float32), 'eval/episode_reward_std': Array(235.52303, dtype=float32), 'eval/episode_reward_alive_std': Array(34.620228, dtype=float32), 'eval/episode_reward_linvel_std': Array(233.15909, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(15.323815, dtype=float32), 'eval/episode_x_position_std': Array(141.37683, dtype=float32), 'eval/episode_x_velocity_std': Array(46.631832, dtype=float32), 'eval/episode_y_position_std': Array(205.23923, dtype=float32), 'eval/episode_y_velocity_std': Array(67.40897, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.9671332836151, 'eval/sps': 934.5307661141812, 'num_steps': 4423680}
{'eval/walltime': 7681.013286113739, 'training/sps': 2945.672913538312, 'training/walltime': 1554.8578400611877, 'training/entropy_loss': Array(0.00786593, dtype=float32), 'training/policy_loss': Array(0.12751561, dtype=float32), 'training/total_loss': Array(0.19194806, dtype=float32), 'training/v_loss': Array(0.05656651, dtype=float32), 'eval/episode_distance_from_origin': Array(3796.4473, dtype=float32), 'eval/episode_distance_reward': Array(6.8649445, dtype=float32), 'eval/episode_forward_reward': Array(1144.1547, dtype=float32), 'eval/episode_reward': Array(1064.4484, dtype=float32), 'eval/episode_reward_alive': Array(297.21094, dtype=float32), 'eval/episode_reward_linvel': Array(1144.1547, dtype=float32), 'eval/episode_reward_quadctrl': Array(-383.78232, dtype=float32), 'eval/episode_x_position': Array(3758.639, dtype=float32), 'eval/episode_x_velocity': Array(228.83095, dtype=float32), 'eval/episode_y_position': Array(14.850348, dtype=float32), 'eval/episode_y_velocity': Array(-14.137739, dtype=float32), 'eval/episode_distance_from_origin_std': Array(240.10748, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0082211, dtype=float32), 'eval/episode_forward_reward_std': Array(501.36783, dtype=float32), 'eval/episode_reward_std': Array(531.1451, dtype=float32), 'eval/episode_reward_alive_std': Array(95.01621, dtype=float32), 'eval/episode_reward_linvel_std': Array(501.36783, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.30981, dtype=float32), 'eval/episode_x_position_std': Array(241.05254, dtype=float32), 'eval/episode_x_velocity_std': Array(100.2736, dtype=float32), 'eval/episode_y_position_std': Array(193.1536, dtype=float32), 'eval/episode_y_velocity_std': Array(57.71025, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6150722503662, 'eval/sps': 936.9390792065908, 'num_steps': 4505600}
{'eval/walltime': 7817.825605392456, 'training/sps': 2942.0545921052567, 'training/walltime': 1582.7023267745972, 'training/entropy_loss': Array(0.00982865, dtype=float32), 'training/policy_loss': Array(0.04767602, dtype=float32), 'training/total_loss': Array(0.11973715, dtype=float32), 'training/v_loss': Array(0.06223248, dtype=float32), 'eval/episode_distance_from_origin': Array(3804.7944, dtype=float32), 'eval/episode_distance_reward': Array(6.7373514, dtype=float32), 'eval/episode_forward_reward': Array(1122.8896, dtype=float32), 'eval/episode_reward': Array(1054.7256, dtype=float32), 'eval/episode_reward_alive': Array(321.28125, dtype=float32), 'eval/episode_reward_linvel': Array(1122.8896, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.18262, dtype=float32), 'eval/episode_x_position': Array(3768.742, dtype=float32), 'eval/episode_x_velocity': Array(224.57793, dtype=float32), 'eval/episode_y_position': Array(85.79737, dtype=float32), 'eval/episode_y_velocity': Array(11.148594, dtype=float32), 'eval/episode_distance_from_origin_std': Array(234.07451, dtype=float32), 'eval/episode_distance_reward_std': Array(3.01403, dtype=float32), 'eval/episode_forward_reward_std': Array(502.33618, dtype=float32), 'eval/episode_reward_std': Array(524.32904, dtype=float32), 'eval/episode_reward_alive_std': Array(96.34321, dtype=float32), 'eval/episode_reward_linvel_std': Array(502.33618, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.34358, dtype=float32), 'eval/episode_x_position_std': Array(236.24088, dtype=float32), 'eval/episode_x_velocity_std': Array(100.46725, dtype=float32), 'eval/episode_y_position_std': Array(152.43332, dtype=float32), 'eval/episode_y_velocity_std': Array(44.348213, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.81231927871704, 'eval/sps': 935.5882618964715, 'num_steps': 4587520}
{'eval/walltime': 7954.526916027069, 'training/sps': 2931.541872996329, 'training/walltime': 1610.6466658115387, 'training/entropy_loss': Array(0.00888965, dtype=float32), 'training/policy_loss': Array(0.07171758, dtype=float32), 'training/total_loss': Array(0.13960263, dtype=float32), 'training/v_loss': Array(0.05899541, dtype=float32), 'eval/episode_distance_from_origin': Array(3918.7183, dtype=float32), 'eval/episode_distance_reward': Array(8.00164, dtype=float32), 'eval/episode_forward_reward': Array(1333.603, dtype=float32), 'eval/episode_reward': Array(1275.3557, dtype=float32), 'eval/episode_reward_alive': Array(319.55078, dtype=float32), 'eval/episode_reward_linvel': Array(1333.603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-385.7999, dtype=float32), 'eval/episode_x_position': Array(3881.4568, dtype=float32), 'eval/episode_x_velocity': Array(266.72064, dtype=float32), 'eval/episode_y_position': Array(31.462385, dtype=float32), 'eval/episode_y_velocity': Array(-5.128651, dtype=float32), 'eval/episode_distance_from_origin_std': Array(233.03111, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0086687, dtype=float32), 'eval/episode_forward_reward_std': Array(501.44177, dtype=float32), 'eval/episode_reward_std': Array(519.44116, dtype=float32), 'eval/episode_reward_alive_std': Array(75.2911, dtype=float32), 'eval/episode_reward_linvel_std': Array(501.44177, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.40754, dtype=float32), 'eval/episode_x_position_std': Array(235.95114, dtype=float32), 'eval/episode_x_velocity_std': Array(100.28835, dtype=float32), 'eval/episode_y_position_std': Array(191.35144, dtype=float32), 'eval/episode_y_velocity_std': Array(59.834305, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70131063461304, 'eval/sps': 936.3480087043888, 'num_steps': 4669440}
{'eval/walltime': 8091.099217414856, 'training/sps': 2948.4511029985565, 'training/walltime': 1638.4307453632355, 'training/entropy_loss': Array(0.00855877, dtype=float32), 'training/policy_loss': Array(0.08069869, dtype=float32), 'training/total_loss': Array(0.15548608, dtype=float32), 'training/v_loss': Array(0.06622861, dtype=float32), 'eval/episode_distance_from_origin': Array(3982.457, dtype=float32), 'eval/episode_distance_reward': Array(9.04359, dtype=float32), 'eval/episode_forward_reward': Array(1507.2603, dtype=float32), 'eval/episode_reward': Array(1464.2979, dtype=float32), 'eval/episode_reward_alive': Array(317.5664, dtype=float32), 'eval/episode_reward_linvel': Array(1507.2603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-369.57233, dtype=float32), 'eval/episode_x_position': Array(3946.9119, dtype=float32), 'eval/episode_x_velocity': Array(301.45203, dtype=float32), 'eval/episode_y_position': Array(29.779352, dtype=float32), 'eval/episode_y_velocity': Array(-4.1615114, dtype=float32), 'eval/episode_distance_from_origin_std': Array(224.39737, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8677688, dtype=float32), 'eval/episode_forward_reward_std': Array(477.95782, dtype=float32), 'eval/episode_reward_std': Array(480.8014, dtype=float32), 'eval/episode_reward_alive_std': Array(55.379173, dtype=float32), 'eval/episode_reward_linvel_std': Array(477.95782, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.585083, dtype=float32), 'eval/episode_x_position_std': Array(224.481, dtype=float32), 'eval/episode_x_velocity_std': Array(95.591576, dtype=float32), 'eval/episode_y_position_std': Array(170.38905, dtype=float32), 'eval/episode_y_velocity_std': Array(57.113644, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57230138778687, 'eval/sps': 937.2325039508088, 'num_steps': 4751360}
{'eval/walltime': 8227.649457216263, 'training/sps': 2937.7808226278153, 'training/walltime': 1666.3157391548157, 'training/entropy_loss': Array(0.00703643, dtype=float32), 'training/policy_loss': Array(0.1158186, dtype=float32), 'training/total_loss': Array(0.1913926, dtype=float32), 'training/v_loss': Array(0.06853758, dtype=float32), 'eval/episode_distance_from_origin': Array(3979.9033, dtype=float32), 'eval/episode_distance_reward': Array(9.076384, dtype=float32), 'eval/episode_forward_reward': Array(1512.7257, dtype=float32), 'eval/episode_reward': Array(1494.3215, dtype=float32), 'eval/episode_reward_alive': Array(332.7422, dtype=float32), 'eval/episode_reward_linvel': Array(1512.7257, dtype=float32), 'eval/episode_reward_quadctrl': Array(-360.22266, dtype=float32), 'eval/episode_x_position': Array(3943.9526, dtype=float32), 'eval/episode_x_velocity': Array(302.5451, dtype=float32), 'eval/episode_y_position': Array(84.94587, dtype=float32), 'eval/episode_y_velocity': Array(24.149818, dtype=float32), 'eval/episode_distance_from_origin_std': Array(215.32219, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8408728, dtype=float32), 'eval/episode_forward_reward_std': Array(473.47534, dtype=float32), 'eval/episode_reward_std': Array(486.05923, dtype=float32), 'eval/episode_reward_alive_std': Array(54.631397, dtype=float32), 'eval/episode_reward_linvel_std': Array(473.47534, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.416885, dtype=float32), 'eval/episode_x_position_std': Array(215.76697, dtype=float32), 'eval/episode_x_velocity_std': Array(94.69507, dtype=float32), 'eval/episode_y_position_std': Array(154.00581, dtype=float32), 'eval/episode_y_velocity_std': Array(55.035137, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55023980140686, 'eval/sps': 937.3839268693927, 'num_steps': 4833280}
{'eval/walltime': 8364.526623249054, 'training/sps': 2948.236363590809, 'training/walltime': 1694.1018424034119, 'training/entropy_loss': Array(0.00725551, dtype=float32), 'training/policy_loss': Array(0.04485366, dtype=float32), 'training/total_loss': Array(0.10506541, dtype=float32), 'training/v_loss': Array(0.05295623, dtype=float32), 'eval/episode_distance_from_origin': Array(4011.159, dtype=float32), 'eval/episode_distance_reward': Array(9.535479, dtype=float32), 'eval/episode_forward_reward': Array(1589.2411, dtype=float32), 'eval/episode_reward': Array(1576.2301, dtype=float32), 'eval/episode_reward_alive': Array(333.82422, dtype=float32), 'eval/episode_reward_linvel': Array(1589.2411, dtype=float32), 'eval/episode_reward_quadctrl': Array(-356.37076, dtype=float32), 'eval/episode_x_position': Array(3973.901, dtype=float32), 'eval/episode_x_velocity': Array(317.8482, dtype=float32), 'eval/episode_y_position': Array(83.48658, dtype=float32), 'eval/episode_y_velocity': Array(23.081753, dtype=float32), 'eval/episode_distance_from_origin_std': Array(209.8998, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7809622, dtype=float32), 'eval/episode_forward_reward_std': Array(463.49048, dtype=float32), 'eval/episode_reward_std': Array(461.4028, dtype=float32), 'eval/episode_reward_alive_std': Array(48.58673, dtype=float32), 'eval/episode_reward_linvel_std': Array(463.49048, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.691769, dtype=float32), 'eval/episode_x_position_std': Array(210.61607, dtype=float32), 'eval/episode_x_velocity_std': Array(92.69808, dtype=float32), 'eval/episode_y_position_std': Array(176.48737, dtype=float32), 'eval/episode_y_velocity_std': Array(60.23929, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.87716603279114, 'eval/sps': 935.1450187778985, 'num_steps': 4915200}
{'eval/walltime': 8500.909317493439, 'training/sps': 2948.9716368391705, 'training/walltime': 1721.8810176849365, 'training/entropy_loss': Array(0.00722284, dtype=float32), 'training/policy_loss': Array(0.018195, dtype=float32), 'training/total_loss': Array(0.08014381, dtype=float32), 'training/v_loss': Array(0.05472597, dtype=float32), 'eval/episode_distance_from_origin': Array(4033.3706, dtype=float32), 'eval/episode_distance_reward': Array(9.857681, dtype=float32), 'eval/episode_forward_reward': Array(1642.941, dtype=float32), 'eval/episode_reward': Array(1629.9348, dtype=float32), 'eval/episode_reward_alive': Array(335.33984, dtype=float32), 'eval/episode_reward_linvel': Array(1642.941, dtype=float32), 'eval/episode_reward_quadctrl': Array(-358.2038, dtype=float32), 'eval/episode_x_position': Array(3996.7983, dtype=float32), 'eval/episode_x_velocity': Array(328.5882, dtype=float32), 'eval/episode_y_position': Array(76.136024, dtype=float32), 'eval/episode_y_velocity': Array(16.342987, dtype=float32), 'eval/episode_distance_from_origin_std': Array(214.78326, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7983785, dtype=float32), 'eval/episode_forward_reward_std': Array(466.39285, dtype=float32), 'eval/episode_reward_std': Array(474.88855, dtype=float32), 'eval/episode_reward_alive_std': Array(46.059444, dtype=float32), 'eval/episode_reward_linvel_std': Array(466.39285, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.663122, dtype=float32), 'eval/episode_x_position_std': Array(215.70378, dtype=float32), 'eval/episode_x_velocity_std': Array(93.2786, dtype=float32), 'eval/episode_y_position_std': Array(172.01938, dtype=float32), 'eval/episode_y_velocity_std': Array(58.830917, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38269424438477, 'eval/sps': 938.535499017465, 'num_steps': 4997120}
{'eval/walltime': 8637.84597992897, 'training/sps': 2948.9580201472013, 'training/walltime': 1749.6603212356567, 'training/entropy_loss': Array(0.00758267, dtype=float32), 'training/policy_loss': Array(0.01009228, dtype=float32), 'training/total_loss': Array(0.06521691, dtype=float32), 'training/v_loss': Array(0.04754196, dtype=float32), 'eval/episode_distance_from_origin': Array(4072.8518, dtype=float32), 'eval/episode_distance_reward': Array(10.308632, dtype=float32), 'eval/episode_forward_reward': Array(1718.0988, dtype=float32), 'eval/episode_reward': Array(1708.5123, dtype=float32), 'eval/episode_reward_alive': Array(343.375, dtype=float32), 'eval/episode_reward_linvel': Array(1718.0988, dtype=float32), 'eval/episode_reward_quadctrl': Array(-363.27008, dtype=float32), 'eval/episode_x_position': Array(4038.3547, dtype=float32), 'eval/episode_x_velocity': Array(343.61975, dtype=float32), 'eval/episode_y_position': Array(19.078285, dtype=float32), 'eval/episode_y_velocity': Array(-3.3565502, dtype=float32), 'eval/episode_distance_from_origin_std': Array(250.48398, dtype=float32), 'eval/episode_distance_reward_std': Array(3.1964383, dtype=float32), 'eval/episode_forward_reward_std': Array(532.7361, dtype=float32), 'eval/episode_reward_std': Array(538.8991, dtype=float32), 'eval/episode_reward_alive_std': Array(47.3392, dtype=float32), 'eval/episode_reward_linvel_std': Array(532.7361, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.250183, dtype=float32), 'eval/episode_x_position_std': Array(250.24928, dtype=float32), 'eval/episode_x_velocity_std': Array(106.54722, dtype=float32), 'eval/episode_y_position_std': Array(148.41684, dtype=float32), 'eval/episode_y_velocity_std': Array(56.10292, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.93666243553162, 'eval/sps': 934.7387158662575, 'num_steps': 5079040}
{'eval/walltime': 8774.375918149948, 'training/sps': 2946.643770601418, 'training/walltime': 1777.461442232132, 'training/entropy_loss': Array(0.00752158, dtype=float32), 'training/policy_loss': Array(0.02473904, dtype=float32), 'training/total_loss': Array(0.08971976, dtype=float32), 'training/v_loss': Array(0.05745914, dtype=float32), 'eval/episode_distance_from_origin': Array(4143.845, dtype=float32), 'eval/episode_distance_reward': Array(10.635868, dtype=float32), 'eval/episode_forward_reward': Array(1772.6375, dtype=float32), 'eval/episode_reward': Array(1765.066, dtype=float32), 'eval/episode_reward_alive': Array(338.22266, dtype=float32), 'eval/episode_reward_linvel': Array(1772.6375, dtype=float32), 'eval/episode_reward_quadctrl': Array(-356.43018, dtype=float32), 'eval/episode_x_position': Array(4107.6914, dtype=float32), 'eval/episode_x_velocity': Array(354.5275, dtype=float32), 'eval/episode_y_position': Array(-25.18233, dtype=float32), 'eval/episode_y_velocity': Array(-12.493687, dtype=float32), 'eval/episode_distance_from_origin_std': Array(232.23695, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9556143, dtype=float32), 'eval/episode_forward_reward_std': Array(492.5986, dtype=float32), 'eval/episode_reward_std': Array(491.79492, dtype=float32), 'eval/episode_reward_alive_std': Array(49.393303, dtype=float32), 'eval/episode_reward_linvel_std': Array(492.5986, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.699444, dtype=float32), 'eval/episode_x_position_std': Array(231.80116, dtype=float32), 'eval/episode_x_velocity_std': Array(98.519684, dtype=float32), 'eval/episode_y_position_std': Array(185.77115, dtype=float32), 'eval/episode_y_velocity_std': Array(70.45101, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52993822097778, 'eval/sps': 937.5233129661875, 'num_steps': 5160960}
{'eval/walltime': 8911.133795022964, 'training/sps': 2946.765071645315, 'training/walltime': 1805.2614188194275, 'training/entropy_loss': Array(0.00436446, dtype=float32), 'training/policy_loss': Array(-0.00285171, dtype=float32), 'training/total_loss': Array(0.05517142, dtype=float32), 'training/v_loss': Array(0.05365867, dtype=float32), 'eval/episode_distance_from_origin': Array(4156.038, dtype=float32), 'eval/episode_distance_reward': Array(10.635008, dtype=float32), 'eval/episode_forward_reward': Array(1772.4937, dtype=float32), 'eval/episode_reward': Array(1757.5056, dtype=float32), 'eval/episode_reward_alive': Array(337.66016, dtype=float32), 'eval/episode_reward_linvel': Array(1772.4937, dtype=float32), 'eval/episode_reward_quadctrl': Array(-363.28323, dtype=float32), 'eval/episode_x_position': Array(4120.56, dtype=float32), 'eval/episode_x_velocity': Array(354.49872, dtype=float32), 'eval/episode_y_position': Array(-14.04684, dtype=float32), 'eval/episode_y_velocity': Array(-18.859581, dtype=float32), 'eval/episode_distance_from_origin_std': Array(258.11975, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3676763, dtype=float32), 'eval/episode_forward_reward_std': Array(561.2749, dtype=float32), 'eval/episode_reward_std': Array(569.5526, dtype=float32), 'eval/episode_reward_alive_std': Array(53.646297, dtype=float32), 'eval/episode_reward_linvel_std': Array(561.2749, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.525936, dtype=float32), 'eval/episode_x_position_std': Array(258.60733, dtype=float32), 'eval/episode_x_velocity_std': Array(112.25498, dtype=float32), 'eval/episode_y_position_std': Array(188.33603, dtype=float32), 'eval/episode_y_velocity_std': Array(58.130123, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.75787687301636, 'eval/sps': 935.9607133916805, 'num_steps': 5242880}
{'eval/walltime': 9047.523788928986, 'training/sps': 2950.539231723711, 'training/walltime': 1833.02583527565, 'training/entropy_loss': Array(0.00719724, dtype=float32), 'training/policy_loss': Array(0.01898364, dtype=float32), 'training/total_loss': Array(0.10678566, dtype=float32), 'training/v_loss': Array(0.08060478, dtype=float32), 'eval/episode_distance_from_origin': Array(4166.7285, dtype=float32), 'eval/episode_distance_reward': Array(10.604553, dtype=float32), 'eval/episode_forward_reward': Array(1767.4181, dtype=float32), 'eval/episode_reward': Array(1737.3662, dtype=float32), 'eval/episode_reward_alive': Array(328.1211, dtype=float32), 'eval/episode_reward_linvel': Array(1767.4181, dtype=float32), 'eval/episode_reward_quadctrl': Array(-368.77777, dtype=float32), 'eval/episode_x_position': Array(4129.4966, dtype=float32), 'eval/episode_x_velocity': Array(353.4837, dtype=float32), 'eval/episode_y_position': Array(-67.34182, dtype=float32), 'eval/episode_y_velocity': Array(-26.073992, dtype=float32), 'eval/episode_distance_from_origin_std': Array(277.44907, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3488295, dtype=float32), 'eval/episode_forward_reward_std': Array(558.1337, dtype=float32), 'eval/episode_reward_std': Array(577.60297, dtype=float32), 'eval/episode_reward_alive_std': Array(62.473766, dtype=float32), 'eval/episode_reward_linvel_std': Array(558.1337, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.808372, dtype=float32), 'eval/episode_x_position_std': Array(278.59137, dtype=float32), 'eval/episode_x_velocity_std': Array(111.62679, dtype=float32), 'eval/episode_y_position_std': Array(204.68198, dtype=float32), 'eval/episode_y_velocity_std': Array(66.98277, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38999390602112, 'eval/sps': 938.4852681216321, 'num_steps': 5324800}
{'eval/walltime': 9184.246881246567, 'training/sps': 2953.5835031305774, 'training/walltime': 1860.7616348266602, 'training/entropy_loss': Array(0.00618753, dtype=float32), 'training/policy_loss': Array(0.01807107, dtype=float32), 'training/total_loss': Array(0.09132427, dtype=float32), 'training/v_loss': Array(0.06706566, dtype=float32), 'eval/episode_distance_from_origin': Array(4199.1006, dtype=float32), 'eval/episode_distance_reward': Array(10.7222595, dtype=float32), 'eval/episode_forward_reward': Array(1787.0359, dtype=float32), 'eval/episode_reward': Array(1769.2776, dtype=float32), 'eval/episode_reward_alive': Array(334.26172, dtype=float32), 'eval/episode_reward_linvel': Array(1787.0359, dtype=float32), 'eval/episode_reward_quadctrl': Array(-362.7422, dtype=float32), 'eval/episode_x_position': Array(4161.7993, dtype=float32), 'eval/episode_x_velocity': Array(357.4071, dtype=float32), 'eval/episode_y_position': Array(-79.77241, dtype=float32), 'eval/episode_y_velocity': Array(-29.35332, dtype=float32), 'eval/episode_distance_from_origin_std': Array(249.39699, dtype=float32), 'eval/episode_distance_reward_std': Array(3.151167, dtype=float32), 'eval/episode_forward_reward_std': Array(525.1903, dtype=float32), 'eval/episode_reward_std': Array(531.96014, dtype=float32), 'eval/episode_reward_alive_std': Array(61.47017, dtype=float32), 'eval/episode_reward_linvel_std': Array(525.1903, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.775417, dtype=float32), 'eval/episode_x_position_std': Array(248.37656, dtype=float32), 'eval/episode_x_velocity_std': Array(105.03804, dtype=float32), 'eval/episode_y_position_std': Array(202.75067, dtype=float32), 'eval/episode_y_velocity_std': Array(66.008415, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.72309231758118, 'eval/sps': 936.1988368627655, 'num_steps': 5406720}
{'eval/walltime': 9320.822926044464, 'training/sps': 2941.605423176834, 'training/walltime': 1888.6103732585907, 'training/entropy_loss': Array(0.00729029, dtype=float32), 'training/policy_loss': Array(0.01403041, dtype=float32), 'training/total_loss': Array(0.08710821, dtype=float32), 'training/v_loss': Array(0.06578751, dtype=float32), 'eval/episode_distance_from_origin': Array(4208.506, dtype=float32), 'eval/episode_distance_reward': Array(10.887438, dtype=float32), 'eval/episode_forward_reward': Array(1814.5652, dtype=float32), 'eval/episode_reward': Array(1791.0382, dtype=float32), 'eval/episode_reward_alive': Array(329.8203, dtype=float32), 'eval/episode_reward_linvel': Array(1814.5652, dtype=float32), 'eval/episode_reward_quadctrl': Array(-364.23477, dtype=float32), 'eval/episode_x_position': Array(4169.6226, dtype=float32), 'eval/episode_x_velocity': Array(362.91302, dtype=float32), 'eval/episode_y_position': Array(-121.858, dtype=float32), 'eval/episode_y_velocity': Array(-49.48792, dtype=float32), 'eval/episode_distance_from_origin_std': Array(267.55106, dtype=float32), 'eval/episode_distance_reward_std': Array(3.4420724, dtype=float32), 'eval/episode_forward_reward_std': Array(573.6744, dtype=float32), 'eval/episode_reward_std': Array(582.2517, dtype=float32), 'eval/episode_reward_alive_std': Array(59.00218, dtype=float32), 'eval/episode_reward_linvel_std': Array(573.6744, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.1783, dtype=float32), 'eval/episode_x_position_std': Array(267.693, dtype=float32), 'eval/episode_x_velocity_std': Array(114.73486, dtype=float32), 'eval/episode_y_position_std': Array(201.86932, dtype=float32), 'eval/episode_y_velocity_std': Array(70.24413, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57604479789734, 'eval/sps': 937.2068153636459, 'num_steps': 5488640}
{'eval/walltime': 9457.667205810547, 'training/sps': 2942.278182412138, 'training/walltime': 1916.4527440071106, 'training/entropy_loss': Array(0.00695925, dtype=float32), 'training/policy_loss': Array(0.00460094, dtype=float32), 'training/total_loss': Array(0.08096414, dtype=float32), 'training/v_loss': Array(0.06940396, dtype=float32), 'eval/episode_distance_from_origin': Array(4231.6543, dtype=float32), 'eval/episode_distance_reward': Array(11.069257, dtype=float32), 'eval/episode_forward_reward': Array(1844.8679, dtype=float32), 'eval/episode_reward': Array(1825.7886, dtype=float32), 'eval/episode_reward_alive': Array(333.91016, dtype=float32), 'eval/episode_reward_linvel': Array(1844.8679, dtype=float32), 'eval/episode_reward_quadctrl': Array(-364.05878, dtype=float32), 'eval/episode_x_position': Array(4192.079, dtype=float32), 'eval/episode_x_velocity': Array(368.97363, dtype=float32), 'eval/episode_y_position': Array(-115.48704, dtype=float32), 'eval/episode_y_velocity': Array(-52.267517, dtype=float32), 'eval/episode_distance_from_origin_std': Array(312.19763, dtype=float32), 'eval/episode_distance_reward_std': Array(3.9196086, dtype=float32), 'eval/episode_forward_reward_std': Array(653.26294, dtype=float32), 'eval/episode_reward_std': Array(664.49365, dtype=float32), 'eval/episode_reward_alive_std': Array(61.88391, dtype=float32), 'eval/episode_reward_linvel_std': Array(653.26294, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.06051, dtype=float32), 'eval/episode_x_position_std': Array(311.65564, dtype=float32), 'eval/episode_x_velocity_std': Array(130.65262, dtype=float32), 'eval/episode_y_position_std': Array(227.28464, dtype=float32), 'eval/episode_y_velocity_std': Array(71.52883, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84427976608276, 'eval/sps': 935.3697517996303, 'num_steps': 5570560}
{'eval/walltime': 9594.293818712234, 'training/sps': 2939.5098730341933, 'training/walltime': 1944.321335554123, 'training/entropy_loss': Array(0.00866151, dtype=float32), 'training/policy_loss': Array(0.1147953, dtype=float32), 'training/total_loss': Array(0.18024963, dtype=float32), 'training/v_loss': Array(0.05679283, dtype=float32), 'eval/episode_distance_from_origin': Array(4294.0117, dtype=float32), 'eval/episode_distance_reward': Array(10.982784, dtype=float32), 'eval/episode_forward_reward': Array(1830.4564, dtype=float32), 'eval/episode_reward': Array(1781.5767, dtype=float32), 'eval/episode_reward_alive': Array(355.91797, dtype=float32), 'eval/episode_reward_linvel': Array(1830.4564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.78052, dtype=float32), 'eval/episode_x_position': Array(4251.1934, dtype=float32), 'eval/episode_x_velocity': Array(366.0913, dtype=float32), 'eval/episode_y_position': Array(-214.10873, dtype=float32), 'eval/episode_y_velocity': Array(-76.31763, dtype=float32), 'eval/episode_distance_from_origin_std': Array(305.03006, dtype=float32), 'eval/episode_distance_reward_std': Array(3.9408097, dtype=float32), 'eval/episode_forward_reward_std': Array(656.7964, dtype=float32), 'eval/episode_reward_std': Array(683.2087, dtype=float32), 'eval/episode_reward_alive_std': Array(57.505222, dtype=float32), 'eval/episode_reward_linvel_std': Array(656.7964, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.72265, dtype=float32), 'eval/episode_x_position_std': Array(301.601, dtype=float32), 'eval/episode_x_velocity_std': Array(131.35927, dtype=float32), 'eval/episode_y_position_std': Array(217.29976, dtype=float32), 'eval/episode_y_velocity_std': Array(71.75013, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62661290168762, 'eval/sps': 936.8599373249846, 'num_steps': 5652480}
{'eval/walltime': 9730.95030450821, 'training/sps': 2943.3753379435657, 'training/walltime': 1972.1533279418945, 'training/entropy_loss': Array(0.00561005, dtype=float32), 'training/policy_loss': Array(0.00425906, dtype=float32), 'training/total_loss': Array(0.07907711, dtype=float32), 'training/v_loss': Array(0.06920798, dtype=float32), 'eval/episode_distance_from_origin': Array(4225.286, dtype=float32), 'eval/episode_distance_reward': Array(10.464233, dtype=float32), 'eval/episode_forward_reward': Array(1744.0317, dtype=float32), 'eval/episode_reward': Array(1697.3256, dtype=float32), 'eval/episode_reward_alive': Array(356.4297, dtype=float32), 'eval/episode_reward_linvel': Array(1744.0317, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.6001, dtype=float32), 'eval/episode_x_position': Array(4184.4287, dtype=float32), 'eval/episode_x_velocity': Array(348.80634, dtype=float32), 'eval/episode_y_position': Array(-170.2473, dtype=float32), 'eval/episode_y_velocity': Array(-62.124504, dtype=float32), 'eval/episode_distance_from_origin_std': Array(342.2139, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2302494, dtype=float32), 'eval/episode_forward_reward_std': Array(705.03577, dtype=float32), 'eval/episode_reward_std': Array(723.5404, dtype=float32), 'eval/episode_reward_alive_std': Array(60.49389, dtype=float32), 'eval/episode_reward_linvel_std': Array(705.03577, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.10203, dtype=float32), 'eval/episode_x_position_std': Array(341.8739, dtype=float32), 'eval/episode_x_velocity_std': Array(141.00719, dtype=float32), 'eval/episode_y_position_std': Array(213.87177, dtype=float32), 'eval/episode_y_velocity_std': Array(72.63952, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65648579597473, 'eval/sps': 936.6551412064065, 'num_steps': 5734400}
{'eval/walltime': 9867.469226360321, 'training/sps': 2948.18551682712, 'training/walltime': 1999.9399104118347, 'training/entropy_loss': Array(0.00968939, dtype=float32), 'training/policy_loss': Array(0.02744422, dtype=float32), 'training/total_loss': Array(0.1092681, dtype=float32), 'training/v_loss': Array(0.07213449, dtype=float32), 'eval/episode_distance_from_origin': Array(4245.162, dtype=float32), 'eval/episode_distance_reward': Array(10.097038, dtype=float32), 'eval/episode_forward_reward': Array(1682.833, dtype=float32), 'eval/episode_reward': Array(1630.0718, dtype=float32), 'eval/episode_reward_alive': Array(361.3086, dtype=float32), 'eval/episode_reward_linvel': Array(1682.833, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.16705, dtype=float32), 'eval/episode_x_position': Array(4201.009, dtype=float32), 'eval/episode_x_velocity': Array(336.56665, dtype=float32), 'eval/episode_y_position': Array(-204.64932, dtype=float32), 'eval/episode_y_velocity': Array(-69.948456, dtype=float32), 'eval/episode_distance_from_origin_std': Array(346.41882, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2141604, dtype=float32), 'eval/episode_forward_reward_std': Array(702.35474, dtype=float32), 'eval/episode_reward_std': Array(714.5758, dtype=float32), 'eval/episode_reward_alive_std': Array(54.951828, dtype=float32), 'eval/episode_reward_linvel_std': Array(702.35474, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.79817, dtype=float32), 'eval/episode_x_position_std': Array(342.74716, dtype=float32), 'eval/episode_x_velocity_std': Array(140.47101, dtype=float32), 'eval/episode_y_position_std': Array(241.25932, dtype=float32), 'eval/episode_y_velocity_std': Array(71.60878, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51892185211182, 'eval/sps': 937.598966234584, 'num_steps': 5816320}
{'eval/walltime': 10004.341495752335, 'training/sps': 2935.0861518838865, 'training/walltime': 2027.8505051136017, 'training/entropy_loss': Array(0.01227944, dtype=float32), 'training/policy_loss': Array(0.05247205, dtype=float32), 'training/total_loss': Array(0.14010039, dtype=float32), 'training/v_loss': Array(0.0753489, dtype=float32), 'eval/episode_distance_from_origin': Array(4327.7256, dtype=float32), 'eval/episode_distance_reward': Array(11.087873, dtype=float32), 'eval/episode_forward_reward': Array(1847.9712, dtype=float32), 'eval/episode_reward': Array(1786.7261, dtype=float32), 'eval/episode_reward_alive': Array(357.79688, dtype=float32), 'eval/episode_reward_linvel': Array(1847.9712, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.12982, dtype=float32), 'eval/episode_x_position': Array(4288.0586, dtype=float32), 'eval/episode_x_velocity': Array(369.59424, dtype=float32), 'eval/episode_y_position': Array(-163.52583, dtype=float32), 'eval/episode_y_velocity': Array(-60.660942, dtype=float32), 'eval/episode_distance_from_origin_std': Array(315.5362, dtype=float32), 'eval/episode_distance_reward_std': Array(3.8412404, dtype=float32), 'eval/episode_forward_reward_std': Array(640.20154, dtype=float32), 'eval/episode_reward_std': Array(659.51294, dtype=float32), 'eval/episode_reward_alive_std': Array(55.265636, dtype=float32), 'eval/episode_reward_linvel_std': Array(640.20154, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.50323, dtype=float32), 'eval/episode_x_position_std': Array(315.3241, dtype=float32), 'eval/episode_x_velocity_std': Array(128.04031, dtype=float32), 'eval/episode_y_position_std': Array(210.00049, dtype=float32), 'eval/episode_y_velocity_std': Array(66.489586, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.87226939201355, 'eval/sps': 935.1784738323975, 'num_steps': 5898240}
{'eval/walltime': 10141.05853152275, 'training/sps': 2935.7040601173203, 'training/walltime': 2055.7552251815796, 'training/entropy_loss': Array(0.01382226, dtype=float32), 'training/policy_loss': Array(0.08795719, dtype=float32), 'training/total_loss': Array(0.15373495, dtype=float32), 'training/v_loss': Array(0.05195551, dtype=float32), 'eval/episode_distance_from_origin': Array(4340.7324, dtype=float32), 'eval/episode_distance_reward': Array(11.013746, dtype=float32), 'eval/episode_forward_reward': Array(1835.617, dtype=float32), 'eval/episode_reward': Array(1781.0558, dtype=float32), 'eval/episode_reward_alive': Array(372.76562, dtype=float32), 'eval/episode_reward_linvel': Array(1835.617, dtype=float32), 'eval/episode_reward_quadctrl': Array(-438.34058, dtype=float32), 'eval/episode_x_position': Array(4303.518, dtype=float32), 'eval/episode_x_velocity': Array(367.1234, dtype=float32), 'eval/episode_y_position': Array(-116.943375, dtype=float32), 'eval/episode_y_velocity': Array(-41.561584, dtype=float32), 'eval/episode_distance_from_origin_std': Array(307.27374, dtype=float32), 'eval/episode_distance_reward_std': Array(4.055142, dtype=float32), 'eval/episode_forward_reward_std': Array(675.8515, dtype=float32), 'eval/episode_reward_std': Array(699.8317, dtype=float32), 'eval/episode_reward_alive_std': Array(51.587376, dtype=float32), 'eval/episode_reward_linvel_std': Array(675.8515, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.047424, dtype=float32), 'eval/episode_x_position_std': Array(306.75275, dtype=float32), 'eval/episode_x_velocity_std': Array(135.1703, dtype=float32), 'eval/episode_y_position_std': Array(216.23131, dtype=float32), 'eval/episode_y_velocity_std': Array(61.477566, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.71703577041626, 'eval/sps': 936.2403103512685, 'num_steps': 5980160}
{'eval/walltime': 10278.05883693695, 'training/sps': 2923.210376774825, 'training/walltime': 2083.7792088985443, 'training/entropy_loss': Array(0.01706438, dtype=float32), 'training/policy_loss': Array(0.03712362, dtype=float32), 'training/total_loss': Array(0.09965715, dtype=float32), 'training/v_loss': Array(0.04546915, dtype=float32), 'eval/episode_distance_from_origin': Array(4301.3916, dtype=float32), 'eval/episode_distance_reward': Array(10.66291, dtype=float32), 'eval/episode_forward_reward': Array(1777.1449, dtype=float32), 'eval/episode_reward': Array(1722.1809, dtype=float32), 'eval/episode_reward_alive': Array(365.03516, dtype=float32), 'eval/episode_reward_linvel': Array(1777.1449, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.6621, dtype=float32), 'eval/episode_x_position': Array(4263.589, dtype=float32), 'eval/episode_x_velocity': Array(355.42896, dtype=float32), 'eval/episode_y_position': Array(-103.76643, dtype=float32), 'eval/episode_y_velocity': Array(-38.69317, dtype=float32), 'eval/episode_distance_from_origin_std': Array(339.29758, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2517953, dtype=float32), 'eval/episode_forward_reward_std': Array(708.6267, dtype=float32), 'eval/episode_reward_std': Array(733.6695, dtype=float32), 'eval/episode_reward_alive_std': Array(61.30002, dtype=float32), 'eval/episode_reward_linvel_std': Array(708.6267, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.745235, dtype=float32), 'eval/episode_x_position_std': Array(340.20288, dtype=float32), 'eval/episode_x_velocity_std': Array(141.72539, dtype=float32), 'eval/episode_y_position_std': Array(224.93683, dtype=float32), 'eval/episode_y_velocity_std': Array(61.928364, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.00030541419983, 'eval/sps': 934.3044864973931, 'num_steps': 6062080}
{'eval/walltime': 10414.779838085175, 'training/sps': 2935.273327540538, 'training/walltime': 2111.6880238056183, 'training/entropy_loss': Array(0.01872931, dtype=float32), 'training/policy_loss': Array(0.06397203, dtype=float32), 'training/total_loss': Array(0.11572525, dtype=float32), 'training/v_loss': Array(0.03302391, dtype=float32), 'eval/episode_distance_from_origin': Array(4229.8525, dtype=float32), 'eval/episode_distance_reward': Array(8.561571, dtype=float32), 'eval/episode_forward_reward': Array(1426.925, dtype=float32), 'eval/episode_reward': Array(1315.9165, dtype=float32), 'eval/episode_reward_alive': Array(382.28906, dtype=float32), 'eval/episode_reward_linvel': Array(1426.925, dtype=float32), 'eval/episode_reward_quadctrl': Array(-501.8593, dtype=float32), 'eval/episode_x_position': Array(4193.595, dtype=float32), 'eval/episode_x_velocity': Array(285.385, dtype=float32), 'eval/episode_y_position': Array(-133.41925, dtype=float32), 'eval/episode_y_velocity': Array(-41.087444, dtype=float32), 'eval/episode_distance_from_origin_std': Array(269.9983, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8262198, dtype=float32), 'eval/episode_forward_reward_std': Array(471.0334, dtype=float32), 'eval/episode_reward_std': Array(481.25433, dtype=float32), 'eval/episode_reward_alive_std': Array(41.36105, dtype=float32), 'eval/episode_reward_linvel_std': Array(471.0334, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.075195, dtype=float32), 'eval/episode_x_position_std': Array(269.58, dtype=float32), 'eval/episode_x_velocity_std': Array(94.206665, dtype=float32), 'eval/episode_y_position_std': Array(187.78815, dtype=float32), 'eval/episode_y_velocity_std': Array(44.75716, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.72100114822388, 'eval/sps': 936.2131561721878, 'num_steps': 6144000}
{'eval/walltime': 10551.62755894661, 'training/sps': 2925.1920425759326, 'training/walltime': 2139.6930227279663, 'training/entropy_loss': Array(0.00622113, dtype=float32), 'training/policy_loss': Array(0.0283429, dtype=float32), 'training/total_loss': Array(0.09936996, dtype=float32), 'training/v_loss': Array(0.06480592, dtype=float32), 'eval/episode_distance_from_origin': Array(4188.8, dtype=float32), 'eval/episode_distance_reward': Array(7.996616, dtype=float32), 'eval/episode_forward_reward': Array(1332.7664, dtype=float32), 'eval/episode_reward': Array(1209.6305, dtype=float32), 'eval/episode_reward_alive': Array(377.3672, dtype=float32), 'eval/episode_reward_linvel': Array(1332.7664, dtype=float32), 'eval/episode_reward_quadctrl': Array(-508.49976, dtype=float32), 'eval/episode_x_position': Array(4149.1, dtype=float32), 'eval/episode_x_velocity': Array(266.55325, dtype=float32), 'eval/episode_y_position': Array(-193.74129, dtype=float32), 'eval/episode_y_velocity': Array(-52.20433, dtype=float32), 'eval/episode_distance_from_origin_std': Array(289.08356, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8924618, dtype=float32), 'eval/episode_forward_reward_std': Array(482.0737, dtype=float32), 'eval/episode_reward_std': Array(494.88943, dtype=float32), 'eval/episode_reward_alive_std': Array(63.12591, dtype=float32), 'eval/episode_reward_linvel_std': Array(482.0737, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(71.037575, dtype=float32), 'eval/episode_x_position_std': Array(286.95648, dtype=float32), 'eval/episode_x_velocity_std': Array(96.41474, dtype=float32), 'eval/episode_y_position_std': Array(203.09167, dtype=float32), 'eval/episode_y_velocity_std': Array(50.638824, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84772086143494, 'eval/sps': 935.3462315211395, 'num_steps': 6225920}
{'eval/walltime': 10688.527825593948, 'training/sps': 2941.717696254154, 'training/walltime': 2167.540698289871, 'training/entropy_loss': Array(0.00773492, dtype=float32), 'training/policy_loss': Array(0.23805133, dtype=float32), 'training/total_loss': Array(0.32388222, dtype=float32), 'training/v_loss': Array(0.078096, dtype=float32), 'eval/episode_distance_from_origin': Array(4308.594, dtype=float32), 'eval/episode_distance_reward': Array(10.309553, dtype=float32), 'eval/episode_forward_reward': Array(1718.2526, dtype=float32), 'eval/episode_reward': Array(1690.823, dtype=float32), 'eval/episode_reward_alive': Array(393.28516, dtype=float32), 'eval/episode_reward_linvel': Array(1718.2526, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.0242, dtype=float32), 'eval/episode_x_position': Array(4261.785, dtype=float32), 'eval/episode_x_velocity': Array(343.65048, dtype=float32), 'eval/episode_y_position': Array(-264.18152, dtype=float32), 'eval/episode_y_velocity': Array(-84.14151, dtype=float32), 'eval/episode_distance_from_origin_std': Array(462.31537, dtype=float32), 'eval/episode_distance_reward_std': Array(5.554276, dtype=float32), 'eval/episode_forward_reward_std': Array(925.70624, dtype=float32), 'eval/episode_reward_std': Array(961.48016, dtype=float32), 'eval/episode_reward_alive_std': Array(52.886806, dtype=float32), 'eval/episode_reward_linvel_std': Array(925.70624, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.008156, dtype=float32), 'eval/episode_x_position_std': Array(453.79303, dtype=float32), 'eval/episode_x_velocity_std': Array(185.1412, dtype=float32), 'eval/episode_y_position_std': Array(228.48473, dtype=float32), 'eval/episode_y_velocity_std': Array(76.04536, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.90026664733887, 'eval/sps': 934.9872219733045, 'num_steps': 6307840}
{'eval/walltime': 10825.57992386818, 'training/sps': 2926.230335546217, 'training/walltime': 2195.5357604026794, 'training/entropy_loss': Array(0.01325938, dtype=float32), 'training/policy_loss': Array(0.07007205, dtype=float32), 'training/total_loss': Array(0.14853601, dtype=float32), 'training/v_loss': Array(0.06520458, dtype=float32), 'eval/episode_distance_from_origin': Array(4350.8774, dtype=float32), 'eval/episode_distance_reward': Array(10.478182, dtype=float32), 'eval/episode_forward_reward': Array(1746.3572, dtype=float32), 'eval/episode_reward': Array(1718.6819, dtype=float32), 'eval/episode_reward_alive': Array(405.625, dtype=float32), 'eval/episode_reward_linvel': Array(1746.3572, dtype=float32), 'eval/episode_reward_quadctrl': Array(-443.7786, dtype=float32), 'eval/episode_x_position': Array(4303.0757, dtype=float32), 'eval/episode_x_velocity': Array(349.27145, dtype=float32), 'eval/episode_y_position': Array(-258.22717, dtype=float32), 'eval/episode_y_velocity': Array(-81.74985, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.31714, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2895327, dtype=float32), 'eval/episode_forward_reward_std': Array(881.5822, dtype=float32), 'eval/episode_reward_std': Array(918.9193, dtype=float32), 'eval/episode_reward_alive_std': Array(37.4789, dtype=float32), 'eval/episode_reward_linvel_std': Array(881.5822, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.45891, dtype=float32), 'eval/episode_x_position_std': Array(432.47055, dtype=float32), 'eval/episode_x_velocity_std': Array(176.31648, dtype=float32), 'eval/episode_y_position_std': Array(253.44246, dtype=float32), 'eval/episode_y_velocity_std': Array(81.99473, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.05209827423096, 'eval/sps': 933.9514068867564, 'num_steps': 6389760}
{'eval/walltime': 10962.15476489067, 'training/sps': 2949.737993537054, 'training/walltime': 2223.307718515396, 'training/entropy_loss': Array(0.01743111, dtype=float32), 'training/policy_loss': Array(0.0428804, dtype=float32), 'training/total_loss': Array(0.08819261, dtype=float32), 'training/v_loss': Array(0.0278811, dtype=float32), 'eval/episode_distance_from_origin': Array(4340.875, dtype=float32), 'eval/episode_distance_reward': Array(10.855611, dtype=float32), 'eval/episode_forward_reward': Array(1809.2611, dtype=float32), 'eval/episode_reward': Array(1792.1099, dtype=float32), 'eval/episode_reward_alive': Array(398.42188, dtype=float32), 'eval/episode_reward_linvel': Array(1809.2611, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.4287, dtype=float32), 'eval/episode_x_position': Array(4294.7617, dtype=float32), 'eval/episode_x_velocity': Array(361.85223, dtype=float32), 'eval/episode_y_position': Array(-258.51645, dtype=float32), 'eval/episode_y_velocity': Array(-92.84758, dtype=float32), 'eval/episode_distance_from_origin_std': Array(475.60947, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7552533, dtype=float32), 'eval/episode_forward_reward_std': Array(959.2019, dtype=float32), 'eval/episode_reward_std': Array(994.2955, dtype=float32), 'eval/episode_reward_alive_std': Array(46.636284, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.2019, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.68809, dtype=float32), 'eval/episode_x_position_std': Array(467.73502, dtype=float32), 'eval/episode_x_velocity_std': Array(191.84042, dtype=float32), 'eval/episode_y_position_std': Array(219.35655, dtype=float32), 'eval/episode_y_velocity_std': Array(82.29993, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57484102249146, 'eval/sps': 937.2150759371608, 'num_steps': 6471680}
{'eval/walltime': 11099.038215875626, 'training/sps': 2930.245542374799, 'training/walltime': 2251.264420032501, 'training/entropy_loss': Array(0.01771703, dtype=float32), 'training/policy_loss': Array(0.02208423, dtype=float32), 'training/total_loss': Array(0.06261705, dtype=float32), 'training/v_loss': Array(0.02281579, dtype=float32), 'eval/episode_distance_from_origin': Array(4412.2607, dtype=float32), 'eval/episode_distance_reward': Array(11.214171, dtype=float32), 'eval/episode_forward_reward': Array(1869.0215, dtype=float32), 'eval/episode_reward': Array(1856.3416, dtype=float32), 'eval/episode_reward_alive': Array(405.1328, dtype=float32), 'eval/episode_reward_linvel': Array(1869.0215, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.02686, dtype=float32), 'eval/episode_x_position': Array(4363.21, dtype=float32), 'eval/episode_x_velocity': Array(373.80423, dtype=float32), 'eval/episode_y_position': Array(-296.5015, dtype=float32), 'eval/episode_y_velocity': Array(-96.93476, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.9501, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2805834, dtype=float32), 'eval/episode_forward_reward_std': Array(880.0906, dtype=float32), 'eval/episode_reward_std': Array(911.6823, dtype=float32), 'eval/episode_reward_alive_std': Array(40.20414, dtype=float32), 'eval/episode_reward_linvel_std': Array(880.0906, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.4033, dtype=float32), 'eval/episode_x_position_std': Array(400.76517, dtype=float32), 'eval/episode_x_velocity_std': Array(176.0181, dtype=float32), 'eval/episode_y_position_std': Array(231.22964, dtype=float32), 'eval/episode_y_velocity_std': Array(77.13678, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.88345098495483, 'eval/sps': 935.1020819461131, 'num_steps': 6553600}
{'eval/walltime': 11235.661992073059, 'training/sps': 2948.638646079177, 'training/walltime': 2279.0467324256897, 'training/entropy_loss': Array(0.01813232, dtype=float32), 'training/policy_loss': Array(0.02287387, dtype=float32), 'training/total_loss': Array(0.06056079, dtype=float32), 'training/v_loss': Array(0.0195546, dtype=float32), 'eval/episode_distance_from_origin': Array(4454.954, dtype=float32), 'eval/episode_distance_reward': Array(11.583271, dtype=float32), 'eval/episode_forward_reward': Array(1930.5375, dtype=float32), 'eval/episode_reward': Array(1919.1938, dtype=float32), 'eval/episode_reward_alive': Array(408.14844, dtype=float32), 'eval/episode_reward_linvel': Array(1930.5375, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.07526, dtype=float32), 'eval/episode_x_position': Array(4409.9053, dtype=float32), 'eval/episode_x_velocity': Array(386.10745, dtype=float32), 'eval/episode_y_position': Array(-244.5173, dtype=float32), 'eval/episode_y_velocity': Array(-80.82485, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.85764, dtype=float32), 'eval/episode_distance_reward_std': Array(5.406908, dtype=float32), 'eval/episode_forward_reward_std': Array(901.1445, dtype=float32), 'eval/episode_reward_std': Array(932.75995, dtype=float32), 'eval/episode_reward_alive_std': Array(46.968212, dtype=float32), 'eval/episode_reward_linvel_std': Array(901.1445, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.18246, dtype=float32), 'eval/episode_x_position_std': Array(437.3601, dtype=float32), 'eval/episode_x_velocity_std': Array(180.22891, dtype=float32), 'eval/episode_y_position_std': Array(235.07312, dtype=float32), 'eval/episode_y_velocity_std': Array(80.86047, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62377619743347, 'eval/sps': 936.8793892435577, 'num_steps': 6635520}
{'eval/walltime': 11372.432165622711, 'training/sps': 2930.729919623949, 'training/walltime': 2306.998813390732, 'training/entropy_loss': Array(0.00694709, dtype=float32), 'training/policy_loss': Array(0.04624092, dtype=float32), 'training/total_loss': Array(0.10983356, dtype=float32), 'training/v_loss': Array(0.05664556, dtype=float32), 'eval/episode_distance_from_origin': Array(4391.027, dtype=float32), 'eval/episode_distance_reward': Array(10.803244, dtype=float32), 'eval/episode_forward_reward': Array(1800.5337, dtype=float32), 'eval/episode_reward': Array(1783.7456, dtype=float32), 'eval/episode_reward_alive': Array(399.30078, dtype=float32), 'eval/episode_reward_linvel': Array(1800.5337, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.89203, dtype=float32), 'eval/episode_x_position': Array(4346.995, dtype=float32), 'eval/episode_x_velocity': Array(360.1067, dtype=float32), 'eval/episode_y_position': Array(-223.9333, dtype=float32), 'eval/episode_y_velocity': Array(-77.96504, dtype=float32), 'eval/episode_distance_from_origin_std': Array(443.6083, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1104927, dtype=float32), 'eval/episode_forward_reward_std': Array(851.74255, dtype=float32), 'eval/episode_reward_std': Array(889.21985, dtype=float32), 'eval/episode_reward_alive_std': Array(40.789925, dtype=float32), 'eval/episode_reward_linvel_std': Array(851.74255, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.94735, dtype=float32), 'eval/episode_x_position_std': Array(436.37592, dtype=float32), 'eval/episode_x_velocity_std': Array(170.34846, dtype=float32), 'eval/episode_y_position_std': Array(228.8323, dtype=float32), 'eval/episode_y_velocity_std': Array(78.58864, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7701735496521, 'eval/sps': 935.8765634199606, 'num_steps': 6717440}
{'eval/walltime': 11508.769402980804, 'training/sps': 2948.04409109783, 'training/walltime': 2334.7867288589478, 'training/entropy_loss': Array(0.0071229, dtype=float32), 'training/policy_loss': Array(0.00214655, dtype=float32), 'training/total_loss': Array(0.06301708, dtype=float32), 'training/v_loss': Array(0.05374763, dtype=float32), 'eval/episode_distance_from_origin': Array(4375.2207, dtype=float32), 'eval/episode_distance_reward': Array(10.581564, dtype=float32), 'eval/episode_forward_reward': Array(1763.5868, dtype=float32), 'eval/episode_reward': Array(1751.0151, dtype=float32), 'eval/episode_reward_alive': Array(412.98047, dtype=float32), 'eval/episode_reward_linvel': Array(1763.5868, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.13373, dtype=float32), 'eval/episode_x_position': Array(4328.729, dtype=float32), 'eval/episode_x_velocity': Array(352.71738, dtype=float32), 'eval/episode_y_position': Array(-249.44006, dtype=float32), 'eval/episode_y_velocity': Array(-81.47633, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.44565, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3042984, dtype=float32), 'eval/episode_forward_reward_std': Array(884.0429, dtype=float32), 'eval/episode_reward_std': Array(925.61786, dtype=float32), 'eval/episode_reward_alive_std': Array(35.479275, dtype=float32), 'eval/episode_reward_linvel_std': Array(884.0429, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.11582, dtype=float32), 'eval/episode_x_position_std': Array(441.63956, dtype=float32), 'eval/episode_x_velocity_std': Array(176.8086, dtype=float32), 'eval/episode_y_position_std': Array(246.69096, dtype=float32), 'eval/episode_y_velocity_std': Array(83.59284, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33723735809326, 'eval/sps': 938.8484208742232, 'num_steps': 6799360}
{'eval/walltime': 11645.438736438751, 'training/sps': 2937.934252754717, 'training/walltime': 2362.670266389847, 'training/entropy_loss': Array(0.00873388, dtype=float32), 'training/policy_loss': Array(0.0027265, dtype=float32), 'training/total_loss': Array(0.07138277, dtype=float32), 'training/v_loss': Array(0.0599224, dtype=float32), 'eval/episode_distance_from_origin': Array(4444.4307, dtype=float32), 'eval/episode_distance_reward': Array(11.408857, dtype=float32), 'eval/episode_forward_reward': Array(1901.4685, dtype=float32), 'eval/episode_reward': Array(1890.8678, dtype=float32), 'eval/episode_reward_alive': Array(414.1836, dtype=float32), 'eval/episode_reward_linvel': Array(1901.4685, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.19284, dtype=float32), 'eval/episode_x_position': Array(4401.2344, dtype=float32), 'eval/episode_x_velocity': Array(380.29367, dtype=float32), 'eval/episode_y_position': Array(-224.61008, dtype=float32), 'eval/episode_y_velocity': Array(-74.62187, dtype=float32), 'eval/episode_distance_from_origin_std': Array(438.1928, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3817763, dtype=float32), 'eval/episode_forward_reward_std': Array(896.9557, dtype=float32), 'eval/episode_reward_std': Array(936.91046, dtype=float32), 'eval/episode_reward_alive_std': Array(39.01962, dtype=float32), 'eval/episode_reward_linvel_std': Array(896.9557, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.95281, dtype=float32), 'eval/episode_x_position_std': Array(431.26077, dtype=float32), 'eval/episode_x_velocity_std': Array(179.39113, dtype=float32), 'eval/episode_y_position_std': Array(231.30838, dtype=float32), 'eval/episode_y_velocity_std': Array(75.84627, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66933345794678, 'eval/sps': 936.5670905198763, 'num_steps': 6881280}
{'eval/walltime': 11782.042079925537, 'training/sps': 2950.4911938029873, 'training/walltime': 2390.4351348876953, 'training/entropy_loss': Array(0.01147053, dtype=float32), 'training/policy_loss': Array(0.00238237, dtype=float32), 'training/total_loss': Array(0.04448058, dtype=float32), 'training/v_loss': Array(0.03062768, dtype=float32), 'eval/episode_distance_from_origin': Array(4471.1562, dtype=float32), 'eval/episode_distance_reward': Array(11.786157, dtype=float32), 'eval/episode_forward_reward': Array(1964.3506, dtype=float32), 'eval/episode_reward': Array(1957.9656, dtype=float32), 'eval/episode_reward_alive': Array(412.5547, dtype=float32), 'eval/episode_reward_linvel': Array(1964.3506, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.726, dtype=float32), 'eval/episode_x_position': Array(4429.644, dtype=float32), 'eval/episode_x_velocity': Array(392.87018, dtype=float32), 'eval/episode_y_position': Array(-192.30139, dtype=float32), 'eval/episode_y_velocity': Array(-66.226105, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.7181, dtype=float32), 'eval/episode_distance_reward_std': Array(5.719526, dtype=float32), 'eval/episode_forward_reward_std': Array(953.2468, dtype=float32), 'eval/episode_reward_std': Array(997.78925, dtype=float32), 'eval/episode_reward_alive_std': Array(45.0973, dtype=float32), 'eval/episode_reward_linvel_std': Array(953.2468, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.98945, dtype=float32), 'eval/episode_x_position_std': Array(446.38885, dtype=float32), 'eval/episode_x_velocity_std': Array(190.64938, dtype=float32), 'eval/episode_y_position_std': Array(235.82639, dtype=float32), 'eval/episode_y_velocity_std': Array(79.72414, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6033434867859, 'eval/sps': 937.0195247994196, 'num_steps': 6963200}
{'eval/walltime': 11918.644805431366, 'training/sps': 2920.696424794695, 'training/walltime': 2418.483239889145, 'training/entropy_loss': Array(0.01291727, dtype=float32), 'training/policy_loss': Array(0.00380814, dtype=float32), 'training/total_loss': Array(0.03940418, dtype=float32), 'training/v_loss': Array(0.02267877, dtype=float32), 'eval/episode_distance_from_origin': Array(4495.534, dtype=float32), 'eval/episode_distance_reward': Array(12.049831, dtype=float32), 'eval/episode_forward_reward': Array(2008.2964, dtype=float32), 'eval/episode_reward': Array(2007.5542, dtype=float32), 'eval/episode_reward_alive': Array(411.35547, dtype=float32), 'eval/episode_reward_linvel': Array(2008.2964, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.14764, dtype=float32), 'eval/episode_x_position': Array(4453.431, dtype=float32), 'eval/episode_x_velocity': Array(401.6592, dtype=float32), 'eval/episode_y_position': Array(-209.62561, dtype=float32), 'eval/episode_y_velocity': Array(-69.74045, dtype=float32), 'eval/episode_distance_from_origin_std': Array(490.28058, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9080696, dtype=float32), 'eval/episode_forward_reward_std': Array(984.6707, dtype=float32), 'eval/episode_reward_std': Array(1020.94965, dtype=float32), 'eval/episode_reward_alive_std': Array(38.967594, dtype=float32), 'eval/episode_reward_linvel_std': Array(984.6707, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.23609, dtype=float32), 'eval/episode_x_position_std': Array(484.89304, dtype=float32), 'eval/episode_x_velocity_std': Array(196.93413, dtype=float32), 'eval/episode_y_position_std': Array(228.42964, dtype=float32), 'eval/episode_y_velocity_std': Array(79.73658, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60272550582886, 'eval/sps': 937.0237638087112, 'num_steps': 7045120}
{'eval/walltime': 12055.251032352448, 'training/sps': 2947.6500121428494, 'training/walltime': 2446.2748703956604, 'training/entropy_loss': Array(0.01336312, dtype=float32), 'training/policy_loss': Array(0.00272703, dtype=float32), 'training/total_loss': Array(0.03687125, dtype=float32), 'training/v_loss': Array(0.0207811, dtype=float32), 'eval/episode_distance_from_origin': Array(4491.467, dtype=float32), 'eval/episode_distance_reward': Array(11.739151, dtype=float32), 'eval/episode_forward_reward': Array(1956.5168, dtype=float32), 'eval/episode_reward': Array(1950.1309, dtype=float32), 'eval/episode_reward_alive': Array(414.89062, dtype=float32), 'eval/episode_reward_linvel': Array(1956.5168, dtype=float32), 'eval/episode_reward_quadctrl': Array(-433.01584, dtype=float32), 'eval/episode_x_position': Array(4451.5015, dtype=float32), 'eval/episode_x_velocity': Array(391.3034, dtype=float32), 'eval/episode_y_position': Array(-178.24736, dtype=float32), 'eval/episode_y_velocity': Array(-55.412857, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.60168, dtype=float32), 'eval/episode_distance_reward_std': Array(5.439672, dtype=float32), 'eval/episode_forward_reward_std': Array(906.6048, dtype=float32), 'eval/episode_reward_std': Array(944.19464, dtype=float32), 'eval/episode_reward_alive_std': Array(38.278885, dtype=float32), 'eval/episode_reward_linvel_std': Array(906.6048, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.626465, dtype=float32), 'eval/episode_x_position_std': Array(455.94833, dtype=float32), 'eval/episode_x_velocity_std': Array(181.32097, dtype=float32), 'eval/episode_y_position_std': Array(227.45343, dtype=float32), 'eval/episode_y_velocity_std': Array(69.031075, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60622692108154, 'eval/sps': 936.9997465338573, 'num_steps': 7127040}
{'eval/walltime': 12191.915265321732, 'training/sps': 2924.556247173358, 'training/walltime': 2474.2859575748444, 'training/entropy_loss': Array(0.00887707, dtype=float32), 'training/policy_loss': Array(0.00054971, dtype=float32), 'training/total_loss': Array(0.04933199, dtype=float32), 'training/v_loss': Array(0.03990521, dtype=float32), 'eval/episode_distance_from_origin': Array(4434.871, dtype=float32), 'eval/episode_distance_reward': Array(11.430754, dtype=float32), 'eval/episode_forward_reward': Array(1905.1177, dtype=float32), 'eval/episode_reward': Array(1892.1088, dtype=float32), 'eval/episode_reward_alive': Array(409.71875, dtype=float32), 'eval/episode_reward_linvel': Array(1905.1177, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.15817, dtype=float32), 'eval/episode_x_position': Array(4392.658, dtype=float32), 'eval/episode_x_velocity': Array(381.0235, dtype=float32), 'eval/episode_y_position': Array(-190.69977, dtype=float32), 'eval/episode_y_velocity': Array(-67.00185, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.17993, dtype=float32), 'eval/episode_distance_reward_std': Array(5.706167, dtype=float32), 'eval/episode_forward_reward_std': Array(951.0207, dtype=float32), 'eval/episode_reward_std': Array(988.513, dtype=float32), 'eval/episode_reward_alive_std': Array(39.97742, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.0207, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.76013, dtype=float32), 'eval/episode_x_position_std': Array(471.7691, dtype=float32), 'eval/episode_x_velocity_std': Array(190.20413, dtype=float32), 'eval/episode_y_position_std': Array(247.0151, dtype=float32), 'eval/episode_y_velocity_std': Array(80.91068, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66423296928406, 'eval/sps': 936.6020444337372, 'num_steps': 7208960}
{'eval/walltime': 12328.488044261932, 'training/sps': 2949.3060445483366, 'training/walltime': 2502.0619831085205, 'training/entropy_loss': Array(0.00632094, dtype=float32), 'training/policy_loss': Array(0.00072605, dtype=float32), 'training/total_loss': Array(0.06274033, dtype=float32), 'training/v_loss': Array(0.05569332, dtype=float32), 'eval/episode_distance_from_origin': Array(4398.9785, dtype=float32), 'eval/episode_distance_reward': Array(10.809923, dtype=float32), 'eval/episode_forward_reward': Array(1801.647, dtype=float32), 'eval/episode_reward': Array(1787.8362, dtype=float32), 'eval/episode_reward_alive': Array(412.82422, dtype=float32), 'eval/episode_reward_linvel': Array(1801.647, dtype=float32), 'eval/episode_reward_quadctrl': Array(-437.44476, dtype=float32), 'eval/episode_x_position': Array(4357.4795, dtype=float32), 'eval/episode_x_velocity': Array(360.32938, dtype=float32), 'eval/episode_y_position': Array(-204.45285, dtype=float32), 'eval/episode_y_velocity': Array(-66.997025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(456.02054, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5261464, dtype=float32), 'eval/episode_forward_reward_std': Array(921.0177, dtype=float32), 'eval/episode_reward_std': Array(955.84546, dtype=float32), 'eval/episode_reward_alive_std': Array(43.652863, dtype=float32), 'eval/episode_reward_linvel_std': Array(921.0177, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.185715, dtype=float32), 'eval/episode_x_position_std': Array(450.8818, dtype=float32), 'eval/episode_x_velocity_std': Array(184.20354, dtype=float32), 'eval/episode_y_position_std': Array(223.76344, dtype=float32), 'eval/episode_y_velocity_std': Array(74.92376, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5727789402008, 'eval/sps': 937.2292267410444, 'num_steps': 7290880}
{'eval/walltime': 12465.098806619644, 'training/sps': 2932.478533342637, 'training/walltime': 2529.997396469116, 'training/entropy_loss': Array(0.0101373, dtype=float32), 'training/policy_loss': Array(0.00733946, dtype=float32), 'training/total_loss': Array(0.0874633, dtype=float32), 'training/v_loss': Array(0.06998653, dtype=float32), 'eval/episode_distance_from_origin': Array(4526.8154, dtype=float32), 'eval/episode_distance_reward': Array(12.386496, dtype=float32), 'eval/episode_forward_reward': Array(2064.407, dtype=float32), 'eval/episode_reward': Array(2059.542, dtype=float32), 'eval/episode_reward_alive': Array(422.19922, dtype=float32), 'eval/episode_reward_linvel': Array(2064.407, dtype=float32), 'eval/episode_reward_quadctrl': Array(-439.4506, dtype=float32), 'eval/episode_x_position': Array(4485.1084, dtype=float32), 'eval/episode_x_velocity': Array(412.88135, dtype=float32), 'eval/episode_y_position': Array(-182.2486, dtype=float32), 'eval/episode_y_velocity': Array(-66.62062, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.25577, dtype=float32), 'eval/episode_distance_reward_std': Array(5.872178, dtype=float32), 'eval/episode_forward_reward_std': Array(978.68896, dtype=float32), 'eval/episode_reward_std': Array(1022.8284, dtype=float32), 'eval/episode_reward_alive_std': Array(32.28428, dtype=float32), 'eval/episode_reward_linvel_std': Array(978.68896, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.33353, dtype=float32), 'eval/episode_x_position_std': Array(465.7713, dtype=float32), 'eval/episode_x_velocity_std': Array(195.73781, dtype=float32), 'eval/episode_y_position_std': Array(247.00049, dtype=float32), 'eval/episode_y_velocity_std': Array(83.03471, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6107623577118, 'eval/sps': 936.9686384212927, 'num_steps': 7372800}
{'eval/walltime': 12601.674519777298, 'training/sps': 2949.2202268436276, 'training/walltime': 2557.7742302417755, 'training/entropy_loss': Array(0.01161578, dtype=float32), 'training/policy_loss': Array(0.00469229, dtype=float32), 'training/total_loss': Array(0.06337476, dtype=float32), 'training/v_loss': Array(0.0470667, dtype=float32), 'eval/episode_distance_from_origin': Array(4437.6855, dtype=float32), 'eval/episode_distance_reward': Array(11.29287, dtype=float32), 'eval/episode_forward_reward': Array(1882.1372, dtype=float32), 'eval/episode_reward': Array(1870.3296, dtype=float32), 'eval/episode_reward_alive': Array(417.20703, dtype=float32), 'eval/episode_reward_linvel': Array(1882.1372, dtype=float32), 'eval/episode_reward_quadctrl': Array(-440.30746, dtype=float32), 'eval/episode_x_position': Array(4390.8984, dtype=float32), 'eval/episode_x_velocity': Array(376.42743, dtype=float32), 'eval/episode_y_position': Array(-248.97443, dtype=float32), 'eval/episode_y_velocity': Array(-82.60341, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.71393, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7853603, dtype=float32), 'eval/episode_forward_reward_std': Array(964.21967, dtype=float32), 'eval/episode_reward_std': Array(1008.6635, dtype=float32), 'eval/episode_reward_alive_std': Array(36.471817, dtype=float32), 'eval/episode_reward_linvel_std': Array(964.21967, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(74.81005, dtype=float32), 'eval/episode_x_position_std': Array(464.5255, dtype=float32), 'eval/episode_x_velocity_std': Array(192.8439, dtype=float32), 'eval/episode_y_position_std': Array(263.70123, dtype=float32), 'eval/episode_y_velocity_std': Array(85.26293, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5757131576538, 'eval/sps': 937.2090911379347, 'num_steps': 7454720}
{'eval/walltime': 12738.517623662949, 'training/sps': 2923.2110482564904, 'training/walltime': 2585.7982075214386, 'training/entropy_loss': Array(0.01310361, dtype=float32), 'training/policy_loss': Array(0.003678, dtype=float32), 'training/total_loss': Array(0.05551146, dtype=float32), 'training/v_loss': Array(0.03872985, dtype=float32), 'eval/episode_distance_from_origin': Array(4429.1875, dtype=float32), 'eval/episode_distance_reward': Array(11.177796, dtype=float32), 'eval/episode_forward_reward': Array(1862.9585, dtype=float32), 'eval/episode_reward': Array(1850.7234, dtype=float32), 'eval/episode_reward_alive': Array(414.65625, dtype=float32), 'eval/episode_reward_linvel': Array(1862.9585, dtype=float32), 'eval/episode_reward_quadctrl': Array(-438.06903, dtype=float32), 'eval/episode_x_position': Array(4383.9443, dtype=float32), 'eval/episode_x_velocity': Array(372.59167, dtype=float32), 'eval/episode_y_position': Array(-228.69681, dtype=float32), 'eval/episode_y_velocity': Array(-77.171745, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.67413, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7234125, dtype=float32), 'eval/episode_forward_reward_std': Array(953.89484, dtype=float32), 'eval/episode_reward_std': Array(994.0188, dtype=float32), 'eval/episode_reward_alive_std': Array(37.774452, dtype=float32), 'eval/episode_reward_linvel_std': Array(953.89484, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.39277, dtype=float32), 'eval/episode_x_position_std': Array(456.01617, dtype=float32), 'eval/episode_x_velocity_std': Array(190.7789, dtype=float32), 'eval/episode_y_position_std': Array(255.72726, dtype=float32), 'eval/episode_y_velocity_std': Array(85.42266, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84310388565063, 'eval/sps': 935.3777893474256, 'num_steps': 7536640}
{'eval/walltime': 12874.917031764984, 'training/sps': 2945.580564890871, 'training/walltime': 2613.6093633174896, 'training/entropy_loss': Array(0.01321137, dtype=float32), 'training/policy_loss': Array(0.00469334, dtype=float32), 'training/total_loss': Array(0.05250537, dtype=float32), 'training/v_loss': Array(0.03460065, dtype=float32), 'eval/episode_distance_from_origin': Array(4428.822, dtype=float32), 'eval/episode_distance_reward': Array(11.1025305, dtype=float32), 'eval/episode_forward_reward': Array(1850.4143, dtype=float32), 'eval/episode_reward': Array(1833.5469, dtype=float32), 'eval/episode_reward_alive': Array(419.35156, dtype=float32), 'eval/episode_reward_linvel': Array(1850.4143, dtype=float32), 'eval/episode_reward_quadctrl': Array(-447.3216, dtype=float32), 'eval/episode_x_position': Array(4383.202, dtype=float32), 'eval/episode_x_velocity': Array(370.08286, dtype=float32), 'eval/episode_y_position': Array(-251.23184, dtype=float32), 'eval/episode_y_velocity': Array(-84.82765, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.67484, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8349195, dtype=float32), 'eval/episode_forward_reward_std': Array(972.47943, dtype=float32), 'eval/episode_reward_std': Array(1022.6756, dtype=float32), 'eval/episode_reward_alive_std': Array(33.19529, dtype=float32), 'eval/episode_reward_linvel_std': Array(972.47943, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(73.913086, dtype=float32), 'eval/episode_x_position_std': Array(484.07477, dtype=float32), 'eval/episode_x_velocity_std': Array(194.49586, dtype=float32), 'eval/episode_y_position_std': Array(231.9265, dtype=float32), 'eval/episode_y_velocity_std': Array(80.67721, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39940810203552, 'eval/sps': 938.4204944954583, 'num_steps': 7618560}
{'eval/walltime': 13011.55529999733, 'training/sps': 2935.6183298704423, 'training/walltime': 2641.514898300171, 'training/entropy_loss': Array(0.01042476, dtype=float32), 'training/policy_loss': Array(-0.00037916, dtype=float32), 'training/total_loss': Array(0.0425868, dtype=float32), 'training/v_loss': Array(0.0325412, dtype=float32), 'eval/episode_distance_from_origin': Array(4431.0264, dtype=float32), 'eval/episode_distance_reward': Array(10.99572, dtype=float32), 'eval/episode_forward_reward': Array(1832.6128, dtype=float32), 'eval/episode_reward': Array(1810.1919, dtype=float32), 'eval/episode_reward_alive': Array(421.42578, dtype=float32), 'eval/episode_reward_linvel': Array(1832.6128, dtype=float32), 'eval/episode_reward_quadctrl': Array(-454.84235, dtype=float32), 'eval/episode_x_position': Array(4389.7676, dtype=float32), 'eval/episode_x_velocity': Array(366.52252, dtype=float32), 'eval/episode_y_position': Array(-167.24454, dtype=float32), 'eval/episode_y_velocity': Array(-54.890686, dtype=float32), 'eval/episode_distance_from_origin_std': Array(505.41602, dtype=float32), 'eval/episode_distance_reward_std': Array(5.906503, dtype=float32), 'eval/episode_forward_reward_std': Array(984.41003, dtype=float32), 'eval/episode_reward_std': Array(1031.338, dtype=float32), 'eval/episode_reward_alive_std': Array(39.33426, dtype=float32), 'eval/episode_reward_linvel_std': Array(984.41003, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(74.52926, dtype=float32), 'eval/episode_x_position_std': Array(498.91156, dtype=float32), 'eval/episode_x_velocity_std': Array(196.882, dtype=float32), 'eval/episode_y_position_std': Array(253.3182, dtype=float32), 'eval/episode_y_velocity_std': Array(81.51285, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63826823234558, 'eval/sps': 936.780022580082, 'num_steps': 7700480}
{'eval/walltime': 13148.130062580109, 'training/sps': 2923.915901036947, 'training/walltime': 2669.532119989395, 'training/entropy_loss': Array(0.00568167, dtype=float32), 'training/policy_loss': Array(-8.75744e-05, dtype=float32), 'training/total_loss': Array(0.06478302, dtype=float32), 'training/v_loss': Array(0.05918893, dtype=float32), 'eval/episode_distance_from_origin': Array(4510.2295, dtype=float32), 'eval/episode_distance_reward': Array(12.155333, dtype=float32), 'eval/episode_forward_reward': Array(2025.8798, dtype=float32), 'eval/episode_reward': Array(2020.6992, dtype=float32), 'eval/episode_reward_alive': Array(423.8086, dtype=float32), 'eval/episode_reward_linvel': Array(2025.8798, dtype=float32), 'eval/episode_reward_quadctrl': Array(-441.1443, dtype=float32), 'eval/episode_x_position': Array(4463.9, dtype=float32), 'eval/episode_x_velocity': Array(405.17596, dtype=float32), 'eval/episode_y_position': Array(-255.71051, dtype=float32), 'eval/episode_y_velocity': Array(-82.78507, dtype=float32), 'eval/episode_distance_from_origin_std': Array(511.881, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1335545, dtype=float32), 'eval/episode_forward_reward_std': Array(1022.25134, dtype=float32), 'eval/episode_reward_std': Array(1071.397, dtype=float32), 'eval/episode_reward_alive_std': Array(38.809383, dtype=float32), 'eval/episode_reward_linvel_std': Array(1022.25134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.529526, dtype=float32), 'eval/episode_x_position_std': Array(501.73444, dtype=float32), 'eval/episode_x_velocity_std': Array(204.45027, dtype=float32), 'eval/episode_y_position_std': Array(255.85707, dtype=float32), 'eval/episode_y_velocity_std': Array(81.05371, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57476258277893, 'eval/sps': 937.2156142128989, 'num_steps': 7782400}
{'eval/walltime': 13284.724741458893, 'training/sps': 2924.5046706337926, 'training/walltime': 2697.543701171875, 'training/entropy_loss': Array(0.00972158, dtype=float32), 'training/policy_loss': Array(0.00642115, dtype=float32), 'training/total_loss': Array(0.07548296, dtype=float32), 'training/v_loss': Array(0.05934023, dtype=float32), 'eval/episode_distance_from_origin': Array(4494.834, dtype=float32), 'eval/episode_distance_reward': Array(11.71286, dtype=float32), 'eval/episode_forward_reward': Array(1952.135, dtype=float32), 'eval/episode_reward': Array(1939.2455, dtype=float32), 'eval/episode_reward_alive': Array(419.70312, dtype=float32), 'eval/episode_reward_linvel': Array(1952.135, dtype=float32), 'eval/episode_reward_quadctrl': Array(-444.30566, dtype=float32), 'eval/episode_x_position': Array(4447.3076, dtype=float32), 'eval/episode_x_velocity': Array(390.42703, dtype=float32), 'eval/episode_y_position': Array(-235.5706, dtype=float32), 'eval/episode_y_velocity': Array(-77.52309, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.18668, dtype=float32), 'eval/episode_distance_reward_std': Array(5.797378, dtype=float32), 'eval/episode_forward_reward_std': Array(966.2224, dtype=float32), 'eval/episode_reward_std': Array(1015.404, dtype=float32), 'eval/episode_reward_alive_std': Array(36.299988, dtype=float32), 'eval/episode_reward_linvel_std': Array(966.2224, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(71.46947, dtype=float32), 'eval/episode_x_position_std': Array(470.14316, dtype=float32), 'eval/episode_x_velocity_std': Array(193.24446, dtype=float32), 'eval/episode_y_position_std': Array(281.65927, dtype=float32), 'eval/episode_y_velocity_std': Array(88.31602, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59467887878418, 'eval/sps': 937.0789627434082, 'num_steps': 7864320}
{'eval/walltime': 13421.328516483307, 'training/sps': 2944.2119234515867, 'training/walltime': 2725.367785215378, 'training/entropy_loss': Array(0.01217852, dtype=float32), 'training/policy_loss': Array(0.00596014, dtype=float32), 'training/total_loss': Array(0.07348552, dtype=float32), 'training/v_loss': Array(0.05534686, dtype=float32), 'eval/episode_distance_from_origin': Array(4557.4478, dtype=float32), 'eval/episode_distance_reward': Array(12.291761, dtype=float32), 'eval/episode_forward_reward': Array(2048.6182, dtype=float32), 'eval/episode_reward': Array(2043.5448, dtype=float32), 'eval/episode_reward_alive': Array(419.53125, dtype=float32), 'eval/episode_reward_linvel': Array(2048.6182, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.89664, dtype=float32), 'eval/episode_x_position': Array(4509.5596, dtype=float32), 'eval/episode_x_velocity': Array(409.72366, dtype=float32), 'eval/episode_y_position': Array(-260.40167, dtype=float32), 'eval/episode_y_velocity': Array(-88.063286, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.7275, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8158984, dtype=float32), 'eval/episode_forward_reward_std': Array(969.3095, dtype=float32), 'eval/episode_reward_std': Array(1014.7248, dtype=float32), 'eval/episode_reward_alive_std': Array(45.502823, dtype=float32), 'eval/episode_reward_linvel_std': Array(969.3095, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.13712, dtype=float32), 'eval/episode_x_position_std': Array(473.16174, dtype=float32), 'eval/episode_x_velocity_std': Array(193.86192, dtype=float32), 'eval/episode_y_position_std': Array(268.2211, dtype=float32), 'eval/episode_y_velocity_std': Array(85.84969, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60377502441406, 'eval/sps': 937.0165647115068, 'num_steps': 7946240}
{'eval/walltime': 13557.908893823624, 'training/sps': 2932.834119056047, 'training/walltime': 2753.299811601639, 'training/entropy_loss': Array(0.01283186, dtype=float32), 'training/policy_loss': Array(0.02866794, dtype=float32), 'training/total_loss': Array(0.07477244, dtype=float32), 'training/v_loss': Array(0.03327265, dtype=float32), 'eval/episode_distance_from_origin': Array(4423.743, dtype=float32), 'eval/episode_distance_reward': Array(10.177347, dtype=float32), 'eval/episode_forward_reward': Array(1696.219, dtype=float32), 'eval/episode_reward': Array(1658.8105, dtype=float32), 'eval/episode_reward_alive': Array(421.8828, dtype=float32), 'eval/episode_reward_linvel': Array(1696.219, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.46848, dtype=float32), 'eval/episode_x_position': Array(4380.815, dtype=float32), 'eval/episode_x_velocity': Array(339.2438, dtype=float32), 'eval/episode_y_position': Array(-205.2211, dtype=float32), 'eval/episode_y_velocity': Array(-60.738113, dtype=float32), 'eval/episode_distance_from_origin_std': Array(407.52563, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7031517, dtype=float32), 'eval/episode_forward_reward_std': Array(783.8529, dtype=float32), 'eval/episode_reward_std': Array(825.45905, dtype=float32), 'eval/episode_reward_alive_std': Array(32.903, dtype=float32), 'eval/episode_reward_linvel_std': Array(783.8529, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.66482, dtype=float32), 'eval/episode_x_position_std': Array(402.7545, dtype=float32), 'eval/episode_x_velocity_std': Array(156.77058, dtype=float32), 'eval/episode_y_position_std': Array(252.97862, dtype=float32), 'eval/episode_y_velocity_std': Array(70.09032, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58037734031677, 'eval/sps': 937.1770857028965, 'num_steps': 8028160}
{'eval/walltime': 13694.39560174942, 'training/sps': 2941.47245941972, 'training/walltime': 2781.149808883667, 'training/entropy_loss': Array(0.01351972, dtype=float32), 'training/policy_loss': Array(0.00632229, dtype=float32), 'training/total_loss': Array(0.04454693, dtype=float32), 'training/v_loss': Array(0.02470493, dtype=float32), 'eval/episode_distance_from_origin': Array(4460.475, dtype=float32), 'eval/episode_distance_reward': Array(10.618181, dtype=float32), 'eval/episode_forward_reward': Array(1769.6904, dtype=float32), 'eval/episode_reward': Array(1742.2208, dtype=float32), 'eval/episode_reward_alive': Array(431.64844, dtype=float32), 'eval/episode_reward_linvel': Array(1769.6904, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.73636, dtype=float32), 'eval/episode_x_position': Array(4415.377, dtype=float32), 'eval/episode_x_velocity': Array(353.9381, dtype=float32), 'eval/episode_y_position': Array(-216.97716, dtype=float32), 'eval/episode_y_velocity': Array(-66.2287, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.17508, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0947037, dtype=float32), 'eval/episode_forward_reward_std': Array(849.1108, dtype=float32), 'eval/episode_reward_std': Array(897.432, dtype=float32), 'eval/episode_reward_alive_std': Array(28.892672, dtype=float32), 'eval/episode_reward_linvel_std': Array(849.1108, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.86822, dtype=float32), 'eval/episode_x_position_std': Array(412.76733, dtype=float32), 'eval/episode_x_velocity_std': Array(169.82217, dtype=float32), 'eval/episode_y_position_std': Array(275.0703, dtype=float32), 'eval/episode_y_velocity_std': Array(80.89237, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4867079257965, 'eval/sps': 937.8202606336548, 'num_steps': 8110080}
{'eval/walltime': 13830.981243133545, 'training/sps': 2932.060005867066, 'training/walltime': 2809.089209794998, 'training/entropy_loss': Array(0.01400219, dtype=float32), 'training/policy_loss': Array(0.0036609, dtype=float32), 'training/total_loss': Array(0.0446449, dtype=float32), 'training/v_loss': Array(0.02698181, dtype=float32), 'eval/episode_distance_from_origin': Array(4462.4443, dtype=float32), 'eval/episode_distance_reward': Array(10.785933, dtype=float32), 'eval/episode_forward_reward': Array(1797.649, dtype=float32), 'eval/episode_reward': Array(1769.3275, dtype=float32), 'eval/episode_reward_alive': Array(423.6836, dtype=float32), 'eval/episode_reward_linvel': Array(1797.649, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.7909, dtype=float32), 'eval/episode_x_position': Array(4416.8325, dtype=float32), 'eval/episode_x_velocity': Array(359.5298, dtype=float32), 'eval/episode_y_position': Array(-237.05865, dtype=float32), 'eval/episode_y_velocity': Array(-73.47652, dtype=float32), 'eval/episode_distance_from_origin_std': Array(464.6734, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4165177, dtype=float32), 'eval/episode_forward_reward_std': Array(902.7461, dtype=float32), 'eval/episode_reward_std': Array(949.19763, dtype=float32), 'eval/episode_reward_alive_std': Array(41.31996, dtype=float32), 'eval/episode_reward_linvel_std': Array(902.7461, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.10986, dtype=float32), 'eval/episode_x_position_std': Array(452.9059, dtype=float32), 'eval/episode_x_velocity_std': Array(180.5492, dtype=float32), 'eval/episode_y_position_std': Array(263.2274, dtype=float32), 'eval/episode_y_velocity_std': Array(80.970314, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58564138412476, 'eval/sps': 937.1409666702882, 'num_steps': 8192000}
{'eval/walltime': 13967.388110637665, 'training/sps': 2941.4944681205448, 'training/walltime': 2836.9389986991882, 'training/entropy_loss': Array(0.00442812, dtype=float32), 'training/policy_loss': Array(0.00101422, dtype=float32), 'training/total_loss': Array(0.06339542, dtype=float32), 'training/v_loss': Array(0.05795309, dtype=float32), 'eval/episode_distance_from_origin': Array(4449.2744, dtype=float32), 'eval/episode_distance_reward': Array(10.756054, dtype=float32), 'eval/episode_forward_reward': Array(1792.6692, dtype=float32), 'eval/episode_reward': Array(1768.6511, dtype=float32), 'eval/episode_reward_alive': Array(432.35938, dtype=float32), 'eval/episode_reward_linvel': Array(1792.6692, dtype=float32), 'eval/episode_reward_quadctrl': Array(-467.1331, dtype=float32), 'eval/episode_x_position': Array(4406.6567, dtype=float32), 'eval/episode_x_velocity': Array(358.53378, dtype=float32), 'eval/episode_y_position': Array(-184.12991, dtype=float32), 'eval/episode_y_velocity': Array(-62.186226, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.05893, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7100005, dtype=float32), 'eval/episode_forward_reward_std': Array(951.6599, dtype=float32), 'eval/episode_reward_std': Array(995.3621, dtype=float32), 'eval/episode_reward_alive_std': Array(30.577383, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.6599, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.040886, dtype=float32), 'eval/episode_x_position_std': Array(478.65247, dtype=float32), 'eval/episode_x_velocity_std': Array(190.33202, dtype=float32), 'eval/episode_y_position_std': Array(250.14494, dtype=float32), 'eval/episode_y_velocity_std': Array(80.09177, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40686750411987, 'eval/sps': 938.3691770220736, 'num_steps': 8273920}
{'eval/walltime': 14104.206431388855, 'training/sps': 2932.5494633794756, 'training/walltime': 2864.8737363815308, 'training/entropy_loss': Array(0.00908797, dtype=float32), 'training/policy_loss': Array(0.00467319, dtype=float32), 'training/total_loss': Array(0.07899851, dtype=float32), 'training/v_loss': Array(0.06523736, dtype=float32), 'eval/episode_distance_from_origin': Array(4467.4717, dtype=float32), 'eval/episode_distance_reward': Array(10.79059, dtype=float32), 'eval/episode_forward_reward': Array(1798.4253, dtype=float32), 'eval/episode_reward': Array(1770.9302, dtype=float32), 'eval/episode_reward_alive': Array(429.88672, dtype=float32), 'eval/episode_reward_linvel': Array(1798.4253, dtype=float32), 'eval/episode_reward_quadctrl': Array(-468.17255, dtype=float32), 'eval/episode_x_position': Array(4421.6743, dtype=float32), 'eval/episode_x_velocity': Array(359.68503, dtype=float32), 'eval/episode_y_position': Array(-204.54922, dtype=float32), 'eval/episode_y_velocity': Array(-69.07435, dtype=float32), 'eval/episode_distance_from_origin_std': Array(469.17654, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5673127, dtype=float32), 'eval/episode_forward_reward_std': Array(927.8786, dtype=float32), 'eval/episode_reward_std': Array(974.9308, dtype=float32), 'eval/episode_reward_alive_std': Array(30.753061, dtype=float32), 'eval/episode_reward_linvel_std': Array(927.8786, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(72.02377, dtype=float32), 'eval/episode_x_position_std': Array(458.9455, dtype=float32), 'eval/episode_x_velocity_std': Array(185.57568, dtype=float32), 'eval/episode_y_position_std': Array(290.04147, dtype=float32), 'eval/episode_y_velocity_std': Array(86.25951, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.81832075119019, 'eval/sps': 935.547222749308, 'num_steps': 8355840}
{'eval/walltime': 14240.81741809845, 'training/sps': 2932.754764354433, 'training/walltime': 2892.8065185546875, 'training/entropy_loss': Array(0.01252275, dtype=float32), 'training/policy_loss': Array(0.00759266, dtype=float32), 'training/total_loss': Array(0.06647897, dtype=float32), 'training/v_loss': Array(0.04636356, dtype=float32), 'eval/episode_distance_from_origin': Array(4517.6377, dtype=float32), 'eval/episode_distance_reward': Array(11.36979, dtype=float32), 'eval/episode_forward_reward': Array(1894.9578, dtype=float32), 'eval/episode_reward': Array(1879.5161, dtype=float32), 'eval/episode_reward_alive': Array(428.20703, dtype=float32), 'eval/episode_reward_linvel': Array(1894.9578, dtype=float32), 'eval/episode_reward_quadctrl': Array(-455.0185, dtype=float32), 'eval/episode_x_position': Array(4472.456, dtype=float32), 'eval/episode_x_velocity': Array(378.99158, dtype=float32), 'eval/episode_y_position': Array(-196.19678, dtype=float32), 'eval/episode_y_velocity': Array(-67.450836, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.22772, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3032913, dtype=float32), 'eval/episode_forward_reward_std': Array(883.87494, dtype=float32), 'eval/episode_reward_std': Array(924.1246, dtype=float32), 'eval/episode_reward_alive_std': Array(32.187107, dtype=float32), 'eval/episode_reward_linvel_std': Array(883.87494, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.105995, dtype=float32), 'eval/episode_x_position_std': Array(417.3487, dtype=float32), 'eval/episode_x_velocity_std': Array(176.77507, dtype=float32), 'eval/episode_y_position_std': Array(285.74173, dtype=float32), 'eval/episode_y_velocity_std': Array(86.71631, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.61098670959473, 'eval/sps': 936.9670996674681, 'num_steps': 8437760}
{'eval/walltime': 14377.556420326233, 'training/sps': 2929.365875016562, 'training/walltime': 2920.7716152668, 'training/entropy_loss': Array(0.0141975, dtype=float32), 'training/policy_loss': Array(0.00786818, dtype=float32), 'training/total_loss': Array(0.05708957, dtype=float32), 'training/v_loss': Array(0.03502389, dtype=float32), 'eval/episode_distance_from_origin': Array(4569.881, dtype=float32), 'eval/episode_distance_reward': Array(12.163988, dtype=float32), 'eval/episode_forward_reward': Array(2027.3232, dtype=float32), 'eval/episode_reward': Array(2015.2032, dtype=float32), 'eval/episode_reward_alive': Array(427.01172, dtype=float32), 'eval/episode_reward_linvel': Array(2027.3232, dtype=float32), 'eval/episode_reward_quadctrl': Array(-451.2954, dtype=float32), 'eval/episode_x_position': Array(4519.312, dtype=float32), 'eval/episode_x_velocity': Array(405.46463, dtype=float32), 'eval/episode_y_position': Array(-289.2063, dtype=float32), 'eval/episode_y_velocity': Array(-91.689316, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.59647, dtype=float32), 'eval/episode_distance_reward_std': Array(5.69318, dtype=float32), 'eval/episode_forward_reward_std': Array(948.8566, dtype=float32), 'eval/episode_reward_std': Array(995.0133, dtype=float32), 'eval/episode_reward_alive_std': Array(36.65477, dtype=float32), 'eval/episode_reward_linvel_std': Array(948.8566, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(72.01252, dtype=float32), 'eval/episode_x_position_std': Array(462.28204, dtype=float32), 'eval/episode_x_velocity_std': Array(189.77133, dtype=float32), 'eval/episode_y_position_std': Array(281.6752, dtype=float32), 'eval/episode_y_velocity_std': Array(89.36918, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7390022277832, 'eval/sps': 936.0899078872496, 'num_steps': 8519680}
{'eval/walltime': 14514.203881978989, 'training/sps': 2927.670262065122, 'training/walltime': 2948.7529084682465, 'training/entropy_loss': Array(0.01524518, dtype=float32), 'training/policy_loss': Array(0.00284932, dtype=float32), 'training/total_loss': Array(0.04455113, dtype=float32), 'training/v_loss': Array(0.02645662, dtype=float32), 'eval/episode_distance_from_origin': Array(4517.9736, dtype=float32), 'eval/episode_distance_reward': Array(11.2659645, dtype=float32), 'eval/episode_forward_reward': Array(1877.6536, dtype=float32), 'eval/episode_reward': Array(1854.5117, dtype=float32), 'eval/episode_reward_alive': Array(426.3828, dtype=float32), 'eval/episode_reward_linvel': Array(1877.6536, dtype=float32), 'eval/episode_reward_quadctrl': Array(-460.7907, dtype=float32), 'eval/episode_x_position': Array(4471.823, dtype=float32), 'eval/episode_x_velocity': Array(375.5307, dtype=float32), 'eval/episode_y_position': Array(-197.26395, dtype=float32), 'eval/episode_y_velocity': Array(-66.27305, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.17764, dtype=float32), 'eval/episode_distance_reward_std': Array(5.622771, dtype=float32), 'eval/episode_forward_reward_std': Array(937.1215, dtype=float32), 'eval/episode_reward_std': Array(978.56323, dtype=float32), 'eval/episode_reward_alive_std': Array(31.812468, dtype=float32), 'eval/episode_reward_linvel_std': Array(937.1215, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.954956, dtype=float32), 'eval/episode_x_position_std': Array(460.40616, dtype=float32), 'eval/episode_x_velocity_std': Array(187.42427, dtype=float32), 'eval/episode_y_position_std': Array(302.05002, dtype=float32), 'eval/episode_y_velocity_std': Array(90.14867, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64746165275574, 'eval/sps': 936.716997533914, 'num_steps': 8601600}
{'eval/walltime': 14650.6938829422, 'training/sps': 2930.5294759948233, 'training/walltime': 2976.7069013118744, 'training/entropy_loss': Array(0.01620566, dtype=float32), 'training/policy_loss': Array(0.01404509, dtype=float32), 'training/total_loss': Array(0.04989884, dtype=float32), 'training/v_loss': Array(0.01964808, dtype=float32), 'eval/episode_distance_from_origin': Array(4557.537, dtype=float32), 'eval/episode_distance_reward': Array(11.684247, dtype=float32), 'eval/episode_forward_reward': Array(1947.367, dtype=float32), 'eval/episode_reward': Array(1929.9015, dtype=float32), 'eval/episode_reward_alive': Array(430.5586, dtype=float32), 'eval/episode_reward_linvel': Array(1947.367, dtype=float32), 'eval/episode_reward_quadctrl': Array(-459.70813, dtype=float32), 'eval/episode_x_position': Array(4513.366, dtype=float32), 'eval/episode_x_velocity': Array(389.47336, dtype=float32), 'eval/episode_y_position': Array(-197.92885, dtype=float32), 'eval/episode_y_velocity': Array(-66.542274, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.977, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4953966, dtype=float32), 'eval/episode_forward_reward_std': Array(915.89276, dtype=float32), 'eval/episode_reward_std': Array(960.6575, dtype=float32), 'eval/episode_reward_alive_std': Array(30.811209, dtype=float32), 'eval/episode_reward_linvel_std': Array(915.89276, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.69289, dtype=float32), 'eval/episode_x_position_std': Array(444.5627, dtype=float32), 'eval/episode_x_velocity_std': Array(183.17845, dtype=float32), 'eval/episode_y_position_std': Array(278.8821, dtype=float32), 'eval/episode_y_velocity_std': Array(84.46956, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49000096321106, 'eval/sps': 937.797634234764, 'num_steps': 8683520}
{'eval/walltime': 14786.979754924774, 'training/sps': 2932.6518349373537, 'training/walltime': 3004.6406638622284, 'training/entropy_loss': Array(0.00797284, dtype=float32), 'training/policy_loss': Array(0.00820007, dtype=float32), 'training/total_loss': Array(0.06003589, dtype=float32), 'training/v_loss': Array(0.04386298, dtype=float32), 'eval/episode_distance_from_origin': Array(4516.522, dtype=float32), 'eval/episode_distance_reward': Array(11.349678, dtype=float32), 'eval/episode_forward_reward': Array(1891.606, dtype=float32), 'eval/episode_reward': Array(1865.9326, dtype=float32), 'eval/episode_reward_alive': Array(429.22266, dtype=float32), 'eval/episode_reward_linvel': Array(1891.606, dtype=float32), 'eval/episode_reward_quadctrl': Array(-466.24548, dtype=float32), 'eval/episode_x_position': Array(4471.0293, dtype=float32), 'eval/episode_x_velocity': Array(378.32114, dtype=float32), 'eval/episode_y_position': Array(-184.8378, dtype=float32), 'eval/episode_y_velocity': Array(-61.93482, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.37637, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7592063, dtype=float32), 'eval/episode_forward_reward_std': Array(959.8611, dtype=float32), 'eval/episode_reward_std': Array(1011.2564, dtype=float32), 'eval/episode_reward_alive_std': Array(33.595352, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.8611, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(75.35372, dtype=float32), 'eval/episode_x_position_std': Array(474.36633, dtype=float32), 'eval/episode_x_velocity_std': Array(191.97218, dtype=float32), 'eval/episode_y_position_std': Array(298.491, dtype=float32), 'eval/episode_y_velocity_std': Array(88.82946, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28587198257446, 'eval/sps': 939.2022675422006, 'num_steps': 8765440}
{'eval/walltime': 14923.56837272644, 'training/sps': 2943.668101395951, 'training/walltime': 3032.4698882102966, 'training/entropy_loss': Array(0.00803312, dtype=float32), 'training/policy_loss': Array(0.0598676, dtype=float32), 'training/total_loss': Array(0.12909335, dtype=float32), 'training/v_loss': Array(0.06119262, dtype=float32), 'eval/episode_distance_from_origin': Array(4410.3506, dtype=float32), 'eval/episode_distance_reward': Array(9.9178505, dtype=float32), 'eval/episode_forward_reward': Array(1652.9698, dtype=float32), 'eval/episode_reward': Array(1632.1835, dtype=float32), 'eval/episode_reward_alive': Array(431.54688, dtype=float32), 'eval/episode_reward_linvel': Array(1652.9698, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.25098, dtype=float32), 'eval/episode_x_position': Array(4366.9653, dtype=float32), 'eval/episode_x_velocity': Array(330.59393, dtype=float32), 'eval/episode_y_position': Array(-175.52325, dtype=float32), 'eval/episode_y_velocity': Array(-53.48977, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.58023, dtype=float32), 'eval/episode_distance_reward_std': Array(4.637814, dtype=float32), 'eval/episode_forward_reward_std': Array(772.9632, dtype=float32), 'eval/episode_reward_std': Array(808.74774, dtype=float32), 'eval/episode_reward_alive_std': Array(42.017406, dtype=float32), 'eval/episode_reward_linvel_std': Array(772.9632, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.15666, dtype=float32), 'eval/episode_x_position_std': Array(407.2154, dtype=float32), 'eval/episode_x_velocity_std': Array(154.59262, dtype=float32), 'eval/episode_y_position_std': Array(274.1243, dtype=float32), 'eval/episode_y_velocity_std': Array(78.65716, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58861780166626, 'eval/sps': 937.1205453287669, 'num_steps': 8847360}
{'eval/walltime': 15059.971554517746, 'training/sps': 2935.814202490423, 'training/walltime': 3060.3735613822937, 'training/entropy_loss': Array(0.01145364, dtype=float32), 'training/policy_loss': Array(0.00652896, dtype=float32), 'training/total_loss': Array(0.07749532, dtype=float32), 'training/v_loss': Array(0.05951272, dtype=float32), 'eval/episode_distance_from_origin': Array(4398.6777, dtype=float32), 'eval/episode_distance_reward': Array(9.804877, dtype=float32), 'eval/episode_forward_reward': Array(1634.1411, dtype=float32), 'eval/episode_reward': Array(1599.6196, dtype=float32), 'eval/episode_reward_alive': Array(428.64453, dtype=float32), 'eval/episode_reward_linvel': Array(1634.1411, dtype=float32), 'eval/episode_reward_quadctrl': Array(-472.97107, dtype=float32), 'eval/episode_x_position': Array(4355.042, dtype=float32), 'eval/episode_x_velocity': Array(326.82822, dtype=float32), 'eval/episode_y_position': Array(-148.54019, dtype=float32), 'eval/episode_y_velocity': Array(-48.23696, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.05963, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6433454, dtype=float32), 'eval/episode_forward_reward_std': Array(773.8854, dtype=float32), 'eval/episode_reward_std': Array(811.9279, dtype=float32), 'eval/episode_reward_alive_std': Array(31.048986, dtype=float32), 'eval/episode_reward_linvel_std': Array(773.8854, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.32955, dtype=float32), 'eval/episode_x_position_std': Array(418.73343, dtype=float32), 'eval/episode_x_velocity_std': Array(154.77704, dtype=float32), 'eval/episode_y_position_std': Array(292.6388, dtype=float32), 'eval/episode_y_velocity_std': Array(80.39119, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40318179130554, 'eval/sps': 938.3945324372106, 'num_steps': 8929280}
{'eval/walltime': 15196.743147611618, 'training/sps': 2934.874131890763, 'training/walltime': 3088.286172389984, 'training/entropy_loss': Array(0.01438577, dtype=float32), 'training/policy_loss': Array(0.02518495, dtype=float32), 'training/total_loss': Array(0.08031002, dtype=float32), 'training/v_loss': Array(0.04073929, dtype=float32), 'eval/episode_distance_from_origin': Array(4431.867, dtype=float32), 'eval/episode_distance_reward': Array(10.280649, dtype=float32), 'eval/episode_forward_reward': Array(1713.4354, dtype=float32), 'eval/episode_reward': Array(1693.8948, dtype=float32), 'eval/episode_reward_alive': Array(433.13672, dtype=float32), 'eval/episode_reward_linvel': Array(1713.4354, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.95795, dtype=float32), 'eval/episode_x_position': Array(4388.0576, dtype=float32), 'eval/episode_x_velocity': Array(342.68707, dtype=float32), 'eval/episode_y_position': Array(-164.37323, dtype=float32), 'eval/episode_y_velocity': Array(-54.53546, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.72205, dtype=float32), 'eval/episode_distance_reward_std': Array(5.013333, dtype=float32), 'eval/episode_forward_reward_std': Array(835.54926, dtype=float32), 'eval/episode_reward_std': Array(874.9202, dtype=float32), 'eval/episode_reward_alive_std': Array(29.128334, dtype=float32), 'eval/episode_reward_linvel_std': Array(835.54926, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.70672, dtype=float32), 'eval/episode_x_position_std': Array(442.0442, dtype=float32), 'eval/episode_x_velocity_std': Array(167.10982, dtype=float32), 'eval/episode_y_position_std': Array(283.1833, dtype=float32), 'eval/episode_y_velocity_std': Array(82.03058, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.77159309387207, 'eval/sps': 935.8668500128404, 'num_steps': 9011200}
{'eval/walltime': 15333.436896324158, 'training/sps': 2930.5401236386892, 'training/walltime': 3116.2400636672974, 'training/entropy_loss': Array(0.01514303, dtype=float32), 'training/policy_loss': Array(0.00360453, dtype=float32), 'training/total_loss': Array(0.04185693, dtype=float32), 'training/v_loss': Array(0.02310937, dtype=float32), 'eval/episode_distance_from_origin': Array(4371.7754, dtype=float32), 'eval/episode_distance_reward': Array(9.631857, dtype=float32), 'eval/episode_forward_reward': Array(1605.3047, dtype=float32), 'eval/episode_reward': Array(1579.5616, dtype=float32), 'eval/episode_reward_alive': Array(435.125, dtype=float32), 'eval/episode_reward_linvel': Array(1605.3047, dtype=float32), 'eval/episode_reward_quadctrl': Array(-470.5, dtype=float32), 'eval/episode_x_position': Array(4331.185, dtype=float32), 'eval/episode_x_velocity': Array(321.06097, dtype=float32), 'eval/episode_y_position': Array(-122.080215, dtype=float32), 'eval/episode_y_velocity': Array(-39.661694, dtype=float32), 'eval/episode_distance_from_origin_std': Array(412.81638, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7659955, dtype=float32), 'eval/episode_forward_reward_std': Array(794.3269, dtype=float32), 'eval/episode_reward_std': Array(831.5408, dtype=float32), 'eval/episode_reward_alive_std': Array(34.527954, dtype=float32), 'eval/episode_reward_linvel_std': Array(794.3269, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(71.37636, dtype=float32), 'eval/episode_x_position_std': Array(406.48853, dtype=float32), 'eval/episode_x_velocity_std': Array(158.86537, dtype=float32), 'eval/episode_y_position_std': Array(259.76025, dtype=float32), 'eval/episode_y_velocity_std': Array(74.29052, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69374871253967, 'eval/sps': 936.3998076399075, 'num_steps': 9093120}
{'eval/walltime': 15470.143034934998, 'training/sps': 2938.5590908665235, 'training/walltime': 3144.1176722049713, 'training/entropy_loss': Array(0.01588761, dtype=float32), 'training/policy_loss': Array(0.0098114, dtype=float32), 'training/total_loss': Array(0.04492385, dtype=float32), 'training/v_loss': Array(0.01922485, dtype=float32), 'eval/episode_distance_from_origin': Array(4321.815, dtype=float32), 'eval/episode_distance_reward': Array(8.9297695, dtype=float32), 'eval/episode_forward_reward': Array(1488.291, dtype=float32), 'eval/episode_reward': Array(1460.4059, dtype=float32), 'eval/episode_reward_alive': Array(436.36328, dtype=float32), 'eval/episode_reward_linvel': Array(1488.291, dtype=float32), 'eval/episode_reward_quadctrl': Array(-473.1781, dtype=float32), 'eval/episode_x_position': Array(4280.634, dtype=float32), 'eval/episode_x_velocity': Array(297.65814, dtype=float32), 'eval/episode_y_position': Array(-136.67386, dtype=float32), 'eval/episode_y_velocity': Array(-42.297928, dtype=float32), 'eval/episode_distance_from_origin_std': Array(406.13058, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2629113, dtype=float32), 'eval/episode_forward_reward_std': Array(710.4801, dtype=float32), 'eval/episode_reward_std': Array(737.14984, dtype=float32), 'eval/episode_reward_alive_std': Array(32.84229, dtype=float32), 'eval/episode_reward_linvel_std': Array(710.4801, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.45898, dtype=float32), 'eval/episode_x_position_std': Array(396.77353, dtype=float32), 'eval/episode_x_velocity_std': Array(142.09598, dtype=float32), 'eval/episode_y_position_std': Array(266.03848, dtype=float32), 'eval/episode_y_velocity_std': Array(73.99015, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70613861083984, 'eval/sps': 936.3149402118398, 'num_steps': 9175040}
{'eval/walltime': 15606.772383213043, 'training/sps': 2928.6523266449003, 'training/walltime': 3172.0895824432373, 'training/entropy_loss': Array(0.010392, dtype=float32), 'training/policy_loss': Array(0.00202348, dtype=float32), 'training/total_loss': Array(0.04723733, dtype=float32), 'training/v_loss': Array(0.03482185, dtype=float32), 'eval/episode_distance_from_origin': Array(4288.5938, dtype=float32), 'eval/episode_distance_reward': Array(8.66852, dtype=float32), 'eval/episode_forward_reward': Array(1444.7498, dtype=float32), 'eval/episode_reward': Array(1419.5867, dtype=float32), 'eval/episode_reward_alive': Array(431.33203, dtype=float32), 'eval/episode_reward_linvel': Array(1444.7498, dtype=float32), 'eval/episode_reward_quadctrl': Array(-465.16364, dtype=float32), 'eval/episode_x_position': Array(4244.404, dtype=float32), 'eval/episode_x_velocity': Array(288.94992, dtype=float32), 'eval/episode_y_position': Array(-107.82802, dtype=float32), 'eval/episode_y_velocity': Array(-37.56975, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.4196, dtype=float32), 'eval/episode_distance_reward_std': Array(4.339306, dtype=float32), 'eval/episode_forward_reward_std': Array(723.2125, dtype=float32), 'eval/episode_reward_std': Array(750.5445, dtype=float32), 'eval/episode_reward_alive_std': Array(33.23139, dtype=float32), 'eval/episode_reward_linvel_std': Array(723.2125, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.044437, dtype=float32), 'eval/episode_x_position_std': Array(418.4516, dtype=float32), 'eval/episode_x_velocity_std': Array(144.64247, dtype=float32), 'eval/episode_y_position_std': Array(312.10068, dtype=float32), 'eval/episode_y_velocity_std': Array(84.08478, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62934827804565, 'eval/sps': 936.8411809995272, 'num_steps': 9256960}
{'eval/walltime': 15743.289878606796, 'training/sps': 2932.6901322470667, 'training/walltime': 3200.0229802131653, 'training/entropy_loss': Array(0.0060585, dtype=float32), 'training/policy_loss': Array(0.0061435, dtype=float32), 'training/total_loss': Array(0.06638767, dtype=float32), 'training/v_loss': Array(0.05418567, dtype=float32), 'eval/episode_distance_from_origin': Array(4382.6377, dtype=float32), 'eval/episode_distance_reward': Array(9.548694, dtype=float32), 'eval/episode_forward_reward': Array(1591.4443, dtype=float32), 'eval/episode_reward': Array(1554.8833, dtype=float32), 'eval/episode_reward_alive': Array(436.6953, dtype=float32), 'eval/episode_reward_linvel': Array(1591.4443, dtype=float32), 'eval/episode_reward_quadctrl': Array(-482.80536, dtype=float32), 'eval/episode_x_position': Array(4337.5186, dtype=float32), 'eval/episode_x_velocity': Array(318.28888, dtype=float32), 'eval/episode_y_position': Array(-191.36313, dtype=float32), 'eval/episode_y_velocity': Array(-57.482193, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.05978, dtype=float32), 'eval/episode_distance_reward_std': Array(4.594815, dtype=float32), 'eval/episode_forward_reward_std': Array(765.7971, dtype=float32), 'eval/episode_reward_std': Array(801.14923, dtype=float32), 'eval/episode_reward_alive_std': Array(29.628508, dtype=float32), 'eval/episode_reward_linvel_std': Array(765.7971, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.643684, dtype=float32), 'eval/episode_x_position_std': Array(411.96292, dtype=float32), 'eval/episode_x_velocity_std': Array(153.15942, dtype=float32), 'eval/episode_y_position_std': Array(285.25, dtype=float32), 'eval/episode_y_velocity_std': Array(78.84511, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51749539375305, 'eval/sps': 937.6087631172378, 'num_steps': 9338880}
{'eval/walltime': 15879.922421455383, 'training/sps': 2934.0290138740497, 'training/walltime': 3227.94363117218, 'training/entropy_loss': Array(0.0105371, dtype=float32), 'training/policy_loss': Array(0.00401872, dtype=float32), 'training/total_loss': Array(0.0719946, dtype=float32), 'training/v_loss': Array(0.05743878, dtype=float32), 'eval/episode_distance_from_origin': Array(4422.1006, dtype=float32), 'eval/episode_distance_reward': Array(10.087799, dtype=float32), 'eval/episode_forward_reward': Array(1681.2944, dtype=float32), 'eval/episode_reward': Array(1658.5923, dtype=float32), 'eval/episode_reward_alive': Array(434.58594, dtype=float32), 'eval/episode_reward_linvel': Array(1681.2944, dtype=float32), 'eval/episode_reward_quadctrl': Array(-467.3759, dtype=float32), 'eval/episode_x_position': Array(4376.0176, dtype=float32), 'eval/episode_x_velocity': Array(336.25885, dtype=float32), 'eval/episode_y_position': Array(-184.60217, dtype=float32), 'eval/episode_y_velocity': Array(-60.488716, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.0035, dtype=float32), 'eval/episode_distance_reward_std': Array(5.445564, dtype=float32), 'eval/episode_forward_reward_std': Array(907.5878, dtype=float32), 'eval/episode_reward_std': Array(951.9522, dtype=float32), 'eval/episode_reward_alive_std': Array(31.050873, dtype=float32), 'eval/episode_reward_linvel_std': Array(907.5878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(76.39758, dtype=float32), 'eval/episode_x_position_std': Array(479.44894, dtype=float32), 'eval/episode_x_velocity_std': Array(181.51749, dtype=float32), 'eval/episode_y_position_std': Array(302.78894, dtype=float32), 'eval/episode_y_velocity_std': Array(85.52601, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63254284858704, 'eval/sps': 936.8192769554657, 'num_steps': 9420800}
{'eval/walltime': 16016.71968960762, 'training/sps': 2933.3019484709002, 'training/walltime': 3255.8712027072906, 'training/entropy_loss': Array(0.01163472, dtype=float32), 'training/policy_loss': Array(0.14341712, dtype=float32), 'training/total_loss': Array(0.19693953, dtype=float32), 'training/v_loss': Array(0.04188769, dtype=float32), 'eval/episode_distance_from_origin': Array(4690.6787, dtype=float32), 'eval/episode_distance_reward': Array(13.127557, dtype=float32), 'eval/episode_forward_reward': Array(2187.9177, dtype=float32), 'eval/episode_reward': Array(2165.9624, dtype=float32), 'eval/episode_reward_alive': Array(415.1836, dtype=float32), 'eval/episode_reward_linvel': Array(2187.9177, dtype=float32), 'eval/episode_reward_quadctrl': Array(-450.26636, dtype=float32), 'eval/episode_x_position': Array(4639.8525, dtype=float32), 'eval/episode_x_velocity': Array(437.5835, dtype=float32), 'eval/episode_y_position': Array(-255.33038, dtype=float32), 'eval/episode_y_velocity': Array(-89.11384, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.55978, dtype=float32), 'eval/episode_distance_reward_std': Array(5.921534, dtype=float32), 'eval/episode_forward_reward_std': Array(986.9149, dtype=float32), 'eval/episode_reward_std': Array(1037.8219, dtype=float32), 'eval/episode_reward_alive_std': Array(43.600586, dtype=float32), 'eval/episode_reward_linvel_std': Array(986.9149, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.78968, dtype=float32), 'eval/episode_x_position_std': Array(459.1595, dtype=float32), 'eval/episode_x_velocity_std': Array(197.38297, dtype=float32), 'eval/episode_y_position_std': Array(315.3151, dtype=float32), 'eval/episode_y_velocity_std': Array(96.05418, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.79726815223694, 'eval/sps': 935.6912000432146, 'num_steps': 9502720}
{'eval/walltime': 16153.184864521027, 'training/sps': 2923.7317632331738, 'training/walltime': 3283.890188932419, 'training/entropy_loss': Array(0.0127432, dtype=float32), 'training/policy_loss': Array(0.00185651, dtype=float32), 'training/total_loss': Array(0.04504461, dtype=float32), 'training/v_loss': Array(0.03044489, dtype=float32), 'eval/episode_distance_from_origin': Array(4661.1216, dtype=float32), 'eval/episode_distance_reward': Array(12.868784, dtype=float32), 'eval/episode_forward_reward': Array(2144.789, dtype=float32), 'eval/episode_reward': Array(2107.9585, dtype=float32), 'eval/episode_reward_alive': Array(414.35547, dtype=float32), 'eval/episode_reward_linvel': Array(2144.789, dtype=float32), 'eval/episode_reward_quadctrl': Array(-464.05463, dtype=float32), 'eval/episode_x_position': Array(4613.5728, dtype=float32), 'eval/episode_x_velocity': Array(428.95776, dtype=float32), 'eval/episode_y_position': Array(-214.48453, dtype=float32), 'eval/episode_y_velocity': Array(-77.7416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.89127, dtype=float32), 'eval/episode_distance_reward_std': Array(6.174733, dtype=float32), 'eval/episode_forward_reward_std': Array(1029.1151, dtype=float32), 'eval/episode_reward_std': Array(1089.7744, dtype=float32), 'eval/episode_reward_alive_std': Array(40.87147, dtype=float32), 'eval/episode_reward_linvel_std': Array(1029.1151, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.22027, dtype=float32), 'eval/episode_x_position_std': Array(483.46146, dtype=float32), 'eval/episode_x_velocity_std': Array(205.82301, dtype=float32), 'eval/episode_y_position_std': Array(307.77686, dtype=float32), 'eval/episode_y_velocity_std': Array(95.73993, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46517491340637, 'eval/sps': 937.9682404776315, 'num_steps': 9584640}
{'eval/walltime': 16289.852428913116, 'training/sps': 2926.763794112729, 'training/walltime': 3311.880148410797, 'training/entropy_loss': Array(0.01416989, dtype=float32), 'training/policy_loss': Array(0.00935669, dtype=float32), 'training/total_loss': Array(0.0537768, dtype=float32), 'training/v_loss': Array(0.03025022, dtype=float32), 'eval/episode_distance_from_origin': Array(4718.7256, dtype=float32), 'eval/episode_distance_reward': Array(13.718918, dtype=float32), 'eval/episode_forward_reward': Array(2286.4766, dtype=float32), 'eval/episode_reward': Array(2265.809, dtype=float32), 'eval/episode_reward_alive': Array(416.45703, dtype=float32), 'eval/episode_reward_linvel': Array(2286.4766, dtype=float32), 'eval/episode_reward_quadctrl': Array(-450.84363, dtype=float32), 'eval/episode_x_position': Array(4670.757, dtype=float32), 'eval/episode_x_velocity': Array(457.29532, dtype=float32), 'eval/episode_y_position': Array(-224.93576, dtype=float32), 'eval/episode_y_velocity': Array(-87.50536, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.7328, dtype=float32), 'eval/episode_distance_reward_std': Array(6.298774, dtype=float32), 'eval/episode_forward_reward_std': Array(1049.7878, dtype=float32), 'eval/episode_reward_std': Array(1107.5323, dtype=float32), 'eval/episode_reward_alive_std': Array(33.385418, dtype=float32), 'eval/episode_reward_linvel_std': Array(1049.7878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.35762, dtype=float32), 'eval/episode_x_position_std': Array(470.78992, dtype=float32), 'eval/episode_x_velocity_std': Array(209.95758, dtype=float32), 'eval/episode_y_position_std': Array(292.88092, dtype=float32), 'eval/episode_y_velocity_std': Array(98.78622, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66756439208984, 'eval/sps': 936.5792137246026, 'num_steps': 9666560}
{'eval/walltime': 16426.20376110077, 'training/sps': 2939.2872061331996, 'training/walltime': 3339.7508511543274, 'training/entropy_loss': Array(0.01165826, dtype=float32), 'training/policy_loss': Array(0.01167673, dtype=float32), 'training/total_loss': Array(0.04678117, dtype=float32), 'training/v_loss': Array(0.02344619, dtype=float32), 'eval/episode_distance_from_origin': Array(4583.1895, dtype=float32), 'eval/episode_distance_reward': Array(11.7692, dtype=float32), 'eval/episode_forward_reward': Array(1961.5264, dtype=float32), 'eval/episode_reward': Array(1928.8801, dtype=float32), 'eval/episode_reward_alive': Array(417.48828, dtype=float32), 'eval/episode_reward_linvel': Array(1961.5264, dtype=float32), 'eval/episode_reward_quadctrl': Array(-461.9035, dtype=float32), 'eval/episode_x_position': Array(4535.7007, dtype=float32), 'eval/episode_x_velocity': Array(392.3053, dtype=float32), 'eval/episode_y_position': Array(-195.71979, dtype=float32), 'eval/episode_y_velocity': Array(-67.22543, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.28894, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8119636, dtype=float32), 'eval/episode_forward_reward_std': Array(968.6543, dtype=float32), 'eval/episode_reward_std': Array(1016.6526, dtype=float32), 'eval/episode_reward_alive_std': Array(38.79455, dtype=float32), 'eval/episode_reward_linvel_std': Array(968.6543, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.9981, dtype=float32), 'eval/episode_x_position_std': Array(476.87216, dtype=float32), 'eval/episode_x_velocity_std': Array(193.7309, dtype=float32), 'eval/episode_y_position_std': Array(318.92856, dtype=float32), 'eval/episode_y_velocity_std': Array(91.2215, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3513321876526, 'eval/sps': 938.7513707885221, 'num_steps': 9748480}
{'eval/walltime': 16562.70863676071, 'training/sps': 2929.5897138900486, 'training/walltime': 3367.713811159134, 'training/entropy_loss': Array(0.0067938, dtype=float32), 'training/policy_loss': Array(0.00340711, dtype=float32), 'training/total_loss': Array(0.07265832, dtype=float32), 'training/v_loss': Array(0.06245741, dtype=float32), 'eval/episode_distance_from_origin': Array(4642.389, dtype=float32), 'eval/episode_distance_reward': Array(12.322497, dtype=float32), 'eval/episode_forward_reward': Array(2053.7424, dtype=float32), 'eval/episode_reward': Array(2019.2755, dtype=float32), 'eval/episode_reward_alive': Array(415.9414, dtype=float32), 'eval/episode_reward_linvel': Array(2053.7424, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.7307, dtype=float32), 'eval/episode_x_position': Array(4592.1206, dtype=float32), 'eval/episode_x_velocity': Array(410.74847, dtype=float32), 'eval/episode_y_position': Array(-217.19946, dtype=float32), 'eval/episode_y_velocity': Array(-77.540344, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.96936, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8334136, dtype=float32), 'eval/episode_forward_reward_std': Array(972.229, dtype=float32), 'eval/episode_reward_std': Array(1023.5017, dtype=float32), 'eval/episode_reward_alive_std': Array(45.00927, dtype=float32), 'eval/episode_reward_linvel_std': Array(972.229, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.55774, dtype=float32), 'eval/episode_x_position_std': Array(474.6253, dtype=float32), 'eval/episode_x_velocity_std': Array(194.44576, dtype=float32), 'eval/episode_y_position_std': Array(338.3295, dtype=float32), 'eval/episode_y_velocity_std': Array(100.56817, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50487565994263, 'eval/sps': 937.6954440724172, 'num_steps': 9830400}
{'eval/walltime': 16699.555199861526, 'training/sps': 2951.856323089767, 'training/walltime': 3395.4658393859863, 'training/entropy_loss': Array(0.00992342, dtype=float32), 'training/policy_loss': Array(0.01228225, dtype=float32), 'training/total_loss': Array(0.10447341, dtype=float32), 'training/v_loss': Array(0.08226775, dtype=float32), 'eval/episode_distance_from_origin': Array(4720.6436, dtype=float32), 'eval/episode_distance_reward': Array(13.29157, dtype=float32), 'eval/episode_forward_reward': Array(2215.2524, dtype=float32), 'eval/episode_reward': Array(2183.9285, dtype=float32), 'eval/episode_reward_alive': Array(418.1797, dtype=float32), 'eval/episode_reward_linvel': Array(2215.2524, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.79553, dtype=float32), 'eval/episode_x_position': Array(4672.818, dtype=float32), 'eval/episode_x_velocity': Array(443.05054, dtype=float32), 'eval/episode_y_position': Array(-240.43921, dtype=float32), 'eval/episode_y_velocity': Array(-84.51949, dtype=float32), 'eval/episode_distance_from_origin_std': Array(553.64856, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6783257, dtype=float32), 'eval/episode_forward_reward_std': Array(1113.0466, dtype=float32), 'eval/episode_reward_std': Array(1172.305, dtype=float32), 'eval/episode_reward_alive_std': Array(37.14965, dtype=float32), 'eval/episode_reward_linvel_std': Array(1113.0466, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.927246, dtype=float32), 'eval/episode_x_position_std': Array(543.5058, dtype=float32), 'eval/episode_x_velocity_std': Array(222.60931, dtype=float32), 'eval/episode_y_position_std': Array(295.3782, dtype=float32), 'eval/episode_y_velocity_std': Array(89.899506, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.84656310081482, 'eval/sps': 935.3541448147473, 'num_steps': 9912320}
{'eval/walltime': 16836.339416265488, 'training/sps': 2920.401262449102, 'training/walltime': 3423.5167791843414, 'training/entropy_loss': Array(0.01258163, dtype=float32), 'training/policy_loss': Array(0.01536853, dtype=float32), 'training/total_loss': Array(0.09308767, dtype=float32), 'training/v_loss': Array(0.06513751, dtype=float32), 'eval/episode_distance_from_origin': Array(4667.3, dtype=float32), 'eval/episode_distance_reward': Array(12.077321, dtype=float32), 'eval/episode_forward_reward': Array(2012.8795, dtype=float32), 'eval/episode_reward': Array(1967.1537, dtype=float32), 'eval/episode_reward_alive': Array(425.58984, dtype=float32), 'eval/episode_reward_linvel': Array(2012.8795, dtype=float32), 'eval/episode_reward_quadctrl': Array(-483.3933, dtype=float32), 'eval/episode_x_position': Array(4618.797, dtype=float32), 'eval/episode_x_velocity': Array(402.57593, dtype=float32), 'eval/episode_y_position': Array(-184.72261, dtype=float32), 'eval/episode_y_velocity': Array(-66.09801, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.2398, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8640776, dtype=float32), 'eval/episode_forward_reward_std': Array(977.3393, dtype=float32), 'eval/episode_reward_std': Array(1027.5038, dtype=float32), 'eval/episode_reward_alive_std': Array(33.172752, dtype=float32), 'eval/episode_reward_linvel_std': Array(977.3393, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.51416, dtype=float32), 'eval/episode_x_position_std': Array(496.44308, dtype=float32), 'eval/episode_x_velocity_std': Array(195.46786, dtype=float32), 'eval/episode_y_position_std': Array(344.62518, dtype=float32), 'eval/episode_y_velocity_std': Array(95.988365, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.78421640396118, 'eval/sps': 935.7804823180842, 'num_steps': 9994240}
{'eval/walltime': 16973.08427810669, 'training/sps': 2946.0704550911823, 'training/walltime': 3451.3233103752136, 'training/entropy_loss': Array(0.01523361, dtype=float32), 'training/policy_loss': Array(0.01316581, dtype=float32), 'training/total_loss': Array(0.07315361, dtype=float32), 'training/v_loss': Array(0.0447542, dtype=float32), 'eval/episode_distance_from_origin': Array(4668.7593, dtype=float32), 'eval/episode_distance_reward': Array(12.544381, dtype=float32), 'eval/episode_forward_reward': Array(2090.722, dtype=float32), 'eval/episode_reward': Array(2062.835, dtype=float32), 'eval/episode_reward_alive': Array(428.60156, dtype=float32), 'eval/episode_reward_linvel': Array(2090.722, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.0332, dtype=float32), 'eval/episode_x_position': Array(4619.343, dtype=float32), 'eval/episode_x_velocity': Array(418.1444, dtype=float32), 'eval/episode_y_position': Array(-220.86905, dtype=float32), 'eval/episode_y_velocity': Array(-77.9662, dtype=float32), 'eval/episode_distance_from_origin_std': Array(560.3527, dtype=float32), 'eval/episode_distance_reward_std': Array(6.435704, dtype=float32), 'eval/episode_forward_reward_std': Array(1072.6101, dtype=float32), 'eval/episode_reward_std': Array(1124.11, dtype=float32), 'eval/episode_reward_alive_std': Array(32.073788, dtype=float32), 'eval/episode_reward_linvel_std': Array(1072.6101, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.33255, dtype=float32), 'eval/episode_x_position_std': Array(545.95233, dtype=float32), 'eval/episode_x_velocity_std': Array(214.52202, dtype=float32), 'eval/episode_y_position_std': Array(326.78867, dtype=float32), 'eval/episode_y_velocity_std': Array(96.56107, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.74486184120178, 'eval/sps': 936.0497957769195, 'num_steps': 10076160}
{'eval/walltime': 17109.836733579636, 'training/sps': 2926.7655890871424, 'training/walltime': 3479.313252687454, 'training/entropy_loss': Array(0.01668982, dtype=float32), 'training/policy_loss': Array(0.02621472, dtype=float32), 'training/total_loss': Array(0.07816582, dtype=float32), 'training/v_loss': Array(0.03526128, dtype=float32), 'eval/episode_distance_from_origin': Array(4707.5864, dtype=float32), 'eval/episode_distance_reward': Array(12.582111, dtype=float32), 'eval/episode_forward_reward': Array(2097.0103, dtype=float32), 'eval/episode_reward': Array(2057.527, dtype=float32), 'eval/episode_reward_alive': Array(422.39844, dtype=float32), 'eval/episode_reward_linvel': Array(2097.0103, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.46375, dtype=float32), 'eval/episode_x_position': Array(4654.207, dtype=float32), 'eval/episode_x_velocity': Array(419.4021, dtype=float32), 'eval/episode_y_position': Array(-262.50787, dtype=float32), 'eval/episode_y_velocity': Array(-85.36955, dtype=float32), 'eval/episode_distance_from_origin_std': Array(568.8749, dtype=float32), 'eval/episode_distance_reward_std': Array(6.278037, dtype=float32), 'eval/episode_forward_reward_std': Array(1046.3319, dtype=float32), 'eval/episode_reward_std': Array(1097.8685, dtype=float32), 'eval/episode_reward_alive_std': Array(35.71635, dtype=float32), 'eval/episode_reward_linvel_std': Array(1046.3319, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.93572, dtype=float32), 'eval/episode_x_position_std': Array(555.1443, dtype=float32), 'eval/episode_x_velocity_std': Array(209.26646, dtype=float32), 'eval/episode_y_position_std': Array(349.1525, dtype=float32), 'eval/episode_y_velocity_std': Array(97.50135, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.75245547294617, 'eval/sps': 935.9978185205042, 'num_steps': 10158080}
{'eval/walltime': 17246.490101099014, 'training/sps': 2934.4422143121114, 'training/walltime': 3507.2299721240997, 'training/entropy_loss': Array(0.01751939, dtype=float32), 'training/policy_loss': Array(0.00814036, dtype=float32), 'training/total_loss': Array(0.05208359, dtype=float32), 'training/v_loss': Array(0.02642383, dtype=float32), 'eval/episode_distance_from_origin': Array(4757.6953, dtype=float32), 'eval/episode_distance_reward': Array(13.326115, dtype=float32), 'eval/episode_forward_reward': Array(2221.0103, dtype=float32), 'eval/episode_reward': Array(2188.1958, dtype=float32), 'eval/episode_reward_alive': Array(420.05078, dtype=float32), 'eval/episode_reward_linvel': Array(2221.0103, dtype=float32), 'eval/episode_reward_quadctrl': Array(-466.19144, dtype=float32), 'eval/episode_x_position': Array(4705.6953, dtype=float32), 'eval/episode_x_velocity': Array(444.2021, dtype=float32), 'eval/episode_y_position': Array(-261.60016, dtype=float32), 'eval/episode_y_velocity': Array(-92.83122, dtype=float32), 'eval/episode_distance_from_origin_std': Array(522.7053, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2181463, dtype=float32), 'eval/episode_forward_reward_std': Array(1036.3505, dtype=float32), 'eval/episode_reward_std': Array(1086.6365, dtype=float32), 'eval/episode_reward_alive_std': Array(31.774832, dtype=float32), 'eval/episode_reward_linvel_std': Array(1036.3505, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.525604, dtype=float32), 'eval/episode_x_position_std': Array(511.081, dtype=float32), 'eval/episode_x_velocity_std': Array(207.27013, dtype=float32), 'eval/episode_y_position_std': Array(331.4574, dtype=float32), 'eval/episode_y_velocity_std': Array(94.45391, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65336751937866, 'eval/sps': 936.6765146263115, 'num_steps': 10240000}
{'eval/walltime': 17383.188069581985, 'training/sps': 2928.5251489012107, 'training/walltime': 3535.2030971050262, 'training/entropy_loss': Array(0.00548365, dtype=float32), 'training/policy_loss': Array(-0.00100555, dtype=float32), 'training/total_loss': Array(0.06370672, dtype=float32), 'training/v_loss': Array(0.05922863, dtype=float32), 'eval/episode_distance_from_origin': Array(4677.873, dtype=float32), 'eval/episode_distance_reward': Array(12.596902, dtype=float32), 'eval/episode_forward_reward': Array(2099.476, dtype=float32), 'eval/episode_reward': Array(2056.6426, dtype=float32), 'eval/episode_reward_alive': Array(412.77734, dtype=float32), 'eval/episode_reward_linvel': Array(2099.476, dtype=float32), 'eval/episode_reward_quadctrl': Array(-468.20813, dtype=float32), 'eval/episode_x_position': Array(4630.3594, dtype=float32), 'eval/episode_x_velocity': Array(419.8952, dtype=float32), 'eval/episode_y_position': Array(-199.4151, dtype=float32), 'eval/episode_y_velocity': Array(-72.74907, dtype=float32), 'eval/episode_distance_from_origin_std': Array(534.59247, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2022734, dtype=float32), 'eval/episode_forward_reward_std': Array(1033.7053, dtype=float32), 'eval/episode_reward_std': Array(1086.2217, dtype=float32), 'eval/episode_reward_alive_std': Array(35.926075, dtype=float32), 'eval/episode_reward_linvel_std': Array(1033.7053, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.87184, dtype=float32), 'eval/episode_x_position_std': Array(525.523, dtype=float32), 'eval/episode_x_velocity_std': Array(206.74112, dtype=float32), 'eval/episode_y_position_std': Array(315.6829, dtype=float32), 'eval/episode_y_velocity_std': Array(96.03545, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6979684829712, 'eval/sps': 936.3709016344693, 'num_steps': 10321920}
{'eval/walltime': 17519.713210105896, 'training/sps': 2938.558512841342, 'training/walltime': 3563.0807111263275, 'training/entropy_loss': Array(0.00900414, dtype=float32), 'training/policy_loss': Array(0.00476333, dtype=float32), 'training/total_loss': Array(0.08664964, dtype=float32), 'training/v_loss': Array(0.07288217, dtype=float32), 'eval/episode_distance_from_origin': Array(4627.241, dtype=float32), 'eval/episode_distance_reward': Array(11.774183, dtype=float32), 'eval/episode_forward_reward': Array(1962.3568, dtype=float32), 'eval/episode_reward': Array(1915.9977, dtype=float32), 'eval/episode_reward_alive': Array(422.64844, dtype=float32), 'eval/episode_reward_linvel': Array(1962.3568, dtype=float32), 'eval/episode_reward_quadctrl': Array(-480.78186, dtype=float32), 'eval/episode_x_position': Array(4579.954, dtype=float32), 'eval/episode_x_velocity': Array(392.47137, dtype=float32), 'eval/episode_y_position': Array(-233.91977, dtype=float32), 'eval/episode_y_velocity': Array(-73.43142, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.9296, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9346375, dtype=float32), 'eval/episode_forward_reward_std': Array(989.0994, dtype=float32), 'eval/episode_reward_std': Array(1037.5244, dtype=float32), 'eval/episode_reward_alive_std': Array(33.365772, dtype=float32), 'eval/episode_reward_linvel_std': Array(989.0994, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.59691, dtype=float32), 'eval/episode_x_position_std': Array(517.12683, dtype=float32), 'eval/episode_x_velocity_std': Array(197.8199, dtype=float32), 'eval/episode_y_position_std': Array(302.2949, dtype=float32), 'eval/episode_y_velocity_std': Array(86.80621, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52514052391052, 'eval/sps': 937.556258933735, 'num_steps': 10403840}
{'eval/walltime': 17656.398981571198, 'training/sps': 2928.7433921961538, 'training/walltime': 3591.051751613617, 'training/entropy_loss': Array(0.01251042, dtype=float32), 'training/policy_loss': Array(0.00265889, dtype=float32), 'training/total_loss': Array(0.08432579, dtype=float32), 'training/v_loss': Array(0.06915648, dtype=float32), 'eval/episode_distance_from_origin': Array(4586.1343, dtype=float32), 'eval/episode_distance_reward': Array(11.623568, dtype=float32), 'eval/episode_forward_reward': Array(1937.2545, dtype=float32), 'eval/episode_reward': Array(1895.9436, dtype=float32), 'eval/episode_reward_alive': Array(427.76953, dtype=float32), 'eval/episode_reward_linvel': Array(1937.2545, dtype=float32), 'eval/episode_reward_quadctrl': Array(-480.70398, dtype=float32), 'eval/episode_x_position': Array(4539.137, dtype=float32), 'eval/episode_x_velocity': Array(387.45093, dtype=float32), 'eval/episode_y_position': Array(-188.20074, dtype=float32), 'eval/episode_y_velocity': Array(-62.170258, dtype=float32), 'eval/episode_distance_from_origin_std': Array(540.1943, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3763227, dtype=float32), 'eval/episode_forward_reward_std': Array(1062.7131, dtype=float32), 'eval/episode_reward_std': Array(1109.3737, dtype=float32), 'eval/episode_reward_alive_std': Array(29.477541, dtype=float32), 'eval/episode_reward_linvel_std': Array(1062.7131, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.70248, dtype=float32), 'eval/episode_x_position_std': Array(529.75055, dtype=float32), 'eval/episode_x_velocity_std': Array(212.54262, dtype=float32), 'eval/episode_y_position_std': Array(316.10965, dtype=float32), 'eval/episode_y_velocity_std': Array(93.414276, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6857714653015, 'eval/sps': 936.4544577523459, 'num_steps': 10485760}
{'eval/walltime': 17792.813474178314, 'training/sps': 2938.843079518395, 'training/walltime': 3618.9266662597656, 'training/entropy_loss': Array(0.01497263, dtype=float32), 'training/policy_loss': Array(0.02825905, dtype=float32), 'training/total_loss': Array(0.09041798, dtype=float32), 'training/v_loss': Array(0.0471863, dtype=float32), 'eval/episode_distance_from_origin': Array(4636.4746, dtype=float32), 'eval/episode_distance_reward': Array(11.973588, dtype=float32), 'eval/episode_forward_reward': Array(1995.5906, dtype=float32), 'eval/episode_reward': Array(1957.1145, dtype=float32), 'eval/episode_reward_alive': Array(424.3789, dtype=float32), 'eval/episode_reward_linvel': Array(1995.5906, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.82883, dtype=float32), 'eval/episode_x_position': Array(4591.0986, dtype=float32), 'eval/episode_x_velocity': Array(399.11813, dtype=float32), 'eval/episode_y_position': Array(-211.383, dtype=float32), 'eval/episode_y_velocity': Array(-72.581566, dtype=float32), 'eval/episode_distance_from_origin_std': Array(534.17615, dtype=float32), 'eval/episode_distance_reward_std': Array(6.033332, dtype=float32), 'eval/episode_forward_reward_std': Array(1005.5486, dtype=float32), 'eval/episode_reward_std': Array(1054.6018, dtype=float32), 'eval/episode_reward_alive_std': Array(30.817617, dtype=float32), 'eval/episode_reward_linvel_std': Array(1005.5486, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.84434, dtype=float32), 'eval/episode_x_position_std': Array(521.0679, dtype=float32), 'eval/episode_x_velocity_std': Array(201.10973, dtype=float32), 'eval/episode_y_position_std': Array(290.78333, dtype=float32), 'eval/episode_y_velocity_std': Array(88.20274, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4144926071167, 'eval/sps': 938.3167253984441, 'num_steps': 10567680}
{'eval/walltime': 17929.56723999977, 'training/sps': 2938.32598924402, 'training/walltime': 3646.8064863681793, 'training/entropy_loss': Array(0.01607759, dtype=float32), 'training/policy_loss': Array(0.05391745, dtype=float32), 'training/total_loss': Array(0.10364686, dtype=float32), 'training/v_loss': Array(0.03365183, dtype=float32), 'eval/episode_distance_from_origin': Array(4619.167, dtype=float32), 'eval/episode_distance_reward': Array(11.682463, dtype=float32), 'eval/episode_forward_reward': Array(1947.0702, dtype=float32), 'eval/episode_reward': Array(1904.9009, dtype=float32), 'eval/episode_reward_alive': Array(417.8828, dtype=float32), 'eval/episode_reward_linvel': Array(1947.0702, dtype=float32), 'eval/episode_reward_quadctrl': Array(-471.73468, dtype=float32), 'eval/episode_x_position': Array(4575.038, dtype=float32), 'eval/episode_x_velocity': Array(389.41406, dtype=float32), 'eval/episode_y_position': Array(-210.32076, dtype=float32), 'eval/episode_y_velocity': Array(-72.76209, dtype=float32), 'eval/episode_distance_from_origin_std': Array(498.54422, dtype=float32), 'eval/episode_distance_reward_std': Array(5.539311, dtype=float32), 'eval/episode_forward_reward_std': Array(923.2123, dtype=float32), 'eval/episode_reward_std': Array(970.72253, dtype=float32), 'eval/episode_reward_alive_std': Array(40.737274, dtype=float32), 'eval/episode_reward_linvel_std': Array(923.2123, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.427994, dtype=float32), 'eval/episode_x_position_std': Array(485.8661, dtype=float32), 'eval/episode_x_velocity_std': Array(184.64249, dtype=float32), 'eval/episode_y_position_std': Array(263.38525, dtype=float32), 'eval/episode_y_velocity_std': Array(84.84319, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7537658214569, 'eval/sps': 935.9888499678638, 'num_steps': 10649600}
{'eval/walltime': 18065.957282066345, 'training/sps': 2936.942565317318, 'training/walltime': 3674.699439048767, 'training/entropy_loss': Array(0.01615787, dtype=float32), 'training/policy_loss': Array(0.01334966, dtype=float32), 'training/total_loss': Array(0.05230375, dtype=float32), 'training/v_loss': Array(0.02279622, dtype=float32), 'eval/episode_distance_from_origin': Array(4634.2803, dtype=float32), 'eval/episode_distance_reward': Array(12.19316, dtype=float32), 'eval/episode_forward_reward': Array(2032.1859, dtype=float32), 'eval/episode_reward': Array(1991.4565, dtype=float32), 'eval/episode_reward_alive': Array(413.33984, dtype=float32), 'eval/episode_reward_linvel': Array(2032.1859, dtype=float32), 'eval/episode_reward_quadctrl': Array(-466.26245, dtype=float32), 'eval/episode_x_position': Array(4588.067, dtype=float32), 'eval/episode_x_velocity': Array(406.43716, dtype=float32), 'eval/episode_y_position': Array(-204.74576, dtype=float32), 'eval/episode_y_velocity': Array(-71.13427, dtype=float32), 'eval/episode_distance_from_origin_std': Array(582.942, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6556334, dtype=float32), 'eval/episode_forward_reward_std': Array(1109.265, dtype=float32), 'eval/episode_reward_std': Array(1153.9795, dtype=float32), 'eval/episode_reward_alive_std': Array(39.717457, dtype=float32), 'eval/episode_reward_linvel_std': Array(1109.265, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.106247, dtype=float32), 'eval/episode_x_position_std': Array(570.8959, dtype=float32), 'eval/episode_x_velocity_std': Array(221.85298, dtype=float32), 'eval/episode_y_position_std': Array(310.3609, dtype=float32), 'eval/episode_y_velocity_std': Array(93.183846, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3900420665741, 'eval/sps': 938.4849367340265, 'num_steps': 10731520}
{'eval/walltime': 18202.804746627808, 'training/sps': 2935.244014732611, 'training/walltime': 3702.60853266716, 'training/entropy_loss': Array(0.00864332, dtype=float32), 'training/policy_loss': Array(-0.00094072, dtype=float32), 'training/total_loss': Array(0.04658636, dtype=float32), 'training/v_loss': Array(0.03888377, dtype=float32), 'eval/episode_distance_from_origin': Array(4687.2515, dtype=float32), 'eval/episode_distance_reward': Array(12.516708, dtype=float32), 'eval/episode_forward_reward': Array(2086.1104, dtype=float32), 'eval/episode_reward': Array(2040.3176, dtype=float32), 'eval/episode_reward_alive': Array(411.67188, dtype=float32), 'eval/episode_reward_linvel': Array(2086.1104, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.98157, dtype=float32), 'eval/episode_x_position': Array(4637.6875, dtype=float32), 'eval/episode_x_velocity': Array(417.2221, dtype=float32), 'eval/episode_y_position': Array(-240.31094, dtype=float32), 'eval/episode_y_velocity': Array(-82.49191, dtype=float32), 'eval/episode_distance_from_origin_std': Array(522.15765, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2020907, dtype=float32), 'eval/episode_forward_reward_std': Array(1033.675, dtype=float32), 'eval/episode_reward_std': Array(1079.9489, dtype=float32), 'eval/episode_reward_alive_std': Array(36.078552, dtype=float32), 'eval/episode_reward_linvel_std': Array(1033.675, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.508656, dtype=float32), 'eval/episode_x_position_std': Array(509.46136, dtype=float32), 'eval/episode_x_velocity_std': Array(206.73495, dtype=float32), 'eval/episode_y_position_std': Array(326.96194, dtype=float32), 'eval/episode_y_velocity_std': Array(94.72004, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8474645614624, 'eval/sps': 935.347983319861, 'num_steps': 10813440}
{'eval/walltime': 18339.180168628693, 'training/sps': 2937.4465371041692, 'training/walltime': 3730.496699810028, 'training/entropy_loss': Array(0.00730767, dtype=float32), 'training/policy_loss': Array(0.01928935, dtype=float32), 'training/total_loss': Array(0.09266051, dtype=float32), 'training/v_loss': Array(0.06606349, dtype=float32), 'eval/episode_distance_from_origin': Array(4641.856, dtype=float32), 'eval/episode_distance_reward': Array(11.895166, dtype=float32), 'eval/episode_forward_reward': Array(1982.5206, dtype=float32), 'eval/episode_reward': Array(1941.0271, dtype=float32), 'eval/episode_reward_alive': Array(416.9375, dtype=float32), 'eval/episode_reward_linvel': Array(1982.5206, dtype=float32), 'eval/episode_reward_quadctrl': Array(-470.3261, dtype=float32), 'eval/episode_x_position': Array(4595.0186, dtype=float32), 'eval/episode_x_velocity': Array(396.5041, dtype=float32), 'eval/episode_y_position': Array(-214.88101, dtype=float32), 'eval/episode_y_velocity': Array(-67.91597, dtype=float32), 'eval/episode_distance_from_origin_std': Array(541.84106, dtype=float32), 'eval/episode_distance_reward_std': Array(6.121407, dtype=float32), 'eval/episode_forward_reward_std': Array(1020.2277, dtype=float32), 'eval/episode_reward_std': Array(1066.9617, dtype=float32), 'eval/episode_reward_alive_std': Array(36.702137, dtype=float32), 'eval/episode_reward_linvel_std': Array(1020.2277, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.271572, dtype=float32), 'eval/episode_x_position_std': Array(526.596, dtype=float32), 'eval/episode_x_velocity_std': Array(204.04561, dtype=float32), 'eval/episode_y_position_std': Array(313.4665, dtype=float32), 'eval/episode_y_velocity_std': Array(90.063194, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.375422000885, 'eval/sps': 938.5855465889546, 'num_steps': 10895360}
{'eval/walltime': 18475.7282538414, 'training/sps': 2932.698667927566, 'training/walltime': 3758.4300162792206, 'training/entropy_loss': Array(0.01119303, dtype=float32), 'training/policy_loss': Array(0.00319251, dtype=float32), 'training/total_loss': Array(0.07638884, dtype=float32), 'training/v_loss': Array(0.0620033, dtype=float32), 'eval/episode_distance_from_origin': Array(4708.9043, dtype=float32), 'eval/episode_distance_reward': Array(12.780628, dtype=float32), 'eval/episode_forward_reward': Array(2130.0962, dtype=float32), 'eval/episode_reward': Array(2099.8755, dtype=float32), 'eval/episode_reward_alive': Array(420.2539, dtype=float32), 'eval/episode_reward_linvel': Array(2130.0962, dtype=float32), 'eval/episode_reward_quadctrl': Array(-463.2551, dtype=float32), 'eval/episode_x_position': Array(4654.6973, dtype=float32), 'eval/episode_x_velocity': Array(426.01926, dtype=float32), 'eval/episode_y_position': Array(-291.50092, dtype=float32), 'eval/episode_y_velocity': Array(-93.402725, dtype=float32), 'eval/episode_distance_from_origin_std': Array(556.03546, dtype=float32), 'eval/episode_distance_reward_std': Array(6.286421, dtype=float32), 'eval/episode_forward_reward_std': Array(1047.7303, dtype=float32), 'eval/episode_reward_std': Array(1098.16, dtype=float32), 'eval/episode_reward_alive_std': Array(35.885777, dtype=float32), 'eval/episode_reward_linvel_std': Array(1047.7303, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.412224, dtype=float32), 'eval/episode_x_position_std': Array(541.2457, dtype=float32), 'eval/episode_x_velocity_std': Array(209.54607, dtype=float32), 'eval/episode_y_position_std': Array(329.44446, dtype=float32), 'eval/episode_y_velocity_std': Array(95.51178, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54808521270752, 'eval/sps': 937.3987178260921, 'num_steps': 10977280}
{'eval/walltime': 18612.077750205994, 'training/sps': 2945.2125157158844, 'training/walltime': 3786.244647502899, 'training/entropy_loss': Array(0.01475018, dtype=float32), 'training/policy_loss': Array(0.00245451, dtype=float32), 'training/total_loss': Array(0.07025519, dtype=float32), 'training/v_loss': Array(0.0530505, dtype=float32), 'eval/episode_distance_from_origin': Array(4702.4575, dtype=float32), 'eval/episode_distance_reward': Array(12.562853, dtype=float32), 'eval/episode_forward_reward': Array(2093.801, dtype=float32), 'eval/episode_reward': Array(2064.864, dtype=float32), 'eval/episode_reward_alive': Array(420.5664, dtype=float32), 'eval/episode_reward_linvel': Array(2093.801, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.06647, dtype=float32), 'eval/episode_x_position': Array(4651.887, dtype=float32), 'eval/episode_x_velocity': Array(418.76022, dtype=float32), 'eval/episode_y_position': Array(-241.1007, dtype=float32), 'eval/episode_y_velocity': Array(-80.27383, dtype=float32), 'eval/episode_distance_from_origin_std': Array(565.0277, dtype=float32), 'eval/episode_distance_reward_std': Array(6.222099, dtype=float32), 'eval/episode_forward_reward_std': Array(1037.0101, dtype=float32), 'eval/episode_reward_std': Array(1086.8232, dtype=float32), 'eval/episode_reward_alive_std': Array(35.129467, dtype=float32), 'eval/episode_reward_linvel_std': Array(1037.0101, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.94335, dtype=float32), 'eval/episode_x_position_std': Array(549.70654, dtype=float32), 'eval/episode_x_velocity_std': Array(207.402, dtype=float32), 'eval/episode_y_position_std': Array(334.26077, dtype=float32), 'eval/episode_y_velocity_std': Array(96.80587, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3494963645935, 'eval/sps': 938.7640102295115, 'num_steps': 11059200}
{'eval/walltime': 18748.621477365494, 'training/sps': 2935.0938992037004, 'training/walltime': 3814.155168533325, 'training/entropy_loss': Array(0.0167243, dtype=float32), 'training/policy_loss': Array(0.00617361, dtype=float32), 'training/total_loss': Array(0.05886145, dtype=float32), 'training/v_loss': Array(0.03596354, dtype=float32), 'eval/episode_distance_from_origin': Array(4840.5874, dtype=float32), 'eval/episode_distance_reward': Array(14.15368, dtype=float32), 'eval/episode_forward_reward': Array(2358.937, dtype=float32), 'eval/episode_reward': Array(2343.332, dtype=float32), 'eval/episode_reward_alive': Array(418.3711, dtype=float32), 'eval/episode_reward_linvel': Array(2358.937, dtype=float32), 'eval/episode_reward_quadctrl': Array(-448.12964, dtype=float32), 'eval/episode_x_position': Array(4786.391, dtype=float32), 'eval/episode_x_velocity': Array(471.78735, dtype=float32), 'eval/episode_y_position': Array(-301.7171, dtype=float32), 'eval/episode_y_velocity': Array(-103.82919, dtype=float32), 'eval/episode_distance_from_origin_std': Array(581.2145, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6896143, dtype=float32), 'eval/episode_forward_reward_std': Array(1114.9286, dtype=float32), 'eval/episode_reward_std': Array(1164.7876, dtype=float32), 'eval/episode_reward_alive_std': Array(34.413002, dtype=float32), 'eval/episode_reward_linvel_std': Array(1114.9286, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.958557, dtype=float32), 'eval/episode_x_position_std': Array(567.3547, dtype=float32), 'eval/episode_x_velocity_std': Array(222.98573, dtype=float32), 'eval/episode_y_position_std': Array(325.71487, dtype=float32), 'eval/episode_y_velocity_std': Array(92.46783, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54372715950012, 'eval/sps': 937.4286366921859, 'num_steps': 11141120}
{'eval/walltime': 18884.998284101486, 'training/sps': 2930.269607494902, 'training/walltime': 3842.1116404533386, 'training/entropy_loss': Array(0.01786039, dtype=float32), 'training/policy_loss': Array(0.00748324, dtype=float32), 'training/total_loss': Array(0.05334058, dtype=float32), 'training/v_loss': Array(0.02799695, dtype=float32), 'eval/episode_distance_from_origin': Array(4670.1177, dtype=float32), 'eval/episode_distance_reward': Array(12.126743, dtype=float32), 'eval/episode_forward_reward': Array(2021.1166, dtype=float32), 'eval/episode_reward': Array(1990.3425, dtype=float32), 'eval/episode_reward_alive': Array(424.66406, dtype=float32), 'eval/episode_reward_linvel': Array(2021.1166, dtype=float32), 'eval/episode_reward_quadctrl': Array(-467.56464, dtype=float32), 'eval/episode_x_position': Array(4617.3105, dtype=float32), 'eval/episode_x_velocity': Array(404.22327, dtype=float32), 'eval/episode_y_position': Array(-258.54968, dtype=float32), 'eval/episode_y_velocity': Array(-86.55663, dtype=float32), 'eval/episode_distance_from_origin_std': Array(567.9513, dtype=float32), 'eval/episode_distance_reward_std': Array(6.051272, dtype=float32), 'eval/episode_forward_reward_std': Array(1008.53864, dtype=float32), 'eval/episode_reward_std': Array(1053.9064, dtype=float32), 'eval/episode_reward_alive_std': Array(37.980675, dtype=float32), 'eval/episode_reward_linvel_std': Array(1008.53864, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.591625, dtype=float32), 'eval/episode_x_position_std': Array(553.3036, dtype=float32), 'eval/episode_x_velocity_std': Array(201.7077, dtype=float32), 'eval/episode_y_position_std': Array(338.6445, dtype=float32), 'eval/episode_y_velocity_std': Array(97.98176, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37680673599243, 'eval/sps': 938.5760164321135, 'num_steps': 11223040}
{'eval/walltime': 19021.56707048416, 'training/sps': 2935.0665706526984, 'training/walltime': 3870.022421360016, 'training/entropy_loss': Array(0.01204201, dtype=float32), 'training/policy_loss': Array(0.00134471, dtype=float32), 'training/total_loss': Array(0.04704511, dtype=float32), 'training/v_loss': Array(0.03365839, dtype=float32), 'eval/episode_distance_from_origin': Array(4691.976, dtype=float32), 'eval/episode_distance_reward': Array(12.060383, dtype=float32), 'eval/episode_forward_reward': Array(2010.0564, dtype=float32), 'eval/episode_reward': Array(1963.5308, dtype=float32), 'eval/episode_reward_alive': Array(409.23438, dtype=float32), 'eval/episode_reward_linvel': Array(2010.0564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-467.82043, dtype=float32), 'eval/episode_x_position': Array(4641.6206, dtype=float32), 'eval/episode_x_velocity': Array(402.01126, dtype=float32), 'eval/episode_y_position': Array(-269.82758, dtype=float32), 'eval/episode_y_velocity': Array(-83.17343, dtype=float32), 'eval/episode_distance_from_origin_std': Array(512.7025, dtype=float32), 'eval/episode_distance_reward_std': Array(5.38347, dtype=float32), 'eval/episode_forward_reward_std': Array(897.239, dtype=float32), 'eval/episode_reward_std': Array(942.80884, dtype=float32), 'eval/episode_reward_alive_std': Array(48.00585, dtype=float32), 'eval/episode_reward_linvel_std': Array(897.239, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.85043, dtype=float32), 'eval/episode_x_position_std': Array(496.1124, dtype=float32), 'eval/episode_x_velocity_std': Array(179.44783, dtype=float32), 'eval/episode_y_position_std': Array(320.7439, dtype=float32), 'eval/episode_y_velocity_std': Array(91.47666, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56878638267517, 'eval/sps': 937.2566264251274, 'num_steps': 11304960}
{'eval/walltime': 19158.10449695587, 'training/sps': 2943.0556845793226, 'training/walltime': 3897.857436656952, 'training/entropy_loss': Array(0.00677653, dtype=float32), 'training/policy_loss': Array(-3.664408e-05, dtype=float32), 'training/total_loss': Array(0.07409052, dtype=float32), 'training/v_loss': Array(0.06735064, dtype=float32), 'eval/episode_distance_from_origin': Array(4741.5957, dtype=float32), 'eval/episode_distance_reward': Array(13.168128, dtype=float32), 'eval/episode_forward_reward': Array(2194.68, dtype=float32), 'eval/episode_reward': Array(2167.5464, dtype=float32), 'eval/episode_reward_alive': Array(421.21094, dtype=float32), 'eval/episode_reward_linvel': Array(2194.68, dtype=float32), 'eval/episode_reward_quadctrl': Array(-461.51245, dtype=float32), 'eval/episode_x_position': Array(4692.38, dtype=float32), 'eval/episode_x_velocity': Array(438.9359, dtype=float32), 'eval/episode_y_position': Array(-256.60428, dtype=float32), 'eval/episode_y_velocity': Array(-86.94342, dtype=float32), 'eval/episode_distance_from_origin_std': Array(564.86926, dtype=float32), 'eval/episode_distance_reward_std': Array(6.7135224, dtype=float32), 'eval/episode_forward_reward_std': Array(1118.9137, dtype=float32), 'eval/episode_reward_std': Array(1172.8429, dtype=float32), 'eval/episode_reward_alive_std': Array(34.489445, dtype=float32), 'eval/episode_reward_linvel_std': Array(1118.9137, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.970184, dtype=float32), 'eval/episode_x_position_std': Array(553.27734, dtype=float32), 'eval/episode_x_velocity_std': Array(223.78271, dtype=float32), 'eval/episode_y_position_std': Array(314.0775, dtype=float32), 'eval/episode_y_velocity_std': Array(90.54262, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5374264717102, 'eval/sps': 937.4718954917529, 'num_steps': 11386880}
{'eval/walltime': 19294.590247392654, 'training/sps': 2939.0537627252866, 'training/walltime': 3925.730353116989, 'training/entropy_loss': Array(0.01029341, dtype=float32), 'training/policy_loss': Array(0.00112829, dtype=float32), 'training/total_loss': Array(0.08195393, dtype=float32), 'training/v_loss': Array(0.07053223, dtype=float32), 'eval/episode_distance_from_origin': Array(4802.3916, dtype=float32), 'eval/episode_distance_reward': Array(13.387608, dtype=float32), 'eval/episode_forward_reward': Array(2231.2593, dtype=float32), 'eval/episode_reward': Array(2200.9805, dtype=float32), 'eval/episode_reward_alive': Array(421.33203, dtype=float32), 'eval/episode_reward_linvel': Array(2231.2593, dtype=float32), 'eval/episode_reward_quadctrl': Array(-464.99838, dtype=float32), 'eval/episode_x_position': Array(4750.789, dtype=float32), 'eval/episode_x_velocity': Array(446.25183, dtype=float32), 'eval/episode_y_position': Array(-298.8692, dtype=float32), 'eval/episode_y_velocity': Array(-94.02278, dtype=float32), 'eval/episode_distance_from_origin_std': Array(565.3458, dtype=float32), 'eval/episode_distance_reward_std': Array(6.520594, dtype=float32), 'eval/episode_forward_reward_std': Array(1086.7589, dtype=float32), 'eval/episode_reward_std': Array(1135.8198, dtype=float32), 'eval/episode_reward_alive_std': Array(33.834114, dtype=float32), 'eval/episode_reward_linvel_std': Array(1086.7589, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.89445, dtype=float32), 'eval/episode_x_position_std': Array(552.33215, dtype=float32), 'eval/episode_x_velocity_std': Array(217.35179, dtype=float32), 'eval/episode_y_position_std': Array(309.13742, dtype=float32), 'eval/episode_y_velocity_std': Array(92.15892, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48575043678284, 'eval/sps': 937.8268397277616, 'num_steps': 11468800}
{'eval/walltime': 19431.054997205734, 'training/sps': 2942.423691822377, 'training/walltime': 3953.5713469982147, 'training/entropy_loss': Array(0.01456185, dtype=float32), 'training/policy_loss': Array(0.007252, dtype=float32), 'training/total_loss': Array(0.08680952, dtype=float32), 'training/v_loss': Array(0.06499567, dtype=float32), 'eval/episode_distance_from_origin': Array(4757.5054, dtype=float32), 'eval/episode_distance_reward': Array(12.822699, dtype=float32), 'eval/episode_forward_reward': Array(2137.1084, dtype=float32), 'eval/episode_reward': Array(2102.2131, dtype=float32), 'eval/episode_reward_alive': Array(422.39453, dtype=float32), 'eval/episode_reward_linvel': Array(2137.1084, dtype=float32), 'eval/episode_reward_quadctrl': Array(-470.1129, dtype=float32), 'eval/episode_x_position': Array(4705.149, dtype=float32), 'eval/episode_x_velocity': Array(427.42172, dtype=float32), 'eval/episode_y_position': Array(-297.7696, dtype=float32), 'eval/episode_y_velocity': Array(-89.8369, dtype=float32), 'eval/episode_distance_from_origin_std': Array(578.44464, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4275894, dtype=float32), 'eval/episode_forward_reward_std': Array(1071.258, dtype=float32), 'eval/episode_reward_std': Array(1119.521, dtype=float32), 'eval/episode_reward_alive_std': Array(35.41758, dtype=float32), 'eval/episode_reward_linvel_std': Array(1071.258, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.629044, dtype=float32), 'eval/episode_x_position_std': Array(562.5729, dtype=float32), 'eval/episode_x_velocity_std': Array(214.25172, dtype=float32), 'eval/episode_y_position_std': Array(323.0793, dtype=float32), 'eval/episode_y_velocity_std': Array(92.713684, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46474981307983, 'eval/sps': 937.9711623355169, 'num_steps': 11550720}
{'eval/walltime': 19567.66189646721, 'training/sps': 2937.6278354907677, 'training/walltime': 3981.4577929973602, 'training/entropy_loss': Array(0.01755368, dtype=float32), 'training/policy_loss': Array(0.00931401, dtype=float32), 'training/total_loss': Array(0.05989729, dtype=float32), 'training/v_loss': Array(0.03302961, dtype=float32), 'eval/episode_distance_from_origin': Array(4772.5483, dtype=float32), 'eval/episode_distance_reward': Array(13.078617, dtype=float32), 'eval/episode_forward_reward': Array(2179.7612, dtype=float32), 'eval/episode_reward': Array(2156.2795, dtype=float32), 'eval/episode_reward_alive': Array(428.23828, dtype=float32), 'eval/episode_reward_linvel': Array(2179.7612, dtype=float32), 'eval/episode_reward_quadctrl': Array(-464.79865, dtype=float32), 'eval/episode_x_position': Array(4722.8745, dtype=float32), 'eval/episode_x_velocity': Array(435.95224, dtype=float32), 'eval/episode_y_position': Array(-259.9291, dtype=float32), 'eval/episode_y_velocity': Array(-86.11754, dtype=float32), 'eval/episode_distance_from_origin_std': Array(576.21826, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3963895, dtype=float32), 'eval/episode_forward_reward_std': Array(1066.0587, dtype=float32), 'eval/episode_reward_std': Array(1114.1476, dtype=float32), 'eval/episode_reward_alive_std': Array(32.609367, dtype=float32), 'eval/episode_reward_linvel_std': Array(1066.0587, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.017326, dtype=float32), 'eval/episode_x_position_std': Array(563.2222, dtype=float32), 'eval/episode_x_velocity_std': Array(213.21167, dtype=float32), 'eval/episode_y_position_std': Array(315.18982, dtype=float32), 'eval/episode_y_velocity_std': Array(91.30862, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6068992614746, 'eval/sps': 936.9951348869984, 'num_steps': 11632640}
{'eval/walltime': 19704.069157361984, 'training/sps': 2948.5155714043576, 'training/walltime': 4009.2412650585175, 'training/entropy_loss': Array(0.01917207, dtype=float32), 'training/policy_loss': Array(0.01425582, dtype=float32), 'training/total_loss': Array(0.0561522, dtype=float32), 'training/v_loss': Array(0.02272431, dtype=float32), 'eval/episode_distance_from_origin': Array(4788.797, dtype=float32), 'eval/episode_distance_reward': Array(13.565034, dtype=float32), 'eval/episode_forward_reward': Array(2260.8298, dtype=float32), 'eval/episode_reward': Array(2247.8936, dtype=float32), 'eval/episode_reward_alive': Array(428.23047, dtype=float32), 'eval/episode_reward_linvel': Array(2260.8298, dtype=float32), 'eval/episode_reward_quadctrl': Array(-454.73196, dtype=float32), 'eval/episode_x_position': Array(4738.3115, dtype=float32), 'eval/episode_x_velocity': Array(452.16595, dtype=float32), 'eval/episode_y_position': Array(-276.26013, dtype=float32), 'eval/episode_y_velocity': Array(-90.88043, dtype=float32), 'eval/episode_distance_from_origin_std': Array(601.1911, dtype=float32), 'eval/episode_distance_reward_std': Array(6.8400526, dtype=float32), 'eval/episode_forward_reward_std': Array(1140.0015, dtype=float32), 'eval/episode_reward_std': Array(1186.0066, dtype=float32), 'eval/episode_reward_alive_std': Array(33.002953, dtype=float32), 'eval/episode_reward_linvel_std': Array(1140.0015, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.527554, dtype=float32), 'eval/episode_x_position_std': Array(588.6062, dtype=float32), 'eval/episode_x_velocity_std': Array(228.00029, dtype=float32), 'eval/episode_y_position_std': Array(314.8085, dtype=float32), 'eval/episode_y_velocity_std': Array(90.64982, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4072608947754, 'eval/sps': 938.3664708196087, 'num_steps': 11714560}
{'eval/walltime': 19840.782394886017, 'training/sps': 2945.79221524927, 'training/walltime': 4037.050422668457, 'training/entropy_loss': Array(0.01551423, dtype=float32), 'training/policy_loss': Array(-7.0323294e-05, dtype=float32), 'training/total_loss': Array(0.0318229, dtype=float32), 'training/v_loss': Array(0.01637899, dtype=float32), 'eval/episode_distance_from_origin': Array(4655.9336, dtype=float32), 'eval/episode_distance_reward': Array(11.885672, dtype=float32), 'eval/episode_forward_reward': Array(1980.9382, dtype=float32), 'eval/episode_reward': Array(1936.7831, dtype=float32), 'eval/episode_reward_alive': Array(417.26172, dtype=float32), 'eval/episode_reward_linvel': Array(1980.9382, dtype=float32), 'eval/episode_reward_quadctrl': Array(-473.30225, dtype=float32), 'eval/episode_x_position': Array(4608.058, dtype=float32), 'eval/episode_x_velocity': Array(396.1876, dtype=float32), 'eval/episode_y_position': Array(-273.6045, dtype=float32), 'eval/episode_y_velocity': Array(-80.56857, dtype=float32), 'eval/episode_distance_from_origin_std': Array(531.64905, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6332197, dtype=float32), 'eval/episode_forward_reward_std': Array(938.86395, dtype=float32), 'eval/episode_reward_std': Array(986.9039, dtype=float32), 'eval/episode_reward_alive_std': Array(40.556145, dtype=float32), 'eval/episode_reward_linvel_std': Array(938.86395, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.14844, dtype=float32), 'eval/episode_x_position_std': Array(518.6111, dtype=float32), 'eval/episode_x_velocity_std': Array(187.77277, dtype=float32), 'eval/episode_y_position_std': Array(276.8769, dtype=float32), 'eval/episode_y_velocity_std': Array(80.23277, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7132375240326, 'eval/sps': 936.2663215220771, 'num_steps': 11796480}
{'eval/walltime': 19977.19709420204, 'training/sps': 2944.132077992469, 'training/walltime': 4064.8752613067627, 'training/entropy_loss': Array(0.00716864, dtype=float32), 'training/policy_loss': Array(0.00121375, dtype=float32), 'training/total_loss': Array(0.06502999, dtype=float32), 'training/v_loss': Array(0.05664761, dtype=float32), 'eval/episode_distance_from_origin': Array(4737.7407, dtype=float32), 'eval/episode_distance_reward': Array(12.918457, dtype=float32), 'eval/episode_forward_reward': Array(2153.0679, dtype=float32), 'eval/episode_reward': Array(2121.7783, dtype=float32), 'eval/episode_reward_alive': Array(422.6172, dtype=float32), 'eval/episode_reward_linvel': Array(2153.0679, dtype=float32), 'eval/episode_reward_quadctrl': Array(-466.825, dtype=float32), 'eval/episode_x_position': Array(4686.8467, dtype=float32), 'eval/episode_x_velocity': Array(430.61353, dtype=float32), 'eval/episode_y_position': Array(-290.0971, dtype=float32), 'eval/episode_y_velocity': Array(-91.86977, dtype=float32), 'eval/episode_distance_from_origin_std': Array(553.5798, dtype=float32), 'eval/episode_distance_reward_std': Array(6.17625, dtype=float32), 'eval/episode_forward_reward_std': Array(1029.3685, dtype=float32), 'eval/episode_reward_std': Array(1073.1528, dtype=float32), 'eval/episode_reward_alive_std': Array(34.55908, dtype=float32), 'eval/episode_reward_linvel_std': Array(1029.3685, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.84014, dtype=float32), 'eval/episode_x_position_std': Array(538.1414, dtype=float32), 'eval/episode_x_velocity_std': Array(205.87373, dtype=float32), 'eval/episode_y_position_std': Array(299.7698, dtype=float32), 'eval/episode_y_velocity_std': Array(86.482315, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41469931602478, 'eval/sps': 938.3153035690759, 'num_steps': 11878400}
{'eval/walltime': 20113.761562108994, 'training/sps': 2944.0543305886645, 'training/walltime': 4092.700834751129, 'training/entropy_loss': Array(0.01034809, dtype=float32), 'training/policy_loss': Array(0.00444964, dtype=float32), 'training/total_loss': Array(0.10117806, dtype=float32), 'training/v_loss': Array(0.08638033, dtype=float32), 'eval/episode_distance_from_origin': Array(4697.0996, dtype=float32), 'eval/episode_distance_reward': Array(12.315946, dtype=float32), 'eval/episode_forward_reward': Array(2052.65, dtype=float32), 'eval/episode_reward': Array(2020.1382, dtype=float32), 'eval/episode_reward_alive': Array(428.7461, dtype=float32), 'eval/episode_reward_linvel': Array(2052.65, dtype=float32), 'eval/episode_reward_quadctrl': Array(-473.57373, dtype=float32), 'eval/episode_x_position': Array(4649.675, dtype=float32), 'eval/episode_x_velocity': Array(410.52997, dtype=float32), 'eval/episode_y_position': Array(-248.77835, dtype=float32), 'eval/episode_y_velocity': Array(-79.25831, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.8225, dtype=float32), 'eval/episode_distance_reward_std': Array(6.05587, dtype=float32), 'eval/episode_forward_reward_std': Array(1009.3053, dtype=float32), 'eval/episode_reward_std': Array(1058.5238, dtype=float32), 'eval/episode_reward_alive_std': Array(31.195452, dtype=float32), 'eval/episode_reward_linvel_std': Array(1009.3053, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.843475, dtype=float32), 'eval/episode_x_position_std': Array(518.9955, dtype=float32), 'eval/episode_x_velocity_std': Array(201.86108, dtype=float32), 'eval/episode_y_position_std': Array(287.69916, dtype=float32), 'eval/episode_y_velocity_std': Array(82.98637, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5644679069519, 'eval/sps': 937.2862645883313, 'num_steps': 11960320}
{'eval/walltime': 20250.26856160164, 'training/sps': 2948.733135130501, 'training/walltime': 4120.482256889343, 'training/entropy_loss': Array(0.0138956, dtype=float32), 'training/policy_loss': Array(0.00733331, dtype=float32), 'training/total_loss': Array(0.09544596, dtype=float32), 'training/v_loss': Array(0.07421704, dtype=float32), 'eval/episode_distance_from_origin': Array(4684.7944, dtype=float32), 'eval/episode_distance_reward': Array(12.343662, dtype=float32), 'eval/episode_forward_reward': Array(2057.2698, dtype=float32), 'eval/episode_reward': Array(2022.3132, dtype=float32), 'eval/episode_reward_alive': Array(426.7578, dtype=float32), 'eval/episode_reward_linvel': Array(2057.2698, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.0579, dtype=float32), 'eval/episode_x_position': Array(4643.038, dtype=float32), 'eval/episode_x_velocity': Array(411.45392, dtype=float32), 'eval/episode_y_position': Array(-189.32285, dtype=float32), 'eval/episode_y_velocity': Array(-64.11807, dtype=float32), 'eval/episode_distance_from_origin_std': Array(575.5388, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5251665, dtype=float32), 'eval/episode_forward_reward_std': Array(1087.5206, dtype=float32), 'eval/episode_reward_std': Array(1136.1913, dtype=float32), 'eval/episode_reward_alive_std': Array(32.181187, dtype=float32), 'eval/episode_reward_linvel_std': Array(1087.5206, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.9174, dtype=float32), 'eval/episode_x_position_std': Array(565.1841, dtype=float32), 'eval/episode_x_velocity_std': Array(217.50417, dtype=float32), 'eval/episode_y_position_std': Array(268.42914, dtype=float32), 'eval/episode_y_velocity_std': Array(79.19396, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50699949264526, 'eval/sps': 937.680855016496, 'num_steps': 12042240}
{'eval/walltime': 20386.68682360649, 'training/sps': 2944.7599087940234, 'training/walltime': 4148.301163196564, 'training/entropy_loss': Array(0.01730299, dtype=float32), 'training/policy_loss': Array(0.0083327, dtype=float32), 'training/total_loss': Array(0.06871879, dtype=float32), 'training/v_loss': Array(0.0430831, dtype=float32), 'eval/episode_distance_from_origin': Array(4780.3345, dtype=float32), 'eval/episode_distance_reward': Array(13.279512, dtype=float32), 'eval/episode_forward_reward': Array(2213.2432, dtype=float32), 'eval/episode_reward': Array(2183.8516, dtype=float32), 'eval/episode_reward_alive': Array(422.01953, dtype=float32), 'eval/episode_reward_linvel': Array(2213.2432, dtype=float32), 'eval/episode_reward_quadctrl': Array(-464.69086, dtype=float32), 'eval/episode_x_position': Array(4735.449, dtype=float32), 'eval/episode_x_velocity': Array(442.64862, dtype=float32), 'eval/episode_y_position': Array(-233.8273, dtype=float32), 'eval/episode_y_velocity': Array(-77.78971, dtype=float32), 'eval/episode_distance_from_origin_std': Array(606.3611, dtype=float32), 'eval/episode_distance_reward_std': Array(6.767429, dtype=float32), 'eval/episode_forward_reward_std': Array(1127.8975, dtype=float32), 'eval/episode_reward_std': Array(1180.9116, dtype=float32), 'eval/episode_reward_alive_std': Array(46.636284, dtype=float32), 'eval/episode_reward_linvel_std': Array(1127.8975, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.541626, dtype=float32), 'eval/episode_x_position_std': Array(595.0961, dtype=float32), 'eval/episode_x_velocity_std': Array(225.57947, dtype=float32), 'eval/episode_y_position_std': Array(275.85843, dtype=float32), 'eval/episode_y_velocity_std': Array(84.01134, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4182620048523, 'eval/sps': 938.2907985988498, 'num_steps': 12124160}
{'eval/walltime': 20523.029515981674, 'training/sps': 2954.0713606077416, 'training/walltime': 4176.032382249832, 'training/entropy_loss': Array(0.01900724, dtype=float32), 'training/policy_loss': Array(0.01782412, dtype=float32), 'training/total_loss': Array(0.06565645, dtype=float32), 'training/v_loss': Array(0.02882509, dtype=float32), 'eval/episode_distance_from_origin': Array(4860.7217, dtype=float32), 'eval/episode_distance_reward': Array(13.784791, dtype=float32), 'eval/episode_forward_reward': Array(2297.456, dtype=float32), 'eval/episode_reward': Array(2274.995, dtype=float32), 'eval/episode_reward_alive': Array(426.73047, dtype=float32), 'eval/episode_reward_linvel': Array(2297.456, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.9762, dtype=float32), 'eval/episode_x_position': Array(4811.071, dtype=float32), 'eval/episode_x_velocity': Array(459.49115, dtype=float32), 'eval/episode_y_position': Array(-298.27478, dtype=float32), 'eval/episode_y_velocity': Array(-93.01175, dtype=float32), 'eval/episode_distance_from_origin_std': Array(569.90045, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3217955, dtype=float32), 'eval/episode_forward_reward_std': Array(1053.626, dtype=float32), 'eval/episode_reward_std': Array(1103.6952, dtype=float32), 'eval/episode_reward_alive_std': Array(41.49397, dtype=float32), 'eval/episode_reward_linvel_std': Array(1053.626, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.301544, dtype=float32), 'eval/episode_x_position_std': Array(558.3051, dtype=float32), 'eval/episode_x_velocity_std': Array(210.72511, dtype=float32), 'eval/episode_y_position_std': Array(286.30014, dtype=float32), 'eval/episode_y_velocity_std': Array(83.18181, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3426923751831, 'eval/sps': 938.810857920966, 'num_steps': 12206080}
{'eval/walltime': 20659.478410959244, 'training/sps': 2940.639820657262, 'training/walltime': 4203.890265226364, 'training/entropy_loss': Array(0.02019738, dtype=float32), 'training/policy_loss': Array(0.00567965, dtype=float32), 'training/total_loss': Array(0.04466186, dtype=float32), 'training/v_loss': Array(0.01878483, dtype=float32), 'eval/episode_distance_from_origin': Array(4907.114, dtype=float32), 'eval/episode_distance_reward': Array(14.381752, dtype=float32), 'eval/episode_forward_reward': Array(2396.9487, dtype=float32), 'eval/episode_reward': Array(2379.4077, dtype=float32), 'eval/episode_reward_alive': Array(430.76172, dtype=float32), 'eval/episode_reward_linvel': Array(2396.9487, dtype=float32), 'eval/episode_reward_quadctrl': Array(-462.68433, dtype=float32), 'eval/episode_x_position': Array(4854.969, dtype=float32), 'eval/episode_x_velocity': Array(479.3897, dtype=float32), 'eval/episode_y_position': Array(-321.37445, dtype=float32), 'eval/episode_y_velocity': Array(-101.51436, dtype=float32), 'eval/episode_distance_from_origin_std': Array(647.4498, dtype=float32), 'eval/episode_distance_reward_std': Array(7.2435527, dtype=float32), 'eval/episode_forward_reward_std': Array(1207.2507, dtype=float32), 'eval/episode_reward_std': Array(1255.3278, dtype=float32), 'eval/episode_reward_alive_std': Array(31.988337, dtype=float32), 'eval/episode_reward_linvel_std': Array(1207.2507, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.473392, dtype=float32), 'eval/episode_x_position_std': Array(638.2606, dtype=float32), 'eval/episode_x_velocity_std': Array(241.45016, dtype=float32), 'eval/episode_y_position_std': Array(300.79416, dtype=float32), 'eval/episode_y_velocity_std': Array(88.04625, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44889497756958, 'eval/sps': 938.0801509681814, 'num_steps': 12288000}
{'eval/walltime': 20795.83075594902, 'training/sps': 2951.603941627344, 'training/walltime': 4231.644666433334, 'training/entropy_loss': Array(0.00627659, dtype=float32), 'training/policy_loss': Array(0.00015646, dtype=float32), 'training/total_loss': Array(0.0488189, dtype=float32), 'training/v_loss': Array(0.04238585, dtype=float32), 'eval/episode_distance_from_origin': Array(4819.1406, dtype=float32), 'eval/episode_distance_reward': Array(13.196215, dtype=float32), 'eval/episode_forward_reward': Array(2199.3608, dtype=float32), 'eval/episode_reward': Array(2166.1655, dtype=float32), 'eval/episode_reward_alive': Array(432.17578, dtype=float32), 'eval/episode_reward_linvel': Array(2199.3608, dtype=float32), 'eval/episode_reward_quadctrl': Array(-478.56754, dtype=float32), 'eval/episode_x_position': Array(4769.9766, dtype=float32), 'eval/episode_x_velocity': Array(439.8722, dtype=float32), 'eval/episode_y_position': Array(-297.6027, dtype=float32), 'eval/episode_y_velocity': Array(-88.0321, dtype=float32), 'eval/episode_distance_from_origin_std': Array(631.26855, dtype=float32), 'eval/episode_distance_reward_std': Array(6.95064, dtype=float32), 'eval/episode_forward_reward_std': Array(1158.4329, dtype=float32), 'eval/episode_reward_std': Array(1208.616, dtype=float32), 'eval/episode_reward_alive_std': Array(28.42442, dtype=float32), 'eval/episode_reward_linvel_std': Array(1158.4329, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.329624, dtype=float32), 'eval/episode_x_position_std': Array(618.4403, dtype=float32), 'eval/episode_x_velocity_std': Array(231.6866, dtype=float32), 'eval/episode_y_position_std': Array(293.39673, dtype=float32), 'eval/episode_y_velocity_std': Array(86.28814, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3523449897766, 'eval/sps': 938.7443979023401, 'num_steps': 12369920}
{'eval/walltime': 20932.259584903717, 'training/sps': 2944.64397132176, 'training/walltime': 4259.464668035507, 'training/entropy_loss': Array(0.00907398, dtype=float32), 'training/policy_loss': Array(0.00213754, dtype=float32), 'training/total_loss': Array(0.08738538, dtype=float32), 'training/v_loss': Array(0.07617386, dtype=float32), 'eval/episode_distance_from_origin': Array(4775.0146, dtype=float32), 'eval/episode_distance_reward': Array(13.0482, dtype=float32), 'eval/episode_forward_reward': Array(2174.6917, dtype=float32), 'eval/episode_reward': Array(2141.5376, dtype=float32), 'eval/episode_reward_alive': Array(427.96484, dtype=float32), 'eval/episode_reward_linvel': Array(2174.6917, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.167, dtype=float32), 'eval/episode_x_position': Array(4730.574, dtype=float32), 'eval/episode_x_velocity': Array(434.93823, dtype=float32), 'eval/episode_y_position': Array(-257.25626, dtype=float32), 'eval/episode_y_velocity': Array(-80.023926, dtype=float32), 'eval/episode_distance_from_origin_std': Array(629.33716, dtype=float32), 'eval/episode_distance_reward_std': Array(6.809487, dtype=float32), 'eval/episode_forward_reward_std': Array(1134.9081, dtype=float32), 'eval/episode_reward_std': Array(1190.0918, dtype=float32), 'eval/episode_reward_alive_std': Array(31.969234, dtype=float32), 'eval/episode_reward_linvel_std': Array(1134.9081, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.774605, dtype=float32), 'eval/episode_x_position_std': Array(618.6212, dtype=float32), 'eval/episode_x_velocity_std': Array(226.98148, dtype=float32), 'eval/episode_y_position_std': Array(259.437, dtype=float32), 'eval/episode_y_velocity_std': Array(79.04969, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42882895469666, 'eval/sps': 938.2181242829873, 'num_steps': 12451840}
{'eval/walltime': 21068.6415245533, 'training/sps': 2956.964357963881, 'training/walltime': 4287.16875576973, 'training/entropy_loss': Array(0.01284125, dtype=float32), 'training/policy_loss': Array(0.0054769, dtype=float32), 'training/total_loss': Array(0.09222119, dtype=float32), 'training/v_loss': Array(0.07390304, dtype=float32), 'eval/episode_distance_from_origin': Array(4787.3438, dtype=float32), 'eval/episode_distance_reward': Array(12.972004, dtype=float32), 'eval/episode_forward_reward': Array(2161.9922, dtype=float32), 'eval/episode_reward': Array(2133.2954, dtype=float32), 'eval/episode_reward_alive': Array(430.6172, dtype=float32), 'eval/episode_reward_linvel': Array(2161.9922, dtype=float32), 'eval/episode_reward_quadctrl': Array(-472.28625, dtype=float32), 'eval/episode_x_position': Array(4738.7847, dtype=float32), 'eval/episode_x_velocity': Array(432.39847, dtype=float32), 'eval/episode_y_position': Array(-285.88483, dtype=float32), 'eval/episode_y_velocity': Array(-82.88249, dtype=float32), 'eval/episode_distance_from_origin_std': Array(612.86456, dtype=float32), 'eval/episode_distance_reward_std': Array(6.542344, dtype=float32), 'eval/episode_forward_reward_std': Array(1090.3838, dtype=float32), 'eval/episode_reward_std': Array(1137.3326, dtype=float32), 'eval/episode_reward_alive_std': Array(29.524717, dtype=float32), 'eval/episode_reward_linvel_std': Array(1090.3838, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.684837, dtype=float32), 'eval/episode_x_position_std': Array(601.7208, dtype=float32), 'eval/episode_x_velocity_std': Array(218.07677, dtype=float32), 'eval/episode_y_position_std': Array(282.37604, dtype=float32), 'eval/episode_y_velocity_std': Array(83.85103, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3819396495819, 'eval/sps': 938.5406918898619, 'num_steps': 12533760}
{'eval/walltime': 21205.098841667175, 'training/sps': 2948.9695614244656, 'training/walltime': 4314.947950601578, 'training/entropy_loss': Array(0.01614534, dtype=float32), 'training/policy_loss': Array(0.0084193, dtype=float32), 'training/total_loss': Array(0.07567476, dtype=float32), 'training/v_loss': Array(0.05111012, dtype=float32), 'eval/episode_distance_from_origin': Array(5041.145, dtype=float32), 'eval/episode_distance_reward': Array(16.076794, dtype=float32), 'eval/episode_forward_reward': Array(2679.4536, dtype=float32), 'eval/episode_reward': Array(2673.4434, dtype=float32), 'eval/episode_reward_alive': Array(428.22266, dtype=float32), 'eval/episode_reward_linvel': Array(2679.4536, dtype=float32), 'eval/episode_reward_quadctrl': Array(-450.30942, dtype=float32), 'eval/episode_x_position': Array(4993.7183, dtype=float32), 'eval/episode_x_velocity': Array(535.8907, dtype=float32), 'eval/episode_y_position': Array(-263.70233, dtype=float32), 'eval/episode_y_velocity': Array(-91.55722, dtype=float32), 'eval/episode_distance_from_origin_std': Array(636.01294, dtype=float32), 'eval/episode_distance_reward_std': Array(7.660819, dtype=float32), 'eval/episode_forward_reward_std': Array(1276.7954, dtype=float32), 'eval/episode_reward_std': Array(1328.608, dtype=float32), 'eval/episode_reward_alive_std': Array(30.874102, dtype=float32), 'eval/episode_reward_linvel_std': Array(1276.7954, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(57.769966, dtype=float32), 'eval/episode_x_position_std': Array(628.0287, dtype=float32), 'eval/episode_x_velocity_std': Array(255.35904, dtype=float32), 'eval/episode_y_position_std': Array(304.35745, dtype=float32), 'eval/episode_y_velocity_std': Array(92.37261, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45731711387634, 'eval/sps': 938.0222527252346, 'num_steps': 12615680}
{'eval/walltime': 21341.433371782303, 'training/sps': 2938.6980748259293, 'training/walltime': 4342.824240684509, 'training/entropy_loss': Array(0.01851051, dtype=float32), 'training/policy_loss': Array(0.00720699, dtype=float32), 'training/total_loss': Array(0.06305598, dtype=float32), 'training/v_loss': Array(0.03733847, dtype=float32), 'eval/episode_distance_from_origin': Array(4882.8438, dtype=float32), 'eval/episode_distance_reward': Array(14.151901, dtype=float32), 'eval/episode_forward_reward': Array(2358.641, dtype=float32), 'eval/episode_reward': Array(2335.042, dtype=float32), 'eval/episode_reward_alive': Array(431.6797, dtype=float32), 'eval/episode_reward_linvel': Array(2358.641, dtype=float32), 'eval/episode_reward_quadctrl': Array(-469.43057, dtype=float32), 'eval/episode_x_position': Array(4838.133, dtype=float32), 'eval/episode_x_velocity': Array(471.7282, dtype=float32), 'eval/episode_y_position': Array(-263.9726, dtype=float32), 'eval/episode_y_velocity': Array(-84.25772, dtype=float32), 'eval/episode_distance_from_origin_std': Array(693.84424, dtype=float32), 'eval/episode_distance_reward_std': Array(7.622568, dtype=float32), 'eval/episode_forward_reward_std': Array(1270.4202, dtype=float32), 'eval/episode_reward_std': Array(1329.4246, dtype=float32), 'eval/episode_reward_alive_std': Array(29.721474, dtype=float32), 'eval/episode_reward_linvel_std': Array(1270.4202, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.23474, dtype=float32), 'eval/episode_x_position_std': Array(684.0354, dtype=float32), 'eval/episode_x_velocity_std': Array(254.084, dtype=float32), 'eval/episode_y_position_std': Array(255.4903, dtype=float32), 'eval/episode_y_velocity_std': Array(82.14392, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33453011512756, 'eval/sps': 938.8670639192471, 'num_steps': 12697600}
{'eval/walltime': 21477.900943040848, 'training/sps': 2940.2207972026135, 'training/walltime': 4370.6860938072205, 'training/entropy_loss': Array(0.0186205, dtype=float32), 'training/policy_loss': Array(0.08684994, dtype=float32), 'training/total_loss': Array(0.13502955, dtype=float32), 'training/v_loss': Array(0.02955913, dtype=float32), 'eval/episode_distance_from_origin': Array(4716.302, dtype=float32), 'eval/episode_distance_reward': Array(11.62973, dtype=float32), 'eval/episode_forward_reward': Array(1938.2814, dtype=float32), 'eval/episode_reward': Array(1869.0955, dtype=float32), 'eval/episode_reward_alive': Array(416.6328, dtype=float32), 'eval/episode_reward_linvel': Array(1938.2814, dtype=float32), 'eval/episode_reward_quadctrl': Array(-497.4485, dtype=float32), 'eval/episode_x_position': Array(4657.7197, dtype=float32), 'eval/episode_x_velocity': Array(387.65625, dtype=float32), 'eval/episode_y_position': Array(-373.62848, dtype=float32), 'eval/episode_y_velocity': Array(-104.11084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(565.8074, dtype=float32), 'eval/episode_distance_reward_std': Array(5.385334, dtype=float32), 'eval/episode_forward_reward_std': Array(897.5506, dtype=float32), 'eval/episode_reward_std': Array(937.10144, dtype=float32), 'eval/episode_reward_alive_std': Array(32.476162, dtype=float32), 'eval/episode_reward_linvel_std': Array(897.5506, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.15962, dtype=float32), 'eval/episode_x_position_std': Array(549.7048, dtype=float32), 'eval/episode_x_velocity_std': Array(179.51012, dtype=float32), 'eval/episode_y_position_std': Array(318.54663, dtype=float32), 'eval/episode_y_velocity_std': Array(85.485985, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46757125854492, 'eval/sps': 937.9517699299955, 'num_steps': 12779520}
{'eval/walltime': 21614.172510147095, 'training/sps': 2937.1149136496174, 'training/walltime': 4398.577409744263, 'training/entropy_loss': Array(0.00945945, dtype=float32), 'training/policy_loss': Array(-0.00058188, dtype=float32), 'training/total_loss': Array(0.05522674, dtype=float32), 'training/v_loss': Array(0.04634917, dtype=float32), 'eval/episode_distance_from_origin': Array(4788.677, dtype=float32), 'eval/episode_distance_reward': Array(12.340047, dtype=float32), 'eval/episode_forward_reward': Array(2056.6665, dtype=float32), 'eval/episode_reward': Array(2000.1125, dtype=float32), 'eval/episode_reward_alive': Array(416.0039, dtype=float32), 'eval/episode_reward_linvel': Array(2056.6665, dtype=float32), 'eval/episode_reward_quadctrl': Array(-484.89777, dtype=float32), 'eval/episode_x_position': Array(4731.693, dtype=float32), 'eval/episode_x_velocity': Array(411.33328, dtype=float32), 'eval/episode_y_position': Array(-361.66626, dtype=float32), 'eval/episode_y_velocity': Array(-103.868454, dtype=float32), 'eval/episode_distance_from_origin_std': Array(562.33514, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4150524, dtype=float32), 'eval/episode_forward_reward_std': Array(902.50287, dtype=float32), 'eval/episode_reward_std': Array(933.0235, dtype=float32), 'eval/episode_reward_alive_std': Array(37.23917, dtype=float32), 'eval/episode_reward_linvel_std': Array(902.50287, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.28876, dtype=float32), 'eval/episode_x_position_std': Array(547.1444, dtype=float32), 'eval/episode_x_velocity_std': Array(180.5006, dtype=float32), 'eval/episode_y_position_std': Array(316.2886, dtype=float32), 'eval/episode_y_velocity_std': Array(83.36749, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27156710624695, 'eval/sps': 939.3008587051924, 'num_steps': 12861440}
{'eval/walltime': 21750.59689426422, 'training/sps': 2934.84209464111, 'training/walltime': 4426.490325450897, 'training/entropy_loss': Array(0.00829872, dtype=float32), 'training/policy_loss': Array(0.00208074, dtype=float32), 'training/total_loss': Array(0.11817098, dtype=float32), 'training/v_loss': Array(0.10779153, dtype=float32), 'eval/episode_distance_from_origin': Array(4895.7017, dtype=float32), 'eval/episode_distance_reward': Array(13.645012, dtype=float32), 'eval/episode_forward_reward': Array(2274.1597, dtype=float32), 'eval/episode_reward': Array(2219.3872, dtype=float32), 'eval/episode_reward_alive': Array(410.20312, dtype=float32), 'eval/episode_reward_linvel': Array(2274.1597, dtype=float32), 'eval/episode_reward_quadctrl': Array(-478.62048, dtype=float32), 'eval/episode_x_position': Array(4831.8975, dtype=float32), 'eval/episode_x_velocity': Array(454.8319, dtype=float32), 'eval/episode_y_position': Array(-411.65286, dtype=float32), 'eval/episode_y_velocity': Array(-119.999084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(568.65247, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8622, dtype=float32), 'eval/episode_forward_reward_std': Array(977.02734, dtype=float32), 'eval/episode_reward_std': Array(1023.1139, dtype=float32), 'eval/episode_reward_alive_std': Array(33.87151, dtype=float32), 'eval/episode_reward_linvel_std': Array(977.02734, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.97219, dtype=float32), 'eval/episode_x_position_std': Array(551.8774, dtype=float32), 'eval/episode_x_velocity_std': Array(195.40547, dtype=float32), 'eval/episode_y_position_std': Array(350.87448, dtype=float32), 'eval/episode_y_velocity_std': Array(89.31081, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42438411712646, 'eval/sps': 938.2486923313229, 'num_steps': 12943360}
{'eval/walltime': 21886.88665151596, 'training/sps': 2945.1388765269066, 'training/walltime': 4454.305652141571, 'training/entropy_loss': Array(0.01314423, dtype=float32), 'training/policy_loss': Array(0.00479733, dtype=float32), 'training/total_loss': Array(0.11627088, dtype=float32), 'training/v_loss': Array(0.09832934, dtype=float32), 'eval/episode_distance_from_origin': Array(4859.8438, dtype=float32), 'eval/episode_distance_reward': Array(12.938262, dtype=float32), 'eval/episode_forward_reward': Array(2156.369, dtype=float32), 'eval/episode_reward': Array(2098.1199, dtype=float32), 'eval/episode_reward_alive': Array(412.39453, dtype=float32), 'eval/episode_reward_linvel': Array(2156.369, dtype=float32), 'eval/episode_reward_quadctrl': Array(-483.5818, dtype=float32), 'eval/episode_x_position': Array(4798.767, dtype=float32), 'eval/episode_x_velocity': Array(431.2738, dtype=float32), 'eval/episode_y_position': Array(-410.02002, dtype=float32), 'eval/episode_y_velocity': Array(-116.046555, dtype=float32), 'eval/episode_distance_from_origin_std': Array(597.55383, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6088424, dtype=float32), 'eval/episode_forward_reward_std': Array(934.8019, dtype=float32), 'eval/episode_reward_std': Array(968.49426, dtype=float32), 'eval/episode_reward_alive_std': Array(32.651012, dtype=float32), 'eval/episode_reward_linvel_std': Array(934.8019, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.671333, dtype=float32), 'eval/episode_x_position_std': Array(578.6916, dtype=float32), 'eval/episode_x_velocity_std': Array(186.96046, dtype=float32), 'eval/episode_y_position_std': Array(322.33762, dtype=float32), 'eval/episode_y_velocity_std': Array(87.076385, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2897572517395, 'eval/sps': 939.175493309981, 'num_steps': 13025280}
{'eval/walltime': 22023.301220417023, 'training/sps': 2941.3294612496325, 'training/walltime': 4482.15700340271, 'training/entropy_loss': Array(0.02013558, dtype=float32), 'training/policy_loss': Array(0.01420361, dtype=float32), 'training/total_loss': Array(0.08084668, dtype=float32), 'training/v_loss': Array(0.0465075, dtype=float32), 'eval/episode_distance_from_origin': Array(4873.9814, dtype=float32), 'eval/episode_distance_reward': Array(13.205412, dtype=float32), 'eval/episode_forward_reward': Array(2200.8936, dtype=float32), 'eval/episode_reward': Array(2142.6074, dtype=float32), 'eval/episode_reward_alive': Array(414.5586, dtype=float32), 'eval/episode_reward_linvel': Array(2200.8936, dtype=float32), 'eval/episode_reward_quadctrl': Array(-486.05008, dtype=float32), 'eval/episode_x_position': Array(4813.158, dtype=float32), 'eval/episode_x_velocity': Array(440.17868, dtype=float32), 'eval/episode_y_position': Array(-403.3388, dtype=float32), 'eval/episode_y_velocity': Array(-116.24544, dtype=float32), 'eval/episode_distance_from_origin_std': Array(594.78314, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1321607, dtype=float32), 'eval/episode_forward_reward_std': Array(1022.021, dtype=float32), 'eval/episode_reward_std': Array(1061.2053, dtype=float32), 'eval/episode_reward_alive_std': Array(29.109346, dtype=float32), 'eval/episode_reward_linvel_std': Array(1022.021, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.268753, dtype=float32), 'eval/episode_x_position_std': Array(577.564, dtype=float32), 'eval/episode_x_velocity_std': Array(204.40419, dtype=float32), 'eval/episode_y_position_std': Array(328.05136, dtype=float32), 'eval/episode_y_velocity_std': Array(89.02792, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.414568901062, 'eval/sps': 938.31620061663, 'num_steps': 13107200}
{'eval/walltime': 22159.551693677902, 'training/sps': 2949.8014546151776, 'training/walltime': 4509.928364038467, 'training/entropy_loss': Array(0.02600294, dtype=float32), 'training/policy_loss': Array(0.10207641, dtype=float32), 'training/total_loss': Array(0.15440172, dtype=float32), 'training/v_loss': Array(0.02632237, dtype=float32), 'eval/episode_distance_from_origin': Array(4689.426, dtype=float32), 'eval/episode_distance_reward': Array(13.480364, dtype=float32), 'eval/episode_forward_reward': Array(2246.7183, dtype=float32), 'eval/episode_reward': Array(2080.3037, dtype=float32), 'eval/episode_reward_alive': Array(296.6836, dtype=float32), 'eval/episode_reward_linvel': Array(2246.7183, dtype=float32), 'eval/episode_reward_quadctrl': Array(-476.57834, dtype=float32), 'eval/episode_x_position': Array(4623.7295, dtype=float32), 'eval/episode_x_velocity': Array(449.34363, dtype=float32), 'eval/episode_y_position': Array(-397.88635, dtype=float32), 'eval/episode_y_velocity': Array(-143.7652, dtype=float32), 'eval/episode_distance_from_origin_std': Array(600.6076, dtype=float32), 'eval/episode_distance_reward_std': Array(7.2151794, dtype=float32), 'eval/episode_forward_reward_std': Array(1202.5232, dtype=float32), 'eval/episode_reward_std': Array(1294.4644, dtype=float32), 'eval/episode_reward_alive_std': Array(50.969425, dtype=float32), 'eval/episode_reward_linvel_std': Array(1202.5232, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(77.96939, dtype=float32), 'eval/episode_x_position_std': Array(584.8322, dtype=float32), 'eval/episode_x_velocity_std': Array(240.50465, dtype=float32), 'eval/episode_y_position_std': Array(340.9783, dtype=float32), 'eval/episode_y_velocity_std': Array(99.62587, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25047326087952, 'eval/sps': 939.446278141858, 'num_steps': 13189120}
{'eval/walltime': 22295.9738574028, 'training/sps': 2941.5240569959383, 'training/walltime': 4537.777872800827, 'training/entropy_loss': Array(0.03266324, dtype=float32), 'training/policy_loss': Array(0.13436452, dtype=float32), 'training/total_loss': Array(0.19735822, dtype=float32), 'training/v_loss': Array(0.03033045, dtype=float32), 'eval/episode_distance_from_origin': Array(4603.964, dtype=float32), 'eval/episode_distance_reward': Array(11.825993, dtype=float32), 'eval/episode_forward_reward': Array(1970.9907, dtype=float32), 'eval/episode_reward': Array(1843.8589, dtype=float32), 'eval/episode_reward_alive': Array(352.42578, dtype=float32), 'eval/episode_reward_linvel': Array(1970.9907, dtype=float32), 'eval/episode_reward_quadctrl': Array(-491.38367, dtype=float32), 'eval/episode_x_position': Array(4532.4727, dtype=float32), 'eval/episode_x_velocity': Array(394.19815, dtype=float32), 'eval/episode_y_position': Array(-449.991, dtype=float32), 'eval/episode_y_velocity': Array(-149.17413, dtype=float32), 'eval/episode_distance_from_origin_std': Array(521.95636, dtype=float32), 'eval/episode_distance_reward_std': Array(5.632028, dtype=float32), 'eval/episode_forward_reward_std': Array(938.6658, dtype=float32), 'eval/episode_reward_std': Array(981.4774, dtype=float32), 'eval/episode_reward_alive_std': Array(49.578777, dtype=float32), 'eval/episode_reward_linvel_std': Array(938.6658, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(72.19375, dtype=float32), 'eval/episode_x_position_std': Array(499.86713, dtype=float32), 'eval/episode_x_velocity_std': Array(187.73315, dtype=float32), 'eval/episode_y_position_std': Array(335.2037, dtype=float32), 'eval/episode_y_velocity_std': Array(97.89954, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4221637248993, 'eval/sps': 938.2639631644978, 'num_steps': 13271040}
{'eval/walltime': 22432.232739925385, 'training/sps': 2946.8498872242426, 'training/walltime': 4565.577049255371, 'training/entropy_loss': Array(0.02056354, dtype=float32), 'training/policy_loss': Array(0.12779906, dtype=float32), 'training/total_loss': Array(0.19391902, dtype=float32), 'training/v_loss': Array(0.0455564, dtype=float32), 'eval/episode_distance_from_origin': Array(4753.454, dtype=float32), 'eval/episode_distance_reward': Array(13.3181305, dtype=float32), 'eval/episode_forward_reward': Array(2219.6787, dtype=float32), 'eval/episode_reward': Array(2125.0083, dtype=float32), 'eval/episode_reward_alive': Array(388.73047, dtype=float32), 'eval/episode_reward_linvel': Array(2219.6787, dtype=float32), 'eval/episode_reward_quadctrl': Array(-496.71884, dtype=float32), 'eval/episode_x_position': Array(4684.46, dtype=float32), 'eval/episode_x_velocity': Array(443.9358, dtype=float32), 'eval/episode_y_position': Array(-442.3418, dtype=float32), 'eval/episode_y_velocity': Array(-141.46097, dtype=float32), 'eval/episode_distance_from_origin_std': Array(556.50183, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4587803, dtype=float32), 'eval/episode_forward_reward_std': Array(1076.4573, dtype=float32), 'eval/episode_reward_std': Array(1121.1304, dtype=float32), 'eval/episode_reward_alive_std': Array(43.263226, dtype=float32), 'eval/episode_reward_linvel_std': Array(1076.4573, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.301704, dtype=float32), 'eval/episode_x_position_std': Array(538.0962, dtype=float32), 'eval/episode_x_velocity_std': Array(215.2915, dtype=float32), 'eval/episode_y_position_std': Array(334.73007, dtype=float32), 'eval/episode_y_velocity_std': Array(100.972404, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.258882522583, 'eval/sps': 939.3882999061422, 'num_steps': 13352960}
{'eval/walltime': 22568.67528605461, 'training/sps': 2937.1495363880167, 'training/walltime': 4593.468036413193, 'training/entropy_loss': Array(0.00903767, dtype=float32), 'training/policy_loss': Array(0.00514746, dtype=float32), 'training/total_loss': Array(0.14807981, dtype=float32), 'training/v_loss': Array(0.13389468, dtype=float32), 'eval/episode_distance_from_origin': Array(4789.515, dtype=float32), 'eval/episode_distance_reward': Array(13.111788, dtype=float32), 'eval/episode_forward_reward': Array(2185.288, dtype=float32), 'eval/episode_reward': Array(2088.6123, dtype=float32), 'eval/episode_reward_alive': Array(385.73828, dtype=float32), 'eval/episode_reward_linvel': Array(2185.288, dtype=float32), 'eval/episode_reward_quadctrl': Array(-495.52582, dtype=float32), 'eval/episode_x_position': Array(4714.218, dtype=float32), 'eval/episode_x_velocity': Array(437.0576, dtype=float32), 'eval/episode_y_position': Array(-509.62497, dtype=float32), 'eval/episode_y_velocity': Array(-157.23389, dtype=float32), 'eval/episode_distance_from_origin_std': Array(523.2882, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5769477, dtype=float32), 'eval/episode_forward_reward_std': Array(929.48596, dtype=float32), 'eval/episode_reward_std': Array(960.5561, dtype=float32), 'eval/episode_reward_alive_std': Array(43.37144, dtype=float32), 'eval/episode_reward_linvel_std': Array(929.48596, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.264774, dtype=float32), 'eval/episode_x_position_std': Array(505.471, dtype=float32), 'eval/episode_x_velocity_std': Array(185.89719, dtype=float32), 'eval/episode_y_position_std': Array(318.15698, dtype=float32), 'eval/episode_y_velocity_std': Array(90.524, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44254612922668, 'eval/sps': 938.1238010522712, 'num_steps': 13434880}
{'eval/walltime': 22705.007827043533, 'training/sps': 2948.3958719088664, 'training/walltime': 4621.252636432648, 'training/entropy_loss': Array(0.02042313, dtype=float32), 'training/policy_loss': Array(0.06408796, dtype=float32), 'training/total_loss': Array(0.20968229, dtype=float32), 'training/v_loss': Array(0.12517121, dtype=float32), 'eval/episode_distance_from_origin': Array(4750.7754, dtype=float32), 'eval/episode_distance_reward': Array(12.805071, dtype=float32), 'eval/episode_forward_reward': Array(2134.1692, dtype=float32), 'eval/episode_reward': Array(2036.7589, dtype=float32), 'eval/episode_reward_alive': Array(389.80078, dtype=float32), 'eval/episode_reward_linvel': Array(2134.1692, dtype=float32), 'eval/episode_reward_quadctrl': Array(-500.01608, dtype=float32), 'eval/episode_x_position': Array(4680.04, dtype=float32), 'eval/episode_x_velocity': Array(426.83386, dtype=float32), 'eval/episode_y_position': Array(-458.44092, dtype=float32), 'eval/episode_y_velocity': Array(-143.87398, dtype=float32), 'eval/episode_distance_from_origin_std': Array(519.9162, dtype=float32), 'eval/episode_distance_reward_std': Array(5.640972, dtype=float32), 'eval/episode_forward_reward_std': Array(940.1569, dtype=float32), 'eval/episode_reward_std': Array(972.40375, dtype=float32), 'eval/episode_reward_alive_std': Array(43.833996, dtype=float32), 'eval/episode_reward_linvel_std': Array(940.1569, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.86654, dtype=float32), 'eval/episode_x_position_std': Array(501.83246, dtype=float32), 'eval/episode_x_velocity_std': Array(188.03142, dtype=float32), 'eval/episode_y_position_std': Array(335.13928, dtype=float32), 'eval/episode_y_velocity_std': Array(91.499985, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33254098892212, 'eval/sps': 938.8807622268318, 'num_steps': 13516800}
{'eval/walltime': 22841.442135810852, 'training/sps': 2939.304253857494, 'training/walltime': 4649.123177528381, 'training/entropy_loss': Array(0.03175392, dtype=float32), 'training/policy_loss': Array(0.1489529, dtype=float32), 'training/total_loss': Array(0.25268772, dtype=float32), 'training/v_loss': Array(0.07198089, dtype=float32), 'eval/episode_distance_from_origin': Array(4648.6226, dtype=float32), 'eval/episode_distance_reward': Array(11.865377, dtype=float32), 'eval/episode_forward_reward': Array(1977.5537, dtype=float32), 'eval/episode_reward': Array(1866.1318, dtype=float32), 'eval/episode_reward_alive': Array(389.15234, dtype=float32), 'eval/episode_reward_linvel': Array(1977.5537, dtype=float32), 'eval/episode_reward_quadctrl': Array(-512.4397, dtype=float32), 'eval/episode_x_position': Array(4574.426, dtype=float32), 'eval/episode_x_velocity': Array(395.5108, dtype=float32), 'eval/episode_y_position': Array(-472.83914, dtype=float32), 'eval/episode_y_velocity': Array(-149.3523, dtype=float32), 'eval/episode_distance_from_origin_std': Array(525.45154, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7105727, dtype=float32), 'eval/episode_forward_reward_std': Array(951.7564, dtype=float32), 'eval/episode_reward_std': Array(985.73315, dtype=float32), 'eval/episode_reward_alive_std': Array(40.39215, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.7564, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.788433, dtype=float32), 'eval/episode_x_position_std': Array(507.55435, dtype=float32), 'eval/episode_x_velocity_std': Array(190.35133, dtype=float32), 'eval/episode_y_position_std': Array(337.0076, dtype=float32), 'eval/episode_y_velocity_std': Array(91.734886, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43430876731873, 'eval/sps': 938.1804412429502, 'num_steps': 13598720}
{'eval/walltime': 22977.761128902435, 'training/sps': 2948.7355391891097, 'training/walltime': 4676.90457701683, 'training/entropy_loss': Array(0.04223446, dtype=float32), 'training/policy_loss': Array(0.12943701, dtype=float32), 'training/total_loss': Array(0.21730196, dtype=float32), 'training/v_loss': Array(0.04563048, dtype=float32), 'eval/episode_distance_from_origin': Array(4538.4526, dtype=float32), 'eval/episode_distance_reward': Array(10.574779, dtype=float32), 'eval/episode_forward_reward': Array(1762.4553, dtype=float32), 'eval/episode_reward': Array(1655.2034, dtype=float32), 'eval/episode_reward_alive': Array(402.04688, dtype=float32), 'eval/episode_reward_linvel': Array(1762.4553, dtype=float32), 'eval/episode_reward_quadctrl': Array(-519.87354, dtype=float32), 'eval/episode_x_position': Array(4481.955, dtype=float32), 'eval/episode_x_velocity': Array(352.49103, dtype=float32), 'eval/episode_y_position': Array(-336.787, dtype=float32), 'eval/episode_y_velocity': Array(-105.359436, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.8413, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4842615, dtype=float32), 'eval/episode_forward_reward_std': Array(747.3722, dtype=float32), 'eval/episode_reward_std': Array(766.8928, dtype=float32), 'eval/episode_reward_alive_std': Array(34.97697, dtype=float32), 'eval/episode_reward_linvel_std': Array(747.3722, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.344772, dtype=float32), 'eval/episode_x_position_std': Array(455.51837, dtype=float32), 'eval/episode_x_velocity_std': Array(149.47443, dtype=float32), 'eval/episode_y_position_std': Array(303.87668, dtype=float32), 'eval/episode_y_velocity_std': Array(84.83063, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31899309158325, 'eval/sps': 938.9740717495301, 'num_steps': 13680640}
{'eval/walltime': 23114.220910787582, 'training/sps': 2940.1848440514855, 'training/walltime': 4704.766770839691, 'training/entropy_loss': Array(0.04426308, dtype=float32), 'training/policy_loss': Array(0.12451847, dtype=float32), 'training/total_loss': Array(0.19805115, dtype=float32), 'training/v_loss': Array(0.0292696, dtype=float32), 'eval/episode_distance_from_origin': Array(4674.0146, dtype=float32), 'eval/episode_distance_reward': Array(12.408035, dtype=float32), 'eval/episode_forward_reward': Array(2067.9966, dtype=float32), 'eval/episode_reward': Array(1971.6111, dtype=float32), 'eval/episode_reward_alive': Array(366.15234, dtype=float32), 'eval/episode_reward_linvel': Array(2067.9966, dtype=float32), 'eval/episode_reward_quadctrl': Array(-474.94568, dtype=float32), 'eval/episode_x_position': Array(4598.823, dtype=float32), 'eval/episode_x_velocity': Array(413.5993, dtype=float32), 'eval/episode_y_position': Array(-496.5367, dtype=float32), 'eval/episode_y_velocity': Array(-153.55405, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.03314, dtype=float32), 'eval/episode_distance_reward_std': Array(5.329916, dtype=float32), 'eval/episode_forward_reward_std': Array(888.31384, dtype=float32), 'eval/episode_reward_std': Array(917.6122, dtype=float32), 'eval/episode_reward_alive_std': Array(49.841805, dtype=float32), 'eval/episode_reward_linvel_std': Array(888.31384, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.29465, dtype=float32), 'eval/episode_x_position_std': Array(456.9572, dtype=float32), 'eval/episode_x_velocity_std': Array(177.66278, dtype=float32), 'eval/episode_y_position_std': Array(316.8002, dtype=float32), 'eval/episode_y_velocity_std': Array(87.87182, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4597818851471, 'eval/sps': 938.0053099288451, 'num_steps': 13762560}
{'eval/walltime': 23250.54743552208, 'training/sps': 2946.549718624227, 'training/walltime': 4732.568779230118, 'training/entropy_loss': Array(0.03431177, dtype=float32), 'training/policy_loss': Array(0.06504689, dtype=float32), 'training/total_loss': Array(0.12258005, dtype=float32), 'training/v_loss': Array(0.02322139, dtype=float32), 'eval/episode_distance_from_origin': Array(4753.7734, dtype=float32), 'eval/episode_distance_reward': Array(13.545966, dtype=float32), 'eval/episode_forward_reward': Array(2257.6504, dtype=float32), 'eval/episode_reward': Array(2161.8384, dtype=float32), 'eval/episode_reward_alive': Array(341.16406, dtype=float32), 'eval/episode_reward_linvel': Array(2257.6504, dtype=float32), 'eval/episode_reward_quadctrl': Array(-450.5221, dtype=float32), 'eval/episode_x_position': Array(4670.0664, dtype=float32), 'eval/episode_x_velocity': Array(451.53006, dtype=float32), 'eval/episode_y_position': Array(-575.3417, dtype=float32), 'eval/episode_y_velocity': Array(-178.09421, dtype=float32), 'eval/episode_distance_from_origin_std': Array(424.37793, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6194153, dtype=float32), 'eval/episode_forward_reward_std': Array(936.56445, dtype=float32), 'eval/episode_reward_std': Array(974.915, dtype=float32), 'eval/episode_reward_alive_std': Array(49.36685, dtype=float32), 'eval/episode_reward_linvel_std': Array(936.56445, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.502266, dtype=float32), 'eval/episode_x_position_std': Array(417.649, dtype=float32), 'eval/episode_x_velocity_std': Array(187.31288, dtype=float32), 'eval/episode_y_position_std': Array(282.45367, dtype=float32), 'eval/episode_y_velocity_std': Array(81.0723, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32652473449707, 'eval/sps': 938.9221961704561, 'num_steps': 13844480}
{'eval/walltime': 23386.999384641647, 'training/sps': 2941.8722431563942, 'training/walltime': 4760.414991855621, 'training/entropy_loss': Array(0.00810656, dtype=float32), 'training/policy_loss': Array(0.00189173, dtype=float32), 'training/total_loss': Array(0.11562046, dtype=float32), 'training/v_loss': Array(0.10562216, dtype=float32), 'eval/episode_distance_from_origin': Array(4751.0176, dtype=float32), 'eval/episode_distance_reward': Array(13.528967, dtype=float32), 'eval/episode_forward_reward': Array(2254.8171, dtype=float32), 'eval/episode_reward': Array(2155.0583, dtype=float32), 'eval/episode_reward_alive': Array(344.1875, dtype=float32), 'eval/episode_reward_linvel': Array(2254.8171, dtype=float32), 'eval/episode_reward_quadctrl': Array(-457.47522, dtype=float32), 'eval/episode_x_position': Array(4670.0825, dtype=float32), 'eval/episode_x_velocity': Array(450.9635, dtype=float32), 'eval/episode_y_position': Array(-561.98035, dtype=float32), 'eval/episode_y_velocity': Array(-175.24918, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.42322, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9497743, dtype=float32), 'eval/episode_forward_reward_std': Array(991.62427, dtype=float32), 'eval/episode_reward_std': Array(1023.88684, dtype=float32), 'eval/episode_reward_alive_std': Array(54.361454, dtype=float32), 'eval/episode_reward_linvel_std': Array(991.62427, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.96053, dtype=float32), 'eval/episode_x_position_std': Array(454.91434, dtype=float32), 'eval/episode_x_velocity_std': Array(198.32487, dtype=float32), 'eval/episode_y_position_std': Array(285.811, dtype=float32), 'eval/episode_y_velocity_std': Array(80.95723, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45194911956787, 'eval/sps': 938.0591543462547, 'num_steps': 13926400}
{'eval/walltime': 23523.36984229088, 'training/sps': 2937.681533642857, 'training/walltime': 4788.300928115845, 'training/entropy_loss': Array(0.01103747, dtype=float32), 'training/policy_loss': Array(0.07022955, dtype=float32), 'training/total_loss': Array(0.23003817, dtype=float32), 'training/v_loss': Array(0.14877115, dtype=float32), 'eval/episode_distance_from_origin': Array(4649.6104, dtype=float32), 'eval/episode_distance_reward': Array(13.199266, dtype=float32), 'eval/episode_forward_reward': Array(2199.8684, dtype=float32), 'eval/episode_reward': Array(2107.6758, dtype=float32), 'eval/episode_reward_alive': Array(320.51172, dtype=float32), 'eval/episode_reward_linvel': Array(2199.8684, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.90375, dtype=float32), 'eval/episode_x_position': Array(4578.076, dtype=float32), 'eval/episode_x_velocity': Array(439.97363, dtype=float32), 'eval/episode_y_position': Array(-464.87787, dtype=float32), 'eval/episode_y_velocity': Array(-150.19922, dtype=float32), 'eval/episode_distance_from_origin_std': Array(441.6316, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0979, dtype=float32), 'eval/episode_forward_reward_std': Array(1016.31116, dtype=float32), 'eval/episode_reward_std': Array(1052.7935, dtype=float32), 'eval/episode_reward_alive_std': Array(60.41162, dtype=float32), 'eval/episode_reward_linvel_std': Array(1016.31116, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.414604, dtype=float32), 'eval/episode_x_position_std': Array(434.06497, dtype=float32), 'eval/episode_x_velocity_std': Array(203.26224, dtype=float32), 'eval/episode_y_position_std': Array(305.2014, dtype=float32), 'eval/episode_y_velocity_std': Array(95.41505, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37045764923096, 'eval/sps': 938.6197143170021, 'num_steps': 14008320}
{'eval/walltime': 23659.794723272324, 'training/sps': 2939.1936231809773, 'training/walltime': 4816.172518253326, 'training/entropy_loss': Array(0.01783208, dtype=float32), 'training/policy_loss': Array(0.09000148, dtype=float32), 'training/total_loss': Array(0.23348147, dtype=float32), 'training/v_loss': Array(0.1256479, dtype=float32), 'eval/episode_distance_from_origin': Array(4673.6807, dtype=float32), 'eval/episode_distance_reward': Array(12.8796835, dtype=float32), 'eval/episode_forward_reward': Array(2146.605, dtype=float32), 'eval/episode_reward': Array(2047.304, dtype=float32), 'eval/episode_reward_alive': Array(320.23828, dtype=float32), 'eval/episode_reward_linvel': Array(2146.605, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.41888, dtype=float32), 'eval/episode_x_position': Array(4606.4155, dtype=float32), 'eval/episode_x_velocity': Array(429.32092, dtype=float32), 'eval/episode_y_position': Array(-429.72803, dtype=float32), 'eval/episode_y_velocity': Array(-144.05997, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.1615, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1063414, dtype=float32), 'eval/episode_forward_reward_std': Array(1017.7182, dtype=float32), 'eval/episode_reward_std': Array(1051.3221, dtype=float32), 'eval/episode_reward_alive_std': Array(65.33519, dtype=float32), 'eval/episode_reward_linvel_std': Array(1017.7182, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.114403, dtype=float32), 'eval/episode_x_position_std': Array(479.70898, dtype=float32), 'eval/episode_x_velocity_std': Array(203.54364, dtype=float32), 'eval/episode_y_position_std': Array(310.75833, dtype=float32), 'eval/episode_y_velocity_std': Array(89.78743, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4248809814453, 'eval/sps': 938.2452751958702, 'num_steps': 14090240}
{'eval/walltime': 23796.10656261444, 'training/sps': 2947.392888301983, 'training/walltime': 4843.966573238373, 'training/entropy_loss': Array(0.02303063, dtype=float32), 'training/policy_loss': Array(0.04349305, dtype=float32), 'training/total_loss': Array(0.14133805, dtype=float32), 'training/v_loss': Array(0.07481437, dtype=float32), 'eval/episode_distance_from_origin': Array(4607.953, dtype=float32), 'eval/episode_distance_reward': Array(12.24953, dtype=float32), 'eval/episode_forward_reward': Array(2041.5793, dtype=float32), 'eval/episode_reward': Array(1937.5487, dtype=float32), 'eval/episode_reward_alive': Array(318.85547, dtype=float32), 'eval/episode_reward_linvel': Array(2041.5793, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.13556, dtype=float32), 'eval/episode_x_position': Array(4541.9414, dtype=float32), 'eval/episode_x_velocity': Array(408.31586, dtype=float32), 'eval/episode_y_position': Array(-416.62592, dtype=float32), 'eval/episode_y_velocity': Array(-135.0264, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.40106, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0949397, dtype=float32), 'eval/episode_forward_reward_std': Array(1015.8173, dtype=float32), 'eval/episode_reward_std': Array(1050.7848, dtype=float32), 'eval/episode_reward_alive_std': Array(60.502327, dtype=float32), 'eval/episode_reward_linvel_std': Array(1015.8173, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.609257, dtype=float32), 'eval/episode_x_position_std': Array(472.70837, dtype=float32), 'eval/episode_x_velocity_std': Array(203.16351, dtype=float32), 'eval/episode_y_position_std': Array(308.4842, dtype=float32), 'eval/episode_y_velocity_std': Array(90.83914, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3118393421173, 'eval/sps': 939.0233498261575, 'num_steps': 14172160}
{'eval/walltime': 23932.556117534637, 'training/sps': 2935.6159220715513, 'training/walltime': 4871.872131109238, 'training/entropy_loss': Array(0.02857837, dtype=float32), 'training/policy_loss': Array(0.04702106, dtype=float32), 'training/total_loss': Array(0.13180846, dtype=float32), 'training/v_loss': Array(0.05620903, dtype=float32), 'eval/episode_distance_from_origin': Array(4695.003, dtype=float32), 'eval/episode_distance_reward': Array(13.7483835, dtype=float32), 'eval/episode_forward_reward': Array(2291.3867, dtype=float32), 'eval/episode_reward': Array(2199.5532, dtype=float32), 'eval/episode_reward_alive': Array(317.66016, dtype=float32), 'eval/episode_reward_linvel': Array(2291.3867, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.2422, dtype=float32), 'eval/episode_x_position': Array(4629.9844, dtype=float32), 'eval/episode_x_velocity': Array(458.2774, dtype=float32), 'eval/episode_y_position': Array(-426.36615, dtype=float32), 'eval/episode_y_velocity': Array(-141.61804, dtype=float32), 'eval/episode_distance_from_origin_std': Array(545.4865, dtype=float32), 'eval/episode_distance_reward_std': Array(6.954901, dtype=float32), 'eval/episode_forward_reward_std': Array(1159.1437, dtype=float32), 'eval/episode_reward_std': Array(1199.5656, dtype=float32), 'eval/episode_reward_alive_std': Array(68.16776, dtype=float32), 'eval/episode_reward_linvel_std': Array(1159.1437, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.644634, dtype=float32), 'eval/episode_x_position_std': Array(535.6534, dtype=float32), 'eval/episode_x_velocity_std': Array(231.82874, dtype=float32), 'eval/episode_y_position_std': Array(294.9192, dtype=float32), 'eval/episode_y_velocity_std': Array(95.31975, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44955492019653, 'eval/sps': 938.0756139135938, 'num_steps': 14254080}
{'eval/walltime': 24068.890620946884, 'training/sps': 2939.819273832929, 'training/walltime': 4899.73778963089, 'training/entropy_loss': Array(0.0333317, dtype=float32), 'training/policy_loss': Array(0.08773522, dtype=float32), 'training/total_loss': Array(0.1616176, dtype=float32), 'training/v_loss': Array(0.04055069, dtype=float32), 'eval/episode_distance_from_origin': Array(4443.924, dtype=float32), 'eval/episode_distance_reward': Array(10.552071, dtype=float32), 'eval/episode_forward_reward': Array(1758.6713, dtype=float32), 'eval/episode_reward': Array(1655.9423, dtype=float32), 'eval/episode_reward_alive': Array(322.89844, dtype=float32), 'eval/episode_reward_linvel': Array(1758.6713, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.1794, dtype=float32), 'eval/episode_x_position': Array(4384.7637, dtype=float32), 'eval/episode_x_velocity': Array(351.73425, dtype=float32), 'eval/episode_y_position': Array(-315.8685, dtype=float32), 'eval/episode_y_velocity': Array(-112.317215, dtype=float32), 'eval/episode_distance_from_origin_std': Array(528.08606, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8239193, dtype=float32), 'eval/episode_forward_reward_std': Array(970.6472, dtype=float32), 'eval/episode_reward_std': Array(996.91833, dtype=float32), 'eval/episode_reward_alive_std': Array(81.872215, dtype=float32), 'eval/episode_reward_linvel_std': Array(970.6472, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.798847, dtype=float32), 'eval/episode_x_position_std': Array(512.44104, dtype=float32), 'eval/episode_x_velocity_std': Array(194.12949, dtype=float32), 'eval/episode_y_position_std': Array(324.14365, dtype=float32), 'eval/episode_y_velocity_std': Array(94.086624, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3345034122467, 'eval/sps': 938.8672478085394, 'num_steps': 14336000}
{'eval/walltime': 24205.314481973648, 'training/sps': 2938.5388098580893, 'training/walltime': 4927.615590572357, 'training/entropy_loss': Array(0.00501159, dtype=float32), 'training/policy_loss': Array(-0.00118239, dtype=float32), 'training/total_loss': Array(0.07930581, dtype=float32), 'training/v_loss': Array(0.07547662, dtype=float32), 'eval/episode_distance_from_origin': Array(4503.1694, dtype=float32), 'eval/episode_distance_reward': Array(11.128415, dtype=float32), 'eval/episode_forward_reward': Array(1854.7285, dtype=float32), 'eval/episode_reward': Array(1754.3931, dtype=float32), 'eval/episode_reward_alive': Array(325.90234, dtype=float32), 'eval/episode_reward_linvel': Array(1854.7285, dtype=float32), 'eval/episode_reward_quadctrl': Array(-437.36597, dtype=float32), 'eval/episode_x_position': Array(4438.2217, dtype=float32), 'eval/episode_x_velocity': Array(370.94568, dtype=float32), 'eval/episode_y_position': Array(-366.24622, dtype=float32), 'eval/episode_y_velocity': Array(-123.17136, dtype=float32), 'eval/episode_distance_from_origin_std': Array(541.0799, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9894457, dtype=float32), 'eval/episode_forward_reward_std': Array(998.23505, dtype=float32), 'eval/episode_reward_std': Array(1024.0785, dtype=float32), 'eval/episode_reward_alive_std': Array(63.298374, dtype=float32), 'eval/episode_reward_linvel_std': Array(998.23505, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.38497, dtype=float32), 'eval/episode_x_position_std': Array(521.1139, dtype=float32), 'eval/episode_x_velocity_std': Array(199.64702, dtype=float32), 'eval/episode_y_position_std': Array(350.3354, dtype=float32), 'eval/episode_y_velocity_std': Array(98.24318, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42386102676392, 'eval/sps': 938.2522898607062, 'num_steps': 14417920}
{'eval/walltime': 24341.693250656128, 'training/sps': 2945.8004485349697, 'training/walltime': 4955.42467045784, 'training/entropy_loss': Array(0.00961209, dtype=float32), 'training/policy_loss': Array(0.00143032, dtype=float32), 'training/total_loss': Array(0.13554345, dtype=float32), 'training/v_loss': Array(0.12450105, dtype=float32), 'eval/episode_distance_from_origin': Array(4382.827, dtype=float32), 'eval/episode_distance_reward': Array(9.899761, dtype=float32), 'eval/episode_forward_reward': Array(1649.9534, dtype=float32), 'eval/episode_reward': Array(1529.6016, dtype=float32), 'eval/episode_reward_alive': Array(308.64844, dtype=float32), 'eval/episode_reward_linvel': Array(1649.9534, dtype=float32), 'eval/episode_reward_quadctrl': Array(-438.89993, dtype=float32), 'eval/episode_x_position': Array(4333.244, dtype=float32), 'eval/episode_x_velocity': Array(329.99066, dtype=float32), 'eval/episode_y_position': Array(-228.37201, dtype=float32), 'eval/episode_y_velocity': Array(-86.38133, dtype=float32), 'eval/episode_distance_from_origin_std': Array(542.41254, dtype=float32), 'eval/episode_distance_reward_std': Array(5.673786, dtype=float32), 'eval/episode_forward_reward_std': Array(945.6251, dtype=float32), 'eval/episode_reward_std': Array(981.95374, dtype=float32), 'eval/episode_reward_alive_std': Array(85.09901, dtype=float32), 'eval/episode_reward_linvel_std': Array(945.6251, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.097546, dtype=float32), 'eval/episode_x_position_std': Array(531.06757, dtype=float32), 'eval/episode_x_velocity_std': Array(189.12505, dtype=float32), 'eval/episode_y_position_std': Array(298.2341, dtype=float32), 'eval/episode_y_velocity_std': Array(84.32487, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37876868247986, 'eval/sps': 938.5625140670722, 'num_steps': 14499840}
{'eval/walltime': 24478.104998111725, 'training/sps': 2934.053567106201, 'training/walltime': 4983.345087766647, 'training/entropy_loss': Array(0.0134209, dtype=float32), 'training/policy_loss': Array(0.01410388, dtype=float32), 'training/total_loss': Array(0.1363849, dtype=float32), 'training/v_loss': Array(0.10886011, dtype=float32), 'eval/episode_distance_from_origin': Array(4451.7095, dtype=float32), 'eval/episode_distance_reward': Array(10.721218, dtype=float32), 'eval/episode_forward_reward': Array(1786.8623, dtype=float32), 'eval/episode_reward': Array(1675.8999, dtype=float32), 'eval/episode_reward_alive': Array(315.60938, dtype=float32), 'eval/episode_reward_linvel': Array(1786.8623, dtype=float32), 'eval/episode_reward_quadctrl': Array(-437.29303, dtype=float32), 'eval/episode_x_position': Array(4396.893, dtype=float32), 'eval/episode_x_velocity': Array(357.37247, dtype=float32), 'eval/episode_y_position': Array(-290.80676, dtype=float32), 'eval/episode_y_velocity': Array(-108.42141, dtype=float32), 'eval/episode_distance_from_origin_std': Array(540.537, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7553043, dtype=float32), 'eval/episode_forward_reward_std': Array(959.21136, dtype=float32), 'eval/episode_reward_std': Array(982.7667, dtype=float32), 'eval/episode_reward_alive_std': Array(89.219086, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.21136, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.917847, dtype=float32), 'eval/episode_x_position_std': Array(524.33124, dtype=float32), 'eval/episode_x_velocity_std': Array(191.84229, dtype=float32), 'eval/episode_y_position_std': Array(310.07254, dtype=float32), 'eval/episode_y_velocity_std': Array(94.99858, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41174745559692, 'eval/sps': 938.33560809464, 'num_steps': 14581760}
{'eval/walltime': 24614.43725347519, 'training/sps': 2947.4995099830535, 'training/walltime': 5011.138137340546, 'training/entropy_loss': Array(0.01912483, dtype=float32), 'training/policy_loss': Array(0.02009137, dtype=float32), 'training/total_loss': Array(0.11270198, dtype=float32), 'training/v_loss': Array(0.07348578, dtype=float32), 'eval/episode_distance_from_origin': Array(4442.305, dtype=float32), 'eval/episode_distance_reward': Array(10.28419, dtype=float32), 'eval/episode_forward_reward': Array(1714.0248, dtype=float32), 'eval/episode_reward': Array(1605.895, dtype=float32), 'eval/episode_reward_alive': Array(324.89453, dtype=float32), 'eval/episode_reward_linvel': Array(1714.0248, dtype=float32), 'eval/episode_reward_quadctrl': Array(-443.3086, dtype=float32), 'eval/episode_x_position': Array(4385.092, dtype=float32), 'eval/episode_x_velocity': Array(342.80496, dtype=float32), 'eval/episode_y_position': Array(-318.59705, dtype=float32), 'eval/episode_y_velocity': Array(-109.4817, dtype=float32), 'eval/episode_distance_from_origin_std': Array(518.97034, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2654552, dtype=float32), 'eval/episode_forward_reward_std': Array(877.57056, dtype=float32), 'eval/episode_reward_std': Array(903.1156, dtype=float32), 'eval/episode_reward_alive_std': Array(77.93591, dtype=float32), 'eval/episode_reward_linvel_std': Array(877.57056, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.029263, dtype=float32), 'eval/episode_x_position_std': Array(503.3247, dtype=float32), 'eval/episode_x_velocity_std': Array(175.51416, dtype=float32), 'eval/episode_y_position_std': Array(304.94287, dtype=float32), 'eval/episode_y_velocity_std': Array(87.98613, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33225536346436, 'eval/sps': 938.8827292466452, 'num_steps': 14663680}
{'eval/walltime': 24750.842550754547, 'training/sps': 2934.6120386013404, 'training/walltime': 5039.053241252899, 'training/entropy_loss': Array(0.02488025, dtype=float32), 'training/policy_loss': Array(0.0535701, dtype=float32), 'training/total_loss': Array(0.13404092, dtype=float32), 'training/v_loss': Array(0.05559056, dtype=float32), 'eval/episode_distance_from_origin': Array(4330.2207, dtype=float32), 'eval/episode_distance_reward': Array(9.105799, dtype=float32), 'eval/episode_forward_reward': Array(1517.6274, dtype=float32), 'eval/episode_reward': Array(1403.4448, dtype=float32), 'eval/episode_reward_alive': Array(330.26562, dtype=float32), 'eval/episode_reward_linvel': Array(1517.6274, dtype=float32), 'eval/episode_reward_quadctrl': Array(-453.55396, dtype=float32), 'eval/episode_x_position': Array(4280.6553, dtype=float32), 'eval/episode_x_velocity': Array(303.52545, dtype=float32), 'eval/episode_y_position': Array(-225.2769, dtype=float32), 'eval/episode_y_velocity': Array(-84.82243, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.76004, dtype=float32), 'eval/episode_distance_reward_std': Array(3.6015277, dtype=float32), 'eval/episode_forward_reward_std': Array(600.25, dtype=float32), 'eval/episode_reward_std': Array(607.6126, dtype=float32), 'eval/episode_reward_alive_std': Array(77.20667, dtype=float32), 'eval/episode_reward_linvel_std': Array(600.25, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.71602, dtype=float32), 'eval/episode_x_position_std': Array(414.66696, dtype=float32), 'eval/episode_x_velocity_std': Array(120.04996, dtype=float32), 'eval/episode_y_position_std': Array(286.49405, dtype=float32), 'eval/episode_y_velocity_std': Array(77.36913, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4052972793579, 'eval/sps': 938.3799790257128, 'num_steps': 14745600}
{'eval/walltime': 24887.16530442238, 'training/sps': 2945.5322337807524, 'training/walltime': 5066.864853382111, 'training/entropy_loss': Array(0.03266644, dtype=float32), 'training/policy_loss': Array(0.27402085, dtype=float32), 'training/total_loss': Array(0.3444286, dtype=float32), 'training/v_loss': Array(0.03774133, dtype=float32), 'eval/episode_distance_from_origin': Array(4229.6694, dtype=float32), 'eval/episode_distance_reward': Array(8.062065, dtype=float32), 'eval/episode_forward_reward': Array(1343.6732, dtype=float32), 'eval/episode_reward': Array(1112.3766, dtype=float32), 'eval/episode_reward_alive': Array(254.51562, dtype=float32), 'eval/episode_reward_linvel': Array(1343.6732, dtype=float32), 'eval/episode_reward_quadctrl': Array(-493.8744, dtype=float32), 'eval/episode_x_position': Array(4161.2812, dtype=float32), 'eval/episode_x_velocity': Array(268.73462, dtype=float32), 'eval/episode_y_position': Array(-415.3192, dtype=float32), 'eval/episode_y_velocity': Array(-144.09879, dtype=float32), 'eval/episode_distance_from_origin_std': Array(392.7281, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8453596, dtype=float32), 'eval/episode_forward_reward_std': Array(474.22293, dtype=float32), 'eval/episode_reward_std': Array(492.95752, dtype=float32), 'eval/episode_reward_alive_std': Array(76.68821, dtype=float32), 'eval/episode_reward_linvel_std': Array(474.22293, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.457655, dtype=float32), 'eval/episode_x_position_std': Array(373.3422, dtype=float32), 'eval/episode_x_velocity_std': Array(94.84462, dtype=float32), 'eval/episode_y_position_std': Array(284.65457, dtype=float32), 'eval/episode_y_velocity_std': Array(75.523834, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32275366783142, 'eval/sps': 938.9481693708233, 'num_steps': 14827520}
{'eval/walltime': 25023.573561906815, 'training/sps': 2943.965740888635, 'training/walltime': 5094.691264152527, 'training/entropy_loss': Array(0.01405185, dtype=float32), 'training/policy_loss': Array(0.03305096, dtype=float32), 'training/total_loss': Array(0.099555, dtype=float32), 'training/v_loss': Array(0.05245218, dtype=float32), 'eval/episode_distance_from_origin': Array(4212.2, dtype=float32), 'eval/episode_distance_reward': Array(8.013715, dtype=float32), 'eval/episode_forward_reward': Array(1335.615, dtype=float32), 'eval/episode_reward': Array(1089.992, dtype=float32), 'eval/episode_reward_alive': Array(233.91016, dtype=float32), 'eval/episode_reward_linvel': Array(1335.615, dtype=float32), 'eval/episode_reward_quadctrl': Array(-487.54706, dtype=float32), 'eval/episode_x_position': Array(4145.747, dtype=float32), 'eval/episode_x_velocity': Array(267.12296, dtype=float32), 'eval/episode_y_position': Array(-394.60147, dtype=float32), 'eval/episode_y_velocity': Array(-138.02647, dtype=float32), 'eval/episode_distance_from_origin_std': Array(381.1102, dtype=float32), 'eval/episode_distance_reward_std': Array(3.075908, dtype=float32), 'eval/episode_forward_reward_std': Array(512.6479, dtype=float32), 'eval/episode_reward_std': Array(537.6766, dtype=float32), 'eval/episode_reward_alive_std': Array(77.64375, dtype=float32), 'eval/episode_reward_linvel_std': Array(512.6479, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.522846, dtype=float32), 'eval/episode_x_position_std': Array(362.42758, dtype=float32), 'eval/episode_x_velocity_std': Array(102.529564, dtype=float32), 'eval/episode_y_position_std': Array(295.61215, dtype=float32), 'eval/episode_y_velocity_std': Array(75.25465, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40825748443604, 'eval/sps': 938.3596151765563, 'num_steps': 14909440}
{'eval/walltime': 25159.895753383636, 'training/sps': 2947.363712169385, 'training/walltime': 5122.4855942726135, 'training/entropy_loss': Array(0.014173, dtype=float32), 'training/policy_loss': Array(0.01138772, dtype=float32), 'training/total_loss': Array(0.14436582, dtype=float32), 'training/v_loss': Array(0.1188051, dtype=float32), 'eval/episode_distance_from_origin': Array(4271.8506, dtype=float32), 'eval/episode_distance_reward': Array(8.372242, dtype=float32), 'eval/episode_forward_reward': Array(1395.369, dtype=float32), 'eval/episode_reward': Array(1164.4778, dtype=float32), 'eval/episode_reward_alive': Array(249.51953, dtype=float32), 'eval/episode_reward_linvel': Array(1395.369, dtype=float32), 'eval/episode_reward_quadctrl': Array(-488.78308, dtype=float32), 'eval/episode_x_position': Array(4200.284, dtype=float32), 'eval/episode_x_velocity': Array(279.07385, dtype=float32), 'eval/episode_y_position': Array(-433.51178, dtype=float32), 'eval/episode_y_velocity': Array(-146.784, dtype=float32), 'eval/episode_distance_from_origin_std': Array(418.00717, dtype=float32), 'eval/episode_distance_reward_std': Array(3.209416, dtype=float32), 'eval/episode_forward_reward_std': Array(534.8988, dtype=float32), 'eval/episode_reward_std': Array(557.8398, dtype=float32), 'eval/episode_reward_alive_std': Array(73.81129, dtype=float32), 'eval/episode_reward_linvel_std': Array(534.8988, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.430653, dtype=float32), 'eval/episode_x_position_std': Array(393.9019, dtype=float32), 'eval/episode_x_velocity_std': Array(106.97977, dtype=float32), 'eval/episode_y_position_std': Array(322.27167, dtype=float32), 'eval/episode_y_velocity_std': Array(83.35675, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3221914768219, 'eval/sps': 938.9520415813087, 'num_steps': 14991360}
{'eval/walltime': 25296.320487976074, 'training/sps': 2941.2449127888563, 'training/walltime': 5150.337746143341, 'training/entropy_loss': Array(0.02411598, dtype=float32), 'training/policy_loss': Array(0.05148292, dtype=float32), 'training/total_loss': Array(0.14694512, dtype=float32), 'training/v_loss': Array(0.07134621, dtype=float32), 'eval/episode_distance_from_origin': Array(4321.8994, dtype=float32), 'eval/episode_distance_reward': Array(8.828614, dtype=float32), 'eval/episode_forward_reward': Array(1471.4312, dtype=float32), 'eval/episode_reward': Array(1224.204, dtype=float32), 'eval/episode_reward_alive': Array(229.3125, dtype=float32), 'eval/episode_reward_linvel': Array(1471.4312, dtype=float32), 'eval/episode_reward_quadctrl': Array(-485.36804, dtype=float32), 'eval/episode_x_position': Array(4252.8223, dtype=float32), 'eval/episode_x_velocity': Array(294.2862, dtype=float32), 'eval/episode_y_position': Array(-432.40125, dtype=float32), 'eval/episode_y_velocity': Array(-148.38208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.27866, dtype=float32), 'eval/episode_distance_reward_std': Array(3.432901, dtype=float32), 'eval/episode_forward_reward_std': Array(572.1463, dtype=float32), 'eval/episode_reward_std': Array(608.5799, dtype=float32), 'eval/episode_reward_alive_std': Array(62.69423, dtype=float32), 'eval/episode_reward_linvel_std': Array(572.1463, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.806978, dtype=float32), 'eval/episode_x_position_std': Array(402.35074, dtype=float32), 'eval/episode_x_velocity_std': Array(114.429214, dtype=float32), 'eval/episode_y_position_std': Array(290.31036, dtype=float32), 'eval/episode_y_velocity_std': Array(71.58509, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42473459243774, 'eval/sps': 938.2462819692761, 'num_steps': 15073280}
{'eval/walltime': 25432.637505054474, 'training/sps': 2943.777404593748, 'training/walltime': 5178.1659371852875, 'training/entropy_loss': Array(0.03235647, dtype=float32), 'training/policy_loss': Array(0.11741766, dtype=float32), 'training/total_loss': Array(0.20308623, dtype=float32), 'training/v_loss': Array(0.05331209, dtype=float32), 'eval/episode_distance_from_origin': Array(4347.0356, dtype=float32), 'eval/episode_distance_reward': Array(8.946112, dtype=float32), 'eval/episode_forward_reward': Array(1491.0135, dtype=float32), 'eval/episode_reward': Array(1250.4645, dtype=float32), 'eval/episode_reward_alive': Array(235.32031, dtype=float32), 'eval/episode_reward_linvel': Array(1491.0135, dtype=float32), 'eval/episode_reward_quadctrl': Array(-484.8155, dtype=float32), 'eval/episode_x_position': Array(4283.6216, dtype=float32), 'eval/episode_x_velocity': Array(298.2027, dtype=float32), 'eval/episode_y_position': Array(-400.5191, dtype=float32), 'eval/episode_y_velocity': Array(-129.42038, dtype=float32), 'eval/episode_distance_from_origin_std': Array(406.70084, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2661028, dtype=float32), 'eval/episode_forward_reward_std': Array(544.3465, dtype=float32), 'eval/episode_reward_std': Array(567.0602, dtype=float32), 'eval/episode_reward_alive_std': Array(58.76884, dtype=float32), 'eval/episode_reward_linvel_std': Array(544.3465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.343838, dtype=float32), 'eval/episode_x_position_std': Array(387.8017, dtype=float32), 'eval/episode_x_velocity_std': Array(108.86928, dtype=float32), 'eval/episode_y_position_std': Array(296.4851, dtype=float32), 'eval/episode_y_velocity_std': Array(77.39753, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31701707839966, 'eval/sps': 938.9876828538853, 'num_steps': 15155200}
{'eval/walltime': 25569.06259894371, 'training/sps': 2942.369618593205, 'training/walltime': 5206.007442712784, 'training/entropy_loss': Array(0.02814796, dtype=float32), 'training/policy_loss': Array(0.3860429, dtype=float32), 'training/total_loss': Array(0.4480945, dtype=float32), 'training/v_loss': Array(0.03390361, dtype=float32), 'eval/episode_distance_from_origin': Array(4445.736, dtype=float32), 'eval/episode_distance_reward': Array(9.748767, dtype=float32), 'eval/episode_forward_reward': Array(1624.7896, dtype=float32), 'eval/episode_reward': Array(1335.6857, dtype=float32), 'eval/episode_reward_alive': Array(153.9336, dtype=float32), 'eval/episode_reward_linvel': Array(1624.7896, dtype=float32), 'eval/episode_reward_quadctrl': Array(-452.78647, dtype=float32), 'eval/episode_x_position': Array(4356.825, dtype=float32), 'eval/episode_x_velocity': Array(324.95792, dtype=float32), 'eval/episode_y_position': Array(-613.5573, dtype=float32), 'eval/episode_y_velocity': Array(-167.52126, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.8895, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6679077, dtype=float32), 'eval/episode_forward_reward_std': Array(777.98, dtype=float32), 'eval/episode_reward_std': Array(862.0653, dtype=float32), 'eval/episode_reward_alive_std': Array(56.47124, dtype=float32), 'eval/episode_reward_linvel_std': Array(777.98, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.124577, dtype=float32), 'eval/episode_x_position_std': Array(360.10367, dtype=float32), 'eval/episode_x_velocity_std': Array(155.59602, dtype=float32), 'eval/episode_y_position_std': Array(301.68176, dtype=float32), 'eval/episode_y_velocity_std': Array(77.10923, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42509388923645, 'eval/sps': 938.2438109511086, 'num_steps': 15237120}
{'eval/walltime': 25705.405876159668, 'training/sps': 2944.918788746365, 'training/walltime': 5233.824848175049, 'training/entropy_loss': Array(0.03178779, dtype=float32), 'training/policy_loss': Array(0.16687375, dtype=float32), 'training/total_loss': Array(0.22391157, dtype=float32), 'training/v_loss': Array(0.02525005, dtype=float32), 'eval/episode_distance_from_origin': Array(4441.172, dtype=float32), 'eval/episode_distance_reward': Array(9.626695, dtype=float32), 'eval/episode_forward_reward': Array(1604.4443, dtype=float32), 'eval/episode_reward': Array(1319.1191, dtype=float32), 'eval/episode_reward_alive': Array(159.71094, dtype=float32), 'eval/episode_reward_linvel': Array(1604.4443, dtype=float32), 'eval/episode_reward_quadctrl': Array(-454.6628, dtype=float32), 'eval/episode_x_position': Array(4360.6113, dtype=float32), 'eval/episode_x_velocity': Array(320.88885, dtype=float32), 'eval/episode_y_position': Array(-557.3229, dtype=float32), 'eval/episode_y_velocity': Array(-157.72292, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.57242, dtype=float32), 'eval/episode_distance_reward_std': Array(4.154911, dtype=float32), 'eval/episode_forward_reward_std': Array(692.48065, dtype=float32), 'eval/episode_reward_std': Array(772.4168, dtype=float32), 'eval/episode_reward_alive_std': Array(61.474705, dtype=float32), 'eval/episode_reward_linvel_std': Array(692.48065, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.632015, dtype=float32), 'eval/episode_x_position_std': Array(381.67032, dtype=float32), 'eval/episode_x_velocity_std': Array(138.49615, dtype=float32), 'eval/episode_y_position_std': Array(295.08957, dtype=float32), 'eval/episode_y_velocity_std': Array(79.64115, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34327721595764, 'eval/sps': 938.8068309173578, 'num_steps': 15319040}
{'eval/walltime': 25841.86692070961, 'training/sps': 2943.439735863507, 'training/walltime': 5261.656231641769, 'training/entropy_loss': Array(0.01882802, dtype=float32), 'training/policy_loss': Array(0.02335016, dtype=float32), 'training/total_loss': Array(0.08620273, dtype=float32), 'training/v_loss': Array(0.04402456, dtype=float32), 'eval/episode_distance_from_origin': Array(4524.404, dtype=float32), 'eval/episode_distance_reward': Array(10.563749, dtype=float32), 'eval/episode_forward_reward': Array(1760.6193, dtype=float32), 'eval/episode_reward': Array(1491.9777, dtype=float32), 'eval/episode_reward_alive': Array(169.86328, dtype=float32), 'eval/episode_reward_linvel': Array(1760.6193, dtype=float32), 'eval/episode_reward_quadctrl': Array(-449.06857, dtype=float32), 'eval/episode_x_position': Array(4438.877, dtype=float32), 'eval/episode_x_velocity': Array(352.12384, dtype=float32), 'eval/episode_y_position': Array(-600.2607, dtype=float32), 'eval/episode_y_velocity': Array(-170.26877, dtype=float32), 'eval/episode_distance_from_origin_std': Array(447.45096, dtype=float32), 'eval/episode_distance_reward_std': Array(4.894159, dtype=float32), 'eval/episode_forward_reward_std': Array(815.68805, dtype=float32), 'eval/episode_reward_std': Array(904.41895, dtype=float32), 'eval/episode_reward_alive_std': Array(63.101597, dtype=float32), 'eval/episode_reward_linvel_std': Array(815.68805, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.515514, dtype=float32), 'eval/episode_x_position_std': Array(431.06372, dtype=float32), 'eval/episode_x_velocity_std': Array(163.13768, dtype=float32), 'eval/episode_y_position_std': Array(292.8806, dtype=float32), 'eval/episode_y_velocity_std': Array(77.90568, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46104454994202, 'eval/sps': 937.996630629297, 'num_steps': 15400960}
{'eval/walltime': 25978.22368788719, 'training/sps': 2945.937491514611, 'training/walltime': 5289.464017868042, 'training/entropy_loss': Array(0.0082433, dtype=float32), 'training/policy_loss': Array(-0.00011302, dtype=float32), 'training/total_loss': Array(0.15095836, dtype=float32), 'training/v_loss': Array(0.14282808, dtype=float32), 'eval/episode_distance_from_origin': Array(4539.56, dtype=float32), 'eval/episode_distance_reward': Array(10.610574, dtype=float32), 'eval/episode_forward_reward': Array(1768.423, dtype=float32), 'eval/episode_reward': Array(1499.7948, dtype=float32), 'eval/episode_reward_alive': Array(167.20703, dtype=float32), 'eval/episode_reward_linvel': Array(1768.423, dtype=float32), 'eval/episode_reward_quadctrl': Array(-446.44577, dtype=float32), 'eval/episode_x_position': Array(4450.9917, dtype=float32), 'eval/episode_x_velocity': Array(353.6846, dtype=float32), 'eval/episode_y_position': Array(-611.75195, dtype=float32), 'eval/episode_y_velocity': Array(-174.05026, dtype=float32), 'eval/episode_distance_from_origin_std': Array(401.41785, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4599276, dtype=float32), 'eval/episode_forward_reward_std': Array(743.31647, dtype=float32), 'eval/episode_reward_std': Array(820.5711, dtype=float32), 'eval/episode_reward_alive_std': Array(52.349094, dtype=float32), 'eval/episode_reward_linvel_std': Array(743.31647, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.937557, dtype=float32), 'eval/episode_x_position_std': Array(387.87756, dtype=float32), 'eval/episode_x_velocity_std': Array(148.66336, dtype=float32), 'eval/episode_y_position_std': Array(304.8276, dtype=float32), 'eval/episode_y_velocity_std': Array(78.20988, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3567671775818, 'eval/sps': 938.7139534725218, 'num_steps': 15482880}
{'eval/walltime': 26114.80811023712, 'training/sps': 2939.689665652757, 'training/walltime': 5317.330904960632, 'training/entropy_loss': Array(0.01167385, dtype=float32), 'training/policy_loss': Array(0.00167436, dtype=float32), 'training/total_loss': Array(0.15165454, dtype=float32), 'training/v_loss': Array(0.13830632, dtype=float32), 'eval/episode_distance_from_origin': Array(4570.2446, dtype=float32), 'eval/episode_distance_reward': Array(10.872002, dtype=float32), 'eval/episode_forward_reward': Array(1811.994, dtype=float32), 'eval/episode_reward': Array(1545.4514, dtype=float32), 'eval/episode_reward_alive': Array(169.47266, dtype=float32), 'eval/episode_reward_linvel': Array(1811.994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-446.88733, dtype=float32), 'eval/episode_x_position': Array(4483.027, dtype=float32), 'eval/episode_x_velocity': Array(362.3988, dtype=float32), 'eval/episode_y_position': Array(-614.3088, dtype=float32), 'eval/episode_y_velocity': Array(-176.91057, dtype=float32), 'eval/episode_distance_from_origin_std': Array(410.39786, dtype=float32), 'eval/episode_distance_reward_std': Array(4.583777, dtype=float32), 'eval/episode_forward_reward_std': Array(763.9572, dtype=float32), 'eval/episode_reward_std': Array(841.93146, dtype=float32), 'eval/episode_reward_alive_std': Array(54.28672, dtype=float32), 'eval/episode_reward_linvel_std': Array(763.9572, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.800816, dtype=float32), 'eval/episode_x_position_std': Array(399.8264, dtype=float32), 'eval/episode_x_velocity_std': Array(152.79144, dtype=float32), 'eval/episode_y_position_std': Array(285.22696, dtype=float32), 'eval/episode_y_velocity_std': Array(75.99724, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5844223499298, 'eval/sps': 937.1493307784655, 'num_steps': 15564800}
{'eval/walltime': 26251.144112110138, 'training/sps': 2942.3577509696347, 'training/walltime': 5345.172522783279, 'training/entropy_loss': Array(0.01493734, dtype=float32), 'training/policy_loss': Array(0.00457655, dtype=float32), 'training/total_loss': Array(0.09924342, dtype=float32), 'training/v_loss': Array(0.07972953, dtype=float32), 'eval/episode_distance_from_origin': Array(4527.536, dtype=float32), 'eval/episode_distance_reward': Array(10.675001, dtype=float32), 'eval/episode_forward_reward': Array(1779.1611, dtype=float32), 'eval/episode_reward': Array(1526.331, dtype=float32), 'eval/episode_reward_alive': Array(177.83594, dtype=float32), 'eval/episode_reward_linvel': Array(1779.1611, dtype=float32), 'eval/episode_reward_quadctrl': Array(-441.3409, dtype=float32), 'eval/episode_x_position': Array(4442.2134, dtype=float32), 'eval/episode_x_velocity': Array(355.8322, dtype=float32), 'eval/episode_y_position': Array(-613.966, dtype=float32), 'eval/episode_y_velocity': Array(-179.91856, dtype=float32), 'eval/episode_distance_from_origin_std': Array(441.0647, dtype=float32), 'eval/episode_distance_reward_std': Array(4.906434, dtype=float32), 'eval/episode_forward_reward_std': Array(817.7341, dtype=float32), 'eval/episode_reward_std': Array(898.21643, dtype=float32), 'eval/episode_reward_alive_std': Array(56.788673, dtype=float32), 'eval/episode_reward_linvel_std': Array(817.7341, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.12016, dtype=float32), 'eval/episode_x_position_std': Array(430.56357, dtype=float32), 'eval/episode_x_velocity_std': Array(163.54675, dtype=float32), 'eval/episode_y_position_std': Array(254.25282, dtype=float32), 'eval/episode_y_velocity_std': Array(64.1536, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33600187301636, 'eval/sps': 938.856928775273, 'num_steps': 15646720}
{'eval/walltime': 26387.634706258774, 'training/sps': 2930.3266606518328, 'training/walltime': 5373.128450393677, 'training/entropy_loss': Array(0.01919494, dtype=float32), 'training/policy_loss': Array(0.02529638, dtype=float32), 'training/total_loss': Array(0.09871229, dtype=float32), 'training/v_loss': Array(0.05422097, dtype=float32), 'eval/episode_distance_from_origin': Array(4485.2095, dtype=float32), 'eval/episode_distance_reward': Array(10.220774, dtype=float32), 'eval/episode_forward_reward': Array(1703.4564, dtype=float32), 'eval/episode_reward': Array(1458.8596, dtype=float32), 'eval/episode_reward_alive': Array(182.11719, dtype=float32), 'eval/episode_reward_linvel': Array(1703.4564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.9347, dtype=float32), 'eval/episode_x_position': Array(4402.19, dtype=float32), 'eval/episode_x_velocity': Array(340.69128, dtype=float32), 'eval/episode_y_position': Array(-599.5679, dtype=float32), 'eval/episode_y_velocity': Array(-173.64276, dtype=float32), 'eval/episode_distance_from_origin_std': Array(474.89682, dtype=float32), 'eval/episode_distance_reward_std': Array(4.547837, dtype=float32), 'eval/episode_forward_reward_std': Array(757.9674, dtype=float32), 'eval/episode_reward_std': Array(831.2258, dtype=float32), 'eval/episode_reward_alive_std': Array(54.17973, dtype=float32), 'eval/episode_reward_linvel_std': Array(757.9674, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.052635, dtype=float32), 'eval/episode_x_position_std': Array(452.33066, dtype=float32), 'eval/episode_x_velocity_std': Array(151.59349, dtype=float32), 'eval/episode_y_position_std': Array(279.46558, dtype=float32), 'eval/episode_y_velocity_std': Array(71.63469, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49059414863586, 'eval/sps': 937.7935585847787, 'num_steps': 15728640}
{'eval/walltime': 26523.957482099533, 'training/sps': 2933.872408998863, 'training/walltime': 5401.05059170723, 'training/entropy_loss': Array(0.02348694, dtype=float32), 'training/policy_loss': Array(0.05582317, dtype=float32), 'training/total_loss': Array(0.12592098, dtype=float32), 'training/v_loss': Array(0.04661087, dtype=float32), 'eval/episode_distance_from_origin': Array(4408.84, dtype=float32), 'eval/episode_distance_reward': Array(9.748266, dtype=float32), 'eval/episode_forward_reward': Array(1624.7063, dtype=float32), 'eval/episode_reward': Array(1384.5083, dtype=float32), 'eval/episode_reward_alive': Array(170.51172, dtype=float32), 'eval/episode_reward_linvel': Array(1624.7063, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.45764, dtype=float32), 'eval/episode_x_position': Array(4325.673, dtype=float32), 'eval/episode_x_velocity': Array(324.94122, dtype=float32), 'eval/episode_y_position': Array(-607.52856, dtype=float32), 'eval/episode_y_velocity': Array(-171.92377, dtype=float32), 'eval/episode_distance_from_origin_std': Array(389.83276, dtype=float32), 'eval/episode_distance_reward_std': Array(4.037266, dtype=float32), 'eval/episode_forward_reward_std': Array(672.87317, dtype=float32), 'eval/episode_reward_std': Array(741.78143, dtype=float32), 'eval/episode_reward_alive_std': Array(52.809853, dtype=float32), 'eval/episode_reward_linvel_std': Array(672.87317, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.81112, dtype=float32), 'eval/episode_x_position_std': Array(379.6017, dtype=float32), 'eval/episode_x_velocity_std': Array(134.57458, dtype=float32), 'eval/episode_y_position_std': Array(218.5668, dtype=float32), 'eval/episode_y_velocity_std': Array(57.810577, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32277584075928, 'eval/sps': 938.9480166507082, 'num_steps': 15810560}
{'eval/walltime': 26660.397438526154, 'training/sps': 2937.3395366039745, 'training/walltime': 5428.939774751663, 'training/entropy_loss': Array(0.02141122, dtype=float32), 'training/policy_loss': Array(0.06428255, dtype=float32), 'training/total_loss': Array(0.12141097, dtype=float32), 'training/v_loss': Array(0.0357172, dtype=float32), 'eval/episode_distance_from_origin': Array(4285.702, dtype=float32), 'eval/episode_distance_reward': Array(8.378077, dtype=float32), 'eval/episode_forward_reward': Array(1396.3434, dtype=float32), 'eval/episode_reward': Array(1160.7645, dtype=float32), 'eval/episode_reward_alive': Array(160.33203, dtype=float32), 'eval/episode_reward_linvel': Array(1396.3434, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.28894, dtype=float32), 'eval/episode_x_position': Array(4217.6387, dtype=float32), 'eval/episode_x_velocity': Array(279.26865, dtype=float32), 'eval/episode_y_position': Array(-496.3822, dtype=float32), 'eval/episode_y_velocity': Array(-138.20872, dtype=float32), 'eval/episode_distance_from_origin_std': Array(387.73758, dtype=float32), 'eval/episode_distance_reward_std': Array(3.4280112, dtype=float32), 'eval/episode_forward_reward_std': Array(571.3322, dtype=float32), 'eval/episode_reward_std': Array(616.5733, dtype=float32), 'eval/episode_reward_alive_std': Array(44.448017, dtype=float32), 'eval/episode_reward_linvel_std': Array(571.3322, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.380913, dtype=float32), 'eval/episode_x_position_std': Array(380.2827, dtype=float32), 'eval/episode_x_velocity_std': Array(114.26641, dtype=float32), 'eval/episode_y_position_std': Array(222.1891, dtype=float32), 'eval/episode_y_velocity_std': Array(56.782955, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43995642662048, 'eval/sps': 938.1416071386711, 'num_steps': 15892480}
{'eval/walltime': 26796.74409365654, 'training/sps': 2942.518412953455, 'training/walltime': 5456.77987241745, 'training/entropy_loss': Array(0.00535815, dtype=float32), 'training/policy_loss': Array(-0.00175405, dtype=float32), 'training/total_loss': Array(0.12804547, dtype=float32), 'training/v_loss': Array(0.12444137, dtype=float32), 'eval/episode_distance_from_origin': Array(4362.1157, dtype=float32), 'eval/episode_distance_reward': Array(8.744563, dtype=float32), 'eval/episode_forward_reward': Array(1457.424, dtype=float32), 'eval/episode_reward': Array(1206.3059, dtype=float32), 'eval/episode_reward_alive': Array(161.40625, dtype=float32), 'eval/episode_reward_linvel': Array(1457.424, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.2691, dtype=float32), 'eval/episode_x_position': Array(4277.226, dtype=float32), 'eval/episode_x_velocity': Array(291.48483, dtype=float32), 'eval/episode_y_position': Array(-611.4064, dtype=float32), 'eval/episode_y_velocity': Array(-167.33948, dtype=float32), 'eval/episode_distance_from_origin_std': Array(375.13818, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3508167, dtype=float32), 'eval/episode_forward_reward_std': Array(558.4661, dtype=float32), 'eval/episode_reward_std': Array(605.31573, dtype=float32), 'eval/episode_reward_alive_std': Array(43.65269, dtype=float32), 'eval/episode_reward_linvel_std': Array(558.4661, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.1536, dtype=float32), 'eval/episode_x_position_std': Array(359.48862, dtype=float32), 'eval/episode_x_velocity_std': Array(111.693184, dtype=float32), 'eval/episode_y_position_std': Array(238.08797, dtype=float32), 'eval/episode_y_velocity_std': Array(60.74339, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34665513038635, 'eval/sps': 938.783572487315, 'num_steps': 15974400}
{'eval/walltime': 26933.181394338608, 'training/sps': 2939.663106567227, 'training/walltime': 5484.64701128006, 'training/entropy_loss': Array(0.00886246, dtype=float32), 'training/policy_loss': Array(-0.00064153, dtype=float32), 'training/total_loss': Array(0.13013583, dtype=float32), 'training/v_loss': Array(0.12191489, dtype=float32), 'eval/episode_distance_from_origin': Array(4489.073, dtype=float32), 'eval/episode_distance_reward': Array(10.267546, dtype=float32), 'eval/episode_forward_reward': Array(1711.2527, dtype=float32), 'eval/episode_reward': Array(1497.456, dtype=float32), 'eval/episode_reward_alive': Array(179.42578, dtype=float32), 'eval/episode_reward_linvel': Array(1711.2527, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.48975, dtype=float32), 'eval/episode_x_position': Array(4400.4272, dtype=float32), 'eval/episode_x_velocity': Array(342.2505, dtype=float32), 'eval/episode_y_position': Array(-648.4741, dtype=float32), 'eval/episode_y_velocity': Array(-179.628, dtype=float32), 'eval/episode_distance_from_origin_std': Array(413.24612, dtype=float32), 'eval/episode_distance_reward_std': Array(3.758517, dtype=float32), 'eval/episode_forward_reward_std': Array(626.41534, dtype=float32), 'eval/episode_reward_std': Array(678.282, dtype=float32), 'eval/episode_reward_alive_std': Array(52.62448, dtype=float32), 'eval/episode_reward_linvel_std': Array(626.41534, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.28819, dtype=float32), 'eval/episode_x_position_std': Array(401.74673, dtype=float32), 'eval/episode_x_velocity_std': Array(125.28302, dtype=float32), 'eval/episode_y_position_std': Array(221.28848, dtype=float32), 'eval/episode_y_velocity_std': Array(53.984467, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43730068206787, 'eval/sps': 938.1598680134487, 'num_steps': 16056320}
{'eval/walltime': 27070.15629887581, 'training/sps': 2946.2668408064255, 'training/walltime': 5512.451689004898, 'training/entropy_loss': Array(0.01060724, dtype=float32), 'training/policy_loss': Array(0.00164141, dtype=float32), 'training/total_loss': Array(0.08934723, dtype=float32), 'training/v_loss': Array(0.07709858, dtype=float32), 'eval/episode_distance_from_origin': Array(4486.505, dtype=float32), 'eval/episode_distance_reward': Array(10.364271, dtype=float32), 'eval/episode_forward_reward': Array(1727.373, dtype=float32), 'eval/episode_reward': Array(1505.6035, dtype=float32), 'eval/episode_reward_alive': Array(176.35547, dtype=float32), 'eval/episode_reward_linvel': Array(1727.373, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.48938, dtype=float32), 'eval/episode_x_position': Array(4402.1504, dtype=float32), 'eval/episode_x_velocity': Array(345.4746, dtype=float32), 'eval/episode_y_position': Array(-610.427, dtype=float32), 'eval/episode_y_velocity': Array(-173.33984, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.08603, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8331842, dtype=float32), 'eval/episode_forward_reward_std': Array(805.52576, dtype=float32), 'eval/episode_reward_std': Array(876.4651, dtype=float32), 'eval/episode_reward_alive_std': Array(57.118984, dtype=float32), 'eval/episode_reward_linvel_std': Array(805.52576, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.949627, dtype=float32), 'eval/episode_x_position_std': Array(483.1966, dtype=float32), 'eval/episode_x_velocity_std': Array(161.10513, dtype=float32), 'eval/episode_y_position_std': Array(247.12646, dtype=float32), 'eval/episode_y_velocity_std': Array(64.601326, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.97490453720093, 'eval/sps': 934.4777456314018, 'num_steps': 16138240}
{'eval/walltime': 27206.590648651123, 'training/sps': 2940.878651019304, 'training/walltime': 5540.307309627533, 'training/entropy_loss': Array(0.01234064, dtype=float32), 'training/policy_loss': Array(0.0055459, dtype=float32), 'training/total_loss': Array(0.07323821, dtype=float32), 'training/v_loss': Array(0.05535167, dtype=float32), 'eval/episode_distance_from_origin': Array(4515.359, dtype=float32), 'eval/episode_distance_reward': Array(10.577757, dtype=float32), 'eval/episode_forward_reward': Array(1762.9543, dtype=float32), 'eval/episode_reward': Array(1561.7822, dtype=float32), 'eval/episode_reward_alive': Array(181.10156, dtype=float32), 'eval/episode_reward_linvel': Array(1762.9543, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.8515, dtype=float32), 'eval/episode_x_position': Array(4436.161, dtype=float32), 'eval/episode_x_velocity': Array(352.59082, dtype=float32), 'eval/episode_y_position': Array(-581.6725, dtype=float32), 'eval/episode_y_velocity': Array(-159.89726, dtype=float32), 'eval/episode_distance_from_origin_std': Array(467.13013, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5287786, dtype=float32), 'eval/episode_forward_reward_std': Array(754.7918, dtype=float32), 'eval/episode_reward_std': Array(808.74994, dtype=float32), 'eval/episode_reward_alive_std': Array(56.71207, dtype=float32), 'eval/episode_reward_linvel_std': Array(754.7918, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.93502, dtype=float32), 'eval/episode_x_position_std': Array(455.9712, dtype=float32), 'eval/episode_x_velocity_std': Array(150.95828, dtype=float32), 'eval/episode_y_position_std': Array(258.85434, dtype=float32), 'eval/episode_y_velocity_std': Array(64.55608, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43434977531433, 'eval/sps': 938.1801592545838, 'num_steps': 16220160}
{'eval/walltime': 27342.952004671097, 'training/sps': 2945.559656567075, 'training/walltime': 5568.1186628341675, 'training/entropy_loss': Array(0.01224658, dtype=float32), 'training/policy_loss': Array(0.00297066, dtype=float32), 'training/total_loss': Array(0.0569465, dtype=float32), 'training/v_loss': Array(0.04172926, dtype=float32), 'eval/episode_distance_from_origin': Array(4466.0444, dtype=float32), 'eval/episode_distance_reward': Array(9.988916, dtype=float32), 'eval/episode_forward_reward': Array(1664.815, dtype=float32), 'eval/episode_reward': Array(1506.6029, dtype=float32), 'eval/episode_reward_alive': Array(213.23828, dtype=float32), 'eval/episode_reward_linvel': Array(1664.815, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.43906, dtype=float32), 'eval/episode_x_position': Array(4390.8716, dtype=float32), 'eval/episode_x_velocity': Array(332.96295, dtype=float32), 'eval/episode_y_position': Array(-538.89465, dtype=float32), 'eval/episode_y_velocity': Array(-144.46222, dtype=float32), 'eval/episode_distance_from_origin_std': Array(426.79526, dtype=float32), 'eval/episode_distance_reward_std': Array(4.0835834, dtype=float32), 'eval/episode_forward_reward_std': Array(680.5927, dtype=float32), 'eval/episode_reward_std': Array(718.3163, dtype=float32), 'eval/episode_reward_alive_std': Array(65.99914, dtype=float32), 'eval/episode_reward_linvel_std': Array(680.5927, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.271904, dtype=float32), 'eval/episode_x_position_std': Array(413.95453, dtype=float32), 'eval/episode_x_velocity_std': Array(136.11859, dtype=float32), 'eval/episode_y_position_std': Array(285.459, dtype=float32), 'eval/episode_y_velocity_std': Array(74.13983, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.36135601997375, 'eval/sps': 938.6823638014497, 'num_steps': 16302080}
{'eval/walltime': 27479.391285657883, 'training/sps': 2934.5921378671637, 'training/walltime': 5596.033956050873, 'training/entropy_loss': Array(0.01168083, dtype=float32), 'training/policy_loss': Array(0.00178128, dtype=float32), 'training/total_loss': Array(0.05008833, dtype=float32), 'training/v_loss': Array(0.03662622, dtype=float32), 'eval/episode_distance_from_origin': Array(4558.452, dtype=float32), 'eval/episode_distance_reward': Array(11.165466, dtype=float32), 'eval/episode_forward_reward': Array(1860.9048, dtype=float32), 'eval/episode_reward': Array(1695.3882, dtype=float32), 'eval/episode_reward_alive': Array(205.28906, dtype=float32), 'eval/episode_reward_linvel': Array(1860.9048, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.97134, dtype=float32), 'eval/episode_x_position': Array(4483.167, dtype=float32), 'eval/episode_x_velocity': Array(372.181, dtype=float32), 'eval/episode_y_position': Array(-552.48145, dtype=float32), 'eval/episode_y_velocity': Array(-150.47757, dtype=float32), 'eval/episode_distance_from_origin_std': Array(459.03592, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7536073, dtype=float32), 'eval/episode_forward_reward_std': Array(792.26263, dtype=float32), 'eval/episode_reward_std': Array(832.5156, dtype=float32), 'eval/episode_reward_alive_std': Array(63.668285, dtype=float32), 'eval/episode_reward_linvel_std': Array(792.26263, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.30285, dtype=float32), 'eval/episode_x_position_std': Array(445.39398, dtype=float32), 'eval/episode_x_velocity_std': Array(158.45255, dtype=float32), 'eval/episode_y_position_std': Array(277.29855, dtype=float32), 'eval/episode_y_velocity_std': Array(75.12891, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4392809867859, 'eval/sps': 938.1462513892665, 'num_steps': 16384000}
{'eval/walltime': 27616.374332666397, 'training/sps': 2944.132128446368, 'training/walltime': 5623.858794212341, 'training/entropy_loss': Array(0.0049949, dtype=float32), 'training/policy_loss': Array(-0.00257001, dtype=float32), 'training/total_loss': Array(0.08464162, dtype=float32), 'training/v_loss': Array(0.08221672, dtype=float32), 'eval/episode_distance_from_origin': Array(4681.1216, dtype=float32), 'eval/episode_distance_reward': Array(11.727897, dtype=float32), 'eval/episode_forward_reward': Array(1954.6423, dtype=float32), 'eval/episode_reward': Array(1759.0985, dtype=float32), 'eval/episode_reward_alive': Array(194.20312, dtype=float32), 'eval/episode_reward_linvel': Array(1954.6423, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.47498, dtype=float32), 'eval/episode_x_position': Array(4602.2383, dtype=float32), 'eval/episode_x_velocity': Array(390.92847, dtype=float32), 'eval/episode_y_position': Array(-588.4633, dtype=float32), 'eval/episode_y_velocity': Array(-160.84747, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.8302, dtype=float32), 'eval/episode_distance_reward_std': Array(3.980056, dtype=float32), 'eval/episode_forward_reward_std': Array(663.33777, dtype=float32), 'eval/episode_reward_std': Array(710.0762, dtype=float32), 'eval/episode_reward_alive_std': Array(62.209618, dtype=float32), 'eval/episode_reward_linvel_std': Array(663.33777, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.582775, dtype=float32), 'eval/episode_x_position_std': Array(426.8162, dtype=float32), 'eval/episode_x_velocity_std': Array(132.66762, dtype=float32), 'eval/episode_y_position_std': Array(280.89957, dtype=float32), 'eval/episode_y_velocity_std': Array(67.50977, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.9830470085144, 'eval/sps': 934.4221989166583, 'num_steps': 16465920}
{'eval/walltime': 27752.657165050507, 'training/sps': 2948.5157738213743, 'training/walltime': 5651.64226436615, 'training/entropy_loss': Array(0.00866337, dtype=float32), 'training/policy_loss': Array(-0.0016092, dtype=float32), 'training/total_loss': Array(0.1529902, dtype=float32), 'training/v_loss': Array(0.14593603, dtype=float32), 'eval/episode_distance_from_origin': Array(4658.2607, dtype=float32), 'eval/episode_distance_reward': Array(11.5076885, dtype=float32), 'eval/episode_forward_reward': Array(1917.941, dtype=float32), 'eval/episode_reward': Array(1708.2751, dtype=float32), 'eval/episode_reward_alive': Array(192.66406, dtype=float32), 'eval/episode_reward_linvel': Array(1917.941, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.83752, dtype=float32), 'eval/episode_x_position': Array(4578.498, dtype=float32), 'eval/episode_x_velocity': Array(383.58823, dtype=float32), 'eval/episode_y_position': Array(-581.3796, dtype=float32), 'eval/episode_y_velocity': Array(-163.76022, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.4514, dtype=float32), 'eval/episode_distance_reward_std': Array(4.1196575, dtype=float32), 'eval/episode_forward_reward_std': Array(686.6048, dtype=float32), 'eval/episode_reward_std': Array(728.95245, dtype=float32), 'eval/episode_reward_alive_std': Array(68.32047, dtype=float32), 'eval/episode_reward_linvel_std': Array(686.6048, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.37522, dtype=float32), 'eval/episode_x_position_std': Array(416.40363, dtype=float32), 'eval/episode_x_velocity_std': Array(137.32098, dtype=float32), 'eval/episode_y_position_std': Array(292.39023, dtype=float32), 'eval/episode_y_velocity_std': Array(71.510704, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2828323841095, 'eval/sps': 939.2232151386129, 'num_steps': 16547840}
{'eval/walltime': 27888.92722415924, 'training/sps': 2946.7588547240166, 'training/walltime': 5679.442299604416, 'training/entropy_loss': Array(0.01061718, dtype=float32), 'training/policy_loss': Array(-0.00013129, dtype=float32), 'training/total_loss': Array(0.12069133, dtype=float32), 'training/v_loss': Array(0.11020543, dtype=float32), 'eval/episode_distance_from_origin': Array(4696.263, dtype=float32), 'eval/episode_distance_reward': Array(12.262236, dtype=float32), 'eval/episode_forward_reward': Array(2043.6976, dtype=float32), 'eval/episode_reward': Array(1837.779, dtype=float32), 'eval/episode_reward_alive': Array(190.0664, dtype=float32), 'eval/episode_reward_linvel': Array(2043.6976, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.24725, dtype=float32), 'eval/episode_x_position': Array(4619.368, dtype=float32), 'eval/episode_x_velocity': Array(408.73956, dtype=float32), 'eval/episode_y_position': Array(-559.8529, dtype=float32), 'eval/episode_y_velocity': Array(-165.83305, dtype=float32), 'eval/episode_distance_from_origin_std': Array(439.70758, dtype=float32), 'eval/episode_distance_reward_std': Array(4.1905704, dtype=float32), 'eval/episode_forward_reward_std': Array(698.4234, dtype=float32), 'eval/episode_reward_std': Array(746.38367, dtype=float32), 'eval/episode_reward_alive_std': Array(48.837517, dtype=float32), 'eval/episode_reward_linvel_std': Array(698.4234, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.72609, dtype=float32), 'eval/episode_x_position_std': Array(427.34317, dtype=float32), 'eval/episode_x_velocity_std': Array(139.6847, dtype=float32), 'eval/episode_y_position_std': Array(296.5597, dtype=float32), 'eval/episode_y_velocity_std': Array(70.03437, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27005910873413, 'eval/sps': 939.3112532362286, 'num_steps': 16629760}
{'eval/walltime': 28025.0360789299, 'training/sps': 2944.763871119731, 'training/walltime': 5707.261168479919, 'training/entropy_loss': Array(0.01068469, dtype=float32), 'training/policy_loss': Array(0.00071058, dtype=float32), 'training/total_loss': Array(0.08750285, dtype=float32), 'training/v_loss': Array(0.07610758, dtype=float32), 'eval/episode_distance_from_origin': Array(4799.576, dtype=float32), 'eval/episode_distance_reward': Array(13.190184, dtype=float32), 'eval/episode_forward_reward': Array(2198.355, dtype=float32), 'eval/episode_reward': Array(2007.4993, dtype=float32), 'eval/episode_reward_alive': Array(199.54688, dtype=float32), 'eval/episode_reward_linvel': Array(2198.355, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.59274, dtype=float32), 'eval/episode_x_position': Array(4716.631, dtype=float32), 'eval/episode_x_velocity': Array(439.671, dtype=float32), 'eval/episode_y_position': Array(-632.3966, dtype=float32), 'eval/episode_y_velocity': Array(-181.60597, dtype=float32), 'eval/episode_distance_from_origin_std': Array(449.17215, dtype=float32), 'eval/episode_distance_reward_std': Array(4.446782, dtype=float32), 'eval/episode_forward_reward_std': Array(741.12555, dtype=float32), 'eval/episode_reward_std': Array(795.14514, dtype=float32), 'eval/episode_reward_alive_std': Array(53.969006, dtype=float32), 'eval/episode_reward_linvel_std': Array(741.12555, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.945797, dtype=float32), 'eval/episode_x_position_std': Array(438.1386, dtype=float32), 'eval/episode_x_velocity_std': Array(148.22508, dtype=float32), 'eval/episode_y_position_std': Array(244.5975, dtype=float32), 'eval/episode_y_velocity_std': Array(59.159256, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1088547706604, 'eval/sps': 940.423752853379, 'num_steps': 16711680}
{'eval/walltime': 28161.814912080765, 'training/sps': 2947.3593888921155, 'training/walltime': 5735.055539369583, 'training/entropy_loss': Array(0.01103926, dtype=float32), 'training/policy_loss': Array(0.00098919, dtype=float32), 'training/total_loss': Array(0.07727722, dtype=float32), 'training/v_loss': Array(0.06524877, dtype=float32), 'eval/episode_distance_from_origin': Array(4795.3027, dtype=float32), 'eval/episode_distance_reward': Array(13.163776, dtype=float32), 'eval/episode_forward_reward': Array(2193.954, dtype=float32), 'eval/episode_reward': Array(2021.4031, dtype=float32), 'eval/episode_reward_alive': Array(202.97266, dtype=float32), 'eval/episode_reward_linvel': Array(2193.954, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.6874, dtype=float32), 'eval/episode_x_position': Array(4716.8438, dtype=float32), 'eval/episode_x_velocity': Array(438.79077, dtype=float32), 'eval/episode_y_position': Array(-571.723, dtype=float32), 'eval/episode_y_velocity': Array(-166.4732, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.6208, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8031178, dtype=float32), 'eval/episode_forward_reward_std': Array(800.51465, dtype=float32), 'eval/episode_reward_std': Array(851.6165, dtype=float32), 'eval/episode_reward_alive_std': Array(59.528202, dtype=float32), 'eval/episode_reward_linvel_std': Array(800.51465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.528292, dtype=float32), 'eval/episode_x_position_std': Array(476.10532, dtype=float32), 'eval/episode_x_velocity_std': Array(160.1029, dtype=float32), 'eval/episode_y_position_std': Array(313.15887, dtype=float32), 'eval/episode_y_velocity_std': Array(80.12252, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.77883315086365, 'eval/sps': 935.8173121627613, 'num_steps': 16793600}
{'eval/walltime': 28298.237644910812, 'training/sps': 2943.2866378266353, 'training/walltime': 5762.888370513916, 'training/entropy_loss': Array(0.00971444, dtype=float32), 'training/policy_loss': Array(0.00037336, dtype=float32), 'training/total_loss': Array(0.06074939, dtype=float32), 'training/v_loss': Array(0.05066158, dtype=float32), 'eval/episode_distance_from_origin': Array(4691.7324, dtype=float32), 'eval/episode_distance_reward': Array(11.960778, dtype=float32), 'eval/episode_forward_reward': Array(1993.4556, dtype=float32), 'eval/episode_reward': Array(1816.5354, dtype=float32), 'eval/episode_reward_alive': Array(191.92969, dtype=float32), 'eval/episode_reward_linvel': Array(1993.4556, dtype=float32), 'eval/episode_reward_quadctrl': Array(-380.8104, dtype=float32), 'eval/episode_x_position': Array(4614.5, dtype=float32), 'eval/episode_x_velocity': Array(398.6911, dtype=float32), 'eval/episode_y_position': Array(-567.10297, dtype=float32), 'eval/episode_y_velocity': Array(-155.98807, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.5558, dtype=float32), 'eval/episode_distance_reward_std': Array(4.017049, dtype=float32), 'eval/episode_forward_reward_std': Array(669.5035, dtype=float32), 'eval/episode_reward_std': Array(708.5259, dtype=float32), 'eval/episode_reward_alive_std': Array(62.56115, dtype=float32), 'eval/episode_reward_linvel_std': Array(669.5035, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.572487, dtype=float32), 'eval/episode_x_position_std': Array(437.98776, dtype=float32), 'eval/episode_x_velocity_std': Array(133.90068, dtype=float32), 'eval/episode_y_position_std': Array(299.17993, dtype=float32), 'eval/episode_y_velocity_std': Array(70.846405, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4227328300476, 'eval/sps': 938.2600490745156, 'num_steps': 16875520}
{'eval/walltime': 28434.559380292892, 'training/sps': 2946.403472398948, 'training/walltime': 5790.6917588710785, 'training/entropy_loss': Array(0.00546215, dtype=float32), 'training/policy_loss': Array(-0.00148145, dtype=float32), 'training/total_loss': Array(0.07155439, dtype=float32), 'training/v_loss': Array(0.06757369, dtype=float32), 'eval/episode_distance_from_origin': Array(4658.2705, dtype=float32), 'eval/episode_distance_reward': Array(12.252531, dtype=float32), 'eval/episode_forward_reward': Array(2042.0807, dtype=float32), 'eval/episode_reward': Array(1874.2601, dtype=float32), 'eval/episode_reward_alive': Array(193.79297, dtype=float32), 'eval/episode_reward_linvel': Array(2042.0807, dtype=float32), 'eval/episode_reward_quadctrl': Array(-373.8657, dtype=float32), 'eval/episode_x_position': Array(4584.541, dtype=float32), 'eval/episode_x_velocity': Array(408.4161, dtype=float32), 'eval/episode_y_position': Array(-519.5372, dtype=float32), 'eval/episode_y_velocity': Array(-149.84186, dtype=float32), 'eval/episode_distance_from_origin_std': Array(433.86005, dtype=float32), 'eval/episode_distance_reward_std': Array(3.8720553, dtype=float32), 'eval/episode_forward_reward_std': Array(645.33777, dtype=float32), 'eval/episode_reward_std': Array(681.06506, dtype=float32), 'eval/episode_reward_alive_std': Array(48.831165, dtype=float32), 'eval/episode_reward_linvel_std': Array(645.33777, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.297657, dtype=float32), 'eval/episode_x_position_std': Array(419.36368, dtype=float32), 'eval/episode_x_velocity_std': Array(129.06761, dtype=float32), 'eval/episode_y_position_std': Array(330.28195, dtype=float32), 'eval/episode_y_velocity_std': Array(72.356575, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32173538208008, 'eval/sps': 938.9551830545872, 'num_steps': 16957440}
{'eval/walltime': 28571.014963150024, 'training/sps': 2938.832673088812, 'training/walltime': 5818.566772222519, 'training/entropy_loss': Array(0.01012678, dtype=float32), 'training/policy_loss': Array(-0.00048784, dtype=float32), 'training/total_loss': Array(0.15642548, dtype=float32), 'training/v_loss': Array(0.14678654, dtype=float32), 'eval/episode_distance_from_origin': Array(4780.335, dtype=float32), 'eval/episode_distance_reward': Array(12.999549, dtype=float32), 'eval/episode_forward_reward': Array(2166.5825, dtype=float32), 'eval/episode_reward': Array(1983.0132, dtype=float32), 'eval/episode_reward_alive': Array(192.21875, dtype=float32), 'eval/episode_reward_linvel': Array(2166.5825, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.78766, dtype=float32), 'eval/episode_x_position': Array(4702.5176, dtype=float32), 'eval/episode_x_velocity': Array(433.3165, dtype=float32), 'eval/episode_y_position': Array(-549.9772, dtype=float32), 'eval/episode_y_velocity': Array(-159.45126, dtype=float32), 'eval/episode_distance_from_origin_std': Array(467.89868, dtype=float32), 'eval/episode_distance_reward_std': Array(4.437927, dtype=float32), 'eval/episode_forward_reward_std': Array(739.64935, dtype=float32), 'eval/episode_reward_std': Array(776.74927, dtype=float32), 'eval/episode_reward_alive_std': Array(53.339485, dtype=float32), 'eval/episode_reward_linvel_std': Array(739.64935, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.151154, dtype=float32), 'eval/episode_x_position_std': Array(454.0439, dtype=float32), 'eval/episode_x_velocity_std': Array(147.92986, dtype=float32), 'eval/episode_y_position_std': Array(346.57742, dtype=float32), 'eval/episode_y_velocity_std': Array(77.135086, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45558285713196, 'eval/sps': 938.0341743438604, 'num_steps': 17039360}
{'eval/walltime': 28707.40732550621, 'training/sps': 2946.931143914924, 'training/walltime': 5846.365182161331, 'training/entropy_loss': Array(0.00961933, dtype=float32), 'training/policy_loss': Array(0.00128689, dtype=float32), 'training/total_loss': Array(0.12850565, dtype=float32), 'training/v_loss': Array(0.11759943, dtype=float32), 'eval/episode_distance_from_origin': Array(4903.3823, dtype=float32), 'eval/episode_distance_reward': Array(13.927561, dtype=float32), 'eval/episode_forward_reward': Array(2321.25, dtype=float32), 'eval/episode_reward': Array(2147.9175, dtype=float32), 'eval/episode_reward_alive': Array(206.02734, dtype=float32), 'eval/episode_reward_linvel': Array(2321.25, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.28772, dtype=float32), 'eval/episode_x_position': Array(4824.5854, dtype=float32), 'eval/episode_x_velocity': Array(464.25, dtype=float32), 'eval/episode_y_position': Array(-598.3593, dtype=float32), 'eval/episode_y_velocity': Array(-172.10791, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.65887, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2154093, dtype=float32), 'eval/episode_forward_reward_std': Array(702.56396, dtype=float32), 'eval/episode_reward_std': Array(743.3089, dtype=float32), 'eval/episode_reward_alive_std': Array(48.399353, dtype=float32), 'eval/episode_reward_linvel_std': Array(702.56396, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.93454, dtype=float32), 'eval/episode_x_position_std': Array(430.13126, dtype=float32), 'eval/episode_x_velocity_std': Array(140.51279, dtype=float32), 'eval/episode_y_position_std': Array(280.16745, dtype=float32), 'eval/episode_y_velocity_std': Array(63.81176, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3923623561859, 'eval/sps': 938.4689713470215, 'num_steps': 17121280}
{'eval/walltime': 28843.815108299255, 'training/sps': 2939.94371145701, 'training/walltime': 5874.229661226273, 'training/entropy_loss': Array(0.00964869, dtype=float32), 'training/policy_loss': Array(0.00206381, dtype=float32), 'training/total_loss': Array(0.10025938, dtype=float32), 'training/v_loss': Array(0.08854689, dtype=float32), 'eval/episode_distance_from_origin': Array(4913.052, dtype=float32), 'eval/episode_distance_reward': Array(13.889991, dtype=float32), 'eval/episode_forward_reward': Array(2314.989, dtype=float32), 'eval/episode_reward': Array(2153.3743, dtype=float32), 'eval/episode_reward_alive': Array(208.95312, dtype=float32), 'eval/episode_reward_linvel': Array(2314.989, dtype=float32), 'eval/episode_reward_quadctrl': Array(-384.4576, dtype=float32), 'eval/episode_x_position': Array(4835.766, dtype=float32), 'eval/episode_x_velocity': Array(462.9978, dtype=float32), 'eval/episode_y_position': Array(-568.5817, dtype=float32), 'eval/episode_y_velocity': Array(-159.33444, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.70297, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4860797, dtype=float32), 'eval/episode_forward_reward_std': Array(747.67554, dtype=float32), 'eval/episode_reward_std': Array(780.1044, dtype=float32), 'eval/episode_reward_alive_std': Array(56.373867, dtype=float32), 'eval/episode_reward_linvel_std': Array(747.67554, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.303432, dtype=float32), 'eval/episode_x_position_std': Array(466.1855, dtype=float32), 'eval/episode_x_velocity_std': Array(149.5351, dtype=float32), 'eval/episode_y_position_std': Array(335.32132, dtype=float32), 'eval/episode_y_velocity_std': Array(81.40622, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40778279304504, 'eval/sps': 938.3628806150955, 'num_steps': 17203200}
{'eval/walltime': 28980.32465362549, 'training/sps': 2944.7066834269403, 'training/walltime': 5902.049070358276, 'training/entropy_loss': Array(0.00891239, dtype=float32), 'training/policy_loss': Array(0.00096908, dtype=float32), 'training/total_loss': Array(0.07088469, dtype=float32), 'training/v_loss': Array(0.06100322, dtype=float32), 'eval/episode_distance_from_origin': Array(4853.835, dtype=float32), 'eval/episode_distance_reward': Array(13.475283, dtype=float32), 'eval/episode_forward_reward': Array(2245.871, dtype=float32), 'eval/episode_reward': Array(2082.3113, dtype=float32), 'eval/episode_reward_alive': Array(202.10938, dtype=float32), 'eval/episode_reward_linvel': Array(2245.871, dtype=float32), 'eval/episode_reward_quadctrl': Array(-379.14438, dtype=float32), 'eval/episode_x_position': Array(4778.2227, dtype=float32), 'eval/episode_x_velocity': Array(449.17426, dtype=float32), 'eval/episode_y_position': Array(-555.083, dtype=float32), 'eval/episode_y_velocity': Array(-155.88617, dtype=float32), 'eval/episode_distance_from_origin_std': Array(456.66022, dtype=float32), 'eval/episode_distance_reward_std': Array(4.144823, dtype=float32), 'eval/episode_forward_reward_std': Array(690.8, dtype=float32), 'eval/episode_reward_std': Array(727.16785, dtype=float32), 'eval/episode_reward_alive_std': Array(51.79979, dtype=float32), 'eval/episode_reward_linvel_std': Array(690.8, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.59794, dtype=float32), 'eval/episode_x_position_std': Array(445.31793, dtype=float32), 'eval/episode_x_velocity_std': Array(138.15999, dtype=float32), 'eval/episode_y_position_std': Array(325.55814, dtype=float32), 'eval/episode_y_velocity_std': Array(76.6312, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5095453262329, 'eval/sps': 937.6633677454814, 'num_steps': 17285120}
{'eval/walltime': 29116.764308691025, 'training/sps': 2954.194137549685, 'training/walltime': 5929.779136896133, 'training/entropy_loss': Array(0.00805171, dtype=float32), 'training/policy_loss': Array(0.00320114, dtype=float32), 'training/total_loss': Array(0.06204198, dtype=float32), 'training/v_loss': Array(0.05078912, dtype=float32), 'eval/episode_distance_from_origin': Array(4772.695, dtype=float32), 'eval/episode_distance_reward': Array(12.855678, dtype=float32), 'eval/episode_forward_reward': Array(2142.6035, dtype=float32), 'eval/episode_reward': Array(1982.9783, dtype=float32), 'eval/episode_reward_alive': Array(196.6211, dtype=float32), 'eval/episode_reward_linvel': Array(2142.6035, dtype=float32), 'eval/episode_reward_quadctrl': Array(-369.10214, dtype=float32), 'eval/episode_x_position': Array(4702.107, dtype=float32), 'eval/episode_x_velocity': Array(428.52075, dtype=float32), 'eval/episode_y_position': Array(-501.92548, dtype=float32), 'eval/episode_y_velocity': Array(-148.75806, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.88055, dtype=float32), 'eval/episode_distance_reward_std': Array(3.9817538, dtype=float32), 'eval/episode_forward_reward_std': Array(663.6209, dtype=float32), 'eval/episode_reward_std': Array(696.95593, dtype=float32), 'eval/episode_reward_alive_std': Array(56.343143, dtype=float32), 'eval/episode_reward_linvel_std': Array(663.6209, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.97738, dtype=float32), 'eval/episode_x_position_std': Array(449.15103, dtype=float32), 'eval/episode_x_velocity_std': Array(132.72421, dtype=float32), 'eval/episode_y_position_std': Array(341.70892, dtype=float32), 'eval/episode_y_velocity_std': Array(81.555305, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4396550655365, 'eval/sps': 938.1436792589174, 'num_steps': 17367040}
{'eval/walltime': 29253.296863794327, 'training/sps': 2957.407615210452, 'training/walltime': 5957.479072332382, 'training/entropy_loss': Array(0.00622004, dtype=float32), 'training/policy_loss': Array(-0.00094088, dtype=float32), 'training/total_loss': Array(0.05899157, dtype=float32), 'training/v_loss': Array(0.05371241, dtype=float32), 'eval/episode_distance_from_origin': Array(4733.362, dtype=float32), 'eval/episode_distance_reward': Array(12.112016, dtype=float32), 'eval/episode_forward_reward': Array(2018.6603, dtype=float32), 'eval/episode_reward': Array(1857.6912, dtype=float32), 'eval/episode_reward_alive': Array(191.4414, dtype=float32), 'eval/episode_reward_linvel': Array(2018.6603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-364.52246, dtype=float32), 'eval/episode_x_position': Array(4665.457, dtype=float32), 'eval/episode_x_velocity': Array(403.73206, dtype=float32), 'eval/episode_y_position': Array(-489.2566, dtype=float32), 'eval/episode_y_velocity': Array(-137.45386, dtype=float32), 'eval/episode_distance_from_origin_std': Array(371.61826, dtype=float32), 'eval/episode_distance_reward_std': Array(3.4355884, dtype=float32), 'eval/episode_forward_reward_std': Array(572.5938, dtype=float32), 'eval/episode_reward_std': Array(611.4329, dtype=float32), 'eval/episode_reward_alive_std': Array(57.62177, dtype=float32), 'eval/episode_reward_linvel_std': Array(572.5938, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.74793, dtype=float32), 'eval/episode_x_position_std': Array(358.1032, dtype=float32), 'eval/episode_x_velocity_std': Array(114.51879, dtype=float32), 'eval/episode_y_position_std': Array(317.05783, dtype=float32), 'eval/episode_y_velocity_std': Array(71.39663, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.532555103302, 'eval/sps': 937.5053437120093, 'num_steps': 17448960}
{'eval/walltime': 29389.75998520851, 'training/sps': 2946.716297316779, 'training/walltime': 5985.279509067535, 'training/entropy_loss': Array(0.0097671, dtype=float32), 'training/policy_loss': Array(0.00012451, dtype=float32), 'training/total_loss': Array(0.1511032, dtype=float32), 'training/v_loss': Array(0.14121158, dtype=float32), 'eval/episode_distance_from_origin': Array(4818.774, dtype=float32), 'eval/episode_distance_reward': Array(12.643459, dtype=float32), 'eval/episode_forward_reward': Array(2107.234, dtype=float32), 'eval/episode_reward': Array(1942.4548, dtype=float32), 'eval/episode_reward_alive': Array(191.39062, dtype=float32), 'eval/episode_reward_linvel': Array(2107.234, dtype=float32), 'eval/episode_reward_quadctrl': Array(-368.81342, dtype=float32), 'eval/episode_x_position': Array(4738.2095, dtype=float32), 'eval/episode_x_velocity': Array(421.44678, dtype=float32), 'eval/episode_y_position': Array(-611.0439, dtype=float32), 'eval/episode_y_velocity': Array(-165.66232, dtype=float32), 'eval/episode_distance_from_origin_std': Array(407.79272, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3237367, dtype=float32), 'eval/episode_forward_reward_std': Array(553.95276, dtype=float32), 'eval/episode_reward_std': Array(581.22266, dtype=float32), 'eval/episode_reward_alive_std': Array(50.79562, dtype=float32), 'eval/episode_reward_linvel_std': Array(553.95276, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.471268, dtype=float32), 'eval/episode_x_position_std': Array(393.79996, dtype=float32), 'eval/episode_x_velocity_std': Array(110.79063, dtype=float32), 'eval/episode_y_position_std': Array(289.03354, dtype=float32), 'eval/episode_y_velocity_std': Array(64.70767, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46312141418457, 'eval/sps': 937.9823550386348, 'num_steps': 17530880}
{'eval/walltime': 29526.110661506653, 'training/sps': 2949.2029120184357, 'training/walltime': 6013.056505918503, 'training/entropy_loss': Array(0.0095332, dtype=float32), 'training/policy_loss': Array(0.00468779, dtype=float32), 'training/total_loss': Array(0.1335916, dtype=float32), 'training/v_loss': Array(0.11937061, dtype=float32), 'eval/episode_distance_from_origin': Array(4754.8403, dtype=float32), 'eval/episode_distance_reward': Array(12.210911, dtype=float32), 'eval/episode_forward_reward': Array(2035.1431, dtype=float32), 'eval/episode_reward': Array(1873.3246, dtype=float32), 'eval/episode_reward_alive': Array(194.2461, dtype=float32), 'eval/episode_reward_linvel': Array(2035.1431, dtype=float32), 'eval/episode_reward_quadctrl': Array(-368.27542, dtype=float32), 'eval/episode_x_position': Array(4681.9023, dtype=float32), 'eval/episode_x_velocity': Array(407.02856, dtype=float32), 'eval/episode_y_position': Array(-540.556, dtype=float32), 'eval/episode_y_velocity': Array(-151.56949, dtype=float32), 'eval/episode_distance_from_origin_std': Array(432.82562, dtype=float32), 'eval/episode_distance_reward_std': Array(3.6828213, dtype=float32), 'eval/episode_forward_reward_std': Array(613.7995, dtype=float32), 'eval/episode_reward_std': Array(640.03796, dtype=float32), 'eval/episode_reward_alive_std': Array(53.09959, dtype=float32), 'eval/episode_reward_linvel_std': Array(613.7995, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.925667, dtype=float32), 'eval/episode_x_position_std': Array(421.53198, dtype=float32), 'eval/episode_x_velocity_std': Array(122.75986, dtype=float32), 'eval/episode_y_position_std': Array(300.5763, dtype=float32), 'eval/episode_y_velocity_std': Array(71.30129, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35067629814148, 'eval/sps': 938.755886476998, 'num_steps': 17612800}
{'eval/walltime': 29662.310267925262, 'training/sps': 2944.560897668051, 'training/walltime': 6040.877292394638, 'training/entropy_loss': Array(0.0077351, dtype=float32), 'training/policy_loss': Array(0.00412268, dtype=float32), 'training/total_loss': Array(0.07400959, dtype=float32), 'training/v_loss': Array(0.06215181, dtype=float32), 'eval/episode_distance_from_origin': Array(4782.7544, dtype=float32), 'eval/episode_distance_reward': Array(12.173317, dtype=float32), 'eval/episode_forward_reward': Array(2028.877, dtype=float32), 'eval/episode_reward': Array(1864.9172, dtype=float32), 'eval/episode_reward_alive': Array(189.66797, dtype=float32), 'eval/episode_reward_linvel': Array(2028.877, dtype=float32), 'eval/episode_reward_quadctrl': Array(-365.80133, dtype=float32), 'eval/episode_x_position': Array(4710.0234, dtype=float32), 'eval/episode_x_velocity': Array(405.7754, dtype=float32), 'eval/episode_y_position': Array(-547.673, dtype=float32), 'eval/episode_y_velocity': Array(-144.71133, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.2184, dtype=float32), 'eval/episode_distance_reward_std': Array(3.8164592, dtype=float32), 'eval/episode_forward_reward_std': Array(636.07166, dtype=float32), 'eval/episode_reward_std': Array(664.39465, dtype=float32), 'eval/episode_reward_alive_std': Array(67.1518, dtype=float32), 'eval/episode_reward_linvel_std': Array(636.07166, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.943226, dtype=float32), 'eval/episode_x_position_std': Array(432.4684, dtype=float32), 'eval/episode_x_velocity_std': Array(127.21439, dtype=float32), 'eval/episode_y_position_std': Array(308.96933, dtype=float32), 'eval/episode_y_velocity_std': Array(75.468315, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.19960641860962, 'eval/sps': 939.7971357317427, 'num_steps': 17694720}
{'eval/walltime': 29798.617193698883, 'training/sps': 2952.441685545982, 'training/walltime': 6068.623818397522, 'training/entropy_loss': Array(0.00532452, dtype=float32), 'training/policy_loss': Array(0.00496019, dtype=float32), 'training/total_loss': Array(0.04699335, dtype=float32), 'training/v_loss': Array(0.03670864, dtype=float32), 'eval/episode_distance_from_origin': Array(4598.593, dtype=float32), 'eval/episode_distance_reward': Array(10.629658, dtype=float32), 'eval/episode_forward_reward': Array(1771.603, dtype=float32), 'eval/episode_reward': Array(1619.5674, dtype=float32), 'eval/episode_reward_alive': Array(174.03906, dtype=float32), 'eval/episode_reward_linvel': Array(1771.603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-336.70435, dtype=float32), 'eval/episode_x_position': Array(4537.7617, dtype=float32), 'eval/episode_x_velocity': Array(354.3206, dtype=float32), 'eval/episode_y_position': Array(-452.2698, dtype=float32), 'eval/episode_y_velocity': Array(-114.61257, dtype=float32), 'eval/episode_distance_from_origin_std': Array(393.53925, dtype=float32), 'eval/episode_distance_reward_std': Array(3.3082492, dtype=float32), 'eval/episode_forward_reward_std': Array(551.371, dtype=float32), 'eval/episode_reward_std': Array(573.1004, dtype=float32), 'eval/episode_reward_alive_std': Array(71.68318, dtype=float32), 'eval/episode_reward_linvel_std': Array(551.371, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.78517, dtype=float32), 'eval/episode_x_position_std': Array(383.75525, dtype=float32), 'eval/episode_x_velocity_std': Array(110.274216, dtype=float32), 'eval/episode_y_position_std': Array(276.50287, dtype=float32), 'eval/episode_y_velocity_std': Array(66.86406, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3069257736206, 'eval/sps': 939.0571995775416, 'num_steps': 17776640}
{'eval/walltime': 29934.789850711823, 'training/sps': 2949.415057954945, 'training/walltime': 6096.3988173007965, 'training/entropy_loss': Array(0.00410627, dtype=float32), 'training/policy_loss': Array(-0.00352637, dtype=float32), 'training/total_loss': Array(0.02726325, dtype=float32), 'training/v_loss': Array(0.02668335, dtype=float32), 'eval/episode_distance_from_origin': Array(4563.0024, dtype=float32), 'eval/episode_distance_reward': Array(10.099539, dtype=float32), 'eval/episode_forward_reward': Array(1683.25, dtype=float32), 'eval/episode_reward': Array(1522.7084, dtype=float32), 'eval/episode_reward_alive': Array(162.98828, dtype=float32), 'eval/episode_reward_linvel': Array(1683.25, dtype=float32), 'eval/episode_reward_quadctrl': Array(-333.62952, dtype=float32), 'eval/episode_x_position': Array(4504.3525, dtype=float32), 'eval/episode_x_velocity': Array(336.65002, dtype=float32), 'eval/episode_y_position': Array(-417.67163, dtype=float32), 'eval/episode_y_velocity': Array(-103.6374, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.825, dtype=float32), 'eval/episode_distance_reward_std': Array(3.6214201, dtype=float32), 'eval/episode_forward_reward_std': Array(603.56586, dtype=float32), 'eval/episode_reward_std': Array(623.3744, dtype=float32), 'eval/episode_reward_alive_std': Array(68.8313, dtype=float32), 'eval/episode_reward_linvel_std': Array(603.56586, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.433815, dtype=float32), 'eval/episode_x_position_std': Array(437.2001, dtype=float32), 'eval/episode_x_velocity_std': Array(120.71316, dtype=float32), 'eval/episode_y_position_std': Array(307.32166, dtype=float32), 'eval/episode_y_velocity_std': Array(71.0806, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.17265701293945, 'eval/sps': 939.9831273604152, 'num_steps': 17858560}
{'eval/walltime': 30071.368575811386, 'training/sps': 2951.811006369895, 'training/walltime': 6124.15127158165, 'training/entropy_loss': Array(0.00294457, dtype=float32), 'training/policy_loss': Array(0.00119147, dtype=float32), 'training/total_loss': Array(0.02965052, dtype=float32), 'training/v_loss': Array(0.02551448, dtype=float32), 'eval/episode_distance_from_origin': Array(4398.3037, dtype=float32), 'eval/episode_distance_reward': Array(8.659307, dtype=float32), 'eval/episode_forward_reward': Array(1443.213, dtype=float32), 'eval/episode_reward': Array(1326.475, dtype=float32), 'eval/episode_reward_alive': Array(191.9961, dtype=float32), 'eval/episode_reward_linvel': Array(1443.213, dtype=float32), 'eval/episode_reward_quadctrl': Array(-317.3933, dtype=float32), 'eval/episode_x_position': Array(4349.4126, dtype=float32), 'eval/episode_x_velocity': Array(288.6426, dtype=float32), 'eval/episode_y_position': Array(-336.32275, dtype=float32), 'eval/episode_y_velocity': Array(-79.25023, dtype=float32), 'eval/episode_distance_from_origin_std': Array(370.44177, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8553376, dtype=float32), 'eval/episode_forward_reward_std': Array(475.8855, dtype=float32), 'eval/episode_reward_std': Array(485.14633, dtype=float32), 'eval/episode_reward_alive_std': Array(111.73716, dtype=float32), 'eval/episode_reward_linvel_std': Array(475.8855, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.482666, dtype=float32), 'eval/episode_x_position_std': Array(364.9453, dtype=float32), 'eval/episode_x_velocity_std': Array(95.17707, dtype=float32), 'eval/episode_y_position_std': Array(249.29372, dtype=float32), 'eval/episode_y_velocity_std': Array(54.80815, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5787250995636, 'eval/sps': 937.1884230628903, 'num_steps': 17940480}
{'eval/walltime': 30207.663559675217, 'training/sps': 2935.598841861555, 'training/walltime': 6152.056991815567, 'training/entropy_loss': Array(0.00951806, dtype=float32), 'training/policy_loss': Array(0.0008648, dtype=float32), 'training/total_loss': Array(0.14580914, dtype=float32), 'training/v_loss': Array(0.13542628, dtype=float32), 'eval/episode_distance_from_origin': Array(4532.788, dtype=float32), 'eval/episode_distance_reward': Array(9.682692, dtype=float32), 'eval/episode_forward_reward': Array(1613.7761, dtype=float32), 'eval/episode_reward': Array(1481.8167, dtype=float32), 'eval/episode_reward_alive': Array(191.91016, dtype=float32), 'eval/episode_reward_linvel': Array(1613.7761, dtype=float32), 'eval/episode_reward_quadctrl': Array(-333.55237, dtype=float32), 'eval/episode_x_position': Array(4474.3086, dtype=float32), 'eval/episode_x_velocity': Array(322.7552, dtype=float32), 'eval/episode_y_position': Array(-395.78033, dtype=float32), 'eval/episode_y_velocity': Array(-97.39154, dtype=float32), 'eval/episode_distance_from_origin_std': Array(419.46, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2617826, dtype=float32), 'eval/episode_forward_reward_std': Array(543.62616, dtype=float32), 'eval/episode_reward_std': Array(562.4986, dtype=float32), 'eval/episode_reward_alive_std': Array(101.21644, dtype=float32), 'eval/episode_reward_linvel_std': Array(543.62616, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.723373, dtype=float32), 'eval/episode_x_position_std': Array(406.8523, dtype=float32), 'eval/episode_x_velocity_std': Array(108.72523, dtype=float32), 'eval/episode_y_position_std': Array(325.06052, dtype=float32), 'eval/episode_y_velocity_std': Array(76.77511, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29498386383057, 'eval/sps': 939.1394780007612, 'num_steps': 18022400}
{'eval/walltime': 30343.877222537994, 'training/sps': 2949.2405289882554, 'training/walltime': 6179.833634376526, 'training/entropy_loss': Array(0.00752571, dtype=float32), 'training/policy_loss': Array(0.00647935, dtype=float32), 'training/total_loss': Array(0.11830198, dtype=float32), 'training/v_loss': Array(0.10429692, dtype=float32), 'eval/episode_distance_from_origin': Array(4498.9375, dtype=float32), 'eval/episode_distance_reward': Array(9.573675, dtype=float32), 'eval/episode_forward_reward': Array(1595.6067, dtype=float32), 'eval/episode_reward': Array(1465.9517, dtype=float32), 'eval/episode_reward_alive': Array(192.72656, dtype=float32), 'eval/episode_reward_linvel': Array(1595.6067, dtype=float32), 'eval/episode_reward_quadctrl': Array(-331.9552, dtype=float32), 'eval/episode_x_position': Array(4437.2266, dtype=float32), 'eval/episode_x_velocity': Array(319.12134, dtype=float32), 'eval/episode_y_position': Array(-428.95038, dtype=float32), 'eval/episode_y_velocity': Array(-104.51836, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.2519, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2151718, dtype=float32), 'eval/episode_forward_reward_std': Array(535.85736, dtype=float32), 'eval/episode_reward_std': Array(540.5888, dtype=float32), 'eval/episode_reward_alive_std': Array(96.4584, dtype=float32), 'eval/episode_reward_linvel_std': Array(535.85736, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.529892, dtype=float32), 'eval/episode_x_position_std': Array(363.19507, dtype=float32), 'eval/episode_x_velocity_std': Array(107.17148, dtype=float32), 'eval/episode_y_position_std': Array(315.70816, dtype=float32), 'eval/episode_y_velocity_std': Array(72.904305, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2136628627777, 'eval/sps': 939.7001542271704, 'num_steps': 18104320}
{'eval/walltime': 30480.065093040466, 'training/sps': 2942.632973445267, 'training/walltime': 6207.672648191452, 'training/entropy_loss': Array(0.00440768, dtype=float32), 'training/policy_loss': Array(0.04548938, dtype=float32), 'training/total_loss': Array(0.09111129, dtype=float32), 'training/v_loss': Array(0.04121423, dtype=float32), 'eval/episode_distance_from_origin': Array(4589.2227, dtype=float32), 'eval/episode_distance_reward': Array(10.1525755, dtype=float32), 'eval/episode_forward_reward': Array(1692.0897, dtype=float32), 'eval/episode_reward': Array(1587.5535, dtype=float32), 'eval/episode_reward_alive': Array(222.96094, dtype=float32), 'eval/episode_reward_linvel': Array(1692.0897, dtype=float32), 'eval/episode_reward_quadctrl': Array(-337.64954, dtype=float32), 'eval/episode_x_position': Array(4534.0205, dtype=float32), 'eval/episode_x_velocity': Array(338.4179, dtype=float32), 'eval/episode_y_position': Array(-397.91565, dtype=float32), 'eval/episode_y_velocity': Array(-97.971054, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.3403, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2554061, dtype=float32), 'eval/episode_forward_reward_std': Array(542.5635, dtype=float32), 'eval/episode_reward_std': Array(542.0226, dtype=float32), 'eval/episode_reward_alive_std': Array(111.99436, dtype=float32), 'eval/episode_reward_linvel_std': Array(542.5635, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.109016, dtype=float32), 'eval/episode_x_position_std': Array(402.67853, dtype=float32), 'eval/episode_x_velocity_std': Array(108.51267, dtype=float32), 'eval/episode_y_position_std': Array(270.50455, dtype=float32), 'eval/episode_y_velocity_std': Array(64.9377, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.18787050247192, 'eval/sps': 939.8781222420002, 'num_steps': 18186240}
{'eval/walltime': 30616.419553756714, 'training/sps': 2945.1275671662197, 'training/walltime': 6235.488081693649, 'training/entropy_loss': Array(0.00223122, dtype=float32), 'training/policy_loss': Array(-0.00274541, dtype=float32), 'training/total_loss': Array(0.01620624, dtype=float32), 'training/v_loss': Array(0.01672043, dtype=float32), 'eval/episode_distance_from_origin': Array(4425.463, dtype=float32), 'eval/episode_distance_reward': Array(8.770021, dtype=float32), 'eval/episode_forward_reward': Array(1461.666, dtype=float32), 'eval/episode_reward': Array(1363.0569, dtype=float32), 'eval/episode_reward_alive': Array(212.71094, dtype=float32), 'eval/episode_reward_linvel': Array(1461.666, dtype=float32), 'eval/episode_reward_quadctrl': Array(-320.09, dtype=float32), 'eval/episode_x_position': Array(4372.55, dtype=float32), 'eval/episode_x_velocity': Array(292.3332, dtype=float32), 'eval/episode_y_position': Array(-375.29633, dtype=float32), 'eval/episode_y_velocity': Array(-88.141235, dtype=float32), 'eval/episode_distance_from_origin_std': Array(336.27997, dtype=float32), 'eval/episode_distance_reward_std': Array(2.556628, dtype=float32), 'eval/episode_forward_reward_std': Array(426.101, dtype=float32), 'eval/episode_reward_std': Array(423.7772, dtype=float32), 'eval/episode_reward_alive_std': Array(117.535545, dtype=float32), 'eval/episode_reward_linvel_std': Array(426.101, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.441998, dtype=float32), 'eval/episode_x_position_std': Array(325.90463, dtype=float32), 'eval/episode_x_velocity_std': Array(85.22022, dtype=float32), 'eval/episode_y_position_std': Array(258.00537, dtype=float32), 'eval/episode_y_velocity_std': Array(59.947792, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35446071624756, 'eval/sps': 938.7298319954995, 'num_steps': 18268160}
{'eval/walltime': 30752.601952552795, 'training/sps': 2953.4824830422313, 'training/walltime': 6263.224829912186, 'training/entropy_loss': Array(0.00137677, dtype=float32), 'training/policy_loss': Array(0.00251819, dtype=float32), 'training/total_loss': Array(0.01225718, dtype=float32), 'training/v_loss': Array(0.00836222, dtype=float32), 'eval/episode_distance_from_origin': Array(4356.7476, dtype=float32), 'eval/episode_distance_reward': Array(8.361084, dtype=float32), 'eval/episode_forward_reward': Array(1393.5104, dtype=float32), 'eval/episode_reward': Array(1278.4089, dtype=float32), 'eval/episode_reward_alive': Array(203.23047, dtype=float32), 'eval/episode_reward_linvel': Array(1393.5104, dtype=float32), 'eval/episode_reward_quadctrl': Array(-326.69302, dtype=float32), 'eval/episode_x_position': Array(4305.904, dtype=float32), 'eval/episode_x_velocity': Array(278.70203, dtype=float32), 'eval/episode_y_position': Array(-348.81174, dtype=float32), 'eval/episode_y_velocity': Array(-83.63799, dtype=float32), 'eval/episode_distance_from_origin_std': Array(371.8994, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8257225, dtype=float32), 'eval/episode_forward_reward_std': Array(470.9506, dtype=float32), 'eval/episode_reward_std': Array(474.04764, dtype=float32), 'eval/episode_reward_alive_std': Array(109.85745, dtype=float32), 'eval/episode_reward_linvel_std': Array(470.9506, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.22097, dtype=float32), 'eval/episode_x_position_std': Array(363.50076, dtype=float32), 'eval/episode_x_velocity_std': Array(94.19006, dtype=float32), 'eval/episode_y_position_std': Array(246.36423, dtype=float32), 'eval/episode_y_velocity_std': Array(58.15478, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.18239879608154, 'eval/sps': 939.9158858382734, 'num_steps': 18350080}
{'eval/walltime': 30888.94847011566, 'training/sps': 2954.5609036333644, 'training/walltime': 6290.951454162598, 'training/entropy_loss': Array(0.0010027, dtype=float32), 'training/policy_loss': Array(-0.0073194, dtype=float32), 'training/total_loss': Array(-0.00164151, dtype=float32), 'training/v_loss': Array(0.00467519, dtype=float32), 'eval/episode_distance_from_origin': Array(4301.293, dtype=float32), 'eval/episode_distance_reward': Array(8.086313, dtype=float32), 'eval/episode_forward_reward': Array(1347.7153, dtype=float32), 'eval/episode_reward': Array(1269.7856, dtype=float32), 'eval/episode_reward_alive': Array(223.44922, dtype=float32), 'eval/episode_reward_linvel': Array(1347.7153, dtype=float32), 'eval/episode_reward_quadctrl': Array(-309.46558, dtype=float32), 'eval/episode_x_position': Array(4255.205, dtype=float32), 'eval/episode_x_velocity': Array(269.5431, dtype=float32), 'eval/episode_y_position': Array(-308.0711, dtype=float32), 'eval/episode_y_velocity': Array(-73.78378, dtype=float32), 'eval/episode_distance_from_origin_std': Array(353.16428, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0248418, dtype=float32), 'eval/episode_forward_reward_std': Array(504.13693, dtype=float32), 'eval/episode_reward_std': Array(513.00006, dtype=float32), 'eval/episode_reward_alive_std': Array(125.11554, dtype=float32), 'eval/episode_reward_linvel_std': Array(504.13693, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.19611, dtype=float32), 'eval/episode_x_position_std': Array(344.84143, dtype=float32), 'eval/episode_x_velocity_std': Array(100.82742, dtype=float32), 'eval/episode_y_position_std': Array(224.5692, dtype=float32), 'eval/episode_y_velocity_std': Array(52.083183, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3465175628662, 'eval/sps': 938.7845196778287, 'num_steps': 18432000}
{'eval/walltime': 31025.107934474945, 'training/sps': 2954.4308053107106, 'training/walltime': 6318.679299354553, 'training/entropy_loss': Array(0.00700107, dtype=float32), 'training/policy_loss': Array(-0.00118429, dtype=float32), 'training/total_loss': Array(0.08960149, dtype=float32), 'training/v_loss': Array(0.08378471, dtype=float32), 'eval/episode_distance_from_origin': Array(4488.323, dtype=float32), 'eval/episode_distance_reward': Array(9.292654, dtype=float32), 'eval/episode_forward_reward': Array(1548.771, dtype=float32), 'eval/episode_reward': Array(1445.7012, dtype=float32), 'eval/episode_reward_alive': Array(207.80469, dtype=float32), 'eval/episode_reward_linvel': Array(1548.771, dtype=float32), 'eval/episode_reward_quadctrl': Array(-320.16718, dtype=float32), 'eval/episode_x_position': Array(4434.401, dtype=float32), 'eval/episode_x_velocity': Array(309.7542, dtype=float32), 'eval/episode_y_position': Array(-377.70734, dtype=float32), 'eval/episode_y_velocity': Array(-92.70347, dtype=float32), 'eval/episode_distance_from_origin_std': Array(366.0336, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8463247, dtype=float32), 'eval/episode_forward_reward_std': Array(474.3838, dtype=float32), 'eval/episode_reward_std': Array(479.3945, dtype=float32), 'eval/episode_reward_alive_std': Array(98.35744, dtype=float32), 'eval/episode_reward_linvel_std': Array(474.3838, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.47189, dtype=float32), 'eval/episode_x_position_std': Array(356.93964, dtype=float32), 'eval/episode_x_velocity_std': Array(94.876724, dtype=float32), 'eval/episode_y_position_std': Array(268.33887, dtype=float32), 'eval/episode_y_velocity_std': Array(63.31337, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.15946435928345, 'eval/sps': 940.074203451968, 'num_steps': 18513920}
{'eval/walltime': 31161.31385755539, 'training/sps': 2963.719916364153, 'training/walltime': 6346.320237874985, 'training/entropy_loss': Array(0.00916542, dtype=float32), 'training/policy_loss': Array(0.01218785, dtype=float32), 'training/total_loss': Array(0.16891882, dtype=float32), 'training/v_loss': Array(0.14756554, dtype=float32), 'eval/episode_distance_from_origin': Array(4458.0425, dtype=float32), 'eval/episode_distance_reward': Array(9.144903, dtype=float32), 'eval/episode_forward_reward': Array(1524.1455, dtype=float32), 'eval/episode_reward': Array(1420.1133, dtype=float32), 'eval/episode_reward_alive': Array(208.35547, dtype=float32), 'eval/episode_reward_linvel': Array(1524.1455, dtype=float32), 'eval/episode_reward_quadctrl': Array(-321.5326, dtype=float32), 'eval/episode_x_position': Array(4406.8955, dtype=float32), 'eval/episode_x_velocity': Array(304.8291, dtype=float32), 'eval/episode_y_position': Array(-342.77747, dtype=float32), 'eval/episode_y_velocity': Array(-84.357834, dtype=float32), 'eval/episode_distance_from_origin_std': Array(358.16864, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8060207, dtype=float32), 'eval/episode_forward_reward_std': Array(467.66608, dtype=float32), 'eval/episode_reward_std': Array(470.15668, dtype=float32), 'eval/episode_reward_alive_std': Array(106.07852, dtype=float32), 'eval/episode_reward_linvel_std': Array(467.66608, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.59388, dtype=float32), 'eval/episode_x_position_std': Array(350.6999, dtype=float32), 'eval/episode_x_velocity_std': Array(93.53322, dtype=float32), 'eval/episode_y_position_std': Array(271.71475, dtype=float32), 'eval/episode_y_velocity_std': Array(62.6522, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20592308044434, 'eval/sps': 939.7535518657448, 'num_steps': 18595840}
{'eval/walltime': 31297.47884464264, 'training/sps': 2957.4115352804497, 'training/walltime': 6374.020136594772, 'training/entropy_loss': Array(0.0054625, dtype=float32), 'training/policy_loss': Array(0.00922901, dtype=float32), 'training/total_loss': Array(0.0634522, dtype=float32), 'training/v_loss': Array(0.0487607, dtype=float32), 'eval/episode_distance_from_origin': Array(4446.107, dtype=float32), 'eval/episode_distance_reward': Array(8.975609, dtype=float32), 'eval/episode_forward_reward': Array(1495.9303, dtype=float32), 'eval/episode_reward': Array(1419.9232, dtype=float32), 'eval/episode_reward_alive': Array(235.4336, dtype=float32), 'eval/episode_reward_linvel': Array(1495.9303, dtype=float32), 'eval/episode_reward_quadctrl': Array(-320.41632, dtype=float32), 'eval/episode_x_position': Array(4388.696, dtype=float32), 'eval/episode_x_velocity': Array(299.18604, dtype=float32), 'eval/episode_y_position': Array(-402.6582, dtype=float32), 'eval/episode_y_velocity': Array(-96.20879, dtype=float32), 'eval/episode_distance_from_origin_std': Array(386.91718, dtype=float32), 'eval/episode_distance_reward_std': Array(3.1573913, dtype=float32), 'eval/episode_forward_reward_std': Array(526.2282, dtype=float32), 'eval/episode_reward_std': Array(523.81274, dtype=float32), 'eval/episode_reward_alive_std': Array(116.33768, dtype=float32), 'eval/episode_reward_linvel_std': Array(526.2282, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.212284, dtype=float32), 'eval/episode_x_position_std': Array(380.89377, dtype=float32), 'eval/episode_x_velocity_std': Array(105.2456, dtype=float32), 'eval/episode_y_position_std': Array(273.45926, dtype=float32), 'eval/episode_y_velocity_std': Array(62.945404, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.16498708724976, 'eval/sps': 940.0360748977421, 'num_steps': 18677760}
{'eval/walltime': 31433.679752588272, 'training/sps': 2965.1384625355226, 'training/walltime': 6401.647851467133, 'training/entropy_loss': Array(0.00242508, dtype=float32), 'training/policy_loss': Array(0.02225054, dtype=float32), 'training/total_loss': Array(0.04236271, dtype=float32), 'training/v_loss': Array(0.01768708, dtype=float32), 'eval/episode_distance_from_origin': Array(4324.96, dtype=float32), 'eval/episode_distance_reward': Array(8.041838, dtype=float32), 'eval/episode_forward_reward': Array(1340.3025, dtype=float32), 'eval/episode_reward': Array(1269.949, dtype=float32), 'eval/episode_reward_alive': Array(237.08984, dtype=float32), 'eval/episode_reward_linvel': Array(1340.3025, dtype=float32), 'eval/episode_reward_quadctrl': Array(-315.48523, dtype=float32), 'eval/episode_x_position': Array(4276.132, dtype=float32), 'eval/episode_x_velocity': Array(268.06052, dtype=float32), 'eval/episode_y_position': Array(-312.24936, dtype=float32), 'eval/episode_y_velocity': Array(-75.217575, dtype=float32), 'eval/episode_distance_from_origin_std': Array(355.62186, dtype=float32), 'eval/episode_distance_reward_std': Array(2.677009, dtype=float32), 'eval/episode_forward_reward_std': Array(446.16452, dtype=float32), 'eval/episode_reward_std': Array(447.94226, dtype=float32), 'eval/episode_reward_alive_std': Array(122.41403, dtype=float32), 'eval/episode_reward_linvel_std': Array(446.16452, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.52136, dtype=float32), 'eval/episode_x_position_std': Array(348.90125, dtype=float32), 'eval/episode_x_velocity_std': Array(89.2329, dtype=float32), 'eval/episode_y_position_std': Array(259.03058, dtype=float32), 'eval/episode_y_velocity_std': Array(59.485397, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20090794563293, 'eval/sps': 939.7881550914002, 'num_steps': 18759680}
{'eval/walltime': 31569.826449632645, 'training/sps': 2956.974715066079, 'training/walltime': 6429.351842164993, 'training/entropy_loss': Array(0.0014326, dtype=float32), 'training/policy_loss': Array(-0.00594639, dtype=float32), 'training/total_loss': Array(0.00318776, dtype=float32), 'training/v_loss': Array(0.00770156, dtype=float32), 'eval/episode_distance_from_origin': Array(4308.3994, dtype=float32), 'eval/episode_distance_reward': Array(7.8989067, dtype=float32), 'eval/episode_forward_reward': Array(1316.481, dtype=float32), 'eval/episode_reward': Array(1273.3335, dtype=float32), 'eval/episode_reward_alive': Array(256.67188, dtype=float32), 'eval/episode_reward_linvel': Array(1316.481, dtype=float32), 'eval/episode_reward_quadctrl': Array(-307.71832, dtype=float32), 'eval/episode_x_position': Array(4258.902, dtype=float32), 'eval/episode_x_velocity': Array(263.2962, dtype=float32), 'eval/episode_y_position': Array(-333.0217, dtype=float32), 'eval/episode_y_velocity': Array(-76.87103, dtype=float32), 'eval/episode_distance_from_origin_std': Array(415.90292, dtype=float32), 'eval/episode_distance_reward_std': Array(3.1608624, dtype=float32), 'eval/episode_forward_reward_std': Array(526.807, dtype=float32), 'eval/episode_reward_std': Array(525.8173, dtype=float32), 'eval/episode_reward_alive_std': Array(129.0287, dtype=float32), 'eval/episode_reward_linvel_std': Array(526.807, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.51703, dtype=float32), 'eval/episode_x_position_std': Array(409.54544, dtype=float32), 'eval/episode_x_velocity_std': Array(105.36148, dtype=float32), 'eval/episode_y_position_std': Array(243.93639, dtype=float32), 'eval/episode_y_velocity_std': Array(55.412045, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.14669704437256, 'eval/sps': 940.1623600040961, 'num_steps': 18841600}
{'eval/walltime': 31706.104946374893, 'training/sps': 2964.1268192164944, 'training/walltime': 6456.988986253738, 'training/entropy_loss': Array(0.00106489, dtype=float32), 'training/policy_loss': Array(-0.00725332, dtype=float32), 'training/total_loss': Array(-0.00276112, dtype=float32), 'training/v_loss': Array(0.00342731, dtype=float32), 'eval/episode_distance_from_origin': Array(4234.6953, dtype=float32), 'eval/episode_distance_reward': Array(7.298018, dtype=float32), 'eval/episode_forward_reward': Array(1216.3335, dtype=float32), 'eval/episode_reward': Array(1217.8865, dtype=float32), 'eval/episode_reward_alive': Array(296.01562, dtype=float32), 'eval/episode_reward_linvel': Array(1216.3335, dtype=float32), 'eval/episode_reward_quadctrl': Array(-301.7608, dtype=float32), 'eval/episode_x_position': Array(4188.3545, dtype=float32), 'eval/episode_x_velocity': Array(243.26671, dtype=float32), 'eval/episode_y_position': Array(-320.51086, dtype=float32), 'eval/episode_y_velocity': Array(-72.50289, dtype=float32), 'eval/episode_distance_from_origin_std': Array(350.3583, dtype=float32), 'eval/episode_distance_reward_std': Array(2.462454, dtype=float32), 'eval/episode_forward_reward_std': Array(410.40628, dtype=float32), 'eval/episode_reward_std': Array(420.56628, dtype=float32), 'eval/episode_reward_alive_std': Array(136.75569, dtype=float32), 'eval/episode_reward_linvel_std': Array(410.40628, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.797037, dtype=float32), 'eval/episode_x_position_std': Array(346.42526, dtype=float32), 'eval/episode_x_velocity_std': Array(82.08128, dtype=float32), 'eval/episode_y_position_std': Array(188.97006, dtype=float32), 'eval/episode_y_velocity_std': Array(41.84798, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27849674224854, 'eval/sps': 939.2530961219352, 'num_steps': 18923520}
{'eval/walltime': 31842.373783111572, 'training/sps': 2949.518180003632, 'training/walltime': 6484.76301407814, 'training/entropy_loss': Array(0.00382135, dtype=float32), 'training/policy_loss': Array(-0.00334452, dtype=float32), 'training/total_loss': Array(0.0527137, dtype=float32), 'training/v_loss': Array(0.05223688, dtype=float32), 'eval/episode_distance_from_origin': Array(4347.5586, dtype=float32), 'eval/episode_distance_reward': Array(8.071704, dtype=float32), 'eval/episode_forward_reward': Array(1345.2802, dtype=float32), 'eval/episode_reward': Array(1357.5239, dtype=float32), 'eval/episode_reward_alive': Array(307.40234, dtype=float32), 'eval/episode_reward_linvel': Array(1345.2802, dtype=float32), 'eval/episode_reward_quadctrl': Array(-303.23044, dtype=float32), 'eval/episode_x_position': Array(4301.468, dtype=float32), 'eval/episode_x_velocity': Array(269.05603, dtype=float32), 'eval/episode_y_position': Array(-330.70312, dtype=float32), 'eval/episode_y_velocity': Array(-74.28914, dtype=float32), 'eval/episode_distance_from_origin_std': Array(358.38556, dtype=float32), 'eval/episode_distance_reward_std': Array(2.6061025, dtype=float32), 'eval/episode_forward_reward_std': Array(434.34705, dtype=float32), 'eval/episode_reward_std': Array(430.7518, dtype=float32), 'eval/episode_reward_alive_std': Array(134.32808, dtype=float32), 'eval/episode_reward_linvel_std': Array(434.34705, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.655716, dtype=float32), 'eval/episode_x_position_std': Array(352.6693, dtype=float32), 'eval/episode_x_velocity_std': Array(86.869415, dtype=float32), 'eval/episode_y_position_std': Array(191.01614, dtype=float32), 'eval/episode_y_velocity_std': Array(43.489025, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26883673667908, 'eval/sps': 939.3196791379568, 'num_steps': 19005440}
{'eval/walltime': 31978.599431037903, 'training/sps': 2961.756107871151, 'training/walltime': 6512.422280073166, 'training/entropy_loss': Array(0.01051445, dtype=float32), 'training/policy_loss': Array(0.00943336, dtype=float32), 'training/total_loss': Array(0.14116982, dtype=float32), 'training/v_loss': Array(0.12122202, dtype=float32), 'eval/episode_distance_from_origin': Array(4392.6606, dtype=float32), 'eval/episode_distance_reward': Array(8.488271, dtype=float32), 'eval/episode_forward_reward': Array(1414.7075, dtype=float32), 'eval/episode_reward': Array(1398.0881, dtype=float32), 'eval/episode_reward_alive': Array(284.39844, dtype=float32), 'eval/episode_reward_linvel': Array(1414.7075, dtype=float32), 'eval/episode_reward_quadctrl': Array(-309.50595, dtype=float32), 'eval/episode_x_position': Array(4343.054, dtype=float32), 'eval/episode_x_velocity': Array(282.94147, dtype=float32), 'eval/episode_y_position': Array(-346.5179, dtype=float32), 'eval/episode_y_velocity': Array(-81.0586, dtype=float32), 'eval/episode_distance_from_origin_std': Array(386.50186, dtype=float32), 'eval/episode_distance_reward_std': Array(2.891152, dtype=float32), 'eval/episode_forward_reward_std': Array(481.85468, dtype=float32), 'eval/episode_reward_std': Array(473.70987, dtype=float32), 'eval/episode_reward_alive_std': Array(125.38214, dtype=float32), 'eval/episode_reward_linvel_std': Array(481.85468, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.76498, dtype=float32), 'eval/episode_x_position_std': Array(380.95367, dtype=float32), 'eval/episode_x_velocity_std': Array(96.3709, dtype=float32), 'eval/episode_y_position_std': Array(234.01839, dtype=float32), 'eval/episode_y_velocity_std': Array(54.74037, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22564792633057, 'eval/sps': 939.6174798832382, 'num_steps': 19087360}
{'eval/walltime': 32114.902183294296, 'training/sps': 2945.0549924209254, 'training/walltime': 6540.238399028778, 'training/entropy_loss': Array(0.00468399, dtype=float32), 'training/policy_loss': Array(0.00785146, dtype=float32), 'training/total_loss': Array(0.06107589, dtype=float32), 'training/v_loss': Array(0.04854044, dtype=float32), 'eval/episode_distance_from_origin': Array(4372.237, dtype=float32), 'eval/episode_distance_reward': Array(8.285318, dtype=float32), 'eval/episode_forward_reward': Array(1380.8828, dtype=float32), 'eval/episode_reward': Array(1383.0715, dtype=float32), 'eval/episode_reward_alive': Array(298.42188, dtype=float32), 'eval/episode_reward_linvel': Array(1380.8828, dtype=float32), 'eval/episode_reward_quadctrl': Array(-304.51852, dtype=float32), 'eval/episode_x_position': Array(4322.366, dtype=float32), 'eval/episode_x_velocity': Array(276.17657, dtype=float32), 'eval/episode_y_position': Array(-359.46857, dtype=float32), 'eval/episode_y_velocity': Array(-82.79996, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.3925, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9082434, dtype=float32), 'eval/episode_forward_reward_std': Array(484.70428, dtype=float32), 'eval/episode_reward_std': Array(495.77185, dtype=float32), 'eval/episode_reward_alive_std': Array(130.47064, dtype=float32), 'eval/episode_reward_linvel_std': Array(484.70428, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.147953, dtype=float32), 'eval/episode_x_position_std': Array(390.11862, dtype=float32), 'eval/episode_x_velocity_std': Array(96.940834, dtype=float32), 'eval/episode_y_position_std': Array(212.26941, dtype=float32), 'eval/episode_y_velocity_std': Array(49.423874, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30275225639343, 'eval/sps': 939.0859530057363, 'num_steps': 19169280}
{'eval/walltime': 32251.130111932755, 'training/sps': 2936.6606003708152, 'training/walltime': 6568.134029865265, 'training/entropy_loss': Array(0.00226975, dtype=float32), 'training/policy_loss': Array(0.00054987, dtype=float32), 'training/total_loss': Array(0.01764024, dtype=float32), 'training/v_loss': Array(0.01482063, dtype=float32), 'eval/episode_distance_from_origin': Array(4281.1426, dtype=float32), 'eval/episode_distance_reward': Array(7.7412252, dtype=float32), 'eval/episode_forward_reward': Array(1290.2012, dtype=float32), 'eval/episode_reward': Array(1321.3892, dtype=float32), 'eval/episode_reward_alive': Array(326.89844, dtype=float32), 'eval/episode_reward_linvel': Array(1290.2012, dtype=float32), 'eval/episode_reward_quadctrl': Array(-303.4516, dtype=float32), 'eval/episode_x_position': Array(4229.4307, dtype=float32), 'eval/episode_x_velocity': Array(258.04022, dtype=float32), 'eval/episode_y_position': Array(-344.07373, dtype=float32), 'eval/episode_y_velocity': Array(-78.085754, dtype=float32), 'eval/episode_distance_from_origin_std': Array(366.49762, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8240135, dtype=float32), 'eval/episode_forward_reward_std': Array(470.66556, dtype=float32), 'eval/episode_reward_std': Array(477.83655, dtype=float32), 'eval/episode_reward_alive_std': Array(132.04501, dtype=float32), 'eval/episode_reward_linvel_std': Array(470.66556, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.745113, dtype=float32), 'eval/episode_x_position_std': Array(357.29407, dtype=float32), 'eval/episode_x_velocity_std': Array(94.133125, dtype=float32), 'eval/episode_y_position_std': Array(248.82607, dtype=float32), 'eval/episode_y_velocity_std': Array(57.98652, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22792863845825, 'eval/sps': 939.6017489167383, 'num_steps': 19251200}
{'eval/walltime': 32387.294272899628, 'training/sps': 2943.395458839055, 'training/walltime': 6595.96583199501, 'training/entropy_loss': Array(0.00150414, dtype=float32), 'training/policy_loss': Array(-0.00682083, dtype=float32), 'training/total_loss': Array(0.00076801, dtype=float32), 'training/v_loss': Array(0.0060847, dtype=float32), 'eval/episode_distance_from_origin': Array(4304.6533, dtype=float32), 'eval/episode_distance_reward': Array(7.9170523, dtype=float32), 'eval/episode_forward_reward': Array(1319.5059, dtype=float32), 'eval/episode_reward': Array(1384.572, dtype=float32), 'eval/episode_reward_alive': Array(356.54297, dtype=float32), 'eval/episode_reward_linvel': Array(1319.5059, dtype=float32), 'eval/episode_reward_quadctrl': Array(-299.3938, dtype=float32), 'eval/episode_x_position': Array(4256.072, dtype=float32), 'eval/episode_x_velocity': Array(263.90112, dtype=float32), 'eval/episode_y_position': Array(-341.42007, dtype=float32), 'eval/episode_y_velocity': Array(-77.13686, dtype=float32), 'eval/episode_distance_from_origin_std': Array(366.87817, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9493706, dtype=float32), 'eval/episode_forward_reward_std': Array(491.5591, dtype=float32), 'eval/episode_reward_std': Array(470.20673, dtype=float32), 'eval/episode_reward_alive_std': Array(122.45166, dtype=float32), 'eval/episode_reward_linvel_std': Array(491.5591, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.247524, dtype=float32), 'eval/episode_x_position_std': Array(358.42258, dtype=float32), 'eval/episode_x_velocity_std': Array(98.31176, dtype=float32), 'eval/episode_y_position_std': Array(204.41428, dtype=float32), 'eval/episode_y_velocity_std': Array(48.707886, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.16416096687317, 'eval/sps': 940.0417781822972, 'num_steps': 19333120}
{'eval/walltime': 32523.514052152634, 'training/sps': 2943.3197925886025, 'training/walltime': 6623.798349618912, 'training/entropy_loss': Array(0.00119373, dtype=float32), 'training/policy_loss': Array(-0.0080262, dtype=float32), 'training/total_loss': Array(-0.00326466, dtype=float32), 'training/v_loss': Array(0.00356781, dtype=float32), 'eval/episode_distance_from_origin': Array(4206.7227, dtype=float32), 'eval/episode_distance_reward': Array(7.143656, dtype=float32), 'eval/episode_forward_reward': Array(1190.6067, dtype=float32), 'eval/episode_reward': Array(1253.6274, dtype=float32), 'eval/episode_reward_alive': Array(354.84766, dtype=float32), 'eval/episode_reward_linvel': Array(1190.6067, dtype=float32), 'eval/episode_reward_quadctrl': Array(-298.9706, dtype=float32), 'eval/episode_x_position': Array(4160.2695, dtype=float32), 'eval/episode_x_velocity': Array(238.12138, dtype=float32), 'eval/episode_y_position': Array(-317.17136, dtype=float32), 'eval/episode_y_velocity': Array(-70.51521, dtype=float32), 'eval/episode_distance_from_origin_std': Array(383.6651, dtype=float32), 'eval/episode_distance_reward_std': Array(2.750225, dtype=float32), 'eval/episode_forward_reward_std': Array(458.36774, dtype=float32), 'eval/episode_reward_std': Array(456.8627, dtype=float32), 'eval/episode_reward_alive_std': Array(121.93116, dtype=float32), 'eval/episode_reward_linvel_std': Array(458.36774, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.48029, dtype=float32), 'eval/episode_x_position_std': Array(377.77795, dtype=float32), 'eval/episode_x_velocity_std': Array(91.67361, dtype=float32), 'eval/episode_y_position_std': Array(188.7976, dtype=float32), 'eval/episode_y_velocity_std': Array(44.91375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21977925300598, 'eval/sps': 939.6579608476748, 'num_steps': 19415040}
{'eval/walltime': 32659.664308309555, 'training/sps': 2944.4092725775504, 'training/walltime': 6651.620568752289, 'training/entropy_loss': Array(0.00268895, dtype=float32), 'training/policy_loss': Array(-0.00397986, dtype=float32), 'training/total_loss': Array(0.02217453, dtype=float32), 'training/v_loss': Array(0.02346544, dtype=float32), 'eval/episode_distance_from_origin': Array(4198.373, dtype=float32), 'eval/episode_distance_reward': Array(7.0410504, dtype=float32), 'eval/episode_forward_reward': Array(1173.5062, dtype=float32), 'eval/episode_reward': Array(1246.2075, dtype=float32), 'eval/episode_reward_alive': Array(363.3047, dtype=float32), 'eval/episode_reward_linvel': Array(1173.5062, dtype=float32), 'eval/episode_reward_quadctrl': Array(-297.64465, dtype=float32), 'eval/episode_x_position': Array(4152.46, dtype=float32), 'eval/episode_x_velocity': Array(234.7013, dtype=float32), 'eval/episode_y_position': Array(-288.27722, dtype=float32), 'eval/episode_y_velocity': Array(-65.02655, dtype=float32), 'eval/episode_distance_from_origin_std': Array(341.6473, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4508853, dtype=float32), 'eval/episode_forward_reward_std': Array(408.47855, dtype=float32), 'eval/episode_reward_std': Array(413.55334, dtype=float32), 'eval/episode_reward_alive_std': Array(117.14317, dtype=float32), 'eval/episode_reward_linvel_std': Array(408.47855, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.031076, dtype=float32), 'eval/episode_x_position_std': Array(336.9421, dtype=float32), 'eval/episode_x_velocity_std': Array(81.695755, dtype=float32), 'eval/episode_y_position_std': Array(212.37202, dtype=float32), 'eval/episode_y_velocity_std': Array(48.97024, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1502561569214, 'eval/sps': 940.1377831597487, 'num_steps': 19496960}
{'eval/walltime': 32795.900611400604, 'training/sps': 2944.3772286678095, 'training/walltime': 6679.443090677261, 'training/entropy_loss': Array(0.00956835, dtype=float32), 'training/policy_loss': Array(0.00977963, dtype=float32), 'training/total_loss': Array(0.1406945, dtype=float32), 'training/v_loss': Array(0.12134652, dtype=float32), 'eval/episode_distance_from_origin': Array(4334.162, dtype=float32), 'eval/episode_distance_reward': Array(8.078342, dtype=float32), 'eval/episode_forward_reward': Array(1346.3872, dtype=float32), 'eval/episode_reward': Array(1408.3774, dtype=float32), 'eval/episode_reward_alive': Array(353.38672, dtype=float32), 'eval/episode_reward_linvel': Array(1346.3872, dtype=float32), 'eval/episode_reward_quadctrl': Array(-299.4748, dtype=float32), 'eval/episode_x_position': Array(4284.5312, dtype=float32), 'eval/episode_x_velocity': Array(269.2774, dtype=float32), 'eval/episode_y_position': Array(-341.73248, dtype=float32), 'eval/episode_y_velocity': Array(-79.41139, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.84308, dtype=float32), 'eval/episode_distance_reward_std': Array(3.326356, dtype=float32), 'eval/episode_forward_reward_std': Array(554.3885, dtype=float32), 'eval/episode_reward_std': Array(537.3443, dtype=float32), 'eval/episode_reward_alive_std': Array(113.29863, dtype=float32), 'eval/episode_reward_linvel_std': Array(554.3885, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.124863, dtype=float32), 'eval/episode_x_position_std': Array(422.43948, dtype=float32), 'eval/episode_x_velocity_std': Array(110.87774, dtype=float32), 'eval/episode_y_position_std': Array(224.67557, dtype=float32), 'eval/episode_y_velocity_std': Array(54.37744, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2363030910492, 'eval/sps': 939.5439915486791, 'num_steps': 19578880}
{'eval/walltime': 32932.06568813324, 'training/sps': 2941.3294612496325, 'training/walltime': 6707.2944419384, 'training/entropy_loss': Array(0.00462758, dtype=float32), 'training/policy_loss': Array(0.01208735, dtype=float32), 'training/total_loss': Array(0.06813762, dtype=float32), 'training/v_loss': Array(0.05142269, dtype=float32), 'eval/episode_distance_from_origin': Array(4320.2314, dtype=float32), 'eval/episode_distance_reward': Array(7.8884163, dtype=float32), 'eval/episode_forward_reward': Array(1314.7329, dtype=float32), 'eval/episode_reward': Array(1396.3225, dtype=float32), 'eval/episode_reward_alive': Array(376.27734, dtype=float32), 'eval/episode_reward_linvel': Array(1314.7329, dtype=float32), 'eval/episode_reward_quadctrl': Array(-302.57617, dtype=float32), 'eval/episode_x_position': Array(4271.213, dtype=float32), 'eval/episode_x_velocity': Array(262.9466, dtype=float32), 'eval/episode_y_position': Array(-327.77213, dtype=float32), 'eval/episode_y_velocity': Array(-75.31886, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.54724, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9257572, dtype=float32), 'eval/episode_forward_reward_std': Array(487.62286, dtype=float32), 'eval/episode_reward_std': Array(459.63913, dtype=float32), 'eval/episode_reward_alive_std': Array(101.55188, dtype=float32), 'eval/episode_reward_linvel_std': Array(487.62286, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.389103, dtype=float32), 'eval/episode_x_position_std': Array(400.19052, dtype=float32), 'eval/episode_x_velocity_std': Array(97.52458, dtype=float32), 'eval/episode_y_position_std': Array(236.74379, dtype=float32), 'eval/episode_y_velocity_std': Array(55.327755, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1650767326355, 'eval/sps': 940.0354560173466, 'num_steps': 19660800}
{'eval/walltime': 33068.28395318985, 'training/sps': 2946.6396768653963, 'training/walltime': 6735.095601558685, 'training/entropy_loss': Array(0.0023325, dtype=float32), 'training/policy_loss': Array(0.00088085, dtype=float32), 'training/total_loss': Array(0.01836153, dtype=float32), 'training/v_loss': Array(0.01514819, dtype=float32), 'eval/episode_distance_from_origin': Array(4261.9844, dtype=float32), 'eval/episode_distance_reward': Array(7.5865045, dtype=float32), 'eval/episode_forward_reward': Array(1264.4147, dtype=float32), 'eval/episode_reward': Array(1339.5562, dtype=float32), 'eval/episode_reward_alive': Array(372.8672, dtype=float32), 'eval/episode_reward_linvel': Array(1264.4147, dtype=float32), 'eval/episode_reward_quadctrl': Array(-305.31235, dtype=float32), 'eval/episode_x_position': Array(4213.4004, dtype=float32), 'eval/episode_x_velocity': Array(252.88293, dtype=float32), 'eval/episode_y_position': Array(-297.2875, dtype=float32), 'eval/episode_y_velocity': Array(-68.507034, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.30945, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2277412, dtype=float32), 'eval/episode_forward_reward_std': Array(537.95355, dtype=float32), 'eval/episode_reward_std': Array(528.5359, dtype=float32), 'eval/episode_reward_alive_std': Array(119.20081, dtype=float32), 'eval/episode_reward_linvel_std': Array(537.95355, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.310993, dtype=float32), 'eval/episode_x_position_std': Array(387.73218, dtype=float32), 'eval/episode_x_velocity_std': Array(107.590706, dtype=float32), 'eval/episode_y_position_std': Array(250.53299, dtype=float32), 'eval/episode_y_velocity_std': Array(58.44326, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2182650566101, 'eval/sps': 939.6684060452926, 'num_steps': 19742720}
{'eval/walltime': 33204.46213746071, 'training/sps': 2940.6306095138375, 'training/walltime': 6762.953571796417, 'training/entropy_loss': Array(0.0016822, dtype=float32), 'training/policy_loss': Array(-0.00211146, dtype=float32), 'training/total_loss': Array(0.0062067, dtype=float32), 'training/v_loss': Array(0.00663596, dtype=float32), 'eval/episode_distance_from_origin': Array(4201.471, dtype=float32), 'eval/episode_distance_reward': Array(7.059775, dtype=float32), 'eval/episode_forward_reward': Array(1176.6267, dtype=float32), 'eval/episode_reward': Array(1255.211, dtype=float32), 'eval/episode_reward_alive': Array(377.8203, dtype=float32), 'eval/episode_reward_linvel': Array(1176.6267, dtype=float32), 'eval/episode_reward_quadctrl': Array(-306.29578, dtype=float32), 'eval/episode_x_position': Array(4154.4883, dtype=float32), 'eval/episode_x_velocity': Array(235.32533, dtype=float32), 'eval/episode_y_position': Array(-319.67313, dtype=float32), 'eval/episode_y_velocity': Array(-71.20599, dtype=float32), 'eval/episode_distance_from_origin_std': Array(375.4998, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7785451, dtype=float32), 'eval/episode_forward_reward_std': Array(463.0874, dtype=float32), 'eval/episode_reward_std': Array(450.47705, dtype=float32), 'eval/episode_reward_alive_std': Array(112.027, dtype=float32), 'eval/episode_reward_linvel_std': Array(463.0874, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.513527, dtype=float32), 'eval/episode_x_position_std': Array(371.59598, dtype=float32), 'eval/episode_x_velocity_std': Array(92.61749, dtype=float32), 'eval/episode_y_position_std': Array(183.21721, dtype=float32), 'eval/episode_y_velocity_std': Array(42.616787, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.17818427085876, 'eval/sps': 939.9449749264365, 'num_steps': 19824640}
{'eval/walltime': 33340.69567990303, 'training/sps': 2950.7324886777233, 'training/walltime': 6790.716169834137, 'training/entropy_loss': Array(0.00142511, dtype=float32), 'training/policy_loss': Array(-0.00484701, dtype=float32), 'training/total_loss': Array(-0.00079191, dtype=float32), 'training/v_loss': Array(0.00262999, dtype=float32), 'eval/episode_distance_from_origin': Array(4222.6445, dtype=float32), 'eval/episode_distance_reward': Array(7.219741, dtype=float32), 'eval/episode_forward_reward': Array(1203.2883, dtype=float32), 'eval/episode_reward': Array(1287.0448, dtype=float32), 'eval/episode_reward_alive': Array(382.05078, dtype=float32), 'eval/episode_reward_linvel': Array(1203.2883, dtype=float32), 'eval/episode_reward_quadctrl': Array(-305.51404, dtype=float32), 'eval/episode_x_position': Array(4172.8506, dtype=float32), 'eval/episode_x_velocity': Array(240.65765, dtype=float32), 'eval/episode_y_position': Array(-355.83063, dtype=float32), 'eval/episode_y_velocity': Array(-80.15875, dtype=float32), 'eval/episode_distance_from_origin_std': Array(394.37714, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8922317, dtype=float32), 'eval/episode_forward_reward_std': Array(482.03653, dtype=float32), 'eval/episode_reward_std': Array(470.1395, dtype=float32), 'eval/episode_reward_alive_std': Array(107.33903, dtype=float32), 'eval/episode_reward_linvel_std': Array(482.03653, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.809395, dtype=float32), 'eval/episode_x_position_std': Array(387.49338, dtype=float32), 'eval/episode_x_velocity_std': Array(96.40729, dtype=float32), 'eval/episode_y_position_std': Array(174.09595, dtype=float32), 'eval/episode_y_velocity_std': Array(45.851738, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23354244232178, 'eval/sps': 939.563030552423, 'num_steps': 19906560}
{'eval/walltime': 33476.87265896797, 'training/sps': 2948.3471700765813, 'training/walltime': 6818.501228809357, 'training/entropy_loss': Array(0.00172337, dtype=float32), 'training/policy_loss': Array(-0.00766524, dtype=float32), 'training/total_loss': Array(0.00101747, dtype=float32), 'training/v_loss': Array(0.00695934, dtype=float32), 'eval/episode_distance_from_origin': Array(4237.248, dtype=float32), 'eval/episode_distance_reward': Array(7.284057, dtype=float32), 'eval/episode_forward_reward': Array(1214.0076, dtype=float32), 'eval/episode_reward': Array(1311.8822, dtype=float32), 'eval/episode_reward_alive': Array(392.54688, dtype=float32), 'eval/episode_reward_linvel': Array(1214.0076, dtype=float32), 'eval/episode_reward_quadctrl': Array(-301.95636, dtype=float32), 'eval/episode_x_position': Array(4190.4365, dtype=float32), 'eval/episode_x_velocity': Array(242.80148, dtype=float32), 'eval/episode_y_position': Array(-282.25455, dtype=float32), 'eval/episode_y_velocity': Array(-64.697845, dtype=float32), 'eval/episode_distance_from_origin_std': Array(380.59863, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7849853, dtype=float32), 'eval/episode_forward_reward_std': Array(464.16168, dtype=float32), 'eval/episode_reward_std': Array(444.6101, dtype=float32), 'eval/episode_reward_alive_std': Array(101.53352, dtype=float32), 'eval/episode_reward_linvel_std': Array(464.16168, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.658627, dtype=float32), 'eval/episode_x_position_std': Array(376.80936, dtype=float32), 'eval/episode_x_velocity_std': Array(92.83229, dtype=float32), 'eval/episode_y_position_std': Array(232.7744, dtype=float32), 'eval/episode_y_velocity_std': Array(53.48335, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1769790649414, 'eval/sps': 939.9532937131621, 'num_steps': 19988480}
{'eval/walltime': 33613.087721824646, 'training/sps': 2958.7110509655035, 'training/walltime': 6846.188961267471, 'training/entropy_loss': Array(0.0100481, dtype=float32), 'training/policy_loss': Array(0.00601375, dtype=float32), 'training/total_loss': Array(0.13005978, dtype=float32), 'training/v_loss': Array(0.11399792, dtype=float32), 'eval/episode_distance_from_origin': Array(4261.817, dtype=float32), 'eval/episode_distance_reward': Array(7.4928207, dtype=float32), 'eval/episode_forward_reward': Array(1248.8016, dtype=float32), 'eval/episode_reward': Array(1330.4738, dtype=float32), 'eval/episode_reward_alive': Array(378.3086, dtype=float32), 'eval/episode_reward_linvel': Array(1248.8016, dtype=float32), 'eval/episode_reward_quadctrl': Array(-304.1293, dtype=float32), 'eval/episode_x_position': Array(4215.443, dtype=float32), 'eval/episode_x_velocity': Array(249.7603, dtype=float32), 'eval/episode_y_position': Array(-270.37958, dtype=float32), 'eval/episode_y_velocity': Array(-62.325397, dtype=float32), 'eval/episode_distance_from_origin_std': Array(383.48917, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8558261, dtype=float32), 'eval/episode_forward_reward_std': Array(475.9687, dtype=float32), 'eval/episode_reward_std': Array(469.99835, dtype=float32), 'eval/episode_reward_alive_std': Array(104.71585, dtype=float32), 'eval/episode_reward_linvel_std': Array(475.9687, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.099113, dtype=float32), 'eval/episode_x_position_std': Array(378.4175, dtype=float32), 'eval/episode_x_velocity_std': Array(95.19372, dtype=float32), 'eval/episode_y_position_std': Array(249.34941, dtype=float32), 'eval/episode_y_velocity_std': Array(56.164913, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2150628566742, 'eval/sps': 939.6904961581371, 'num_steps': 20070400}
{'eval/walltime': 33749.275371313095, 'training/sps': 2936.0041554174527, 'training/walltime': 6874.090829133987, 'training/entropy_loss': Array(0.00630014, dtype=float32), 'training/policy_loss': Array(0.01717324, dtype=float32), 'training/total_loss': Array(0.09746865, dtype=float32), 'training/v_loss': Array(0.07399527, dtype=float32), 'eval/episode_distance_from_origin': Array(4300.2705, dtype=float32), 'eval/episode_distance_reward': Array(7.6670275, dtype=float32), 'eval/episode_forward_reward': Array(1277.8358, dtype=float32), 'eval/episode_reward': Array(1367.5781, dtype=float32), 'eval/episode_reward_alive': Array(389.57812, dtype=float32), 'eval/episode_reward_linvel': Array(1277.8358, dtype=float32), 'eval/episode_reward_quadctrl': Array(-307.50272, dtype=float32), 'eval/episode_x_position': Array(4248.9844, dtype=float32), 'eval/episode_x_velocity': Array(255.56715, dtype=float32), 'eval/episode_y_position': Array(-360.33807, dtype=float32), 'eval/episode_y_velocity': Array(-80.80409, dtype=float32), 'eval/episode_distance_from_origin_std': Array(328.3841, dtype=float32), 'eval/episode_distance_reward_std': Array(2.3900497, dtype=float32), 'eval/episode_forward_reward_std': Array(398.33875, dtype=float32), 'eval/episode_reward_std': Array(385.05405, dtype=float32), 'eval/episode_reward_alive_std': Array(104.20573, dtype=float32), 'eval/episode_reward_linvel_std': Array(398.33875, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.675186, dtype=float32), 'eval/episode_x_position_std': Array(321.87177, dtype=float32), 'eval/episode_x_velocity_std': Array(79.66778, dtype=float32), 'eval/episode_y_position_std': Array(208.61215, dtype=float32), 'eval/episode_y_velocity_std': Array(49.040718, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1876494884491, 'eval/sps': 939.8796475362948, 'num_steps': 20152320}
{'eval/walltime': 33885.51169323921, 'training/sps': 2945.5001149233854, 'training/walltime': 6901.9027445316315, 'training/entropy_loss': Array(0.00327987, dtype=float32), 'training/policy_loss': Array(0.00606246, dtype=float32), 'training/total_loss': Array(0.02587975, dtype=float32), 'training/v_loss': Array(0.01653742, dtype=float32), 'eval/episode_distance_from_origin': Array(4229.142, dtype=float32), 'eval/episode_distance_reward': Array(7.2371645, dtype=float32), 'eval/episode_forward_reward': Array(1206.1921, dtype=float32), 'eval/episode_reward': Array(1292.5198, dtype=float32), 'eval/episode_reward_alive': Array(388.65234, dtype=float32), 'eval/episode_reward_linvel': Array(1206.1921, dtype=float32), 'eval/episode_reward_quadctrl': Array(-309.56207, dtype=float32), 'eval/episode_x_position': Array(4174.879, dtype=float32), 'eval/episode_x_velocity': Array(241.23846, dtype=float32), 'eval/episode_y_position': Array(-348.8482, dtype=float32), 'eval/episode_y_velocity': Array(-78.48554, dtype=float32), 'eval/episode_distance_from_origin_std': Array(346.15085, dtype=float32), 'eval/episode_distance_reward_std': Array(2.6375728, dtype=float32), 'eval/episode_forward_reward_std': Array(439.59375, dtype=float32), 'eval/episode_reward_std': Array(434.63077, dtype=float32), 'eval/episode_reward_alive_std': Array(101.80547, dtype=float32), 'eval/episode_reward_linvel_std': Array(439.59375, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.75144, dtype=float32), 'eval/episode_x_position_std': Array(338.08105, dtype=float32), 'eval/episode_x_velocity_std': Array(87.91876, dtype=float32), 'eval/episode_y_position_std': Array(260.4764, dtype=float32), 'eval/episode_y_velocity_std': Array(60.06475, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23632192611694, 'eval/sps': 939.5438616539896, 'num_steps': 20234240}
{'eval/walltime': 34021.673248291016, 'training/sps': 2940.22789233002, 'training/walltime': 6929.764530420303, 'training/entropy_loss': Array(0.00210936, dtype=float32), 'training/policy_loss': Array(-0.00458204, dtype=float32), 'training/total_loss': Array(0.00256388, dtype=float32), 'training/v_loss': Array(0.00503656, dtype=float32), 'eval/episode_distance_from_origin': Array(4138.0723, dtype=float32), 'eval/episode_distance_reward': Array(6.615226, dtype=float32), 'eval/episode_forward_reward': Array(1102.5361, dtype=float32), 'eval/episode_reward': Array(1211.0219, dtype=float32), 'eval/episode_reward_alive': Array(400.39453, dtype=float32), 'eval/episode_reward_linvel': Array(1102.5361, dtype=float32), 'eval/episode_reward_quadctrl': Array(-298.5243, dtype=float32), 'eval/episode_x_position': Array(4090.989, dtype=float32), 'eval/episode_x_velocity': Array(220.50726, dtype=float32), 'eval/episode_y_position': Array(-308.85733, dtype=float32), 'eval/episode_y_velocity': Array(-66.62061, dtype=float32), 'eval/episode_distance_from_origin_std': Array(316.1255, dtype=float32), 'eval/episode_distance_reward_std': Array(2.2102938, dtype=float32), 'eval/episode_forward_reward_std': Array(368.38086, dtype=float32), 'eval/episode_reward_std': Array(362.39316, dtype=float32), 'eval/episode_reward_alive_std': Array(93.89253, dtype=float32), 'eval/episode_reward_linvel_std': Array(368.38086, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.950443, dtype=float32), 'eval/episode_x_position_std': Array(308.72205, dtype=float32), 'eval/episode_x_velocity_std': Array(73.6762, dtype=float32), 'eval/episode_y_position_std': Array(193.3113, dtype=float32), 'eval/episode_y_velocity_std': Array(43.977562, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1615550518036, 'eval/sps': 940.059769083142, 'num_steps': 20316160}
{'eval/walltime': 34157.981018066406, 'training/sps': 2937.756282327642, 'training/walltime': 6957.649757146835, 'training/entropy_loss': Array(0.00174229, dtype=float32), 'training/policy_loss': Array(-0.00990676, dtype=float32), 'training/total_loss': Array(-0.00619929, dtype=float32), 'training/v_loss': Array(0.00196518, dtype=float32), 'eval/episode_distance_from_origin': Array(4198.1494, dtype=float32), 'eval/episode_distance_reward': Array(7.078598, dtype=float32), 'eval/episode_forward_reward': Array(1179.7645, dtype=float32), 'eval/episode_reward': Array(1301.1598, dtype=float32), 'eval/episode_reward_alive': Array(409.71094, dtype=float32), 'eval/episode_reward_linvel': Array(1179.7645, dtype=float32), 'eval/episode_reward_quadctrl': Array(-295.39423, dtype=float32), 'eval/episode_x_position': Array(4148.092, dtype=float32), 'eval/episode_x_velocity': Array(235.95288, dtype=float32), 'eval/episode_y_position': Array(-349.8444, dtype=float32), 'eval/episode_y_velocity': Array(-77.304794, dtype=float32), 'eval/episode_distance_from_origin_std': Array(357.42484, dtype=float32), 'eval/episode_distance_reward_std': Array(2.636623, dtype=float32), 'eval/episode_forward_reward_std': Array(439.43494, dtype=float32), 'eval/episode_reward_std': Array(425.29935, dtype=float32), 'eval/episode_reward_alive_std': Array(77.302635, dtype=float32), 'eval/episode_reward_linvel_std': Array(439.43494, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.575794, dtype=float32), 'eval/episode_x_position_std': Array(349.37335, dtype=float32), 'eval/episode_x_velocity_std': Array(87.88699, dtype=float32), 'eval/episode_y_position_std': Array(185.6065, dtype=float32), 'eval/episode_y_velocity_std': Array(44.82313, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30776977539062, 'eval/sps': 939.0513850451794, 'num_steps': 20398080}
{'eval/walltime': 34294.15896511078, 'training/sps': 2959.58118196443, 'training/walltime': 6985.329349279404, 'training/entropy_loss': Array(0.00168961, dtype=float32), 'training/policy_loss': Array(-0.01529738, dtype=float32), 'training/total_loss': Array(-0.01200414, dtype=float32), 'training/v_loss': Array(0.00160363, dtype=float32), 'eval/episode_distance_from_origin': Array(4021.0586, dtype=float32), 'eval/episode_distance_reward': Array(5.906083, dtype=float32), 'eval/episode_forward_reward': Array(984.346, dtype=float32), 'eval/episode_reward': Array(1102.9873, dtype=float32), 'eval/episode_reward_alive': Array(399.6797, dtype=float32), 'eval/episode_reward_linvel': Array(984.346, dtype=float32), 'eval/episode_reward_quadctrl': Array(-286.9445, dtype=float32), 'eval/episode_x_position': Array(3977.4758, dtype=float32), 'eval/episode_x_velocity': Array(196.86923, dtype=float32), 'eval/episode_y_position': Array(-255.74199, dtype=float32), 'eval/episode_y_velocity': Array(-55.087845, dtype=float32), 'eval/episode_distance_from_origin_std': Array(276.41592, dtype=float32), 'eval/episode_distance_reward_std': Array(2.04051, dtype=float32), 'eval/episode_forward_reward_std': Array(340.0838, dtype=float32), 'eval/episode_reward_std': Array(373.1137, dtype=float32), 'eval/episode_reward_alive_std': Array(104.35122, dtype=float32), 'eval/episode_reward_linvel_std': Array(340.0838, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.399158, dtype=float32), 'eval/episode_x_position_std': Array(270.78732, dtype=float32), 'eval/episode_x_velocity_std': Array(68.016754, dtype=float32), 'eval/episode_y_position_std': Array(178.66652, dtype=float32), 'eval/episode_y_velocity_std': Array(43.206894, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.17794704437256, 'eval/sps': 939.9466123416603, 'num_steps': 20480000}
{'eval/walltime': 34430.48516917229, 'training/sps': 2955.9606486720936, 'training/walltime': 7013.042844057083, 'training/entropy_loss': Array(0.00729496, dtype=float32), 'training/policy_loss': Array(-0.00164297, dtype=float32), 'training/total_loss': Array(0.08385815, dtype=float32), 'training/v_loss': Array(0.07820617, dtype=float32), 'eval/episode_distance_from_origin': Array(4147.82, dtype=float32), 'eval/episode_distance_reward': Array(6.6552, dtype=float32), 'eval/episode_forward_reward': Array(1109.1986, dtype=float32), 'eval/episode_reward': Array(1218.8641, dtype=float32), 'eval/episode_reward_alive': Array(391.83984, dtype=float32), 'eval/episode_reward_linvel': Array(1109.1986, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.82977, dtype=float32), 'eval/episode_x_position': Array(4098.4434, dtype=float32), 'eval/episode_x_velocity': Array(221.83972, dtype=float32), 'eval/episode_y_position': Array(-327.0977, dtype=float32), 'eval/episode_y_velocity': Array(-71.407616, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.6544, dtype=float32), 'eval/episode_distance_reward_std': Array(2.716167, dtype=float32), 'eval/episode_forward_reward_std': Array(452.6928, dtype=float32), 'eval/episode_reward_std': Array(447.50064, dtype=float32), 'eval/episode_reward_alive_std': Array(106.25989, dtype=float32), 'eval/episode_reward_linvel_std': Array(452.6928, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.893646, dtype=float32), 'eval/episode_x_position_std': Array(378.00522, dtype=float32), 'eval/episode_x_velocity_std': Array(90.53856, dtype=float32), 'eval/episode_y_position_std': Array(214.80614, dtype=float32), 'eval/episode_y_velocity_std': Array(50.40332, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32620406150818, 'eval/sps': 938.9244047479564, 'num_steps': 20561920}
{'eval/walltime': 34566.64992642403, 'training/sps': 2942.8763873988464, 'training/walltime': 7040.879555225372, 'training/entropy_loss': Array(0.00828445, dtype=float32), 'training/policy_loss': Array(0.00399845, dtype=float32), 'training/total_loss': Array(0.09103169, dtype=float32), 'training/v_loss': Array(0.07874878, dtype=float32), 'eval/episode_distance_from_origin': Array(4195.6997, dtype=float32), 'eval/episode_distance_reward': Array(7.1214924, dtype=float32), 'eval/episode_forward_reward': Array(1186.9137, dtype=float32), 'eval/episode_reward': Array(1306.752, dtype=float32), 'eval/episode_reward_alive': Array(407.27344, dtype=float32), 'eval/episode_reward_linvel': Array(1186.9137, dtype=float32), 'eval/episode_reward_quadctrl': Array(-294.55673, dtype=float32), 'eval/episode_x_position': Array(4145.6406, dtype=float32), 'eval/episode_x_velocity': Array(237.38275, dtype=float32), 'eval/episode_y_position': Array(-338.9934, dtype=float32), 'eval/episode_y_velocity': Array(-76.76851, dtype=float32), 'eval/episode_distance_from_origin_std': Array(394.84763, dtype=float32), 'eval/episode_distance_reward_std': Array(3.112708, dtype=float32), 'eval/episode_forward_reward_std': Array(518.7823, dtype=float32), 'eval/episode_reward_std': Array(490.17798, dtype=float32), 'eval/episode_reward_alive_std': Array(91.5292, dtype=float32), 'eval/episode_reward_linvel_std': Array(518.7823, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.577507, dtype=float32), 'eval/episode_x_position_std': Array(383.7048, dtype=float32), 'eval/episode_x_velocity_std': Array(103.756485, dtype=float32), 'eval/episode_y_position_std': Array(208.08377, dtype=float32), 'eval/episode_y_velocity_std': Array(52.709576, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1647572517395, 'eval/sps': 940.0376616054577, 'num_steps': 20643840}
{'eval/walltime': 34702.97146034241, 'training/sps': 2945.767717708188, 'training/walltime': 7068.688944101334, 'training/entropy_loss': Array(0.00328956, dtype=float32), 'training/policy_loss': Array(0.00109303, dtype=float32), 'training/total_loss': Array(0.0275008, dtype=float32), 'training/v_loss': Array(0.02311821, dtype=float32), 'eval/episode_distance_from_origin': Array(4187.8877, dtype=float32), 'eval/episode_distance_reward': Array(7.00216, dtype=float32), 'eval/episode_forward_reward': Array(1167.025, dtype=float32), 'eval/episode_reward': Array(1302.6082, dtype=float32), 'eval/episode_reward_alive': Array(417.89844, dtype=float32), 'eval/episode_reward_linvel': Array(1167.025, dtype=float32), 'eval/episode_reward_quadctrl': Array(-289.31747, dtype=float32), 'eval/episode_x_position': Array(4142.42, dtype=float32), 'eval/episode_x_velocity': Array(233.40503, dtype=float32), 'eval/episode_y_position': Array(-282.35873, dtype=float32), 'eval/episode_y_velocity': Array(-62.325966, dtype=float32), 'eval/episode_distance_from_origin_std': Array(370.72873, dtype=float32), 'eval/episode_distance_reward_std': Array(2.8829272, dtype=float32), 'eval/episode_forward_reward_std': Array(480.4853, dtype=float32), 'eval/episode_reward_std': Array(462.74792, dtype=float32), 'eval/episode_reward_alive_std': Array(92.53855, dtype=float32), 'eval/episode_reward_linvel_std': Array(480.4853, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.3367, dtype=float32), 'eval/episode_x_position_std': Array(365.46967, dtype=float32), 'eval/episode_x_velocity_std': Array(96.09705, dtype=float32), 'eval/episode_y_position_std': Array(204.17279, dtype=float32), 'eval/episode_y_velocity_std': Array(47.592846, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32153391838074, 'eval/sps': 938.9565706958443, 'num_steps': 20725760}
{'eval/walltime': 34839.12764215469, 'training/sps': 2942.5685856213736, 'training/walltime': 7096.528567075729, 'training/entropy_loss': Array(0.00196273, dtype=float32), 'training/policy_loss': Array(-0.00499545, dtype=float32), 'training/total_loss': Array(0.00099622, dtype=float32), 'training/v_loss': Array(0.00402893, dtype=float32), 'eval/episode_distance_from_origin': Array(4073.7046, dtype=float32), 'eval/episode_distance_reward': Array(6.150816, dtype=float32), 'eval/episode_forward_reward': Array(1025.135, dtype=float32), 'eval/episode_reward': Array(1189.5726, dtype=float32), 'eval/episode_reward_alive': Array(438.4375, dtype=float32), 'eval/episode_reward_linvel': Array(1025.135, dtype=float32), 'eval/episode_reward_quadctrl': Array(-280.1507, dtype=float32), 'eval/episode_x_position': Array(4031.1665, dtype=float32), 'eval/episode_x_velocity': Array(205.02701, dtype=float32), 'eval/episode_y_position': Array(-270.23273, dtype=float32), 'eval/episode_y_velocity': Array(-57.31253, dtype=float32), 'eval/episode_distance_from_origin_std': Array(296.30096, dtype=float32), 'eval/episode_distance_reward_std': Array(2.1759472, dtype=float32), 'eval/episode_forward_reward_std': Array(362.65656, dtype=float32), 'eval/episode_reward_std': Array(352.73254, dtype=float32), 'eval/episode_reward_alive_std': Array(60.42554, dtype=float32), 'eval/episode_reward_linvel_std': Array(362.65656, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.320675, dtype=float32), 'eval/episode_x_position_std': Array(291.99472, dtype=float32), 'eval/episode_x_velocity_std': Array(72.531334, dtype=float32), 'eval/episode_y_position_std': Array(142.63829, dtype=float32), 'eval/episode_y_velocity_std': Array(31.212585, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.15618181228638, 'eval/sps': 940.0968674082606, 'num_steps': 20807680}
{'eval/walltime': 34975.45064711571, 'training/sps': 2948.724050354944, 'training/walltime': 7124.310074806213, 'training/entropy_loss': Array(0.0017634, dtype=float32), 'training/policy_loss': Array(-0.01540627, dtype=float32), 'training/total_loss': Array(-0.0125912, dtype=float32), 'training/v_loss': Array(0.00105168, dtype=float32), 'eval/episode_distance_from_origin': Array(4029.061, dtype=float32), 'eval/episode_distance_reward': Array(5.985261, dtype=float32), 'eval/episode_forward_reward': Array(997.54236, dtype=float32), 'eval/episode_reward': Array(1138.5303, dtype=float32), 'eval/episode_reward_alive': Array(423.0664, dtype=float32), 'eval/episode_reward_linvel': Array(997.54236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.06372, dtype=float32), 'eval/episode_x_position': Array(3984.7092, dtype=float32), 'eval/episode_x_velocity': Array(199.50847, dtype=float32), 'eval/episode_y_position': Array(-272.20667, dtype=float32), 'eval/episode_y_velocity': Array(-59.265377, dtype=float32), 'eval/episode_distance_from_origin_std': Array(307.7149, dtype=float32), 'eval/episode_distance_reward_std': Array(2.6112568, dtype=float32), 'eval/episode_forward_reward_std': Array(435.20712, dtype=float32), 'eval/episode_reward_std': Array(430.38013, dtype=float32), 'eval/episode_reward_alive_std': Array(88.70514, dtype=float32), 'eval/episode_reward_linvel_std': Array(435.20712, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.123, dtype=float32), 'eval/episode_x_position_std': Array(299.55334, dtype=float32), 'eval/episode_x_velocity_std': Array(87.04146, dtype=float32), 'eval/episode_y_position_std': Array(169.67973, dtype=float32), 'eval/episode_y_velocity_std': Array(40.116222, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3230049610138, 'eval/sps': 938.9464385457609, 'num_steps': 20889600}
{'eval/walltime': 35111.70550465584, 'training/sps': 2950.067737282104, 'training/walltime': 7152.07892870903, 'training/entropy_loss': Array(0.00173856, dtype=float32), 'training/policy_loss': Array(-0.02494285, dtype=float32), 'training/total_loss': Array(-0.02256547, dtype=float32), 'training/v_loss': Array(0.00063882, dtype=float32), 'eval/episode_distance_from_origin': Array(3919.274, dtype=float32), 'eval/episode_distance_reward': Array(5.2669177, dtype=float32), 'eval/episode_forward_reward': Array(877.8188, dtype=float32), 'eval/episode_reward': Array(1035.4343, dtype=float32), 'eval/episode_reward_alive': Array(436.2422, dtype=float32), 'eval/episode_reward_linvel': Array(877.8188, dtype=float32), 'eval/episode_reward_quadctrl': Array(-283.89365, dtype=float32), 'eval/episode_x_position': Array(3877.1406, dtype=float32), 'eval/episode_x_velocity': Array(175.56375, dtype=float32), 'eval/episode_y_position': Array(-229.12263, dtype=float32), 'eval/episode_y_velocity': Array(-49.35619, dtype=float32), 'eval/episode_distance_from_origin_std': Array(218.4866, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7910331, dtype=float32), 'eval/episode_forward_reward_std': Array(298.5042, dtype=float32), 'eval/episode_reward_std': Array(308.28125, dtype=float32), 'eval/episode_reward_alive_std': Array(80.01155, dtype=float32), 'eval/episode_reward_linvel_std': Array(298.5042, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.147022, dtype=float32), 'eval/episode_x_position_std': Array(217.02512, dtype=float32), 'eval/episode_x_velocity_std': Array(59.70086, dtype=float32), 'eval/episode_y_position_std': Array(151.81573, dtype=float32), 'eval/episode_y_velocity_std': Array(34.96832, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25485754013062, 'eval/sps': 939.416049532771, 'num_steps': 20971520}
{'eval/walltime': 35248.10883831978, 'training/sps': 2942.66356809941, 'training/walltime': 7179.917653083801, 'training/entropy_loss': Array(0.00647816, dtype=float32), 'training/policy_loss': Array(0.00183403, dtype=float32), 'training/total_loss': Array(0.07052335, dtype=float32), 'training/v_loss': Array(0.06221118, dtype=float32), 'eval/episode_distance_from_origin': Array(4020.4229, dtype=float32), 'eval/episode_distance_reward': Array(5.9051704, dtype=float32), 'eval/episode_forward_reward': Array(984.19385, dtype=float32), 'eval/episode_reward': Array(1122.8757, dtype=float32), 'eval/episode_reward_alive': Array(421.13672, dtype=float32), 'eval/episode_reward_linvel': Array(984.19385, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.35995, dtype=float32), 'eval/episode_x_position': Array(3973.441, dtype=float32), 'eval/episode_x_velocity': Array(196.83878, dtype=float32), 'eval/episode_y_position': Array(-292.21014, dtype=float32), 'eval/episode_y_velocity': Array(-62.395603, dtype=float32), 'eval/episode_distance_from_origin_std': Array(314.8336, dtype=float32), 'eval/episode_distance_reward_std': Array(2.6064415, dtype=float32), 'eval/episode_forward_reward_std': Array(434.40488, dtype=float32), 'eval/episode_reward_std': Array(426.35577, dtype=float32), 'eval/episode_reward_alive_std': Array(91.759254, dtype=float32), 'eval/episode_reward_linvel_std': Array(434.40488, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.735844, dtype=float32), 'eval/episode_x_position_std': Array(305.02548, dtype=float32), 'eval/episode_x_velocity_std': Array(86.88098, dtype=float32), 'eval/episode_y_position_std': Array(189.74094, dtype=float32), 'eval/episode_y_velocity_std': Array(47.118626, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40333366394043, 'eval/sps': 938.393487620736, 'num_steps': 21053440}
{'eval/walltime': 35384.503121852875, 'training/sps': 2953.6392588203616, 'training/walltime': 7207.652929067612, 'training/entropy_loss': Array(0.01036558, dtype=float32), 'training/policy_loss': Array(0.00361729, dtype=float32), 'training/total_loss': Array(0.10275203, dtype=float32), 'training/v_loss': Array(0.08876916, dtype=float32), 'eval/episode_distance_from_origin': Array(4002.5925, dtype=float32), 'eval/episode_distance_reward': Array(5.72252, dtype=float32), 'eval/episode_forward_reward': Array(953.75244, dtype=float32), 'eval/episode_reward': Array(1113.8276, dtype=float32), 'eval/episode_reward_alive': Array(438.97266, dtype=float32), 'eval/episode_reward_linvel': Array(953.75244, dtype=float32), 'eval/episode_reward_quadctrl': Array(-284.6203, dtype=float32), 'eval/episode_x_position': Array(3957.3975, dtype=float32), 'eval/episode_x_velocity': Array(190.75046, dtype=float32), 'eval/episode_y_position': Array(-280.44778, dtype=float32), 'eval/episode_y_velocity': Array(-60.56119, dtype=float32), 'eval/episode_distance_from_origin_std': Array(251.12268, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8529016, dtype=float32), 'eval/episode_forward_reward_std': Array(308.81607, dtype=float32), 'eval/episode_reward_std': Array(308.3551, dtype=float32), 'eval/episode_reward_alive_std': Array(77.56117, dtype=float32), 'eval/episode_reward_linvel_std': Array(308.81607, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.35046, dtype=float32), 'eval/episode_x_position_std': Array(246.87471, dtype=float32), 'eval/episode_x_velocity_std': Array(61.76319, dtype=float32), 'eval/episode_y_position_std': Array(158.54007, dtype=float32), 'eval/episode_y_velocity_std': Array(36.82267, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3942835330963, 'eval/sps': 938.4557525751479, 'num_steps': 21135360}
{'eval/walltime': 35520.87866663933, 'training/sps': 2958.002973969221, 'training/walltime': 7235.347289323807, 'training/entropy_loss': Array(0.00387421, dtype=float32), 'training/policy_loss': Array(-0.00032033, dtype=float32), 'training/total_loss': Array(0.02255899, dtype=float32), 'training/v_loss': Array(0.01900511, dtype=float32), 'eval/episode_distance_from_origin': Array(3991.1035, dtype=float32), 'eval/episode_distance_reward': Array(5.694281, dtype=float32), 'eval/episode_forward_reward': Array(949.04553, dtype=float32), 'eval/episode_reward': Array(1105.3594, dtype=float32), 'eval/episode_reward_alive': Array(435.90234, dtype=float32), 'eval/episode_reward_linvel': Array(949.04553, dtype=float32), 'eval/episode_reward_quadctrl': Array(-285.2827, dtype=float32), 'eval/episode_x_position': Array(3947.601, dtype=float32), 'eval/episode_x_velocity': Array(189.80913, dtype=float32), 'eval/episode_y_position': Array(-247.71976, dtype=float32), 'eval/episode_y_velocity': Array(-52.90674, dtype=float32), 'eval/episode_distance_from_origin_std': Array(315.41077, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4839869, dtype=float32), 'eval/episode_forward_reward_std': Array(413.99576, dtype=float32), 'eval/episode_reward_std': Array(422.02475, dtype=float32), 'eval/episode_reward_alive_std': Array(78.66804, dtype=float32), 'eval/episode_reward_linvel_std': Array(413.99576, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.556595, dtype=float32), 'eval/episode_x_position_std': Array(311.35715, dtype=float32), 'eval/episode_x_velocity_std': Array(82.79918, dtype=float32), 'eval/episode_y_position_std': Array(176.23056, dtype=float32), 'eval/episode_y_velocity_std': Array(39.037403, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37554478645325, 'eval/sps': 938.5847015345142, 'num_steps': 21217280}
{'eval/walltime': 35657.30103611946, 'training/sps': 2956.427720152333, 'training/walltime': 7263.0564057827, 'training/entropy_loss': Array(0.00256253, dtype=float32), 'training/policy_loss': Array(-0.00327495, dtype=float32), 'training/total_loss': Array(0.00455412, dtype=float32), 'training/v_loss': Array(0.00526654, dtype=float32), 'eval/episode_distance_from_origin': Array(4022.8638, dtype=float32), 'eval/episode_distance_reward': Array(5.93888, dtype=float32), 'eval/episode_forward_reward': Array(989.812, dtype=float32), 'eval/episode_reward': Array(1155.4929, dtype=float32), 'eval/episode_reward_alive': Array(435.19922, dtype=float32), 'eval/episode_reward_linvel': Array(989.812, dtype=float32), 'eval/episode_reward_quadctrl': Array(-275.45718, dtype=float32), 'eval/episode_x_position': Array(3980.4248, dtype=float32), 'eval/episode_x_velocity': Array(197.9624, dtype=float32), 'eval/episode_y_position': Array(-235.4434, dtype=float32), 'eval/episode_y_velocity': Array(-51.118256, dtype=float32), 'eval/episode_distance_from_origin_std': Array(308.87128, dtype=float32), 'eval/episode_distance_reward_std': Array(2.4468572, dtype=float32), 'eval/episode_forward_reward_std': Array(407.80737, dtype=float32), 'eval/episode_reward_std': Array(405.7052, dtype=float32), 'eval/episode_reward_alive_std': Array(84.715454, dtype=float32), 'eval/episode_reward_linvel_std': Array(407.80737, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.595623, dtype=float32), 'eval/episode_x_position_std': Array(306.17795, dtype=float32), 'eval/episode_x_velocity_std': Array(81.56149, dtype=float32), 'eval/episode_y_position_std': Array(172.36713, dtype=float32), 'eval/episode_y_velocity_std': Array(39.368233, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42236948013306, 'eval/sps': 938.2625480540448, 'num_steps': 21299200}
{'eval/walltime': 35793.656279563904, 'training/sps': 2969.1495895050307, 'training/walltime': 7290.646797418594, 'training/entropy_loss': Array(0.00229218, dtype=float32), 'training/policy_loss': Array(-0.00469604, dtype=float32), 'training/total_loss': Array(-3.8886268e-05, dtype=float32), 'training/v_loss': Array(0.00236498, dtype=float32), 'eval/episode_distance_from_origin': Array(3974.803, dtype=float32), 'eval/episode_distance_reward': Array(5.7700768, dtype=float32), 'eval/episode_forward_reward': Array(961.6786, dtype=float32), 'eval/episode_reward': Array(1125.5901, dtype=float32), 'eval/episode_reward_alive': Array(435.3203, dtype=float32), 'eval/episode_reward_linvel': Array(961.6786, dtype=float32), 'eval/episode_reward_quadctrl': Array(-277.17883, dtype=float32), 'eval/episode_x_position': Array(3934.7183, dtype=float32), 'eval/episode_x_velocity': Array(192.33572, dtype=float32), 'eval/episode_y_position': Array(-185.97818, dtype=float32), 'eval/episode_y_velocity': Array(-40.326126, dtype=float32), 'eval/episode_distance_from_origin_std': Array(300.29733, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7554603, dtype=float32), 'eval/episode_forward_reward_std': Array(459.24182, dtype=float32), 'eval/episode_reward_std': Array(459.39957, dtype=float32), 'eval/episode_reward_alive_std': Array(86.53137, dtype=float32), 'eval/episode_reward_linvel_std': Array(459.24182, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.901085, dtype=float32), 'eval/episode_x_position_std': Array(296.11307, dtype=float32), 'eval/episode_x_velocity_std': Array(91.84833, dtype=float32), 'eval/episode_y_position_std': Array(170.74321, dtype=float32), 'eval/episode_y_velocity_std': Array(43.366837, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35524344444275, 'eval/sps': 938.7244433482526, 'num_steps': 21381120}
{'eval/walltime': 35930.26377129555, 'training/sps': 2960.505110821959, 'training/walltime': 7318.317751169205, 'training/entropy_loss': Array(0.00216444, dtype=float32), 'training/policy_loss': Array(-0.01401642, dtype=float32), 'training/total_loss': Array(-0.01090223, dtype=float32), 'training/v_loss': Array(0.00094975, dtype=float32), 'eval/episode_distance_from_origin': Array(3905.2192, dtype=float32), 'eval/episode_distance_reward': Array(5.2361026, dtype=float32), 'eval/episode_forward_reward': Array(872.68384, dtype=float32), 'eval/episode_reward': Array(1060.1987, dtype=float32), 'eval/episode_reward_alive': Array(450.6289, dtype=float32), 'eval/episode_reward_linvel': Array(872.68384, dtype=float32), 'eval/episode_reward_quadctrl': Array(-268.35007, dtype=float32), 'eval/episode_x_position': Array(3868.558, dtype=float32), 'eval/episode_x_velocity': Array(174.53671, dtype=float32), 'eval/episode_y_position': Array(-128.48477, dtype=float32), 'eval/episode_y_velocity': Array(-28.045343, dtype=float32), 'eval/episode_distance_from_origin_std': Array(200.92416, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8769891, dtype=float32), 'eval/episode_forward_reward_std': Array(312.83078, dtype=float32), 'eval/episode_reward_std': Array(310.89276, dtype=float32), 'eval/episode_reward_alive_std': Array(68.44743, dtype=float32), 'eval/episode_reward_linvel_std': Array(312.83078, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.017788, dtype=float32), 'eval/episode_x_position_std': Array(199.75876, dtype=float32), 'eval/episode_x_velocity_std': Array(62.566116, dtype=float32), 'eval/episode_y_position_std': Array(135.42737, dtype=float32), 'eval/episode_y_velocity_std': Array(32.198334, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60749173164368, 'eval/sps': 936.9910711152465, 'num_steps': 21463040}
{'eval/walltime': 36066.63381195068, 'training/sps': 2965.826151925377, 'training/walltime': 7345.939059972763, 'training/entropy_loss': Array(0.00443859, dtype=float32), 'training/policy_loss': Array(-0.00560205, dtype=float32), 'training/total_loss': Array(0.01234754, dtype=float32), 'training/v_loss': Array(0.01351101, dtype=float32), 'eval/episode_distance_from_origin': Array(3986.5464, dtype=float32), 'eval/episode_distance_reward': Array(5.5690923, dtype=float32), 'eval/episode_forward_reward': Array(928.18176, dtype=float32), 'eval/episode_reward': Array(1127.6825, dtype=float32), 'eval/episode_reward_alive': Array(456.16016, dtype=float32), 'eval/episode_reward_linvel': Array(928.18176, dtype=float32), 'eval/episode_reward_quadctrl': Array(-262.2285, dtype=float32), 'eval/episode_x_position': Array(3947.9644, dtype=float32), 'eval/episode_x_velocity': Array(185.63635, dtype=float32), 'eval/episode_y_position': Array(-193.40411, dtype=float32), 'eval/episode_y_velocity': Array(-40.67973, dtype=float32), 'eval/episode_distance_from_origin_std': Array(268.34122, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9846903, dtype=float32), 'eval/episode_forward_reward_std': Array(330.78027, dtype=float32), 'eval/episode_reward_std': Array(330.541, dtype=float32), 'eval/episode_reward_alive_std': Array(60.97745, dtype=float32), 'eval/episode_reward_linvel_std': Array(330.78027, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.185453, dtype=float32), 'eval/episode_x_position_std': Array(265.80014, dtype=float32), 'eval/episode_x_velocity_std': Array(66.15607, dtype=float32), 'eval/episode_y_position_std': Array(136.96745, dtype=float32), 'eval/episode_y_velocity_std': Array(28.475952, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3700406551361, 'eval/sps': 938.6225844406473, 'num_steps': 21544960}
{'eval/walltime': 36203.24193882942, 'training/sps': 2961.1298137222298, 'training/walltime': 7373.604176044464, 'training/entropy_loss': Array(0.01099239, dtype=float32), 'training/policy_loss': Array(0.00552574, dtype=float32), 'training/total_loss': Array(0.10823236, dtype=float32), 'training/v_loss': Array(0.09171423, dtype=float32), 'eval/episode_distance_from_origin': Array(4105.9316, dtype=float32), 'eval/episode_distance_reward': Array(6.4858427, dtype=float32), 'eval/episode_forward_reward': Array(1080.9725, dtype=float32), 'eval/episode_reward': Array(1266.1305, dtype=float32), 'eval/episode_reward_alive': Array(442.88672, dtype=float32), 'eval/episode_reward_linvel': Array(1080.9725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-264.21454, dtype=float32), 'eval/episode_x_position': Array(4066.3003, dtype=float32), 'eval/episode_x_velocity': Array(216.19449, dtype=float32), 'eval/episode_y_position': Array(-206.24872, dtype=float32), 'eval/episode_y_velocity': Array(-46.710426, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.37503, dtype=float32), 'eval/episode_distance_reward_std': Array(3.0514789, dtype=float32), 'eval/episode_forward_reward_std': Array(508.57687, dtype=float32), 'eval/episode_reward_std': Array(491.6138, dtype=float32), 'eval/episode_reward_alive_std': Array(75.90751, dtype=float32), 'eval/episode_reward_linvel_std': Array(508.57687, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.351166, dtype=float32), 'eval/episode_x_position_std': Array(372.31964, dtype=float32), 'eval/episode_x_velocity_std': Array(101.71534, dtype=float32), 'eval/episode_y_position_std': Array(162.78548, dtype=float32), 'eval/episode_y_velocity_std': Array(39.18807, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6081268787384, 'eval/sps': 936.9867146602522, 'num_steps': 21626880}
{'eval/walltime': 36339.61558556557, 'training/sps': 2966.424546794046, 'training/walltime': 7401.219913005829, 'training/entropy_loss': Array(0.00419355, dtype=float32), 'training/policy_loss': Array(0.00088991, dtype=float32), 'training/total_loss': Array(0.03141288, dtype=float32), 'training/v_loss': Array(0.02632941, dtype=float32), 'eval/episode_distance_from_origin': Array(4019.0525, dtype=float32), 'eval/episode_distance_reward': Array(5.928868, dtype=float32), 'eval/episode_forward_reward': Array(988.1439, dtype=float32), 'eval/episode_reward': Array(1191.823, dtype=float32), 'eval/episode_reward_alive': Array(460.78906, dtype=float32), 'eval/episode_reward_linvel': Array(988.1439, dtype=float32), 'eval/episode_reward_quadctrl': Array(-263.0388, dtype=float32), 'eval/episode_x_position': Array(3979.0786, dtype=float32), 'eval/episode_x_velocity': Array(197.62875, dtype=float32), 'eval/episode_y_position': Array(-193.35632, dtype=float32), 'eval/episode_y_velocity': Array(-42.924137, dtype=float32), 'eval/episode_distance_from_origin_std': Array(321.8553, dtype=float32), 'eval/episode_distance_reward_std': Array(2.7861605, dtype=float32), 'eval/episode_forward_reward_std': Array(464.35782, dtype=float32), 'eval/episode_reward_std': Array(436.4449, dtype=float32), 'eval/episode_reward_alive_std': Array(61.705055, dtype=float32), 'eval/episode_reward_linvel_std': Array(464.35782, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.314598, dtype=float32), 'eval/episode_x_position_std': Array(316.07047, dtype=float32), 'eval/episode_x_velocity_std': Array(92.87152, dtype=float32), 'eval/episode_y_position_std': Array(174.3019, dtype=float32), 'eval/episode_y_velocity_std': Array(40.404026, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37364673614502, 'eval/sps': 938.5977647694184, 'num_steps': 21708800}
{'eval/walltime': 36476.21867728233, 'training/sps': 2961.4315565723405, 'training/walltime': 7428.882210254669, 'training/entropy_loss': Array(0.00274509, dtype=float32), 'training/policy_loss': Array(0.00592896, dtype=float32), 'training/total_loss': Array(0.01771904, dtype=float32), 'training/v_loss': Array(0.00904498, dtype=float32), 'eval/episode_distance_from_origin': Array(4036.0083, dtype=float32), 'eval/episode_distance_reward': Array(6.1310916, dtype=float32), 'eval/episode_forward_reward': Array(1021.8481, dtype=float32), 'eval/episode_reward': Array(1233.9988, dtype=float32), 'eval/episode_reward_alive': Array(468., dtype=float32), 'eval/episode_reward_linvel': Array(1021.8481, dtype=float32), 'eval/episode_reward_quadctrl': Array(-261.98026, dtype=float32), 'eval/episode_x_position': Array(3996.1167, dtype=float32), 'eval/episode_x_velocity': Array(204.36957, dtype=float32), 'eval/episode_y_position': Array(-181.48843, dtype=float32), 'eval/episode_y_velocity': Array(-41.3042, dtype=float32), 'eval/episode_distance_from_origin_std': Array(326.81042, dtype=float32), 'eval/episode_distance_reward_std': Array(2.9787464, dtype=float32), 'eval/episode_forward_reward_std': Array(496.45578, dtype=float32), 'eval/episode_reward_std': Array(467.61588, dtype=float32), 'eval/episode_reward_alive_std': Array(25.845997, dtype=float32), 'eval/episode_reward_linvel_std': Array(496.45578, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.819336, dtype=float32), 'eval/episode_x_position_std': Array(321.83075, dtype=float32), 'eval/episode_x_velocity_std': Array(99.29113, dtype=float32), 'eval/episode_y_position_std': Array(172.7358, dtype=float32), 'eval/episode_y_velocity_std': Array(44.09331, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60309171676636, 'eval/sps': 937.0212517985752, 'num_steps': 21790720}
{'eval/walltime': 36612.52976560593, 'training/sps': 2949.584847321295, 'training/walltime': 7456.655610322952, 'training/entropy_loss': Array(0.00254024, dtype=float32), 'training/policy_loss': Array(-0.00214672, dtype=float32), 'training/total_loss': Array(0.00387491, dtype=float32), 'training/v_loss': Array(0.00348139, dtype=float32), 'eval/episode_distance_from_origin': Array(3993.2231, dtype=float32), 'eval/episode_distance_reward': Array(5.9644566, dtype=float32), 'eval/episode_forward_reward': Array(994.07556, dtype=float32), 'eval/episode_reward': Array(1202.6256, dtype=float32), 'eval/episode_reward_alive': Array(469.48047, dtype=float32), 'eval/episode_reward_linvel': Array(994.07556, dtype=float32), 'eval/episode_reward_quadctrl': Array(-266.89496, dtype=float32), 'eval/episode_x_position': Array(3954.814, dtype=float32), 'eval/episode_x_velocity': Array(198.8151, dtype=float32), 'eval/episode_y_position': Array(-128.6766, dtype=float32), 'eval/episode_y_velocity': Array(-33.171688, dtype=float32), 'eval/episode_distance_from_origin_std': Array(335.14648, dtype=float32), 'eval/episode_distance_reward_std': Array(3.2752213, dtype=float32), 'eval/episode_forward_reward_std': Array(545.8679, dtype=float32), 'eval/episode_reward_std': Array(516.9894, dtype=float32), 'eval/episode_reward_alive_std': Array(41.404133, dtype=float32), 'eval/episode_reward_linvel_std': Array(545.8679, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.69952, dtype=float32), 'eval/episode_x_position_std': Array(332.41833, dtype=float32), 'eval/episode_x_velocity_std': Array(109.17359, dtype=float32), 'eval/episode_y_position_std': Array(180.25945, dtype=float32), 'eval/episode_y_velocity_std': Array(47.95918, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31108832359314, 'eval/sps': 939.0285234619859, 'num_steps': 21872640}
{'eval/walltime': 36749.05903315544, 'training/sps': 2951.7748199268344, 'training/walltime': 7484.408404827118, 'training/entropy_loss': Array(0.00246743, dtype=float32), 'training/policy_loss': Array(-0.01282364, dtype=float32), 'training/total_loss': Array(-0.00867389, dtype=float32), 'training/v_loss': Array(0.00168231, dtype=float32), 'eval/episode_distance_from_origin': Array(4008.729, dtype=float32), 'eval/episode_distance_reward': Array(6.0807223, dtype=float32), 'eval/episode_forward_reward': Array(1013.45294, dtype=float32), 'eval/episode_reward': Array(1230.713, dtype=float32), 'eval/episode_reward_alive': Array(471.01953, dtype=float32), 'eval/episode_reward_linvel': Array(1013.45294, dtype=float32), 'eval/episode_reward_quadctrl': Array(-259.84027, dtype=float32), 'eval/episode_x_position': Array(3970.6519, dtype=float32), 'eval/episode_x_velocity': Array(202.69061, dtype=float32), 'eval/episode_y_position': Array(-112.00838, dtype=float32), 'eval/episode_y_velocity': Array(-28.061665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(408.62802, dtype=float32), 'eval/episode_distance_reward_std': Array(3.5701854, dtype=float32), 'eval/episode_forward_reward_std': Array(595.0269, dtype=float32), 'eval/episode_reward_std': Array(558.13367, dtype=float32), 'eval/episode_reward_alive_std': Array(24.777401, dtype=float32), 'eval/episode_reward_linvel_std': Array(595.0269, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.89617, dtype=float32), 'eval/episode_x_position_std': Array(403.62094, dtype=float32), 'eval/episode_x_velocity_std': Array(119.00541, dtype=float32), 'eval/episode_y_position_std': Array(184.75276, dtype=float32), 'eval/episode_y_velocity_std': Array(47.026676, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52926754951477, 'eval/sps': 937.5279183533195, 'num_steps': 21954560}
{'eval/walltime': 36885.55660510063, 'training/sps': 2958.959068853616, 'training/walltime': 7512.093816518784, 'training/entropy_loss': Array(0.00265845, dtype=float32), 'training/policy_loss': Array(-0.0080647, dtype=float32), 'training/total_loss': Array(0.00570226, dtype=float32), 'training/v_loss': Array(0.0111085, dtype=float32), 'eval/episode_distance_from_origin': Array(4140.0166, dtype=float32), 'eval/episode_distance_reward': Array(7.3750057, dtype=float32), 'eval/episode_forward_reward': Array(1229.166, dtype=float32), 'eval/episode_reward': Array(1431.13, dtype=float32), 'eval/episode_reward_alive': Array(460.54688, dtype=float32), 'eval/episode_reward_linvel': Array(1229.166, dtype=float32), 'eval/episode_reward_quadctrl': Array(-265.95767, dtype=float32), 'eval/episode_x_position': Array(4100.658, dtype=float32), 'eval/episode_x_velocity': Array(245.83319, dtype=float32), 'eval/episode_y_position': Array(-140.9316, dtype=float32), 'eval/episode_y_velocity': Array(-38.09175, dtype=float32), 'eval/episode_distance_from_origin_std': Array(415.314, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2723126, dtype=float32), 'eval/episode_forward_reward_std': Array(712.04767, dtype=float32), 'eval/episode_reward_std': Array(660.8873, dtype=float32), 'eval/episode_reward_alive_std': Array(50.039803, dtype=float32), 'eval/episode_reward_linvel_std': Array(712.04767, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.17954, dtype=float32), 'eval/episode_x_position_std': Array(412.358, dtype=float32), 'eval/episode_x_velocity_std': Array(142.4095, dtype=float32), 'eval/episode_y_position_std': Array(196.49556, dtype=float32), 'eval/episode_y_velocity_std': Array(55.248486, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49757194519043, 'eval/sps': 937.7456182985983, 'num_steps': 22036480}
{'eval/walltime': 37022.074180841446, 'training/sps': 2950.6514783215675, 'training/walltime': 7539.857176780701, 'training/entropy_loss': Array(0.01083214, dtype=float32), 'training/policy_loss': Array(0.00359151, dtype=float32), 'training/total_loss': Array(0.10653748, dtype=float32), 'training/v_loss': Array(0.09211382, dtype=float32), 'eval/episode_distance_from_origin': Array(4341.248, dtype=float32), 'eval/episode_distance_reward': Array(8.82337, dtype=float32), 'eval/episode_forward_reward': Array(1470.5585, dtype=float32), 'eval/episode_reward': Array(1653.7043, dtype=float32), 'eval/episode_reward_alive': Array(451.80078, dtype=float32), 'eval/episode_reward_linvel': Array(1470.5585, dtype=float32), 'eval/episode_reward_quadctrl': Array(-277.47833, dtype=float32), 'eval/episode_x_position': Array(4301.3564, dtype=float32), 'eval/episode_x_velocity': Array(294.1117, dtype=float32), 'eval/episode_y_position': Array(-188.69572, dtype=float32), 'eval/episode_y_velocity': Array(-52.144615, dtype=float32), 'eval/episode_distance_from_origin_std': Array(520.2783, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7013984, dtype=float32), 'eval/episode_forward_reward_std': Array(783.5614, dtype=float32), 'eval/episode_reward_std': Array(723.88855, dtype=float32), 'eval/episode_reward_alive_std': Array(49.40538, dtype=float32), 'eval/episode_reward_linvel_std': Array(783.5614, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.87596, dtype=float32), 'eval/episode_x_position_std': Array(515.86487, dtype=float32), 'eval/episode_x_velocity_std': Array(156.71234, dtype=float32), 'eval/episode_y_position_std': Array(200.031, dtype=float32), 'eval/episode_y_velocity_std': Array(55.92213, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5175757408142, 'eval/sps': 937.6082112900593, 'num_steps': 22118400}
{'eval/walltime': 37158.54465460777, 'training/sps': 2950.4888628888198, 'training/walltime': 7567.6220672130585, 'training/entropy_loss': Array(0.00578383, dtype=float32), 'training/policy_loss': Array(0.01036555, dtype=float32), 'training/total_loss': Array(0.07239707, dtype=float32), 'training/v_loss': Array(0.05624769, dtype=float32), 'eval/episode_distance_from_origin': Array(4210.679, dtype=float32), 'eval/episode_distance_reward': Array(8.130899, dtype=float32), 'eval/episode_forward_reward': Array(1355.1475, dtype=float32), 'eval/episode_reward': Array(1549.1465, dtype=float32), 'eval/episode_reward_alive': Array(460.375, dtype=float32), 'eval/episode_reward_linvel': Array(1355.1475, dtype=float32), 'eval/episode_reward_quadctrl': Array(-274.50684, dtype=float32), 'eval/episode_x_position': Array(4171.0894, dtype=float32), 'eval/episode_x_velocity': Array(271.02942, dtype=float32), 'eval/episode_y_position': Array(-140.1658, dtype=float32), 'eval/episode_y_velocity': Array(-43.172398, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.96625, dtype=float32), 'eval/episode_distance_reward_std': Array(4.562757, dtype=float32), 'eval/episode_forward_reward_std': Array(760.45447, dtype=float32), 'eval/episode_reward_std': Array(705.17456, dtype=float32), 'eval/episode_reward_alive_std': Array(32.26005, dtype=float32), 'eval/episode_reward_linvel_std': Array(760.45447, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.549526, dtype=float32), 'eval/episode_x_position_std': Array(428.64682, dtype=float32), 'eval/episode_x_velocity_std': Array(152.09087, dtype=float32), 'eval/episode_y_position_std': Array(200.0972, dtype=float32), 'eval/episode_y_velocity_std': Array(56.515102, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4704737663269, 'eval/sps': 937.9318212023609, 'num_steps': 22200320}
{'eval/walltime': 37295.06990599632, 'training/sps': 2956.6733199780633, 'training/walltime': 7595.328881978989, 'training/entropy_loss': Array(0.00391699, dtype=float32), 'training/policy_loss': Array(0.00350751, dtype=float32), 'training/total_loss': Array(0.03719056, dtype=float32), 'training/v_loss': Array(0.02976606, dtype=float32), 'eval/episode_distance_from_origin': Array(4303.792, dtype=float32), 'eval/episode_distance_reward': Array(8.574135, dtype=float32), 'eval/episode_forward_reward': Array(1429.019, dtype=float32), 'eval/episode_reward': Array(1625.0103, dtype=float32), 'eval/episode_reward_alive': Array(461.3828, dtype=float32), 'eval/episode_reward_linvel': Array(1429.019, dtype=float32), 'eval/episode_reward_quadctrl': Array(-273.9659, dtype=float32), 'eval/episode_x_position': Array(4265.796, dtype=float32), 'eval/episode_x_velocity': Array(285.80383, dtype=float32), 'eval/episode_y_position': Array(-142.63391, dtype=float32), 'eval/episode_y_velocity': Array(-38.582047, dtype=float32), 'eval/episode_distance_from_origin_std': Array(514.2289, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6988826, dtype=float32), 'eval/episode_forward_reward_std': Array(783.14215, dtype=float32), 'eval/episode_reward_std': Array(722.84393, dtype=float32), 'eval/episode_reward_alive_std': Array(35.72412, dtype=float32), 'eval/episode_reward_linvel_std': Array(783.14215, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.007, dtype=float32), 'eval/episode_x_position_std': Array(512.42444, dtype=float32), 'eval/episode_x_velocity_std': Array(156.62846, dtype=float32), 'eval/episode_y_position_std': Array(191.90749, dtype=float32), 'eval/episode_y_velocity_std': Array(49.507565, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5252513885498, 'eval/sps': 937.5554975959209, 'num_steps': 22282240}
{'eval/walltime': 37431.53480219841, 'training/sps': 2956.7799271735084, 'training/walltime': 7623.034697771072, 'training/entropy_loss': Array(0.00342378, dtype=float32), 'training/policy_loss': Array(0.01021056, dtype=float32), 'training/total_loss': Array(0.02907179, dtype=float32), 'training/v_loss': Array(0.01543745, dtype=float32), 'eval/episode_distance_from_origin': Array(4431.302, dtype=float32), 'eval/episode_distance_reward': Array(10.569513, dtype=float32), 'eval/episode_forward_reward': Array(1761.5803, dtype=float32), 'eval/episode_reward': Array(1906.6987, dtype=float32), 'eval/episode_reward_alive': Array(440.21875, dtype=float32), 'eval/episode_reward_linvel': Array(1761.5803, dtype=float32), 'eval/episode_reward_quadctrl': Array(-305.66968, dtype=float32), 'eval/episode_x_position': Array(4389.454, dtype=float32), 'eval/episode_x_velocity': Array(352.31604, dtype=float32), 'eval/episode_y_position': Array(-114.26596, dtype=float32), 'eval/episode_y_velocity': Array(-41.40214, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.17215, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7043495, dtype=float32), 'eval/episode_forward_reward_std': Array(784.05194, dtype=float32), 'eval/episode_reward_std': Array(726.0248, dtype=float32), 'eval/episode_reward_alive_std': Array(51.182987, dtype=float32), 'eval/episode_reward_linvel_std': Array(784.05194, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.413265, dtype=float32), 'eval/episode_x_position_std': Array(462.40762, dtype=float32), 'eval/episode_x_velocity_std': Array(156.8104, dtype=float32), 'eval/episode_y_position_std': Array(255.35188, dtype=float32), 'eval/episode_y_velocity_std': Array(80.971695, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4648962020874, 'eval/sps': 937.9701561524514, 'num_steps': 22364160}
{'eval/walltime': 37568.05507135391, 'training/sps': 2951.7170553202463, 'training/walltime': 7650.788035392761, 'training/entropy_loss': Array(0.00328874, dtype=float32), 'training/policy_loss': Array(-0.00118329, dtype=float32), 'training/total_loss': Array(0.01732346, dtype=float32), 'training/v_loss': Array(0.01521802, dtype=float32), 'eval/episode_distance_from_origin': Array(4432.9414, dtype=float32), 'eval/episode_distance_reward': Array(10.731416, dtype=float32), 'eval/episode_forward_reward': Array(1788.5627, dtype=float32), 'eval/episode_reward': Array(1940.1857, dtype=float32), 'eval/episode_reward_alive': Array(443.6836, dtype=float32), 'eval/episode_reward_linvel': Array(1788.5627, dtype=float32), 'eval/episode_reward_quadctrl': Array(-302.7922, dtype=float32), 'eval/episode_x_position': Array(4393.1064, dtype=float32), 'eval/episode_x_velocity': Array(357.71252, dtype=float32), 'eval/episode_y_position': Array(-135.12846, dtype=float32), 'eval/episode_y_velocity': Array(-50.79898, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.40332, dtype=float32), 'eval/episode_distance_reward_std': Array(4.89814, dtype=float32), 'eval/episode_forward_reward_std': Array(816.3501, dtype=float32), 'eval/episode_reward_std': Array(751.11707, dtype=float32), 'eval/episode_reward_alive_std': Array(37.049843, dtype=float32), 'eval/episode_reward_linvel_std': Array(816.3501, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.82477, dtype=float32), 'eval/episode_x_position_std': Array(476.0475, dtype=float32), 'eval/episode_x_velocity_std': Array(163.27007, dtype=float32), 'eval/episode_y_position_std': Array(214.8134, dtype=float32), 'eval/episode_y_velocity_std': Array(72.435616, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52026915550232, 'eval/sps': 937.5897131744051, 'num_steps': 22446080}
{'eval/walltime': 37704.5255086422, 'training/sps': 2954.347940608625, 'training/walltime': 7678.516658306122, 'training/entropy_loss': Array(0.00329027, dtype=float32), 'training/policy_loss': Array(0.01542787, dtype=float32), 'training/total_loss': Array(0.03151999, dtype=float32), 'training/v_loss': Array(0.01280185, dtype=float32), 'eval/episode_distance_from_origin': Array(4464.3022, dtype=float32), 'eval/episode_distance_reward': Array(11.585108, dtype=float32), 'eval/episode_forward_reward': Array(1930.8431, dtype=float32), 'eval/episode_reward': Array(2039.3192, dtype=float32), 'eval/episode_reward_alive': Array(431.1836, dtype=float32), 'eval/episode_reward_linvel': Array(1930.8431, dtype=float32), 'eval/episode_reward_quadctrl': Array(-334.2927, dtype=float32), 'eval/episode_x_position': Array(4423.636, dtype=float32), 'eval/episode_x_velocity': Array(386.16864, dtype=float32), 'eval/episode_y_position': Array(-67.91258, dtype=float32), 'eval/episode_y_velocity': Array(-30.768997, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.70554, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7315536, dtype=float32), 'eval/episode_forward_reward_std': Array(788.5858, dtype=float32), 'eval/episode_reward_std': Array(729.75793, dtype=float32), 'eval/episode_reward_alive_std': Array(40.082233, dtype=float32), 'eval/episode_reward_linvel_std': Array(788.5858, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.716663, dtype=float32), 'eval/episode_x_position_std': Array(426.22092, dtype=float32), 'eval/episode_x_velocity_std': Array(157.71718, dtype=float32), 'eval/episode_y_position_std': Array(236.66826, dtype=float32), 'eval/episode_y_velocity_std': Array(78.75551, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4704372882843, 'eval/sps': 937.9320719080639, 'num_steps': 22528000}
{'eval/walltime': 37841.04168510437, 'training/sps': 2958.538324216543, 'training/walltime': 7706.206007242203, 'training/entropy_loss': Array(0.0078792, dtype=float32), 'training/policy_loss': Array(0.00216734, dtype=float32), 'training/total_loss': Array(0.10003497, dtype=float32), 'training/v_loss': Array(0.08998844, dtype=float32), 'eval/episode_distance_from_origin': Array(4580.299, dtype=float32), 'eval/episode_distance_reward': Array(12.28696, dtype=float32), 'eval/episode_forward_reward': Array(2047.8176, dtype=float32), 'eval/episode_reward': Array(2155.038, dtype=float32), 'eval/episode_reward_alive': Array(429.84766, dtype=float32), 'eval/episode_reward_linvel': Array(2047.8176, dtype=float32), 'eval/episode_reward_quadctrl': Array(-334.91412, dtype=float32), 'eval/episode_x_position': Array(4539.205, dtype=float32), 'eval/episode_x_velocity': Array(409.56348, dtype=float32), 'eval/episode_y_position': Array(-81.490616, dtype=float32), 'eval/episode_y_velocity': Array(-31.239365, dtype=float32), 'eval/episode_distance_from_origin_std': Array(405.78677, dtype=float32), 'eval/episode_distance_reward_std': Array(4.57658, dtype=float32), 'eval/episode_forward_reward_std': Array(762.7564, dtype=float32), 'eval/episode_reward_std': Array(698.7285, dtype=float32), 'eval/episode_reward_alive_std': Array(31.739145, dtype=float32), 'eval/episode_reward_linvel_std': Array(762.7564, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.568512, dtype=float32), 'eval/episode_x_position_std': Array(404.57166, dtype=float32), 'eval/episode_x_velocity_std': Array(152.5513, dtype=float32), 'eval/episode_y_position_std': Array(255.51941, dtype=float32), 'eval/episode_y_velocity_std': Array(86.30574, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51617646217346, 'eval/sps': 937.617821690654, 'num_steps': 22609920}
{'eval/walltime': 37977.52368426323, 'training/sps': 2960.8232081844326, 'training/walltime': 7733.87398815155, 'training/entropy_loss': Array(0.00986042, dtype=float32), 'training/policy_loss': Array(0.00512338, dtype=float32), 'training/total_loss': Array(0.15042922, dtype=float32), 'training/v_loss': Array(0.13544545, dtype=float32), 'eval/episode_distance_from_origin': Array(4547.793, dtype=float32), 'eval/episode_distance_reward': Array(12.313019, dtype=float32), 'eval/episode_forward_reward': Array(2052.1614, dtype=float32), 'eval/episode_reward': Array(2169.7195, dtype=float32), 'eval/episode_reward_alive': Array(436.54688, dtype=float32), 'eval/episode_reward_linvel': Array(2052.1614, dtype=float32), 'eval/episode_reward_quadctrl': Array(-331.30164, dtype=float32), 'eval/episode_x_position': Array(4507.378, dtype=float32), 'eval/episode_x_velocity': Array(410.43225, dtype=float32), 'eval/episode_y_position': Array(-93.10457, dtype=float32), 'eval/episode_y_velocity': Array(-29.220387, dtype=float32), 'eval/episode_distance_from_origin_std': Array(426.32553, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9583316, dtype=float32), 'eval/episode_forward_reward_std': Array(826.38245, dtype=float32), 'eval/episode_reward_std': Array(767.916, dtype=float32), 'eval/episode_reward_alive_std': Array(29.704365, dtype=float32), 'eval/episode_reward_linvel_std': Array(826.38245, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.57028, dtype=float32), 'eval/episode_x_position_std': Array(426.20032, dtype=float32), 'eval/episode_x_velocity_std': Array(165.27644, dtype=float32), 'eval/episode_y_position_std': Array(231.82013, dtype=float32), 'eval/episode_y_velocity_std': Array(83.886375, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48199915885925, 'eval/sps': 937.852616380666, 'num_steps': 22691840}
{'eval/walltime': 38114.04520511627, 'training/sps': 2962.690055449029, 'training/walltime': 7761.52453494072, 'training/entropy_loss': Array(0.00844442, dtype=float32), 'training/policy_loss': Array(0.07003677, dtype=float32), 'training/total_loss': Array(0.17005304, dtype=float32), 'training/v_loss': Array(0.09157184, dtype=float32), 'eval/episode_distance_from_origin': Array(4678.825, dtype=float32), 'eval/episode_distance_reward': Array(12.942255, dtype=float32), 'eval/episode_forward_reward': Array(2157.034, dtype=float32), 'eval/episode_reward': Array(2252.4165, dtype=float32), 'eval/episode_reward_alive': Array(425.78906, dtype=float32), 'eval/episode_reward_linvel': Array(2157.034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-343.3485, dtype=float32), 'eval/episode_x_position': Array(4639.8667, dtype=float32), 'eval/episode_x_velocity': Array(431.4068, dtype=float32), 'eval/episode_y_position': Array(-52.767174, dtype=float32), 'eval/episode_y_velocity': Array(-17.262674, dtype=float32), 'eval/episode_distance_from_origin_std': Array(422.77026, dtype=float32), 'eval/episode_distance_reward_std': Array(5.02846, dtype=float32), 'eval/episode_forward_reward_std': Array(838.0703, dtype=float32), 'eval/episode_reward_std': Array(779.0444, dtype=float32), 'eval/episode_reward_alive_std': Array(45.95228, dtype=float32), 'eval/episode_reward_linvel_std': Array(838.0703, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.78353, dtype=float32), 'eval/episode_x_position_std': Array(422.85306, dtype=float32), 'eval/episode_x_velocity_std': Array(167.61409, dtype=float32), 'eval/episode_y_position_std': Array(241.67862, dtype=float32), 'eval/episode_y_velocity_std': Array(83.28658, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5215208530426, 'eval/sps': 937.5811168832823, 'num_steps': 22773760}
{'eval/walltime': 38250.49826216698, 'training/sps': 2968.4919026207326, 'training/walltime': 7789.121039390564, 'training/entropy_loss': Array(0.00855984, dtype=float32), 'training/policy_loss': Array(0.00733594, dtype=float32), 'training/total_loss': Array(0.0968893, dtype=float32), 'training/v_loss': Array(0.08099353, dtype=float32), 'eval/episode_distance_from_origin': Array(4754.726, dtype=float32), 'eval/episode_distance_reward': Array(13.613127, dtype=float32), 'eval/episode_forward_reward': Array(2268.8447, dtype=float32), 'eval/episode_reward': Array(2362.3142, dtype=float32), 'eval/episode_reward_alive': Array(424.4414, dtype=float32), 'eval/episode_reward_linvel': Array(2268.8447, dtype=float32), 'eval/episode_reward_quadctrl': Array(-344.58478, dtype=float32), 'eval/episode_x_position': Array(4712.709, dtype=float32), 'eval/episode_x_velocity': Array(453.76892, dtype=float32), 'eval/episode_y_position': Array(9.789408, dtype=float32), 'eval/episode_y_velocity': Array(6.172034, dtype=float32), 'eval/episode_distance_from_origin_std': Array(394.76483, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8937182, dtype=float32), 'eval/episode_forward_reward_std': Array(815.6129, dtype=float32), 'eval/episode_reward_std': Array(761.443, dtype=float32), 'eval/episode_reward_alive_std': Array(42.12874, dtype=float32), 'eval/episode_reward_linvel_std': Array(815.6129, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.54852, dtype=float32), 'eval/episode_x_position_std': Array(394.09735, dtype=float32), 'eval/episode_x_velocity_std': Array(163.1226, dtype=float32), 'eval/episode_y_position_std': Array(295.36157, dtype=float32), 'eval/episode_y_velocity_std': Array(103.12851, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45305705070496, 'eval/sps': 938.0515377712361, 'num_steps': 22855680}
{'eval/walltime': 38387.16054391861, 'training/sps': 2961.1251437376077, 'training/walltime': 7816.786199092865, 'training/entropy_loss': Array(0.00894829, dtype=float32), 'training/policy_loss': Array(0.00737029, dtype=float32), 'training/total_loss': Array(0.10900574, dtype=float32), 'training/v_loss': Array(0.09268714, dtype=float32), 'eval/episode_distance_from_origin': Array(4751.241, dtype=float32), 'eval/episode_distance_reward': Array(13.715588, dtype=float32), 'eval/episode_forward_reward': Array(2285.9214, dtype=float32), 'eval/episode_reward': Array(2371.747, dtype=float32), 'eval/episode_reward_alive': Array(421.33203, dtype=float32), 'eval/episode_reward_linvel': Array(2285.9214, dtype=float32), 'eval/episode_reward_quadctrl': Array(-349.22168, dtype=float32), 'eval/episode_x_position': Array(4711.6577, dtype=float32), 'eval/episode_x_velocity': Array(457.18423, dtype=float32), 'eval/episode_y_position': Array(21.27636, dtype=float32), 'eval/episode_y_velocity': Array(2.469101, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.8185, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8954544, dtype=float32), 'eval/episode_forward_reward_std': Array(815.9025, dtype=float32), 'eval/episode_reward_std': Array(763.09485, dtype=float32), 'eval/episode_reward_alive_std': Array(48.76503, dtype=float32), 'eval/episode_reward_linvel_std': Array(815.9025, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.49798, dtype=float32), 'eval/episode_x_position_std': Array(411.3623, dtype=float32), 'eval/episode_x_velocity_std': Array(163.18048, dtype=float32), 'eval/episode_y_position_std': Array(264.58926, dtype=float32), 'eval/episode_y_velocity_std': Array(90.14341, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6622817516327, 'eval/sps': 936.6154169196783, 'num_steps': 22937600}
{'eval/walltime': 38523.70062828064, 'training/sps': 2966.127444417102, 'training/walltime': 7844.4047021865845, 'training/entropy_loss': Array(0.00859005, dtype=float32), 'training/policy_loss': Array(0.01279012, dtype=float32), 'training/total_loss': Array(0.13158798, dtype=float32), 'training/v_loss': Array(0.11020783, dtype=float32), 'eval/episode_distance_from_origin': Array(4742.45, dtype=float32), 'eval/episode_distance_reward': Array(13.920631, dtype=float32), 'eval/episode_forward_reward': Array(2320.0957, dtype=float32), 'eval/episode_reward': Array(2394.3198, dtype=float32), 'eval/episode_reward_alive': Array(415.66797, dtype=float32), 'eval/episode_reward_linvel': Array(2320.0957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-355.3642, dtype=float32), 'eval/episode_x_position': Array(4699.9375, dtype=float32), 'eval/episode_x_velocity': Array(464.0191, dtype=float32), 'eval/episode_y_position': Array(-24.943893, dtype=float32), 'eval/episode_y_velocity': Array(-9.808717, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.09787, dtype=float32), 'eval/episode_distance_reward_std': Array(4.531375, dtype=float32), 'eval/episode_forward_reward_std': Array(755.2231, dtype=float32), 'eval/episode_reward_std': Array(716.8448, dtype=float32), 'eval/episode_reward_alive_std': Array(47.828278, dtype=float32), 'eval/episode_reward_linvel_std': Array(755.2231, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.65379, dtype=float32), 'eval/episode_x_position_std': Array(388.48257, dtype=float32), 'eval/episode_x_velocity_std': Array(151.0446, dtype=float32), 'eval/episode_y_position_std': Array(292.37415, dtype=float32), 'eval/episode_y_velocity_std': Array(100.028656, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54008436203003, 'eval/sps': 937.4536466567109, 'num_steps': 23019520}
{'eval/walltime': 38660.32565689087, 'training/sps': 2950.476929679415, 'training/walltime': 7872.169704914093, 'training/entropy_loss': Array(0.00700097, dtype=float32), 'training/policy_loss': Array(0.00141284, dtype=float32), 'training/total_loss': Array(0.085201, dtype=float32), 'training/v_loss': Array(0.07678718, dtype=float32), 'eval/episode_distance_from_origin': Array(4809.7505, dtype=float32), 'eval/episode_distance_reward': Array(13.845592, dtype=float32), 'eval/episode_forward_reward': Array(2307.589, dtype=float32), 'eval/episode_reward': Array(2401.2268, dtype=float32), 'eval/episode_reward_alive': Array(421.6836, dtype=float32), 'eval/episode_reward_linvel': Array(2307.589, dtype=float32), 'eval/episode_reward_quadctrl': Array(-341.89175, dtype=float32), 'eval/episode_x_position': Array(4768.416, dtype=float32), 'eval/episode_x_velocity': Array(461.51785, dtype=float32), 'eval/episode_y_position': Array(-36.883717, dtype=float32), 'eval/episode_y_velocity': Array(-22.41096, dtype=float32), 'eval/episode_distance_from_origin_std': Array(369.45132, dtype=float32), 'eval/episode_distance_reward_std': Array(4.433808, dtype=float32), 'eval/episode_forward_reward_std': Array(738.9619, dtype=float32), 'eval/episode_reward_std': Array(692.1834, dtype=float32), 'eval/episode_reward_alive_std': Array(40.94484, dtype=float32), 'eval/episode_reward_linvel_std': Array(738.9619, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.879128, dtype=float32), 'eval/episode_x_position_std': Array(368.75482, dtype=float32), 'eval/episode_x_velocity_std': Array(147.79236, dtype=float32), 'eval/episode_y_position_std': Array(292.166, dtype=float32), 'eval/episode_y_velocity_std': Array(97.86848, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6250286102295, 'eval/sps': 936.8708010679699, 'num_steps': 23101440}
{'eval/walltime': 38796.80603313446, 'training/sps': 2959.127155566366, 'training/walltime': 7899.853543996811, 'training/entropy_loss': Array(0.01245625, dtype=float32), 'training/policy_loss': Array(0.01740811, dtype=float32), 'training/total_loss': Array(0.15779895, dtype=float32), 'training/v_loss': Array(0.12793459, dtype=float32), 'eval/episode_distance_from_origin': Array(4859.552, dtype=float32), 'eval/episode_distance_reward': Array(14.406074, dtype=float32), 'eval/episode_forward_reward': Array(2401.0017, dtype=float32), 'eval/episode_reward': Array(2495.4272, dtype=float32), 'eval/episode_reward_alive': Array(422.89453, dtype=float32), 'eval/episode_reward_linvel': Array(2401.0017, dtype=float32), 'eval/episode_reward_quadctrl': Array(-342.8753, dtype=float32), 'eval/episode_x_position': Array(4818.008, dtype=float32), 'eval/episode_x_velocity': Array(480.20035, dtype=float32), 'eval/episode_y_position': Array(-30.342516, dtype=float32), 'eval/episode_y_velocity': Array(-19.853123, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.66437, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9318256, dtype=float32), 'eval/episode_forward_reward_std': Array(821.9641, dtype=float32), 'eval/episode_reward_std': Array(760.3526, dtype=float32), 'eval/episode_reward_alive_std': Array(34.65402, dtype=float32), 'eval/episode_reward_linvel_std': Array(821.9641, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.410427, dtype=float32), 'eval/episode_x_position_std': Array(419.58502, dtype=float32), 'eval/episode_x_velocity_std': Array(164.39285, dtype=float32), 'eval/episode_y_position_std': Array(306.62842, dtype=float32), 'eval/episode_y_velocity_std': Array(94.62532, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4803762435913, 'eval/sps': 937.8637685724469, 'num_steps': 23183360}
{'eval/walltime': 38933.3273665905, 'training/sps': 2956.661031385015, 'training/walltime': 7927.560473918915, 'training/entropy_loss': Array(0.01013927, dtype=float32), 'training/policy_loss': Array(0.01378856, dtype=float32), 'training/total_loss': Array(0.13287285, dtype=float32), 'training/v_loss': Array(0.10894503, dtype=float32), 'eval/episode_distance_from_origin': Array(4838.4917, dtype=float32), 'eval/episode_distance_reward': Array(14.83564, dtype=float32), 'eval/episode_forward_reward': Array(2472.595, dtype=float32), 'eval/episode_reward': Array(2546.0413, dtype=float32), 'eval/episode_reward_alive': Array(411.6914, dtype=float32), 'eval/episode_reward_linvel': Array(2472.595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-353.08075, dtype=float32), 'eval/episode_x_position': Array(4795.149, dtype=float32), 'eval/episode_x_velocity': Array(494.51898, dtype=float32), 'eval/episode_y_position': Array(-27.523579, dtype=float32), 'eval/episode_y_velocity': Array(-18.316462, dtype=float32), 'eval/episode_distance_from_origin_std': Array(405.24136, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7176003, dtype=float32), 'eval/episode_forward_reward_std': Array(786.26056, dtype=float32), 'eval/episode_reward_std': Array(737.0043, dtype=float32), 'eval/episode_reward_alive_std': Array(36.69879, dtype=float32), 'eval/episode_reward_linvel_std': Array(786.26056, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.10956, dtype=float32), 'eval/episode_x_position_std': Array(404.48282, dtype=float32), 'eval/episode_x_velocity_std': Array(157.25206, dtype=float32), 'eval/episode_y_position_std': Array(314.235, dtype=float32), 'eval/episode_y_velocity_std': Array(106.85628, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52133345603943, 'eval/sps': 937.5824038608343, 'num_steps': 23265280}
{'eval/walltime': 39069.95408010483, 'training/sps': 2965.989540715612, 'training/walltime': 7955.180261135101, 'training/entropy_loss': Array(0.00926535, dtype=float32), 'training/policy_loss': Array(0.02410661, dtype=float32), 'training/total_loss': Array(0.12857251, dtype=float32), 'training/v_loss': Array(0.09520054, dtype=float32), 'eval/episode_distance_from_origin': Array(4805.294, dtype=float32), 'eval/episode_distance_reward': Array(13.693693, dtype=float32), 'eval/episode_forward_reward': Array(2282.272, dtype=float32), 'eval/episode_reward': Array(2384.0962, dtype=float32), 'eval/episode_reward_alive': Array(418.3711, dtype=float32), 'eval/episode_reward_linvel': Array(2282.272, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.2406, dtype=float32), 'eval/episode_x_position': Array(4767.416, dtype=float32), 'eval/episode_x_velocity': Array(456.45438, dtype=float32), 'eval/episode_y_position': Array(-124.71099, dtype=float32), 'eval/episode_y_velocity': Array(-45.37327, dtype=float32), 'eval/episode_distance_from_origin_std': Array(400.34653, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6873794, dtype=float32), 'eval/episode_forward_reward_std': Array(781.2232, dtype=float32), 'eval/episode_reward_std': Array(724.02527, dtype=float32), 'eval/episode_reward_alive_std': Array(43.088764, dtype=float32), 'eval/episode_reward_linvel_std': Array(781.2232, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.209488, dtype=float32), 'eval/episode_x_position_std': Array(397.84146, dtype=float32), 'eval/episode_x_velocity_std': Array(156.24466, dtype=float32), 'eval/episode_y_position_std': Array(220.56184, dtype=float32), 'eval/episode_y_velocity_std': Array(75.588005, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.626713514328, 'eval/sps': 936.8592474163311, 'num_steps': 23347200}
{'eval/walltime': 39206.47292423248, 'training/sps': 2955.5931790789823, 'training/walltime': 7982.897201538086, 'training/entropy_loss': Array(0.00854649, dtype=float32), 'training/policy_loss': Array(0.00615907, dtype=float32), 'training/total_loss': Array(0.1220403, dtype=float32), 'training/v_loss': Array(0.10733473, dtype=float32), 'eval/episode_distance_from_origin': Array(4776.4443, dtype=float32), 'eval/episode_distance_reward': Array(12.916687, dtype=float32), 'eval/episode_forward_reward': Array(2152.7727, dtype=float32), 'eval/episode_reward': Array(2259.379, dtype=float32), 'eval/episode_reward_alive': Array(419.28125, dtype=float32), 'eval/episode_reward_linvel': Array(2152.7727, dtype=float32), 'eval/episode_reward_quadctrl': Array(-325.59186, dtype=float32), 'eval/episode_x_position': Array(4735.036, dtype=float32), 'eval/episode_x_velocity': Array(430.55457, dtype=float32), 'eval/episode_y_position': Array(-134.32062, dtype=float32), 'eval/episode_y_velocity': Array(-53.630585, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.84995, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4475417, dtype=float32), 'eval/episode_forward_reward_std': Array(741.2501, dtype=float32), 'eval/episode_reward_std': Array(688.6462, dtype=float32), 'eval/episode_reward_alive_std': Array(42.453503, dtype=float32), 'eval/episode_reward_linvel_std': Array(741.2501, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.21266, dtype=float32), 'eval/episode_x_position_std': Array(409.07025, dtype=float32), 'eval/episode_x_velocity_std': Array(148.25002, dtype=float32), 'eval/episode_y_position_std': Array(269.10083, dtype=float32), 'eval/episode_y_velocity_std': Array(85.44298, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51884412765503, 'eval/sps': 937.599500039062, 'num_steps': 23429120}
{'eval/walltime': 39343.00748920441, 'training/sps': 2963.5287374517625, 'training/walltime': 8010.539923191071, 'training/entropy_loss': Array(0.00793245, dtype=float32), 'training/policy_loss': Array(0.00854249, dtype=float32), 'training/total_loss': Array(0.09128483, dtype=float32), 'training/v_loss': Array(0.07480989, dtype=float32), 'eval/episode_distance_from_origin': Array(4871.33, dtype=float32), 'eval/episode_distance_reward': Array(14.150293, dtype=float32), 'eval/episode_forward_reward': Array(2358.3726, dtype=float32), 'eval/episode_reward': Array(2462.4106, dtype=float32), 'eval/episode_reward_alive': Array(422.05078, dtype=float32), 'eval/episode_reward_linvel': Array(2358.3726, dtype=float32), 'eval/episode_reward_quadctrl': Array(-332.1629, dtype=float32), 'eval/episode_x_position': Array(4830.066, dtype=float32), 'eval/episode_x_velocity': Array(471.6745, dtype=float32), 'eval/episode_y_position': Array(-58.57258, dtype=float32), 'eval/episode_y_velocity': Array(-30.082924, dtype=float32), 'eval/episode_distance_from_origin_std': Array(403.08597, dtype=float32), 'eval/episode_distance_reward_std': Array(5.051346, dtype=float32), 'eval/episode_forward_reward_std': Array(841.88434, dtype=float32), 'eval/episode_reward_std': Array(781.1361, dtype=float32), 'eval/episode_reward_alive_std': Array(34.36442, dtype=float32), 'eval/episode_reward_linvel_std': Array(841.88434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(57.305412, dtype=float32), 'eval/episode_x_position_std': Array(401.88855, dtype=float32), 'eval/episode_x_velocity_std': Array(168.37686, dtype=float32), 'eval/episode_y_position_std': Array(303.10477, dtype=float32), 'eval/episode_y_velocity_std': Array(93.957436, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53456497192383, 'eval/sps': 937.491543085234, 'num_steps': 23511040}
{'eval/walltime': 39479.65648698807, 'training/sps': 2951.11152520892, 'training/walltime': 8038.298955440521, 'training/entropy_loss': Array(0.00669299, dtype=float32), 'training/policy_loss': Array(0.0055893, dtype=float32), 'training/total_loss': Array(0.07386133, dtype=float32), 'training/v_loss': Array(0.06157904, dtype=float32), 'eval/episode_distance_from_origin': Array(4831.545, dtype=float32), 'eval/episode_distance_reward': Array(13.55674, dtype=float32), 'eval/episode_forward_reward': Array(2259.448, dtype=float32), 'eval/episode_reward': Array(2360.1719, dtype=float32), 'eval/episode_reward_alive': Array(414.36328, dtype=float32), 'eval/episode_reward_linvel': Array(2259.448, dtype=float32), 'eval/episode_reward_quadctrl': Array(-327.19556, dtype=float32), 'eval/episode_x_position': Array(4792.8047, dtype=float32), 'eval/episode_x_velocity': Array(451.8896, dtype=float32), 'eval/episode_y_position': Array(-12.740218, dtype=float32), 'eval/episode_y_velocity': Array(-26.36774, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.5886, dtype=float32), 'eval/episode_distance_reward_std': Array(4.827553, dtype=float32), 'eval/episode_forward_reward_std': Array(804.5854, dtype=float32), 'eval/episode_reward_std': Array(750.7816, dtype=float32), 'eval/episode_reward_alive_std': Array(43.519604, dtype=float32), 'eval/episode_reward_linvel_std': Array(804.5854, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(57.111263, dtype=float32), 'eval/episode_x_position_std': Array(386.51517, dtype=float32), 'eval/episode_x_velocity_std': Array(160.91705, dtype=float32), 'eval/episode_y_position_std': Array(275.592, dtype=float32), 'eval/episode_y_velocity_std': Array(87.70249, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6489977836609, 'eval/sps': 936.7064674901329, 'num_steps': 23592960}
{'eval/walltime': 39616.18790960312, 'training/sps': 2962.2592595769706, 'training/walltime': 8065.953523397446, 'training/entropy_loss': Array(0.01334742, dtype=float32), 'training/policy_loss': Array(0.0116648, dtype=float32), 'training/total_loss': Array(0.13768063, dtype=float32), 'training/v_loss': Array(0.11266842, dtype=float32), 'eval/episode_distance_from_origin': Array(4852.4434, dtype=float32), 'eval/episode_distance_reward': Array(13.976211, dtype=float32), 'eval/episode_forward_reward': Array(2329.359, dtype=float32), 'eval/episode_reward': Array(2413.603, dtype=float32), 'eval/episode_reward_alive': Array(404.83984, dtype=float32), 'eval/episode_reward_linvel': Array(2329.359, dtype=float32), 'eval/episode_reward_quadctrl': Array(-334.5721, dtype=float32), 'eval/episode_x_position': Array(4813.092, dtype=float32), 'eval/episode_x_velocity': Array(465.87177, dtype=float32), 'eval/episode_y_position': Array(-58.132565, dtype=float32), 'eval/episode_y_velocity': Array(-46.50826, dtype=float32), 'eval/episode_distance_from_origin_std': Array(401.97287, dtype=float32), 'eval/episode_distance_reward_std': Array(5.20112, dtype=float32), 'eval/episode_forward_reward_std': Array(866.84674, dtype=float32), 'eval/episode_reward_std': Array(813.1359, dtype=float32), 'eval/episode_reward_alive_std': Array(50.792313, dtype=float32), 'eval/episode_reward_linvel_std': Array(866.84674, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.203342, dtype=float32), 'eval/episode_x_position_std': Array(400.07892, dtype=float32), 'eval/episode_x_velocity_std': Array(173.36931, dtype=float32), 'eval/episode_y_position_std': Array(269.6307, dtype=float32), 'eval/episode_y_velocity_std': Array(80.168686, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53142261505127, 'eval/sps': 937.5131200448594, 'num_steps': 23674880}
{'eval/walltime': 39752.821607112885, 'training/sps': 2959.7282804035535, 'training/walltime': 8093.631739854813, 'training/entropy_loss': Array(0.00966621, dtype=float32), 'training/policy_loss': Array(0.00395718, dtype=float32), 'training/total_loss': Array(0.10055351, dtype=float32), 'training/v_loss': Array(0.08693011, dtype=float32), 'eval/episode_distance_from_origin': Array(4869.1353, dtype=float32), 'eval/episode_distance_reward': Array(13.9115095, dtype=float32), 'eval/episode_forward_reward': Array(2318.5747, dtype=float32), 'eval/episode_reward': Array(2396.9683, dtype=float32), 'eval/episode_reward_alive': Array(402.42578, dtype=float32), 'eval/episode_reward_linvel': Array(2318.5747, dtype=float32), 'eval/episode_reward_quadctrl': Array(-337.94366, dtype=float32), 'eval/episode_x_position': Array(4828.867, dtype=float32), 'eval/episode_x_velocity': Array(463.71497, dtype=float32), 'eval/episode_y_position': Array(-58.957893, dtype=float32), 'eval/episode_y_velocity': Array(-38.246796, dtype=float32), 'eval/episode_distance_from_origin_std': Array(349.89124, dtype=float32), 'eval/episode_distance_reward_std': Array(4.586205, dtype=float32), 'eval/episode_forward_reward_std': Array(764.3609, dtype=float32), 'eval/episode_reward_std': Array(722.7765, dtype=float32), 'eval/episode_reward_alive_std': Array(54.06041, dtype=float32), 'eval/episode_reward_linvel_std': Array(764.3609, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.432182, dtype=float32), 'eval/episode_x_position_std': Array(345.33585, dtype=float32), 'eval/episode_x_velocity_std': Array(152.87225, dtype=float32), 'eval/episode_y_position_std': Array(288.3125, dtype=float32), 'eval/episode_y_velocity_std': Array(86.715294, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63369750976562, 'eval/sps': 936.811360102814, 'num_steps': 23756800}
{'eval/walltime': 39889.36847496033, 'training/sps': 2965.2470629267414, 'training/walltime': 8121.258442878723, 'training/entropy_loss': Array(0.00827555, dtype=float32), 'training/policy_loss': Array(0.00439282, dtype=float32), 'training/total_loss': Array(0.07651193, dtype=float32), 'training/v_loss': Array(0.06384356, dtype=float32), 'eval/episode_distance_from_origin': Array(4879.0005, dtype=float32), 'eval/episode_distance_reward': Array(13.98364, dtype=float32), 'eval/episode_forward_reward': Array(2330.5967, dtype=float32), 'eval/episode_reward': Array(2427.2678, dtype=float32), 'eval/episode_reward_alive': Array(413.64062, dtype=float32), 'eval/episode_reward_linvel': Array(2330.5967, dtype=float32), 'eval/episode_reward_quadctrl': Array(-330.95343, dtype=float32), 'eval/episode_x_position': Array(4842.135, dtype=float32), 'eval/episode_x_velocity': Array(466.11935, dtype=float32), 'eval/episode_y_position': Array(-28.80112, dtype=float32), 'eval/episode_y_velocity': Array(-38.373116, dtype=float32), 'eval/episode_distance_from_origin_std': Array(382.81842, dtype=float32), 'eval/episode_distance_reward_std': Array(4.800367, dtype=float32), 'eval/episode_forward_reward_std': Array(800.05444, dtype=float32), 'eval/episode_reward_std': Array(751.2614, dtype=float32), 'eval/episode_reward_alive_std': Array(46.657574, dtype=float32), 'eval/episode_reward_linvel_std': Array(800.05444, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.17661, dtype=float32), 'eval/episode_x_position_std': Array(381.48422, dtype=float32), 'eval/episode_x_velocity_std': Array(160.0109, dtype=float32), 'eval/episode_y_position_std': Array(237.50148, dtype=float32), 'eval/episode_y_velocity_std': Array(74.32515, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54686784744263, 'eval/sps': 937.4070750784878, 'num_steps': 23838720}
{'eval/walltime': 40026.0191822052, 'training/sps': 2959.530937303763, 'training/walltime': 8148.938504934311, 'training/entropy_loss': Array(0.0079717, dtype=float32), 'training/policy_loss': Array(0.00587934, dtype=float32), 'training/total_loss': Array(0.07539976, dtype=float32), 'training/v_loss': Array(0.06154872, dtype=float32), 'eval/episode_distance_from_origin': Array(4959.399, dtype=float32), 'eval/episode_distance_reward': Array(14.69318, dtype=float32), 'eval/episode_forward_reward': Array(2448.853, dtype=float32), 'eval/episode_reward': Array(2534.6895, dtype=float32), 'eval/episode_reward_alive': Array(406.42578, dtype=float32), 'eval/episode_reward_linvel': Array(2448.853, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.28265, dtype=float32), 'eval/episode_x_position': Array(4917.8066, dtype=float32), 'eval/episode_x_velocity': Array(489.77063, dtype=float32), 'eval/episode_y_position': Array(-91.49335, dtype=float32), 'eval/episode_y_velocity': Array(-48.751827, dtype=float32), 'eval/episode_distance_from_origin_std': Array(422.8363, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9516115, dtype=float32), 'eval/episode_forward_reward_std': Array(825.2621, dtype=float32), 'eval/episode_reward_std': Array(772.0799, dtype=float32), 'eval/episode_reward_alive_std': Array(46.711094, dtype=float32), 'eval/episode_reward_linvel_std': Array(825.2621, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.47324, dtype=float32), 'eval/episode_x_position_std': Array(417.7607, dtype=float32), 'eval/episode_x_velocity_std': Array(165.05241, dtype=float32), 'eval/episode_y_position_std': Array(305.44437, dtype=float32), 'eval/episode_y_velocity_std': Array(88.18294, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65070724487305, 'eval/sps': 936.6947495604886, 'num_steps': 23920640}
{'eval/walltime': 40162.55776309967, 'training/sps': 2957.947817339856, 'training/walltime': 8176.633381605148, 'training/entropy_loss': Array(0.0077844, dtype=float32), 'training/policy_loss': Array(0.00344462, dtype=float32), 'training/total_loss': Array(0.0739677, dtype=float32), 'training/v_loss': Array(0.06273867, dtype=float32), 'eval/episode_distance_from_origin': Array(4978.081, dtype=float32), 'eval/episode_distance_reward': Array(14.782995, dtype=float32), 'eval/episode_forward_reward': Array(2463.8223, dtype=float32), 'eval/episode_reward': Array(2544.5334, dtype=float32), 'eval/episode_reward_alive': Array(401.3164, dtype=float32), 'eval/episode_reward_linvel': Array(2463.8223, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.38803, dtype=float32), 'eval/episode_x_position': Array(4939.012, dtype=float32), 'eval/episode_x_velocity': Array(492.76443, dtype=float32), 'eval/episode_y_position': Array(-18.83316, dtype=float32), 'eval/episode_y_velocity': Array(-37.35635, dtype=float32), 'eval/episode_distance_from_origin_std': Array(363.69635, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2364273, dtype=float32), 'eval/episode_forward_reward_std': Array(706.0648, dtype=float32), 'eval/episode_reward_std': Array(669.2936, dtype=float32), 'eval/episode_reward_alive_std': Array(54.198486, dtype=float32), 'eval/episode_reward_linvel_std': Array(706.0648, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.647503, dtype=float32), 'eval/episode_x_position_std': Array(360.86774, dtype=float32), 'eval/episode_x_velocity_std': Array(141.21292, dtype=float32), 'eval/episode_y_position_std': Array(284.16086, dtype=float32), 'eval/episode_y_velocity_std': Array(81.35399, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53858089447021, 'eval/sps': 937.4639692420003, 'num_steps': 24002560}
{'eval/walltime': 40299.186954021454, 'training/sps': 2956.5627771986938, 'training/walltime': 8204.341232299805, 'training/entropy_loss': Array(0.00627153, dtype=float32), 'training/policy_loss': Array(0.0061268, dtype=float32), 'training/total_loss': Array(0.06083922, dtype=float32), 'training/v_loss': Array(0.04844089, dtype=float32), 'eval/episode_distance_from_origin': Array(4909.503, dtype=float32), 'eval/episode_distance_reward': Array(13.918533, dtype=float32), 'eval/episode_forward_reward': Array(2319.7463, dtype=float32), 'eval/episode_reward': Array(2413.3354, dtype=float32), 'eval/episode_reward_alive': Array(406.90234, dtype=float32), 'eval/episode_reward_linvel': Array(2319.7463, dtype=float32), 'eval/episode_reward_quadctrl': Array(-327.2317, dtype=float32), 'eval/episode_x_position': Array(4869.6143, dtype=float32), 'eval/episode_x_velocity': Array(463.94925, dtype=float32), 'eval/episode_y_position': Array(-11.067295, dtype=float32), 'eval/episode_y_velocity': Array(-39.948715, dtype=float32), 'eval/episode_distance_from_origin_std': Array(412.07816, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9426217, dtype=float32), 'eval/episode_forward_reward_std': Array(823.7636, dtype=float32), 'eval/episode_reward_std': Array(771.78174, dtype=float32), 'eval/episode_reward_alive_std': Array(46.42602, dtype=float32), 'eval/episode_reward_linvel_std': Array(823.7636, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.714855, dtype=float32), 'eval/episode_x_position_std': Array(412.52246, dtype=float32), 'eval/episode_x_velocity_std': Array(164.75272, dtype=float32), 'eval/episode_y_position_std': Array(283.10355, dtype=float32), 'eval/episode_y_velocity_std': Array(84.0446, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62919092178345, 'eval/sps': 936.8422599624158, 'num_steps': 24084480}
{'eval/walltime': 40435.72023558617, 'training/sps': 2953.3969044537453, 'training/walltime': 8232.078784227371, 'training/entropy_loss': Array(0.01169087, dtype=float32), 'training/policy_loss': Array(0.01489046, dtype=float32), 'training/total_loss': Array(0.1687926, dtype=float32), 'training/v_loss': Array(0.14221126, dtype=float32), 'eval/episode_distance_from_origin': Array(4968.987, dtype=float32), 'eval/episode_distance_reward': Array(14.3848, dtype=float32), 'eval/episode_forward_reward': Array(2397.457, dtype=float32), 'eval/episode_reward': Array(2476.5964, dtype=float32), 'eval/episode_reward_alive': Array(402.8789, dtype=float32), 'eval/episode_reward_linvel': Array(2397.457, dtype=float32), 'eval/episode_reward_quadctrl': Array(-338.12405, dtype=float32), 'eval/episode_x_position': Array(4928.141, dtype=float32), 'eval/episode_x_velocity': Array(479.49133, dtype=float32), 'eval/episode_y_position': Array(13.282983, dtype=float32), 'eval/episode_y_velocity': Array(-32.537777, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.4752, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9961567, dtype=float32), 'eval/episode_forward_reward_std': Array(832.6863, dtype=float32), 'eval/episode_reward_std': Array(781.3671, dtype=float32), 'eval/episode_reward_alive_std': Array(47.729206, dtype=float32), 'eval/episode_reward_linvel_std': Array(832.6863, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.0239, dtype=float32), 'eval/episode_x_position_std': Array(423.94934, dtype=float32), 'eval/episode_x_velocity_std': Array(166.53728, dtype=float32), 'eval/episode_y_position_std': Array(307.92056, dtype=float32), 'eval/episode_y_velocity_std': Array(92.06759, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53328156471252, 'eval/sps': 937.5003554670441, 'num_steps': 24166400}
{'eval/walltime': 40572.36202931404, 'training/sps': 2968.760416272456, 'training/walltime': 8259.672792673111, 'training/entropy_loss': Array(0.01279886, dtype=float32), 'training/policy_loss': Array(0.02810281, dtype=float32), 'training/total_loss': Array(0.1463967, dtype=float32), 'training/v_loss': Array(0.10549504, dtype=float32), 'eval/episode_distance_from_origin': Array(4884.8223, dtype=float32), 'eval/episode_distance_reward': Array(13.521778, dtype=float32), 'eval/episode_forward_reward': Array(2253.621, dtype=float32), 'eval/episode_reward': Array(2356.1826, dtype=float32), 'eval/episode_reward_alive': Array(413.14062, dtype=float32), 'eval/episode_reward_linvel': Array(2253.621, dtype=float32), 'eval/episode_reward_quadctrl': Array(-324.1004, dtype=float32), 'eval/episode_x_position': Array(4844.2485, dtype=float32), 'eval/episode_x_velocity': Array(450.72424, dtype=float32), 'eval/episode_y_position': Array(73.3272, dtype=float32), 'eval/episode_y_velocity': Array(-15.395292, dtype=float32), 'eval/episode_distance_from_origin_std': Array(389.51767, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6823077, dtype=float32), 'eval/episode_forward_reward_std': Array(780.3785, dtype=float32), 'eval/episode_reward_std': Array(724.0137, dtype=float32), 'eval/episode_reward_alive_std': Array(45.22595, dtype=float32), 'eval/episode_reward_linvel_std': Array(780.3785, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.252373, dtype=float32), 'eval/episode_x_position_std': Array(388.29932, dtype=float32), 'eval/episode_x_velocity_std': Array(156.07567, dtype=float32), 'eval/episode_y_position_std': Array(294.20407, dtype=float32), 'eval/episode_y_velocity_std': Array(83.37449, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64179372787476, 'eval/sps': 936.7558527145429, 'num_steps': 24248320}
{'eval/walltime': 40708.98225545883, 'training/sps': 2976.903030552814, 'training/walltime': 8287.191324234009, 'training/entropy_loss': Array(0.00884424, dtype=float32), 'training/policy_loss': Array(0.03730465, dtype=float32), 'training/total_loss': Array(0.11261038, dtype=float32), 'training/v_loss': Array(0.06646148, dtype=float32), 'eval/episode_distance_from_origin': Array(4988.0083, dtype=float32), 'eval/episode_distance_reward': Array(14.927666, dtype=float32), 'eval/episode_forward_reward': Array(2487.934, dtype=float32), 'eval/episode_reward': Array(2547.52, dtype=float32), 'eval/episode_reward_alive': Array(388.29297, dtype=float32), 'eval/episode_reward_linvel': Array(2487.934, dtype=float32), 'eval/episode_reward_quadctrl': Array(-343.63467, dtype=float32), 'eval/episode_x_position': Array(4947.1494, dtype=float32), 'eval/episode_x_velocity': Array(497.58682, dtype=float32), 'eval/episode_y_position': Array(45.885307, dtype=float32), 'eval/episode_y_velocity': Array(-33.66636, dtype=float32), 'eval/episode_distance_from_origin_std': Array(462.8648, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5462384, dtype=float32), 'eval/episode_forward_reward_std': Array(924.36615, dtype=float32), 'eval/episode_reward_std': Array(882.009, dtype=float32), 'eval/episode_reward_alive_std': Array(62.482136, dtype=float32), 'eval/episode_reward_linvel_std': Array(924.36615, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(57.45699, dtype=float32), 'eval/episode_x_position_std': Array(461.72516, dtype=float32), 'eval/episode_x_velocity_std': Array(184.87326, dtype=float32), 'eval/episode_y_position_std': Array(298.98193, dtype=float32), 'eval/episode_y_velocity_std': Array(77.73239, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62022614479065, 'eval/sps': 936.9037338903619, 'num_steps': 24330240}
{'eval/walltime': 40845.490917921066, 'training/sps': 2960.7050840148254, 'training/walltime': 8314.860409021378, 'training/entropy_loss': Array(0.00819699, dtype=float32), 'training/policy_loss': Array(0.0038914, dtype=float32), 'training/total_loss': Array(0.07462838, dtype=float32), 'training/v_loss': Array(0.06253999, dtype=float32), 'eval/episode_distance_from_origin': Array(4920.748, dtype=float32), 'eval/episode_distance_reward': Array(14.355913, dtype=float32), 'eval/episode_forward_reward': Array(2392.642, dtype=float32), 'eval/episode_reward': Array(2472.2852, dtype=float32), 'eval/episode_reward_alive': Array(401.4336, dtype=float32), 'eval/episode_reward_linvel': Array(2392.642, dtype=float32), 'eval/episode_reward_quadctrl': Array(-336.14636, dtype=float32), 'eval/episode_x_position': Array(4879.135, dtype=float32), 'eval/episode_x_velocity': Array(478.52844, dtype=float32), 'eval/episode_y_position': Array(48.173615, dtype=float32), 'eval/episode_y_velocity': Array(-27.64139, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.6411, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1467624, dtype=float32), 'eval/episode_forward_reward_std': Array(857.78723, dtype=float32), 'eval/episode_reward_std': Array(800.8806, dtype=float32), 'eval/episode_reward_alive_std': Array(53.723915, dtype=float32), 'eval/episode_reward_linvel_std': Array(857.78723, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.74358, dtype=float32), 'eval/episode_x_position_std': Array(408.4499, dtype=float32), 'eval/episode_x_velocity_std': Array(171.5575, dtype=float32), 'eval/episode_y_position_std': Array(300.25888, dtype=float32), 'eval/episode_y_velocity_std': Array(93.634155, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5086624622345, 'eval/sps': 937.6694320436372, 'num_steps': 24412160}
{'eval/walltime': 40982.089747428894, 'training/sps': 2962.5216148248883, 'training/walltime': 8342.512527942657, 'training/entropy_loss': Array(0.0079281, dtype=float32), 'training/policy_loss': Array(0.00223563, dtype=float32), 'training/total_loss': Array(0.07092428, dtype=float32), 'training/v_loss': Array(0.06076056, dtype=float32), 'eval/episode_distance_from_origin': Array(4995.0225, dtype=float32), 'eval/episode_distance_reward': Array(14.936519, dtype=float32), 'eval/episode_forward_reward': Array(2489.41, dtype=float32), 'eval/episode_reward': Array(2547.1643, dtype=float32), 'eval/episode_reward_alive': Array(390.59766, dtype=float32), 'eval/episode_reward_linvel': Array(2489.41, dtype=float32), 'eval/episode_reward_quadctrl': Array(-347.7799, dtype=float32), 'eval/episode_x_position': Array(4954.7437, dtype=float32), 'eval/episode_x_velocity': Array(497.88202, dtype=float32), 'eval/episode_y_position': Array(9.92705, dtype=float32), 'eval/episode_y_velocity': Array(-46.144325, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.2098, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1008353, dtype=float32), 'eval/episode_forward_reward_std': Array(850.1333, dtype=float32), 'eval/episode_reward_std': Array(812.6588, dtype=float32), 'eval/episode_reward_alive_std': Array(50.63634, dtype=float32), 'eval/episode_reward_linvel_std': Array(850.1333, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.702263, dtype=float32), 'eval/episode_x_position_std': Array(448.55032, dtype=float32), 'eval/episode_x_velocity_std': Array(170.02672, dtype=float32), 'eval/episode_y_position_std': Array(281.61334, dtype=float32), 'eval/episode_y_velocity_std': Array(78.57673, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59882950782776, 'eval/sps': 937.0504890941617, 'num_steps': 24494080}
{'eval/walltime': 41118.60166621208, 'training/sps': 2960.1585444041807, 'training/walltime': 8370.18672132492, 'training/entropy_loss': Array(0.00726576, dtype=float32), 'training/policy_loss': Array(0.0025536, dtype=float32), 'training/total_loss': Array(0.06090143, dtype=float32), 'training/v_loss': Array(0.05108207, dtype=float32), 'eval/episode_distance_from_origin': Array(5001.797, dtype=float32), 'eval/episode_distance_reward': Array(15.386843, dtype=float32), 'eval/episode_forward_reward': Array(2564.4626, dtype=float32), 'eval/episode_reward': Array(2629.7756, dtype=float32), 'eval/episode_reward_alive': Array(395.64844, dtype=float32), 'eval/episode_reward_linvel': Array(2564.4626, dtype=float32), 'eval/episode_reward_quadctrl': Array(-345.7226, dtype=float32), 'eval/episode_x_position': Array(4960.3203, dtype=float32), 'eval/episode_x_velocity': Array(512.8925, dtype=float32), 'eval/episode_y_position': Array(48.568916, dtype=float32), 'eval/episode_y_velocity': Array(-24.429314, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.56207, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4089346, dtype=float32), 'eval/episode_forward_reward_std': Array(901.4822, dtype=float32), 'eval/episode_reward_std': Array(854.492, dtype=float32), 'eval/episode_reward_alive_std': Array(44.236195, dtype=float32), 'eval/episode_reward_linvel_std': Array(901.4822, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.92903, dtype=float32), 'eval/episode_x_position_std': Array(422.58923, dtype=float32), 'eval/episode_x_velocity_std': Array(180.29652, dtype=float32), 'eval/episode_y_position_std': Array(309.01904, dtype=float32), 'eval/episode_y_velocity_std': Array(91.49235, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51191878318787, 'eval/sps': 937.6470651129977, 'num_steps': 24576000}
{'eval/walltime': 41255.1893286705, 'training/sps': 2965.0860843705273, 'training/walltime': 8397.814924240112, 'training/entropy_loss': Array(0.01039318, dtype=float32), 'training/policy_loss': Array(0.0104677, dtype=float32), 'training/total_loss': Array(0.10162469, dtype=float32), 'training/v_loss': Array(0.08076382, dtype=float32), 'eval/episode_distance_from_origin': Array(5024.3545, dtype=float32), 'eval/episode_distance_reward': Array(15.2828245, dtype=float32), 'eval/episode_forward_reward': Array(2547.126, dtype=float32), 'eval/episode_reward': Array(2603.2314, dtype=float32), 'eval/episode_reward_alive': Array(389.29297, dtype=float32), 'eval/episode_reward_linvel': Array(2547.126, dtype=float32), 'eval/episode_reward_quadctrl': Array(-348.47028, dtype=float32), 'eval/episode_x_position': Array(4984.68, dtype=float32), 'eval/episode_x_velocity': Array(509.42517, dtype=float32), 'eval/episode_y_position': Array(44.052773, dtype=float32), 'eval/episode_y_velocity': Array(-37.271793, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.32718, dtype=float32), 'eval/episode_distance_reward_std': Array(5.018071, dtype=float32), 'eval/episode_forward_reward_std': Array(836.3385, dtype=float32), 'eval/episode_reward_std': Array(778.0935, dtype=float32), 'eval/episode_reward_alive_std': Array(49.325512, dtype=float32), 'eval/episode_reward_linvel_std': Array(836.3385, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.636257, dtype=float32), 'eval/episode_x_position_std': Array(413.8995, dtype=float32), 'eval/episode_x_velocity_std': Array(167.26762, dtype=float32), 'eval/episode_y_position_std': Array(265.7082, dtype=float32), 'eval/episode_y_velocity_std': Array(84.32639, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5876624584198, 'eval/sps': 937.127099886975, 'num_steps': 24657920}
{'eval/walltime': 41391.71547842026, 'training/sps': 2957.556457888762, 'training/walltime': 8425.513465642929, 'training/entropy_loss': Array(0.01336278, dtype=float32), 'training/policy_loss': Array(0.14555962, dtype=float32), 'training/total_loss': Array(0.26227552, dtype=float32), 'training/v_loss': Array(0.10335314, dtype=float32), 'eval/episode_distance_from_origin': Array(5050.169, dtype=float32), 'eval/episode_distance_reward': Array(15.5624485, dtype=float32), 'eval/episode_forward_reward': Array(2593.7295, dtype=float32), 'eval/episode_reward': Array(2587.6995, dtype=float32), 'eval/episode_reward_alive': Array(379.6875, dtype=float32), 'eval/episode_reward_linvel': Array(2593.7295, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.27997, dtype=float32), 'eval/episode_x_position': Array(5005.995, dtype=float32), 'eval/episode_x_velocity': Array(518.746, dtype=float32), 'eval/episode_y_position': Array(138.03357, dtype=float32), 'eval/episode_y_velocity': Array(-10.200596, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.81482, dtype=float32), 'eval/episode_distance_reward_std': Array(4.816145, dtype=float32), 'eval/episode_forward_reward_std': Array(802.68506, dtype=float32), 'eval/episode_reward_std': Array(786.48773, dtype=float32), 'eval/episode_reward_alive_std': Array(65.016045, dtype=float32), 'eval/episode_reward_linvel_std': Array(802.68506, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.247448, dtype=float32), 'eval/episode_x_position_std': Array(428.52625, dtype=float32), 'eval/episode_x_velocity_std': Array(160.53702, dtype=float32), 'eval/episode_y_position_std': Array(305.44345, dtype=float32), 'eval/episode_y_velocity_std': Array(89.570984, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52614974975586, 'eval/sps': 937.5493283493032, 'num_steps': 24739840}
{'eval/walltime': 41528.25094008446, 'training/sps': 2960.667888333476, 'training/walltime': 8453.182898044586, 'training/entropy_loss': Array(0.01226815, dtype=float32), 'training/policy_loss': Array(0.01027798, dtype=float32), 'training/total_loss': Array(0.12524608, dtype=float32), 'training/v_loss': Array(0.10269994, dtype=float32), 'eval/episode_distance_from_origin': Array(4895.427, dtype=float32), 'eval/episode_distance_reward': Array(13.651204, dtype=float32), 'eval/episode_forward_reward': Array(2275.1914, dtype=float32), 'eval/episode_reward': Array(2301.975, dtype=float32), 'eval/episode_reward_alive': Array(392.09375, dtype=float32), 'eval/episode_reward_linvel': Array(2275.1914, dtype=float32), 'eval/episode_reward_quadctrl': Array(-378.96106, dtype=float32), 'eval/episode_x_position': Array(4852.6294, dtype=float32), 'eval/episode_x_velocity': Array(455.03824, dtype=float32), 'eval/episode_y_position': Array(160.24887, dtype=float32), 'eval/episode_y_velocity': Array(-6.026914, dtype=float32), 'eval/episode_distance_from_origin_std': Array(419.63477, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7595696, dtype=float32), 'eval/episode_forward_reward_std': Array(793.25586, dtype=float32), 'eval/episode_reward_std': Array(767.23566, dtype=float32), 'eval/episode_reward_alive_std': Array(56.065243, dtype=float32), 'eval/episode_reward_linvel_std': Array(793.25586, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.17969, dtype=float32), 'eval/episode_x_position_std': Array(421.99704, dtype=float32), 'eval/episode_x_velocity_std': Array(158.65112, dtype=float32), 'eval/episode_y_position_std': Array(259.96594, dtype=float32), 'eval/episode_y_velocity_std': Array(84.48521, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53546166419983, 'eval/sps': 937.48538613952, 'num_steps': 24821760}
{'eval/walltime': 41664.781693935394, 'training/sps': 2956.9789648071383, 'training/walltime': 8480.886848926544, 'training/entropy_loss': Array(0.01289029, dtype=float32), 'training/policy_loss': Array(0.0078169, dtype=float32), 'training/total_loss': Array(0.14056781, dtype=float32), 'training/v_loss': Array(0.11986063, dtype=float32), 'eval/episode_distance_from_origin': Array(5056.3174, dtype=float32), 'eval/episode_distance_reward': Array(15.704612, dtype=float32), 'eval/episode_forward_reward': Array(2617.4236, dtype=float32), 'eval/episode_reward': Array(2609.543, dtype=float32), 'eval/episode_reward_alive': Array(378.98438, dtype=float32), 'eval/episode_reward_linvel': Array(2617.4236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-402.5698, dtype=float32), 'eval/episode_x_position': Array(5008.491, dtype=float32), 'eval/episode_x_velocity': Array(523.48474, dtype=float32), 'eval/episode_y_position': Array(149.3097, dtype=float32), 'eval/episode_y_velocity': Array(-12.662082, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.85156, dtype=float32), 'eval/episode_distance_reward_std': Array(5.445993, dtype=float32), 'eval/episode_forward_reward_std': Array(907.65906, dtype=float32), 'eval/episode_reward_std': Array(892.47577, dtype=float32), 'eval/episode_reward_alive_std': Array(67.73007, dtype=float32), 'eval/episode_reward_linvel_std': Array(907.65906, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(68.055565, dtype=float32), 'eval/episode_x_position_std': Array(450.2598, dtype=float32), 'eval/episode_x_velocity_std': Array(181.53183, dtype=float32), 'eval/episode_y_position_std': Array(338.70972, dtype=float32), 'eval/episode_y_velocity_std': Array(103.826904, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5307538509369, 'eval/sps': 937.5177122346319, 'num_steps': 24903680}
{'eval/walltime': 41801.339079618454, 'training/sps': 2947.647129396629, 'training/walltime': 8508.678506612778, 'training/entropy_loss': Array(0.01219149, dtype=float32), 'training/policy_loss': Array(0.00563553, dtype=float32), 'training/total_loss': Array(0.11732665, dtype=float32), 'training/v_loss': Array(0.09949963, dtype=float32), 'eval/episode_distance_from_origin': Array(5020.3994, dtype=float32), 'eval/episode_distance_reward': Array(15.163368, dtype=float32), 'eval/episode_forward_reward': Array(2527.2168, dtype=float32), 'eval/episode_reward': Array(2532.9482, dtype=float32), 'eval/episode_reward_alive': Array(387.71875, dtype=float32), 'eval/episode_reward_linvel': Array(2527.2168, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.15106, dtype=float32), 'eval/episode_x_position': Array(4978.6987, dtype=float32), 'eval/episode_x_velocity': Array(505.4433, dtype=float32), 'eval/episode_y_position': Array(82.59521, dtype=float32), 'eval/episode_y_velocity': Array(-28.355572, dtype=float32), 'eval/episode_distance_from_origin_std': Array(442.4929, dtype=float32), 'eval/episode_distance_reward_std': Array(5.149711, dtype=float32), 'eval/episode_forward_reward_std': Array(858.27924, dtype=float32), 'eval/episode_reward_std': Array(833.0508, dtype=float32), 'eval/episode_reward_alive_std': Array(54.895737, dtype=float32), 'eval/episode_reward_linvel_std': Array(858.27924, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.666145, dtype=float32), 'eval/episode_x_position_std': Array(443.04648, dtype=float32), 'eval/episode_x_velocity_std': Array(171.65582, dtype=float32), 'eval/episode_y_position_std': Array(269.9588, dtype=float32), 'eval/episode_y_velocity_std': Array(84.95056, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5573856830597, 'eval/sps': 937.3348747103229, 'num_steps': 24985600}
{'eval/walltime': 41937.756289720535, 'training/sps': 2946.8902496299206, 'training/walltime': 8536.477302312851, 'training/entropy_loss': Array(0.01070054, dtype=float32), 'training/policy_loss': Array(0.02818575, dtype=float32), 'training/total_loss': Array(0.11415994, dtype=float32), 'training/v_loss': Array(0.07527365, dtype=float32), 'eval/episode_distance_from_origin': Array(5075.409, dtype=float32), 'eval/episode_distance_reward': Array(15.279272, dtype=float32), 'eval/episode_forward_reward': Array(2546.5347, dtype=float32), 'eval/episode_reward': Array(2554.062, dtype=float32), 'eval/episode_reward_alive': Array(382.97266, dtype=float32), 'eval/episode_reward_linvel': Array(2546.5347, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.72418, dtype=float32), 'eval/episode_x_position': Array(5034.871, dtype=float32), 'eval/episode_x_velocity': Array(509.30685, dtype=float32), 'eval/episode_y_position': Array(93.707504, dtype=float32), 'eval/episode_y_velocity': Array(-23.139996, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.33673, dtype=float32), 'eval/episode_distance_reward_std': Array(4.776967, dtype=float32), 'eval/episode_forward_reward_std': Array(796.15607, dtype=float32), 'eval/episode_reward_std': Array(770.23596, dtype=float32), 'eval/episode_reward_alive_std': Array(61.642437, dtype=float32), 'eval/episode_reward_linvel_std': Array(796.15607, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.48661, dtype=float32), 'eval/episode_x_position_std': Array(439.26483, dtype=float32), 'eval/episode_x_velocity_std': Array(159.23114, dtype=float32), 'eval/episode_y_position_std': Array(265.73477, dtype=float32), 'eval/episode_y_velocity_std': Array(79.15571, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4172101020813, 'eval/sps': 938.2980336881052, 'num_steps': 25067520}
{'eval/walltime': 42074.24625372887, 'training/sps': 2949.3324237371808, 'training/walltime': 8564.253079414368, 'training/entropy_loss': Array(0.00800246, dtype=float32), 'training/policy_loss': Array(0.00329303, dtype=float32), 'training/total_loss': Array(0.07564112, dtype=float32), 'training/v_loss': Array(0.06434563, dtype=float32), 'eval/episode_distance_from_origin': Array(5000.949, dtype=float32), 'eval/episode_distance_reward': Array(14.602676, dtype=float32), 'eval/episode_forward_reward': Array(2433.7686, dtype=float32), 'eval/episode_reward': Array(2434.3816, dtype=float32), 'eval/episode_reward_alive': Array(380.33203, dtype=float32), 'eval/episode_reward_linvel': Array(2433.7686, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.32156, dtype=float32), 'eval/episode_x_position': Array(4956.3857, dtype=float32), 'eval/episode_x_velocity': Array(486.75366, dtype=float32), 'eval/episode_y_position': Array(109.231064, dtype=float32), 'eval/episode_y_velocity': Array(-28.845127, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.2316, dtype=float32), 'eval/episode_distance_reward_std': Array(5.138355, dtype=float32), 'eval/episode_forward_reward_std': Array(856.3863, dtype=float32), 'eval/episode_reward_std': Array(837.1631, dtype=float32), 'eval/episode_reward_alive_std': Array(63.799286, dtype=float32), 'eval/episode_reward_linvel_std': Array(856.3863, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(61.564533, dtype=float32), 'eval/episode_x_position_std': Array(452.17807, dtype=float32), 'eval/episode_x_velocity_std': Array(171.27722, dtype=float32), 'eval/episode_y_position_std': Array(305.1034, dtype=float32), 'eval/episode_y_velocity_std': Array(89.912056, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4899640083313, 'eval/sps': 937.7978881449989, 'num_steps': 25149440}
{'eval/walltime': 42210.65897607803, 'training/sps': 2954.7488690711484, 'training/walltime': 8591.977939844131, 'training/entropy_loss': Array(0.01782466, dtype=float32), 'training/policy_loss': Array(0.02431571, dtype=float32), 'training/total_loss': Array(0.16856477, dtype=float32), 'training/v_loss': Array(0.1264244, dtype=float32), 'eval/episode_distance_from_origin': Array(5048.289, dtype=float32), 'eval/episode_distance_reward': Array(15.208395, dtype=float32), 'eval/episode_forward_reward': Array(2534.7212, dtype=float32), 'eval/episode_reward': Array(2525.1074, dtype=float32), 'eval/episode_reward_alive': Array(366.98047, dtype=float32), 'eval/episode_reward_linvel': Array(2534.7212, dtype=float32), 'eval/episode_reward_quadctrl': Array(-391.8031, dtype=float32), 'eval/episode_x_position': Array(5005.337, dtype=float32), 'eval/episode_x_velocity': Array(506.9443, dtype=float32), 'eval/episode_y_position': Array(57.44342, dtype=float32), 'eval/episode_y_velocity': Array(-39.163372, dtype=float32), 'eval/episode_distance_from_origin_std': Array(467.4488, dtype=float32), 'eval/episode_distance_reward_std': Array(5.334178, dtype=float32), 'eval/episode_forward_reward_std': Array(889.0234, dtype=float32), 'eval/episode_reward_std': Array(873.48035, dtype=float32), 'eval/episode_reward_alive_std': Array(63.8921, dtype=float32), 'eval/episode_reward_linvel_std': Array(889.0234, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.251274, dtype=float32), 'eval/episode_x_position_std': Array(465.42557, dtype=float32), 'eval/episode_x_velocity_std': Array(177.8047, dtype=float32), 'eval/episode_y_position_std': Array(288.98734, dtype=float32), 'eval/episode_y_velocity_std': Array(91.83548, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41272234916687, 'eval/sps': 938.328902141302, 'num_steps': 25231360}
{'eval/walltime': 42347.15939831734, 'training/sps': 2950.0583656663825, 'training/walltime': 8619.746881961823, 'training/entropy_loss': Array(0.01587669, dtype=float32), 'training/policy_loss': Array(0.00639427, dtype=float32), 'training/total_loss': Array(0.1553899, dtype=float32), 'training/v_loss': Array(0.13311894, dtype=float32), 'eval/episode_distance_from_origin': Array(4987.1104, dtype=float32), 'eval/episode_distance_reward': Array(14.311195, dtype=float32), 'eval/episode_forward_reward': Array(2385.1892, dtype=float32), 'eval/episode_reward': Array(2375.811, dtype=float32), 'eval/episode_reward_alive': Array(362.91016, dtype=float32), 'eval/episode_reward_linvel': Array(2385.1892, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.59973, dtype=float32), 'eval/episode_x_position': Array(4942.5303, dtype=float32), 'eval/episode_x_velocity': Array(477.03787, dtype=float32), 'eval/episode_y_position': Array(92.59755, dtype=float32), 'eval/episode_y_velocity': Array(-38.632736, dtype=float32), 'eval/episode_distance_from_origin_std': Array(431.86768, dtype=float32), 'eval/episode_distance_reward_std': Array(4.610825, dtype=float32), 'eval/episode_forward_reward_std': Array(768.4648, dtype=float32), 'eval/episode_reward_std': Array(737.6131, dtype=float32), 'eval/episode_reward_alive_std': Array(68.58023, dtype=float32), 'eval/episode_reward_linvel_std': Array(768.4648, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.648586, dtype=float32), 'eval/episode_x_position_std': Array(430.75192, dtype=float32), 'eval/episode_x_velocity_std': Array(153.69304, dtype=float32), 'eval/episode_y_position_std': Array(302.99127, dtype=float32), 'eval/episode_y_velocity_std': Array(95.1923, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5004222393036, 'eval/sps': 937.726037034514, 'num_steps': 25313280}
{'eval/walltime': 42483.56704378128, 'training/sps': 2950.857801227829, 'training/walltime': 8647.508301019669, 'training/entropy_loss': Array(0.01429923, dtype=float32), 'training/policy_loss': Array(0.00444474, dtype=float32), 'training/total_loss': Array(0.12268734, dtype=float32), 'training/v_loss': Array(0.10394338, dtype=float32), 'eval/episode_distance_from_origin': Array(5041.3257, dtype=float32), 'eval/episode_distance_reward': Array(14.922979, dtype=float32), 'eval/episode_forward_reward': Array(2487.1523, dtype=float32), 'eval/episode_reward': Array(2474.0571, dtype=float32), 'eval/episode_reward_alive': Array(371.42188, dtype=float32), 'eval/episode_reward_linvel': Array(2487.1523, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.44022, dtype=float32), 'eval/episode_x_position': Array(4998.073, dtype=float32), 'eval/episode_x_velocity': Array(497.43042, dtype=float32), 'eval/episode_y_position': Array(64.912384, dtype=float32), 'eval/episode_y_velocity': Array(-42.19316, dtype=float32), 'eval/episode_distance_from_origin_std': Array(433.4328, dtype=float32), 'eval/episode_distance_reward_std': Array(5.308617, dtype=float32), 'eval/episode_forward_reward_std': Array(884.7633, dtype=float32), 'eval/episode_reward_std': Array(871.79614, dtype=float32), 'eval/episode_reward_alive_std': Array(61.308468, dtype=float32), 'eval/episode_reward_linvel_std': Array(884.7633, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.61798, dtype=float32), 'eval/episode_x_position_std': Array(433.9649, dtype=float32), 'eval/episode_x_velocity_std': Array(176.95268, dtype=float32), 'eval/episode_y_position_std': Array(295.59293, dtype=float32), 'eval/episode_y_velocity_std': Array(83.90496, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40764546394348, 'eval/sps': 938.3638253167718, 'num_steps': 25395200}
{'eval/walltime': 42620.10516285896, 'training/sps': 2945.8807633678825, 'training/walltime': 8675.31662273407, 'training/entropy_loss': Array(0.01218154, dtype=float32), 'training/policy_loss': Array(0.00496397, dtype=float32), 'training/total_loss': Array(0.08820935, dtype=float32), 'training/v_loss': Array(0.07106384, dtype=float32), 'eval/episode_distance_from_origin': Array(4926.365, dtype=float32), 'eval/episode_distance_reward': Array(13.561112, dtype=float32), 'eval/episode_forward_reward': Array(2260.1758, dtype=float32), 'eval/episode_reward': Array(2265.4263, dtype=float32), 'eval/episode_reward_alive': Array(370.8711, dtype=float32), 'eval/episode_reward_linvel': Array(2260.1758, dtype=float32), 'eval/episode_reward_quadctrl': Array(-379.18176, dtype=float32), 'eval/episode_x_position': Array(4884.935, dtype=float32), 'eval/episode_x_velocity': Array(452.03513, dtype=float32), 'eval/episode_y_position': Array(79.99748, dtype=float32), 'eval/episode_y_velocity': Array(-30.876678, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.5188, dtype=float32), 'eval/episode_distance_reward_std': Array(4.422924, dtype=float32), 'eval/episode_forward_reward_std': Array(737.148, dtype=float32), 'eval/episode_reward_std': Array(711.4647, dtype=float32), 'eval/episode_reward_alive_std': Array(64.714165, dtype=float32), 'eval/episode_reward_linvel_std': Array(737.148, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.60504, dtype=float32), 'eval/episode_x_position_std': Array(451.2865, dtype=float32), 'eval/episode_x_velocity_std': Array(147.42957, dtype=float32), 'eval/episode_y_position_std': Array(264.24997, dtype=float32), 'eval/episode_y_velocity_std': Array(79.63143, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5381190776825, 'eval/sps': 937.4671400532127, 'num_steps': 25477120}
{'eval/walltime': 42756.641297101974, 'training/sps': 2948.946985150789, 'training/walltime': 8703.09603023529, 'training/entropy_loss': Array(0.01033815, dtype=float32), 'training/policy_loss': Array(0.00581888, dtype=float32), 'training/total_loss': Array(0.07932849, dtype=float32), 'training/v_loss': Array(0.06317146, dtype=float32), 'eval/episode_distance_from_origin': Array(4947.42, dtype=float32), 'eval/episode_distance_reward': Array(13.6889, dtype=float32), 'eval/episode_forward_reward': Array(2281.474, dtype=float32), 'eval/episode_reward': Array(2287.501, dtype=float32), 'eval/episode_reward_alive': Array(369.86328, dtype=float32), 'eval/episode_reward_linvel': Array(2281.474, dtype=float32), 'eval/episode_reward_quadctrl': Array(-377.52512, dtype=float32), 'eval/episode_x_position': Array(4904.712, dtype=float32), 'eval/episode_x_velocity': Array(456.29477, dtype=float32), 'eval/episode_y_position': Array(17.842186, dtype=float32), 'eval/episode_y_velocity': Array(-48.2582, dtype=float32), 'eval/episode_distance_from_origin_std': Array(426.64496, dtype=float32), 'eval/episode_distance_reward_std': Array(4.487734, dtype=float32), 'eval/episode_forward_reward_std': Array(747.95026, dtype=float32), 'eval/episode_reward_std': Array(725.8162, dtype=float32), 'eval/episode_reward_alive_std': Array(69.36094, dtype=float32), 'eval/episode_reward_linvel_std': Array(747.95026, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.420193, dtype=float32), 'eval/episode_x_position_std': Array(427.20593, dtype=float32), 'eval/episode_x_velocity_std': Array(149.59004, dtype=float32), 'eval/episode_y_position_std': Array(278.41925, dtype=float32), 'eval/episode_y_velocity_std': Array(90.17085, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53613424301147, 'eval/sps': 937.48076807405, 'num_steps': 25559040}
{'eval/walltime': 42893.16748762131, 'training/sps': 2959.808285658751, 'training/walltime': 8730.773498535156, 'training/entropy_loss': Array(0.00828897, dtype=float32), 'training/policy_loss': Array(0.00039161, dtype=float32), 'training/total_loss': Array(0.04715467, dtype=float32), 'training/v_loss': Array(0.03847409, dtype=float32), 'eval/episode_distance_from_origin': Array(4964.859, dtype=float32), 'eval/episode_distance_reward': Array(14.094619, dtype=float32), 'eval/episode_forward_reward': Array(2349.093, dtype=float32), 'eval/episode_reward': Array(2341.6074, dtype=float32), 'eval/episode_reward_alive': Array(370.4297, dtype=float32), 'eval/episode_reward_linvel': Array(2349.093, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.00995, dtype=float32), 'eval/episode_x_position': Array(4921.3506, dtype=float32), 'eval/episode_x_velocity': Array(469.81854, dtype=float32), 'eval/episode_y_position': Array(113.51395, dtype=float32), 'eval/episode_y_velocity': Array(-27.640518, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.48712, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4372873, dtype=float32), 'eval/episode_forward_reward_std': Array(906.208, dtype=float32), 'eval/episode_reward_std': Array(876.3795, dtype=float32), 'eval/episode_reward_alive_std': Array(62.563957, dtype=float32), 'eval/episode_reward_linvel_std': Array(906.208, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(66.24744, dtype=float32), 'eval/episode_x_position_std': Array(482.62405, dtype=float32), 'eval/episode_x_velocity_std': Array(181.24158, dtype=float32), 'eval/episode_y_position_std': Array(291.86, dtype=float32), 'eval/episode_y_velocity_std': Array(89.366295, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52619051933289, 'eval/sps': 937.5490483774574, 'num_steps': 25640960}
{'eval/walltime': 43029.83665513992, 'training/sps': 2955.19690151266, 'training/walltime': 8758.49415564537, 'training/entropy_loss': Array(0.0179049, dtype=float32), 'training/policy_loss': Array(0.01249038, dtype=float32), 'training/total_loss': Array(0.14790198, dtype=float32), 'training/v_loss': Array(0.1175067, dtype=float32), 'eval/episode_distance_from_origin': Array(4942.3047, dtype=float32), 'eval/episode_distance_reward': Array(13.580442, dtype=float32), 'eval/episode_forward_reward': Array(2263.3967, dtype=float32), 'eval/episode_reward': Array(2257.624, dtype=float32), 'eval/episode_reward_alive': Array(368.55078, dtype=float32), 'eval/episode_reward_linvel': Array(2263.3967, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.90414, dtype=float32), 'eval/episode_x_position': Array(4899.314, dtype=float32), 'eval/episode_x_velocity': Array(452.67944, dtype=float32), 'eval/episode_y_position': Array(140.36841, dtype=float32), 'eval/episode_y_velocity': Array(-18.275623, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.41095, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4624505, dtype=float32), 'eval/episode_forward_reward_std': Array(743.73627, dtype=float32), 'eval/episode_reward_std': Array(724.5378, dtype=float32), 'eval/episode_reward_alive_std': Array(70.31138, dtype=float32), 'eval/episode_reward_linvel_std': Array(743.73627, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.001564, dtype=float32), 'eval/episode_x_position_std': Array(395.8056, dtype=float32), 'eval/episode_x_velocity_std': Array(148.74722, dtype=float32), 'eval/episode_y_position_std': Array(264.6678, dtype=float32), 'eval/episode_y_velocity_std': Array(80.93306, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66916751861572, 'eval/sps': 936.5682276696762, 'num_steps': 25722880}
{'eval/walltime': 43166.40692734718, 'training/sps': 2955.7308550517046, 'training/walltime': 8786.20980501175, 'training/entropy_loss': Array(0.01496163, dtype=float32), 'training/policy_loss': Array(0.01060167, dtype=float32), 'training/total_loss': Array(0.15409774, dtype=float32), 'training/v_loss': Array(0.12853444, dtype=float32), 'eval/episode_distance_from_origin': Array(5027.9443, dtype=float32), 'eval/episode_distance_reward': Array(14.216429, dtype=float32), 'eval/episode_forward_reward': Array(2369.3938, dtype=float32), 'eval/episode_reward': Array(2348.8086, dtype=float32), 'eval/episode_reward_alive': Array(361.89844, dtype=float32), 'eval/episode_reward_linvel': Array(2369.3938, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.70026, dtype=float32), 'eval/episode_x_position': Array(4986.2925, dtype=float32), 'eval/episode_x_velocity': Array(473.87878, dtype=float32), 'eval/episode_y_position': Array(80.2659, dtype=float32), 'eval/episode_y_velocity': Array(-40.375706, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.5906, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3188157, dtype=float32), 'eval/episode_forward_reward_std': Array(719.7972, dtype=float32), 'eval/episode_reward_std': Array(717.9468, dtype=float32), 'eval/episode_reward_alive_std': Array(73.08453, dtype=float32), 'eval/episode_reward_linvel_std': Array(719.7972, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.90727, dtype=float32), 'eval/episode_x_position_std': Array(439.04407, dtype=float32), 'eval/episode_x_velocity_std': Array(143.95943, dtype=float32), 'eval/episode_y_position_std': Array(250.2635, dtype=float32), 'eval/episode_y_velocity_std': Array(84.62834, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57027220726013, 'eval/sps': 937.2464294846405, 'num_steps': 25804800}
{'eval/walltime': 43302.9345638752, 'training/sps': 2951.5821363528626, 'training/walltime': 8813.964411258698, 'training/entropy_loss': Array(0.01414711, dtype=float32), 'training/policy_loss': Array(0.00503667, dtype=float32), 'training/total_loss': Array(0.13152786, dtype=float32), 'training/v_loss': Array(0.11234407, dtype=float32), 'eval/episode_distance_from_origin': Array(5004.9697, dtype=float32), 'eval/episode_distance_reward': Array(14.39306, dtype=float32), 'eval/episode_forward_reward': Array(2398.832, dtype=float32), 'eval/episode_reward': Array(2394.6353, dtype=float32), 'eval/episode_reward_alive': Array(367.73438, dtype=float32), 'eval/episode_reward_linvel': Array(2398.832, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.3239, dtype=float32), 'eval/episode_x_position': Array(4960.2285, dtype=float32), 'eval/episode_x_velocity': Array(479.76645, dtype=float32), 'eval/episode_y_position': Array(119.918724, dtype=float32), 'eval/episode_y_velocity': Array(-29.090046, dtype=float32), 'eval/episode_distance_from_origin_std': Array(391.87927, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2299705, dtype=float32), 'eval/episode_forward_reward_std': Array(704.9902, dtype=float32), 'eval/episode_reward_std': Array(695.23206, dtype=float32), 'eval/episode_reward_alive_std': Array(69.78678, dtype=float32), 'eval/episode_reward_linvel_std': Array(704.9902, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.889355, dtype=float32), 'eval/episode_x_position_std': Array(391.593, dtype=float32), 'eval/episode_x_velocity_std': Array(140.99803, dtype=float32), 'eval/episode_y_position_std': Array(288.55594, dtype=float32), 'eval/episode_y_velocity_std': Array(87.53227, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52763652801514, 'eval/sps': 937.5391184900114, 'num_steps': 25886720}
{'eval/walltime': 43439.46532845497, 'training/sps': 2954.844080479489, 'training/walltime': 8841.688378334045, 'training/entropy_loss': Array(0.0126566, dtype=float32), 'training/policy_loss': Array(0.05438894, dtype=float32), 'training/total_loss': Array(0.15047961, dtype=float32), 'training/v_loss': Array(0.08343408, dtype=float32), 'eval/episode_distance_from_origin': Array(4959.424, dtype=float32), 'eval/episode_distance_reward': Array(14.049535, dtype=float32), 'eval/episode_forward_reward': Array(2341.5774, dtype=float32), 'eval/episode_reward': Array(2293.1648, dtype=float32), 'eval/episode_reward_alive': Array(365.70312, dtype=float32), 'eval/episode_reward_linvel': Array(2341.5774, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.16544, dtype=float32), 'eval/episode_x_position': Array(4914.5356, dtype=float32), 'eval/episode_x_velocity': Array(468.3155, dtype=float32), 'eval/episode_y_position': Array(145.04063, dtype=float32), 'eval/episode_y_velocity': Array(-30.77399, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.95694, dtype=float32), 'eval/episode_distance_reward_std': Array(4.509396, dtype=float32), 'eval/episode_forward_reward_std': Array(751.5598, dtype=float32), 'eval/episode_reward_std': Array(734.20874, dtype=float32), 'eval/episode_reward_alive_std': Array(61.886562, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.5598, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(64.520134, dtype=float32), 'eval/episode_x_position_std': Array(427.7245, dtype=float32), 'eval/episode_x_velocity_std': Array(150.31197, dtype=float32), 'eval/episode_y_position_std': Array(277.80884, dtype=float32), 'eval/episode_y_velocity_std': Array(83.52213, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53076457977295, 'eval/sps': 937.5176385627831, 'num_steps': 25968640}
{'eval/walltime': 43576.09034347534, 'training/sps': 2952.3431788598796, 'training/walltime': 8869.435830116272, 'training/entropy_loss': Array(0.01192647, dtype=float32), 'training/policy_loss': Array(0.02778021, dtype=float32), 'training/total_loss': Array(0.09311829, dtype=float32), 'training/v_loss': Array(0.05341161, dtype=float32), 'eval/episode_distance_from_origin': Array(4998.7627, dtype=float32), 'eval/episode_distance_reward': Array(14.395024, dtype=float32), 'eval/episode_forward_reward': Array(2399.1592, dtype=float32), 'eval/episode_reward': Array(2363.9722, dtype=float32), 'eval/episode_reward_alive': Array(375.0625, dtype=float32), 'eval/episode_reward_linvel': Array(2399.1592, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.64484, dtype=float32), 'eval/episode_x_position': Array(4955.1494, dtype=float32), 'eval/episode_x_velocity': Array(479.83188, dtype=float32), 'eval/episode_y_position': Array(98.08695, dtype=float32), 'eval/episode_y_velocity': Array(-43.471455, dtype=float32), 'eval/episode_distance_from_origin_std': Array(427.4176, dtype=float32), 'eval/episode_distance_reward_std': Array(4.367521, dtype=float32), 'eval/episode_forward_reward_std': Array(727.91425, dtype=float32), 'eval/episode_reward_std': Array(707.4207, dtype=float32), 'eval/episode_reward_alive_std': Array(59.337982, dtype=float32), 'eval/episode_reward_linvel_std': Array(727.91425, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(69.06181, dtype=float32), 'eval/episode_x_position_std': Array(427.3375, dtype=float32), 'eval/episode_x_velocity_std': Array(145.58289, dtype=float32), 'eval/episode_y_position_std': Array(258.9523, dtype=float32), 'eval/episode_y_velocity_std': Array(84.23402, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62501502037048, 'eval/sps': 936.8708942569227, 'num_steps': 26050560}
{'eval/walltime': 43712.64222621918, 'training/sps': 2947.980983833513, 'training/walltime': 8897.224340438843, 'training/entropy_loss': Array(0.00924097, dtype=float32), 'training/policy_loss': Array(0.06938244, dtype=float32), 'training/total_loss': Array(0.11509238, dtype=float32), 'training/v_loss': Array(0.03646897, dtype=float32), 'eval/episode_distance_from_origin': Array(5002.5967, dtype=float32), 'eval/episode_distance_reward': Array(14.309561, dtype=float32), 'eval/episode_forward_reward': Array(2384.9155, dtype=float32), 'eval/episode_reward': Array(2349.0376, dtype=float32), 'eval/episode_reward_alive': Array(376.98438, dtype=float32), 'eval/episode_reward_linvel': Array(2384.9155, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.17194, dtype=float32), 'eval/episode_x_position': Array(4958.662, dtype=float32), 'eval/episode_x_velocity': Array(476.9831, dtype=float32), 'eval/episode_y_position': Array(105.936584, dtype=float32), 'eval/episode_y_velocity': Array(-38.728355, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.0059, dtype=float32), 'eval/episode_distance_reward_std': Array(4.825433, dtype=float32), 'eval/episode_forward_reward_std': Array(804.2327, dtype=float32), 'eval/episode_reward_std': Array(788.8739, dtype=float32), 'eval/episode_reward_alive_std': Array(57.962536, dtype=float32), 'eval/episode_reward_linvel_std': Array(804.2327, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(70.081894, dtype=float32), 'eval/episode_x_position_std': Array(465.47424, dtype=float32), 'eval/episode_x_velocity_std': Array(160.84648, dtype=float32), 'eval/episode_y_position_std': Array(270.73013, dtype=float32), 'eval/episode_y_velocity_std': Array(87.23002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55188274383545, 'eval/sps': 937.3726486080141, 'num_steps': 26132480}
{'eval/walltime': 43849.31464600563, 'training/sps': 2949.8691730786672, 'training/walltime': 8924.99506354332, 'training/entropy_loss': Array(0.01494356, dtype=float32), 'training/policy_loss': Array(0.00499462, dtype=float32), 'training/total_loss': Array(0.14904106, dtype=float32), 'training/v_loss': Array(0.12910289, dtype=float32), 'eval/episode_distance_from_origin': Array(4905.784, dtype=float32), 'eval/episode_distance_reward': Array(13.350678, dtype=float32), 'eval/episode_forward_reward': Array(2225.1033, dtype=float32), 'eval/episode_reward': Array(2207.4795, dtype=float32), 'eval/episode_reward_alive': Array(381.73047, dtype=float32), 'eval/episode_reward_linvel': Array(2225.1033, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.70483, dtype=float32), 'eval/episode_x_position': Array(4863.6196, dtype=float32), 'eval/episode_x_velocity': Array(445.02063, dtype=float32), 'eval/episode_y_position': Array(95.85867, dtype=float32), 'eval/episode_y_velocity': Array(-38.081493, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.0771, dtype=float32), 'eval/episode_distance_reward_std': Array(4.212385, dtype=float32), 'eval/episode_forward_reward_std': Array(702.059, dtype=float32), 'eval/episode_reward_std': Array(661.70776, dtype=float32), 'eval/episode_reward_alive_std': Array(55.26534, dtype=float32), 'eval/episode_reward_linvel_std': Array(702.059, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(73.09049, dtype=float32), 'eval/episode_x_position_std': Array(375.52438, dtype=float32), 'eval/episode_x_velocity_std': Array(140.41176, dtype=float32), 'eval/episode_y_position_std': Array(243.92603, dtype=float32), 'eval/episode_y_velocity_std': Array(79.03803, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67241978645325, 'eval/sps': 936.5459410171879, 'num_steps': 26214400}
{'eval/walltime': 43985.811957359314, 'training/sps': 2948.8587334605077, 'training/walltime': 8952.775302410126, 'training/entropy_loss': Array(0.02506144, dtype=float32), 'training/policy_loss': Array(0.07030677, dtype=float32), 'training/total_loss': Array(0.23786071, dtype=float32), 'training/v_loss': Array(0.1424925, dtype=float32), 'eval/episode_distance_from_origin': Array(5059.6655, dtype=float32), 'eval/episode_distance_reward': Array(14.971565, dtype=float32), 'eval/episode_forward_reward': Array(2495.248, dtype=float32), 'eval/episode_reward': Array(2433.6372, dtype=float32), 'eval/episode_reward_alive': Array(385.29297, dtype=float32), 'eval/episode_reward_linvel': Array(2495.248, dtype=float32), 'eval/episode_reward_quadctrl': Array(-461.87558, dtype=float32), 'eval/episode_x_position': Array(5015.152, dtype=float32), 'eval/episode_x_velocity': Array(499.04956, dtype=float32), 'eval/episode_y_position': Array(89.00925, dtype=float32), 'eval/episode_y_velocity': Array(-60.141758, dtype=float32), 'eval/episode_distance_from_origin_std': Array(362.8179, dtype=float32), 'eval/episode_distance_reward_std': Array(3.6689155, dtype=float32), 'eval/episode_forward_reward_std': Array(611.4819, dtype=float32), 'eval/episode_reward_std': Array(605.5532, dtype=float32), 'eval/episode_reward_alive_std': Array(46.720978, dtype=float32), 'eval/episode_reward_linvel_std': Array(611.4819, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.472736, dtype=float32), 'eval/episode_x_position_std': Array(363.6541, dtype=float32), 'eval/episode_x_velocity_std': Array(122.29632, dtype=float32), 'eval/episode_y_position_std': Array(249.55603, dtype=float32), 'eval/episode_y_velocity_std': Array(83.92962, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49731135368347, 'eval/sps': 937.7474085796038, 'num_steps': 26296320}
{'eval/walltime': 44122.34873819351, 'training/sps': 2945.5463491290943, 'training/walltime': 8980.586781263351, 'training/entropy_loss': Array(0.02173854, dtype=float32), 'training/policy_loss': Array(0.0625983, dtype=float32), 'training/total_loss': Array(0.20205311, dtype=float32), 'training/v_loss': Array(0.11771628, dtype=float32), 'eval/episode_distance_from_origin': Array(4859.9087, dtype=float32), 'eval/episode_distance_reward': Array(13.884158, dtype=float32), 'eval/episode_forward_reward': Array(2314.017, dtype=float32), 'eval/episode_reward': Array(2311.5796, dtype=float32), 'eval/episode_reward_alive': Array(397.92578, dtype=float32), 'eval/episode_reward_linvel': Array(2314.017, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.24725, dtype=float32), 'eval/episode_x_position': Array(4813.744, dtype=float32), 'eval/episode_x_velocity': Array(462.80328, dtype=float32), 'eval/episode_y_position': Array(150.0005, dtype=float32), 'eval/episode_y_velocity': Array(-27.190514, dtype=float32), 'eval/episode_distance_from_origin_std': Array(502.60132, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4238667, dtype=float32), 'eval/episode_forward_reward_std': Array(903.97186, dtype=float32), 'eval/episode_reward_std': Array(883.97797, dtype=float32), 'eval/episode_reward_alive_std': Array(40.057873, dtype=float32), 'eval/episode_reward_linvel_std': Array(903.97186, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.949192, dtype=float32), 'eval/episode_x_position_std': Array(499.7538, dtype=float32), 'eval/episode_x_velocity_std': Array(180.79428, dtype=float32), 'eval/episode_y_position_std': Array(285.02914, dtype=float32), 'eval/episode_y_velocity_std': Array(90.43887, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.536780834198, 'eval/sps': 937.4763284878926, 'num_steps': 26378240}
{'eval/walltime': 44258.82233476639, 'training/sps': 2952.060481134708, 'training/walltime': 9008.336890220642, 'training/entropy_loss': Array(0.01654679, dtype=float32), 'training/policy_loss': Array(0.15631068, dtype=float32), 'training/total_loss': Array(0.2468755, dtype=float32), 'training/v_loss': Array(0.07401805, dtype=float32), 'eval/episode_distance_from_origin': Array(4814.5464, dtype=float32), 'eval/episode_distance_reward': Array(13.723172, dtype=float32), 'eval/episode_forward_reward': Array(2287.1855, dtype=float32), 'eval/episode_reward': Array(2318.0872, dtype=float32), 'eval/episode_reward_alive': Array(393.92188, dtype=float32), 'eval/episode_reward_linvel': Array(2287.1855, dtype=float32), 'eval/episode_reward_quadctrl': Array(-376.7437, dtype=float32), 'eval/episode_x_position': Array(4771.6704, dtype=float32), 'eval/episode_x_velocity': Array(457.43716, dtype=float32), 'eval/episode_y_position': Array(103.90442, dtype=float32), 'eval/episode_y_velocity': Array(-28.367342, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.62363, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4184117, dtype=float32), 'eval/episode_forward_reward_std': Array(903.0621, dtype=float32), 'eval/episode_reward_std': Array(875.59283, dtype=float32), 'eval/episode_reward_alive_std': Array(41.554955, dtype=float32), 'eval/episode_reward_linvel_std': Array(903.0621, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.860928, dtype=float32), 'eval/episode_x_position_std': Array(451.99646, dtype=float32), 'eval/episode_x_velocity_std': Array(180.61247, dtype=float32), 'eval/episode_y_position_std': Array(266.4119, dtype=float32), 'eval/episode_y_velocity_std': Array(88.4429, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47359657287598, 'eval/sps': 937.9103593246981, 'num_steps': 26460160}
{'eval/walltime': 44395.378789663315, 'training/sps': 2960.230131214406, 'training/walltime': 9036.010414361954, 'training/entropy_loss': Array(0.01257665, dtype=float32), 'training/policy_loss': Array(0.00174773, dtype=float32), 'training/total_loss': Array(0.05852172, dtype=float32), 'training/v_loss': Array(0.04419734, dtype=float32), 'eval/episode_distance_from_origin': Array(4855.062, dtype=float32), 'eval/episode_distance_reward': Array(14.098322, dtype=float32), 'eval/episode_forward_reward': Array(2349.7104, dtype=float32), 'eval/episode_reward': Array(2367.7788, dtype=float32), 'eval/episode_reward_alive': Array(385.46875, dtype=float32), 'eval/episode_reward_linvel': Array(2349.7104, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.4984, dtype=float32), 'eval/episode_x_position': Array(4811.5576, dtype=float32), 'eval/episode_x_velocity': Array(469.94208, dtype=float32), 'eval/episode_y_position': Array(102.13924, dtype=float32), 'eval/episode_y_velocity': Array(-37.284267, dtype=float32), 'eval/episode_distance_from_origin_std': Array(462.51483, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3458834, dtype=float32), 'eval/episode_forward_reward_std': Array(890.975, dtype=float32), 'eval/episode_reward_std': Array(862.0598, dtype=float32), 'eval/episode_reward_alive_std': Array(47.840504, dtype=float32), 'eval/episode_reward_linvel_std': Array(890.975, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.162563, dtype=float32), 'eval/episode_x_position_std': Array(458.5451, dtype=float32), 'eval/episode_x_velocity_std': Array(178.19495, dtype=float32), 'eval/episode_y_position_std': Array(274.11752, dtype=float32), 'eval/episode_y_velocity_std': Array(85.98882, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55645489692688, 'eval/sps': 937.3412637038263, 'num_steps': 26542080}
{'eval/walltime': 44531.86746263504, 'training/sps': 2956.8829796216887, 'training/walltime': 9063.715264558792, 'training/entropy_loss': Array(0.01124528, dtype=float32), 'training/policy_loss': Array(-0.00150418, dtype=float32), 'training/total_loss': Array(0.04039885, dtype=float32), 'training/v_loss': Array(0.03065776, dtype=float32), 'eval/episode_distance_from_origin': Array(4885.4907, dtype=float32), 'eval/episode_distance_reward': Array(14.218258, dtype=float32), 'eval/episode_forward_reward': Array(2369.6992, dtype=float32), 'eval/episode_reward': Array(2393.1963, dtype=float32), 'eval/episode_reward_alive': Array(394.8789, dtype=float32), 'eval/episode_reward_linvel': Array(2369.6992, dtype=float32), 'eval/episode_reward_quadctrl': Array(-385.60046, dtype=float32), 'eval/episode_x_position': Array(4842.6484, dtype=float32), 'eval/episode_x_velocity': Array(473.93988, dtype=float32), 'eval/episode_y_position': Array(103.15575, dtype=float32), 'eval/episode_y_velocity': Array(-38.475258, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.84396, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1669717, dtype=float32), 'eval/episode_forward_reward_std': Array(861.1563, dtype=float32), 'eval/episode_reward_std': Array(833.83075, dtype=float32), 'eval/episode_reward_alive_std': Array(44.13601, dtype=float32), 'eval/episode_reward_linvel_std': Array(861.1563, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.29875, dtype=float32), 'eval/episode_x_position_std': Array(436.73694, dtype=float32), 'eval/episode_x_velocity_std': Array(172.23123, dtype=float32), 'eval/episode_y_position_std': Array(253.60088, dtype=float32), 'eval/episode_y_velocity_std': Array(82.33395, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48867297172546, 'eval/sps': 937.8067587082194, 'num_steps': 26624000}
{'eval/walltime': 44668.397404909134, 'training/sps': 2965.1059658498484, 'training/walltime': 9091.343282222748, 'training/entropy_loss': Array(0.01177759, dtype=float32), 'training/policy_loss': Array(0.0034659, dtype=float32), 'training/total_loss': Array(0.09117816, dtype=float32), 'training/v_loss': Array(0.07593466, dtype=float32), 'eval/episode_distance_from_origin': Array(4875.613, dtype=float32), 'eval/episode_distance_reward': Array(13.871488, dtype=float32), 'eval/episode_forward_reward': Array(2311.9058, dtype=float32), 'eval/episode_reward': Array(2327.9937, dtype=float32), 'eval/episode_reward_alive': Array(392.51953, dtype=float32), 'eval/episode_reward_linvel': Array(2311.9058, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.30298, dtype=float32), 'eval/episode_x_position': Array(4832.195, dtype=float32), 'eval/episode_x_velocity': Array(462.38116, dtype=float32), 'eval/episode_y_position': Array(152.29028, dtype=float32), 'eval/episode_y_velocity': Array(-23.484821, dtype=float32), 'eval/episode_distance_from_origin_std': Array(447.8447, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2789817, dtype=float32), 'eval/episode_forward_reward_std': Array(879.8241, dtype=float32), 'eval/episode_reward_std': Array(859.8303, dtype=float32), 'eval/episode_reward_alive_std': Array(53.582928, dtype=float32), 'eval/episode_reward_linvel_std': Array(879.8241, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.363586, dtype=float32), 'eval/episode_x_position_std': Array(446.98386, dtype=float32), 'eval/episode_x_velocity_std': Array(175.96481, dtype=float32), 'eval/episode_y_position_std': Array(249.08409, dtype=float32), 'eval/episode_y_velocity_std': Array(83.38224, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52994227409363, 'eval/sps': 937.5232851342663, 'num_steps': 26705920}
{'eval/walltime': 44804.912652254105, 'training/sps': 2959.4169180783406, 'training/walltime': 9119.02441072464, 'training/entropy_loss': Array(0.01480069, dtype=float32), 'training/policy_loss': Array(0.00280812, dtype=float32), 'training/total_loss': Array(0.15587667, dtype=float32), 'training/v_loss': Array(0.13826784, dtype=float32), 'eval/episode_distance_from_origin': Array(4900.968, dtype=float32), 'eval/episode_distance_reward': Array(13.87305, dtype=float32), 'eval/episode_forward_reward': Array(2312.165, dtype=float32), 'eval/episode_reward': Array(2331.6882, dtype=float32), 'eval/episode_reward_alive': Array(392.64453, dtype=float32), 'eval/episode_reward_linvel': Array(2312.165, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.9943, dtype=float32), 'eval/episode_x_position': Array(4858.5986, dtype=float32), 'eval/episode_x_velocity': Array(462.433, dtype=float32), 'eval/episode_y_position': Array(114.14832, dtype=float32), 'eval/episode_y_velocity': Array(-32.77652, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.4037, dtype=float32), 'eval/episode_distance_reward_std': Array(4.833314, dtype=float32), 'eval/episode_forward_reward_std': Array(805.54663, dtype=float32), 'eval/episode_reward_std': Array(780.0975, dtype=float32), 'eval/episode_reward_alive_std': Array(42.38307, dtype=float32), 'eval/episode_reward_linvel_std': Array(805.54663, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.802135, dtype=float32), 'eval/episode_x_position_std': Array(446.63416, dtype=float32), 'eval/episode_x_velocity_std': Array(161.1093, dtype=float32), 'eval/episode_y_position_std': Array(252.1374, dtype=float32), 'eval/episode_y_velocity_std': Array(79.87456, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5152473449707, 'eval/sps': 937.6242030792877, 'num_steps': 26787840}
{'eval/walltime': 44941.46459889412, 'training/sps': 2961.061909002531, 'training/walltime': 9146.69016122818, 'training/entropy_loss': Array(0.01311172, dtype=float32), 'training/policy_loss': Array(0.00143915, dtype=float32), 'training/total_loss': Array(0.11870259, dtype=float32), 'training/v_loss': Array(0.10415173, dtype=float32), 'eval/episode_distance_from_origin': Array(4950.1924, dtype=float32), 'eval/episode_distance_reward': Array(14.821299, dtype=float32), 'eval/episode_forward_reward': Array(2470.2065, dtype=float32), 'eval/episode_reward': Array(2498.3918, dtype=float32), 'eval/episode_reward_alive': Array(394.64062, dtype=float32), 'eval/episode_reward_linvel': Array(2470.2065, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.276, dtype=float32), 'eval/episode_x_position': Array(4907.7793, dtype=float32), 'eval/episode_x_velocity': Array(494.0412, dtype=float32), 'eval/episode_y_position': Array(76.04976, dtype=float32), 'eval/episode_y_velocity': Array(-44.610916, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.38794, dtype=float32), 'eval/episode_distance_reward_std': Array(5.93292, dtype=float32), 'eval/episode_forward_reward_std': Array(988.8134, dtype=float32), 'eval/episode_reward_std': Array(956.5086, dtype=float32), 'eval/episode_reward_alive_std': Array(47.37384, dtype=float32), 'eval/episode_reward_linvel_std': Array(988.8134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.358112, dtype=float32), 'eval/episode_x_position_std': Array(483.3482, dtype=float32), 'eval/episode_x_velocity_std': Array(197.76265, dtype=float32), 'eval/episode_y_position_std': Array(260.118, dtype=float32), 'eval/episode_y_velocity_std': Array(89.52826, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55194664001465, 'eval/sps': 937.3722099871653, 'num_steps': 26869760}
{'eval/walltime': 45077.974314689636, 'training/sps': 2966.590204265278, 'training/walltime': 9174.304356098175, 'training/entropy_loss': Array(0.01272537, dtype=float32), 'training/policy_loss': Array(0.0011951, dtype=float32), 'training/total_loss': Array(0.09791323, dtype=float32), 'training/v_loss': Array(0.08399276, dtype=float32), 'eval/episode_distance_from_origin': Array(4891.387, dtype=float32), 'eval/episode_distance_reward': Array(14.289626, dtype=float32), 'eval/episode_forward_reward': Array(2381.5947, dtype=float32), 'eval/episode_reward': Array(2397.0142, dtype=float32), 'eval/episode_reward_alive': Array(385.9336, dtype=float32), 'eval/episode_reward_linvel': Array(2381.5947, dtype=float32), 'eval/episode_reward_quadctrl': Array(-384.8036, dtype=float32), 'eval/episode_x_position': Array(4848.17, dtype=float32), 'eval/episode_x_velocity': Array(476.3189, dtype=float32), 'eval/episode_y_position': Array(71.889496, dtype=float32), 'eval/episode_y_velocity': Array(-46.062477, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.35153, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8601255, dtype=float32), 'eval/episode_forward_reward_std': Array(976.68134, dtype=float32), 'eval/episode_reward_std': Array(954.38983, dtype=float32), 'eval/episode_reward_alive_std': Array(52.625607, dtype=float32), 'eval/episode_reward_linvel_std': Array(976.68134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.613705, dtype=float32), 'eval/episode_x_position_std': Array(476.45856, dtype=float32), 'eval/episode_x_velocity_std': Array(195.33617, dtype=float32), 'eval/episode_y_position_std': Array(271.25735, dtype=float32), 'eval/episode_y_velocity_std': Array(85.606125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50971579551697, 'eval/sps': 937.66219681928, 'num_steps': 26951680}
{'eval/walltime': 45214.52775931358, 'training/sps': 2963.5962696905563, 'training/walltime': 9201.946447849274, 'training/entropy_loss': Array(0.01178068, dtype=float32), 'training/policy_loss': Array(0.00123404, dtype=float32), 'training/total_loss': Array(0.08178747, dtype=float32), 'training/v_loss': Array(0.06877273, dtype=float32), 'eval/episode_distance_from_origin': Array(4889.0557, dtype=float32), 'eval/episode_distance_reward': Array(14.316037, dtype=float32), 'eval/episode_forward_reward': Array(2385.996, dtype=float32), 'eval/episode_reward': Array(2411.6436, dtype=float32), 'eval/episode_reward_alive': Array(394.8203, dtype=float32), 'eval/episode_reward_linvel': Array(2385.996, dtype=float32), 'eval/episode_reward_quadctrl': Array(-383.48904, dtype=float32), 'eval/episode_x_position': Array(4845.951, dtype=float32), 'eval/episode_x_velocity': Array(477.19922, dtype=float32), 'eval/episode_y_position': Array(106.206345, dtype=float32), 'eval/episode_y_velocity': Array(-34.49719, dtype=float32), 'eval/episode_distance_from_origin_std': Array(500.71915, dtype=float32), 'eval/episode_distance_reward_std': Array(5.567999, dtype=float32), 'eval/episode_forward_reward_std': Array(927.99347, dtype=float32), 'eval/episode_reward_std': Array(894.24066, dtype=float32), 'eval/episode_reward_alive_std': Array(50.67859, dtype=float32), 'eval/episode_reward_linvel_std': Array(927.99347, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.785522, dtype=float32), 'eval/episode_x_position_std': Array(500.75974, dtype=float32), 'eval/episode_x_velocity_std': Array(185.59865, dtype=float32), 'eval/episode_y_position_std': Array(261.11572, dtype=float32), 'eval/episode_y_velocity_std': Array(93.56621, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55344462394714, 'eval/sps': 937.3619270645104, 'num_steps': 27033600}
{'eval/walltime': 45351.017058610916, 'training/sps': 2956.9478681818405, 'training/walltime': 9229.650690078735, 'training/entropy_loss': Array(0.01079247, dtype=float32), 'training/policy_loss': Array(0.00026822, dtype=float32), 'training/total_loss': Array(0.06582741, dtype=float32), 'training/v_loss': Array(0.05476671, dtype=float32), 'eval/episode_distance_from_origin': Array(5030.121, dtype=float32), 'eval/episode_distance_reward': Array(15.678662, dtype=float32), 'eval/episode_forward_reward': Array(2613.0986, dtype=float32), 'eval/episode_reward': Array(2633.0684, dtype=float32), 'eval/episode_reward_alive': Array(391.71484, dtype=float32), 'eval/episode_reward_linvel': Array(2613.0986, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.42337, dtype=float32), 'eval/episode_x_position': Array(4988.36, dtype=float32), 'eval/episode_x_velocity': Array(522.6197, dtype=float32), 'eval/episode_y_position': Array(98.04862, dtype=float32), 'eval/episode_y_velocity': Array(-44.715237, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.19727, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4632597, dtype=float32), 'eval/episode_forward_reward_std': Array(910.5368, dtype=float32), 'eval/episode_reward_std': Array(890.7154, dtype=float32), 'eval/episode_reward_alive_std': Array(45.804897, dtype=float32), 'eval/episode_reward_linvel_std': Array(910.5368, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.702507, dtype=float32), 'eval/episode_x_position_std': Array(471.6918, dtype=float32), 'eval/episode_x_velocity_std': Array(182.1074, dtype=float32), 'eval/episode_y_position_std': Array(247.98671, dtype=float32), 'eval/episode_y_velocity_std': Array(84.64069, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48929929733276, 'eval/sps': 937.8024552764433, 'num_steps': 27115520}
{'eval/walltime': 45487.56447863579, 'training/sps': 2956.6593776484074, 'training/walltime': 9257.357635498047, 'training/entropy_loss': Array(0.00844032, dtype=float32), 'training/policy_loss': Array(-0.0008212, dtype=float32), 'training/total_loss': Array(0.05524419, dtype=float32), 'training/v_loss': Array(0.04762507, dtype=float32), 'eval/episode_distance_from_origin': Array(5015.18, dtype=float32), 'eval/episode_distance_reward': Array(15.4066925, dtype=float32), 'eval/episode_forward_reward': Array(2567.7715, dtype=float32), 'eval/episode_reward': Array(2586.0513, dtype=float32), 'eval/episode_reward_alive': Array(389.33203, dtype=float32), 'eval/episode_reward_linvel': Array(2567.7715, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.4588, dtype=float32), 'eval/episode_x_position': Array(4972.4907, dtype=float32), 'eval/episode_x_velocity': Array(513.55426, dtype=float32), 'eval/episode_y_position': Array(87.199066, dtype=float32), 'eval/episode_y_velocity': Array(-39.459282, dtype=float32), 'eval/episode_distance_from_origin_std': Array(493.5269, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7110243, dtype=float32), 'eval/episode_forward_reward_std': Array(951.831, dtype=float32), 'eval/episode_reward_std': Array(925.79944, dtype=float32), 'eval/episode_reward_alive_std': Array(45.567142, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.831, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.694878, dtype=float32), 'eval/episode_x_position_std': Array(493.10797, dtype=float32), 'eval/episode_x_velocity_std': Array(190.3662, dtype=float32), 'eval/episode_y_position_std': Array(272.8646, dtype=float32), 'eval/episode_y_velocity_std': Array(90.33243, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54742002487183, 'eval/sps': 937.4032843438937, 'num_steps': 27197440}
{'eval/walltime': 45624.05020022392, 'training/sps': 2948.14441065102, 'training/walltime': 9285.144605398178, 'training/entropy_loss': Array(0.01645363, dtype=float32), 'training/policy_loss': Array(0.00690469, dtype=float32), 'training/total_loss': Array(0.13437186, dtype=float32), 'training/v_loss': Array(0.11101355, dtype=float32), 'eval/episode_distance_from_origin': Array(4948.0923, dtype=float32), 'eval/episode_distance_reward': Array(14.7392025, dtype=float32), 'eval/episode_forward_reward': Array(2456.5227, dtype=float32), 'eval/episode_reward': Array(2464.9255, dtype=float32), 'eval/episode_reward_alive': Array(391.8711, dtype=float32), 'eval/episode_reward_linvel': Array(2456.5227, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.20737, dtype=float32), 'eval/episode_x_position': Array(4905.921, dtype=float32), 'eval/episode_x_velocity': Array(491.30457, dtype=float32), 'eval/episode_y_position': Array(69.92504, dtype=float32), 'eval/episode_y_velocity': Array(-47.891296, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.61655, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3790774, dtype=float32), 'eval/episode_forward_reward_std': Array(896.50684, dtype=float32), 'eval/episode_reward_std': Array(876.5403, dtype=float32), 'eval/episode_reward_alive_std': Array(48.81363, dtype=float32), 'eval/episode_reward_linvel_std': Array(896.50684, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.918636, dtype=float32), 'eval/episode_x_position_std': Array(453.56693, dtype=float32), 'eval/episode_x_velocity_std': Array(179.30139, dtype=float32), 'eval/episode_y_position_std': Array(257.69406, dtype=float32), 'eval/episode_y_velocity_std': Array(84.14591, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48572158813477, 'eval/sps': 937.827037953892, 'num_steps': 27279360}
{'eval/walltime': 45760.60361504555, 'training/sps': 2940.39795919424, 'training/walltime': 9313.004779815674, 'training/entropy_loss': Array(0.01367419, dtype=float32), 'training/policy_loss': Array(0.00373, dtype=float32), 'training/total_loss': Array(0.1280509, dtype=float32), 'training/v_loss': Array(0.11064669, dtype=float32), 'eval/episode_distance_from_origin': Array(5001.123, dtype=float32), 'eval/episode_distance_reward': Array(15.119913, dtype=float32), 'eval/episode_forward_reward': Array(2519.9736, dtype=float32), 'eval/episode_reward': Array(2535.8042, dtype=float32), 'eval/episode_reward_alive': Array(384.51562, dtype=float32), 'eval/episode_reward_linvel': Array(2519.9736, dtype=float32), 'eval/episode_reward_quadctrl': Array(-383.80542, dtype=float32), 'eval/episode_x_position': Array(4959.177, dtype=float32), 'eval/episode_x_velocity': Array(503.99472, dtype=float32), 'eval/episode_y_position': Array(0.08046532, dtype=float32), 'eval/episode_y_velocity': Array(-69.035416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.75027, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0978026, dtype=float32), 'eval/episode_forward_reward_std': Array(849.6279, dtype=float32), 'eval/episode_reward_std': Array(828.6921, dtype=float32), 'eval/episode_reward_alive_std': Array(47.036465, dtype=float32), 'eval/episode_reward_linvel_std': Array(849.6279, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.27788, dtype=float32), 'eval/episode_x_position_std': Array(451.63937, dtype=float32), 'eval/episode_x_velocity_std': Array(169.92564, dtype=float32), 'eval/episode_y_position_std': Array(248.93004, dtype=float32), 'eval/episode_y_velocity_std': Array(86.238716, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55341482162476, 'eval/sps': 937.3621316405906, 'num_steps': 27361280}
{'eval/walltime': 45897.09552884102, 'training/sps': 2936.78810919287, 'training/walltime': 9340.899199485779, 'training/entropy_loss': Array(0.01357974, dtype=float32), 'training/policy_loss': Array(0.00228814, dtype=float32), 'training/total_loss': Array(0.12294398, dtype=float32), 'training/v_loss': Array(0.10707611, dtype=float32), 'eval/episode_distance_from_origin': Array(5043.894, dtype=float32), 'eval/episode_distance_reward': Array(15.595097, dtype=float32), 'eval/episode_forward_reward': Array(2599.1719, dtype=float32), 'eval/episode_reward': Array(2597.9722, dtype=float32), 'eval/episode_reward_alive': Array(377.9453, dtype=float32), 'eval/episode_reward_linvel': Array(2599.1719, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.74057, dtype=float32), 'eval/episode_x_position': Array(5002.4995, dtype=float32), 'eval/episode_x_velocity': Array(519.8345, dtype=float32), 'eval/episode_y_position': Array(0.02772355, dtype=float32), 'eval/episode_y_velocity': Array(-71.75763, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.75824, dtype=float32), 'eval/episode_distance_reward_std': Array(5.301762, dtype=float32), 'eval/episode_forward_reward_std': Array(883.62085, dtype=float32), 'eval/episode_reward_std': Array(866.45026, dtype=float32), 'eval/episode_reward_alive_std': Array(51.450603, dtype=float32), 'eval/episode_reward_linvel_std': Array(883.62085, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.905357, dtype=float32), 'eval/episode_x_position_std': Array(452.5218, dtype=float32), 'eval/episode_x_velocity_std': Array(176.72418, dtype=float32), 'eval/episode_y_position_std': Array(242.18895, dtype=float32), 'eval/episode_y_velocity_std': Array(79.224, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4919137954712, 'eval/sps': 937.7844917011271, 'num_steps': 27443200}
{'eval/walltime': 46033.619736909866, 'training/sps': 2933.8156184964173, 'training/walltime': 9368.82188129425, 'training/entropy_loss': Array(0.01244882, dtype=float32), 'training/policy_loss': Array(0.01146488, dtype=float32), 'training/total_loss': Array(0.10584004, dtype=float32), 'training/v_loss': Array(0.08192635, dtype=float32), 'eval/episode_distance_from_origin': Array(4862.054, dtype=float32), 'eval/episode_distance_reward': Array(13.680195, dtype=float32), 'eval/episode_forward_reward': Array(2280.0227, dtype=float32), 'eval/episode_reward': Array(2295.601, dtype=float32), 'eval/episode_reward_alive': Array(401.73438, dtype=float32), 'eval/episode_reward_linvel': Array(2280.0227, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.83643, dtype=float32), 'eval/episode_x_position': Array(4819.6377, dtype=float32), 'eval/episode_x_velocity': Array(456.00458, dtype=float32), 'eval/episode_y_position': Array(39.33776, dtype=float32), 'eval/episode_y_velocity': Array(-53.584763, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.09656, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2070036, dtype=float32), 'eval/episode_forward_reward_std': Array(867.82733, dtype=float32), 'eval/episode_reward_std': Array(839.3444, dtype=float32), 'eval/episode_reward_alive_std': Array(48.74943, dtype=float32), 'eval/episode_reward_linvel_std': Array(867.82733, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.866257, dtype=float32), 'eval/episode_x_position_std': Array(436.69705, dtype=float32), 'eval/episode_x_velocity_std': Array(173.56549, dtype=float32), 'eval/episode_y_position_std': Array(244.01566, dtype=float32), 'eval/episode_y_velocity_std': Array(88.57199, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52420806884766, 'eval/sps': 937.562662406736, 'num_steps': 27525120}
{'eval/walltime': 46170.079461336136, 'training/sps': 2945.5264765755483, 'training/walltime': 9396.633547782898, 'training/entropy_loss': Array(0.01220708, dtype=float32), 'training/policy_loss': Array(0.00542597, dtype=float32), 'training/total_loss': Array(0.08397298, dtype=float32), 'training/v_loss': Array(0.06633992, dtype=float32), 'eval/episode_distance_from_origin': Array(4897.2, dtype=float32), 'eval/episode_distance_reward': Array(13.551006, dtype=float32), 'eval/episode_forward_reward': Array(2258.4922, dtype=float32), 'eval/episode_reward': Array(2269.1401, dtype=float32), 'eval/episode_reward_alive': Array(405.89453, dtype=float32), 'eval/episode_reward_linvel': Array(2258.4922, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.7971, dtype=float32), 'eval/episode_x_position': Array(4854.751, dtype=float32), 'eval/episode_x_velocity': Array(451.69836, dtype=float32), 'eval/episode_y_position': Array(-4.039409, dtype=float32), 'eval/episode_y_velocity': Array(-62.146614, dtype=float32), 'eval/episode_distance_from_origin_std': Array(432.28, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5469713, dtype=float32), 'eval/episode_forward_reward_std': Array(757.8233, dtype=float32), 'eval/episode_reward_std': Array(724.9673, dtype=float32), 'eval/episode_reward_alive_std': Array(45.306446, dtype=float32), 'eval/episode_reward_linvel_std': Array(757.8233, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.332485, dtype=float32), 'eval/episode_x_position_std': Array(432.73993, dtype=float32), 'eval/episode_x_velocity_std': Array(151.5646, dtype=float32), 'eval/episode_y_position_std': Array(238.15828, dtype=float32), 'eval/episode_y_velocity_std': Array(80.35185, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45972442626953, 'eval/sps': 938.0057048932383, 'num_steps': 27607040}
{'eval/walltime': 46306.63929796219, 'training/sps': 2937.6900732866916, 'training/walltime': 9424.519402980804, 'training/entropy_loss': Array(0.00952262, dtype=float32), 'training/policy_loss': Array(0.00148917, dtype=float32), 'training/total_loss': Array(0.05775245, dtype=float32), 'training/v_loss': Array(0.04674066, dtype=float32), 'eval/episode_distance_from_origin': Array(4890.152, dtype=float32), 'eval/episode_distance_reward': Array(13.639209, dtype=float32), 'eval/episode_forward_reward': Array(2273.1914, dtype=float32), 'eval/episode_reward': Array(2292.4858, dtype=float32), 'eval/episode_reward_alive': Array(402.2422, dtype=float32), 'eval/episode_reward_linvel': Array(2273.1914, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.5873, dtype=float32), 'eval/episode_x_position': Array(4846.0293, dtype=float32), 'eval/episode_x_velocity': Array(454.6384, dtype=float32), 'eval/episode_y_position': Array(34.831207, dtype=float32), 'eval/episode_y_velocity': Array(-58.85025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(405.69287, dtype=float32), 'eval/episode_distance_reward_std': Array(4.691392, dtype=float32), 'eval/episode_forward_reward_std': Array(781.89264, dtype=float32), 'eval/episode_reward_std': Array(751.9377, dtype=float32), 'eval/episode_reward_alive_std': Array(48.557793, dtype=float32), 'eval/episode_reward_linvel_std': Array(781.89264, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(58.57665, dtype=float32), 'eval/episode_x_position_std': Array(402.72595, dtype=float32), 'eval/episode_x_velocity_std': Array(156.37854, dtype=float32), 'eval/episode_y_position_std': Array(270.23434, dtype=float32), 'eval/episode_y_velocity_std': Array(90.46048, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55983662605286, 'eval/sps': 937.3180516501891, 'num_steps': 27688960}
{'eval/walltime': 46443.12558555603, 'training/sps': 2944.3618629774046, 'training/walltime': 9452.342070102692, 'training/entropy_loss': Array(0.01715595, dtype=float32), 'training/policy_loss': Array(0.00732292, dtype=float32), 'training/total_loss': Array(0.12263128, dtype=float32), 'training/v_loss': Array(0.09815241, dtype=float32), 'eval/episode_distance_from_origin': Array(4924.473, dtype=float32), 'eval/episode_distance_reward': Array(13.705389, dtype=float32), 'eval/episode_forward_reward': Array(2284.2217, dtype=float32), 'eval/episode_reward': Array(2301.7317, dtype=float32), 'eval/episode_reward_alive': Array(400.95312, dtype=float32), 'eval/episode_reward_linvel': Array(2284.2217, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.14825, dtype=float32), 'eval/episode_x_position': Array(4880.5415, dtype=float32), 'eval/episode_x_velocity': Array(456.8443, dtype=float32), 'eval/episode_y_position': Array(41.5901, dtype=float32), 'eval/episode_y_velocity': Array(-51.319298, dtype=float32), 'eval/episode_distance_from_origin_std': Array(437.42914, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7558527, dtype=float32), 'eval/episode_forward_reward_std': Array(792.6361, dtype=float32), 'eval/episode_reward_std': Array(759.78973, dtype=float32), 'eval/episode_reward_alive_std': Array(53.59452, dtype=float32), 'eval/episode_reward_linvel_std': Array(792.6361, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.69049, dtype=float32), 'eval/episode_x_position_std': Array(436.50778, dtype=float32), 'eval/episode_x_velocity_std': Array(158.52716, dtype=float32), 'eval/episode_y_position_std': Array(269.64523, dtype=float32), 'eval/episode_y_velocity_std': Array(97.1979, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48628759384155, 'eval/sps': 937.8231488052836, 'num_steps': 27770880}
{'eval/walltime': 46579.676522254944, 'training/sps': 2941.380650931981, 'training/walltime': 9480.19293665886, 'training/entropy_loss': Array(0.01336426, dtype=float32), 'training/policy_loss': Array(0.00206837, dtype=float32), 'training/total_loss': Array(0.09496382, dtype=float32), 'training/v_loss': Array(0.07953118, dtype=float32), 'eval/episode_distance_from_origin': Array(4902.6514, dtype=float32), 'eval/episode_distance_reward': Array(13.700462, dtype=float32), 'eval/episode_forward_reward': Array(2283.4, dtype=float32), 'eval/episode_reward': Array(2293.9106, dtype=float32), 'eval/episode_reward_alive': Array(398.42578, dtype=float32), 'eval/episode_reward_linvel': Array(2283.4, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.61572, dtype=float32), 'eval/episode_x_position': Array(4858.4326, dtype=float32), 'eval/episode_x_velocity': Array(456.68, dtype=float32), 'eval/episode_y_position': Array(0.61845183, dtype=float32), 'eval/episode_y_velocity': Array(-70.109344, dtype=float32), 'eval/episode_distance_from_origin_std': Array(371.27487, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5821033, dtype=float32), 'eval/episode_forward_reward_std': Array(763.67773, dtype=float32), 'eval/episode_reward_std': Array(729.8784, dtype=float32), 'eval/episode_reward_alive_std': Array(47.498356, dtype=float32), 'eval/episode_reward_linvel_std': Array(763.67773, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.22204, dtype=float32), 'eval/episode_x_position_std': Array(369.7949, dtype=float32), 'eval/episode_x_velocity_std': Array(152.73555, dtype=float32), 'eval/episode_y_position_std': Array(258.53238, dtype=float32), 'eval/episode_y_velocity_std': Array(90.95011, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55093669891357, 'eval/sps': 937.3791428632389, 'num_steps': 27852800}
{'eval/walltime': 46716.1490278244, 'training/sps': 2924.81298700401, 'training/walltime': 9508.201565027237, 'training/entropy_loss': Array(0.01400192, dtype=float32), 'training/policy_loss': Array(0.00273629, dtype=float32), 'training/total_loss': Array(0.09010493, dtype=float32), 'training/v_loss': Array(0.07336673, dtype=float32), 'eval/episode_distance_from_origin': Array(4916.917, dtype=float32), 'eval/episode_distance_reward': Array(13.361868, dtype=float32), 'eval/episode_forward_reward': Array(2226.9692, dtype=float32), 'eval/episode_reward': Array(2244.3774, dtype=float32), 'eval/episode_reward_alive': Array(402.22656, dtype=float32), 'eval/episode_reward_linvel': Array(2226.9692, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.18048, dtype=float32), 'eval/episode_x_position': Array(4873.8613, dtype=float32), 'eval/episode_x_velocity': Array(445.39383, dtype=float32), 'eval/episode_y_position': Array(-10.657841, dtype=float32), 'eval/episode_y_velocity': Array(-64.09587, dtype=float32), 'eval/episode_distance_from_origin_std': Array(410.0629, dtype=float32), 'eval/episode_distance_reward_std': Array(4.755156, dtype=float32), 'eval/episode_forward_reward_std': Array(792.5199, dtype=float32), 'eval/episode_reward_std': Array(768.5911, dtype=float32), 'eval/episode_reward_alive_std': Array(53.831074, dtype=float32), 'eval/episode_reward_linvel_std': Array(792.5199, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.727085, dtype=float32), 'eval/episode_x_position_std': Array(409.7278, dtype=float32), 'eval/episode_x_velocity_std': Array(158.50392, dtype=float32), 'eval/episode_y_position_std': Array(253.22906, dtype=float32), 'eval/episode_y_velocity_std': Array(88.022736, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.472505569458, 'eval/sps': 937.9178572701891, 'num_steps': 27934720}
{'eval/walltime': 46852.709742069244, 'training/sps': 2937.0538048761823, 'training/walltime': 9536.0934612751, 'training/entropy_loss': Array(0.01331327, dtype=float32), 'training/policy_loss': Array(0.01431162, dtype=float32), 'training/total_loss': Array(0.08735522, dtype=float32), 'training/v_loss': Array(0.05973032, dtype=float32), 'eval/episode_distance_from_origin': Array(4909.092, dtype=float32), 'eval/episode_distance_reward': Array(13.540423, dtype=float32), 'eval/episode_forward_reward': Array(2256.7273, dtype=float32), 'eval/episode_reward': Array(2265.8489, dtype=float32), 'eval/episode_reward_alive': Array(396.07422, dtype=float32), 'eval/episode_reward_linvel': Array(2256.7273, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.49292, dtype=float32), 'eval/episode_x_position': Array(4866.4785, dtype=float32), 'eval/episode_x_velocity': Array(451.34546, dtype=float32), 'eval/episode_y_position': Array(-30.051739, dtype=float32), 'eval/episode_y_velocity': Array(-72.67533, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.58163, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6335735, dtype=float32), 'eval/episode_forward_reward_std': Array(772.25574, dtype=float32), 'eval/episode_reward_std': Array(747.7125, dtype=float32), 'eval/episode_reward_alive_std': Array(53.407562, dtype=float32), 'eval/episode_reward_linvel_std': Array(772.25574, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.96358, dtype=float32), 'eval/episode_x_position_std': Array(421.05008, dtype=float32), 'eval/episode_x_velocity_std': Array(154.45125, dtype=float32), 'eval/episode_y_position_std': Array(233.75095, dtype=float32), 'eval/episode_y_velocity_std': Array(84.0745, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56071424484253, 'eval/sps': 937.3120278977609, 'num_steps': 28016640}
{'eval/walltime': 46989.21040511131, 'training/sps': 2944.3762194221395, 'training/walltime': 9563.915992736816, 'training/entropy_loss': Array(0.01274084, dtype=float32), 'training/policy_loss': Array(0.00404752, dtype=float32), 'training/total_loss': Array(0.0737264, dtype=float32), 'training/v_loss': Array(0.05693805, dtype=float32), 'eval/episode_distance_from_origin': Array(4927.1787, dtype=float32), 'eval/episode_distance_reward': Array(13.6079855, dtype=float32), 'eval/episode_forward_reward': Array(2267.9878, dtype=float32), 'eval/episode_reward': Array(2266.3755, dtype=float32), 'eval/episode_reward_alive': Array(393.08984, dtype=float32), 'eval/episode_reward_linvel': Array(2267.9878, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.31012, dtype=float32), 'eval/episode_x_position': Array(4881.806, dtype=float32), 'eval/episode_x_velocity': Array(453.5976, dtype=float32), 'eval/episode_y_position': Array(-62.222916, dtype=float32), 'eval/episode_y_velocity': Array(-84.87999, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.1162, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5254784, dtype=float32), 'eval/episode_forward_reward_std': Array(754.2413, dtype=float32), 'eval/episode_reward_std': Array(737.47736, dtype=float32), 'eval/episode_reward_alive_std': Array(51.39497, dtype=float32), 'eval/episode_reward_linvel_std': Array(754.2413, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.386765, dtype=float32), 'eval/episode_x_position_std': Array(418.14014, dtype=float32), 'eval/episode_x_velocity_std': Array(150.84822, dtype=float32), 'eval/episode_y_position_std': Array(252.08894, dtype=float32), 'eval/episode_y_velocity_std': Array(87.2505, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50066304206848, 'eval/sps': 937.7243827786489, 'num_steps': 28098560}
{'eval/walltime': 47125.757135391235, 'training/sps': 2941.521261766078, 'training/walltime': 9591.765527963638, 'training/entropy_loss': Array(0.01027576, dtype=float32), 'training/policy_loss': Array(0.00711771, dtype=float32), 'training/total_loss': Array(0.0531191, dtype=float32), 'training/v_loss': Array(0.03572563, dtype=float32), 'eval/episode_distance_from_origin': Array(4983.8057, dtype=float32), 'eval/episode_distance_reward': Array(14.36927, dtype=float32), 'eval/episode_forward_reward': Array(2394.8684, dtype=float32), 'eval/episode_reward': Array(2402.7173, dtype=float32), 'eval/episode_reward_alive': Array(389.08594, dtype=float32), 'eval/episode_reward_linvel': Array(2394.8684, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.6065, dtype=float32), 'eval/episode_x_position': Array(4939.3643, dtype=float32), 'eval/episode_x_velocity': Array(478.97363, dtype=float32), 'eval/episode_y_position': Array(-63.991615, dtype=float32), 'eval/episode_y_velocity': Array(-88.735535, dtype=float32), 'eval/episode_distance_from_origin_std': Array(474.42282, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0932946, dtype=float32), 'eval/episode_forward_reward_std': Array(848.8754, dtype=float32), 'eval/episode_reward_std': Array(823.1591, dtype=float32), 'eval/episode_reward_alive_std': Array(53.12482, dtype=float32), 'eval/episode_reward_linvel_std': Array(848.8754, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.820652, dtype=float32), 'eval/episode_x_position_std': Array(473.28772, dtype=float32), 'eval/episode_x_velocity_std': Array(169.77509, dtype=float32), 'eval/episode_y_position_std': Array(255.00232, dtype=float32), 'eval/episode_y_velocity_std': Array(87.9734, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54673027992249, 'eval/sps': 937.4080194933882, 'num_steps': 28180480}
{'eval/walltime': 47262.27506828308, 'training/sps': 2954.049366478398, 'training/walltime': 9619.496953487396, 'training/entropy_loss': Array(0.01243423, dtype=float32), 'training/policy_loss': Array(0.00208004, dtype=float32), 'training/total_loss': Array(0.09876023, dtype=float32), 'training/v_loss': Array(0.08424596, dtype=float32), 'eval/episode_distance_from_origin': Array(5004.7188, dtype=float32), 'eval/episode_distance_reward': Array(14.520447, dtype=float32), 'eval/episode_forward_reward': Array(2420.0635, dtype=float32), 'eval/episode_reward': Array(2409.3142, dtype=float32), 'eval/episode_reward_alive': Array(383.21875, dtype=float32), 'eval/episode_reward_linvel': Array(2420.0635, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.48807, dtype=float32), 'eval/episode_x_position': Array(4960.7725, dtype=float32), 'eval/episode_x_velocity': Array(484.0127, dtype=float32), 'eval/episode_y_position': Array(-63.368683, dtype=float32), 'eval/episode_y_velocity': Array(-91.80745, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.605, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5001516, dtype=float32), 'eval/episode_forward_reward_std': Array(750.01886, dtype=float32), 'eval/episode_reward_std': Array(731.1261, dtype=float32), 'eval/episode_reward_alive_std': Array(51.431984, dtype=float32), 'eval/episode_reward_linvel_std': Array(750.01886, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.12964, dtype=float32), 'eval/episode_x_position_std': Array(428.97818, dtype=float32), 'eval/episode_x_velocity_std': Array(150.00377, dtype=float32), 'eval/episode_y_position_std': Array(236.22664, dtype=float32), 'eval/episode_y_velocity_std': Array(83.26513, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5179328918457, 'eval/sps': 937.6057583688005, 'num_steps': 28262400}
{'eval/walltime': 47398.936972141266, 'training/sps': 2936.6746810177365, 'training/walltime': 9647.39245057106, 'training/entropy_loss': Array(0.01495791, dtype=float32), 'training/policy_loss': Array(0.00476144, dtype=float32), 'training/total_loss': Array(0.14061433, dtype=float32), 'training/v_loss': Array(0.12089499, dtype=float32), 'eval/episode_distance_from_origin': Array(5000.0977, dtype=float32), 'eval/episode_distance_reward': Array(14.130031, dtype=float32), 'eval/episode_forward_reward': Array(2354.9946, dtype=float32), 'eval/episode_reward': Array(2353.2622, dtype=float32), 'eval/episode_reward_alive': Array(388.60156, dtype=float32), 'eval/episode_reward_linvel': Array(2354.9946, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.46423, dtype=float32), 'eval/episode_x_position': Array(4955.666, dtype=float32), 'eval/episode_x_velocity': Array(470.99896, dtype=float32), 'eval/episode_y_position': Array(-47.275185, dtype=float32), 'eval/episode_y_velocity': Array(-81.951416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(408.4983, dtype=float32), 'eval/episode_distance_reward_std': Array(4.373224, dtype=float32), 'eval/episode_forward_reward_std': Array(728.86505, dtype=float32), 'eval/episode_reward_std': Array(704.8723, dtype=float32), 'eval/episode_reward_alive_std': Array(56.523964, dtype=float32), 'eval/episode_reward_linvel_std': Array(728.86505, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.163, dtype=float32), 'eval/episode_x_position_std': Array(406.15073, dtype=float32), 'eval/episode_x_velocity_std': Array(145.77296, dtype=float32), 'eval/episode_y_position_std': Array(262.98798, dtype=float32), 'eval/episode_y_velocity_std': Array(91.2435, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66190385818481, 'eval/sps': 936.6180068208815, 'num_steps': 28344320}
{'eval/walltime': 47535.478078603745, 'training/sps': 2944.200823033786, 'training/walltime': 9675.216639518738, 'training/entropy_loss': Array(0.01447604, dtype=float32), 'training/policy_loss': Array(0.02309499, dtype=float32), 'training/total_loss': Array(0.13202068, dtype=float32), 'training/v_loss': Array(0.09444965, dtype=float32), 'eval/episode_distance_from_origin': Array(4949.615, dtype=float32), 'eval/episode_distance_reward': Array(13.73883, dtype=float32), 'eval/episode_forward_reward': Array(2289.7947, dtype=float32), 'eval/episode_reward': Array(2304.7854, dtype=float32), 'eval/episode_reward_alive': Array(393.98438, dtype=float32), 'eval/episode_reward_linvel': Array(2289.7947, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.7328, dtype=float32), 'eval/episode_x_position': Array(4903.0005, dtype=float32), 'eval/episode_x_velocity': Array(457.95892, dtype=float32), 'eval/episode_y_position': Array(-17.646633, dtype=float32), 'eval/episode_y_velocity': Array(-69.570206, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.16223, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5772905, dtype=float32), 'eval/episode_forward_reward_std': Array(762.8756, dtype=float32), 'eval/episode_reward_std': Array(725.71045, dtype=float32), 'eval/episode_reward_alive_std': Array(56.597534, dtype=float32), 'eval/episode_reward_linvel_std': Array(762.8756, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(62.856754, dtype=float32), 'eval/episode_x_position_std': Array(393.17438, dtype=float32), 'eval/episode_x_velocity_std': Array(152.57515, dtype=float32), 'eval/episode_y_position_std': Array(305.62015, dtype=float32), 'eval/episode_y_velocity_std': Array(101.502945, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54110646247864, 'eval/sps': 937.4466291964192, 'num_steps': 28426240}
{'eval/walltime': 47672.11536741257, 'training/sps': 2936.227981209536, 'training/walltime': 9703.11638045311, 'training/entropy_loss': Array(0.01365469, dtype=float32), 'training/policy_loss': Array(0.00465482, dtype=float32), 'training/total_loss': Array(0.09804182, dtype=float32), 'training/v_loss': Array(0.0797323, dtype=float32), 'eval/episode_distance_from_origin': Array(5042.0244, dtype=float32), 'eval/episode_distance_reward': Array(14.64164, dtype=float32), 'eval/episode_forward_reward': Array(2440.2632, dtype=float32), 'eval/episode_reward': Array(2444.6865, dtype=float32), 'eval/episode_reward_alive': Array(393.04688, dtype=float32), 'eval/episode_reward_linvel': Array(2440.2632, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.2653, dtype=float32), 'eval/episode_x_position': Array(4996.461, dtype=float32), 'eval/episode_x_velocity': Array(488.05255, dtype=float32), 'eval/episode_y_position': Array(9.9833975, dtype=float32), 'eval/episode_y_velocity': Array(-63.350693, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.48212, dtype=float32), 'eval/episode_distance_reward_std': Array(5.32043, dtype=float32), 'eval/episode_forward_reward_std': Array(886.7319, dtype=float32), 'eval/episode_reward_std': Array(858.2678, dtype=float32), 'eval/episode_reward_alive_std': Array(54.218323, dtype=float32), 'eval/episode_reward_linvel_std': Array(886.7319, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.793285, dtype=float32), 'eval/episode_x_position_std': Array(459.64636, dtype=float32), 'eval/episode_x_velocity_std': Array(177.34636, dtype=float32), 'eval/episode_y_position_std': Array(306.82275, dtype=float32), 'eval/episode_y_velocity_std': Array(97.76418, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63728880882263, 'eval/sps': 936.78673747027, 'num_steps': 28508160}
{'eval/walltime': 47808.64922165871, 'training/sps': 2946.9190119937944, 'training/walltime': 9730.91490483284, 'training/entropy_loss': Array(0.01297662, dtype=float32), 'training/policy_loss': Array(0.00197368, dtype=float32), 'training/total_loss': Array(0.06949872, dtype=float32), 'training/v_loss': Array(0.05454842, dtype=float32), 'eval/episode_distance_from_origin': Array(5050.312, dtype=float32), 'eval/episode_distance_reward': Array(14.410379, dtype=float32), 'eval/episode_forward_reward': Array(2401.7192, dtype=float32), 'eval/episode_reward': Array(2405.5618, dtype=float32), 'eval/episode_reward_alive': Array(384.5586, dtype=float32), 'eval/episode_reward_linvel': Array(2401.7192, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.12646, dtype=float32), 'eval/episode_x_position': Array(5008.578, dtype=float32), 'eval/episode_x_velocity': Array(480.34387, dtype=float32), 'eval/episode_y_position': Array(-27.97715, dtype=float32), 'eval/episode_y_velocity': Array(-73.739265, dtype=float32), 'eval/episode_distance_from_origin_std': Array(404.18597, dtype=float32), 'eval/episode_distance_reward_std': Array(4.281018, dtype=float32), 'eval/episode_forward_reward_std': Array(713.49664, dtype=float32), 'eval/episode_reward_std': Array(684.5849, dtype=float32), 'eval/episode_reward_alive_std': Array(59.820095, dtype=float32), 'eval/episode_reward_linvel_std': Array(713.49664, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.47412, dtype=float32), 'eval/episode_x_position_std': Array(403.6535, dtype=float32), 'eval/episode_x_velocity_std': Array(142.69937, dtype=float32), 'eval/episode_y_position_std': Array(242.54088, dtype=float32), 'eval/episode_y_velocity_std': Array(90.52317, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53385424613953, 'eval/sps': 937.4964231892632, 'num_steps': 28590080}
{'eval/walltime': 47945.333939790726, 'training/sps': 2937.9288015407997, 'training/walltime': 9758.79849410057, 'training/entropy_loss': Array(0.01224838, dtype=float32), 'training/policy_loss': Array(0.00433516, dtype=float32), 'training/total_loss': Array(0.05663577, dtype=float32), 'training/v_loss': Array(0.04005222, dtype=float32), 'eval/episode_distance_from_origin': Array(4979.549, dtype=float32), 'eval/episode_distance_reward': Array(13.893345, dtype=float32), 'eval/episode_forward_reward': Array(2315.5469, dtype=float32), 'eval/episode_reward': Array(2316.4258, dtype=float32), 'eval/episode_reward_alive': Array(391.34766, dtype=float32), 'eval/episode_reward_linvel': Array(2315.5469, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.36255, dtype=float32), 'eval/episode_x_position': Array(4937.5947, dtype=float32), 'eval/episode_x_velocity': Array(463.10944, dtype=float32), 'eval/episode_y_position': Array(-32.63699, dtype=float32), 'eval/episode_y_velocity': Array(-73.06219, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.34912, dtype=float32), 'eval/episode_distance_reward_std': Array(4.655278, dtype=float32), 'eval/episode_forward_reward_std': Array(775.87354, dtype=float32), 'eval/episode_reward_std': Array(753.8695, dtype=float32), 'eval/episode_reward_alive_std': Array(59.03146, dtype=float32), 'eval/episode_reward_linvel_std': Array(775.87354, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.311737, dtype=float32), 'eval/episode_x_position_std': Array(427.44415, dtype=float32), 'eval/episode_x_velocity_std': Array(155.17467, dtype=float32), 'eval/episode_y_position_std': Array(235.68709, dtype=float32), 'eval/episode_y_velocity_std': Array(87.30345, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.68471813201904, 'eval/sps': 936.4616743502315, 'num_steps': 28672000}
{'eval/walltime': 48081.8900039196, 'training/sps': 2947.6777778293463, 'training/walltime': 9786.589862823486, 'training/entropy_loss': Array(0.01157888, dtype=float32), 'training/policy_loss': Array(0.00328592, dtype=float32), 'training/total_loss': Array(0.11446758, dtype=float32), 'training/v_loss': Array(0.09960277, dtype=float32), 'eval/episode_distance_from_origin': Array(5046.298, dtype=float32), 'eval/episode_distance_reward': Array(14.368752, dtype=float32), 'eval/episode_forward_reward': Array(2394.7808, dtype=float32), 'eval/episode_reward': Array(2390.4526, dtype=float32), 'eval/episode_reward_alive': Array(386.23828, dtype=float32), 'eval/episode_reward_linvel': Array(2394.7808, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.9348, dtype=float32), 'eval/episode_x_position': Array(5001.4375, dtype=float32), 'eval/episode_x_velocity': Array(478.95612, dtype=float32), 'eval/episode_y_position': Array(-59.098354, dtype=float32), 'eval/episode_y_velocity': Array(-90.55413, dtype=float32), 'eval/episode_distance_from_origin_std': Array(399.2701, dtype=float32), 'eval/episode_distance_reward_std': Array(4.249541, dtype=float32), 'eval/episode_forward_reward_std': Array(708.2514, dtype=float32), 'eval/episode_reward_std': Array(688.6544, dtype=float32), 'eval/episode_reward_alive_std': Array(58.73793, dtype=float32), 'eval/episode_reward_linvel_std': Array(708.2514, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.451454, dtype=float32), 'eval/episode_x_position_std': Array(395.9054, dtype=float32), 'eval/episode_x_velocity_std': Array(141.65036, dtype=float32), 'eval/episode_y_position_std': Array(264.65637, dtype=float32), 'eval/episode_y_velocity_std': Array(95.23683, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55606412887573, 'eval/sps': 937.343945994219, 'num_steps': 28753920}
{'eval/walltime': 48218.528071165085, 'training/sps': 2925.0441735685736, 'training/walltime': 9814.596277475357, 'training/entropy_loss': Array(0.01491181, dtype=float32), 'training/policy_loss': Array(0.00350045, dtype=float32), 'training/total_loss': Array(0.13953018, dtype=float32), 'training/v_loss': Array(0.12111793, dtype=float32), 'eval/episode_distance_from_origin': Array(5021.2783, dtype=float32), 'eval/episode_distance_reward': Array(13.847617, dtype=float32), 'eval/episode_forward_reward': Array(2307.926, dtype=float32), 'eval/episode_reward': Array(2316.6582, dtype=float32), 'eval/episode_reward_alive': Array(390.20312, dtype=float32), 'eval/episode_reward_linvel': Array(2307.926, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.31833, dtype=float32), 'eval/episode_x_position': Array(4979.128, dtype=float32), 'eval/episode_x_velocity': Array(461.5852, dtype=float32), 'eval/episode_y_position': Array(-41.245064, dtype=float32), 'eval/episode_y_velocity': Array(-76.392624, dtype=float32), 'eval/episode_distance_from_origin_std': Array(383.0841, dtype=float32), 'eval/episode_distance_reward_std': Array(3.890334, dtype=float32), 'eval/episode_forward_reward_std': Array(648.3835, dtype=float32), 'eval/episode_reward_std': Array(620.072, dtype=float32), 'eval/episode_reward_alive_std': Array(61.60279, dtype=float32), 'eval/episode_reward_linvel_std': Array(648.3835, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.675915, dtype=float32), 'eval/episode_x_position_std': Array(380.4844, dtype=float32), 'eval/episode_x_velocity_std': Array(129.67673, dtype=float32), 'eval/episode_y_position_std': Array(245.92935, dtype=float32), 'eval/episode_y_velocity_std': Array(87.36881, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6380672454834, 'eval/sps': 936.7814005304665, 'num_steps': 28835840}
{'eval/walltime': 48355.03009366989, 'training/sps': 2936.483386517902, 'training/walltime': 9842.49359178543, 'training/entropy_loss': Array(0.0136664, dtype=float32), 'training/policy_loss': Array(0.00229662, dtype=float32), 'training/total_loss': Array(0.08871108, dtype=float32), 'training/v_loss': Array(0.07274805, dtype=float32), 'eval/episode_distance_from_origin': Array(5080.5063, dtype=float32), 'eval/episode_distance_reward': Array(14.538158, dtype=float32), 'eval/episode_forward_reward': Array(2423.015, dtype=float32), 'eval/episode_reward': Array(2425.955, dtype=float32), 'eval/episode_reward_alive': Array(383.46875, dtype=float32), 'eval/episode_reward_linvel': Array(2423.015, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.06668, dtype=float32), 'eval/episode_x_position': Array(5034.1587, dtype=float32), 'eval/episode_x_velocity': Array(484.60294, dtype=float32), 'eval/episode_y_position': Array(-90.23628, dtype=float32), 'eval/episode_y_velocity': Array(-95.574875, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.1748, dtype=float32), 'eval/episode_distance_reward_std': Array(4.373859, dtype=float32), 'eval/episode_forward_reward_std': Array(728.9697, dtype=float32), 'eval/episode_reward_std': Array(698.48914, dtype=float32), 'eval/episode_reward_alive_std': Array(58.01161, dtype=float32), 'eval/episode_reward_linvel_std': Array(728.9697, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.239334, dtype=float32), 'eval/episode_x_position_std': Array(413.6486, dtype=float32), 'eval/episode_x_velocity_std': Array(145.794, dtype=float32), 'eval/episode_y_position_std': Array(273.64786, dtype=float32), 'eval/episode_y_velocity_std': Array(95.601685, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50202250480652, 'eval/sps': 937.7150437129446, 'num_steps': 28917760}
{'eval/walltime': 48491.46029281616, 'training/sps': 2929.166666709292, 'training/walltime': 9870.460590362549, 'training/entropy_loss': Array(0.01372352, dtype=float32), 'training/policy_loss': Array(0.0049873, dtype=float32), 'training/total_loss': Array(0.07854766, dtype=float32), 'training/v_loss': Array(0.05983685, dtype=float32), 'eval/episode_distance_from_origin': Array(5092.8564, dtype=float32), 'eval/episode_distance_reward': Array(14.6897335, dtype=float32), 'eval/episode_forward_reward': Array(2448.2776, dtype=float32), 'eval/episode_reward': Array(2446.919, dtype=float32), 'eval/episode_reward_alive': Array(388.80078, dtype=float32), 'eval/episode_reward_linvel': Array(2448.2776, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.8491, dtype=float32), 'eval/episode_x_position': Array(5048.4106, dtype=float32), 'eval/episode_x_velocity': Array(489.65552, dtype=float32), 'eval/episode_y_position': Array(-83.49034, dtype=float32), 'eval/episode_y_velocity': Array(-84.57847, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.2884, dtype=float32), 'eval/episode_distance_reward_std': Array(4.718994, dtype=float32), 'eval/episode_forward_reward_std': Array(786.4928, dtype=float32), 'eval/episode_reward_std': Array(762.0161, dtype=float32), 'eval/episode_reward_alive_std': Array(60.557224, dtype=float32), 'eval/episode_reward_linvel_std': Array(786.4928, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.959908, dtype=float32), 'eval/episode_x_position_std': Array(426.48734, dtype=float32), 'eval/episode_x_velocity_std': Array(157.29858, dtype=float32), 'eval/episode_y_position_std': Array(255.13596, dtype=float32), 'eval/episode_y_velocity_std': Array(84.71964, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43019914627075, 'eval/sps': 938.208701599618, 'num_steps': 28999680}
{'eval/walltime': 48628.100999593735, 'training/sps': 2946.02844801388, 'training/walltime': 9898.267518043518, 'training/entropy_loss': Array(0.01343525, dtype=float32), 'training/policy_loss': Array(0.00553594, dtype=float32), 'training/total_loss': Array(0.06734839, dtype=float32), 'training/v_loss': Array(0.0483772, dtype=float32), 'eval/episode_distance_from_origin': Array(5054.3926, dtype=float32), 'eval/episode_distance_reward': Array(14.605702, dtype=float32), 'eval/episode_forward_reward': Array(2434.272, dtype=float32), 'eval/episode_reward': Array(2448.02, dtype=float32), 'eval/episode_reward_alive': Array(391.58984, dtype=float32), 'eval/episode_reward_linvel': Array(2434.272, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.4472, dtype=float32), 'eval/episode_x_position': Array(5009.7617, dtype=float32), 'eval/episode_x_velocity': Array(486.85428, dtype=float32), 'eval/episode_y_position': Array(-74.842384, dtype=float32), 'eval/episode_y_velocity': Array(-89.84341, dtype=float32), 'eval/episode_distance_from_origin_std': Array(379.53088, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5609355, dtype=float32), 'eval/episode_forward_reward_std': Array(760.1497, dtype=float32), 'eval/episode_reward_std': Array(730.444, dtype=float32), 'eval/episode_reward_alive_std': Array(51.001358, dtype=float32), 'eval/episode_reward_linvel_std': Array(760.1497, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.27322, dtype=float32), 'eval/episode_x_position_std': Array(378.13275, dtype=float32), 'eval/episode_x_velocity_std': Array(152.03, dtype=float32), 'eval/episode_y_position_std': Array(261.0495, dtype=float32), 'eval/episode_y_velocity_std': Array(92.81225, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64070677757263, 'eval/sps': 936.7633044255384, 'num_steps': 29081600}
{'eval/walltime': 48764.516283750534, 'training/sps': 2950.9975961983373, 'training/walltime': 9926.027621984482, 'training/entropy_loss': Array(0.01247815, dtype=float32), 'training/policy_loss': Array(0.00261833, dtype=float32), 'training/total_loss': Array(0.05295188, dtype=float32), 'training/v_loss': Array(0.0378554, dtype=float32), 'eval/episode_distance_from_origin': Array(5155.327, dtype=float32), 'eval/episode_distance_reward': Array(15.261572, dtype=float32), 'eval/episode_forward_reward': Array(2543.583, dtype=float32), 'eval/episode_reward': Array(2547.636, dtype=float32), 'eval/episode_reward_alive': Array(388.32812, dtype=float32), 'eval/episode_reward_linvel': Array(2543.583, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.53687, dtype=float32), 'eval/episode_x_position': Array(5106.8945, dtype=float32), 'eval/episode_x_velocity': Array(508.7166, dtype=float32), 'eval/episode_y_position': Array(-101.75194, dtype=float32), 'eval/episode_y_velocity': Array(-101.573235, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.87686, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7821302, dtype=float32), 'eval/episode_forward_reward_std': Array(797.01544, dtype=float32), 'eval/episode_reward_std': Array(771.4477, dtype=float32), 'eval/episode_reward_alive_std': Array(56.56272, dtype=float32), 'eval/episode_reward_linvel_std': Array(797.01544, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.56907, dtype=float32), 'eval/episode_x_position_std': Array(477.74155, dtype=float32), 'eval/episode_x_velocity_std': Array(159.40308, dtype=float32), 'eval/episode_y_position_std': Array(299.8625, dtype=float32), 'eval/episode_y_velocity_std': Array(98.07364, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41528415679932, 'eval/sps': 938.3112808156704, 'num_steps': 29163520}
{'eval/walltime': 48901.13343334198, 'training/sps': 2960.548705175295, 'training/walltime': 9953.69816827774, 'training/entropy_loss': Array(0.0094525, dtype=float32), 'training/policy_loss': Array(0.01474249, dtype=float32), 'training/total_loss': Array(0.10116395, dtype=float32), 'training/v_loss': Array(0.07696896, dtype=float32), 'eval/episode_distance_from_origin': Array(5103.384, dtype=float32), 'eval/episode_distance_reward': Array(14.6834755, dtype=float32), 'eval/episode_forward_reward': Array(2447.2354, dtype=float32), 'eval/episode_reward': Array(2445.7998, dtype=float32), 'eval/episode_reward_alive': Array(385.17578, dtype=float32), 'eval/episode_reward_linvel': Array(2447.2354, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.29492, dtype=float32), 'eval/episode_x_position': Array(5056.7085, dtype=float32), 'eval/episode_x_velocity': Array(489.44708, dtype=float32), 'eval/episode_y_position': Array(-155.2666, dtype=float32), 'eval/episode_y_velocity': Array(-108.62433, dtype=float32), 'eval/episode_distance_from_origin_std': Array(381.88956, dtype=float32), 'eval/episode_distance_reward_std': Array(4.089767, dtype=float32), 'eval/episode_forward_reward_std': Array(681.6212, dtype=float32), 'eval/episode_reward_std': Array(661.2442, dtype=float32), 'eval/episode_reward_alive_std': Array(57.311295, dtype=float32), 'eval/episode_reward_linvel_std': Array(681.6212, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.540787, dtype=float32), 'eval/episode_x_position_std': Array(377.46292, dtype=float32), 'eval/episode_x_velocity_std': Array(136.3243, dtype=float32), 'eval/episode_y_position_std': Array(242.47766, dtype=float32), 'eval/episode_y_velocity_std': Array(89.27254, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.61714959144592, 'eval/sps': 936.9248325176192, 'num_steps': 29245440}
{'eval/walltime': 49037.56290602684, 'training/sps': 2943.9394576125524, 'training/walltime': 9981.524827480316, 'training/entropy_loss': Array(0.01614195, dtype=float32), 'training/policy_loss': Array(0.00783469, dtype=float32), 'training/total_loss': Array(0.12289264, dtype=float32), 'training/v_loss': Array(0.098916, dtype=float32), 'eval/episode_distance_from_origin': Array(5142.1924, dtype=float32), 'eval/episode_distance_reward': Array(14.915577, dtype=float32), 'eval/episode_forward_reward': Array(2485.9177, dtype=float32), 'eval/episode_reward': Array(2499.81, dtype=float32), 'eval/episode_reward_alive': Array(396.48438, dtype=float32), 'eval/episode_reward_linvel': Array(2485.9177, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.50754, dtype=float32), 'eval/episode_x_position': Array(5098.506, dtype=float32), 'eval/episode_x_velocity': Array(497.18353, dtype=float32), 'eval/episode_y_position': Array(-86.50675, dtype=float32), 'eval/episode_y_velocity': Array(-88.2063, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.03314, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2692, dtype=float32), 'eval/episode_forward_reward_std': Array(711.52747, dtype=float32), 'eval/episode_reward_std': Array(681.24725, dtype=float32), 'eval/episode_reward_alive_std': Array(51.01868, dtype=float32), 'eval/episode_reward_linvel_std': Array(711.52747, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.85706, dtype=float32), 'eval/episode_x_position_std': Array(426.93353, dtype=float32), 'eval/episode_x_velocity_std': Array(142.3054, dtype=float32), 'eval/episode_y_position_std': Array(249.38326, dtype=float32), 'eval/episode_y_velocity_std': Array(83.95344, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42947268486023, 'eval/sps': 938.2136973853769, 'num_steps': 29327360}
{'eval/walltime': 49174.18534517288, 'training/sps': 2954.1325954112995, 'training/walltime': 10009.25547170639, 'training/entropy_loss': Array(0.01323472, dtype=float32), 'training/policy_loss': Array(0.00067717, dtype=float32), 'training/total_loss': Array(0.09511012, dtype=float32), 'training/v_loss': Array(0.08119823, dtype=float32), 'eval/episode_distance_from_origin': Array(5161.3135, dtype=float32), 'eval/episode_distance_reward': Array(15.247086, dtype=float32), 'eval/episode_forward_reward': Array(2541.1694, dtype=float32), 'eval/episode_reward': Array(2541.5522, dtype=float32), 'eval/episode_reward_alive': Array(385.16797, dtype=float32), 'eval/episode_reward_linvel': Array(2541.1694, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.03162, dtype=float32), 'eval/episode_x_position': Array(5110.7944, dtype=float32), 'eval/episode_x_velocity': Array(508.23395, dtype=float32), 'eval/episode_y_position': Array(-201.28311, dtype=float32), 'eval/episode_y_velocity': Array(-120.41424, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.8124, dtype=float32), 'eval/episode_distance_reward_std': Array(4.63972, dtype=float32), 'eval/episode_forward_reward_std': Array(773.28, dtype=float32), 'eval/episode_reward_std': Array(755.1871, dtype=float32), 'eval/episode_reward_alive_std': Array(55.769417, dtype=float32), 'eval/episode_reward_linvel_std': Array(773.28, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.199333, dtype=float32), 'eval/episode_x_position_std': Array(414.41058, dtype=float32), 'eval/episode_x_velocity_std': Array(154.656, dtype=float32), 'eval/episode_y_position_std': Array(268.0877, dtype=float32), 'eval/episode_y_velocity_std': Array(95.478806, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62243914604187, 'eval/sps': 936.8885579855228, 'num_steps': 29409280}
{'eval/walltime': 49310.64175581932, 'training/sps': 2954.148164847434, 'training/walltime': 10036.985969781876, 'training/entropy_loss': Array(0.0137221, dtype=float32), 'training/policy_loss': Array(0.00337899, dtype=float32), 'training/total_loss': Array(0.09513347, dtype=float32), 'training/v_loss': Array(0.07803239, dtype=float32), 'eval/episode_distance_from_origin': Array(5150.763, dtype=float32), 'eval/episode_distance_reward': Array(15.255612, dtype=float32), 'eval/episode_forward_reward': Array(2542.5908, dtype=float32), 'eval/episode_reward': Array(2554.6572, dtype=float32), 'eval/episode_reward_alive': Array(390.30078, dtype=float32), 'eval/episode_reward_linvel': Array(2542.5908, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.49, dtype=float32), 'eval/episode_x_position': Array(5106.5684, dtype=float32), 'eval/episode_x_velocity': Array(508.5182, dtype=float32), 'eval/episode_y_position': Array(-130.06148, dtype=float32), 'eval/episode_y_velocity': Array(-102.79081, dtype=float32), 'eval/episode_distance_from_origin_std': Array(415.64276, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5191684, dtype=float32), 'eval/episode_forward_reward_std': Array(753.18823, dtype=float32), 'eval/episode_reward_std': Array(721.80707, dtype=float32), 'eval/episode_reward_alive_std': Array(56.583916, dtype=float32), 'eval/episode_reward_linvel_std': Array(753.18823, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.595425, dtype=float32), 'eval/episode_x_position_std': Array(412.00934, dtype=float32), 'eval/episode_x_velocity_std': Array(150.63768, dtype=float32), 'eval/episode_y_position_std': Array(234.01428, dtype=float32), 'eval/episode_y_velocity_std': Array(86.140434, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4564106464386, 'eval/sps': 938.028483921145, 'num_steps': 29491200}
{'eval/walltime': 49447.19633817673, 'training/sps': 2952.4496516069994, 'training/walltime': 10064.732420921326, 'training/entropy_loss': Array(0.0132467, dtype=float32), 'training/policy_loss': Array(0.00181213, dtype=float32), 'training/total_loss': Array(0.07423694, dtype=float32), 'training/v_loss': Array(0.05917811, dtype=float32), 'eval/episode_distance_from_origin': Array(5220.385, dtype=float32), 'eval/episode_distance_reward': Array(16.168238, dtype=float32), 'eval/episode_forward_reward': Array(2694.6934, dtype=float32), 'eval/episode_reward': Array(2695.9111, dtype=float32), 'eval/episode_reward_alive': Array(380.89844, dtype=float32), 'eval/episode_reward_linvel': Array(2694.6934, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.84894, dtype=float32), 'eval/episode_x_position': Array(5175.6455, dtype=float32), 'eval/episode_x_velocity': Array(538.9387, dtype=float32), 'eval/episode_y_position': Array(-146.2173, dtype=float32), 'eval/episode_y_velocity': Array(-113.03458, dtype=float32), 'eval/episode_distance_from_origin_std': Array(413.993, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7033806, dtype=float32), 'eval/episode_forward_reward_std': Array(783.8895, dtype=float32), 'eval/episode_reward_std': Array(756.7978, dtype=float32), 'eval/episode_reward_alive_std': Array(63.061237, dtype=float32), 'eval/episode_reward_linvel_std': Array(783.8895, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.136314, dtype=float32), 'eval/episode_x_position_std': Array(411.40262, dtype=float32), 'eval/episode_x_velocity_std': Array(156.77792, dtype=float32), 'eval/episode_y_position_std': Array(236.97786, dtype=float32), 'eval/episode_y_velocity_std': Array(85.868774, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55458235740662, 'eval/sps': 937.3541172348463, 'num_steps': 29573120}
{'eval/walltime': 49583.71843004227, 'training/sps': 2944.5364963037946, 'training/walltime': 10092.553437948227, 'training/entropy_loss': Array(0.0129343, dtype=float32), 'training/policy_loss': Array(0.00153726, dtype=float32), 'training/total_loss': Array(0.06209888, dtype=float32), 'training/v_loss': Array(0.04762732, dtype=float32), 'eval/episode_distance_from_origin': Array(5273.6035, dtype=float32), 'eval/episode_distance_reward': Array(16.430908, dtype=float32), 'eval/episode_forward_reward': Array(2738.472, dtype=float32), 'eval/episode_reward': Array(2728.164, dtype=float32), 'eval/episode_reward_alive': Array(374.97266, dtype=float32), 'eval/episode_reward_linvel': Array(2738.472, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.71136, dtype=float32), 'eval/episode_x_position': Array(5225.744, dtype=float32), 'eval/episode_x_velocity': Array(547.69434, dtype=float32), 'eval/episode_y_position': Array(-161.31915, dtype=float32), 'eval/episode_y_velocity': Array(-120.72478, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.5748, dtype=float32), 'eval/episode_distance_reward_std': Array(5.269419, dtype=float32), 'eval/episode_forward_reward_std': Array(878.22894, dtype=float32), 'eval/episode_reward_std': Array(852.1528, dtype=float32), 'eval/episode_reward_alive_std': Array(67.2376, dtype=float32), 'eval/episode_reward_linvel_std': Array(878.22894, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.62649, dtype=float32), 'eval/episode_x_position_std': Array(487.57678, dtype=float32), 'eval/episode_x_velocity_std': Array(175.64578, dtype=float32), 'eval/episode_y_position_std': Array(260.65237, dtype=float32), 'eval/episode_y_velocity_std': Array(96.85447, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52209186553955, 'eval/sps': 937.5771953894982, 'num_steps': 29655040}
{'eval/walltime': 49720.29903292656, 'training/sps': 2953.9366580544774, 'training/walltime': 10120.285921573639, 'training/entropy_loss': Array(0.00996675, dtype=float32), 'training/policy_loss': Array(0.00022035, dtype=float32), 'training/total_loss': Array(0.04940403, dtype=float32), 'training/v_loss': Array(0.03921694, dtype=float32), 'eval/episode_distance_from_origin': Array(5325.6885, dtype=float32), 'eval/episode_distance_reward': Array(16.922184, dtype=float32), 'eval/episode_forward_reward': Array(2820.3499, dtype=float32), 'eval/episode_reward': Array(2817.594, dtype=float32), 'eval/episode_reward_alive': Array(377.5039, dtype=float32), 'eval/episode_reward_linvel': Array(2820.3499, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.182, dtype=float32), 'eval/episode_x_position': Array(5279.51, dtype=float32), 'eval/episode_x_velocity': Array(564.07, dtype=float32), 'eval/episode_y_position': Array(-143.99545, dtype=float32), 'eval/episode_y_velocity': Array(-122.73984, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.97263, dtype=float32), 'eval/episode_distance_reward_std': Array(5.186325, dtype=float32), 'eval/episode_forward_reward_std': Array(864.38086, dtype=float32), 'eval/episode_reward_std': Array(841.92834, dtype=float32), 'eval/episode_reward_alive_std': Array(57.363068, dtype=float32), 'eval/episode_reward_linvel_std': Array(864.38086, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.852924, dtype=float32), 'eval/episode_x_position_std': Array(467.58572, dtype=float32), 'eval/episode_x_velocity_std': Array(172.87622, dtype=float32), 'eval/episode_y_position_std': Array(249.97823, dtype=float32), 'eval/episode_y_velocity_std': Array(86.65417, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5806028842926, 'eval/sps': 937.1755380845561, 'num_steps': 29736960}
{'eval/walltime': 49856.80678796768, 'training/sps': 2944.270075871744, 'training/walltime': 10148.109456062317, 'training/entropy_loss': Array(0.016209, dtype=float32), 'training/policy_loss': Array(0.00558568, dtype=float32), 'training/total_loss': Array(0.15285653, dtype=float32), 'training/v_loss': Array(0.13106185, dtype=float32), 'eval/episode_distance_from_origin': Array(5426.8047, dtype=float32), 'eval/episode_distance_reward': Array(18.108028, dtype=float32), 'eval/episode_forward_reward': Array(3017.9902, dtype=float32), 'eval/episode_reward': Array(3010.941, dtype=float32), 'eval/episode_reward_alive': Array(368.77344, dtype=float32), 'eval/episode_reward_linvel': Array(3017.9902, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.93048, dtype=float32), 'eval/episode_x_position': Array(5375.8955, dtype=float32), 'eval/episode_x_velocity': Array(603.5979, dtype=float32), 'eval/episode_y_position': Array(-234.20724, dtype=float32), 'eval/episode_y_velocity': Array(-141.99985, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.2515, dtype=float32), 'eval/episode_distance_reward_std': Array(4.951143, dtype=float32), 'eval/episode_forward_reward_std': Array(825.18353, dtype=float32), 'eval/episode_reward_std': Array(801.4385, dtype=float32), 'eval/episode_reward_alive_std': Array(63.703255, dtype=float32), 'eval/episode_reward_linvel_std': Array(825.18353, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.712563, dtype=float32), 'eval/episode_x_position_std': Array(413.05597, dtype=float32), 'eval/episode_x_velocity_std': Array(165.0367, dtype=float32), 'eval/episode_y_position_std': Array(248.73976, dtype=float32), 'eval/episode_y_velocity_std': Array(90.998146, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50775504112244, 'eval/sps': 937.6756651037188, 'num_steps': 29818880}
{'eval/walltime': 49993.369760513306, 'training/sps': 2942.6735480418283, 'training/walltime': 10175.94808602333, 'training/entropy_loss': Array(0.01300521, dtype=float32), 'training/policy_loss': Array(0.00469087, dtype=float32), 'training/total_loss': Array(0.10739601, dtype=float32), 'training/v_loss': Array(0.08969992, dtype=float32), 'eval/episode_distance_from_origin': Array(5336.539, dtype=float32), 'eval/episode_distance_reward': Array(16.950323, dtype=float32), 'eval/episode_forward_reward': Array(2825.0393, dtype=float32), 'eval/episode_reward': Array(2822.2375, dtype=float32), 'eval/episode_reward_alive': Array(377.97656, dtype=float32), 'eval/episode_reward_linvel': Array(2825.0393, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.7285, dtype=float32), 'eval/episode_x_position': Array(5289.5645, dtype=float32), 'eval/episode_x_velocity': Array(565.0078, dtype=float32), 'eval/episode_y_position': Array(-199.00974, dtype=float32), 'eval/episode_y_velocity': Array(-125.20273, dtype=float32), 'eval/episode_distance_from_origin_std': Array(384.19427, dtype=float32), 'eval/episode_distance_reward_std': Array(4.349931, dtype=float32), 'eval/episode_forward_reward_std': Array(724.9836, dtype=float32), 'eval/episode_reward_std': Array(702.1389, dtype=float32), 'eval/episode_reward_alive_std': Array(56.493217, dtype=float32), 'eval/episode_reward_linvel_std': Array(724.9836, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.182266, dtype=float32), 'eval/episode_x_position_std': Array(381.7813, dtype=float32), 'eval/episode_x_velocity_std': Array(144.9967, dtype=float32), 'eval/episode_y_position_std': Array(239.57803, dtype=float32), 'eval/episode_y_velocity_std': Array(84.16103, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56297254562378, 'eval/sps': 937.2965278508198, 'num_steps': 29900800}
{'eval/walltime': 50129.8845603466, 'training/sps': 2947.5459081197305, 'training/walltime': 10203.740698099136, 'training/entropy_loss': Array(0.01298435, dtype=float32), 'training/policy_loss': Array(0.00303563, dtype=float32), 'training/total_loss': Array(0.09483266, dtype=float32), 'training/v_loss': Array(0.07881267, dtype=float32), 'eval/episode_distance_from_origin': Array(5354.365, dtype=float32), 'eval/episode_distance_reward': Array(17.501556, dtype=float32), 'eval/episode_forward_reward': Array(2916.9111, dtype=float32), 'eval/episode_reward': Array(2912.4614, dtype=float32), 'eval/episode_reward_alive': Array(369.3203, dtype=float32), 'eval/episode_reward_linvel': Array(2916.9111, dtype=float32), 'eval/episode_reward_quadctrl': Array(-391.2715, dtype=float32), 'eval/episode_x_position': Array(5303.6304, dtype=float32), 'eval/episode_x_velocity': Array(583.38226, dtype=float32), 'eval/episode_y_position': Array(-207.94824, dtype=float32), 'eval/episode_y_velocity': Array(-136.50854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.30582, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7332664, dtype=float32), 'eval/episode_forward_reward_std': Array(788.8705, dtype=float32), 'eval/episode_reward_std': Array(766.3003, dtype=float32), 'eval/episode_reward_alive_std': Array(67.793106, dtype=float32), 'eval/episode_reward_linvel_std': Array(788.8705, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.307377, dtype=float32), 'eval/episode_x_position_std': Array(394.10178, dtype=float32), 'eval/episode_x_velocity_std': Array(157.77415, dtype=float32), 'eval/episode_y_position_std': Array(272.00186, dtype=float32), 'eval/episode_y_velocity_std': Array(95.728966, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51479983329773, 'eval/sps': 937.627276722411, 'num_steps': 29982720}
{'eval/walltime': 50266.44993829727, 'training/sps': 2943.2469287335643, 'training/walltime': 10231.573904752731, 'training/entropy_loss': Array(0.01263484, dtype=float32), 'training/policy_loss': Array(0.00206897, dtype=float32), 'training/total_loss': Array(0.08111904, dtype=float32), 'training/v_loss': Array(0.06641522, dtype=float32), 'eval/episode_distance_from_origin': Array(5365.616, dtype=float32), 'eval/episode_distance_reward': Array(17.092396, dtype=float32), 'eval/episode_forward_reward': Array(2848.7188, dtype=float32), 'eval/episode_reward': Array(2846.122, dtype=float32), 'eval/episode_reward_alive': Array(379.28516, dtype=float32), 'eval/episode_reward_linvel': Array(2848.7188, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.9744, dtype=float32), 'eval/episode_x_position': Array(5317.421, dtype=float32), 'eval/episode_x_velocity': Array(569.7439, dtype=float32), 'eval/episode_y_position': Array(-138.46909, dtype=float32), 'eval/episode_y_velocity': Array(-116.1869, dtype=float32), 'eval/episode_distance_from_origin_std': Array(448.90067, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6743746, dtype=float32), 'eval/episode_forward_reward_std': Array(779.0559, dtype=float32), 'eval/episode_reward_std': Array(754.9451, dtype=float32), 'eval/episode_reward_alive_std': Array(61.76362, dtype=float32), 'eval/episode_reward_linvel_std': Array(779.0559, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.507153, dtype=float32), 'eval/episode_x_position_std': Array(448.4341, dtype=float32), 'eval/episode_x_velocity_std': Array(155.81125, dtype=float32), 'eval/episode_y_position_std': Array(293.75903, dtype=float32), 'eval/episode_y_velocity_std': Array(100.94341, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56537795066833, 'eval/sps': 937.2800187045767, 'num_steps': 30064640}
{'eval/walltime': 50403.0042719841, 'training/sps': 2931.6567059828485, 'training/walltime': 10259.517149209976, 'training/entropy_loss': Array(0.01272051, dtype=float32), 'training/policy_loss': Array(0.0052316, dtype=float32), 'training/total_loss': Array(0.07495287, dtype=float32), 'training/v_loss': Array(0.05700076, dtype=float32), 'eval/episode_distance_from_origin': Array(5423.8574, dtype=float32), 'eval/episode_distance_reward': Array(18.492193, dtype=float32), 'eval/episode_forward_reward': Array(3082.0164, dtype=float32), 'eval/episode_reward': Array(3077.643, dtype=float32), 'eval/episode_reward_alive': Array(369.1875, dtype=float32), 'eval/episode_reward_linvel': Array(3082.0164, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.0526, dtype=float32), 'eval/episode_x_position': Array(5374.14, dtype=float32), 'eval/episode_x_velocity': Array(616.4032, dtype=float32), 'eval/episode_y_position': Array(-187.09435, dtype=float32), 'eval/episode_y_velocity': Array(-138.3263, dtype=float32), 'eval/episode_distance_from_origin_std': Array(439.97516, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9726763, dtype=float32), 'eval/episode_forward_reward_std': Array(828.77405, dtype=float32), 'eval/episode_reward_std': Array(818.115, dtype=float32), 'eval/episode_reward_alive_std': Array(57.62378, dtype=float32), 'eval/episode_reward_linvel_std': Array(828.77405, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.354755, dtype=float32), 'eval/episode_x_position_std': Array(439.47708, dtype=float32), 'eval/episode_x_velocity_std': Array(165.75484, dtype=float32), 'eval/episode_y_position_std': Array(274.25708, dtype=float32), 'eval/episode_y_velocity_std': Array(99.281235, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5543336868286, 'eval/sps': 937.3558241919515, 'num_steps': 30146560}
{'eval/walltime': 50539.557500362396, 'training/sps': 2929.461081033083, 'training/walltime': 10287.481337070465, 'training/entropy_loss': Array(0.0109678, dtype=float32), 'training/policy_loss': Array(0.00093852, dtype=float32), 'training/total_loss': Array(0.05433092, dtype=float32), 'training/v_loss': Array(0.04242459, dtype=float32), 'eval/episode_distance_from_origin': Array(5544.3594, dtype=float32), 'eval/episode_distance_reward': Array(19.270731, dtype=float32), 'eval/episode_forward_reward': Array(3211.772, dtype=float32), 'eval/episode_reward': Array(3210.9277, dtype=float32), 'eval/episode_reward_alive': Array(373.60547, dtype=float32), 'eval/episode_reward_linvel': Array(3211.772, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.72058, dtype=float32), 'eval/episode_x_position': Array(5494.635, dtype=float32), 'eval/episode_x_velocity': Array(642.3544, dtype=float32), 'eval/episode_y_position': Array(-198.64838, dtype=float32), 'eval/episode_y_velocity': Array(-141.44852, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.35257, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1181173, dtype=float32), 'eval/episode_forward_reward_std': Array(853.013, dtype=float32), 'eval/episode_reward_std': Array(837.18286, dtype=float32), 'eval/episode_reward_alive_std': Array(59.08659, dtype=float32), 'eval/episode_reward_linvel_std': Array(853.013, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.79266, dtype=float32), 'eval/episode_x_position_std': Array(456.6151, dtype=float32), 'eval/episode_x_velocity_std': Array(170.6026, dtype=float32), 'eval/episode_y_position_std': Array(260.25864, dtype=float32), 'eval/episode_y_velocity_std': Array(93.16634, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5532283782959, 'eval/sps': 937.3634114705752, 'num_steps': 30228480}
{'eval/walltime': 50676.09190630913, 'training/sps': 2929.642668950373, 'training/walltime': 10315.443791627884, 'training/entropy_loss': Array(0.01247688, dtype=float32), 'training/policy_loss': Array(0.00317053, dtype=float32), 'training/total_loss': Array(0.10396028, dtype=float32), 'training/v_loss': Array(0.08831288, dtype=float32), 'eval/episode_distance_from_origin': Array(5437.6426, dtype=float32), 'eval/episode_distance_reward': Array(17.751095, dtype=float32), 'eval/episode_forward_reward': Array(2958.5002, dtype=float32), 'eval/episode_reward': Array(2974.2686, dtype=float32), 'eval/episode_reward_alive': Array(390.4922, dtype=float32), 'eval/episode_reward_linvel': Array(2958.5002, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.47546, dtype=float32), 'eval/episode_x_position': Array(5389.6333, dtype=float32), 'eval/episode_x_velocity': Array(591.70013, dtype=float32), 'eval/episode_y_position': Array(-148.22363, dtype=float32), 'eval/episode_y_velocity': Array(-116.86722, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.61658, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2309604, dtype=float32), 'eval/episode_forward_reward_std': Array(871.8204, dtype=float32), 'eval/episode_reward_std': Array(855.6603, dtype=float32), 'eval/episode_reward_alive_std': Array(61.06151, dtype=float32), 'eval/episode_reward_linvel_std': Array(871.8204, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.95092, dtype=float32), 'eval/episode_x_position_std': Array(480.32263, dtype=float32), 'eval/episode_x_velocity_std': Array(174.36403, dtype=float32), 'eval/episode_y_position_std': Array(292.5789, dtype=float32), 'eval/episode_y_velocity_std': Array(101.1048, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53440594673157, 'eval/sps': 937.4926350061446, 'num_steps': 30310400}
{'eval/walltime': 50812.65026926994, 'training/sps': 2923.7242250495487, 'training/walltime': 10343.462850093842, 'training/entropy_loss': Array(0.01476819, dtype=float32), 'training/policy_loss': Array(0.00543411, dtype=float32), 'training/total_loss': Array(0.16454315, dtype=float32), 'training/v_loss': Array(0.14434084, dtype=float32), 'eval/episode_distance_from_origin': Array(5421.1274, dtype=float32), 'eval/episode_distance_reward': Array(17.84788, dtype=float32), 'eval/episode_forward_reward': Array(2974.6313, dtype=float32), 'eval/episode_reward': Array(2979.5134, dtype=float32), 'eval/episode_reward_alive': Array(383.08594, dtype=float32), 'eval/episode_reward_linvel': Array(2974.6313, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.05154, dtype=float32), 'eval/episode_x_position': Array(5374.5015, dtype=float32), 'eval/episode_x_velocity': Array(594.9263, dtype=float32), 'eval/episode_y_position': Array(-151.16992, dtype=float32), 'eval/episode_y_velocity': Array(-123.062836, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.77637, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5309453, dtype=float32), 'eval/episode_forward_reward_std': Array(921.8174, dtype=float32), 'eval/episode_reward_std': Array(913.3688, dtype=float32), 'eval/episode_reward_alive_std': Array(61.018475, dtype=float32), 'eval/episode_reward_linvel_std': Array(921.8174, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.7355, dtype=float32), 'eval/episode_x_position_std': Array(488.3194, dtype=float32), 'eval/episode_x_velocity_std': Array(184.36346, dtype=float32), 'eval/episode_y_position_std': Array(265.44647, dtype=float32), 'eval/episode_y_velocity_std': Array(94.668846, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55836296081543, 'eval/sps': 937.3281666881786, 'num_steps': 30392320}
{'eval/walltime': 50949.17584347725, 'training/sps': 2925.230493955237, 'training/walltime': 10371.467480897903, 'training/entropy_loss': Array(0.01341872, dtype=float32), 'training/policy_loss': Array(0.00337704, dtype=float32), 'training/total_loss': Array(0.11354794, dtype=float32), 'training/v_loss': Array(0.09675217, dtype=float32), 'eval/episode_distance_from_origin': Array(5450.23, dtype=float32), 'eval/episode_distance_reward': Array(17.752457, dtype=float32), 'eval/episode_forward_reward': Array(2958.7283, dtype=float32), 'eval/episode_reward': Array(2970.9578, dtype=float32), 'eval/episode_reward_alive': Array(387.58594, dtype=float32), 'eval/episode_reward_linvel': Array(2958.7283, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.10907, dtype=float32), 'eval/episode_x_position': Array(5401.159, dtype=float32), 'eval/episode_x_velocity': Array(591.74567, dtype=float32), 'eval/episode_y_position': Array(-159.56915, dtype=float32), 'eval/episode_y_velocity': Array(-120.05644, dtype=float32), 'eval/episode_distance_from_origin_std': Array(402.88864, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7690296, dtype=float32), 'eval/episode_forward_reward_std': Array(794.8312, dtype=float32), 'eval/episode_reward_std': Array(780.39014, dtype=float32), 'eval/episode_reward_alive_std': Array(62.226, dtype=float32), 'eval/episode_reward_linvel_std': Array(794.8312, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.51076, dtype=float32), 'eval/episode_x_position_std': Array(401.25494, dtype=float32), 'eval/episode_x_velocity_std': Array(158.96631, dtype=float32), 'eval/episode_y_position_std': Array(290.5451, dtype=float32), 'eval/episode_y_velocity_std': Array(102.58895, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5255742073059, 'eval/sps': 937.5532807182313, 'num_steps': 30474240}
{'eval/walltime': 51085.73295497894, 'training/sps': 2924.2399463358734, 'training/walltime': 10399.48159790039, 'training/entropy_loss': Array(0.01307642, dtype=float32), 'training/policy_loss': Array(0.0064549, dtype=float32), 'training/total_loss': Array(0.11038275, dtype=float32), 'training/v_loss': Array(0.09085143, dtype=float32), 'eval/episode_distance_from_origin': Array(5501.922, dtype=float32), 'eval/episode_distance_reward': Array(18.370527, dtype=float32), 'eval/episode_forward_reward': Array(3061.74, dtype=float32), 'eval/episode_reward': Array(3072.0273, dtype=float32), 'eval/episode_reward_alive': Array(387.17578, dtype=float32), 'eval/episode_reward_linvel': Array(3061.74, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.25882, dtype=float32), 'eval/episode_x_position': Array(5452.2056, dtype=float32), 'eval/episode_x_velocity': Array(612.348, dtype=float32), 'eval/episode_y_position': Array(-202.13507, dtype=float32), 'eval/episode_y_velocity': Array(-137.84863, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.47922, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1874304, dtype=float32), 'eval/episode_forward_reward_std': Array(864.56494, dtype=float32), 'eval/episode_reward_std': Array(849.08545, dtype=float32), 'eval/episode_reward_alive_std': Array(59.810104, dtype=float32), 'eval/episode_reward_linvel_std': Array(864.56494, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.330853, dtype=float32), 'eval/episode_x_position_std': Array(477.59842, dtype=float32), 'eval/episode_x_velocity_std': Array(172.91295, dtype=float32), 'eval/episode_y_position_std': Array(260.21216, dtype=float32), 'eval/episode_y_velocity_std': Array(90.33057, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55711150169373, 'eval/sps': 937.3367567049952, 'num_steps': 30556160}
{'eval/walltime': 51222.30302000046, 'training/sps': 2923.094289692675, 'training/walltime': 10427.506694555283, 'training/entropy_loss': Array(0.01293215, dtype=float32), 'training/policy_loss': Array(0.03891325, dtype=float32), 'training/total_loss': Array(0.1271603, dtype=float32), 'training/v_loss': Array(0.07531489, dtype=float32), 'eval/episode_distance_from_origin': Array(5539.71, dtype=float32), 'eval/episode_distance_reward': Array(18.856964, dtype=float32), 'eval/episode_forward_reward': Array(3142.8123, dtype=float32), 'eval/episode_reward': Array(3152.1965, dtype=float32), 'eval/episode_reward_alive': Array(383.94922, dtype=float32), 'eval/episode_reward_linvel': Array(3142.8123, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.42203, dtype=float32), 'eval/episode_x_position': Array(5488.544, dtype=float32), 'eval/episode_x_velocity': Array(628.5624, dtype=float32), 'eval/episode_y_position': Array(-196.31519, dtype=float32), 'eval/episode_y_velocity': Array(-137.26678, dtype=float32), 'eval/episode_distance_from_origin_std': Array(424.5489, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3677177, dtype=float32), 'eval/episode_forward_reward_std': Array(727.94727, dtype=float32), 'eval/episode_reward_std': Array(714.0593, dtype=float32), 'eval/episode_reward_alive_std': Array(59.937363, dtype=float32), 'eval/episode_reward_linvel_std': Array(727.94727, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.432953, dtype=float32), 'eval/episode_x_position_std': Array(420.89136, dtype=float32), 'eval/episode_x_velocity_std': Array(145.58946, dtype=float32), 'eval/episode_y_position_std': Array(293.33856, dtype=float32), 'eval/episode_y_velocity_std': Array(96.45762, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5700650215149, 'eval/sps': 937.247851348941, 'num_steps': 30638080}
{'eval/walltime': 51358.852405548096, 'training/sps': 2944.3501558923595, 'training/walltime': 10455.32947230339, 'training/entropy_loss': Array(0.01326241, dtype=float32), 'training/policy_loss': Array(0.00238602, dtype=float32), 'training/total_loss': Array(0.08752723, dtype=float32), 'training/v_loss': Array(0.07187881, dtype=float32), 'eval/episode_distance_from_origin': Array(5595.703, dtype=float32), 'eval/episode_distance_reward': Array(20.023495, dtype=float32), 'eval/episode_forward_reward': Array(3337.2334, dtype=float32), 'eval/episode_reward': Array(3346.2139, dtype=float32), 'eval/episode_reward_alive': Array(378.1797, dtype=float32), 'eval/episode_reward_linvel': Array(3337.2334, dtype=float32), 'eval/episode_reward_quadctrl': Array(-389.22256, dtype=float32), 'eval/episode_x_position': Array(5547., dtype=float32), 'eval/episode_x_velocity': Array(667.4466, dtype=float32), 'eval/episode_y_position': Array(-146.99057, dtype=float32), 'eval/episode_y_velocity': Array(-138.95741, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.48315, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4724054, dtype=float32), 'eval/episode_forward_reward_std': Array(912.0603, dtype=float32), 'eval/episode_reward_std': Array(900.6452, dtype=float32), 'eval/episode_reward_alive_std': Array(60.76375, dtype=float32), 'eval/episode_reward_linvel_std': Array(912.0603, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.011814, dtype=float32), 'eval/episode_x_position_std': Array(478.10742, dtype=float32), 'eval/episode_x_velocity_std': Array(182.41205, dtype=float32), 'eval/episode_y_position_std': Array(286.7458, dtype=float32), 'eval/episode_y_velocity_std': Array(99.158295, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54938554763794, 'eval/sps': 937.3897911488198, 'num_steps': 30720000}
{'eval/walltime': 51495.41151857376, 'training/sps': 2940.4151959486726, 'training/walltime': 10483.18948340416, 'training/entropy_loss': Array(0.01042495, dtype=float32), 'training/policy_loss': Array(0.00192372, dtype=float32), 'training/total_loss': Array(0.09752129, dtype=float32), 'training/v_loss': Array(0.08517262, dtype=float32), 'eval/episode_distance_from_origin': Array(5642.508, dtype=float32), 'eval/episode_distance_reward': Array(20.31291, dtype=float32), 'eval/episode_forward_reward': Array(3385.4685, dtype=float32), 'eval/episode_reward': Array(3394.747, dtype=float32), 'eval/episode_reward_alive': Array(374.8203, dtype=float32), 'eval/episode_reward_linvel': Array(3385.4685, dtype=float32), 'eval/episode_reward_quadctrl': Array(-385.85443, dtype=float32), 'eval/episode_x_position': Array(5591.9053, dtype=float32), 'eval/episode_x_velocity': Array(677.09375, dtype=float32), 'eval/episode_y_position': Array(-168.73096, dtype=float32), 'eval/episode_y_velocity': Array(-137.84912, dtype=float32), 'eval/episode_distance_from_origin_std': Array(386.67822, dtype=float32), 'eval/episode_distance_reward_std': Array(4.725476, dtype=float32), 'eval/episode_forward_reward_std': Array(787.57324, dtype=float32), 'eval/episode_reward_std': Array(764.60956, dtype=float32), 'eval/episode_reward_alive_std': Array(61.67717, dtype=float32), 'eval/episode_reward_linvel_std': Array(787.57324, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.616644, dtype=float32), 'eval/episode_x_position_std': Array(384.67392, dtype=float32), 'eval/episode_x_velocity_std': Array(157.51457, dtype=float32), 'eval/episode_y_position_std': Array(311.64075, dtype=float32), 'eval/episode_y_velocity_std': Array(103.428314, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55911302566528, 'eval/sps': 937.3230183176669, 'num_steps': 30801920}
{'eval/walltime': 51632.00938487053, 'training/sps': 2944.221384101008, 'training/walltime': 10511.013478040695, 'training/entropy_loss': Array(0.01394433, dtype=float32), 'training/policy_loss': Array(0.00910281, dtype=float32), 'training/total_loss': Array(0.16754791, dtype=float32), 'training/v_loss': Array(0.14450076, dtype=float32), 'eval/episode_distance_from_origin': Array(5608.168, dtype=float32), 'eval/episode_distance_reward': Array(19.951488, dtype=float32), 'eval/episode_forward_reward': Array(3325.2317, dtype=float32), 'eval/episode_reward': Array(3336.129, dtype=float32), 'eval/episode_reward_alive': Array(379.5039, dtype=float32), 'eval/episode_reward_linvel': Array(3325.2317, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.55823, dtype=float32), 'eval/episode_x_position': Array(5558.7383, dtype=float32), 'eval/episode_x_velocity': Array(665.04626, dtype=float32), 'eval/episode_y_position': Array(-181.68524, dtype=float32), 'eval/episode_y_velocity': Array(-140.54639, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.98743, dtype=float32), 'eval/episode_distance_reward_std': Array(5.092967, dtype=float32), 'eval/episode_forward_reward_std': Array(848.8201, dtype=float32), 'eval/episode_reward_std': Array(831.91974, dtype=float32), 'eval/episode_reward_alive_std': Array(62.56916, dtype=float32), 'eval/episode_reward_linvel_std': Array(848.8201, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.49405, dtype=float32), 'eval/episode_x_position_std': Array(425.07172, dtype=float32), 'eval/episode_x_velocity_std': Array(169.7641, dtype=float32), 'eval/episode_y_position_std': Array(282.55435, dtype=float32), 'eval/episode_y_velocity_std': Array(95.73887, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5978662967682, 'eval/sps': 937.057096645355, 'num_steps': 30883840}
{'eval/walltime': 51768.44719696045, 'training/sps': 2937.3869463308306, 'training/walltime': 10538.902210950851, 'training/entropy_loss': Array(0.01308434, dtype=float32), 'training/policy_loss': Array(0.00355859, dtype=float32), 'training/total_loss': Array(0.12975642, dtype=float32), 'training/v_loss': Array(0.11311349, dtype=float32), 'eval/episode_distance_from_origin': Array(5618.2734, dtype=float32), 'eval/episode_distance_reward': Array(19.76447, dtype=float32), 'eval/episode_forward_reward': Array(3294.0625, dtype=float32), 'eval/episode_reward': Array(3307.1387, dtype=float32), 'eval/episode_reward_alive': Array(385.60156, dtype=float32), 'eval/episode_reward_linvel': Array(3294.0625, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.2897, dtype=float32), 'eval/episode_x_position': Array(5568.7935, dtype=float32), 'eval/episode_x_velocity': Array(658.8125, dtype=float32), 'eval/episode_y_position': Array(-145.14352, dtype=float32), 'eval/episode_y_velocity': Array(-128.02603, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.5482, dtype=float32), 'eval/episode_distance_reward_std': Array(5.140092, dtype=float32), 'eval/episode_forward_reward_std': Array(856.67554, dtype=float32), 'eval/episode_reward_std': Array(842.35034, dtype=float32), 'eval/episode_reward_alive_std': Array(59.885513, dtype=float32), 'eval/episode_reward_linvel_std': Array(856.67554, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.506702, dtype=float32), 'eval/episode_x_position_std': Array(441.39856, dtype=float32), 'eval/episode_x_velocity_std': Array(171.33496, dtype=float32), 'eval/episode_y_position_std': Array(311.4302, dtype=float32), 'eval/episode_y_velocity_std': Array(107.96784, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43781208992004, 'eval/sps': 938.1563515225599, 'num_steps': 30965760}
{'eval/walltime': 51904.99928355217, 'training/sps': 2949.5584382968364, 'training/walltime': 10566.675859689713, 'training/entropy_loss': Array(0.01309975, dtype=float32), 'training/policy_loss': Array(0.00253496, dtype=float32), 'training/total_loss': Array(0.10544425, dtype=float32), 'training/v_loss': Array(0.08980955, dtype=float32), 'eval/episode_distance_from_origin': Array(5646.92, dtype=float32), 'eval/episode_distance_reward': Array(20.108696, dtype=float32), 'eval/episode_forward_reward': Array(3351.433, dtype=float32), 'eval/episode_reward': Array(3358.1245, dtype=float32), 'eval/episode_reward_alive': Array(374.96094, dtype=float32), 'eval/episode_reward_linvel': Array(3351.433, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.37793, dtype=float32), 'eval/episode_x_position': Array(5598.397, dtype=float32), 'eval/episode_x_velocity': Array(670.2865, dtype=float32), 'eval/episode_y_position': Array(-176.55661, dtype=float32), 'eval/episode_y_velocity': Array(-146.0542, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.91736, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3146205, dtype=float32), 'eval/episode_forward_reward_std': Array(885.76263, dtype=float32), 'eval/episode_reward_std': Array(865.0524, dtype=float32), 'eval/episode_reward_alive_std': Array(66.61813, dtype=float32), 'eval/episode_reward_linvel_std': Array(885.76263, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.331549, dtype=float32), 'eval/episode_x_position_std': Array(458.4311, dtype=float32), 'eval/episode_x_velocity_std': Array(177.15253, dtype=float32), 'eval/episode_y_position_std': Array(262.10413, dtype=float32), 'eval/episode_y_velocity_std': Array(100.864944, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55208659172058, 'eval/sps': 937.3712492780091, 'num_steps': 31047680}
{'eval/walltime': 52041.56157517433, 'training/sps': 2932.8760260791, 'training/walltime': 10594.607486963272, 'training/entropy_loss': Array(0.01304284, dtype=float32), 'training/policy_loss': Array(0.00241521, dtype=float32), 'training/total_loss': Array(0.0971836, dtype=float32), 'training/v_loss': Array(0.08172555, dtype=float32), 'eval/episode_distance_from_origin': Array(5688.7515, dtype=float32), 'eval/episode_distance_reward': Array(20.36217, dtype=float32), 'eval/episode_forward_reward': Array(3393.6787, dtype=float32), 'eval/episode_reward': Array(3409.419, dtype=float32), 'eval/episode_reward_alive': Array(386.36328, dtype=float32), 'eval/episode_reward_linvel': Array(3393.6787, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.98486, dtype=float32), 'eval/episode_x_position': Array(5640.5103, dtype=float32), 'eval/episode_x_velocity': Array(678.73566, dtype=float32), 'eval/episode_y_position': Array(-128.34633, dtype=float32), 'eval/episode_y_velocity': Array(-128.17105, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.3674, dtype=float32), 'eval/episode_distance_reward_std': Array(5.120751, dtype=float32), 'eval/episode_forward_reward_std': Array(853.45105, dtype=float32), 'eval/episode_reward_std': Array(837.79504, dtype=float32), 'eval/episode_reward_alive_std': Array(60.661705, dtype=float32), 'eval/episode_reward_linvel_std': Array(853.45105, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.96923, dtype=float32), 'eval/episode_x_position_std': Array(472.0333, dtype=float32), 'eval/episode_x_velocity_std': Array(170.69022, dtype=float32), 'eval/episode_y_position_std': Array(292.91977, dtype=float32), 'eval/episode_y_velocity_std': Array(98.56536, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56229162216187, 'eval/sps': 937.3012013751801, 'num_steps': 31129600}
{'eval/walltime': 52178.14827775955, 'training/sps': 2947.8659559796183, 'training/walltime': 10622.39708161354, 'training/entropy_loss': Array(0.01318979, dtype=float32), 'training/policy_loss': Array(0.00253077, dtype=float32), 'training/total_loss': Array(0.10197242, dtype=float32), 'training/v_loss': Array(0.08625187, dtype=float32), 'eval/episode_distance_from_origin': Array(5688.754, dtype=float32), 'eval/episode_distance_reward': Array(20.23457, dtype=float32), 'eval/episode_forward_reward': Array(3372.411, dtype=float32), 'eval/episode_reward': Array(3384.5896, dtype=float32), 'eval/episode_reward_alive': Array(379.1836, dtype=float32), 'eval/episode_reward_linvel': Array(3372.411, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.24, dtype=float32), 'eval/episode_x_position': Array(5638.343, dtype=float32), 'eval/episode_x_velocity': Array(674.4823, dtype=float32), 'eval/episode_y_position': Array(-157.082, dtype=float32), 'eval/episode_y_velocity': Array(-137.04482, dtype=float32), 'eval/episode_distance_from_origin_std': Array(459.4478, dtype=float32), 'eval/episode_distance_reward_std': Array(4.850368, dtype=float32), 'eval/episode_forward_reward_std': Array(808.3886, dtype=float32), 'eval/episode_reward_std': Array(791.5565, dtype=float32), 'eval/episode_reward_alive_std': Array(63.32835, dtype=float32), 'eval/episode_reward_linvel_std': Array(808.3886, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.25008, dtype=float32), 'eval/episode_x_position_std': Array(459.01624, dtype=float32), 'eval/episode_x_velocity_std': Array(161.67776, dtype=float32), 'eval/episode_y_position_std': Array(306.8544, dtype=float32), 'eval/episode_y_velocity_std': Array(100.71359, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58670258522034, 'eval/sps': 937.1336856172887, 'num_steps': 31211520}
{'eval/walltime': 52314.67781877518, 'training/sps': 2938.371119012676, 'training/walltime': 10650.276473522186, 'training/entropy_loss': Array(0.0096631, dtype=float32), 'training/policy_loss': Array(0.00192281, dtype=float32), 'training/total_loss': Array(0.06845634, dtype=float32), 'training/v_loss': Array(0.05687043, dtype=float32), 'eval/episode_distance_from_origin': Array(5636.3975, dtype=float32), 'eval/episode_distance_reward': Array(20.258041, dtype=float32), 'eval/episode_forward_reward': Array(3376.3228, dtype=float32), 'eval/episode_reward': Array(3387.6233, dtype=float32), 'eval/episode_reward_alive': Array(377.13672, dtype=float32), 'eval/episode_reward_linvel': Array(3376.3228, dtype=float32), 'eval/episode_reward_quadctrl': Array(-386.09363, dtype=float32), 'eval/episode_x_position': Array(5583.0566, dtype=float32), 'eval/episode_x_velocity': Array(675.26447, dtype=float32), 'eval/episode_y_position': Array(-207.0708, dtype=float32), 'eval/episode_y_velocity': Array(-152.49948, dtype=float32), 'eval/episode_distance_from_origin_std': Array(515.40094, dtype=float32), 'eval/episode_distance_reward_std': Array(5.582488, dtype=float32), 'eval/episode_forward_reward_std': Array(930.4081, dtype=float32), 'eval/episode_reward_std': Array(914.0569, dtype=float32), 'eval/episode_reward_alive_std': Array(62.80033, dtype=float32), 'eval/episode_reward_linvel_std': Array(930.4081, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.570024, dtype=float32), 'eval/episode_x_position_std': Array(513.4161, dtype=float32), 'eval/episode_x_velocity_std': Array(186.08148, dtype=float32), 'eval/episode_y_position_std': Array(301.41974, dtype=float32), 'eval/episode_y_velocity_std': Array(105.08453, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.529541015625, 'eval/sps': 937.5260405024811, 'num_steps': 31293440}
{'eval/walltime': 52451.27602934837, 'training/sps': 2942.493768241449, 'training/walltime': 10678.116804361343, 'training/entropy_loss': Array(0.01495751, dtype=float32), 'training/policy_loss': Array(0.00957198, dtype=float32), 'training/total_loss': Array(0.15451474, dtype=float32), 'training/v_loss': Array(0.12998524, dtype=float32), 'eval/episode_distance_from_origin': Array(5620.062, dtype=float32), 'eval/episode_distance_reward': Array(19.789377, dtype=float32), 'eval/episode_forward_reward': Array(3298.2134, dtype=float32), 'eval/episode_reward': Array(3310.4004, dtype=float32), 'eval/episode_reward_alive': Array(382.83594, dtype=float32), 'eval/episode_reward_linvel': Array(3298.2134, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.43802, dtype=float32), 'eval/episode_x_position': Array(5566.587, dtype=float32), 'eval/episode_x_velocity': Array(659.64264, dtype=float32), 'eval/episode_y_position': Array(-235.27908, dtype=float32), 'eval/episode_y_velocity': Array(-158.53625, dtype=float32), 'eval/episode_distance_from_origin_std': Array(415.59177, dtype=float32), 'eval/episode_distance_reward_std': Array(4.662772, dtype=float32), 'eval/episode_forward_reward_std': Array(777.12225, dtype=float32), 'eval/episode_reward_std': Array(767.3231, dtype=float32), 'eval/episode_reward_alive_std': Array(55.448177, dtype=float32), 'eval/episode_reward_linvel_std': Array(777.12225, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.186396, dtype=float32), 'eval/episode_x_position_std': Array(410.8675, dtype=float32), 'eval/episode_x_velocity_std': Array(155.42448, dtype=float32), 'eval/episode_y_position_std': Array(263.50302, dtype=float32), 'eval/episode_y_velocity_std': Array(91.3548, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5982105731964, 'eval/sps': 937.0547349257621, 'num_steps': 31375360}
{'eval/walltime': 52587.83826303482, 'training/sps': 2937.9955237809545, 'training/walltime': 10705.999760389328, 'training/entropy_loss': Array(0.01386057, dtype=float32), 'training/policy_loss': Array(0.00628977, dtype=float32), 'training/total_loss': Array(0.15401018, dtype=float32), 'training/v_loss': Array(0.13385984, dtype=float32), 'eval/episode_distance_from_origin': Array(5675.261, dtype=float32), 'eval/episode_distance_reward': Array(20.130116, dtype=float32), 'eval/episode_forward_reward': Array(3355.0015, dtype=float32), 'eval/episode_reward': Array(3367.2622, dtype=float32), 'eval/episode_reward_alive': Array(380.98828, dtype=float32), 'eval/episode_reward_linvel': Array(3355.0015, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.8579, dtype=float32), 'eval/episode_x_position': Array(5622.4585, dtype=float32), 'eval/episode_x_velocity': Array(671.00037, dtype=float32), 'eval/episode_y_position': Array(-237.77577, dtype=float32), 'eval/episode_y_velocity': Array(-157.04562, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.50342, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9070835, dtype=float32), 'eval/episode_forward_reward_std': Array(817.84094, dtype=float32), 'eval/episode_reward_std': Array(795.84717, dtype=float32), 'eval/episode_reward_alive_std': Array(60.896507, dtype=float32), 'eval/episode_reward_linvel_std': Array(817.84094, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.817894, dtype=float32), 'eval/episode_x_position_std': Array(448.66122, dtype=float32), 'eval/episode_x_velocity_std': Array(163.56818, dtype=float32), 'eval/episode_y_position_std': Array(259.65308, dtype=float32), 'eval/episode_y_velocity_std': Array(90.534706, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56223368644714, 'eval/sps': 937.3015990196352, 'num_steps': 31457280}
{'eval/walltime': 52724.42161941528, 'training/sps': 2930.495833947767, 'training/walltime': 10733.954074144363, 'training/entropy_loss': Array(0.01277698, dtype=float32), 'training/policy_loss': Array(0.00364947, dtype=float32), 'training/total_loss': Array(0.12795268, dtype=float32), 'training/v_loss': Array(0.11152624, dtype=float32), 'eval/episode_distance_from_origin': Array(5665.0337, dtype=float32), 'eval/episode_distance_reward': Array(20.17333, dtype=float32), 'eval/episode_forward_reward': Array(3362.2048, dtype=float32), 'eval/episode_reward': Array(3376.8716, dtype=float32), 'eval/episode_reward_alive': Array(376.53125, dtype=float32), 'eval/episode_reward_linvel': Array(3362.2048, dtype=float32), 'eval/episode_reward_quadctrl': Array(-382.03717, dtype=float32), 'eval/episode_x_position': Array(5609.491, dtype=float32), 'eval/episode_x_velocity': Array(672.441, dtype=float32), 'eval/episode_y_position': Array(-237.95596, dtype=float32), 'eval/episode_y_velocity': Array(-159.01208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(424.313, dtype=float32), 'eval/episode_distance_reward_std': Array(4.606257, dtype=float32), 'eval/episode_forward_reward_std': Array(767.70306, dtype=float32), 'eval/episode_reward_std': Array(752.628, dtype=float32), 'eval/episode_reward_alive_std': Array(63.364296, dtype=float32), 'eval/episode_reward_linvel_std': Array(767.70306, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.15986, dtype=float32), 'eval/episode_x_position_std': Array(419.13202, dtype=float32), 'eval/episode_x_velocity_std': Array(153.54059, dtype=float32), 'eval/episode_y_position_std': Array(309.33545, dtype=float32), 'eval/episode_y_velocity_std': Array(103.34866, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58335638046265, 'eval/sps': 937.1566447924072, 'num_steps': 31539200}
{'eval/walltime': 52861.079151153564, 'training/sps': 2933.7514406101473, 'training/walltime': 10761.877366781235, 'training/entropy_loss': Array(0.01270004, dtype=float32), 'training/policy_loss': Array(0.00239074, dtype=float32), 'training/total_loss': Array(0.11096501, dtype=float32), 'training/v_loss': Array(0.09587422, dtype=float32), 'eval/episode_distance_from_origin': Array(5628.841, dtype=float32), 'eval/episode_distance_reward': Array(20.166042, dtype=float32), 'eval/episode_forward_reward': Array(3360.9902, dtype=float32), 'eval/episode_reward': Array(3369.8965, dtype=float32), 'eval/episode_reward_alive': Array(370.2578, dtype=float32), 'eval/episode_reward_linvel': Array(3360.9902, dtype=float32), 'eval/episode_reward_quadctrl': Array(-381.51688, dtype=float32), 'eval/episode_x_position': Array(5572.19, dtype=float32), 'eval/episode_x_velocity': Array(672.198, dtype=float32), 'eval/episode_y_position': Array(-246.16933, dtype=float32), 'eval/episode_y_velocity': Array(-170.99998, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.75995, dtype=float32), 'eval/episode_distance_reward_std': Array(4.389329, dtype=float32), 'eval/episode_forward_reward_std': Array(731.5487, dtype=float32), 'eval/episode_reward_std': Array(715.3713, dtype=float32), 'eval/episode_reward_alive_std': Array(60.026882, dtype=float32), 'eval/episode_reward_linvel_std': Array(731.5487, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.492336, dtype=float32), 'eval/episode_x_position_std': Array(411.1464, dtype=float32), 'eval/episode_x_velocity_std': Array(146.30981, dtype=float32), 'eval/episode_y_position_std': Array(266.12756, dtype=float32), 'eval/episode_y_velocity_std': Array(90.7952, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65753173828125, 'eval/sps': 936.6479722840182, 'num_steps': 31621120}
{'eval/walltime': 52997.66739273071, 'training/sps': 2939.7496768689134, 'training/walltime': 10789.743685007095, 'training/entropy_loss': Array(0.01266379, dtype=float32), 'training/policy_loss': Array(0.01482302, dtype=float32), 'training/total_loss': Array(0.12038454, dtype=float32), 'training/v_loss': Array(0.09289773, dtype=float32), 'eval/episode_distance_from_origin': Array(5720.918, dtype=float32), 'eval/episode_distance_reward': Array(20.965174, dtype=float32), 'eval/episode_forward_reward': Array(3494.1782, dtype=float32), 'eval/episode_reward': Array(3514.6118, dtype=float32), 'eval/episode_reward_alive': Array(389.05078, dtype=float32), 'eval/episode_reward_linvel': Array(3494.1782, dtype=float32), 'eval/episode_reward_quadctrl': Array(-389.5829, dtype=float32), 'eval/episode_x_position': Array(5669.955, dtype=float32), 'eval/episode_x_velocity': Array(698.83575, dtype=float32), 'eval/episode_y_position': Array(-186.34958, dtype=float32), 'eval/episode_y_velocity': Array(-145.8667, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.9885, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9863577, dtype=float32), 'eval/episode_forward_reward_std': Array(831.0525, dtype=float32), 'eval/episode_reward_std': Array(815.7877, dtype=float32), 'eval/episode_reward_alive_std': Array(55.285652, dtype=float32), 'eval/episode_reward_linvel_std': Array(831.0525, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.609993, dtype=float32), 'eval/episode_x_position_std': Array(454.0008, dtype=float32), 'eval/episode_x_velocity_std': Array(166.21053, dtype=float32), 'eval/episode_y_position_std': Array(298.40244, dtype=float32), 'eval/episode_y_velocity_std': Array(97.91405, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58824157714844, 'eval/sps': 937.1231265738377, 'num_steps': 31703040}
{'eval/walltime': 53134.212137937546, 'training/sps': 2941.775901305441, 'training/walltime': 10817.590809583664, 'training/entropy_loss': Array(0.0097571, dtype=float32), 'training/policy_loss': Array(0.00859776, dtype=float32), 'training/total_loss': Array(0.07870704, dtype=float32), 'training/v_loss': Array(0.06035218, dtype=float32), 'eval/episode_distance_from_origin': Array(5668.0107, dtype=float32), 'eval/episode_distance_reward': Array(20.77373, dtype=float32), 'eval/episode_forward_reward': Array(3462.2715, dtype=float32), 'eval/episode_reward': Array(3483.2275, dtype=float32), 'eval/episode_reward_alive': Array(388.5547, dtype=float32), 'eval/episode_reward_linvel': Array(3462.2715, dtype=float32), 'eval/episode_reward_quadctrl': Array(-388.3722, dtype=float32), 'eval/episode_x_position': Array(5616.7, dtype=float32), 'eval/episode_x_velocity': Array(692.4542, dtype=float32), 'eval/episode_y_position': Array(-231.60971, dtype=float32), 'eval/episode_y_velocity': Array(-153.2489, dtype=float32), 'eval/episode_distance_from_origin_std': Array(459.75052, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2817163, dtype=float32), 'eval/episode_forward_reward_std': Array(880.2789, dtype=float32), 'eval/episode_reward_std': Array(864.9762, dtype=float32), 'eval/episode_reward_alive_std': Array(51.854824, dtype=float32), 'eval/episode_reward_linvel_std': Array(880.2789, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.431252, dtype=float32), 'eval/episode_x_position_std': Array(456.5132, dtype=float32), 'eval/episode_x_velocity_std': Array(176.0557, dtype=float32), 'eval/episode_y_position_std': Array(255.88205, dtype=float32), 'eval/episode_y_velocity_std': Array(90.3671, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54474520683289, 'eval/sps': 937.4216474322053, 'num_steps': 31784960}
{'eval/walltime': 53270.74046707153, 'training/sps': 2952.5490787684566, 'training/walltime': 10845.336326360703, 'training/entropy_loss': Array(0.01482214, dtype=float32), 'training/policy_loss': Array(0.00564908, dtype=float32), 'training/total_loss': Array(0.13209105, dtype=float32), 'training/v_loss': Array(0.11161982, dtype=float32), 'eval/episode_distance_from_origin': Array(5667.104, dtype=float32), 'eval/episode_distance_reward': Array(19.858707, dtype=float32), 'eval/episode_forward_reward': Array(3309.7683, dtype=float32), 'eval/episode_reward': Array(3338.3892, dtype=float32), 'eval/episode_reward_alive': Array(399.17188, dtype=float32), 'eval/episode_reward_linvel': Array(3309.7683, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.4093, dtype=float32), 'eval/episode_x_position': Array(5618.334, dtype=float32), 'eval/episode_x_velocity': Array(661.9536, dtype=float32), 'eval/episode_y_position': Array(-165.11736, dtype=float32), 'eval/episode_y_velocity': Array(-124.77735, dtype=float32), 'eval/episode_distance_from_origin_std': Array(484.5985, dtype=float32), 'eval/episode_distance_reward_std': Array(5.588285, dtype=float32), 'eval/episode_forward_reward_std': Array(931.373, dtype=float32), 'eval/episode_reward_std': Array(911.339, dtype=float32), 'eval/episode_reward_alive_std': Array(58.448242, dtype=float32), 'eval/episode_reward_linvel_std': Array(931.373, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.01275, dtype=float32), 'eval/episode_x_position_std': Array(482.92188, dtype=float32), 'eval/episode_x_velocity_std': Array(186.27457, dtype=float32), 'eval/episode_y_position_std': Array(295.5693, dtype=float32), 'eval/episode_y_velocity_std': Array(101.85013, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52832913398743, 'eval/sps': 937.534362369455, 'num_steps': 31866880}
{'eval/walltime': 53407.28917479515, 'training/sps': 2946.261055465759, 'training/walltime': 10873.141058683395, 'training/entropy_loss': Array(0.01337792, dtype=float32), 'training/policy_loss': Array(0.00405983, dtype=float32), 'training/total_loss': Array(0.14942366, dtype=float32), 'training/v_loss': Array(0.1319859, dtype=float32), 'eval/episode_distance_from_origin': Array(5753.8633, dtype=float32), 'eval/episode_distance_reward': Array(20.926857, dtype=float32), 'eval/episode_forward_reward': Array(3487.7927, dtype=float32), 'eval/episode_reward': Array(3505.0242, dtype=float32), 'eval/episode_reward_alive': Array(393.84766, dtype=float32), 'eval/episode_reward_linvel': Array(3487.7927, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.54315, dtype=float32), 'eval/episode_x_position': Array(5706.583, dtype=float32), 'eval/episode_x_velocity': Array(697.5586, dtype=float32), 'eval/episode_y_position': Array(-167.03737, dtype=float32), 'eval/episode_y_velocity': Array(-132.02283, dtype=float32), 'eval/episode_distance_from_origin_std': Array(455.70175, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2820377, dtype=float32), 'eval/episode_forward_reward_std': Array(880.3318, dtype=float32), 'eval/episode_reward_std': Array(871.3271, dtype=float32), 'eval/episode_reward_alive_std': Array(54.829586, dtype=float32), 'eval/episode_reward_linvel_std': Array(880.3318, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.78285, dtype=float32), 'eval/episode_x_position_std': Array(452.95828, dtype=float32), 'eval/episode_x_velocity_std': Array(176.06633, dtype=float32), 'eval/episode_y_position_std': Array(280.45554, dtype=float32), 'eval/episode_y_velocity_std': Array(94.797615, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54870772361755, 'eval/sps': 937.3944443258985, 'num_steps': 31948800}
{'eval/walltime': 53543.79580593109, 'training/sps': 2949.223618953081, 'training/walltime': 10900.917860507965, 'training/entropy_loss': Array(0.01289693, dtype=float32), 'training/policy_loss': Array(0.00513935, dtype=float32), 'training/total_loss': Array(0.13438793, dtype=float32), 'training/v_loss': Array(0.11635163, dtype=float32), 'eval/episode_distance_from_origin': Array(5672.5967, dtype=float32), 'eval/episode_distance_reward': Array(20.606487, dtype=float32), 'eval/episode_forward_reward': Array(3434.398, dtype=float32), 'eval/episode_reward': Array(3460.0527, dtype=float32), 'eval/episode_reward_alive': Array(392.76172, dtype=float32), 'eval/episode_reward_linvel': Array(3434.398, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.7133, dtype=float32), 'eval/episode_x_position': Array(5620.3774, dtype=float32), 'eval/episode_x_velocity': Array(686.8795, dtype=float32), 'eval/episode_y_position': Array(-179.919, dtype=float32), 'eval/episode_y_velocity': Array(-137.5781, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.31882, dtype=float32), 'eval/episode_distance_reward_std': Array(5.544456, dtype=float32), 'eval/episode_forward_reward_std': Array(924.0688, dtype=float32), 'eval/episode_reward_std': Array(904.962, dtype=float32), 'eval/episode_reward_alive_std': Array(54.106228, dtype=float32), 'eval/episode_reward_linvel_std': Array(924.0688, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.99702, dtype=float32), 'eval/episode_x_position_std': Array(480.37073, dtype=float32), 'eval/episode_x_velocity_std': Array(184.81375, dtype=float32), 'eval/episode_y_position_std': Array(318.92856, dtype=float32), 'eval/episode_y_velocity_std': Array(107.70465, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50663113594055, 'eval/sps': 937.6833853040501, 'num_steps': 32030720}
{'eval/walltime': 53680.24427008629, 'training/sps': 2946.171701364605, 'training/walltime': 10928.723436117172, 'training/entropy_loss': Array(0.01295757, dtype=float32), 'training/policy_loss': Array(0.0019116, dtype=float32), 'training/total_loss': Array(0.1300867, dtype=float32), 'training/v_loss': Array(0.11521754, dtype=float32), 'eval/episode_distance_from_origin': Array(5805.5146, dtype=float32), 'eval/episode_distance_reward': Array(21.692343, dtype=float32), 'eval/episode_forward_reward': Array(3615.3726, dtype=float32), 'eval/episode_reward': Array(3636.651, dtype=float32), 'eval/episode_reward_alive': Array(389.59375, dtype=float32), 'eval/episode_reward_linvel': Array(3615.3726, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.00787, dtype=float32), 'eval/episode_x_position': Array(5755.6895, dtype=float32), 'eval/episode_x_velocity': Array(723.0745, dtype=float32), 'eval/episode_y_position': Array(-216.04726, dtype=float32), 'eval/episode_y_velocity': Array(-147.58458, dtype=float32), 'eval/episode_distance_from_origin_std': Array(504.1529, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7803745, dtype=float32), 'eval/episode_forward_reward_std': Array(963.3878, dtype=float32), 'eval/episode_reward_std': Array(943.5342, dtype=float32), 'eval/episode_reward_alive_std': Array(60.06818, dtype=float32), 'eval/episode_reward_linvel_std': Array(963.3878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.332567, dtype=float32), 'eval/episode_x_position_std': Array(505.15912, dtype=float32), 'eval/episode_x_velocity_std': Array(192.67766, dtype=float32), 'eval/episode_y_position_std': Array(274.75964, dtype=float32), 'eval/episode_y_velocity_std': Array(95.98008, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44846415519714, 'eval/sps': 938.0831128623931, 'num_steps': 32112640}
{'eval/walltime': 53816.76204943657, 'training/sps': 2952.20487976719, 'training/walltime': 10956.472187757492, 'training/entropy_loss': Array(0.01330413, dtype=float32), 'training/policy_loss': Array(0.00423683, dtype=float32), 'training/total_loss': Array(0.107136, dtype=float32), 'training/v_loss': Array(0.08959503, dtype=float32), 'eval/episode_distance_from_origin': Array(5765.9556, dtype=float32), 'eval/episode_distance_reward': Array(21.329494, dtype=float32), 'eval/episode_forward_reward': Array(3554.8984, dtype=float32), 'eval/episode_reward': Array(3568.2534, dtype=float32), 'eval/episode_reward_alive': Array(384.65625, dtype=float32), 'eval/episode_reward_linvel': Array(3554.8984, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.63046, dtype=float32), 'eval/episode_x_position': Array(5713.4375, dtype=float32), 'eval/episode_x_velocity': Array(710.9797, dtype=float32), 'eval/episode_y_position': Array(-224.2684, dtype=float32), 'eval/episode_y_velocity': Array(-152.30383, dtype=float32), 'eval/episode_distance_from_origin_std': Array(437.65863, dtype=float32), 'eval/episode_distance_reward_std': Array(4.946067, dtype=float32), 'eval/episode_forward_reward_std': Array(824.3372, dtype=float32), 'eval/episode_reward_std': Array(803.73645, dtype=float32), 'eval/episode_reward_alive_std': Array(56.44251, dtype=float32), 'eval/episode_reward_linvel_std': Array(824.3372, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.138973, dtype=float32), 'eval/episode_x_position_std': Array(433.4671, dtype=float32), 'eval/episode_x_velocity_std': Array(164.86739, dtype=float32), 'eval/episode_y_position_std': Array(289.01694, dtype=float32), 'eval/episode_y_velocity_std': Array(97.95374, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51777935028076, 'eval/sps': 937.606812894124, 'num_steps': 32194560}
{'eval/walltime': 53953.19293117523, 'training/sps': 2942.985203284054, 'training/walltime': 10984.307869672775, 'training/entropy_loss': Array(0.01137491, dtype=float32), 'training/policy_loss': Array(0.01552967, dtype=float32), 'training/total_loss': Array(0.08580223, dtype=float32), 'training/v_loss': Array(0.05889765, dtype=float32), 'eval/episode_distance_from_origin': Array(5709.141, dtype=float32), 'eval/episode_distance_reward': Array(20.800236, dtype=float32), 'eval/episode_forward_reward': Array(3466.6895, dtype=float32), 'eval/episode_reward': Array(3481.1348, dtype=float32), 'eval/episode_reward_alive': Array(393.59375, dtype=float32), 'eval/episode_reward_linvel': Array(3466.6895, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.94846, dtype=float32), 'eval/episode_x_position': Array(5657.2266, dtype=float32), 'eval/episode_x_velocity': Array(693.3379, dtype=float32), 'eval/episode_y_position': Array(-212.17355, dtype=float32), 'eval/episode_y_velocity': Array(-143.48761, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.17343, dtype=float32), 'eval/episode_distance_reward_std': Array(5.395737, dtype=float32), 'eval/episode_forward_reward_std': Array(899.2816, dtype=float32), 'eval/episode_reward_std': Array(890.0684, dtype=float32), 'eval/episode_reward_alive_std': Array(57.57294, dtype=float32), 'eval/episode_reward_linvel_std': Array(899.2816, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.524796, dtype=float32), 'eval/episode_x_position_std': Array(449.94354, dtype=float32), 'eval/episode_x_velocity_std': Array(179.85637, dtype=float32), 'eval/episode_y_position_std': Array(300.28094, dtype=float32), 'eval/episode_y_velocity_std': Array(101.27565, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43088173866272, 'eval/sps': 938.204007544184, 'num_steps': 32276480}
{'eval/walltime': 54089.76594376564, 'training/sps': 2953.136035872178, 'training/walltime': 11012.04787182808, 'training/entropy_loss': Array(0.0124205, dtype=float32), 'training/policy_loss': Array(0.00396681, dtype=float32), 'training/total_loss': Array(0.1024131, dtype=float32), 'training/v_loss': Array(0.08602579, dtype=float32), 'eval/episode_distance_from_origin': Array(5784.92, dtype=float32), 'eval/episode_distance_reward': Array(21.413607, dtype=float32), 'eval/episode_forward_reward': Array(3568.9158, dtype=float32), 'eval/episode_reward': Array(3581.277, dtype=float32), 'eval/episode_reward_alive': Array(384.0547, dtype=float32), 'eval/episode_reward_linvel': Array(3568.9158, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.1073, dtype=float32), 'eval/episode_x_position': Array(5731.755, dtype=float32), 'eval/episode_x_velocity': Array(713.78314, dtype=float32), 'eval/episode_y_position': Array(-246.0481, dtype=float32), 'eval/episode_y_velocity': Array(-155.17984, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.21448, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6170144, dtype=float32), 'eval/episode_forward_reward_std': Array(936.1606, dtype=float32), 'eval/episode_reward_std': Array(922.7393, dtype=float32), 'eval/episode_reward_alive_std': Array(59.53988, dtype=float32), 'eval/episode_reward_linvel_std': Array(936.1606, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.329702, dtype=float32), 'eval/episode_x_position_std': Array(490.67804, dtype=float32), 'eval/episode_x_velocity_std': Array(187.23201, dtype=float32), 'eval/episode_y_position_std': Array(293.23315, dtype=float32), 'eval/episode_y_velocity_std': Array(96.13988, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57301259040833, 'eval/sps': 937.2276233217513, 'num_steps': 32358400}
{'eval/walltime': 54226.204612493515, 'training/sps': 2940.6188062477327, 'training/walltime': 11039.905953884125, 'training/entropy_loss': Array(0.0147597, dtype=float32), 'training/policy_loss': Array(0.00502042, dtype=float32), 'training/total_loss': Array(0.17805697, dtype=float32), 'training/v_loss': Array(0.15827686, dtype=float32), 'eval/episode_distance_from_origin': Array(5828.547, dtype=float32), 'eval/episode_distance_reward': Array(21.55947, dtype=float32), 'eval/episode_forward_reward': Array(3593.2285, dtype=float32), 'eval/episode_reward': Array(3611.497, dtype=float32), 'eval/episode_reward_alive': Array(392.04688, dtype=float32), 'eval/episode_reward_linvel': Array(3593.2285, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.33707, dtype=float32), 'eval/episode_x_position': Array(5779.918, dtype=float32), 'eval/episode_x_velocity': Array(718.64557, dtype=float32), 'eval/episode_y_position': Array(-197.18945, dtype=float32), 'eval/episode_y_velocity': Array(-138.15926, dtype=float32), 'eval/episode_distance_from_origin_std': Array(477.19882, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3805127, dtype=float32), 'eval/episode_forward_reward_std': Array(896.74445, dtype=float32), 'eval/episode_reward_std': Array(879.7071, dtype=float32), 'eval/episode_reward_alive_std': Array(59.52538, dtype=float32), 'eval/episode_reward_linvel_std': Array(896.74445, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.23099, dtype=float32), 'eval/episode_x_position_std': Array(473.89703, dtype=float32), 'eval/episode_x_velocity_std': Array(179.34892, dtype=float32), 'eval/episode_y_position_std': Array(290.99588, dtype=float32), 'eval/episode_y_velocity_std': Array(95.9128, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43866872787476, 'eval/sps': 938.1504612544587, 'num_steps': 32440320}
{'eval/walltime': 54362.71325659752, 'training/sps': 2935.025553709258, 'training/walltime': 11067.817124843597, 'training/entropy_loss': Array(0.01348389, dtype=float32), 'training/policy_loss': Array(0.00444508, dtype=float32), 'training/total_loss': Array(0.11834376, dtype=float32), 'training/v_loss': Array(0.10041478, dtype=float32), 'eval/episode_distance_from_origin': Array(5705.3716, dtype=float32), 'eval/episode_distance_reward': Array(20.895912, dtype=float32), 'eval/episode_forward_reward': Array(3482.6343, dtype=float32), 'eval/episode_reward': Array(3502.0024, dtype=float32), 'eval/episode_reward_alive': Array(388.73828, dtype=float32), 'eval/episode_reward_linvel': Array(3482.6343, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.26642, dtype=float32), 'eval/episode_x_position': Array(5656.093, dtype=float32), 'eval/episode_x_velocity': Array(696.5269, dtype=float32), 'eval/episode_y_position': Array(-228.9417, dtype=float32), 'eval/episode_y_velocity': Array(-152.77298, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.9288, dtype=float32), 'eval/episode_distance_reward_std': Array(5.596326, dtype=float32), 'eval/episode_forward_reward_std': Array(932.713, dtype=float32), 'eval/episode_reward_std': Array(913.02826, dtype=float32), 'eval/episode_reward_alive_std': Array(59.06984, dtype=float32), 'eval/episode_reward_linvel_std': Array(932.713, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.96529, dtype=float32), 'eval/episode_x_position_std': Array(457.44186, dtype=float32), 'eval/episode_x_velocity_std': Array(186.54254, dtype=float32), 'eval/episode_y_position_std': Array(236.68138, dtype=float32), 'eval/episode_y_velocity_std': Array(91.45214, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5086441040039, 'eval/sps': 937.6695581451875, 'num_steps': 32522240}
{'eval/walltime': 54499.15591931343, 'training/sps': 2937.918150379358, 'training/walltime': 11095.700815200806, 'training/entropy_loss': Array(0.0138038, dtype=float32), 'training/policy_loss': Array(0.00432081, dtype=float32), 'training/total_loss': Array(0.12507653, dtype=float32), 'training/v_loss': Array(0.10695193, dtype=float32), 'eval/episode_distance_from_origin': Array(5810.6475, dtype=float32), 'eval/episode_distance_reward': Array(21.493416, dtype=float32), 'eval/episode_forward_reward': Array(3582.2188, dtype=float32), 'eval/episode_reward': Array(3596.0505, dtype=float32), 'eval/episode_reward_alive': Array(388.34375, dtype=float32), 'eval/episode_reward_linvel': Array(3582.2188, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.00555, dtype=float32), 'eval/episode_x_position': Array(5759.2983, dtype=float32), 'eval/episode_x_velocity': Array(716.4437, dtype=float32), 'eval/episode_y_position': Array(-221.07724, dtype=float32), 'eval/episode_y_velocity': Array(-150.62607, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.9542, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3467546, dtype=float32), 'eval/episode_forward_reward_std': Array(891.1187, dtype=float32), 'eval/episode_reward_std': Array(884.61774, dtype=float32), 'eval/episode_reward_alive_std': Array(54.15158, dtype=float32), 'eval/episode_reward_linvel_std': Array(891.1187, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.73326, dtype=float32), 'eval/episode_x_position_std': Array(451.26556, dtype=float32), 'eval/episode_x_velocity_std': Array(178.22371, dtype=float32), 'eval/episode_y_position_std': Array(285.1682, dtype=float32), 'eval/episode_y_velocity_std': Array(101.13862, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44266271591187, 'eval/sps': 938.1229994500299, 'num_steps': 32604160}
{'eval/walltime': 54635.74173998833, 'training/sps': 2946.260474406598, 'training/walltime': 11123.505553007126, 'training/entropy_loss': Array(0.01367737, dtype=float32), 'training/policy_loss': Array(0.00252899, dtype=float32), 'training/total_loss': Array(0.11539817, dtype=float32), 'training/v_loss': Array(0.09919181, dtype=float32), 'eval/episode_distance_from_origin': Array(5819.282, dtype=float32), 'eval/episode_distance_reward': Array(22.313423, dtype=float32), 'eval/episode_forward_reward': Array(3718.8853, dtype=float32), 'eval/episode_reward': Array(3735.0046, dtype=float32), 'eval/episode_reward_alive': Array(386.54297, dtype=float32), 'eval/episode_reward_linvel': Array(3718.8853, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.73666, dtype=float32), 'eval/episode_x_position': Array(5767.864, dtype=float32), 'eval/episode_x_velocity': Array(743.77704, dtype=float32), 'eval/episode_y_position': Array(-201.8021, dtype=float32), 'eval/episode_y_velocity': Array(-151.09969, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.81537, dtype=float32), 'eval/episode_distance_reward_std': Array(5.391482, dtype=float32), 'eval/episode_forward_reward_std': Array(898.57355, dtype=float32), 'eval/episode_reward_std': Array(883.07996, dtype=float32), 'eval/episode_reward_alive_std': Array(54.92111, dtype=float32), 'eval/episode_reward_linvel_std': Array(898.57355, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.247568, dtype=float32), 'eval/episode_x_position_std': Array(474.87082, dtype=float32), 'eval/episode_x_velocity_std': Array(179.71463, dtype=float32), 'eval/episode_y_position_std': Array(299.5583, dtype=float32), 'eval/episode_y_velocity_std': Array(95.853935, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58582067489624, 'eval/sps': 937.139736522634, 'num_steps': 32686080}
{'eval/walltime': 54772.31689167023, 'training/sps': 2932.229904857717, 'training/walltime': 11151.443335056305, 'training/entropy_loss': Array(0.01346403, dtype=float32), 'training/policy_loss': Array(0.0040013, dtype=float32), 'training/total_loss': Array(0.101487, dtype=float32), 'training/v_loss': Array(0.08402167, dtype=float32), 'eval/episode_distance_from_origin': Array(5870.94, dtype=float32), 'eval/episode_distance_reward': Array(22.47816, dtype=float32), 'eval/episode_forward_reward': Array(3746.3416, dtype=float32), 'eval/episode_reward': Array(3761.5986, dtype=float32), 'eval/episode_reward_alive': Array(384.17188, dtype=float32), 'eval/episode_reward_linvel': Array(3746.3416, dtype=float32), 'eval/episode_reward_quadctrl': Array(-391.3924, dtype=float32), 'eval/episode_x_position': Array(5821.5312, dtype=float32), 'eval/episode_x_velocity': Array(749.26825, dtype=float32), 'eval/episode_y_position': Array(-197.07742, dtype=float32), 'eval/episode_y_velocity': Array(-153.76068, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.3321, dtype=float32), 'eval/episode_distance_reward_std': Array(5.425756, dtype=float32), 'eval/episode_forward_reward_std': Array(904.2851, dtype=float32), 'eval/episode_reward_std': Array(884.5178, dtype=float32), 'eval/episode_reward_alive_std': Array(59.42522, dtype=float32), 'eval/episode_reward_linvel_std': Array(904.2851, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.0962, dtype=float32), 'eval/episode_x_position_std': Array(452.24738, dtype=float32), 'eval/episode_x_velocity_std': Array(180.85696, dtype=float32), 'eval/episode_y_position_std': Array(264.17422, dtype=float32), 'eval/episode_y_velocity_std': Array(93.91131, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57515168190002, 'eval/sps': 937.2129441095362, 'num_steps': 32768000}
{'eval/walltime': 54908.91067671776, 'training/sps': 2947.8620358833214, 'training/walltime': 11179.232966661453, 'training/entropy_loss': Array(0.01203007, dtype=float32), 'training/policy_loss': Array(0.004905, dtype=float32), 'training/total_loss': Array(0.09863778, dtype=float32), 'training/v_loss': Array(0.08170271, dtype=float32), 'eval/episode_distance_from_origin': Array(5942.9863, dtype=float32), 'eval/episode_distance_reward': Array(22.428532, dtype=float32), 'eval/episode_forward_reward': Array(3738.0698, dtype=float32), 'eval/episode_reward': Array(3747.3696, dtype=float32), 'eval/episode_reward_alive': Array(385.83203, dtype=float32), 'eval/episode_reward_linvel': Array(3738.0698, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.96136, dtype=float32), 'eval/episode_x_position': Array(5889.0303, dtype=float32), 'eval/episode_x_velocity': Array(747.614, dtype=float32), 'eval/episode_y_position': Array(-277.57196, dtype=float32), 'eval/episode_y_velocity': Array(-161.16174, dtype=float32), 'eval/episode_distance_from_origin_std': Array(433.86765, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9339542, dtype=float32), 'eval/episode_forward_reward_std': Array(822.3191, dtype=float32), 'eval/episode_reward_std': Array(799.08203, dtype=float32), 'eval/episode_reward_alive_std': Array(55.781075, dtype=float32), 'eval/episode_reward_linvel_std': Array(822.3191, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.487404, dtype=float32), 'eval/episode_x_position_std': Array(430.45166, dtype=float32), 'eval/episode_x_velocity_std': Array(164.46378, dtype=float32), 'eval/episode_y_position_std': Array(291.70364, dtype=float32), 'eval/episode_y_velocity_std': Array(93.5525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59378504753113, 'eval/sps': 937.0850947241801, 'num_steps': 32849920}
{'eval/walltime': 55045.458020448685, 'training/sps': 2941.1439293209996, 'training/walltime': 11207.086074829102, 'training/entropy_loss': Array(0.01471629, dtype=float32), 'training/policy_loss': Array(0.00727774, dtype=float32), 'training/total_loss': Array(0.17498231, dtype=float32), 'training/v_loss': Array(0.15298827, dtype=float32), 'eval/episode_distance_from_origin': Array(5850.83, dtype=float32), 'eval/episode_distance_reward': Array(22.171246, dtype=float32), 'eval/episode_forward_reward': Array(3695.1892, dtype=float32), 'eval/episode_reward': Array(3705.1123, dtype=float32), 'eval/episode_reward_alive': Array(385.13672, dtype=float32), 'eval/episode_reward_linvel': Array(3695.1892, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.38474, dtype=float32), 'eval/episode_x_position': Array(5798.5293, dtype=float32), 'eval/episode_x_velocity': Array(739.0377, dtype=float32), 'eval/episode_y_position': Array(-260.1646, dtype=float32), 'eval/episode_y_velocity': Array(-159.91075, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.8491, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4224024, dtype=float32), 'eval/episode_forward_reward_std': Array(903.72577, dtype=float32), 'eval/episode_reward_std': Array(890.3369, dtype=float32), 'eval/episode_reward_alive_std': Array(54.569397, dtype=float32), 'eval/episode_reward_linvel_std': Array(903.72577, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.520103, dtype=float32), 'eval/episode_x_position_std': Array(452.2897, dtype=float32), 'eval/episode_x_velocity_std': Array(180.74524, dtype=float32), 'eval/episode_y_position_std': Array(267.70874, dtype=float32), 'eval/episode_y_velocity_std': Array(86.747765, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5473437309265, 'eval/sps': 937.4038081050519, 'num_steps': 32931840}
{'eval/walltime': 55182.038974285126, 'training/sps': 2961.0370037303833, 'training/walltime': 11234.752058029175, 'training/entropy_loss': Array(0.01385278, dtype=float32), 'training/policy_loss': Array(0.00525594, dtype=float32), 'training/total_loss': Array(0.13931765, dtype=float32), 'training/v_loss': Array(0.12020894, dtype=float32), 'eval/episode_distance_from_origin': Array(5819.6035, dtype=float32), 'eval/episode_distance_reward': Array(21.720116, dtype=float32), 'eval/episode_forward_reward': Array(3620.0017, dtype=float32), 'eval/episode_reward': Array(3627.3438, dtype=float32), 'eval/episode_reward_alive': Array(382.8047, dtype=float32), 'eval/episode_reward_linvel': Array(3620.0017, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.1829, dtype=float32), 'eval/episode_x_position': Array(5761.9653, dtype=float32), 'eval/episode_x_velocity': Array(724.00037, dtype=float32), 'eval/episode_y_position': Array(-321.60394, dtype=float32), 'eval/episode_y_velocity': Array(-176.8087, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.6197, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4052367, dtype=float32), 'eval/episode_forward_reward_std': Array(900.86456, dtype=float32), 'eval/episode_reward_std': Array(879.42224, dtype=float32), 'eval/episode_reward_alive_std': Array(55.535328, dtype=float32), 'eval/episode_reward_linvel_std': Array(900.86456, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.383417, dtype=float32), 'eval/episode_x_position_std': Array(487.224, dtype=float32), 'eval/episode_x_velocity_std': Array(180.17291, dtype=float32), 'eval/episode_y_position_std': Array(277.51065, dtype=float32), 'eval/episode_y_velocity_std': Array(94.21467, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58095383644104, 'eval/sps': 937.17312996132, 'num_steps': 33013760}
{'eval/walltime': 55318.56360769272, 'training/sps': 2964.9663149734797, 'training/walltime': 11262.381376981735, 'training/entropy_loss': Array(0.01450566, dtype=float32), 'training/policy_loss': Array(0.00368167, dtype=float32), 'training/total_loss': Array(0.13927847, dtype=float32), 'training/v_loss': Array(0.12109116, dtype=float32), 'eval/episode_distance_from_origin': Array(5842.9365, dtype=float32), 'eval/episode_distance_reward': Array(21.927586, dtype=float32), 'eval/episode_forward_reward': Array(3654.58, dtype=float32), 'eval/episode_reward': Array(3672.3958, dtype=float32), 'eval/episode_reward_alive': Array(395.22656, dtype=float32), 'eval/episode_reward_linvel': Array(3654.58, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.33826, dtype=float32), 'eval/episode_x_position': Array(5791.3765, dtype=float32), 'eval/episode_x_velocity': Array(730.916, dtype=float32), 'eval/episode_y_position': Array(-225.42712, dtype=float32), 'eval/episode_y_velocity': Array(-148.64757, dtype=float32), 'eval/episode_distance_from_origin_std': Array(526.1561, dtype=float32), 'eval/episode_distance_reward_std': Array(6.13848, dtype=float32), 'eval/episode_forward_reward_std': Array(1023.07214, dtype=float32), 'eval/episode_reward_std': Array(1005.95496, dtype=float32), 'eval/episode_reward_alive_std': Array(56.940033, dtype=float32), 'eval/episode_reward_linvel_std': Array(1023.07214, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.5109, dtype=float32), 'eval/episode_x_position_std': Array(523.70496, dtype=float32), 'eval/episode_x_velocity_std': Array(204.61443, dtype=float32), 'eval/episode_y_position_std': Array(303.51544, dtype=float32), 'eval/episode_y_velocity_std': Array(99.085526, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52463340759277, 'eval/sps': 937.5597414560157, 'num_steps': 33095680}
{'eval/walltime': 55455.1398127079, 'training/sps': 2948.8427894970996, 'training/walltime': 11290.161766052246, 'training/entropy_loss': Array(0.01452531, dtype=float32), 'training/policy_loss': Array(0.00423588, dtype=float32), 'training/total_loss': Array(0.13461465, dtype=float32), 'training/v_loss': Array(0.11585346, dtype=float32), 'eval/episode_distance_from_origin': Array(5740.648, dtype=float32), 'eval/episode_distance_reward': Array(21.442448, dtype=float32), 'eval/episode_forward_reward': Array(3573.7227, dtype=float32), 'eval/episode_reward': Array(3584.3203, dtype=float32), 'eval/episode_reward_alive': Array(384.8086, dtype=float32), 'eval/episode_reward_linvel': Array(3573.7227, dtype=float32), 'eval/episode_reward_quadctrl': Array(-395.65366, dtype=float32), 'eval/episode_x_position': Array(5683.8438, dtype=float32), 'eval/episode_x_velocity': Array(714.74457, dtype=float32), 'eval/episode_y_position': Array(-288.02673, dtype=float32), 'eval/episode_y_velocity': Array(-164.74332, dtype=float32), 'eval/episode_distance_from_origin_std': Array(557.1629, dtype=float32), 'eval/episode_distance_reward_std': Array(6.324784, dtype=float32), 'eval/episode_forward_reward_std': Array(1054.1217, dtype=float32), 'eval/episode_reward_std': Array(1036.71, dtype=float32), 'eval/episode_reward_alive_std': Array(60.003223, dtype=float32), 'eval/episode_reward_linvel_std': Array(1054.1217, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.23587, dtype=float32), 'eval/episode_x_position_std': Array(553.20294, dtype=float32), 'eval/episode_x_velocity_std': Array(210.82426, dtype=float32), 'eval/episode_y_position_std': Array(298.92822, dtype=float32), 'eval/episode_y_velocity_std': Array(102.56525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5762050151825, 'eval/sps': 937.2057159281214, 'num_steps': 33177600}
{'eval/walltime': 55591.655348300934, 'training/sps': 2947.68794353937, 'training/walltime': 11317.953038930893, 'training/entropy_loss': Array(0.01464752, dtype=float32), 'training/policy_loss': Array(0.00569083, dtype=float32), 'training/total_loss': Array(0.12778339, dtype=float32), 'training/v_loss': Array(0.10744504, dtype=float32), 'eval/episode_distance_from_origin': Array(5834.2617, dtype=float32), 'eval/episode_distance_reward': Array(22.292465, dtype=float32), 'eval/episode_forward_reward': Array(3715.3928, dtype=float32), 'eval/episode_reward': Array(3730.9429, dtype=float32), 'eval/episode_reward_alive': Array(390.3672, dtype=float32), 'eval/episode_reward_linvel': Array(3715.3928, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.10974, dtype=float32), 'eval/episode_x_position': Array(5779.7627, dtype=float32), 'eval/episode_x_velocity': Array(743.07855, dtype=float32), 'eval/episode_y_position': Array(-261.40393, dtype=float32), 'eval/episode_y_velocity': Array(-164.29787, dtype=float32), 'eval/episode_distance_from_origin_std': Array(523.8018, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9204435, dtype=float32), 'eval/episode_forward_reward_std': Array(986.7326, dtype=float32), 'eval/episode_reward_std': Array(974.20404, dtype=float32), 'eval/episode_reward_alive_std': Array(55.447098, dtype=float32), 'eval/episode_reward_linvel_std': Array(986.7326, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.843735, dtype=float32), 'eval/episode_x_position_std': Array(522.01154, dtype=float32), 'eval/episode_x_velocity_std': Array(197.34651, dtype=float32), 'eval/episode_y_position_std': Array(294.77008, dtype=float32), 'eval/episode_y_velocity_std': Array(94.9341, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51553559303284, 'eval/sps': 937.6222233166301, 'num_steps': 33259520}
{'eval/walltime': 55728.25129342079, 'training/sps': 2963.619505377626, 'training/walltime': 11345.594913959503, 'training/entropy_loss': Array(0.01044088, dtype=float32), 'training/policy_loss': Array(0.0006332, dtype=float32), 'training/total_loss': Array(0.05765728, dtype=float32), 'training/v_loss': Array(0.04658321, dtype=float32), 'eval/episode_distance_from_origin': Array(5848.038, dtype=float32), 'eval/episode_distance_reward': Array(22.184938, dtype=float32), 'eval/episode_forward_reward': Array(3697.4707, dtype=float32), 'eval/episode_reward': Array(3707.5996, dtype=float32), 'eval/episode_reward_alive': Array(382.66016, dtype=float32), 'eval/episode_reward_linvel': Array(3697.4707, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.71664, dtype=float32), 'eval/episode_x_position': Array(5795.3267, dtype=float32), 'eval/episode_x_velocity': Array(739.49414, dtype=float32), 'eval/episode_y_position': Array(-265.5354, dtype=float32), 'eval/episode_y_velocity': Array(-168.6252, dtype=float32), 'eval/episode_distance_from_origin_std': Array(466.1939, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2968516, dtype=float32), 'eval/episode_forward_reward_std': Array(882.8012, dtype=float32), 'eval/episode_reward_std': Array(863.5944, dtype=float32), 'eval/episode_reward_alive_std': Array(59.74898, dtype=float32), 'eval/episode_reward_linvel_std': Array(882.8012, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.503145, dtype=float32), 'eval/episode_x_position_std': Array(464.44318, dtype=float32), 'eval/episode_x_velocity_std': Array(176.56026, dtype=float32), 'eval/episode_y_position_std': Array(257.608, dtype=float32), 'eval/episode_y_velocity_std': Array(92.12159, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5959451198578, 'eval/sps': 937.0702760443206, 'num_steps': 33341440}
{'eval/walltime': 55864.775019168854, 'training/sps': 2957.715245018876, 'training/walltime': 11373.291968345642, 'training/entropy_loss': Array(0.01572216, dtype=float32), 'training/policy_loss': Array(0.00785233, dtype=float32), 'training/total_loss': Array(0.15712716, dtype=float32), 'training/v_loss': Array(0.13355267, dtype=float32), 'eval/episode_distance_from_origin': Array(5818.9917, dtype=float32), 'eval/episode_distance_reward': Array(22.004814, dtype=float32), 'eval/episode_forward_reward': Array(3667.4507, dtype=float32), 'eval/episode_reward': Array(3687.9775, dtype=float32), 'eval/episode_reward_alive': Array(394.58594, dtype=float32), 'eval/episode_reward_linvel': Array(3667.4507, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.06372, dtype=float32), 'eval/episode_x_position': Array(5762.4536, dtype=float32), 'eval/episode_x_velocity': Array(733.4901, dtype=float32), 'eval/episode_y_position': Array(-314.96704, dtype=float32), 'eval/episode_y_velocity': Array(-169.31714, dtype=float32), 'eval/episode_distance_from_origin_std': Array(447.78067, dtype=float32), 'eval/episode_distance_reward_std': Array(5.226103, dtype=float32), 'eval/episode_forward_reward_std': Array(871.0099, dtype=float32), 'eval/episode_reward_std': Array(851.48236, dtype=float32), 'eval/episode_reward_alive_std': Array(51.24524, dtype=float32), 'eval/episode_reward_linvel_std': Array(871.0099, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.470798, dtype=float32), 'eval/episode_x_position_std': Array(444.91608, dtype=float32), 'eval/episode_x_velocity_std': Array(174.20193, dtype=float32), 'eval/episode_y_position_std': Array(272.97324, dtype=float32), 'eval/episode_y_velocity_std': Array(89.93308, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52372574806213, 'eval/sps': 937.565974695185, 'num_steps': 33423360}
{'eval/walltime': 56001.337619781494, 'training/sps': 2966.564744879274, 'training/walltime': 11400.906400203705, 'training/entropy_loss': Array(0.01551126, dtype=float32), 'training/policy_loss': Array(0.0079982, dtype=float32), 'training/total_loss': Array(0.14514978, dtype=float32), 'training/v_loss': Array(0.12164033, dtype=float32), 'eval/episode_distance_from_origin': Array(5803.665, dtype=float32), 'eval/episode_distance_reward': Array(21.586208, dtype=float32), 'eval/episode_forward_reward': Array(3597.6836, dtype=float32), 'eval/episode_reward': Array(3622.3606, dtype=float32), 'eval/episode_reward_alive': Array(397.1797, dtype=float32), 'eval/episode_reward_linvel': Array(3597.6836, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.08884, dtype=float32), 'eval/episode_x_position': Array(5751.17, dtype=float32), 'eval/episode_x_velocity': Array(719.53674, dtype=float32), 'eval/episode_y_position': Array(-230.60184, dtype=float32), 'eval/episode_y_velocity': Array(-153.07346, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.4263, dtype=float32), 'eval/episode_distance_reward_std': Array(5.735419, dtype=float32), 'eval/episode_forward_reward_std': Array(955.8941, dtype=float32), 'eval/episode_reward_std': Array(931.21075, dtype=float32), 'eval/episode_reward_alive_std': Array(57.49962, dtype=float32), 'eval/episode_reward_linvel_std': Array(955.8941, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.871706, dtype=float32), 'eval/episode_x_position_std': Array(465.19333, dtype=float32), 'eval/episode_x_velocity_std': Array(191.17886, dtype=float32), 'eval/episode_y_position_std': Array(308.52853, dtype=float32), 'eval/episode_y_velocity_std': Array(109.619484, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56260061264038, 'eval/sps': 937.2990806104507, 'num_steps': 33505280}
{'eval/walltime': 56137.8541033268, 'training/sps': 2952.417330976365, 'training/walltime': 11428.653155088425, 'training/entropy_loss': Array(0.01452967, dtype=float32), 'training/policy_loss': Array(0.00927764, dtype=float32), 'training/total_loss': Array(0.13721287, dtype=float32), 'training/v_loss': Array(0.11340557, dtype=float32), 'eval/episode_distance_from_origin': Array(5915.7783, dtype=float32), 'eval/episode_distance_reward': Array(23.16219, dtype=float32), 'eval/episode_forward_reward': Array(3860.3445, dtype=float32), 'eval/episode_reward': Array(3872.6475, dtype=float32), 'eval/episode_reward_alive': Array(387.8203, dtype=float32), 'eval/episode_reward_linvel': Array(3860.3445, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.68024, dtype=float32), 'eval/episode_x_position': Array(5860.959, dtype=float32), 'eval/episode_x_velocity': Array(772.06885, dtype=float32), 'eval/episode_y_position': Array(-272.1748, dtype=float32), 'eval/episode_y_velocity': Array(-169.97073, dtype=float32), 'eval/episode_distance_from_origin_std': Array(434.1655, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1256337, dtype=float32), 'eval/episode_forward_reward_std': Array(854.2655, dtype=float32), 'eval/episode_reward_std': Array(844.5006, dtype=float32), 'eval/episode_reward_alive_std': Array(52.630184, dtype=float32), 'eval/episode_reward_linvel_std': Array(854.2655, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.618683, dtype=float32), 'eval/episode_x_position_std': Array(433.0233, dtype=float32), 'eval/episode_x_velocity_std': Array(170.85312, dtype=float32), 'eval/episode_y_position_std': Array(307.2857, dtype=float32), 'eval/episode_y_velocity_std': Array(92.28628, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51648354530334, 'eval/sps': 937.6157125928523, 'num_steps': 33587200}
{'eval/walltime': 56274.40595269203, 'training/sps': 2961.732569510824, 'training/walltime': 11456.31264090538, 'training/entropy_loss': Array(0.01483203, dtype=float32), 'training/policy_loss': Array(0.00360512, dtype=float32), 'training/total_loss': Array(0.11224843, dtype=float32), 'training/v_loss': Array(0.09381129, dtype=float32), 'eval/episode_distance_from_origin': Array(5856.8438, dtype=float32), 'eval/episode_distance_reward': Array(22.748816, dtype=float32), 'eval/episode_forward_reward': Array(3791.4495, dtype=float32), 'eval/episode_reward': Array(3808.9697, dtype=float32), 'eval/episode_reward_alive': Array(387.27344, dtype=float32), 'eval/episode_reward_linvel': Array(3791.4495, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.50204, dtype=float32), 'eval/episode_x_position': Array(5797.6104, dtype=float32), 'eval/episode_x_velocity': Array(758.2899, dtype=float32), 'eval/episode_y_position': Array(-348.41943, dtype=float32), 'eval/episode_y_velocity': Array(-191.41612, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.20358, dtype=float32), 'eval/episode_distance_reward_std': Array(5.722594, dtype=float32), 'eval/episode_forward_reward_std': Array(953.7572, dtype=float32), 'eval/episode_reward_std': Array(933.1754, dtype=float32), 'eval/episode_reward_alive_std': Array(57.30827, dtype=float32), 'eval/episode_reward_linvel_std': Array(953.7572, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.627848, dtype=float32), 'eval/episode_x_position_std': Array(504.6225, dtype=float32), 'eval/episode_x_velocity_std': Array(190.75153, dtype=float32), 'eval/episode_y_position_std': Array(262.61993, dtype=float32), 'eval/episode_y_velocity_std': Array(81.0549, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55184936523438, 'eval/sps': 937.3728777384714, 'num_steps': 33669120}
{'eval/walltime': 56410.92410039902, 'training/sps': 2953.948162147954, 'training/walltime': 11484.045016527176, 'training/entropy_loss': Array(0.01472517, dtype=float32), 'training/policy_loss': Array(0.0047499, dtype=float32), 'training/total_loss': Array(0.12313902, dtype=float32), 'training/v_loss': Array(0.10366396, dtype=float32), 'eval/episode_distance_from_origin': Array(5960.2363, dtype=float32), 'eval/episode_distance_reward': Array(23.538979, dtype=float32), 'eval/episode_forward_reward': Array(3923.143, dtype=float32), 'eval/episode_reward': Array(3946.6423, dtype=float32), 'eval/episode_reward_alive': Array(394.54688, dtype=float32), 'eval/episode_reward_linvel': Array(3923.143, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.58673, dtype=float32), 'eval/episode_x_position': Array(5902.5103, dtype=float32), 'eval/episode_x_velocity': Array(784.62866, dtype=float32), 'eval/episode_y_position': Array(-329.75305, dtype=float32), 'eval/episode_y_velocity': Array(-181.48782, dtype=float32), 'eval/episode_distance_from_origin_std': Array(404.9384, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1438246, dtype=float32), 'eval/episode_forward_reward_std': Array(857.29724, dtype=float32), 'eval/episode_reward_std': Array(848.8048, dtype=float32), 'eval/episode_reward_alive_std': Array(52.013535, dtype=float32), 'eval/episode_reward_linvel_std': Array(857.29724, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.98919, dtype=float32), 'eval/episode_x_position_std': Array(403.9307, dtype=float32), 'eval/episode_x_velocity_std': Array(171.4595, dtype=float32), 'eval/episode_y_position_std': Array(283.77377, dtype=float32), 'eval/episode_y_velocity_std': Array(91.28705, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51814770698547, 'eval/sps': 937.6042830198054, 'num_steps': 33751040}
{'eval/walltime': 56547.60091423988, 'training/sps': 2962.6602691342123, 'training/walltime': 11511.695841312408, 'training/entropy_loss': Array(0.01116609, dtype=float32), 'training/policy_loss': Array(2.0999316e-05, dtype=float32), 'training/total_loss': Array(0.06912901, dtype=float32), 'training/v_loss': Array(0.05794192, dtype=float32), 'eval/episode_distance_from_origin': Array(5993.502, dtype=float32), 'eval/episode_distance_reward': Array(24.757511, dtype=float32), 'eval/episode_forward_reward': Array(4126.2295, dtype=float32), 'eval/episode_reward': Array(4137.2397, dtype=float32), 'eval/episode_reward_alive': Array(374.125, dtype=float32), 'eval/episode_reward_linvel': Array(4126.2295, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.87238, dtype=float32), 'eval/episode_x_position': Array(5937.0747, dtype=float32), 'eval/episode_x_velocity': Array(825.2458, dtype=float32), 'eval/episode_y_position': Array(-289.81317, dtype=float32), 'eval/episode_y_velocity': Array(-186.44162, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.96292, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4502416, dtype=float32), 'eval/episode_forward_reward_std': Array(908.3658, dtype=float32), 'eval/episode_reward_std': Array(897.13855, dtype=float32), 'eval/episode_reward_alive_std': Array(52.42461, dtype=float32), 'eval/episode_reward_linvel_std': Array(908.3658, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.78142, dtype=float32), 'eval/episode_x_position_std': Array(459.63162, dtype=float32), 'eval/episode_x_velocity_std': Array(181.6731, dtype=float32), 'eval/episode_y_position_std': Array(299.2323, dtype=float32), 'eval/episode_y_velocity_std': Array(97.8485, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6768138408661, 'eval/sps': 936.5158317857148, 'num_steps': 33832960}
{'eval/walltime': 56684.131049871445, 'training/sps': 2960.5430421732826, 'training/walltime': 11539.366440534592, 'training/entropy_loss': Array(0.0162283, dtype=float32), 'training/policy_loss': Array(0.00747763, dtype=float32), 'training/total_loss': Array(0.12102527, dtype=float32), 'training/v_loss': Array(0.09731933, dtype=float32), 'eval/episode_distance_from_origin': Array(6015.137, dtype=float32), 'eval/episode_distance_reward': Array(24.360422, dtype=float32), 'eval/episode_forward_reward': Array(4060.048, dtype=float32), 'eval/episode_reward': Array(4077.0342, dtype=float32), 'eval/episode_reward_alive': Array(381.84375, dtype=float32), 'eval/episode_reward_linvel': Array(4060.048, dtype=float32), 'eval/episode_reward_quadctrl': Array(-389.2188, dtype=float32), 'eval/episode_x_position': Array(5956.2573, dtype=float32), 'eval/episode_x_velocity': Array(812.00964, dtype=float32), 'eval/episode_y_position': Array(-348.5185, dtype=float32), 'eval/episode_y_velocity': Array(-191.70726, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.23587, dtype=float32), 'eval/episode_distance_reward_std': Array(5.318455, dtype=float32), 'eval/episode_forward_reward_std': Array(886.4022, dtype=float32), 'eval/episode_reward_std': Array(875.3975, dtype=float32), 'eval/episode_reward_alive_std': Array(45.92388, dtype=float32), 'eval/episode_reward_linvel_std': Array(886.4022, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.710396, dtype=float32), 'eval/episode_x_position_std': Array(461.2789, dtype=float32), 'eval/episode_x_velocity_std': Array(177.28049, dtype=float32), 'eval/episode_y_position_std': Array(269.45706, dtype=float32), 'eval/episode_y_velocity_std': Array(95.3493, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53013563156128, 'eval/sps': 937.5219573898278, 'num_steps': 33914880}
{'eval/walltime': 56820.64221072197, 'training/sps': 2958.2395392784065, 'training/walltime': 11567.058586120605, 'training/entropy_loss': Array(0.01408796, dtype=float32), 'training/policy_loss': Array(0.00999373, dtype=float32), 'training/total_loss': Array(0.16328424, dtype=float32), 'training/v_loss': Array(0.13920254, dtype=float32), 'eval/episode_distance_from_origin': Array(5939.779, dtype=float32), 'eval/episode_distance_reward': Array(23.62608, dtype=float32), 'eval/episode_forward_reward': Array(3937.66, dtype=float32), 'eval/episode_reward': Array(3945.4644, dtype=float32), 'eval/episode_reward_alive': Array(374.5664, dtype=float32), 'eval/episode_reward_linvel': Array(3937.66, dtype=float32), 'eval/episode_reward_quadctrl': Array(-390.3875, dtype=float32), 'eval/episode_x_position': Array(5882.6167, dtype=float32), 'eval/episode_x_velocity': Array(787.53186, dtype=float32), 'eval/episode_y_position': Array(-312.29205, dtype=float32), 'eval/episode_y_velocity': Array(-188.74008, dtype=float32), 'eval/episode_distance_from_origin_std': Array(403.1677, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6168976, dtype=float32), 'eval/episode_forward_reward_std': Array(769.4773, dtype=float32), 'eval/episode_reward_std': Array(760.98206, dtype=float32), 'eval/episode_reward_alive_std': Array(57.196323, dtype=float32), 'eval/episode_reward_linvel_std': Array(769.4773, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.55453, dtype=float32), 'eval/episode_x_position_std': Array(402.84006, dtype=float32), 'eval/episode_x_velocity_std': Array(153.89532, dtype=float32), 'eval/episode_y_position_std': Array(263.42422, dtype=float32), 'eval/episode_y_velocity_std': Array(82.18147, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5111608505249, 'eval/sps': 937.6522710854072, 'num_steps': 33996800}
{'eval/walltime': 56957.087446689606, 'training/sps': 2952.7455679518725, 'training/walltime': 11594.802256584167, 'training/entropy_loss': Array(0.01360939, dtype=float32), 'training/policy_loss': Array(0.12409414, dtype=float32), 'training/total_loss': Array(0.25490075, dtype=float32), 'training/v_loss': Array(0.11719723, dtype=float32), 'eval/episode_distance_from_origin': Array(5691.8687, dtype=float32), 'eval/episode_distance_reward': Array(20.696968, dtype=float32), 'eval/episode_forward_reward': Array(3449.4768, dtype=float32), 'eval/episode_reward': Array(3453.0884, dtype=float32), 'eval/episode_reward_alive': Array(394.34375, dtype=float32), 'eval/episode_reward_linvel': Array(3449.4768, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.42914, dtype=float32), 'eval/episode_x_position': Array(5639.0186, dtype=float32), 'eval/episode_x_velocity': Array(689.89526, dtype=float32), 'eval/episode_y_position': Array(-217.07849, dtype=float32), 'eval/episode_y_velocity': Array(-154.60654, dtype=float32), 'eval/episode_distance_from_origin_std': Array(573.78265, dtype=float32), 'eval/episode_distance_reward_std': Array(6.417063, dtype=float32), 'eval/episode_forward_reward_std': Array(1069.5032, dtype=float32), 'eval/episode_reward_std': Array(1054.4868, dtype=float32), 'eval/episode_reward_alive_std': Array(51.425983, dtype=float32), 'eval/episode_reward_linvel_std': Array(1069.5032, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.622028, dtype=float32), 'eval/episode_x_position_std': Array(568.7209, dtype=float32), 'eval/episode_x_velocity_std': Array(213.90057, dtype=float32), 'eval/episode_y_position_std': Array(285.52, dtype=float32), 'eval/episode_y_velocity_std': Array(103.83069, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4452359676361, 'eval/sps': 938.1053071751127, 'num_steps': 34078720}
{'eval/walltime': 57093.5982735157, 'training/sps': 2960.024102153932, 'training/walltime': 11622.47770690918, 'training/entropy_loss': Array(0.0147225, dtype=float32), 'training/policy_loss': Array(0.01417429, dtype=float32), 'training/total_loss': Array(0.14743271, dtype=float32), 'training/v_loss': Array(0.11853591, dtype=float32), 'eval/episode_distance_from_origin': Array(5815.415, dtype=float32), 'eval/episode_distance_reward': Array(22.293339, dtype=float32), 'eval/episode_forward_reward': Array(3715.5369, dtype=float32), 'eval/episode_reward': Array(3714.1472, dtype=float32), 'eval/episode_reward_alive': Array(384.16797, dtype=float32), 'eval/episode_reward_linvel': Array(3715.5369, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.8509, dtype=float32), 'eval/episode_x_position': Array(5760.4546, dtype=float32), 'eval/episode_x_velocity': Array(743.1073, dtype=float32), 'eval/episode_y_position': Array(-252.97269, dtype=float32), 'eval/episode_y_velocity': Array(-173.99654, dtype=float32), 'eval/episode_distance_from_origin_std': Array(525.7051, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6727314, dtype=float32), 'eval/episode_forward_reward_std': Array(945.44885, dtype=float32), 'eval/episode_reward_std': Array(935.97943, dtype=float32), 'eval/episode_reward_alive_std': Array(50.426044, dtype=float32), 'eval/episode_reward_linvel_std': Array(945.44885, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.263893, dtype=float32), 'eval/episode_x_position_std': Array(521.6344, dtype=float32), 'eval/episode_x_velocity_std': Array(189.08969, dtype=float32), 'eval/episode_y_position_std': Array(283.48602, dtype=float32), 'eval/episode_y_velocity_std': Array(95.391365, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51082682609558, 'eval/sps': 937.6545653998731, 'num_steps': 34160640}
{'eval/walltime': 57230.054261446, 'training/sps': 2950.5229908803412, 'training/walltime': 11650.242276191711, 'training/entropy_loss': Array(0.01436177, dtype=float32), 'training/policy_loss': Array(0.00409682, dtype=float32), 'training/total_loss': Array(0.1493647, dtype=float32), 'training/v_loss': Array(0.1309061, dtype=float32), 'eval/episode_distance_from_origin': Array(5762.83, dtype=float32), 'eval/episode_distance_reward': Array(21.21592, dtype=float32), 'eval/episode_forward_reward': Array(3535.969, dtype=float32), 'eval/episode_reward': Array(3547.5488, dtype=float32), 'eval/episode_reward_alive': Array(397.51562, dtype=float32), 'eval/episode_reward_linvel': Array(3535.969, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.15125, dtype=float32), 'eval/episode_x_position': Array(5710.755, dtype=float32), 'eval/episode_x_velocity': Array(707.19385, dtype=float32), 'eval/episode_y_position': Array(-228.83571, dtype=float32), 'eval/episode_y_velocity': Array(-161.55225, dtype=float32), 'eval/episode_distance_from_origin_std': Array(494.75626, dtype=float32), 'eval/episode_distance_reward_std': Array(5.759898, dtype=float32), 'eval/episode_forward_reward_std': Array(959.9755, dtype=float32), 'eval/episode_reward_std': Array(946.61847, dtype=float32), 'eval/episode_reward_alive_std': Array(45.82, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.9755, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.761786, dtype=float32), 'eval/episode_x_position_std': Array(489.02896, dtype=float32), 'eval/episode_x_velocity_std': Array(191.99501, dtype=float32), 'eval/episode_y_position_std': Array(264.8231, dtype=float32), 'eval/episode_y_velocity_std': Array(98.68084, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45598793029785, 'eval/sps': 938.0313897649021, 'num_steps': 34242560}
{'eval/walltime': 57366.56637144089, 'training/sps': 2959.6030800951266, 'training/walltime': 11677.92166352272, 'training/entropy_loss': Array(0.01239306, dtype=float32), 'training/policy_loss': Array(0.00243564, dtype=float32), 'training/total_loss': Array(0.11177219, dtype=float32), 'training/v_loss': Array(0.09694349, dtype=float32), 'eval/episode_distance_from_origin': Array(5921.5757, dtype=float32), 'eval/episode_distance_reward': Array(22.803967, dtype=float32), 'eval/episode_forward_reward': Array(3800.641, dtype=float32), 'eval/episode_reward': Array(3805.1277, dtype=float32), 'eval/episode_reward_alive': Array(387.44922, dtype=float32), 'eval/episode_reward_linvel': Array(3800.641, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.7663, dtype=float32), 'eval/episode_x_position': Array(5866.95, dtype=float32), 'eval/episode_x_velocity': Array(760.1282, dtype=float32), 'eval/episode_y_position': Array(-296.10278, dtype=float32), 'eval/episode_y_velocity': Array(-176.27826, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.3632, dtype=float32), 'eval/episode_distance_reward_std': Array(5.886185, dtype=float32), 'eval/episode_forward_reward_std': Array(981.02277, dtype=float32), 'eval/episode_reward_std': Array(971.1896, dtype=float32), 'eval/episode_reward_alive_std': Array(53.087704, dtype=float32), 'eval/episode_reward_linvel_std': Array(981.02277, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.745533, dtype=float32), 'eval/episode_x_position_std': Array(478.78522, dtype=float32), 'eval/episode_x_velocity_std': Array(196.20467, dtype=float32), 'eval/episode_y_position_std': Array(237.97687, dtype=float32), 'eval/episode_y_velocity_std': Array(90.84529, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5121099948883, 'eval/sps': 937.645751756331, 'num_steps': 34324480}
{'eval/walltime': 57502.99839305878, 'training/sps': 2963.2075541325266, 'training/walltime': 11705.567381381989, 'training/entropy_loss': Array(0.01395259, dtype=float32), 'training/policy_loss': Array(0.00413939, dtype=float32), 'training/total_loss': Array(0.11894848, dtype=float32), 'training/v_loss': Array(0.10085651, dtype=float32), 'eval/episode_distance_from_origin': Array(5878.2656, dtype=float32), 'eval/episode_distance_reward': Array(22.784527, dtype=float32), 'eval/episode_forward_reward': Array(3797.4, dtype=float32), 'eval/episode_reward': Array(3802.384, dtype=float32), 'eval/episode_reward_alive': Array(390.71875, dtype=float32), 'eval/episode_reward_linvel': Array(3797.4, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.5197, dtype=float32), 'eval/episode_x_position': Array(5824.788, dtype=float32), 'eval/episode_x_velocity': Array(759.4801, dtype=float32), 'eval/episode_y_position': Array(-262.85388, dtype=float32), 'eval/episode_y_velocity': Array(-171.52664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.9696, dtype=float32), 'eval/episode_distance_reward_std': Array(6.105083, dtype=float32), 'eval/episode_forward_reward_std': Array(1017.50635, dtype=float32), 'eval/episode_reward_std': Array(1006.5855, dtype=float32), 'eval/episode_reward_alive_std': Array(51.37419, dtype=float32), 'eval/episode_reward_linvel_std': Array(1017.50635, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.94764, dtype=float32), 'eval/episode_x_position_std': Array(503.79117, dtype=float32), 'eval/episode_x_velocity_std': Array(203.50134, dtype=float32), 'eval/episode_y_position_std': Array(254.97144, dtype=float32), 'eval/episode_y_velocity_std': Array(92.60493, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4320216178894, 'eval/sps': 938.196168920627, 'num_steps': 34406400}
{'eval/walltime': 57639.50946140289, 'training/sps': 2961.2370232667267, 'training/walltime': 11733.231495857239, 'training/entropy_loss': Array(0.01857593, dtype=float32), 'training/policy_loss': Array(0.01086502, dtype=float32), 'training/total_loss': Array(0.18109244, dtype=float32), 'training/v_loss': Array(0.15165149, dtype=float32), 'eval/episode_distance_from_origin': Array(5918.0635, dtype=float32), 'eval/episode_distance_reward': Array(23.32827, dtype=float32), 'eval/episode_forward_reward': Array(3888.0237, dtype=float32), 'eval/episode_reward': Array(3896.373, dtype=float32), 'eval/episode_reward_alive': Array(392.42578, dtype=float32), 'eval/episode_reward_linvel': Array(3888.0237, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.40472, dtype=float32), 'eval/episode_x_position': Array(5860.2246, dtype=float32), 'eval/episode_x_velocity': Array(777.6048, dtype=float32), 'eval/episode_y_position': Array(-270.71262, dtype=float32), 'eval/episode_y_velocity': Array(-183.31659, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.2571, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0515337, dtype=float32), 'eval/episode_forward_reward_std': Array(1008.581, dtype=float32), 'eval/episode_reward_std': Array(1005.90015, dtype=float32), 'eval/episode_reward_alive_std': Array(47.32637, dtype=float32), 'eval/episode_reward_linvel_std': Array(1008.581, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.569132, dtype=float32), 'eval/episode_x_position_std': Array(530.4995, dtype=float32), 'eval/episode_x_velocity_std': Array(201.71616, dtype=float32), 'eval/episode_y_position_std': Array(269.43613, dtype=float32), 'eval/episode_y_velocity_std': Array(90.90719, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5110683441162, 'eval/sps': 937.6529064832929, 'num_steps': 34488320}
{'eval/walltime': 57775.93997812271, 'training/sps': 2954.203941858038, 'training/walltime': 11760.961470365524, 'training/entropy_loss': Array(0.01477497, dtype=float32), 'training/policy_loss': Array(0.01733037, dtype=float32), 'training/total_loss': Array(0.11753307, dtype=float32), 'training/v_loss': Array(0.08542772, dtype=float32), 'eval/episode_distance_from_origin': Array(5865.0195, dtype=float32), 'eval/episode_distance_reward': Array(22.716085, dtype=float32), 'eval/episode_forward_reward': Array(3785.994, dtype=float32), 'eval/episode_reward': Array(3796.766, dtype=float32), 'eval/episode_reward_alive': Array(393.65625, dtype=float32), 'eval/episode_reward_linvel': Array(3785.994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.6001, dtype=float32), 'eval/episode_x_position': Array(5809.3613, dtype=float32), 'eval/episode_x_velocity': Array(757.1987, dtype=float32), 'eval/episode_y_position': Array(-251.6485, dtype=float32), 'eval/episode_y_velocity': Array(-179.54312, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.13422, dtype=float32), 'eval/episode_distance_reward_std': Array(5.557594, dtype=float32), 'eval/episode_forward_reward_std': Array(926.25806, dtype=float32), 'eval/episode_reward_std': Array(923.05286, dtype=float32), 'eval/episode_reward_alive_std': Array(48.748745, dtype=float32), 'eval/episode_reward_linvel_std': Array(926.25806, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.422699, dtype=float32), 'eval/episode_x_position_std': Array(467.2454, dtype=float32), 'eval/episode_x_velocity_std': Array(185.25166, dtype=float32), 'eval/episode_y_position_std': Array(265.84003, dtype=float32), 'eval/episode_y_velocity_std': Array(96.869286, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43051671981812, 'eval/sps': 938.2065177021096, 'num_steps': 34570240}
{'eval/walltime': 57912.44764328003, 'training/sps': 2956.9321674337552, 'training/walltime': 11788.66585969925, 'training/entropy_loss': Array(0.0154353, dtype=float32), 'training/policy_loss': Array(0.00481451, dtype=float32), 'training/total_loss': Array(0.11603492, dtype=float32), 'training/v_loss': Array(0.09578511, dtype=float32), 'eval/episode_distance_from_origin': Array(5912.474, dtype=float32), 'eval/episode_distance_reward': Array(23.190136, dtype=float32), 'eval/episode_forward_reward': Array(3865.002, dtype=float32), 'eval/episode_reward': Array(3879.3125, dtype=float32), 'eval/episode_reward_alive': Array(398.71094, dtype=float32), 'eval/episode_reward_linvel': Array(3865.002, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.59076, dtype=float32), 'eval/episode_x_position': Array(5858.4385, dtype=float32), 'eval/episode_x_velocity': Array(773.0005, dtype=float32), 'eval/episode_y_position': Array(-199.46442, dtype=float32), 'eval/episode_y_velocity': Array(-159.25198, dtype=float32), 'eval/episode_distance_from_origin_std': Array(570.21027, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5980873, dtype=float32), 'eval/episode_forward_reward_std': Array(1099.6724, dtype=float32), 'eval/episode_reward_std': Array(1091.234, dtype=float32), 'eval/episode_reward_alive_std': Array(45.790993, dtype=float32), 'eval/episode_reward_linvel_std': Array(1099.6724, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.727045, dtype=float32), 'eval/episode_x_position_std': Array(568.41223, dtype=float32), 'eval/episode_x_velocity_std': Array(219.93465, dtype=float32), 'eval/episode_y_position_std': Array(303.30682, dtype=float32), 'eval/episode_y_velocity_std': Array(102.69596, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50766515731812, 'eval/sps': 937.6762825185424, 'num_steps': 34652160}
{'eval/walltime': 58048.87054228783, 'training/sps': 2950.3572228879707, 'training/walltime': 11816.431988954544, 'training/entropy_loss': Array(0.01480205, dtype=float32), 'training/policy_loss': Array(0.00336324, dtype=float32), 'training/total_loss': Array(0.110342, dtype=float32), 'training/v_loss': Array(0.09217672, dtype=float32), 'eval/episode_distance_from_origin': Array(6045.3223, dtype=float32), 'eval/episode_distance_reward': Array(24.839106, dtype=float32), 'eval/episode_forward_reward': Array(4139.8286, dtype=float32), 'eval/episode_reward': Array(4147.2925, dtype=float32), 'eval/episode_reward_alive': Array(389.92188, dtype=float32), 'eval/episode_reward_linvel': Array(4139.8286, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.29718, dtype=float32), 'eval/episode_x_position': Array(5989.5464, dtype=float32), 'eval/episode_x_velocity': Array(827.96564, dtype=float32), 'eval/episode_y_position': Array(-255.52475, dtype=float32), 'eval/episode_y_velocity': Array(-176.49689, dtype=float32), 'eval/episode_distance_from_origin_std': Array(565.80914, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4262147, dtype=float32), 'eval/episode_forward_reward_std': Array(1071.028, dtype=float32), 'eval/episode_reward_std': Array(1064.3048, dtype=float32), 'eval/episode_reward_alive_std': Array(51.733593, dtype=float32), 'eval/episode_reward_linvel_std': Array(1071.028, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.242823, dtype=float32), 'eval/episode_x_position_std': Array(563.2343, dtype=float32), 'eval/episode_x_velocity_std': Array(214.20558, dtype=float32), 'eval/episode_y_position_std': Array(299.42722, dtype=float32), 'eval/episode_y_velocity_std': Array(97.40682, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42289900779724, 'eval/sps': 938.2589061729598, 'num_steps': 34734080}
{'eval/walltime': 58185.43022155762, 'training/sps': 2958.354002693345, 'training/walltime': 11844.123063087463, 'training/entropy_loss': Array(0.01509129, dtype=float32), 'training/policy_loss': Array(0.00189885, dtype=float32), 'training/total_loss': Array(0.11636254, dtype=float32), 'training/v_loss': Array(0.09937239, dtype=float32), 'eval/episode_distance_from_origin': Array(5844.832, dtype=float32), 'eval/episode_distance_reward': Array(22.813635, dtype=float32), 'eval/episode_forward_reward': Array(3802.252, dtype=float32), 'eval/episode_reward': Array(3810.775, dtype=float32), 'eval/episode_reward_alive': Array(393.375, dtype=float32), 'eval/episode_reward_linvel': Array(3802.252, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.66577, dtype=float32), 'eval/episode_x_position': Array(5789.8984, dtype=float32), 'eval/episode_x_velocity': Array(760.45044, dtype=float32), 'eval/episode_y_position': Array(-262.40234, dtype=float32), 'eval/episode_y_velocity': Array(-179.8646, dtype=float32), 'eval/episode_distance_from_origin_std': Array(580.249, dtype=float32), 'eval/episode_distance_reward_std': Array(6.424984, dtype=float32), 'eval/episode_forward_reward_std': Array(1070.8231, dtype=float32), 'eval/episode_reward_std': Array(1065.059, dtype=float32), 'eval/episode_reward_alive_std': Array(51.312843, dtype=float32), 'eval/episode_reward_linvel_std': Array(1070.8231, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.594736, dtype=float32), 'eval/episode_x_position_std': Array(576.9032, dtype=float32), 'eval/episode_x_velocity_std': Array(214.16461, dtype=float32), 'eval/episode_y_position_std': Array(264.68878, dtype=float32), 'eval/episode_y_velocity_std': Array(97.25047, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55967926979065, 'eval/sps': 937.3191317117848, 'num_steps': 34816000}
{'eval/walltime': 58321.936499118805, 'training/sps': 2952.072782241872, 'training/walltime': 11871.873056411743, 'training/entropy_loss': Array(0.0133833, dtype=float32), 'training/policy_loss': Array(0.00735109, dtype=float32), 'training/total_loss': Array(0.1106566, dtype=float32), 'training/v_loss': Array(0.08992222, dtype=float32), 'eval/episode_distance_from_origin': Array(5920.627, dtype=float32), 'eval/episode_distance_reward': Array(23.01656, dtype=float32), 'eval/episode_forward_reward': Array(3836.0728, dtype=float32), 'eval/episode_reward': Array(3847.3174, dtype=float32), 'eval/episode_reward_alive': Array(395.73047, dtype=float32), 'eval/episode_reward_linvel': Array(3836.0728, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.5025, dtype=float32), 'eval/episode_x_position': Array(5866.6245, dtype=float32), 'eval/episode_x_velocity': Array(767.2145, dtype=float32), 'eval/episode_y_position': Array(-268.0354, dtype=float32), 'eval/episode_y_velocity': Array(-170.04665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(584.48645, dtype=float32), 'eval/episode_distance_reward_std': Array(6.388731, dtype=float32), 'eval/episode_forward_reward_std': Array(1064.7802, dtype=float32), 'eval/episode_reward_std': Array(1058.6124, dtype=float32), 'eval/episode_reward_alive_std': Array(52.505985, dtype=float32), 'eval/episode_reward_linvel_std': Array(1064.7802, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.026468, dtype=float32), 'eval/episode_x_position_std': Array(580.8713, dtype=float32), 'eval/episode_x_velocity_std': Array(212.95604, dtype=float32), 'eval/episode_y_position_std': Array(280.57825, dtype=float32), 'eval/episode_y_velocity_std': Array(95.76974, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50627756118774, 'eval/sps': 937.6858140654017, 'num_steps': 34897920}
{'eval/walltime': 58458.48251461983, 'training/sps': 2961.853022458689, 'training/walltime': 11899.531417369843, 'training/entropy_loss': Array(0.01790402, dtype=float32), 'training/policy_loss': Array(0.01774304, dtype=float32), 'training/total_loss': Array(0.17265563, dtype=float32), 'training/v_loss': Array(0.13700856, dtype=float32), 'eval/episode_distance_from_origin': Array(5979.6367, dtype=float32), 'eval/episode_distance_reward': Array(23.29544, dtype=float32), 'eval/episode_forward_reward': Array(3882.5522, dtype=float32), 'eval/episode_reward': Array(3888.83, dtype=float32), 'eval/episode_reward_alive': Array(396.27734, dtype=float32), 'eval/episode_reward_linvel': Array(3882.5522, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.2952, dtype=float32), 'eval/episode_x_position': Array(5925.3184, dtype=float32), 'eval/episode_x_velocity': Array(776.51056, dtype=float32), 'eval/episode_y_position': Array(-236.36064, dtype=float32), 'eval/episode_y_velocity': Array(-161.05025, dtype=float32), 'eval/episode_distance_from_origin_std': Array(540.96893, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0160103, dtype=float32), 'eval/episode_forward_reward_std': Array(1002.66016, dtype=float32), 'eval/episode_reward_std': Array(998.9701, dtype=float32), 'eval/episode_reward_alive_std': Array(46.51457, dtype=float32), 'eval/episode_reward_linvel_std': Array(1002.66016, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.64062, dtype=float32), 'eval/episode_x_position_std': Array(537.9955, dtype=float32), 'eval/episode_x_velocity_std': Array(200.53203, dtype=float32), 'eval/episode_y_position_std': Array(304.66623, dtype=float32), 'eval/episode_y_velocity_std': Array(101.940994, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54601550102234, 'eval/sps': 937.4129265532589, 'num_steps': 34979840}
{'eval/walltime': 58595.00688648224, 'training/sps': 2951.740789757663, 'training/walltime': 11927.284531831741, 'training/entropy_loss': Array(0.01383967, dtype=float32), 'training/policy_loss': Array(0.00785659, dtype=float32), 'training/total_loss': Array(0.09907682, dtype=float32), 'training/v_loss': Array(0.07738058, dtype=float32), 'eval/episode_distance_from_origin': Array(5993.84, dtype=float32), 'eval/episode_distance_reward': Array(23.896128, dtype=float32), 'eval/episode_forward_reward': Array(3982.6665, dtype=float32), 'eval/episode_reward': Array(3990.741, dtype=float32), 'eval/episode_reward_alive': Array(394.1914, dtype=float32), 'eval/episode_reward_linvel': Array(3982.6665, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.0134, dtype=float32), 'eval/episode_x_position': Array(5940.715, dtype=float32), 'eval/episode_x_velocity': Array(796.5334, dtype=float32), 'eval/episode_y_position': Array(-250.40414, dtype=float32), 'eval/episode_y_velocity': Array(-170.97491, dtype=float32), 'eval/episode_distance_from_origin_std': Array(540.4474, dtype=float32), 'eval/episode_distance_reward_std': Array(6.232529, dtype=float32), 'eval/episode_forward_reward_std': Array(1038.7457, dtype=float32), 'eval/episode_reward_std': Array(1034.3246, dtype=float32), 'eval/episode_reward_alive_std': Array(48.154297, dtype=float32), 'eval/episode_reward_linvel_std': Array(1038.7457, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.371433, dtype=float32), 'eval/episode_x_position_std': Array(536.62213, dtype=float32), 'eval/episode_x_velocity_std': Array(207.74919, dtype=float32), 'eval/episode_y_position_std': Array(259.02496, dtype=float32), 'eval/episode_y_velocity_std': Array(96.265816, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5243718624115, 'eval/sps': 937.5615375765851, 'num_steps': 35061760}
{'eval/walltime': 58731.5733628273, 'training/sps': 2952.696925309046, 'training/walltime': 11955.02865934372, 'training/entropy_loss': Array(0.01466923, dtype=float32), 'training/policy_loss': Array(0.00214302, dtype=float32), 'training/total_loss': Array(0.11811149, dtype=float32), 'training/v_loss': Array(0.10129924, dtype=float32), 'eval/episode_distance_from_origin': Array(5973.3857, dtype=float32), 'eval/episode_distance_reward': Array(23.995266, dtype=float32), 'eval/episode_forward_reward': Array(3999.1897, dtype=float32), 'eval/episode_reward': Array(4005.7725, dtype=float32), 'eval/episode_reward_alive': Array(394.1211, dtype=float32), 'eval/episode_reward_linvel': Array(3999.1897, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.53333, dtype=float32), 'eval/episode_x_position': Array(5921.6836, dtype=float32), 'eval/episode_x_velocity': Array(799.8379, dtype=float32), 'eval/episode_y_position': Array(-206.66547, dtype=float32), 'eval/episode_y_velocity': Array(-163.96887, dtype=float32), 'eval/episode_distance_from_origin_std': Array(577.3721, dtype=float32), 'eval/episode_distance_reward_std': Array(6.8727884, dtype=float32), 'eval/episode_forward_reward_std': Array(1145.4556, dtype=float32), 'eval/episode_reward_std': Array(1138.6816, dtype=float32), 'eval/episode_reward_alive_std': Array(46.39764, dtype=float32), 'eval/episode_reward_linvel_std': Array(1145.4556, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.88086, dtype=float32), 'eval/episode_x_position_std': Array(574.18335, dtype=float32), 'eval/episode_x_velocity_std': Array(229.09114, dtype=float32), 'eval/episode_y_position_std': Array(281.10724, dtype=float32), 'eval/episode_y_velocity_std': Array(99.964325, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56647634506226, 'eval/sps': 937.272480228476, 'num_steps': 35143680}
{'eval/walltime': 58868.0999147892, 'training/sps': 2963.417400329363, 'training/walltime': 11982.672419548035, 'training/entropy_loss': Array(0.01500192, dtype=float32), 'training/policy_loss': Array(0.0071603, dtype=float32), 'training/total_loss': Array(0.1466536, dtype=float32), 'training/v_loss': Array(0.12449138, dtype=float32), 'eval/episode_distance_from_origin': Array(6064.1562, dtype=float32), 'eval/episode_distance_reward': Array(25.216774, dtype=float32), 'eval/episode_forward_reward': Array(4202.7725, dtype=float32), 'eval/episode_reward': Array(4217.0195, dtype=float32), 'eval/episode_reward_alive': Array(394.92578, dtype=float32), 'eval/episode_reward_linvel': Array(4202.7725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.89612, dtype=float32), 'eval/episode_x_position': Array(6010.6685, dtype=float32), 'eval/episode_x_velocity': Array(840.5546, dtype=float32), 'eval/episode_y_position': Array(-247.94257, dtype=float32), 'eval/episode_y_velocity': Array(-185.71024, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.20502, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0518875, dtype=float32), 'eval/episode_forward_reward_std': Array(1008.64026, dtype=float32), 'eval/episode_reward_std': Array(1007.7441, dtype=float32), 'eval/episode_reward_alive_std': Array(40.659702, dtype=float32), 'eval/episode_reward_linvel_std': Array(1008.64026, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.171545, dtype=float32), 'eval/episode_x_position_std': Array(504.94785, dtype=float32), 'eval/episode_x_velocity_std': Array(201.72806, dtype=float32), 'eval/episode_y_position_std': Array(234.69226, dtype=float32), 'eval/episode_y_velocity_std': Array(82.40785, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5265519618988, 'eval/sps': 937.5465662951896, 'num_steps': 35225600}
{'eval/walltime': 59004.69183969498, 'training/sps': 2971.6810364596645, 'training/walltime': 12010.23930811882, 'training/entropy_loss': Array(0.0146825, dtype=float32), 'training/policy_loss': Array(0.00250535, dtype=float32), 'training/total_loss': Array(0.14178573, dtype=float32), 'training/v_loss': Array(0.12459788, dtype=float32), 'eval/episode_distance_from_origin': Array(6120.163, dtype=float32), 'eval/episode_distance_reward': Array(25.524536, dtype=float32), 'eval/episode_forward_reward': Array(4254.0654, dtype=float32), 'eval/episode_reward': Array(4261.2007, dtype=float32), 'eval/episode_reward_alive': Array(386.02344, dtype=float32), 'eval/episode_reward_linvel': Array(4254.0654, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.41315, dtype=float32), 'eval/episode_x_position': Array(6064.455, dtype=float32), 'eval/episode_x_velocity': Array(850.8131, dtype=float32), 'eval/episode_y_position': Array(-268.86755, dtype=float32), 'eval/episode_y_velocity': Array(-192.47928, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.7494, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0558443, dtype=float32), 'eval/episode_forward_reward_std': Array(842.6339, dtype=float32), 'eval/episode_reward_std': Array(842.57153, dtype=float32), 'eval/episode_reward_alive_std': Array(44.69737, dtype=float32), 'eval/episode_reward_linvel_std': Array(842.6339, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.802652, dtype=float32), 'eval/episode_x_position_std': Array(437.55118, dtype=float32), 'eval/episode_x_velocity_std': Array(168.52686, dtype=float32), 'eval/episode_y_position_std': Array(279.14465, dtype=float32), 'eval/episode_y_velocity_std': Array(94.010124, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59192490577698, 'eval/sps': 937.0978561748522, 'num_steps': 35307520}
{'eval/walltime': 59141.22047138214, 'training/sps': 2968.5135224682504, 'training/walltime': 12037.835611581802, 'training/entropy_loss': Array(0.01133668, dtype=float32), 'training/policy_loss': Array(0.00745654, dtype=float32), 'training/total_loss': Array(0.09375563, dtype=float32), 'training/v_loss': Array(0.07496241, dtype=float32), 'eval/episode_distance_from_origin': Array(6167.872, dtype=float32), 'eval/episode_distance_reward': Array(26.148115, dtype=float32), 'eval/episode_forward_reward': Array(4357.9956, dtype=float32), 'eval/episode_reward': Array(4360.8, dtype=float32), 'eval/episode_reward_alive': Array(382.51172, dtype=float32), 'eval/episode_reward_linvel': Array(4357.9956, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.85486, dtype=float32), 'eval/episode_x_position': Array(6114.4883, dtype=float32), 'eval/episode_x_velocity': Array(871.59906, dtype=float32), 'eval/episode_y_position': Array(-262.87952, dtype=float32), 'eval/episode_y_velocity': Array(-189.47627, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.16623, dtype=float32), 'eval/episode_distance_reward_std': Array(5.703026, dtype=float32), 'eval/episode_forward_reward_std': Array(950.49677, dtype=float32), 'eval/episode_reward_std': Array(956.91034, dtype=float32), 'eval/episode_reward_alive_std': Array(41.415363, dtype=float32), 'eval/episode_reward_linvel_std': Array(950.49677, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.7457, dtype=float32), 'eval/episode_x_position_std': Array(473.44806, dtype=float32), 'eval/episode_x_velocity_std': Array(190.09932, dtype=float32), 'eval/episode_y_position_std': Array(251.17575, dtype=float32), 'eval/episode_y_velocity_std': Array(88.35309, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5286316871643, 'eval/sps': 937.5322847539669, 'num_steps': 35389440}
{'eval/walltime': 59277.78868341446, 'training/sps': 2975.0924994125967, 'training/walltime': 12065.370889902115, 'training/entropy_loss': Array(0.01708437, dtype=float32), 'training/policy_loss': Array(0.0056691, dtype=float32), 'training/total_loss': Array(0.12588134, dtype=float32), 'training/v_loss': Array(0.10312788, dtype=float32), 'eval/episode_distance_from_origin': Array(6223.066, dtype=float32), 'eval/episode_distance_reward': Array(26.759491, dtype=float32), 'eval/episode_forward_reward': Array(4459.89, dtype=float32), 'eval/episode_reward': Array(4465.882, dtype=float32), 'eval/episode_reward_alive': Array(380.02734, dtype=float32), 'eval/episode_reward_linvel': Array(4459.89, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.79477, dtype=float32), 'eval/episode_x_position': Array(6169.998, dtype=float32), 'eval/episode_x_velocity': Array(891.978, dtype=float32), 'eval/episode_y_position': Array(-249.98999, dtype=float32), 'eval/episode_y_velocity': Array(-187.07405, dtype=float32), 'eval/episode_distance_from_origin_std': Array(486.22092, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5079966, dtype=float32), 'eval/episode_forward_reward_std': Array(917.9924, dtype=float32), 'eval/episode_reward_std': Array(917.9252, dtype=float32), 'eval/episode_reward_alive_std': Array(45.17195, dtype=float32), 'eval/episode_reward_linvel_std': Array(917.9924, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.408554, dtype=float32), 'eval/episode_x_position_std': Array(487.01953, dtype=float32), 'eval/episode_x_velocity_std': Array(183.59848, dtype=float32), 'eval/episode_y_position_std': Array(274.72745, dtype=float32), 'eval/episode_y_velocity_std': Array(91.75411, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56821203231812, 'eval/sps': 937.2605681453126, 'num_steps': 35471360}
{'eval/walltime': 59414.21425175667, 'training/sps': 2964.7656378492043, 'training/walltime': 12093.00207901001, 'training/entropy_loss': Array(0.01580582, dtype=float32), 'training/policy_loss': Array(0.00551971, dtype=float32), 'training/total_loss': Array(0.13203561, dtype=float32), 'training/v_loss': Array(0.11071008, dtype=float32), 'eval/episode_distance_from_origin': Array(6161.1973, dtype=float32), 'eval/episode_distance_reward': Array(26.108582, dtype=float32), 'eval/episode_forward_reward': Array(4351.4062, dtype=float32), 'eval/episode_reward': Array(4358.6816, dtype=float32), 'eval/episode_reward_alive': Array(382.16797, dtype=float32), 'eval/episode_reward_linvel': Array(4351.4062, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.00143, dtype=float32), 'eval/episode_x_position': Array(6108.2324, dtype=float32), 'eval/episode_x_velocity': Array(870.28125, dtype=float32), 'eval/episode_y_position': Array(-245.22008, dtype=float32), 'eval/episode_y_velocity': Array(-189.74338, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.97476, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3196244, dtype=float32), 'eval/episode_forward_reward_std': Array(886.5979, dtype=float32), 'eval/episode_reward_std': Array(891.1956, dtype=float32), 'eval/episode_reward_alive_std': Array(41.138786, dtype=float32), 'eval/episode_reward_linvel_std': Array(886.5979, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.863167, dtype=float32), 'eval/episode_x_position_std': Array(468.7523, dtype=float32), 'eval/episode_x_velocity_std': Array(177.31961, dtype=float32), 'eval/episode_y_position_std': Array(252.6279, dtype=float32), 'eval/episode_y_velocity_std': Array(82.54101, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42556834220886, 'eval/sps': 938.2405479809017, 'num_steps': 35553280}
{'eval/walltime': 59550.74870920181, 'training/sps': 2962.588973449586, 'training/walltime': 12120.653569221497, 'training/entropy_loss': Array(0.0144853, dtype=float32), 'training/policy_loss': Array(0.00623228, dtype=float32), 'training/total_loss': Array(0.13102679, dtype=float32), 'training/v_loss': Array(0.11030921, dtype=float32), 'eval/episode_distance_from_origin': Array(6177.1626, dtype=float32), 'eval/episode_distance_reward': Array(26.302647, dtype=float32), 'eval/episode_forward_reward': Array(4383.7505, dtype=float32), 'eval/episode_reward': Array(4392.6377, dtype=float32), 'eval/episode_reward_alive': Array(379.34375, dtype=float32), 'eval/episode_reward_linvel': Array(4383.7505, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.75922, dtype=float32), 'eval/episode_x_position': Array(6124.6514, dtype=float32), 'eval/episode_x_velocity': Array(876.7502, dtype=float32), 'eval/episode_y_position': Array(-228.60416, dtype=float32), 'eval/episode_y_velocity': Array(-175.87608, dtype=float32), 'eval/episode_distance_from_origin_std': Array(475.54364, dtype=float32), 'eval/episode_distance_reward_std': Array(5.666627, dtype=float32), 'eval/episode_forward_reward_std': Array(944.4306, dtype=float32), 'eval/episode_reward_std': Array(940.51385, dtype=float32), 'eval/episode_reward_alive_std': Array(50.750374, dtype=float32), 'eval/episode_reward_linvel_std': Array(944.4306, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.111988, dtype=float32), 'eval/episode_x_position_std': Array(472.79852, dtype=float32), 'eval/episode_x_velocity_std': Array(188.88622, dtype=float32), 'eval/episode_y_position_std': Array(277.49286, dtype=float32), 'eval/episode_y_velocity_std': Array(94.055214, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53445744514465, 'eval/sps': 937.4922814002939, 'num_steps': 35635200}
{'eval/walltime': 59687.17686533928, 'training/sps': 2967.33517437329, 'training/walltime': 12148.260831356049, 'training/entropy_loss': Array(0.01449726, dtype=float32), 'training/policy_loss': Array(0.00355944, dtype=float32), 'training/total_loss': Array(0.14173843, dtype=float32), 'training/v_loss': Array(0.12368172, dtype=float32), 'eval/episode_distance_from_origin': Array(6173.962, dtype=float32), 'eval/episode_distance_reward': Array(25.850801, dtype=float32), 'eval/episode_forward_reward': Array(4308.4434, dtype=float32), 'eval/episode_reward': Array(4315.633, dtype=float32), 'eval/episode_reward_alive': Array(384.73438, dtype=float32), 'eval/episode_reward_linvel': Array(4308.4434, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.39545, dtype=float32), 'eval/episode_x_position': Array(6121.4287, dtype=float32), 'eval/episode_x_velocity': Array(861.68866, dtype=float32), 'eval/episode_y_position': Array(-213.90662, dtype=float32), 'eval/episode_y_velocity': Array(-171.81181, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.01776, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0666156, dtype=float32), 'eval/episode_forward_reward_std': Array(1011.0946, dtype=float32), 'eval/episode_reward_std': Array(1006.5772, dtype=float32), 'eval/episode_reward_alive_std': Array(47.052948, dtype=float32), 'eval/episode_reward_linvel_std': Array(1011.0946, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.088417, dtype=float32), 'eval/episode_x_position_std': Array(478.6318, dtype=float32), 'eval/episode_x_velocity_std': Array(202.219, dtype=float32), 'eval/episode_y_position_std': Array(290.94693, dtype=float32), 'eval/episode_y_velocity_std': Array(92.20407, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42815613746643, 'eval/sps': 938.2227512554364, 'num_steps': 35717120}
{'eval/walltime': 59823.83020544052, 'training/sps': 2967.8778560740516, 'training/walltime': 12175.863045454025, 'training/entropy_loss': Array(0.01443682, dtype=float32), 'training/policy_loss': Array(0.0176732, dtype=float32), 'training/total_loss': Array(0.1940454, dtype=float32), 'training/v_loss': Array(0.16193536, dtype=float32), 'eval/episode_distance_from_origin': Array(6211.685, dtype=float32), 'eval/episode_distance_reward': Array(26.316227, dtype=float32), 'eval/episode_forward_reward': Array(4386.0137, dtype=float32), 'eval/episode_reward': Array(4388.5205, dtype=float32), 'eval/episode_reward_alive': Array(376.82422, dtype=float32), 'eval/episode_reward_linvel': Array(4386.0137, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.63342, dtype=float32), 'eval/episode_x_position': Array(6159.7505, dtype=float32), 'eval/episode_x_velocity': Array(877.2027, dtype=float32), 'eval/episode_y_position': Array(-213.99579, dtype=float32), 'eval/episode_y_velocity': Array(-177.45807, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.22015, dtype=float32), 'eval/episode_distance_reward_std': Array(5.461882, dtype=float32), 'eval/episode_forward_reward_std': Array(910.30554, dtype=float32), 'eval/episode_reward_std': Array(907.2747, dtype=float32), 'eval/episode_reward_alive_std': Array(48.612534, dtype=float32), 'eval/episode_reward_linvel_std': Array(910.30554, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.731014, dtype=float32), 'eval/episode_x_position_std': Array(443.70648, dtype=float32), 'eval/episode_x_velocity_std': Array(182.06114, dtype=float32), 'eval/episode_y_position_std': Array(292.8406, dtype=float32), 'eval/episode_y_velocity_std': Array(91.15599, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65334010124207, 'eval/sps': 936.6767025611589, 'num_steps': 35799040}
{'eval/walltime': 59960.257088661194, 'training/sps': 2964.3573064384823, 'training/walltime': 12203.498040676117, 'training/entropy_loss': Array(0.01199225, dtype=float32), 'training/policy_loss': Array(0.00609988, dtype=float32), 'training/total_loss': Array(0.10903915, dtype=float32), 'training/v_loss': Array(0.09094702, dtype=float32), 'eval/episode_distance_from_origin': Array(6217.6055, dtype=float32), 'eval/episode_distance_reward': Array(26.596249, dtype=float32), 'eval/episode_forward_reward': Array(4432.6836, dtype=float32), 'eval/episode_reward': Array(4438.7627, dtype=float32), 'eval/episode_reward_alive': Array(377.73438, dtype=float32), 'eval/episode_reward_linvel': Array(4432.6836, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.25195, dtype=float32), 'eval/episode_x_position': Array(6166.385, dtype=float32), 'eval/episode_x_velocity': Array(886.5368, dtype=float32), 'eval/episode_y_position': Array(-246.11433, dtype=float32), 'eval/episode_y_velocity': Array(-183.93631, dtype=float32), 'eval/episode_distance_from_origin_std': Array(454.92548, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2943525, dtype=float32), 'eval/episode_forward_reward_std': Array(882.38525, dtype=float32), 'eval/episode_reward_std': Array(872.9709, dtype=float32), 'eval/episode_reward_alive_std': Array(48.7866, dtype=float32), 'eval/episode_reward_linvel_std': Array(882.38525, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.027304, dtype=float32), 'eval/episode_x_position_std': Array(456.30368, dtype=float32), 'eval/episode_x_velocity_std': Array(176.47697, dtype=float32), 'eval/episode_y_position_std': Array(231.77477, dtype=float32), 'eval/episode_y_velocity_std': Array(74.959526, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4268832206726, 'eval/sps': 938.2315052448864, 'num_steps': 35880960}
{'eval/walltime': 60096.85121846199, 'training/sps': 2969.685594416527, 'training/walltime': 12231.08345246315, 'training/entropy_loss': Array(0.01715933, dtype=float32), 'training/policy_loss': Array(0.00920169, dtype=float32), 'training/total_loss': Array(0.1172585, dtype=float32), 'training/v_loss': Array(0.09089749, dtype=float32), 'eval/episode_distance_from_origin': Array(6205.4414, dtype=float32), 'eval/episode_distance_reward': Array(27.271448, dtype=float32), 'eval/episode_forward_reward': Array(4545.216, dtype=float32), 'eval/episode_reward': Array(4552.914, dtype=float32), 'eval/episode_reward_alive': Array(374.98828, dtype=float32), 'eval/episode_reward_linvel': Array(4545.216, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.5609, dtype=float32), 'eval/episode_x_position': Array(6153.461, dtype=float32), 'eval/episode_x_velocity': Array(909.0431, dtype=float32), 'eval/episode_y_position': Array(-221.78754, dtype=float32), 'eval/episode_y_velocity': Array(-189.32324, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.03088, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2018547, dtype=float32), 'eval/episode_forward_reward_std': Array(866.96893, dtype=float32), 'eval/episode_reward_std': Array(865.1821, dtype=float32), 'eval/episode_reward_alive_std': Array(43.10744, dtype=float32), 'eval/episode_reward_linvel_std': Array(866.96893, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.070711, dtype=float32), 'eval/episode_x_position_std': Array(444.94952, dtype=float32), 'eval/episode_x_velocity_std': Array(173.39378, dtype=float32), 'eval/episode_y_position_std': Array(247.4572, dtype=float32), 'eval/episode_y_velocity_std': Array(76.28041, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5941298007965, 'eval/sps': 937.0827295921878, 'num_steps': 35962880}
{'eval/walltime': 60233.284752845764, 'training/sps': 2962.978804269761, 'training/walltime': 12258.731304645538, 'training/entropy_loss': Array(0.01415628, dtype=float32), 'training/policy_loss': Array(0.00465432, dtype=float32), 'training/total_loss': Array(0.1362136, dtype=float32), 'training/v_loss': Array(0.11740299, dtype=float32), 'eval/episode_distance_from_origin': Array(6281.506, dtype=float32), 'eval/episode_distance_reward': Array(27.219, dtype=float32), 'eval/episode_forward_reward': Array(4536.4746, dtype=float32), 'eval/episode_reward': Array(4540.1875, dtype=float32), 'eval/episode_reward_alive': Array(376.1172, dtype=float32), 'eval/episode_reward_linvel': Array(4536.4746, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.62372, dtype=float32), 'eval/episode_x_position': Array(6227.67, dtype=float32), 'eval/episode_x_velocity': Array(907.29486, dtype=float32), 'eval/episode_y_position': Array(-284.3556, dtype=float32), 'eval/episode_y_velocity': Array(-191.88103, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.81766, dtype=float32), 'eval/episode_distance_reward_std': Array(4.882263, dtype=float32), 'eval/episode_forward_reward_std': Array(813.70435, dtype=float32), 'eval/episode_reward_std': Array(807.5124, dtype=float32), 'eval/episode_reward_alive_std': Array(49.8144, dtype=float32), 'eval/episode_reward_linvel_std': Array(813.70435, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.432966, dtype=float32), 'eval/episode_x_position_std': Array(420.27988, dtype=float32), 'eval/episode_x_velocity_std': Array(162.7408, dtype=float32), 'eval/episode_y_position_std': Array(248.57727, dtype=float32), 'eval/episode_y_velocity_std': Array(78.46302, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4335343837738, 'eval/sps': 938.1857662643913, 'num_steps': 36044800}
{'eval/walltime': 60369.81173348427, 'training/sps': 2972.031360324854, 'training/walltime': 12286.29494380951, 'training/entropy_loss': Array(0.01415498, dtype=float32), 'training/policy_loss': Array(0.00492246, dtype=float32), 'training/total_loss': Array(0.12796974, dtype=float32), 'training/v_loss': Array(0.10889229, dtype=float32), 'eval/episode_distance_from_origin': Array(6341.279, dtype=float32), 'eval/episode_distance_reward': Array(27.777739, dtype=float32), 'eval/episode_forward_reward': Array(4629.596, dtype=float32), 'eval/episode_reward': Array(4631.0137, dtype=float32), 'eval/episode_reward_alive': Array(374.23828, dtype=float32), 'eval/episode_reward_linvel': Array(4629.596, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.5988, dtype=float32), 'eval/episode_x_position': Array(6289.2817, dtype=float32), 'eval/episode_x_velocity': Array(925.9194, dtype=float32), 'eval/episode_y_position': Array(-262.03323, dtype=float32), 'eval/episode_y_velocity': Array(-188.24335, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.41315, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0735, dtype=float32), 'eval/episode_forward_reward_std': Array(845.57666, dtype=float32), 'eval/episode_reward_std': Array(843.45184, dtype=float32), 'eval/episode_reward_alive_std': Array(48.08874, dtype=float32), 'eval/episode_reward_linvel_std': Array(845.57666, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.034887, dtype=float32), 'eval/episode_x_position_std': Array(444.94562, dtype=float32), 'eval/episode_x_velocity_std': Array(169.1154, dtype=float32), 'eval/episode_y_position_std': Array(255.9573, dtype=float32), 'eval/episode_y_velocity_std': Array(79.26903, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52698063850403, 'eval/sps': 937.5436225233622, 'num_steps': 36126720}
{'eval/walltime': 60506.249505996704, 'training/sps': 2961.5897390029177, 'training/walltime': 12313.955763578415, 'training/entropy_loss': Array(0.01461084, dtype=float32), 'training/policy_loss': Array(0.00327979, dtype=float32), 'training/total_loss': Array(0.15957329, dtype=float32), 'training/v_loss': Array(0.14168265, dtype=float32), 'eval/episode_distance_from_origin': Array(6332.8555, dtype=float32), 'eval/episode_distance_reward': Array(28.127993, dtype=float32), 'eval/episode_forward_reward': Array(4687.972, dtype=float32), 'eval/episode_reward': Array(4693.9766, dtype=float32), 'eval/episode_reward_alive': Array(378.5586, dtype=float32), 'eval/episode_reward_linvel': Array(4687.972, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.68213, dtype=float32), 'eval/episode_x_position': Array(6280.8906, dtype=float32), 'eval/episode_x_velocity': Array(937.5945, dtype=float32), 'eval/episode_y_position': Array(-252.74655, dtype=float32), 'eval/episode_y_velocity': Array(-184.34438, dtype=float32), 'eval/episode_distance_from_origin_std': Array(530.554, dtype=float32), 'eval/episode_distance_reward_std': Array(5.874914, dtype=float32), 'eval/episode_forward_reward_std': Array(979.1448, dtype=float32), 'eval/episode_reward_std': Array(972.6248, dtype=float32), 'eval/episode_reward_alive_std': Array(48.238327, dtype=float32), 'eval/episode_reward_linvel_std': Array(979.1448, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.199934, dtype=float32), 'eval/episode_x_position_std': Array(530.3925, dtype=float32), 'eval/episode_x_velocity_std': Array(195.829, dtype=float32), 'eval/episode_y_position_std': Array(260.69058, dtype=float32), 'eval/episode_y_velocity_std': Array(80.58379, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4377725124359, 'eval/sps': 938.1566236603076, 'num_steps': 36208640}
{'eval/walltime': 60642.78904604912, 'training/sps': 2958.5034246530818, 'training/walltime': 12341.64543914795, 'training/entropy_loss': Array(0.01477298, dtype=float32), 'training/policy_loss': Array(0.00238112, dtype=float32), 'training/total_loss': Array(0.19240475, dtype=float32), 'training/v_loss': Array(0.17525065, dtype=float32), 'eval/episode_distance_from_origin': Array(6405.707, dtype=float32), 'eval/episode_distance_reward': Array(28.742273, dtype=float32), 'eval/episode_forward_reward': Array(4790.3516, dtype=float32), 'eval/episode_reward': Array(4798.511, dtype=float32), 'eval/episode_reward_alive': Array(377.05078, dtype=float32), 'eval/episode_reward_linvel': Array(4790.3516, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.63336, dtype=float32), 'eval/episode_x_position': Array(6353.429, dtype=float32), 'eval/episode_x_velocity': Array(958.0704, dtype=float32), 'eval/episode_y_position': Array(-251.17862, dtype=float32), 'eval/episode_y_velocity': Array(-186.61064, dtype=float32), 'eval/episode_distance_from_origin_std': Array(424.60046, dtype=float32), 'eval/episode_distance_reward_std': Array(4.537998, dtype=float32), 'eval/episode_forward_reward_std': Array(756.32715, dtype=float32), 'eval/episode_reward_std': Array(753.56445, dtype=float32), 'eval/episode_reward_alive_std': Array(40.302605, dtype=float32), 'eval/episode_reward_linvel_std': Array(756.32715, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.990837, dtype=float32), 'eval/episode_x_position_std': Array(427.00827, dtype=float32), 'eval/episode_x_velocity_std': Array(151.2654, dtype=float32), 'eval/episode_y_position_std': Array(247.17384, dtype=float32), 'eval/episode_y_velocity_std': Array(72.9488, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53954005241394, 'eval/sps': 937.457383779557, 'num_steps': 36290560}
{'eval/walltime': 60779.21851539612, 'training/sps': 2969.0342635298066, 'training/walltime': 12369.236902475357, 'training/entropy_loss': Array(0.01295523, dtype=float32), 'training/policy_loss': Array(0.00285522, dtype=float32), 'training/total_loss': Array(0.1461997, dtype=float32), 'training/v_loss': Array(0.13038924, dtype=float32), 'eval/episode_distance_from_origin': Array(6418.592, dtype=float32), 'eval/episode_distance_reward': Array(28.486986, dtype=float32), 'eval/episode_forward_reward': Array(4747.804, dtype=float32), 'eval/episode_reward': Array(4744.4424, dtype=float32), 'eval/episode_reward_alive': Array(371.53516, dtype=float32), 'eval/episode_reward_linvel': Array(4747.804, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.38345, dtype=float32), 'eval/episode_x_position': Array(6364.2935, dtype=float32), 'eval/episode_x_velocity': Array(949.5608, dtype=float32), 'eval/episode_y_position': Array(-286.0284, dtype=float32), 'eval/episode_y_velocity': Array(-191.32692, dtype=float32), 'eval/episode_distance_from_origin_std': Array(442.8397, dtype=float32), 'eval/episode_distance_reward_std': Array(5.073634, dtype=float32), 'eval/episode_forward_reward_std': Array(845.59875, dtype=float32), 'eval/episode_reward_std': Array(848.5061, dtype=float32), 'eval/episode_reward_alive_std': Array(47.850155, dtype=float32), 'eval/episode_reward_linvel_std': Array(845.59875, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.300316, dtype=float32), 'eval/episode_x_position_std': Array(441.809, dtype=float32), 'eval/episode_x_velocity_std': Array(169.11978, dtype=float32), 'eval/episode_y_position_std': Array(280.8176, dtype=float32), 'eval/episode_y_velocity_std': Array(88.012115, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42946934700012, 'eval/sps': 938.2137203395531, 'num_steps': 36372480}
{'eval/walltime': 60915.74240541458, 'training/sps': 2967.8784969622893, 'training/walltime': 12396.83911061287, 'training/entropy_loss': Array(0.01492955, dtype=float32), 'training/policy_loss': Array(0.00557653, dtype=float32), 'training/total_loss': Array(0.10650621, dtype=float32), 'training/v_loss': Array(0.08600013, dtype=float32), 'eval/episode_distance_from_origin': Array(6417.2793, dtype=float32), 'eval/episode_distance_reward': Array(28.611858, dtype=float32), 'eval/episode_forward_reward': Array(4768.615, dtype=float32), 'eval/episode_reward': Array(4767.8623, dtype=float32), 'eval/episode_reward_alive': Array(375.2461, dtype=float32), 'eval/episode_reward_linvel': Array(4768.615, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.61148, dtype=float32), 'eval/episode_x_position': Array(6362.6685, dtype=float32), 'eval/episode_x_velocity': Array(953.72314, dtype=float32), 'eval/episode_y_position': Array(-290.19135, dtype=float32), 'eval/episode_y_velocity': Array(-197.13208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.47495, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1681366, dtype=float32), 'eval/episode_forward_reward_std': Array(861.3486, dtype=float32), 'eval/episode_reward_std': Array(859.42566, dtype=float32), 'eval/episode_reward_alive_std': Array(48.46237, dtype=float32), 'eval/episode_reward_linvel_std': Array(861.3486, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.48614, dtype=float32), 'eval/episode_x_position_std': Array(416.80872, dtype=float32), 'eval/episode_x_velocity_std': Array(172.26979, dtype=float32), 'eval/episode_y_position_std': Array(279.00546, dtype=float32), 'eval/episode_y_velocity_std': Array(81.98915, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52389001846313, 'eval/sps': 937.5648465824524, 'num_steps': 36454400}
{'eval/walltime': 61052.17896556854, 'training/sps': 2960.844971613674, 'training/walltime': 12424.506888151169, 'training/entropy_loss': Array(0.01698509, dtype=float32), 'training/policy_loss': Array(0.0078495, dtype=float32), 'training/total_loss': Array(0.17841199, dtype=float32), 'training/v_loss': Array(0.15357739, dtype=float32), 'eval/episode_distance_from_origin': Array(6358.243, dtype=float32), 'eval/episode_distance_reward': Array(27.615063, dtype=float32), 'eval/episode_forward_reward': Array(4602.4844, dtype=float32), 'eval/episode_reward': Array(4599.011, dtype=float32), 'eval/episode_reward_alive': Array(374.33594, dtype=float32), 'eval/episode_reward_linvel': Array(4602.4844, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.4245, dtype=float32), 'eval/episode_x_position': Array(6303.2285, dtype=float32), 'eval/episode_x_velocity': Array(920.49695, dtype=float32), 'eval/episode_y_position': Array(-296.70383, dtype=float32), 'eval/episode_y_velocity': Array(-193.31238, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.6739, dtype=float32), 'eval/episode_distance_reward_std': Array(5.415823, dtype=float32), 'eval/episode_forward_reward_std': Array(902.63, dtype=float32), 'eval/episode_reward_std': Array(902.86487, dtype=float32), 'eval/episode_reward_alive_std': Array(45.103096, dtype=float32), 'eval/episode_reward_linvel_std': Array(902.63, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.12116, dtype=float32), 'eval/episode_x_position_std': Array(484.4985, dtype=float32), 'eval/episode_x_velocity_std': Array(180.52611, dtype=float32), 'eval/episode_y_position_std': Array(251.55415, dtype=float32), 'eval/episode_y_velocity_std': Array(76.68109, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43656015396118, 'eval/sps': 938.1649600045546, 'num_steps': 36536320}
{'eval/walltime': 61188.70417261124, 'training/sps': 2946.598866476977, 'training/walltime': 12452.30843281746, 'training/entropy_loss': Array(0.014141, dtype=float32), 'training/policy_loss': Array(0.00625943, dtype=float32), 'training/total_loss': Array(0.11984906, dtype=float32), 'training/v_loss': Array(0.09944864, dtype=float32), 'eval/episode_distance_from_origin': Array(6378.1562, dtype=float32), 'eval/episode_distance_reward': Array(28.067516, dtype=float32), 'eval/episode_forward_reward': Array(4677.8926, dtype=float32), 'eval/episode_reward': Array(4681.0186, dtype=float32), 'eval/episode_reward_alive': Array(379.98438, dtype=float32), 'eval/episode_reward_linvel': Array(4677.8926, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.925, dtype=float32), 'eval/episode_x_position': Array(6322.321, dtype=float32), 'eval/episode_x_velocity': Array(935.5784, dtype=float32), 'eval/episode_y_position': Array(-265.7786, dtype=float32), 'eval/episode_y_velocity': Array(-192.11661, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.79855, dtype=float32), 'eval/episode_distance_reward_std': Array(5.242646, dtype=float32), 'eval/episode_forward_reward_std': Array(873.7675, dtype=float32), 'eval/episode_reward_std': Array(877.8481, dtype=float32), 'eval/episode_reward_alive_std': Array(50.926296, dtype=float32), 'eval/episode_reward_linvel_std': Array(873.7675, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.222502, dtype=float32), 'eval/episode_x_position_std': Array(456.252, dtype=float32), 'eval/episode_x_velocity_std': Array(174.75357, dtype=float32), 'eval/episode_y_position_std': Array(302.3756, dtype=float32), 'eval/episode_y_velocity_std': Array(91.31579, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5252070426941, 'eval/sps': 937.5558021308981, 'num_steps': 36618240}
{'eval/walltime': 61325.223888635635, 'training/sps': 2942.180251973455, 'training/walltime': 12480.151730298996, 'training/entropy_loss': Array(0.01493795, dtype=float32), 'training/policy_loss': Array(0.00367196, dtype=float32), 'training/total_loss': Array(0.16475362, dtype=float32), 'training/v_loss': Array(0.1461437, dtype=float32), 'eval/episode_distance_from_origin': Array(6426.5415, dtype=float32), 'eval/episode_distance_reward': Array(29.01791, dtype=float32), 'eval/episode_forward_reward': Array(4836.29, dtype=float32), 'eval/episode_reward': Array(4837.755, dtype=float32), 'eval/episode_reward_alive': Array(380.30078, dtype=float32), 'eval/episode_reward_linvel': Array(4836.29, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.8537, dtype=float32), 'eval/episode_x_position': Array(6373.205, dtype=float32), 'eval/episode_x_velocity': Array(967.2582, dtype=float32), 'eval/episode_y_position': Array(-224.56195, dtype=float32), 'eval/episode_y_velocity': Array(-186.07687, dtype=float32), 'eval/episode_distance_from_origin_std': Array(398.33112, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7232594, dtype=float32), 'eval/episode_forward_reward_std': Array(787.2034, dtype=float32), 'eval/episode_reward_std': Array(789.80963, dtype=float32), 'eval/episode_reward_alive_std': Array(45.29191, dtype=float32), 'eval/episode_reward_linvel_std': Array(787.2034, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.264137, dtype=float32), 'eval/episode_x_position_std': Array(400.38528, dtype=float32), 'eval/episode_x_velocity_std': Array(157.4407, dtype=float32), 'eval/episode_y_position_std': Array(307.9784, dtype=float32), 'eval/episode_y_velocity_std': Array(93.05026, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5197160243988, 'eval/sps': 937.5935119666074, 'num_steps': 36700160}
{'eval/walltime': 61461.75529909134, 'training/sps': 2938.4738471740966, 'training/walltime': 12508.03014755249, 'training/entropy_loss': Array(0.01436416, dtype=float32), 'training/policy_loss': Array(0.00240447, dtype=float32), 'training/total_loss': Array(0.18114665, dtype=float32), 'training/v_loss': Array(0.16437802, dtype=float32), 'eval/episode_distance_from_origin': Array(6537.8896, dtype=float32), 'eval/episode_distance_reward': Array(29.958126, dtype=float32), 'eval/episode_forward_reward': Array(4992.992, dtype=float32), 'eval/episode_reward': Array(4991.173, dtype=float32), 'eval/episode_reward_alive': Array(380.30078, dtype=float32), 'eval/episode_reward_linvel': Array(4992.992, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.07822, dtype=float32), 'eval/episode_x_position': Array(6486.5933, dtype=float32), 'eval/episode_x_velocity': Array(998.5984, dtype=float32), 'eval/episode_y_position': Array(-246.27573, dtype=float32), 'eval/episode_y_velocity': Array(-189.62453, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.11163, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6091247, dtype=float32), 'eval/episode_forward_reward_std': Array(934.8465, dtype=float32), 'eval/episode_reward_std': Array(935.94824, dtype=float32), 'eval/episode_reward_alive_std': Array(44.100796, dtype=float32), 'eval/episode_reward_linvel_std': Array(934.8465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.872272, dtype=float32), 'eval/episode_x_position_std': Array(477.6267, dtype=float32), 'eval/episode_x_velocity_std': Array(186.96933, dtype=float32), 'eval/episode_y_position_std': Array(243.56184, dtype=float32), 'eval/episode_y_velocity_std': Array(84.45286, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53141045570374, 'eval/sps': 937.5132035388174, 'num_steps': 36782080}
{'eval/walltime': 61598.20207285881, 'training/sps': 2940.137218172952, 'training/walltime': 12535.892792701721, 'training/entropy_loss': Array(0.01481705, dtype=float32), 'training/policy_loss': Array(0.00302931, dtype=float32), 'training/total_loss': Array(0.2072646, dtype=float32), 'training/v_loss': Array(0.18941824, dtype=float32), 'eval/episode_distance_from_origin': Array(6470.0566, dtype=float32), 'eval/episode_distance_reward': Array(29.789795, dtype=float32), 'eval/episode_forward_reward': Array(4964.936, dtype=float32), 'eval/episode_reward': Array(4971.9062, dtype=float32), 'eval/episode_reward_alive': Array(380.78125, dtype=float32), 'eval/episode_reward_linvel': Array(4964.936, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.6018, dtype=float32), 'eval/episode_x_position': Array(6420.722, dtype=float32), 'eval/episode_x_velocity': Array(992.9874, dtype=float32), 'eval/episode_y_position': Array(-148.63002, dtype=float32), 'eval/episode_y_velocity': Array(-167.00597, dtype=float32), 'eval/episode_distance_from_origin_std': Array(437.97226, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9827676, dtype=float32), 'eval/episode_forward_reward_std': Array(830.4549, dtype=float32), 'eval/episode_reward_std': Array(831.8947, dtype=float32), 'eval/episode_reward_alive_std': Array(42.016308, dtype=float32), 'eval/episode_reward_linvel_std': Array(830.4549, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.75828, dtype=float32), 'eval/episode_x_position_std': Array(440.5831, dtype=float32), 'eval/episode_x_velocity_std': Array(166.09102, dtype=float32), 'eval/episode_y_position_std': Array(301.53537, dtype=float32), 'eval/episode_y_velocity_std': Array(93.29663, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4467737674713, 'eval/sps': 938.0947344210126, 'num_steps': 36864000}
{'eval/walltime': 61734.69552588463, 'training/sps': 2939.096325355719, 'training/walltime': 12563.765305519104, 'training/entropy_loss': Array(0.01414189, dtype=float32), 'training/policy_loss': Array(0.00578615, dtype=float32), 'training/total_loss': Array(0.09014703, dtype=float32), 'training/v_loss': Array(0.07021898, dtype=float32), 'eval/episode_distance_from_origin': Array(6375.4346, dtype=float32), 'eval/episode_distance_reward': Array(28.891182, dtype=float32), 'eval/episode_forward_reward': Array(4815.1704, dtype=float32), 'eval/episode_reward': Array(4815.355, dtype=float32), 'eval/episode_reward_alive': Array(376.09766, dtype=float32), 'eval/episode_reward_linvel': Array(4815.1704, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.80338, dtype=float32), 'eval/episode_x_position': Array(6319.167, dtype=float32), 'eval/episode_x_velocity': Array(963.034, dtype=float32), 'eval/episode_y_position': Array(-294.9823, dtype=float32), 'eval/episode_y_velocity': Array(-206.45267, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.8139, dtype=float32), 'eval/episode_distance_reward_std': Array(4.430374, dtype=float32), 'eval/episode_forward_reward_std': Array(738.3898, dtype=float32), 'eval/episode_reward_std': Array(736.5526, dtype=float32), 'eval/episode_reward_alive_std': Array(42.848892, dtype=float32), 'eval/episode_reward_linvel_std': Array(738.3898, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.222666, dtype=float32), 'eval/episode_x_position_std': Array(388.4541, dtype=float32), 'eval/episode_x_velocity_std': Array(147.67789, dtype=float32), 'eval/episode_y_position_std': Array(260.7069, dtype=float32), 'eval/episode_y_velocity_std': Array(73.36248, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49345302581787, 'eval/sps': 937.7739163488573, 'num_steps': 36945920}
{'eval/walltime': 61871.14812064171, 'training/sps': 2944.4058663020464, 'training/walltime': 12591.58755683899, 'training/entropy_loss': Array(0.01662388, dtype=float32), 'training/policy_loss': Array(0.00892575, dtype=float32), 'training/total_loss': Array(0.17409289, dtype=float32), 'training/v_loss': Array(0.14854325, dtype=float32), 'eval/episode_distance_from_origin': Array(6467.891, dtype=float32), 'eval/episode_distance_reward': Array(29.505844, dtype=float32), 'eval/episode_forward_reward': Array(4917.613, dtype=float32), 'eval/episode_reward': Array(4926.0024, dtype=float32), 'eval/episode_reward_alive': Array(382.64453, dtype=float32), 'eval/episode_reward_linvel': Array(4917.613, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.76044, dtype=float32), 'eval/episode_x_position': Array(6412.7573, dtype=float32), 'eval/episode_x_velocity': Array(983.52246, dtype=float32), 'eval/episode_y_position': Array(-263.6925, dtype=float32), 'eval/episode_y_velocity': Array(-198.81522, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.17447, dtype=float32), 'eval/episode_distance_reward_std': Array(4.490234, dtype=float32), 'eval/episode_forward_reward_std': Array(748.36664, dtype=float32), 'eval/episode_reward_std': Array(745.9451, dtype=float32), 'eval/episode_reward_alive_std': Array(37.337208, dtype=float32), 'eval/episode_reward_linvel_std': Array(748.36664, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.317963, dtype=float32), 'eval/episode_x_position_std': Array(419.3115, dtype=float32), 'eval/episode_x_velocity_std': Array(149.67337, dtype=float32), 'eval/episode_y_position_std': Array(275.6667, dtype=float32), 'eval/episode_y_velocity_std': Array(81.61351, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45259475708008, 'eval/sps': 938.0547158364571, 'num_steps': 37027840}
{'eval/walltime': 62007.66843342781, 'training/sps': 2952.180376913822, 'training/walltime': 12619.336538791656, 'training/entropy_loss': Array(0.01419478, dtype=float32), 'training/policy_loss': Array(0.00621214, dtype=float32), 'training/total_loss': Array(0.15028164, dtype=float32), 'training/v_loss': Array(0.12987474, dtype=float32), 'eval/episode_distance_from_origin': Array(6368.8237, dtype=float32), 'eval/episode_distance_reward': Array(28.375803, dtype=float32), 'eval/episode_forward_reward': Array(4729.2725, dtype=float32), 'eval/episode_reward': Array(4740.826, dtype=float32), 'eval/episode_reward_alive': Array(390.875, dtype=float32), 'eval/episode_reward_linvel': Array(4729.2725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.6972, dtype=float32), 'eval/episode_x_position': Array(6316.6396, dtype=float32), 'eval/episode_x_velocity': Array(945.8545, dtype=float32), 'eval/episode_y_position': Array(-233.76472, dtype=float32), 'eval/episode_y_velocity': Array(-180.62267, dtype=float32), 'eval/episode_distance_from_origin_std': Array(549.4638, dtype=float32), 'eval/episode_distance_reward_std': Array(6.338247, dtype=float32), 'eval/episode_forward_reward_std': Array(1056.3672, dtype=float32), 'eval/episode_reward_std': Array(1059.4418, dtype=float32), 'eval/episode_reward_alive_std': Array(43.051113, dtype=float32), 'eval/episode_reward_linvel_std': Array(1056.3672, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.953451, dtype=float32), 'eval/episode_x_position_std': Array(549.684, dtype=float32), 'eval/episode_x_velocity_std': Array(211.27333, dtype=float32), 'eval/episode_y_position_std': Array(272.03842, dtype=float32), 'eval/episode_y_velocity_std': Array(90.77873, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5203127861023, 'eval/sps': 937.5894135296058, 'num_steps': 37109760}
{'eval/walltime': 62144.10426187515, 'training/sps': 2937.0882755355806, 'training/walltime': 12647.228107690811, 'training/entropy_loss': Array(0.01511555, dtype=float32), 'training/policy_loss': Array(0.00705691, dtype=float32), 'training/total_loss': Array(0.16267619, dtype=float32), 'training/v_loss': Array(0.14050372, dtype=float32), 'eval/episode_distance_from_origin': Array(6487.67, dtype=float32), 'eval/episode_distance_reward': Array(29.204275, dtype=float32), 'eval/episode_forward_reward': Array(4867.351, dtype=float32), 'eval/episode_reward': Array(4873.715, dtype=float32), 'eval/episode_reward_alive': Array(386.09766, dtype=float32), 'eval/episode_reward_linvel': Array(4867.351, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.93817, dtype=float32), 'eval/episode_x_position': Array(6434.6167, dtype=float32), 'eval/episode_x_velocity': Array(973.4703, dtype=float32), 'eval/episode_y_position': Array(-257.66705, dtype=float32), 'eval/episode_y_velocity': Array(-194.92862, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.0328, dtype=float32), 'eval/episode_distance_reward_std': Array(5.051043, dtype=float32), 'eval/episode_forward_reward_std': Array(841.8333, dtype=float32), 'eval/episode_reward_std': Array(848.87787, dtype=float32), 'eval/episode_reward_alive_std': Array(42.63641, dtype=float32), 'eval/episode_reward_linvel_std': Array(841.8333, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.9544, dtype=float32), 'eval/episode_x_position_std': Array(448.78122, dtype=float32), 'eval/episode_x_velocity_std': Array(168.36682, dtype=float32), 'eval/episode_y_position_std': Array(272.17328, dtype=float32), 'eval/episode_y_velocity_std': Array(80.058464, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43582844734192, 'eval/sps': 938.1699913919769, 'num_steps': 37191680}
{'eval/walltime': 62280.81254506111, 'training/sps': 2947.2942884432864, 'training/walltime': 12675.023092508316, 'training/entropy_loss': Array(0.01456384, dtype=float32), 'training/policy_loss': Array(0.00514969, dtype=float32), 'training/total_loss': Array(0.1863532, dtype=float32), 'training/v_loss': Array(0.16663967, dtype=float32), 'eval/episode_distance_from_origin': Array(6531.851, dtype=float32), 'eval/episode_distance_reward': Array(29.942415, dtype=float32), 'eval/episode_forward_reward': Array(4990.374, dtype=float32), 'eval/episode_reward': Array(5008.6357, dtype=float32), 'eval/episode_reward_alive': Array(395.5039, dtype=float32), 'eval/episode_reward_linvel': Array(4990.374, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.1858, dtype=float32), 'eval/episode_x_position': Array(6478.454, dtype=float32), 'eval/episode_x_velocity': Array(998.0748, dtype=float32), 'eval/episode_y_position': Array(-229.7695, dtype=float32), 'eval/episode_y_velocity': Array(-185.13354, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.66617, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5930653, dtype=float32), 'eval/episode_forward_reward_std': Array(765.5047, dtype=float32), 'eval/episode_reward_std': Array(767.0751, dtype=float32), 'eval/episode_reward_alive_std': Array(38.94936, dtype=float32), 'eval/episode_reward_linvel_std': Array(765.5047, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.668636, dtype=float32), 'eval/episode_x_position_std': Array(417.8154, dtype=float32), 'eval/episode_x_velocity_std': Array(153.101, dtype=float32), 'eval/episode_y_position_std': Array(292.0899, dtype=float32), 'eval/episode_y_velocity_std': Array(85.44992, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70828318595886, 'eval/sps': 936.3002520182824, 'num_steps': 37273600}
{'eval/walltime': 62417.35433912277, 'training/sps': 2941.140782353514, 'training/walltime': 12702.876230478287, 'training/entropy_loss': Array(0.01482225, dtype=float32), 'training/policy_loss': Array(0.00368413, dtype=float32), 'training/total_loss': Array(0.19961107, dtype=float32), 'training/v_loss': Array(0.18110467, dtype=float32), 'eval/episode_distance_from_origin': Array(6518.3496, dtype=float32), 'eval/episode_distance_reward': Array(29.79969, dtype=float32), 'eval/episode_forward_reward': Array(4966.5874, dtype=float32), 'eval/episode_reward': Array(4977.493, dtype=float32), 'eval/episode_reward_alive': Array(391.63672, dtype=float32), 'eval/episode_reward_linvel': Array(4966.5874, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.52985, dtype=float32), 'eval/episode_x_position': Array(6466.207, dtype=float32), 'eval/episode_x_velocity': Array(993.3174, dtype=float32), 'eval/episode_y_position': Array(-197.87894, dtype=float32), 'eval/episode_y_velocity': Array(-176.92639, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.03647, dtype=float32), 'eval/episode_distance_reward_std': Array(5.148455, dtype=float32), 'eval/episode_forward_reward_std': Array(858.07007, dtype=float32), 'eval/episode_reward_std': Array(862.4152, dtype=float32), 'eval/episode_reward_alive_std': Array(37.867043, dtype=float32), 'eval/episode_reward_linvel_std': Array(858.07007, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.869873, dtype=float32), 'eval/episode_x_position_std': Array(450.29758, dtype=float32), 'eval/episode_x_velocity_std': Array(171.61388, dtype=float32), 'eval/episode_y_position_std': Array(304.35156, dtype=float32), 'eval/episode_y_velocity_std': Array(95.734955, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54179406166077, 'eval/sps': 937.4419083888455, 'num_steps': 37355520}
{'eval/walltime': 62553.91189265251, 'training/sps': 2937.014514834545, 'training/walltime': 12730.768499851227, 'training/entropy_loss': Array(0.0118395, dtype=float32), 'training/policy_loss': Array(0.00776446, dtype=float32), 'training/total_loss': Array(0.09959425, dtype=float32), 'training/v_loss': Array(0.07999028, dtype=float32), 'eval/episode_distance_from_origin': Array(6430.6543, dtype=float32), 'eval/episode_distance_reward': Array(28.794975, dtype=float32), 'eval/episode_forward_reward': Array(4799.1357, dtype=float32), 'eval/episode_reward': Array(4814.3535, dtype=float32), 'eval/episode_reward_alive': Array(397.72656, dtype=float32), 'eval/episode_reward_linvel': Array(4799.1357, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.30362, dtype=float32), 'eval/episode_x_position': Array(6380.0234, dtype=float32), 'eval/episode_x_velocity': Array(959.827, dtype=float32), 'eval/episode_y_position': Array(-212.74893, dtype=float32), 'eval/episode_y_velocity': Array(-181.75992, dtype=float32), 'eval/episode_distance_from_origin_std': Array(412.61145, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0223064, dtype=float32), 'eval/episode_forward_reward_std': Array(837.0446, dtype=float32), 'eval/episode_reward_std': Array(840.9727, dtype=float32), 'eval/episode_reward_alive_std': Array(40.51769, dtype=float32), 'eval/episode_reward_linvel_std': Array(837.0446, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.449774, dtype=float32), 'eval/episode_x_position_std': Array(410.50037, dtype=float32), 'eval/episode_x_velocity_std': Array(167.40889, dtype=float32), 'eval/episode_y_position_std': Array(274.49966, dtype=float32), 'eval/episode_y_velocity_std': Array(84.09455, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55755352973938, 'eval/sps': 937.3337226060094, 'num_steps': 37437440}
{'eval/walltime': 62690.36472630501, 'training/sps': 2943.765122080651, 'training/walltime': 12758.596807003021, 'training/entropy_loss': Array(0.01803211, dtype=float32), 'training/policy_loss': Array(0.01180423, dtype=float32), 'training/total_loss': Array(0.13458392, dtype=float32), 'training/v_loss': Array(0.10474758, dtype=float32), 'eval/episode_distance_from_origin': Array(6437.7676, dtype=float32), 'eval/episode_distance_reward': Array(29.58781, dtype=float32), 'eval/episode_forward_reward': Array(4931.2734, dtype=float32), 'eval/episode_reward': Array(4950.6777, dtype=float32), 'eval/episode_reward_alive': Array(396.35156, dtype=float32), 'eval/episode_reward_linvel': Array(4931.2734, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.5349, dtype=float32), 'eval/episode_x_position': Array(6384.707, dtype=float32), 'eval/episode_x_velocity': Array(986.25476, dtype=float32), 'eval/episode_y_position': Array(-211.10312, dtype=float32), 'eval/episode_y_velocity': Array(-189.66478, dtype=float32), 'eval/episode_distance_from_origin_std': Array(410.98596, dtype=float32), 'eval/episode_distance_reward_std': Array(4.729733, dtype=float32), 'eval/episode_forward_reward_std': Array(788.2821, dtype=float32), 'eval/episode_reward_std': Array(789.56555, dtype=float32), 'eval/episode_reward_alive_std': Array(39.96216, dtype=float32), 'eval/episode_reward_linvel_std': Array(788.2821, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.75015, dtype=float32), 'eval/episode_x_position_std': Array(411.6681, dtype=float32), 'eval/episode_x_velocity_std': Array(157.6563, dtype=float32), 'eval/episode_y_position_std': Array(277.86884, dtype=float32), 'eval/episode_y_velocity_std': Array(79.48341, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45283365249634, 'eval/sps': 938.0530735329168, 'num_steps': 37519360}
{'eval/walltime': 62826.90330338478, 'training/sps': 2944.1110893204864, 'training/walltime': 12786.421844005585, 'training/entropy_loss': Array(0.01632303, dtype=float32), 'training/policy_loss': Array(0.0103143, dtype=float32), 'training/total_loss': Array(0.15010445, dtype=float32), 'training/v_loss': Array(0.12346712, dtype=float32), 'eval/episode_distance_from_origin': Array(6498.6006, dtype=float32), 'eval/episode_distance_reward': Array(30.011837, dtype=float32), 'eval/episode_forward_reward': Array(5001.9453, dtype=float32), 'eval/episode_reward': Array(5010.1426, dtype=float32), 'eval/episode_reward_alive': Array(388.85938, dtype=float32), 'eval/episode_reward_linvel': Array(5001.9453, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.67346, dtype=float32), 'eval/episode_x_position': Array(6444.5693, dtype=float32), 'eval/episode_x_velocity': Array(1000.3889, dtype=float32), 'eval/episode_y_position': Array(-191.29883, dtype=float32), 'eval/episode_y_velocity': Array(-176.46762, dtype=float32), 'eval/episode_distance_from_origin_std': Array(486.09964, dtype=float32), 'eval/episode_distance_reward_std': Array(5.545929, dtype=float32), 'eval/episode_forward_reward_std': Array(924.31445, dtype=float32), 'eval/episode_reward_std': Array(930.327, dtype=float32), 'eval/episode_reward_alive_std': Array(42.338707, dtype=float32), 'eval/episode_reward_linvel_std': Array(924.31445, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.74345, dtype=float32), 'eval/episode_x_position_std': Array(485.49768, dtype=float32), 'eval/episode_x_velocity_std': Array(184.86282, dtype=float32), 'eval/episode_y_position_std': Array(339.26172, dtype=float32), 'eval/episode_y_velocity_std': Array(101.48298, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53857707977295, 'eval/sps': 937.4639954334351, 'num_steps': 37601280}
{'eval/walltime': 62963.3531794548, 'training/sps': 2944.4761128670507, 'training/walltime': 12814.243431568146, 'training/entropy_loss': Array(0.0162435, dtype=float32), 'training/policy_loss': Array(0.01475598, dtype=float32), 'training/total_loss': Array(0.15154275, dtype=float32), 'training/v_loss': Array(0.12054326, dtype=float32), 'eval/episode_distance_from_origin': Array(6503.6016, dtype=float32), 'eval/episode_distance_reward': Array(29.801582, dtype=float32), 'eval/episode_forward_reward': Array(4966.9023, dtype=float32), 'eval/episode_reward': Array(4979.6855, dtype=float32), 'eval/episode_reward_alive': Array(389.40234, dtype=float32), 'eval/episode_reward_linvel': Array(4966.9023, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.42065, dtype=float32), 'eval/episode_x_position': Array(6449.37, dtype=float32), 'eval/episode_x_velocity': Array(993.38043, dtype=float32), 'eval/episode_y_position': Array(-248.55916, dtype=float32), 'eval/episode_y_velocity': Array(-190.35593, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.53232, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8179874, dtype=float32), 'eval/episode_forward_reward_std': Array(802.9923, dtype=float32), 'eval/episode_reward_std': Array(803.9104, dtype=float32), 'eval/episode_reward_alive_std': Array(39.174843, dtype=float32), 'eval/episode_reward_linvel_std': Array(802.9923, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.771433, dtype=float32), 'eval/episode_x_position_std': Array(463.33566, dtype=float32), 'eval/episode_x_velocity_std': Array(160.5985, dtype=float32), 'eval/episode_y_position_std': Array(280.0955, dtype=float32), 'eval/episode_y_velocity_std': Array(83.00863, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44987607002258, 'eval/sps': 938.0734060492197, 'num_steps': 37683200}
{'eval/walltime': 63099.861028671265, 'training/sps': 2947.4132917119264, 'training/walltime': 12842.037294149399, 'training/entropy_loss': Array(0.01574709, dtype=float32), 'training/policy_loss': Array(0.00834462, dtype=float32), 'training/total_loss': Array(0.19073549, dtype=float32), 'training/v_loss': Array(0.16664378, dtype=float32), 'eval/episode_distance_from_origin': Array(6530.057, dtype=float32), 'eval/episode_distance_reward': Array(30.153261, dtype=float32), 'eval/episode_forward_reward': Array(5025.5156, dtype=float32), 'eval/episode_reward': Array(5045.6113, dtype=float32), 'eval/episode_reward_alive': Array(395.4961, dtype=float32), 'eval/episode_reward_linvel': Array(5025.5156, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.5534, dtype=float32), 'eval/episode_x_position': Array(6479.043, dtype=float32), 'eval/episode_x_velocity': Array(1005.10297, dtype=float32), 'eval/episode_y_position': Array(-163.02902, dtype=float32), 'eval/episode_y_velocity': Array(-167.73004, dtype=float32), 'eval/episode_distance_from_origin_std': Array(409.2611, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4047937, dtype=float32), 'eval/episode_forward_reward_std': Array(734.126, dtype=float32), 'eval/episode_reward_std': Array(732.5526, dtype=float32), 'eval/episode_reward_alive_std': Array(40.218666, dtype=float32), 'eval/episode_reward_linvel_std': Array(734.126, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.615772, dtype=float32), 'eval/episode_x_position_std': Array(411.53592, dtype=float32), 'eval/episode_x_velocity_std': Array(146.8251, dtype=float32), 'eval/episode_y_position_std': Array(316.64008, dtype=float32), 'eval/episode_y_velocity_std': Array(86.54908, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50784921646118, 'eval/sps': 937.6750182110756, 'num_steps': 37765120}
{'eval/walltime': 63236.30820608139, 'training/sps': 2934.9572364676405, 'training/walltime': 12869.9491147995, 'training/entropy_loss': Array(0.01631252, dtype=float32), 'training/policy_loss': Array(0.00186774, dtype=float32), 'training/total_loss': Array(0.21666852, dtype=float32), 'training/v_loss': Array(0.19848827, dtype=float32), 'eval/episode_distance_from_origin': Array(6521.0337, dtype=float32), 'eval/episode_distance_reward': Array(30.251204, dtype=float32), 'eval/episode_forward_reward': Array(5041.8384, dtype=float32), 'eval/episode_reward': Array(5056.9404, dtype=float32), 'eval/episode_reward_alive': Array(390.0664, dtype=float32), 'eval/episode_reward_linvel': Array(5041.8384, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.2152, dtype=float32), 'eval/episode_x_position': Array(6469.1113, dtype=float32), 'eval/episode_x_velocity': Array(1008.36755, dtype=float32), 'eval/episode_y_position': Array(-206.33798, dtype=float32), 'eval/episode_y_velocity': Array(-179.0665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.6969, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3526945, dtype=float32), 'eval/episode_forward_reward_std': Array(725.4434, dtype=float32), 'eval/episode_reward_std': Array(723.6156, dtype=float32), 'eval/episode_reward_alive_std': Array(37.491997, dtype=float32), 'eval/episode_reward_linvel_std': Array(725.4434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.737045, dtype=float32), 'eval/episode_x_position_std': Array(419.35257, dtype=float32), 'eval/episode_x_velocity_std': Array(145.08867, dtype=float32), 'eval/episode_y_position_std': Array(289.29837, dtype=float32), 'eval/episode_y_velocity_std': Array(92.09248, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44717741012573, 'eval/sps': 938.0919593174459, 'num_steps': 37847040}
{'eval/walltime': 63372.8277528286, 'training/sps': 2955.4208924267546, 'training/walltime': 12897.667670965195, 'training/entropy_loss': Array(0.01276974, dtype=float32), 'training/policy_loss': Array(0.00477291, dtype=float32), 'training/total_loss': Array(0.12379608, dtype=float32), 'training/v_loss': Array(0.10625342, dtype=float32), 'eval/episode_distance_from_origin': Array(6480.294, dtype=float32), 'eval/episode_distance_reward': Array(29.897964, dtype=float32), 'eval/episode_forward_reward': Array(4982.9653, dtype=float32), 'eval/episode_reward': Array(5001.7373, dtype=float32), 'eval/episode_reward_alive': Array(395.34766, dtype=float32), 'eval/episode_reward_linvel': Array(4982.9653, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.47308, dtype=float32), 'eval/episode_x_position': Array(6427.9062, dtype=float32), 'eval/episode_x_velocity': Array(996.593, dtype=float32), 'eval/episode_y_position': Array(-192.55598, dtype=float32), 'eval/episode_y_velocity': Array(-184.56506, dtype=float32), 'eval/episode_distance_from_origin_std': Array(446.2497, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9170475, dtype=float32), 'eval/episode_forward_reward_std': Array(819.50183, dtype=float32), 'eval/episode_reward_std': Array(819.2143, dtype=float32), 'eval/episode_reward_alive_std': Array(37.63043, dtype=float32), 'eval/episode_reward_linvel_std': Array(819.50183, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.442307, dtype=float32), 'eval/episode_x_position_std': Array(448.43164, dtype=float32), 'eval/episode_x_velocity_std': Array(163.90045, dtype=float32), 'eval/episode_y_position_std': Array(288.5318, dtype=float32), 'eval/episode_y_velocity_std': Array(80.388435, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51954674720764, 'eval/sps': 937.594674534166, 'num_steps': 37928960}
{'eval/walltime': 63509.2607152462, 'training/sps': 2944.849303474414, 'training/walltime': 12925.485732793808, 'training/entropy_loss': Array(0.01806552, dtype=float32), 'training/policy_loss': Array(0.01328016, dtype=float32), 'training/total_loss': Array(0.12106253, dtype=float32), 'training/v_loss': Array(0.08971684, dtype=float32), 'eval/episode_distance_from_origin': Array(6385.0327, dtype=float32), 'eval/episode_distance_reward': Array(28.813568, dtype=float32), 'eval/episode_forward_reward': Array(4802.234, dtype=float32), 'eval/episode_reward': Array(4807.866, dtype=float32), 'eval/episode_reward_alive': Array(390.3672, dtype=float32), 'eval/episode_reward_linvel': Array(4802.234, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.54758, dtype=float32), 'eval/episode_x_position': Array(6330.133, dtype=float32), 'eval/episode_x_velocity': Array(960.4466, dtype=float32), 'eval/episode_y_position': Array(-251.40909, dtype=float32), 'eval/episode_y_velocity': Array(-184.88739, dtype=float32), 'eval/episode_distance_from_origin_std': Array(496.25262, dtype=float32), 'eval/episode_distance_reward_std': Array(5.993983, dtype=float32), 'eval/episode_forward_reward_std': Array(998.98956, dtype=float32), 'eval/episode_reward_std': Array(996.7604, dtype=float32), 'eval/episode_reward_alive_std': Array(43.11062, dtype=float32), 'eval/episode_reward_linvel_std': Array(998.98956, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.824133, dtype=float32), 'eval/episode_x_position_std': Array(494.93484, dtype=float32), 'eval/episode_x_velocity_std': Array(199.79787, dtype=float32), 'eval/episode_y_position_std': Array(301.74023, dtype=float32), 'eval/episode_y_velocity_std': Array(92.77436, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43296241760254, 'eval/sps': 938.189699408634, 'num_steps': 38010880}
{'eval/walltime': 63645.76316356659, 'training/sps': 2951.112640464068, 'training/walltime': 12953.244754552841, 'training/entropy_loss': Array(0.01539862, dtype=float32), 'training/policy_loss': Array(0.00858281, dtype=float32), 'training/total_loss': Array(0.1507745, dtype=float32), 'training/v_loss': Array(0.12679306, dtype=float32), 'eval/episode_distance_from_origin': Array(6353.888, dtype=float32), 'eval/episode_distance_reward': Array(28.813074, dtype=float32), 'eval/episode_forward_reward': Array(4802.1514, dtype=float32), 'eval/episode_reward': Array(4813.29, dtype=float32), 'eval/episode_reward_alive': Array(388.4961, dtype=float32), 'eval/episode_reward_linvel': Array(4802.1514, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.171, dtype=float32), 'eval/episode_x_position': Array(6298.1353, dtype=float32), 'eval/episode_x_velocity': Array(960.4303, dtype=float32), 'eval/episode_y_position': Array(-279.45795, dtype=float32), 'eval/episode_y_velocity': Array(-190.28778, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.68842, dtype=float32), 'eval/episode_distance_reward_std': Array(5.452074, dtype=float32), 'eval/episode_forward_reward_std': Array(908.6721, dtype=float32), 'eval/episode_reward_std': Array(905.94434, dtype=float32), 'eval/episode_reward_alive_std': Array(41.38819, dtype=float32), 'eval/episode_reward_linvel_std': Array(908.6721, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.874336, dtype=float32), 'eval/episode_x_position_std': Array(474.0788, dtype=float32), 'eval/episode_x_velocity_std': Array(181.73453, dtype=float32), 'eval/episode_y_position_std': Array(278.58694, dtype=float32), 'eval/episode_y_velocity_std': Array(93.43863, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5024483203888, 'eval/sps': 937.7121185370064, 'num_steps': 38092800}
{'eval/walltime': 63782.46949648857, 'training/sps': 2940.0851912428743, 'training/walltime': 12981.107892751694, 'training/entropy_loss': Array(0.01512406, dtype=float32), 'training/policy_loss': Array(0.00550038, dtype=float32), 'training/total_loss': Array(0.14660122, dtype=float32), 'training/v_loss': Array(0.12597677, dtype=float32), 'eval/episode_distance_from_origin': Array(6445.3623, dtype=float32), 'eval/episode_distance_reward': Array(29.607233, dtype=float32), 'eval/episode_forward_reward': Array(4934.5107, dtype=float32), 'eval/episode_reward': Array(4939.4316, dtype=float32), 'eval/episode_reward_alive': Array(382.23438, dtype=float32), 'eval/episode_reward_linvel': Array(4934.5107, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.92032, dtype=float32), 'eval/episode_x_position': Array(6391.4297, dtype=float32), 'eval/episode_x_velocity': Array(986.9022, dtype=float32), 'eval/episode_y_position': Array(-226.06534, dtype=float32), 'eval/episode_y_velocity': Array(-191.54388, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.8868, dtype=float32), 'eval/episode_distance_reward_std': Array(4.928116, dtype=float32), 'eval/episode_forward_reward_std': Array(821.3466, dtype=float32), 'eval/episode_reward_std': Array(813.6462, dtype=float32), 'eval/episode_reward_alive_std': Array(47.324795, dtype=float32), 'eval/episode_reward_linvel_std': Array(821.3466, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.828964, dtype=float32), 'eval/episode_x_position_std': Array(422.69193, dtype=float32), 'eval/episode_x_velocity_std': Array(164.26932, dtype=float32), 'eval/episode_y_position_std': Array(280.91147, dtype=float32), 'eval/episode_y_velocity_std': Array(82.280334, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7063329219818, 'eval/sps': 936.3136093559725, 'num_steps': 38174720}
{'eval/walltime': 63919.29837632179, 'training/sps': 2924.38091427244, 'training/walltime': 13009.120659351349, 'training/entropy_loss': Array(0.01540237, dtype=float32), 'training/policy_loss': Array(0.00328909, dtype=float32), 'training/total_loss': Array(0.20557705, dtype=float32), 'training/v_loss': Array(0.1868856, dtype=float32), 'eval/episode_distance_from_origin': Array(6483.7217, dtype=float32), 'eval/episode_distance_reward': Array(30.324692, dtype=float32), 'eval/episode_forward_reward': Array(5054.086, dtype=float32), 'eval/episode_reward': Array(5069.1924, dtype=float32), 'eval/episode_reward_alive': Array(389.20312, dtype=float32), 'eval/episode_reward_linvel': Array(5054.086, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.42133, dtype=float32), 'eval/episode_x_position': Array(6432.7397, dtype=float32), 'eval/episode_x_velocity': Array(1010.81714, dtype=float32), 'eval/episode_y_position': Array(-152.1634, dtype=float32), 'eval/episode_y_velocity': Array(-168.15874, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.4201, dtype=float32), 'eval/episode_distance_reward_std': Array(4.551212, dtype=float32), 'eval/episode_forward_reward_std': Array(758.52966, dtype=float32), 'eval/episode_reward_std': Array(763.5136, dtype=float32), 'eval/episode_reward_alive_std': Array(36.648266, dtype=float32), 'eval/episode_reward_linvel_std': Array(758.52966, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.59326, dtype=float32), 'eval/episode_x_position_std': Array(441.82028, dtype=float32), 'eval/episode_x_velocity_std': Array(151.70587, dtype=float32), 'eval/episode_y_position_std': Array(310.00253, dtype=float32), 'eval/episode_y_velocity_std': Array(98.62613, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.82887983322144, 'eval/sps': 935.4750265880798, 'num_steps': 38256640}
{'eval/walltime': 64056.215973854065, 'training/sps': 2931.398888363444, 'training/walltime': 13037.066361427307, 'training/entropy_loss': Array(0.01518262, dtype=float32), 'training/policy_loss': Array(0.00416883, dtype=float32), 'training/total_loss': Array(0.20115149, dtype=float32), 'training/v_loss': Array(0.18180004, dtype=float32), 'eval/episode_distance_from_origin': Array(6446.3936, dtype=float32), 'eval/episode_distance_reward': Array(29.656206, dtype=float32), 'eval/episode_forward_reward': Array(4942.6724, dtype=float32), 'eval/episode_reward': Array(4948.483, dtype=float32), 'eval/episode_reward_alive': Array(389.32812, dtype=float32), 'eval/episode_reward_linvel': Array(4942.6724, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.17352, dtype=float32), 'eval/episode_x_position': Array(6391.57, dtype=float32), 'eval/episode_x_velocity': Array(988.5344, dtype=float32), 'eval/episode_y_position': Array(-190.82047, dtype=float32), 'eval/episode_y_velocity': Array(-177.33217, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.94656, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0295386, dtype=float32), 'eval/episode_forward_reward_std': Array(838.2503, dtype=float32), 'eval/episode_reward_std': Array(846.9181, dtype=float32), 'eval/episode_reward_alive_std': Array(39.6334, dtype=float32), 'eval/episode_reward_linvel_std': Array(838.2503, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.904938, dtype=float32), 'eval/episode_x_position_std': Array(420.98914, dtype=float32), 'eval/episode_x_velocity_std': Array(167.65001, dtype=float32), 'eval/episode_y_position_std': Array(355.00696, dtype=float32), 'eval/episode_y_velocity_std': Array(105.62986, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.91759753227234, 'eval/sps': 934.8688722779378, 'num_steps': 38338560}
{'eval/walltime': 64193.23120236397, 'training/sps': 2946.0690910421936, 'training/walltime': 13064.872905492783, 'training/entropy_loss': Array(0.01318199, dtype=float32), 'training/policy_loss': Array(0.00667064, dtype=float32), 'training/total_loss': Array(0.19831997, dtype=float32), 'training/v_loss': Array(0.17846735, dtype=float32), 'eval/episode_distance_from_origin': Array(6468.6797, dtype=float32), 'eval/episode_distance_reward': Array(30.570686, dtype=float32), 'eval/episode_forward_reward': Array(5095.0845, dtype=float32), 'eval/episode_reward': Array(5112.501, dtype=float32), 'eval/episode_reward_alive': Array(393.8789, dtype=float32), 'eval/episode_reward_linvel': Array(5095.0845, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.03323, dtype=float32), 'eval/episode_x_position': Array(6415.2256, dtype=float32), 'eval/episode_x_velocity': Array(1019.01697, dtype=float32), 'eval/episode_y_position': Array(-202.06107, dtype=float32), 'eval/episode_y_velocity': Array(-184.25159, dtype=float32), 'eval/episode_distance_from_origin_std': Array(375.477, dtype=float32), 'eval/episode_distance_reward_std': Array(3.8235104, dtype=float32), 'eval/episode_forward_reward_std': Array(637.247, dtype=float32), 'eval/episode_reward_std': Array(639.2496, dtype=float32), 'eval/episode_reward_alive_std': Array(35.257908, dtype=float32), 'eval/episode_reward_linvel_std': Array(637.247, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.028484, dtype=float32), 'eval/episode_x_position_std': Array(377.0006, dtype=float32), 'eval/episode_x_velocity_std': Array(127.44953, dtype=float32), 'eval/episode_y_position_std': Array(322.16028, dtype=float32), 'eval/episode_y_velocity_std': Array(86.58617, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.01522850990295, 'eval/sps': 934.2027261644762, 'num_steps': 38420480}
{'eval/walltime': 64329.902752399445, 'training/sps': 2935.7313252914873, 'training/walltime': 13092.777366399765, 'training/entropy_loss': Array(0.01506049, dtype=float32), 'training/policy_loss': Array(0.00750586, dtype=float32), 'training/total_loss': Array(0.09082954, dtype=float32), 'training/v_loss': Array(0.06826319, dtype=float32), 'eval/episode_distance_from_origin': Array(6410.928, dtype=float32), 'eval/episode_distance_reward': Array(29.475418, dtype=float32), 'eval/episode_forward_reward': Array(4912.5425, dtype=float32), 'eval/episode_reward': Array(4929.959, dtype=float32), 'eval/episode_reward_alive': Array(399.53125, dtype=float32), 'eval/episode_reward_linvel': Array(4912.5425, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.58954, dtype=float32), 'eval/episode_x_position': Array(6358.235, dtype=float32), 'eval/episode_x_velocity': Array(982.5084, dtype=float32), 'eval/episode_y_position': Array(-186.79688, dtype=float32), 'eval/episode_y_velocity': Array(-173.08084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.1772, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7037616, dtype=float32), 'eval/episode_forward_reward_std': Array(950.6211, dtype=float32), 'eval/episode_reward_std': Array(952.8164, dtype=float32), 'eval/episode_reward_alive_std': Array(39.360153, dtype=float32), 'eval/episode_reward_linvel_std': Array(950.6211, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.831491, dtype=float32), 'eval/episode_x_position_std': Array(481.8599, dtype=float32), 'eval/episode_x_velocity_std': Array(190.12424, dtype=float32), 'eval/episode_y_position_std': Array(307.61212, dtype=float32), 'eval/episode_y_velocity_std': Array(96.43106, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67155003547668, 'eval/sps': 936.5519010121291, 'num_steps': 38502400}
{'eval/walltime': 64466.90661621094, 'training/sps': 2945.7063241144197, 'training/walltime': 13120.587334871292, 'training/entropy_loss': Array(0.01756342, dtype=float32), 'training/policy_loss': Array(0.01050202, dtype=float32), 'training/total_loss': Array(0.16849892, dtype=float32), 'training/v_loss': Array(0.14043349, dtype=float32), 'eval/episode_distance_from_origin': Array(6529.976, dtype=float32), 'eval/episode_distance_reward': Array(30.893051, dtype=float32), 'eval/episode_forward_reward': Array(5148.8125, dtype=float32), 'eval/episode_reward': Array(5153.758, dtype=float32), 'eval/episode_reward_alive': Array(381.01953, dtype=float32), 'eval/episode_reward_linvel': Array(5148.8125, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.96674, dtype=float32), 'eval/episode_x_position': Array(6476.9834, dtype=float32), 'eval/episode_x_velocity': Array(1029.7623, dtype=float32), 'eval/episode_y_position': Array(-183.57365, dtype=float32), 'eval/episode_y_velocity': Array(-180.85458, dtype=float32), 'eval/episode_distance_from_origin_std': Array(423.6368, dtype=float32), 'eval/episode_distance_reward_std': Array(4.663843, dtype=float32), 'eval/episode_forward_reward_std': Array(777.3018, dtype=float32), 'eval/episode_reward_std': Array(786.7864, dtype=float32), 'eval/episode_reward_alive_std': Array(39.368324, dtype=float32), 'eval/episode_reward_linvel_std': Array(777.3018, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.778336, dtype=float32), 'eval/episode_x_position_std': Array(425.855, dtype=float32), 'eval/episode_x_velocity_std': Array(155.4604, dtype=float32), 'eval/episode_y_position_std': Array(331.11493, dtype=float32), 'eval/episode_y_velocity_std': Array(99.748665, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.00386381149292, 'eval/sps': 934.2802198346642, 'num_steps': 38584320}
{'eval/walltime': 64603.56566119194, 'training/sps': 2928.4229654064025, 'training/walltime': 13148.561435937881, 'training/entropy_loss': Array(0.01533887, dtype=float32), 'training/policy_loss': Array(0.00841578, dtype=float32), 'training/total_loss': Array(0.13966754, dtype=float32), 'training/v_loss': Array(0.11591288, dtype=float32), 'eval/episode_distance_from_origin': Array(6475.2065, dtype=float32), 'eval/episode_distance_reward': Array(30.048538, dtype=float32), 'eval/episode_forward_reward': Array(5008.0605, dtype=float32), 'eval/episode_reward': Array(5008.8613, dtype=float32), 'eval/episode_reward_alive': Array(383.6211, dtype=float32), 'eval/episode_reward_linvel': Array(5008.0605, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.86853, dtype=float32), 'eval/episode_x_position': Array(6425.0293, dtype=float32), 'eval/episode_x_velocity': Array(1001.6121, dtype=float32), 'eval/episode_y_position': Array(-156.27893, dtype=float32), 'eval/episode_y_velocity': Array(-170.60245, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.02786, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8637724, dtype=float32), 'eval/episode_forward_reward_std': Array(810.6228, dtype=float32), 'eval/episode_reward_std': Array(810.8259, dtype=float32), 'eval/episode_reward_alive_std': Array(45.690052, dtype=float32), 'eval/episode_reward_linvel_std': Array(810.6228, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.074436, dtype=float32), 'eval/episode_x_position_std': Array(435.40158, dtype=float32), 'eval/episode_x_velocity_std': Array(162.12453, dtype=float32), 'eval/episode_y_position_std': Array(307.20712, dtype=float32), 'eval/episode_y_velocity_std': Array(100.32876, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6590449810028, 'eval/sps': 936.6376006637064, 'num_steps': 38666240}
{'eval/walltime': 64740.41708922386, 'training/sps': 2935.889684010846, 'training/walltime': 13176.464391708374, 'training/entropy_loss': Array(0.01598803, dtype=float32), 'training/policy_loss': Array(0.01006208, dtype=float32), 'training/total_loss': Array(0.18206641, dtype=float32), 'training/v_loss': Array(0.15601629, dtype=float32), 'eval/episode_distance_from_origin': Array(6532.4336, dtype=float32), 'eval/episode_distance_reward': Array(30.782505, dtype=float32), 'eval/episode_forward_reward': Array(5130.388, dtype=float32), 'eval/episode_reward': Array(5132.591, dtype=float32), 'eval/episode_reward_alive': Array(379.76172, dtype=float32), 'eval/episode_reward_linvel': Array(5130.388, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.34195, dtype=float32), 'eval/episode_x_position': Array(6478.397, dtype=float32), 'eval/episode_x_velocity': Array(1026.0776, dtype=float32), 'eval/episode_y_position': Array(-106.84717, dtype=float32), 'eval/episode_y_velocity': Array(-158.86035, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.55426, dtype=float32), 'eval/episode_distance_reward_std': Array(4.2730846, dtype=float32), 'eval/episode_forward_reward_std': Array(712.1758, dtype=float32), 'eval/episode_reward_std': Array(711.6833, dtype=float32), 'eval/episode_reward_alive_std': Array(43.088886, dtype=float32), 'eval/episode_reward_linvel_std': Array(712.1758, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.008291, dtype=float32), 'eval/episode_x_position_std': Array(399.21133, dtype=float32), 'eval/episode_x_velocity_std': Array(142.43507, dtype=float32), 'eval/episode_y_position_std': Array(390.14603, dtype=float32), 'eval/episode_y_velocity_std': Array(117.28854, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8514280319214, 'eval/sps': 935.3208939123621, 'num_steps': 38748160}
{'eval/walltime': 64877.138451337814, 'training/sps': 2938.491262420351, 'training/walltime': 13204.342643737793, 'training/entropy_loss': Array(0.01571837, dtype=float32), 'training/policy_loss': Array(0.00716349, dtype=float32), 'training/total_loss': Array(0.21967882, dtype=float32), 'training/v_loss': Array(0.19679695, dtype=float32), 'eval/episode_distance_from_origin': Array(6532.869, dtype=float32), 'eval/episode_distance_reward': Array(30.782543, dtype=float32), 'eval/episode_forward_reward': Array(5130.395, dtype=float32), 'eval/episode_reward': Array(5134.1807, dtype=float32), 'eval/episode_reward_alive': Array(384.21094, dtype=float32), 'eval/episode_reward_linvel': Array(5130.395, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.2072, dtype=float32), 'eval/episode_x_position': Array(6482.6084, dtype=float32), 'eval/episode_x_velocity': Array(1026.079, dtype=float32), 'eval/episode_y_position': Array(-99.130936, dtype=float32), 'eval/episode_y_velocity': Array(-159.51337, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.13773, dtype=float32), 'eval/episode_distance_reward_std': Array(5.347803, dtype=float32), 'eval/episode_forward_reward_std': Array(891.295, dtype=float32), 'eval/episode_reward_std': Array(892.0382, dtype=float32), 'eval/episode_reward_alive_std': Array(43.07622, dtype=float32), 'eval/episode_reward_linvel_std': Array(891.295, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.425262, dtype=float32), 'eval/episode_x_position_std': Array(478.6949, dtype=float32), 'eval/episode_x_velocity_std': Array(178.25891, dtype=float32), 'eval/episode_y_position_std': Array(333.93912, dtype=float32), 'eval/episode_y_velocity_std': Array(101.64319, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.72136211395264, 'eval/sps': 936.2106844233773, 'num_steps': 38830080}
{'eval/walltime': 65013.8327255249, 'training/sps': 2937.070173944946, 'training/walltime': 13232.234384536743, 'training/entropy_loss': Array(0.01619307, dtype=float32), 'training/policy_loss': Array(0.01028993, dtype=float32), 'training/total_loss': Array(0.23371343, dtype=float32), 'training/v_loss': Array(0.20723042, dtype=float32), 'eval/episode_distance_from_origin': Array(6530.53, dtype=float32), 'eval/episode_distance_reward': Array(31.171478, dtype=float32), 'eval/episode_forward_reward': Array(5195.2163, dtype=float32), 'eval/episode_reward': Array(5195.503, dtype=float32), 'eval/episode_reward_alive': Array(378.40234, dtype=float32), 'eval/episode_reward_linvel': Array(5195.2163, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.28683, dtype=float32), 'eval/episode_x_position': Array(6479.8633, dtype=float32), 'eval/episode_x_velocity': Array(1039.0433, dtype=float32), 'eval/episode_y_position': Array(-130.5761, dtype=float32), 'eval/episode_y_velocity': Array(-162.10559, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.75577, dtype=float32), 'eval/episode_distance_reward_std': Array(5.293243, dtype=float32), 'eval/episode_forward_reward_std': Array(882.2009, dtype=float32), 'eval/episode_reward_std': Array(878.0251, dtype=float32), 'eval/episode_reward_alive_std': Array(39.901493, dtype=float32), 'eval/episode_reward_linvel_std': Array(882.2009, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.53915, dtype=float32), 'eval/episode_x_position_std': Array(472.4243, dtype=float32), 'eval/episode_x_velocity_std': Array(176.44026, dtype=float32), 'eval/episode_y_position_std': Array(341.89883, dtype=float32), 'eval/episode_y_velocity_std': Array(103.99765, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.694274187088, 'eval/sps': 936.3962079699951, 'num_steps': 38912000}
{'eval/walltime': 65150.4424738884, 'training/sps': 2933.2613564477, 'training/walltime': 13260.16234254837, 'training/entropy_loss': Array(0.01468239, dtype=float32), 'training/policy_loss': Array(0.00859311, dtype=float32), 'training/total_loss': Array(0.09426905, dtype=float32), 'training/v_loss': Array(0.07099356, dtype=float32), 'eval/episode_distance_from_origin': Array(6452.9277, dtype=float32), 'eval/episode_distance_reward': Array(29.967556, dtype=float32), 'eval/episode_forward_reward': Array(4994.564, dtype=float32), 'eval/episode_reward': Array(4987.9014, dtype=float32), 'eval/episode_reward_alive': Array(376.1172, dtype=float32), 'eval/episode_reward_linvel': Array(4994.564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.74707, dtype=float32), 'eval/episode_x_position': Array(6397.737, dtype=float32), 'eval/episode_x_velocity': Array(998.9127, dtype=float32), 'eval/episode_y_position': Array(-242.94196, dtype=float32), 'eval/episode_y_velocity': Array(-188.63892, dtype=float32), 'eval/episode_distance_from_origin_std': Array(397.5496, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6776943, dtype=float32), 'eval/episode_forward_reward_std': Array(779.6097, dtype=float32), 'eval/episode_reward_std': Array(781.64136, dtype=float32), 'eval/episode_reward_alive_std': Array(44.74378, dtype=float32), 'eval/episode_reward_linvel_std': Array(779.6097, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.21434, dtype=float32), 'eval/episode_x_position_std': Array(400.89938, dtype=float32), 'eval/episode_x_velocity_std': Array(155.92198, dtype=float32), 'eval/episode_y_position_std': Array(322.0294, dtype=float32), 'eval/episode_y_velocity_std': Array(91.09023, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60974836349487, 'eval/sps': 936.9755931283481, 'num_steps': 38993920}
{'eval/walltime': 65287.327073812485, 'training/sps': 2944.3609798966227, 'training/walltime': 13287.985018014908, 'training/entropy_loss': Array(0.01642764, dtype=float32), 'training/policy_loss': Array(0.01314346, dtype=float32), 'training/total_loss': Array(0.16111083, dtype=float32), 'training/v_loss': Array(0.13153973, dtype=float32), 'eval/episode_distance_from_origin': Array(6541.334, dtype=float32), 'eval/episode_distance_reward': Array(30.97543, dtype=float32), 'eval/episode_forward_reward': Array(5162.541, dtype=float32), 'eval/episode_reward': Array(5155.1377, dtype=float32), 'eval/episode_reward_alive': Array(372.01562, dtype=float32), 'eval/episode_reward_linvel': Array(5162.541, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.3945, dtype=float32), 'eval/episode_x_position': Array(6489.8633, dtype=float32), 'eval/episode_x_velocity': Array(1032.5082, dtype=float32), 'eval/episode_y_position': Array(-184.06665, dtype=float32), 'eval/episode_y_velocity': Array(-171.17886, dtype=float32), 'eval/episode_distance_from_origin_std': Array(432.37973, dtype=float32), 'eval/episode_distance_reward_std': Array(4.79544, dtype=float32), 'eval/episode_forward_reward_std': Array(799.2357, dtype=float32), 'eval/episode_reward_std': Array(802.87384, dtype=float32), 'eval/episode_reward_alive_std': Array(49.20774, dtype=float32), 'eval/episode_reward_linvel_std': Array(799.2357, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.37816, dtype=float32), 'eval/episode_x_position_std': Array(435.52744, dtype=float32), 'eval/episode_x_velocity_std': Array(159.84706, dtype=float32), 'eval/episode_y_position_std': Array(329.26337, dtype=float32), 'eval/episode_y_velocity_std': Array(105.847664, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.88459992408752, 'eval/sps': 935.0942331787894, 'num_steps': 39075840}
{'eval/walltime': 65423.93208909035, 'training/sps': 2933.4642276211407, 'training/walltime': 13315.911044597626, 'training/entropy_loss': Array(0.01498433, dtype=float32), 'training/policy_loss': Array(0.00605653, dtype=float32), 'training/total_loss': Array(0.13450508, dtype=float32), 'training/v_loss': Array(0.11346422, dtype=float32), 'eval/episode_distance_from_origin': Array(6523.1094, dtype=float32), 'eval/episode_distance_reward': Array(30.580765, dtype=float32), 'eval/episode_forward_reward': Array(5096.764, dtype=float32), 'eval/episode_reward': Array(5082.7007, dtype=float32), 'eval/episode_reward_alive': Array(372.98047, dtype=float32), 'eval/episode_reward_linvel': Array(5096.764, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.625, dtype=float32), 'eval/episode_x_position': Array(6471.1074, dtype=float32), 'eval/episode_x_velocity': Array(1019.35284, dtype=float32), 'eval/episode_y_position': Array(-230.39313, dtype=float32), 'eval/episode_y_velocity': Array(-182.298, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.95294, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1832404, dtype=float32), 'eval/episode_forward_reward_std': Array(863.86707, dtype=float32), 'eval/episode_reward_std': Array(869.0937, dtype=float32), 'eval/episode_reward_alive_std': Array(43.66104, dtype=float32), 'eval/episode_reward_linvel_std': Array(863.86707, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.61909, dtype=float32), 'eval/episode_x_position_std': Array(473.99823, dtype=float32), 'eval/episode_x_velocity_std': Array(172.77336, dtype=float32), 'eval/episode_y_position_std': Array(299.5182, dtype=float32), 'eval/episode_y_velocity_std': Array(92.48203, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60501527786255, 'eval/sps': 937.0080574248358, 'num_steps': 39157760}
{'eval/walltime': 65560.64739513397, 'training/sps': 2933.7726325290646, 'training/walltime': 13343.83413553238, 'training/entropy_loss': Array(0.0160711, dtype=float32), 'training/policy_loss': Array(0.00645835, dtype=float32), 'training/total_loss': Array(0.16422017, dtype=float32), 'training/v_loss': Array(0.14169072, dtype=float32), 'eval/episode_distance_from_origin': Array(6527.1924, dtype=float32), 'eval/episode_distance_reward': Array(31.134739, dtype=float32), 'eval/episode_forward_reward': Array(5189.0938, dtype=float32), 'eval/episode_reward': Array(5177.473, dtype=float32), 'eval/episode_reward_alive': Array(366.6211, dtype=float32), 'eval/episode_reward_linvel': Array(5189.0938, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.37662, dtype=float32), 'eval/episode_x_position': Array(6474.3945, dtype=float32), 'eval/episode_x_velocity': Array(1037.8188, dtype=float32), 'eval/episode_y_position': Array(-182.84436, dtype=float32), 'eval/episode_y_velocity': Array(-178.71664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(413.5019, dtype=float32), 'eval/episode_distance_reward_std': Array(4.602904, dtype=float32), 'eval/episode_forward_reward_std': Array(767.14465, dtype=float32), 'eval/episode_reward_std': Array(776.2169, dtype=float32), 'eval/episode_reward_alive_std': Array(44.80835, dtype=float32), 'eval/episode_reward_linvel_std': Array(767.14465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.903658, dtype=float32), 'eval/episode_x_position_std': Array(420.01965, dtype=float32), 'eval/episode_x_velocity_std': Array(153.4292, dtype=float32), 'eval/episode_y_position_std': Array(322.06223, dtype=float32), 'eval/episode_y_velocity_std': Array(91.94198, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.71530604362488, 'eval/sps': 936.2521556961304, 'num_steps': 39239680}
{'eval/walltime': 65697.32749843597, 'training/sps': 2924.1211645212284, 'training/walltime': 13371.849390506744, 'training/entropy_loss': Array(0.01583423, dtype=float32), 'training/policy_loss': Array(0.06195794, dtype=float32), 'training/total_loss': Array(0.25817573, dtype=float32), 'training/v_loss': Array(0.18038356, dtype=float32), 'eval/episode_distance_from_origin': Array(6649.678, dtype=float32), 'eval/episode_distance_reward': Array(31.904875, dtype=float32), 'eval/episode_forward_reward': Array(5317.448, dtype=float32), 'eval/episode_reward': Array(5309.786, dtype=float32), 'eval/episode_reward_alive': Array(371.64844, dtype=float32), 'eval/episode_reward_linvel': Array(5317.448, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.21524, dtype=float32), 'eval/episode_x_position': Array(6600.6655, dtype=float32), 'eval/episode_x_velocity': Array(1063.4896, dtype=float32), 'eval/episode_y_position': Array(-172.55872, dtype=float32), 'eval/episode_y_velocity': Array(-170.45262, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.64948, dtype=float32), 'eval/episode_distance_reward_std': Array(4.763141, dtype=float32), 'eval/episode_forward_reward_std': Array(793.8512, dtype=float32), 'eval/episode_reward_std': Array(788.6563, dtype=float32), 'eval/episode_reward_alive_std': Array(41.25593, dtype=float32), 'eval/episode_reward_linvel_std': Array(793.8512, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(15.341946, dtype=float32), 'eval/episode_x_position_std': Array(425.57437, dtype=float32), 'eval/episode_x_velocity_std': Array(158.77025, dtype=float32), 'eval/episode_y_position_std': Array(285.9432, dtype=float32), 'eval/episode_y_velocity_std': Array(89.25784, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.68010330200195, 'eval/sps': 936.4932927887623, 'num_steps': 39321600}
{'eval/walltime': 65834.21051740646, 'training/sps': 2949.5325614564167, 'training/walltime': 13399.623282909393, 'training/entropy_loss': Array(0.01601385, dtype=float32), 'training/policy_loss': Array(0.01062187, dtype=float32), 'training/total_loss': Array(0.24655364, dtype=float32), 'training/v_loss': Array(0.21991792, dtype=float32), 'eval/episode_distance_from_origin': Array(6715.661, dtype=float32), 'eval/episode_distance_reward': Array(32.76758, dtype=float32), 'eval/episode_forward_reward': Array(5461.2324, dtype=float32), 'eval/episode_reward': Array(5452.5, dtype=float32), 'eval/episode_reward_alive': Array(367.33594, dtype=float32), 'eval/episode_reward_linvel': Array(5461.2324, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.8354, dtype=float32), 'eval/episode_x_position': Array(6665.5, dtype=float32), 'eval/episode_x_velocity': Array(1092.2466, dtype=float32), 'eval/episode_y_position': Array(-115.636215, dtype=float32), 'eval/episode_y_velocity': Array(-167.25362, dtype=float32), 'eval/episode_distance_from_origin_std': Array(380.95944, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3721547, dtype=float32), 'eval/episode_forward_reward_std': Array(728.68665, dtype=float32), 'eval/episode_reward_std': Array(727.756, dtype=float32), 'eval/episode_reward_alive_std': Array(43.644207, dtype=float32), 'eval/episode_reward_linvel_std': Array(728.68665, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.125938, dtype=float32), 'eval/episode_x_position_std': Array(384.86945, dtype=float32), 'eval/episode_x_velocity_std': Array(145.73738, dtype=float32), 'eval/episode_y_position_std': Array(328.71808, dtype=float32), 'eval/episode_y_velocity_std': Array(107.56162, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8830189704895, 'eval/sps': 935.1050332079205, 'num_steps': 39403520}
{'eval/walltime': 65970.93383431435, 'training/sps': 2936.353319488954, 'training/walltime': 13427.521832942963, 'training/entropy_loss': Array(0.01232392, dtype=float32), 'training/policy_loss': Array(0.00333926, dtype=float32), 'training/total_loss': Array(0.10681415, dtype=float32), 'training/v_loss': Array(0.09115098, dtype=float32), 'eval/episode_distance_from_origin': Array(6715.267, dtype=float32), 'eval/episode_distance_reward': Array(32.53547, dtype=float32), 'eval/episode_forward_reward': Array(5422.546, dtype=float32), 'eval/episode_reward': Array(5415.687, dtype=float32), 'eval/episode_reward_alive': Array(371.3711, dtype=float32), 'eval/episode_reward_linvel': Array(5422.546, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.76578, dtype=float32), 'eval/episode_x_position': Array(6664.114, dtype=float32), 'eval/episode_x_velocity': Array(1084.5093, dtype=float32), 'eval/episode_y_position': Array(-93.9787, dtype=float32), 'eval/episode_y_velocity': Array(-147.09956, dtype=float32), 'eval/episode_distance_from_origin_std': Array(375.89087, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4341974, dtype=float32), 'eval/episode_forward_reward_std': Array(739.0279, dtype=float32), 'eval/episode_reward_std': Array(737.69507, dtype=float32), 'eval/episode_reward_alive_std': Array(45.421, dtype=float32), 'eval/episode_reward_linvel_std': Array(739.0279, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.35695, dtype=float32), 'eval/episode_x_position_std': Array(380.34412, dtype=float32), 'eval/episode_x_velocity_std': Array(147.80556, dtype=float32), 'eval/episode_y_position_std': Array(375.18842, dtype=float32), 'eval/episode_y_velocity_std': Array(111.03401, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7233169078827, 'eval/sps': 936.1972990037974, 'num_steps': 39485440}
{'eval/walltime': 66107.74419641495, 'training/sps': 2934.937531608369, 'training/walltime': 13455.433840990067, 'training/entropy_loss': Array(0.01789051, dtype=float32), 'training/policy_loss': Array(0.00687369, dtype=float32), 'training/total_loss': Array(0.13913709, dtype=float32), 'training/v_loss': Array(0.11437288, dtype=float32), 'eval/episode_distance_from_origin': Array(6769.2036, dtype=float32), 'eval/episode_distance_reward': Array(32.900185, dtype=float32), 'eval/episode_forward_reward': Array(5483.333, dtype=float32), 'eval/episode_reward': Array(5475.0757, dtype=float32), 'eval/episode_reward_alive': Array(368.57812, dtype=float32), 'eval/episode_reward_linvel': Array(5483.333, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.73547, dtype=float32), 'eval/episode_x_position': Array(6720.696, dtype=float32), 'eval/episode_x_velocity': Array(1096.6665, dtype=float32), 'eval/episode_y_position': Array(-108.63475, dtype=float32), 'eval/episode_y_velocity': Array(-157.08424, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.46402, dtype=float32), 'eval/episode_distance_reward_std': Array(4.59712, dtype=float32), 'eval/episode_forward_reward_std': Array(766.18134, dtype=float32), 'eval/episode_reward_std': Array(767.30457, dtype=float32), 'eval/episode_reward_alive_std': Array(45.678364, dtype=float32), 'eval/episode_reward_linvel_std': Array(766.18134, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.43946, dtype=float32), 'eval/episode_x_position_std': Array(428.48593, dtype=float32), 'eval/episode_x_velocity_std': Array(153.23624, dtype=float32), 'eval/episode_y_position_std': Array(322.3185, dtype=float32), 'eval/episode_y_velocity_std': Array(98.50986, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8103621006012, 'eval/sps': 935.6016462106676, 'num_steps': 39567360}
{'eval/walltime': 66244.3517203331, 'training/sps': 2942.425405265666, 'training/walltime': 13483.274818658829, 'training/entropy_loss': Array(0.0162437, dtype=float32), 'training/policy_loss': Array(0.00740338, dtype=float32), 'training/total_loss': Array(0.17297032, dtype=float32), 'training/v_loss': Array(0.14932324, dtype=float32), 'eval/episode_distance_from_origin': Array(6705.9785, dtype=float32), 'eval/episode_distance_reward': Array(32.27097, dtype=float32), 'eval/episode_forward_reward': Array(5378.4634, dtype=float32), 'eval/episode_reward': Array(5368.1973, dtype=float32), 'eval/episode_reward_alive': Array(369.90625, dtype=float32), 'eval/episode_reward_linvel': Array(5378.4634, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.4433, dtype=float32), 'eval/episode_x_position': Array(6655.497, dtype=float32), 'eval/episode_x_velocity': Array(1075.6927, dtype=float32), 'eval/episode_y_position': Array(-106.13846, dtype=float32), 'eval/episode_y_velocity': Array(-151.19719, dtype=float32), 'eval/episode_distance_from_origin_std': Array(392.85916, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5111437, dtype=float32), 'eval/episode_forward_reward_std': Array(751.85205, dtype=float32), 'eval/episode_reward_std': Array(755.33765, dtype=float32), 'eval/episode_reward_alive_std': Array(45.233456, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.85205, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.950893, dtype=float32), 'eval/episode_x_position_std': Array(399.11606, dtype=float32), 'eval/episode_x_velocity_std': Array(150.3704, dtype=float32), 'eval/episode_y_position_std': Array(370.32886, dtype=float32), 'eval/episode_y_velocity_std': Array(119.79503, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60752391815186, 'eval/sps': 936.9908503479718, 'num_steps': 39649280}
{'eval/walltime': 66381.22242951393, 'training/sps': 2947.3073841471637, 'training/walltime': 13511.06967997551, 'training/entropy_loss': Array(0.01690696, dtype=float32), 'training/policy_loss': Array(0.0061651, dtype=float32), 'training/total_loss': Array(0.20568165, dtype=float32), 'training/v_loss': Array(0.1826096, dtype=float32), 'eval/episode_distance_from_origin': Array(6689.718, dtype=float32), 'eval/episode_distance_reward': Array(31.645891, dtype=float32), 'eval/episode_forward_reward': Array(5274.285, dtype=float32), 'eval/episode_reward': Array(5258.5977, dtype=float32), 'eval/episode_reward_alive': Array(362.35156, dtype=float32), 'eval/episode_reward_linvel': Array(5274.285, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.6844, dtype=float32), 'eval/episode_x_position': Array(6637.3564, dtype=float32), 'eval/episode_x_velocity': Array(1054.8568, dtype=float32), 'eval/episode_y_position': Array(-214.24365, dtype=float32), 'eval/episode_y_velocity': Array(-176.32857, dtype=float32), 'eval/episode_distance_from_origin_std': Array(438.28302, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7179713, dtype=float32), 'eval/episode_forward_reward_std': Array(786.3222, dtype=float32), 'eval/episode_reward_std': Array(786.385, dtype=float32), 'eval/episode_reward_alive_std': Array(46.47909, dtype=float32), 'eval/episode_reward_linvel_std': Array(786.3222, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.36825, dtype=float32), 'eval/episode_x_position_std': Array(440.53043, dtype=float32), 'eval/episode_x_velocity_std': Array(157.26447, dtype=float32), 'eval/episode_y_position_std': Array(332.64853, dtype=float32), 'eval/episode_y_velocity_std': Array(98.12081, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8707091808319, 'eval/sps': 935.1891340819164, 'num_steps': 39731200}
{'eval/walltime': 66517.84750461578, 'training/sps': 2935.414483552989, 'training/walltime': 13538.977152824402, 'training/entropy_loss': Array(0.01618419, dtype=float32), 'training/policy_loss': Array(0.00583325, dtype=float32), 'training/total_loss': Array(0.24247083, dtype=float32), 'training/v_loss': Array(0.2204534, dtype=float32), 'eval/episode_distance_from_origin': Array(6742.3315, dtype=float32), 'eval/episode_distance_reward': Array(32.478607, dtype=float32), 'eval/episode_forward_reward': Array(5413.071, dtype=float32), 'eval/episode_reward': Array(5394.2285, dtype=float32), 'eval/episode_reward_alive': Array(356.78125, dtype=float32), 'eval/episode_reward_linvel': Array(5413.071, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.10208, dtype=float32), 'eval/episode_x_position': Array(6690.497, dtype=float32), 'eval/episode_x_velocity': Array(1082.6141, dtype=float32), 'eval/episode_y_position': Array(-222.97118, dtype=float32), 'eval/episode_y_velocity': Array(-177.62653, dtype=float32), 'eval/episode_distance_from_origin_std': Array(392.8656, dtype=float32), 'eval/episode_distance_reward_std': Array(4.488781, dtype=float32), 'eval/episode_forward_reward_std': Array(748.1242, dtype=float32), 'eval/episode_reward_std': Array(746.8415, dtype=float32), 'eval/episode_reward_alive_std': Array(51.24671, dtype=float32), 'eval/episode_reward_linvel_std': Array(748.1242, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.865934, dtype=float32), 'eval/episode_x_position_std': Array(396.468, dtype=float32), 'eval/episode_x_velocity_std': Array(149.62482, dtype=float32), 'eval/episode_y_position_std': Array(315.15942, dtype=float32), 'eval/episode_y_velocity_std': Array(92.90418, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62507510185242, 'eval/sps': 936.8704822637973, 'num_steps': 39813120}
{'eval/walltime': 66654.61073875427, 'training/sps': 2940.2901648641637, 'training/walltime': 13566.83834862709, 'training/entropy_loss': Array(0.01645112, dtype=float32), 'training/policy_loss': Array(0.00528228, dtype=float32), 'training/total_loss': Array(0.25843498, dtype=float32), 'training/v_loss': Array(0.23670158, dtype=float32), 'eval/episode_distance_from_origin': Array(6817.284, dtype=float32), 'eval/episode_distance_reward': Array(33.00284, dtype=float32), 'eval/episode_forward_reward': Array(5500.442, dtype=float32), 'eval/episode_reward': Array(5480.5435, dtype=float32), 'eval/episode_reward_alive': Array(356.20312, dtype=float32), 'eval/episode_reward_linvel': Array(5500.442, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.1046, dtype=float32), 'eval/episode_x_position': Array(6768.3584, dtype=float32), 'eval/episode_x_velocity': Array(1100.0884, dtype=float32), 'eval/episode_y_position': Array(-224.89157, dtype=float32), 'eval/episode_y_velocity': Array(-170.34, dtype=float32), 'eval/episode_distance_from_origin_std': Array(427.02374, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5084796, dtype=float32), 'eval/episode_forward_reward_std': Array(751.40784, dtype=float32), 'eval/episode_reward_std': Array(744.61584, dtype=float32), 'eval/episode_reward_alive_std': Array(48.256046, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.40784, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.874792, dtype=float32), 'eval/episode_x_position_std': Array(429.88007, dtype=float32), 'eval/episode_x_velocity_std': Array(150.28151, dtype=float32), 'eval/episode_y_position_std': Array(288.62592, dtype=float32), 'eval/episode_y_velocity_std': Array(92.0177, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.76323413848877, 'eval/sps': 935.9240501024203, 'num_steps': 39895040}
{'eval/walltime': 66791.20020341873, 'training/sps': 2921.9116373177285, 'training/walltime': 13594.87478852272, 'training/entropy_loss': Array(0.01286583, dtype=float32), 'training/policy_loss': Array(0.00453564, dtype=float32), 'training/total_loss': Array(0.14668775, dtype=float32), 'training/v_loss': Array(0.12928626, dtype=float32), 'eval/episode_distance_from_origin': Array(6774.8164, dtype=float32), 'eval/episode_distance_reward': Array(32.450905, dtype=float32), 'eval/episode_forward_reward': Array(5408.453, dtype=float32), 'eval/episode_reward': Array(5376.13, dtype=float32), 'eval/episode_reward_alive': Array(349.45703, dtype=float32), 'eval/episode_reward_linvel': Array(5408.453, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.2309, dtype=float32), 'eval/episode_x_position': Array(6724.616, dtype=float32), 'eval/episode_x_velocity': Array(1081.6906, dtype=float32), 'eval/episode_y_position': Array(-248.89795, dtype=float32), 'eval/episode_y_velocity': Array(-184.90323, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.53467, dtype=float32), 'eval/episode_distance_reward_std': Array(4.656127, dtype=float32), 'eval/episode_forward_reward_std': Array(776.01556, dtype=float32), 'eval/episode_reward_std': Array(771.46295, dtype=float32), 'eval/episode_reward_alive_std': Array(53.896023, dtype=float32), 'eval/episode_reward_linvel_std': Array(776.01556, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.369785, dtype=float32), 'eval/episode_x_position_std': Array(423.17447, dtype=float32), 'eval/episode_x_velocity_std': Array(155.20317, dtype=float32), 'eval/episode_y_position_std': Array(262.9392, dtype=float32), 'eval/episode_y_velocity_std': Array(84.798416, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58946466445923, 'eval/sps': 937.1147351257302, 'num_steps': 39976960}
{'eval/walltime': 66927.84718942642, 'training/sps': 2939.828354127986, 'training/walltime': 13622.740360975266, 'training/entropy_loss': Array(0.01817251, dtype=float32), 'training/policy_loss': Array(0.00684323, dtype=float32), 'training/total_loss': Array(0.11932586, dtype=float32), 'training/v_loss': Array(0.09431011, dtype=float32), 'eval/episode_distance_from_origin': Array(6800.377, dtype=float32), 'eval/episode_distance_reward': Array(32.859116, dtype=float32), 'eval/episode_forward_reward': Array(5476.488, dtype=float32), 'eval/episode_reward': Array(5449.5615, dtype=float32), 'eval/episode_reward_alive': Array(353.33984, dtype=float32), 'eval/episode_reward_linvel': Array(5476.488, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.12497, dtype=float32), 'eval/episode_x_position': Array(6750.006, dtype=float32), 'eval/episode_x_velocity': Array(1095.2975, dtype=float32), 'eval/episode_y_position': Array(-209.3222, dtype=float32), 'eval/episode_y_velocity': Array(-169.2614, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.62204, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7110014, dtype=float32), 'eval/episode_forward_reward_std': Array(785.16156, dtype=float32), 'eval/episode_reward_std': Array(782.7984, dtype=float32), 'eval/episode_reward_alive_std': Array(51.083145, dtype=float32), 'eval/episode_reward_linvel_std': Array(785.16156, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.64523, dtype=float32), 'eval/episode_x_position_std': Array(428.78336, dtype=float32), 'eval/episode_x_velocity_std': Array(157.03223, dtype=float32), 'eval/episode_y_position_std': Array(319.55368, dtype=float32), 'eval/episode_y_velocity_std': Array(98.90039, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64698600769043, 'eval/sps': 936.7202580874797, 'num_steps': 40058880}
{'eval/walltime': 67064.53308272362, 'training/sps': 2919.16213257836, 'training/walltime': 13650.803207874298, 'training/entropy_loss': Array(0.01578646, dtype=float32), 'training/policy_loss': Array(0.00774712, dtype=float32), 'training/total_loss': Array(0.17278948, dtype=float32), 'training/v_loss': Array(0.1492559, dtype=float32), 'eval/episode_distance_from_origin': Array(6725.412, dtype=float32), 'eval/episode_distance_reward': Array(32.266815, dtype=float32), 'eval/episode_forward_reward': Array(5377.7715, dtype=float32), 'eval/episode_reward': Array(5363.21, dtype=float32), 'eval/episode_reward_alive': Array(363.5078, dtype=float32), 'eval/episode_reward_linvel': Array(5377.7715, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.33682, dtype=float32), 'eval/episode_x_position': Array(6672.7217, dtype=float32), 'eval/episode_x_velocity': Array(1075.5543, dtype=float32), 'eval/episode_y_position': Array(-232.06827, dtype=float32), 'eval/episode_y_velocity': Array(-181.18152, dtype=float32), 'eval/episode_distance_from_origin_std': Array(401.14514, dtype=float32), 'eval/episode_distance_reward_std': Array(4.575888, dtype=float32), 'eval/episode_forward_reward_std': Array(762.6427, dtype=float32), 'eval/episode_reward_std': Array(763.49554, dtype=float32), 'eval/episode_reward_alive_std': Array(49.46969, dtype=float32), 'eval/episode_reward_linvel_std': Array(762.6427, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.014715, dtype=float32), 'eval/episode_x_position_std': Array(404.8368, dtype=float32), 'eval/episode_x_velocity_std': Array(152.52844, dtype=float32), 'eval/episode_y_position_std': Array(322.79315, dtype=float32), 'eval/episode_y_velocity_std': Array(90.81185, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.68589329719543, 'eval/sps': 936.4536230647464, 'num_steps': 40140800}
{'eval/walltime': 67201.0845682621, 'training/sps': 2937.4947790249307, 'training/walltime': 13678.690917015076, 'training/entropy_loss': Array(0.01639896, dtype=float32), 'training/policy_loss': Array(0.00550028, dtype=float32), 'training/total_loss': Array(0.18460771, dtype=float32), 'training/v_loss': Array(0.16270846, dtype=float32), 'eval/episode_distance_from_origin': Array(6738.114, dtype=float32), 'eval/episode_distance_reward': Array(32.590767, dtype=float32), 'eval/episode_forward_reward': Array(5431.7627, dtype=float32), 'eval/episode_reward': Array(5415.812, dtype=float32), 'eval/episode_reward_alive': Array(361.16797, dtype=float32), 'eval/episode_reward_linvel': Array(5431.7627, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.70963, dtype=float32), 'eval/episode_x_position': Array(6686.8022, dtype=float32), 'eval/episode_x_velocity': Array(1086.3525, dtype=float32), 'eval/episode_y_position': Array(-157.68167, dtype=float32), 'eval/episode_y_velocity': Array(-168.71037, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.5537, dtype=float32), 'eval/episode_distance_reward_std': Array(5.530424, dtype=float32), 'eval/episode_forward_reward_std': Array(921.73145, dtype=float32), 'eval/episode_reward_std': Array(922.82733, dtype=float32), 'eval/episode_reward_alive_std': Array(50.737732, dtype=float32), 'eval/episode_reward_linvel_std': Array(921.73145, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.755407, dtype=float32), 'eval/episode_x_position_std': Array(489.5111, dtype=float32), 'eval/episode_x_velocity_std': Array(184.34631, dtype=float32), 'eval/episode_y_position_std': Array(351.49014, dtype=float32), 'eval/episode_y_velocity_std': Array(107.07441, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55148553848267, 'eval/sps': 937.3753752677212, 'num_steps': 40222720}
{'eval/walltime': 67337.5219078064, 'training/sps': 2935.737044269919, 'training/walltime': 13706.595323562622, 'training/entropy_loss': Array(0.01735266, dtype=float32), 'training/policy_loss': Array(0.00626723, dtype=float32), 'training/total_loss': Array(0.22443587, dtype=float32), 'training/v_loss': Array(0.20081598, dtype=float32), 'eval/episode_distance_from_origin': Array(6821.514, dtype=float32), 'eval/episode_distance_reward': Array(33.65776, dtype=float32), 'eval/episode_forward_reward': Array(5609.5957, dtype=float32), 'eval/episode_reward': Array(5605.1763, dtype=float32), 'eval/episode_reward_alive': Array(376.01172, dtype=float32), 'eval/episode_reward_linvel': Array(5609.5957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.08853, dtype=float32), 'eval/episode_x_position': Array(6772.0957, dtype=float32), 'eval/episode_x_velocity': Array(1121.919, dtype=float32), 'eval/episode_y_position': Array(-125.45801, dtype=float32), 'eval/episode_y_velocity': Array(-156.09248, dtype=float32), 'eval/episode_distance_from_origin_std': Array(401.13458, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7290535, dtype=float32), 'eval/episode_forward_reward_std': Array(788.1694, dtype=float32), 'eval/episode_reward_std': Array(786.5886, dtype=float32), 'eval/episode_reward_alive_std': Array(41.969364, dtype=float32), 'eval/episode_reward_linvel_std': Array(788.1694, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.000639, dtype=float32), 'eval/episode_x_position_std': Array(406.10736, dtype=float32), 'eval/episode_x_velocity_std': Array(157.63371, dtype=float32), 'eval/episode_y_position_std': Array(351.26346, dtype=float32), 'eval/episode_y_velocity_std': Array(101.57728, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43733954429626, 'eval/sps': 938.1596007920034, 'num_steps': 40304640}
{'eval/walltime': 67473.79177355766, 'training/sps': 2943.150673296241, 'training/walltime': 13734.429440498352, 'training/entropy_loss': Array(0.01736676, dtype=float32), 'training/policy_loss': Array(0.00492344, dtype=float32), 'training/total_loss': Array(0.25145394, dtype=float32), 'training/v_loss': Array(0.22916374, dtype=float32), 'eval/episode_distance_from_origin': Array(6746.3438, dtype=float32), 'eval/episode_distance_reward': Array(32.468414, dtype=float32), 'eval/episode_forward_reward': Array(5411.372, dtype=float32), 'eval/episode_reward': Array(5411.5444, dtype=float32), 'eval/episode_reward_alive': Array(379.95312, dtype=float32), 'eval/episode_reward_linvel': Array(5411.372, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.24847, dtype=float32), 'eval/episode_x_position': Array(6695.17, dtype=float32), 'eval/episode_x_velocity': Array(1082.2742, dtype=float32), 'eval/episode_y_position': Array(-160.57402, dtype=float32), 'eval/episode_y_velocity': Array(-166.112, dtype=float32), 'eval/episode_distance_from_origin_std': Array(437.25262, dtype=float32), 'eval/episode_distance_reward_std': Array(4.94904, dtype=float32), 'eval/episode_forward_reward_std': Array(824.83325, dtype=float32), 'eval/episode_reward_std': Array(826.5587, dtype=float32), 'eval/episode_reward_alive_std': Array(46.45299, dtype=float32), 'eval/episode_reward_linvel_std': Array(824.83325, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.326468, dtype=float32), 'eval/episode_x_position_std': Array(443.60593, dtype=float32), 'eval/episode_x_velocity_std': Array(164.96669, dtype=float32), 'eval/episode_y_position_std': Array(335.0964, dtype=float32), 'eval/episode_y_velocity_std': Array(104.3495, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26986575126648, 'eval/sps': 939.3125860536072, 'num_steps': 40386560}
{'eval/walltime': 67610.23885083199, 'training/sps': 2939.071989335775, 'training/walltime': 13762.30218410492, 'training/entropy_loss': Array(0.01500466, dtype=float32), 'training/policy_loss': Array(0.01132233, dtype=float32), 'training/total_loss': Array(0.1982392, dtype=float32), 'training/v_loss': Array(0.17191221, dtype=float32), 'eval/episode_distance_from_origin': Array(6836.911, dtype=float32), 'eval/episode_distance_reward': Array(33.527367, dtype=float32), 'eval/episode_forward_reward': Array(5587.8643, dtype=float32), 'eval/episode_reward': Array(5585.7124, dtype=float32), 'eval/episode_reward_alive': Array(375.71484, dtype=float32), 'eval/episode_reward_linvel': Array(5587.8643, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.39343, dtype=float32), 'eval/episode_x_position': Array(6789.7266, dtype=float32), 'eval/episode_x_velocity': Array(1117.5728, dtype=float32), 'eval/episode_y_position': Array(-109.06827, dtype=float32), 'eval/episode_y_velocity': Array(-147.63945, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.387, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4072065, dtype=float32), 'eval/episode_forward_reward_std': Array(734.5286, dtype=float32), 'eval/episode_reward_std': Array(731.93445, dtype=float32), 'eval/episode_reward_alive_std': Array(45.56669, dtype=float32), 'eval/episode_reward_linvel_std': Array(734.5286, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.122795, dtype=float32), 'eval/episode_x_position_std': Array(379.3358, dtype=float32), 'eval/episode_x_velocity_std': Array(146.90556, dtype=float32), 'eval/episode_y_position_std': Array(303.83472, dtype=float32), 'eval/episode_y_velocity_std': Array(104.61544, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4470772743225, 'eval/sps': 938.0926477645254, 'num_steps': 40468480}
{'eval/walltime': 67746.57676148415, 'training/sps': 2942.729144616549, 'training/walltime': 13790.140288114548, 'training/entropy_loss': Array(0.01584669, dtype=float32), 'training/policy_loss': Array(0.00808267, dtype=float32), 'training/total_loss': Array(0.10846761, dtype=float32), 'training/v_loss': Array(0.08453825, dtype=float32), 'eval/episode_distance_from_origin': Array(6880.817, dtype=float32), 'eval/episode_distance_reward': Array(33.803696, dtype=float32), 'eval/episode_forward_reward': Array(5633.917, dtype=float32), 'eval/episode_reward': Array(5622.7637, dtype=float32), 'eval/episode_reward_alive': Array(368.65234, dtype=float32), 'eval/episode_reward_linvel': Array(5633.917, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.60947, dtype=float32), 'eval/episode_x_position': Array(6832.3633, dtype=float32), 'eval/episode_x_velocity': Array(1126.7834, dtype=float32), 'eval/episode_y_position': Array(-153.37732, dtype=float32), 'eval/episode_y_velocity': Array(-150.33252, dtype=float32), 'eval/episode_distance_from_origin_std': Array(379.04764, dtype=float32), 'eval/episode_distance_reward_std': Array(4.672283, dtype=float32), 'eval/episode_forward_reward_std': Array(778.7076, dtype=float32), 'eval/episode_reward_std': Array(787.57416, dtype=float32), 'eval/episode_reward_alive_std': Array(45.854115, dtype=float32), 'eval/episode_reward_linvel_std': Array(778.7076, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.92325, dtype=float32), 'eval/episode_x_position_std': Array(382.66156, dtype=float32), 'eval/episode_x_velocity_std': Array(155.74156, dtype=float32), 'eval/episode_y_position_std': Array(348.03387, dtype=float32), 'eval/episode_y_velocity_std': Array(106.34941, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33791065216064, 'eval/sps': 938.843784445009, 'num_steps': 40550400}
{'eval/walltime': 67883.10347938538, 'training/sps': 2928.6872494146332, 'training/walltime': 13818.111864805222, 'training/entropy_loss': Array(0.01809785, dtype=float32), 'training/policy_loss': Array(0.00981807, dtype=float32), 'training/total_loss': Array(0.25042447, dtype=float32), 'training/v_loss': Array(0.22250856, dtype=float32), 'eval/episode_distance_from_origin': Array(6843.9434, dtype=float32), 'eval/episode_distance_reward': Array(33.407005, dtype=float32), 'eval/episode_forward_reward': Array(5567.8037, dtype=float32), 'eval/episode_reward': Array(5561.869, dtype=float32), 'eval/episode_reward_alive': Array(374.4922, dtype=float32), 'eval/episode_reward_linvel': Array(5567.8037, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.83325, dtype=float32), 'eval/episode_x_position': Array(6793.7207, dtype=float32), 'eval/episode_x_velocity': Array(1113.5608, dtype=float32), 'eval/episode_y_position': Array(-161.37021, dtype=float32), 'eval/episode_y_velocity': Array(-164.59279, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.63364, dtype=float32), 'eval/episode_distance_reward_std': Array(5.007102, dtype=float32), 'eval/episode_forward_reward_std': Array(834.5109, dtype=float32), 'eval/episode_reward_std': Array(834.67975, dtype=float32), 'eval/episode_reward_alive_std': Array(43.422882, dtype=float32), 'eval/episode_reward_linvel_std': Array(834.5109, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.887346, dtype=float32), 'eval/episode_x_position_std': Array(438.54062, dtype=float32), 'eval/episode_x_velocity_std': Array(166.90216, dtype=float32), 'eval/episode_y_position_std': Array(338.80005, dtype=float32), 'eval/episode_y_velocity_std': Array(100.7371, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52671790122986, 'eval/sps': 937.5454267684183, 'num_steps': 40632320}
{'eval/walltime': 68019.50678110123, 'training/sps': 2936.1407651290738, 'training/walltime': 13846.012434482574, 'training/entropy_loss': Array(0.01649415, dtype=float32), 'training/policy_loss': Array(0.00640628, dtype=float32), 'training/total_loss': Array(0.19912562, dtype=float32), 'training/v_loss': Array(0.17622519, dtype=float32), 'eval/episode_distance_from_origin': Array(6887.359, dtype=float32), 'eval/episode_distance_reward': Array(33.637142, dtype=float32), 'eval/episode_forward_reward': Array(5606.1587, dtype=float32), 'eval/episode_reward': Array(5596.4766, dtype=float32), 'eval/episode_reward_alive': Array(371.51953, dtype=float32), 'eval/episode_reward_linvel': Array(5606.1587, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.83905, dtype=float32), 'eval/episode_x_position': Array(6836.1157, dtype=float32), 'eval/episode_x_velocity': Array(1121.2317, dtype=float32), 'eval/episode_y_position': Array(-206.02892, dtype=float32), 'eval/episode_y_velocity': Array(-179.80954, dtype=float32), 'eval/episode_distance_from_origin_std': Array(393.6517, dtype=float32), 'eval/episode_distance_reward_std': Array(4.470833, dtype=float32), 'eval/episode_forward_reward_std': Array(745.13354, dtype=float32), 'eval/episode_reward_std': Array(747.7217, dtype=float32), 'eval/episode_reward_alive_std': Array(44.0061, dtype=float32), 'eval/episode_reward_linvel_std': Array(745.13354, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.140448, dtype=float32), 'eval/episode_x_position_std': Array(396.70996, dtype=float32), 'eval/episode_x_velocity_std': Array(149.02676, dtype=float32), 'eval/episode_y_position_std': Array(307.72403, dtype=float32), 'eval/episode_y_velocity_std': Array(82.76266, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40330171585083, 'eval/sps': 938.3937074092516, 'num_steps': 40714240}
{'eval/walltime': 68156.00727820396, 'training/sps': 2933.660839841945, 'training/walltime': 13873.936589479446, 'training/entropy_loss': Array(0.01783329, dtype=float32), 'training/policy_loss': Array(0.0064398, dtype=float32), 'training/total_loss': Array(0.24021786, dtype=float32), 'training/v_loss': Array(0.21594478, dtype=float32), 'eval/episode_distance_from_origin': Array(6911.6724, dtype=float32), 'eval/episode_distance_reward': Array(34.10804, dtype=float32), 'eval/episode_forward_reward': Array(5684.64, dtype=float32), 'eval/episode_reward': Array(5670.9316, dtype=float32), 'eval/episode_reward_alive': Array(364.8672, dtype=float32), 'eval/episode_reward_linvel': Array(5684.64, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.68378, dtype=float32), 'eval/episode_x_position': Array(6862.285, dtype=float32), 'eval/episode_x_velocity': Array(1136.9282, dtype=float32), 'eval/episode_y_position': Array(-175.84464, dtype=float32), 'eval/episode_y_velocity': Array(-175.12038, dtype=float32), 'eval/episode_distance_from_origin_std': Array(351.92804, dtype=float32), 'eval/episode_distance_reward_std': Array(4.0226674, dtype=float32), 'eval/episode_forward_reward_std': Array(670.4399, dtype=float32), 'eval/episode_reward_std': Array(663.8946, dtype=float32), 'eval/episode_reward_alive_std': Array(43.142635, dtype=float32), 'eval/episode_reward_linvel_std': Array(670.4399, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.491755, dtype=float32), 'eval/episode_x_position_std': Array(355.54462, dtype=float32), 'eval/episode_x_velocity_std': Array(134.08788, dtype=float32), 'eval/episode_y_position_std': Array(313.44916, dtype=float32), 'eval/episode_y_velocity_std': Array(92.36519, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50049710273743, 'eval/sps': 937.7255227404812, 'num_steps': 40796160}
{'eval/walltime': 68292.35397219658, 'training/sps': 2926.8222814952733, 'training/walltime': 13901.925989627838, 'training/entropy_loss': Array(0.0171571, dtype=float32), 'training/policy_loss': Array(0.00959817, dtype=float32), 'training/total_loss': Array(0.24919997, dtype=float32), 'training/v_loss': Array(0.2224447, dtype=float32), 'eval/episode_distance_from_origin': Array(6993.833, dtype=float32), 'eval/episode_distance_reward': Array(35.33245, dtype=float32), 'eval/episode_forward_reward': Array(5888.7085, dtype=float32), 'eval/episode_reward': Array(5882.2637, dtype=float32), 'eval/episode_reward_alive': Array(371.25, dtype=float32), 'eval/episode_reward_linvel': Array(5888.7085, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.02637, dtype=float32), 'eval/episode_x_position': Array(6943.635, dtype=float32), 'eval/episode_x_velocity': Array(1177.7415, dtype=float32), 'eval/episode_y_position': Array(-156.13518, dtype=float32), 'eval/episode_y_velocity': Array(-156.74854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(361.16754, dtype=float32), 'eval/episode_distance_reward_std': Array(3.9684727, dtype=float32), 'eval/episode_forward_reward_std': Array(661.4083, dtype=float32), 'eval/episode_reward_std': Array(662.79626, dtype=float32), 'eval/episode_reward_alive_std': Array(42.74552, dtype=float32), 'eval/episode_reward_linvel_std': Array(661.4083, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.7412, dtype=float32), 'eval/episode_x_position_std': Array(366.57828, dtype=float32), 'eval/episode_x_velocity_std': Array(132.28165, dtype=float32), 'eval/episode_y_position_std': Array(358.65854, dtype=float32), 'eval/episode_y_velocity_std': Array(112.94616, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34669399261475, 'eval/sps': 938.783304910445, 'num_steps': 40878080}
{'eval/walltime': 68428.87529420853, 'training/sps': 2932.8685408061274, 'training/walltime': 13929.857688188553, 'training/entropy_loss': Array(0.01731744, dtype=float32), 'training/policy_loss': Array(0.00773797, dtype=float32), 'training/total_loss': Array(0.24972321, dtype=float32), 'training/v_loss': Array(0.22466779, dtype=float32), 'eval/episode_distance_from_origin': Array(6813.8135, dtype=float32), 'eval/episode_distance_reward': Array(32.816383, dtype=float32), 'eval/episode_forward_reward': Array(5469.3667, dtype=float32), 'eval/episode_reward': Array(5462.0635, dtype=float32), 'eval/episode_reward_alive': Array(371.59375, dtype=float32), 'eval/episode_reward_linvel': Array(5469.3667, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.71353, dtype=float32), 'eval/episode_x_position': Array(6762.9463, dtype=float32), 'eval/episode_x_velocity': Array(1093.8733, dtype=float32), 'eval/episode_y_position': Array(-207.8044, dtype=float32), 'eval/episode_y_velocity': Array(-169.92323, dtype=float32), 'eval/episode_distance_from_origin_std': Array(359.4673, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6169734, dtype=float32), 'eval/episode_forward_reward_std': Array(769.48975, dtype=float32), 'eval/episode_reward_std': Array(769.95044, dtype=float32), 'eval/episode_reward_alive_std': Array(53.26664, dtype=float32), 'eval/episode_reward_linvel_std': Array(769.48975, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.801306, dtype=float32), 'eval/episode_x_position_std': Array(360.20926, dtype=float32), 'eval/episode_x_velocity_std': Array(153.89795, dtype=float32), 'eval/episode_y_position_std': Array(312.72433, dtype=float32), 'eval/episode_y_velocity_std': Array(98.82577, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52132201194763, 'eval/sps': 937.5824824549978, 'num_steps': 40960000}
{'eval/walltime': 68565.21964526176, 'training/sps': 2936.71755126968, 'training/walltime': 13957.752778053284, 'training/entropy_loss': Array(0.01461302, dtype=float32), 'training/policy_loss': Array(0.00817608, dtype=float32), 'training/total_loss': Array(0.08141625, dtype=float32), 'training/v_loss': Array(0.05862715, dtype=float32), 'eval/episode_distance_from_origin': Array(6862.089, dtype=float32), 'eval/episode_distance_reward': Array(33.579296, dtype=float32), 'eval/episode_forward_reward': Array(5596.5186, dtype=float32), 'eval/episode_reward': Array(5580.454, dtype=float32), 'eval/episode_reward_alive': Array(361.63672, dtype=float32), 'eval/episode_reward_linvel': Array(5596.5186, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.2796, dtype=float32), 'eval/episode_x_position': Array(6810.8896, dtype=float32), 'eval/episode_x_velocity': Array(1119.3035, dtype=float32), 'eval/episode_y_position': Array(-197.55234, dtype=float32), 'eval/episode_y_velocity': Array(-173.25507, dtype=float32), 'eval/episode_distance_from_origin_std': Array(349.30878, dtype=float32), 'eval/episode_distance_reward_std': Array(4.387535, dtype=float32), 'eval/episode_forward_reward_std': Array(731.2507, dtype=float32), 'eval/episode_reward_std': Array(733.86774, dtype=float32), 'eval/episode_reward_alive_std': Array(48.511467, dtype=float32), 'eval/episode_reward_linvel_std': Array(731.2507, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.444279, dtype=float32), 'eval/episode_x_position_std': Array(351.83963, dtype=float32), 'eval/episode_x_velocity_std': Array(146.25012, dtype=float32), 'eval/episode_y_position_std': Array(328.2447, dtype=float32), 'eval/episode_y_velocity_std': Array(107.253136, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34435105323792, 'eval/sps': 938.7994369493186, 'num_steps': 41041920}
{'eval/walltime': 68701.72566509247, 'training/sps': 2935.851478688401, 'training/walltime': 13985.656096935272, 'training/entropy_loss': Array(0.01665531, dtype=float32), 'training/policy_loss': Array(0.01111621, dtype=float32), 'training/total_loss': Array(0.17958213, dtype=float32), 'training/v_loss': Array(0.15181062, dtype=float32), 'eval/episode_distance_from_origin': Array(6855.8867, dtype=float32), 'eval/episode_distance_reward': Array(32.913376, dtype=float32), 'eval/episode_forward_reward': Array(5485.532, dtype=float32), 'eval/episode_reward': Array(5472.1772, dtype=float32), 'eval/episode_reward_alive': Array(366.78125, dtype=float32), 'eval/episode_reward_linvel': Array(5485.532, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.04877, dtype=float32), 'eval/episode_x_position': Array(6804.807, dtype=float32), 'eval/episode_x_velocity': Array(1097.1062, dtype=float32), 'eval/episode_y_position': Array(-191.92375, dtype=float32), 'eval/episode_y_velocity': Array(-167.21759, dtype=float32), 'eval/episode_distance_from_origin_std': Array(380.36548, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7782354, dtype=float32), 'eval/episode_forward_reward_std': Array(796.3665, dtype=float32), 'eval/episode_reward_std': Array(792.61316, dtype=float32), 'eval/episode_reward_alive_std': Array(51.227158, dtype=float32), 'eval/episode_reward_linvel_std': Array(796.3665, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.657354, dtype=float32), 'eval/episode_x_position_std': Array(381.9923, dtype=float32), 'eval/episode_x_velocity_std': Array(159.27335, dtype=float32), 'eval/episode_y_position_std': Array(321.0463, dtype=float32), 'eval/episode_y_velocity_std': Array(109.27456, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50601983070374, 'eval/sps': 937.6875844651174, 'num_steps': 41123840}
{'eval/walltime': 68838.09732437134, 'training/sps': 2935.0856504406474, 'training/walltime': 14013.56669640541, 'training/entropy_loss': Array(0.01580724, dtype=float32), 'training/policy_loss': Array(0.01156807, dtype=float32), 'training/total_loss': Array(0.15089756, dtype=float32), 'training/v_loss': Array(0.12352225, dtype=float32), 'eval/episode_distance_from_origin': Array(6883.534, dtype=float32), 'eval/episode_distance_reward': Array(33.560917, dtype=float32), 'eval/episode_forward_reward': Array(5593.4546, dtype=float32), 'eval/episode_reward': Array(5580.922, dtype=float32), 'eval/episode_reward_alive': Array(367.5, dtype=float32), 'eval/episode_reward_linvel': Array(5593.4546, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.59314, dtype=float32), 'eval/episode_x_position': Array(6830.4824, dtype=float32), 'eval/episode_x_velocity': Array(1118.6908, dtype=float32), 'eval/episode_y_position': Array(-221.39316, dtype=float32), 'eval/episode_y_velocity': Array(-171.64548, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.6186, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0704846, dtype=float32), 'eval/episode_forward_reward_std': Array(845.07465, dtype=float32), 'eval/episode_reward_std': Array(841.5625, dtype=float32), 'eval/episode_reward_alive_std': Array(50.54384, dtype=float32), 'eval/episode_reward_linvel_std': Array(845.07465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.095772, dtype=float32), 'eval/episode_x_position_std': Array(430.7188, dtype=float32), 'eval/episode_x_velocity_std': Array(169.01497, dtype=float32), 'eval/episode_y_position_std': Array(345.864, dtype=float32), 'eval/episode_y_velocity_std': Array(107.23213, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37165927886963, 'eval/sps': 938.6114437329663, 'num_steps': 41205760}
{'eval/walltime': 68974.6335799694, 'training/sps': 2933.676018900292, 'training/walltime': 14041.490706920624, 'training/entropy_loss': Array(0.01695124, dtype=float32), 'training/policy_loss': Array(0.0066679, dtype=float32), 'training/total_loss': Array(0.19143468, dtype=float32), 'training/v_loss': Array(0.16781555, dtype=float32), 'eval/episode_distance_from_origin': Array(6822.7705, dtype=float32), 'eval/episode_distance_reward': Array(33.138092, dtype=float32), 'eval/episode_forward_reward': Array(5522.9834, dtype=float32), 'eval/episode_reward': Array(5504.5693, dtype=float32), 'eval/episode_reward_alive': Array(358.0039, dtype=float32), 'eval/episode_reward_linvel': Array(5522.9834, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.55624, dtype=float32), 'eval/episode_x_position': Array(6772.7607, dtype=float32), 'eval/episode_x_velocity': Array(1104.5967, dtype=float32), 'eval/episode_y_position': Array(-206.93718, dtype=float32), 'eval/episode_y_velocity': Array(-173.86337, dtype=float32), 'eval/episode_distance_from_origin_std': Array(406.38416, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4806495, dtype=float32), 'eval/episode_forward_reward_std': Array(746.76917, dtype=float32), 'eval/episode_reward_std': Array(746.58405, dtype=float32), 'eval/episode_reward_alive_std': Array(52.563076, dtype=float32), 'eval/episode_reward_linvel_std': Array(746.76917, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.883726, dtype=float32), 'eval/episode_x_position_std': Array(410.8587, dtype=float32), 'eval/episode_x_velocity_std': Array(149.3538, dtype=float32), 'eval/episode_y_position_std': Array(301.6034, dtype=float32), 'eval/episode_y_velocity_std': Array(96.282394, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53625559806824, 'eval/sps': 937.4799348299324, 'num_steps': 41287680}
{'eval/walltime': 69110.99264717102, 'training/sps': 2941.592252177398, 'training/walltime': 14069.339570045471, 'training/entropy_loss': Array(0.01677757, dtype=float32), 'training/policy_loss': Array(0.00605171, dtype=float32), 'training/total_loss': Array(0.24462894, dtype=float32), 'training/v_loss': Array(0.22179966, dtype=float32), 'eval/episode_distance_from_origin': Array(6864.3726, dtype=float32), 'eval/episode_distance_reward': Array(33.671993, dtype=float32), 'eval/episode_forward_reward': Array(5611.967, dtype=float32), 'eval/episode_reward': Array(5592.3037, dtype=float32), 'eval/episode_reward_alive': Array(360.6289, dtype=float32), 'eval/episode_reward_linvel': Array(5611.967, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.96368, dtype=float32), 'eval/episode_x_position': Array(6813.9663, dtype=float32), 'eval/episode_x_velocity': Array(1122.3933, dtype=float32), 'eval/episode_y_position': Array(-199.5227, dtype=float32), 'eval/episode_y_velocity': Array(-177.45224, dtype=float32), 'eval/episode_distance_from_origin_std': Array(367.04138, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4588566, dtype=float32), 'eval/episode_forward_reward_std': Array(743.1369, dtype=float32), 'eval/episode_reward_std': Array(749.2492, dtype=float32), 'eval/episode_reward_alive_std': Array(46.170467, dtype=float32), 'eval/episode_reward_linvel_std': Array(743.1369, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.738375, dtype=float32), 'eval/episode_x_position_std': Array(372.1797, dtype=float32), 'eval/episode_x_velocity_std': Array(148.62744, dtype=float32), 'eval/episode_y_position_std': Array(291.8326, dtype=float32), 'eval/episode_y_velocity_std': Array(89.85327, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35906720161438, 'eval/sps': 938.6981198011935, 'num_steps': 41369600}
{'eval/walltime': 69247.53536748886, 'training/sps': 2934.05341677904, 'training/walltime': 14097.25998878479, 'training/entropy_loss': Array(0.01678433, dtype=float32), 'training/policy_loss': Array(0.01012553, dtype=float32), 'training/total_loss': Array(0.25799775, dtype=float32), 'training/v_loss': Array(0.23108788, dtype=float32), 'eval/episode_distance_from_origin': Array(6876.7544, dtype=float32), 'eval/episode_distance_reward': Array(33.612896, dtype=float32), 'eval/episode_forward_reward': Array(5602.118, dtype=float32), 'eval/episode_reward': Array(5575.0034, dtype=float32), 'eval/episode_reward_alive': Array(354.77734, dtype=float32), 'eval/episode_reward_linvel': Array(5602.118, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.50455, dtype=float32), 'eval/episode_x_position': Array(6825.5566, dtype=float32), 'eval/episode_x_velocity': Array(1120.4235, dtype=float32), 'eval/episode_y_position': Array(-248.9827, dtype=float32), 'eval/episode_y_velocity': Array(-185.01569, dtype=float32), 'eval/episode_distance_from_origin_std': Array(380.69513, dtype=float32), 'eval/episode_distance_reward_std': Array(4.3440394, dtype=float32), 'eval/episode_forward_reward_std': Array(724.00104, dtype=float32), 'eval/episode_reward_std': Array(728.2033, dtype=float32), 'eval/episode_reward_alive_std': Array(48.274883, dtype=float32), 'eval/episode_reward_linvel_std': Array(724.00104, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.77455, dtype=float32), 'eval/episode_x_position_std': Array(384.47318, dtype=float32), 'eval/episode_x_velocity_std': Array(144.80023, dtype=float32), 'eval/episode_y_position_std': Array(267.17685, dtype=float32), 'eval/episode_y_velocity_std': Array(84.30175, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54272031784058, 'eval/sps': 937.4355491237097, 'num_steps': 41451520}
{'eval/walltime': 69383.92146897316, 'training/sps': 2944.201605105936, 'training/walltime': 14125.084170341492, 'training/entropy_loss': Array(0.01273611, dtype=float32), 'training/policy_loss': Array(0.00786551, dtype=float32), 'training/total_loss': Array(0.11010421, dtype=float32), 'training/v_loss': Array(0.08950259, dtype=float32), 'eval/episode_distance_from_origin': Array(6777.176, dtype=float32), 'eval/episode_distance_reward': Array(32.628944, dtype=float32), 'eval/episode_forward_reward': Array(5438.1274, dtype=float32), 'eval/episode_reward': Array(5416.0337, dtype=float32), 'eval/episode_reward_alive': Array(360.53516, dtype=float32), 'eval/episode_reward_linvel': Array(5438.1274, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.25754, dtype=float32), 'eval/episode_x_position': Array(6724.36, dtype=float32), 'eval/episode_x_velocity': Array(1087.6254, dtype=float32), 'eval/episode_y_position': Array(-237.89569, dtype=float32), 'eval/episode_y_velocity': Array(-180.62424, dtype=float32), 'eval/episode_distance_from_origin_std': Array(393.05835, dtype=float32), 'eval/episode_distance_reward_std': Array(4.509414, dtype=float32), 'eval/episode_forward_reward_std': Array(751.56287, dtype=float32), 'eval/episode_reward_std': Array(750.1086, dtype=float32), 'eval/episode_reward_alive_std': Array(47.46982, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.56287, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.244164, dtype=float32), 'eval/episode_x_position_std': Array(394.99722, dtype=float32), 'eval/episode_x_velocity_std': Array(150.31255, dtype=float32), 'eval/episode_y_position_std': Array(293.16272, dtype=float32), 'eval/episode_y_velocity_std': Array(104.11545, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3861014842987, 'eval/sps': 938.5120522323592, 'num_steps': 41533440}
{'eval/walltime': 69520.50034999847, 'training/sps': 2937.027820609522, 'training/walltime': 14152.976313352585, 'training/entropy_loss': Array(0.01812018, dtype=float32), 'training/policy_loss': Array(0.00692351, dtype=float32), 'training/total_loss': Array(0.12772322, dtype=float32), 'training/v_loss': Array(0.10267953, dtype=float32), 'eval/episode_distance_from_origin': Array(6861.8022, dtype=float32), 'eval/episode_distance_reward': Array(33.60444, dtype=float32), 'eval/episode_forward_reward': Array(5600.708, dtype=float32), 'eval/episode_reward': Array(5576.7876, dtype=float32), 'eval/episode_reward_alive': Array(357.90625, dtype=float32), 'eval/episode_reward_linvel': Array(5600.708, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.43164, dtype=float32), 'eval/episode_x_position': Array(6809.1846, dtype=float32), 'eval/episode_x_velocity': Array(1120.1416, dtype=float32), 'eval/episode_y_position': Array(-211.45218, dtype=float32), 'eval/episode_y_velocity': Array(-178.80038, dtype=float32), 'eval/episode_distance_from_origin_std': Array(400.6035, dtype=float32), 'eval/episode_distance_reward_std': Array(4.5098877, dtype=float32), 'eval/episode_forward_reward_std': Array(751.6429, dtype=float32), 'eval/episode_reward_std': Array(752.88934, dtype=float32), 'eval/episode_reward_alive_std': Array(48.214478, dtype=float32), 'eval/episode_reward_linvel_std': Array(751.6429, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.08192, dtype=float32), 'eval/episode_x_position_std': Array(404.37027, dtype=float32), 'eval/episode_x_velocity_std': Array(150.32854, dtype=float32), 'eval/episode_y_position_std': Array(320.26303, dtype=float32), 'eval/episode_y_velocity_std': Array(98.1679, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57888102531433, 'eval/sps': 937.1873531184937, 'num_steps': 41615360}
{'eval/walltime': 69656.87371587753, 'training/sps': 2940.2474921684293, 'training/walltime': 14180.837913513184, 'training/entropy_loss': Array(0.01656828, dtype=float32), 'training/policy_loss': Array(0.00878553, dtype=float32), 'training/total_loss': Array(0.19583656, dtype=float32), 'training/v_loss': Array(0.17048275, dtype=float32), 'eval/episode_distance_from_origin': Array(6839.7803, dtype=float32), 'eval/episode_distance_reward': Array(32.803085, dtype=float32), 'eval/episode_forward_reward': Array(5467.1504, dtype=float32), 'eval/episode_reward': Array(5447.542, dtype=float32), 'eval/episode_reward_alive': Array(362.16016, dtype=float32), 'eval/episode_reward_linvel': Array(5467.1504, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.57126, dtype=float32), 'eval/episode_x_position': Array(6790.0225, dtype=float32), 'eval/episode_x_velocity': Array(1093.4299, dtype=float32), 'eval/episode_y_position': Array(-213.18683, dtype=float32), 'eval/episode_y_velocity': Array(-176.2911, dtype=float32), 'eval/episode_distance_from_origin_std': Array(396.26035, dtype=float32), 'eval/episode_distance_reward_std': Array(4.6178412, dtype=float32), 'eval/episode_forward_reward_std': Array(769.63477, dtype=float32), 'eval/episode_reward_std': Array(776.76056, dtype=float32), 'eval/episode_reward_alive_std': Array(44.97247, dtype=float32), 'eval/episode_reward_linvel_std': Array(769.63477, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.039604, dtype=float32), 'eval/episode_x_position_std': Array(396.8455, dtype=float32), 'eval/episode_x_velocity_std': Array(153.92688, dtype=float32), 'eval/episode_y_position_std': Array(288.66132, dtype=float32), 'eval/episode_y_velocity_std': Array(86.330986, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37336587905884, 'eval/sps': 938.5996977849424, 'num_steps': 41697280}
{'eval/walltime': 69793.43945884705, 'training/sps': 2934.69788554176, 'training/walltime': 14208.752200841904, 'training/entropy_loss': Array(0.01765596, dtype=float32), 'training/policy_loss': Array(0.00561985, dtype=float32), 'training/total_loss': Array(0.21750107, dtype=float32), 'training/v_loss': Array(0.19422527, dtype=float32), 'eval/episode_distance_from_origin': Array(6879.5166, dtype=float32), 'eval/episode_distance_reward': Array(33.515137, dtype=float32), 'eval/episode_forward_reward': Array(5585.825, dtype=float32), 'eval/episode_reward': Array(5554.952, dtype=float32), 'eval/episode_reward_alive': Array(354.42188, dtype=float32), 'eval/episode_reward_linvel': Array(5585.825, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.80994, dtype=float32), 'eval/episode_x_position': Array(6828.836, dtype=float32), 'eval/episode_x_velocity': Array(1117.1649, dtype=float32), 'eval/episode_y_position': Array(-204.06949, dtype=float32), 'eval/episode_y_velocity': Array(-172.56317, dtype=float32), 'eval/episode_distance_from_origin_std': Array(388.67133, dtype=float32), 'eval/episode_distance_reward_std': Array(4.476474, dtype=float32), 'eval/episode_forward_reward_std': Array(746.07367, dtype=float32), 'eval/episode_reward_std': Array(744.9256, dtype=float32), 'eval/episode_reward_alive_std': Array(48.812073, dtype=float32), 'eval/episode_reward_linvel_std': Array(746.07367, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.186516, dtype=float32), 'eval/episode_x_position_std': Array(390.06238, dtype=float32), 'eval/episode_x_velocity_std': Array(149.21466, dtype=float32), 'eval/episode_y_position_std': Array(319.95413, dtype=float32), 'eval/episode_y_velocity_std': Array(107.230995, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56574296951294, 'eval/sps': 937.2775135018658, 'num_steps': 41779200}
{'eval/walltime': 69929.83475542068, 'training/sps': 2933.843424775622, 'training/walltime': 14236.674618005753, 'training/entropy_loss': Array(0.01757651, dtype=float32), 'training/policy_loss': Array(0.00759282, dtype=float32), 'training/total_loss': Array(0.2805417, dtype=float32), 'training/v_loss': Array(0.25537235, dtype=float32), 'eval/episode_distance_from_origin': Array(6904.8, dtype=float32), 'eval/episode_distance_reward': Array(33.300976, dtype=float32), 'eval/episode_forward_reward': Array(5550.132, dtype=float32), 'eval/episode_reward': Array(5524.124, dtype=float32), 'eval/episode_reward_alive': Array(359.66016, dtype=float32), 'eval/episode_reward_linvel': Array(5550.132, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.96918, dtype=float32), 'eval/episode_x_position': Array(6853.0176, dtype=float32), 'eval/episode_x_velocity': Array(1110.0264, dtype=float32), 'eval/episode_y_position': Array(-154.7951, dtype=float32), 'eval/episode_y_velocity': Array(-161.52612, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.83304, dtype=float32), 'eval/episode_distance_reward_std': Array(4.928783, dtype=float32), 'eval/episode_forward_reward_std': Array(821.45746, dtype=float32), 'eval/episode_reward_std': Array(820.20166, dtype=float32), 'eval/episode_reward_alive_std': Array(49.40406, dtype=float32), 'eval/episode_reward_linvel_std': Array(821.45746, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.458925, dtype=float32), 'eval/episode_x_position_std': Array(436.17953, dtype=float32), 'eval/episode_x_velocity_std': Array(164.29149, dtype=float32), 'eval/episode_y_position_std': Array(370.36078, dtype=float32), 'eval/episode_y_velocity_std': Array(112.48123, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39529657363892, 'eval/sps': 938.4487824394564, 'num_steps': 41861120}
{'eval/walltime': 70066.36701655388, 'training/sps': 2933.003056236357, 'training/walltime': 14264.605035543442, 'training/entropy_loss': Array(0.01725426, dtype=float32), 'training/policy_loss': Array(0.00650755, dtype=float32), 'training/total_loss': Array(0.30264467, dtype=float32), 'training/v_loss': Array(0.27888283, dtype=float32), 'eval/episode_distance_from_origin': Array(6896.1064, dtype=float32), 'eval/episode_distance_reward': Array(34.083626, dtype=float32), 'eval/episode_forward_reward': Array(5680.572, dtype=float32), 'eval/episode_reward': Array(5658.809, dtype=float32), 'eval/episode_reward_alive': Array(360.14453, dtype=float32), 'eval/episode_reward_linvel': Array(5680.572, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.99164, dtype=float32), 'eval/episode_x_position': Array(6847.953, dtype=float32), 'eval/episode_x_velocity': Array(1136.1145, dtype=float32), 'eval/episode_y_position': Array(-145.24396, dtype=float32), 'eval/episode_y_velocity': Array(-157.91965, dtype=float32), 'eval/episode_distance_from_origin_std': Array(379.77057, dtype=float32), 'eval/episode_distance_reward_std': Array(4.1165605, dtype=float32), 'eval/episode_forward_reward_std': Array(686.0879, dtype=float32), 'eval/episode_reward_std': Array(681.66046, dtype=float32), 'eval/episode_reward_alive_std': Array(52.372803, dtype=float32), 'eval/episode_reward_linvel_std': Array(686.0879, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.69247, dtype=float32), 'eval/episode_x_position_std': Array(385.00656, dtype=float32), 'eval/episode_x_velocity_std': Array(137.21758, dtype=float32), 'eval/episode_y_position_std': Array(315.30124, dtype=float32), 'eval/episode_y_velocity_std': Array(98.45399, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53226113319397, 'eval/sps': 937.5073622719078, 'num_steps': 41943040}
{'eval/walltime': 70202.74626636505, 'training/sps': 2935.694754456228, 'training/walltime': 14292.509844064713, 'training/entropy_loss': Array(0.01376085, dtype=float32), 'training/policy_loss': Array(0.00531705, dtype=float32), 'training/total_loss': Array(0.16076648, dtype=float32), 'training/v_loss': Array(0.14168859, dtype=float32), 'eval/episode_distance_from_origin': Array(6859.296, dtype=float32), 'eval/episode_distance_reward': Array(33.88778, dtype=float32), 'eval/episode_forward_reward': Array(5647.9316, dtype=float32), 'eval/episode_reward': Array(5629.866, dtype=float32), 'eval/episode_reward_alive': Array(362.34375, dtype=float32), 'eval/episode_reward_linvel': Array(5647.9316, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.29663, dtype=float32), 'eval/episode_x_position': Array(6808.025, dtype=float32), 'eval/episode_x_velocity': Array(1129.5862, dtype=float32), 'eval/episode_y_position': Array(-75.58859, dtype=float32), 'eval/episode_y_velocity': Array(-141.69589, dtype=float32), 'eval/episode_distance_from_origin_std': Array(460.98215, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1632032, dtype=float32), 'eval/episode_forward_reward_std': Array(860.52795, dtype=float32), 'eval/episode_reward_std': Array(859.9611, dtype=float32), 'eval/episode_reward_alive_std': Array(50.868465, dtype=float32), 'eval/episode_reward_linvel_std': Array(860.52795, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.683056, dtype=float32), 'eval/episode_x_position_std': Array(464.82114, dtype=float32), 'eval/episode_x_velocity_std': Array(172.10567, dtype=float32), 'eval/episode_y_position_std': Array(386.23026, dtype=float32), 'eval/episode_y_velocity_std': Array(120.33185, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37924981117249, 'eval/sps': 938.5592029375862, 'num_steps': 42024960}
{'eval/walltime': 70339.2763311863, 'training/sps': 2935.620060478335, 'training/walltime': 14320.415362596512, 'training/entropy_loss': Array(0.01845124, dtype=float32), 'training/policy_loss': Array(0.0076482, dtype=float32), 'training/total_loss': Array(0.10969335, dtype=float32), 'training/v_loss': Array(0.0835939, dtype=float32), 'eval/episode_distance_from_origin': Array(6808.4663, dtype=float32), 'eval/episode_distance_reward': Array(33.14132, dtype=float32), 'eval/episode_forward_reward': Array(5523.5225, dtype=float32), 'eval/episode_reward': Array(5493.673, dtype=float32), 'eval/episode_reward_alive': Array(352.70312, dtype=float32), 'eval/episode_reward_linvel': Array(5523.5225, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.69336, dtype=float32), 'eval/episode_x_position': Array(6759.205, dtype=float32), 'eval/episode_x_velocity': Array(1104.7043, dtype=float32), 'eval/episode_y_position': Array(-165.21802, dtype=float32), 'eval/episode_y_velocity': Array(-173.89545, dtype=float32), 'eval/episode_distance_from_origin_std': Array(419.01285, dtype=float32), 'eval/episode_distance_reward_std': Array(4.705, dtype=float32), 'eval/episode_forward_reward_std': Array(784.16064, dtype=float32), 'eval/episode_reward_std': Array(786.3219, dtype=float32), 'eval/episode_reward_alive_std': Array(47.68149, dtype=float32), 'eval/episode_reward_linvel_std': Array(784.16064, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.167637, dtype=float32), 'eval/episode_x_position_std': Array(422.2325, dtype=float32), 'eval/episode_x_velocity_std': Array(156.83221, dtype=float32), 'eval/episode_y_position_std': Array(303.10437, dtype=float32), 'eval/episode_y_velocity_std': Array(91.32671, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5300648212433, 'eval/sps': 937.5224436287233, 'num_steps': 42106880}
{'eval/walltime': 70475.61357402802, 'training/sps': 2944.2723212824017, 'training/walltime': 14348.238875865936, 'training/entropy_loss': Array(0.01617163, dtype=float32), 'training/policy_loss': Array(0.0056483, dtype=float32), 'training/total_loss': Array(0.1913496, dtype=float32), 'training/v_loss': Array(0.16952965, dtype=float32), 'eval/episode_distance_from_origin': Array(6798.544, dtype=float32), 'eval/episode_distance_reward': Array(32.951057, dtype=float32), 'eval/episode_forward_reward': Array(5491.812, dtype=float32), 'eval/episode_reward': Array(5468.493, dtype=float32), 'eval/episode_reward_alive': Array(361.33984, dtype=float32), 'eval/episode_reward_linvel': Array(5491.812, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.6097, dtype=float32), 'eval/episode_x_position': Array(6750.058, dtype=float32), 'eval/episode_x_velocity': Array(1098.3624, dtype=float32), 'eval/episode_y_position': Array(-153.538, dtype=float32), 'eval/episode_y_velocity': Array(-165.51883, dtype=float32), 'eval/episode_distance_from_origin_std': Array(389.7539, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8781533, dtype=float32), 'eval/episode_forward_reward_std': Array(813.0188, dtype=float32), 'eval/episode_reward_std': Array(817.61993, dtype=float32), 'eval/episode_reward_alive_std': Array(46.374744, dtype=float32), 'eval/episode_reward_linvel_std': Array(813.0188, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.268356, dtype=float32), 'eval/episode_x_position_std': Array(392.49475, dtype=float32), 'eval/episode_x_velocity_std': Array(162.60374, dtype=float32), 'eval/episode_y_position_std': Array(298.02148, dtype=float32), 'eval/episode_y_velocity_std': Array(94.363106, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33724284172058, 'eval/sps': 938.8483831127521, 'num_steps': 42188800}
{'eval/walltime': 70612.14868164062, 'training/sps': 2944.372283370637, 'training/walltime': 14376.06144452095, 'training/entropy_loss': Array(0.01670094, dtype=float32), 'training/policy_loss': Array(0.01000166, dtype=float32), 'training/total_loss': Array(0.19211361, dtype=float32), 'training/v_loss': Array(0.16541101, dtype=float32), 'eval/episode_distance_from_origin': Array(6795.365, dtype=float32), 'eval/episode_distance_reward': Array(32.782814, dtype=float32), 'eval/episode_forward_reward': Array(5463.7725, dtype=float32), 'eval/episode_reward': Array(5436.0703, dtype=float32), 'eval/episode_reward_alive': Array(359.07812, dtype=float32), 'eval/episode_reward_linvel': Array(5463.7725, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.56345, dtype=float32), 'eval/episode_x_position': Array(6742.9453, dtype=float32), 'eval/episode_x_velocity': Array(1092.7545, dtype=float32), 'eval/episode_y_position': Array(-179.01678, dtype=float32), 'eval/episode_y_velocity': Array(-167.37495, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.7684, dtype=float32), 'eval/episode_distance_reward_std': Array(5.51074, dtype=float32), 'eval/episode_forward_reward_std': Array(918.45056, dtype=float32), 'eval/episode_reward_std': Array(915.75543, dtype=float32), 'eval/episode_reward_alive_std': Array(49.477913, dtype=float32), 'eval/episode_reward_linvel_std': Array(918.45056, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.756163, dtype=float32), 'eval/episode_x_position_std': Array(456.63956, dtype=float32), 'eval/episode_x_velocity_std': Array(183.69022, dtype=float32), 'eval/episode_y_position_std': Array(330.9872, dtype=float32), 'eval/episode_y_velocity_std': Array(104.94561, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53510761260986, 'eval/sps': 937.4878171493704, 'num_steps': 42270720}
{'eval/walltime': 70748.50155687332, 'training/sps': 2941.6213897090634, 'training/walltime': 14403.910031795502, 'training/entropy_loss': Array(0.01743342, dtype=float32), 'training/policy_loss': Array(0.00714038, dtype=float32), 'training/total_loss': Array(0.23872754, dtype=float32), 'training/v_loss': Array(0.21415372, dtype=float32), 'eval/episode_distance_from_origin': Array(6860.63, dtype=float32), 'eval/episode_distance_reward': Array(33.367207, dtype=float32), 'eval/episode_forward_reward': Array(5561.1704, dtype=float32), 'eval/episode_reward': Array(5541.0464, dtype=float32), 'eval/episode_reward_alive': Array(362.09766, dtype=float32), 'eval/episode_reward_linvel': Array(5561.1704, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.5893, dtype=float32), 'eval/episode_x_position': Array(6806.914, dtype=float32), 'eval/episode_x_velocity': Array(1112.2341, dtype=float32), 'eval/episode_y_position': Array(-115.5467, dtype=float32), 'eval/episode_y_velocity': Array(-151.85081, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.29312, dtype=float32), 'eval/episode_distance_reward_std': Array(4.932752, dtype=float32), 'eval/episode_forward_reward_std': Array(822.11835, dtype=float32), 'eval/episode_reward_std': Array(820.48047, dtype=float32), 'eval/episode_reward_alive_std': Array(46.54505, dtype=float32), 'eval/episode_reward_linvel_std': Array(822.11835, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.450457, dtype=float32), 'eval/episode_x_position_std': Array(416.32663, dtype=float32), 'eval/episode_x_velocity_std': Array(164.42369, dtype=float32), 'eval/episode_y_position_std': Array(399.1942, dtype=float32), 'eval/episode_y_velocity_std': Array(123.23498, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35287523269653, 'eval/sps': 938.7407473554063, 'num_steps': 42352640}
{'eval/walltime': 70884.98199677467, 'training/sps': 2946.404558832584, 'training/walltime': 14431.713409900665, 'training/entropy_loss': Array(0.01788453, dtype=float32), 'training/policy_loss': Array(0.00531639, dtype=float32), 'training/total_loss': Array(0.22441556, dtype=float32), 'training/v_loss': Array(0.20121461, dtype=float32), 'eval/episode_distance_from_origin': Array(6760.9043, dtype=float32), 'eval/episode_distance_reward': Array(32.736004, dtype=float32), 'eval/episode_forward_reward': Array(5455.97, dtype=float32), 'eval/episode_reward': Array(5434.3135, dtype=float32), 'eval/episode_reward_alive': Array(361.5625, dtype=float32), 'eval/episode_reward_linvel': Array(5455.97, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.95572, dtype=float32), 'eval/episode_x_position': Array(6710.9487, dtype=float32), 'eval/episode_x_velocity': Array(1091.194, dtype=float32), 'eval/episode_y_position': Array(-142.3797, dtype=float32), 'eval/episode_y_velocity': Array(-165.6396, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.79205, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2541027, dtype=float32), 'eval/episode_forward_reward_std': Array(875.677, dtype=float32), 'eval/episode_reward_std': Array(872.2173, dtype=float32), 'eval/episode_reward_alive_std': Array(46.3289, dtype=float32), 'eval/episode_reward_linvel_std': Array(875.677, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.688562, dtype=float32), 'eval/episode_x_position_std': Array(478.0125, dtype=float32), 'eval/episode_x_velocity_std': Array(175.13539, dtype=float32), 'eval/episode_y_position_std': Array(312.1502, dtype=float32), 'eval/episode_y_velocity_std': Array(98.49319, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48043990135193, 'eval/sps': 937.8633311302222, 'num_steps': 42434560}
{'eval/walltime': 71021.23948740959, 'training/sps': 2939.5809675843025, 'training/walltime': 14459.581327438354, 'training/entropy_loss': Array(0.01557922, dtype=float32), 'training/policy_loss': Array(0.00923299, dtype=float32), 'training/total_loss': Array(0.20070635, dtype=float32), 'training/v_loss': Array(0.17589414, dtype=float32), 'eval/episode_distance_from_origin': Array(6781.49, dtype=float32), 'eval/episode_distance_reward': Array(33.083416, dtype=float32), 'eval/episode_forward_reward': Array(5513.871, dtype=float32), 'eval/episode_reward': Array(5493.9844, dtype=float32), 'eval/episode_reward_alive': Array(368.14062, dtype=float32), 'eval/episode_reward_linvel': Array(5513.871, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.11078, dtype=float32), 'eval/episode_x_position': Array(6729.1484, dtype=float32), 'eval/episode_x_velocity': Array(1102.7743, dtype=float32), 'eval/episode_y_position': Array(-87.14193, dtype=float32), 'eval/episode_y_velocity': Array(-150.86795, dtype=float32), 'eval/episode_distance_from_origin_std': Array(466.24222, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5201087, dtype=float32), 'eval/episode_forward_reward_std': Array(920.0119, dtype=float32), 'eval/episode_reward_std': Array(924.7974, dtype=float32), 'eval/episode_reward_alive_std': Array(43.28069, dtype=float32), 'eval/episode_reward_linvel_std': Array(920.0119, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.692228, dtype=float32), 'eval/episode_x_position_std': Array(470.35468, dtype=float32), 'eval/episode_x_velocity_std': Array(184.0023, dtype=float32), 'eval/episode_y_position_std': Array(377.81302, dtype=float32), 'eval/episode_y_velocity_std': Array(121.2383, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2574906349182, 'eval/sps': 939.3978958775709, 'num_steps': 42516480}
{'eval/walltime': 71157.68428945541, 'training/sps': 2934.737539751327, 'training/walltime': 14487.495237588882, 'training/entropy_loss': Array(0.0165088, dtype=float32), 'training/policy_loss': Array(0.01322692, dtype=float32), 'training/total_loss': Array(0.11009087, dtype=float32), 'training/v_loss': Array(0.08035515, dtype=float32), 'eval/episode_distance_from_origin': Array(6853.6963, dtype=float32), 'eval/episode_distance_reward': Array(33.708374, dtype=float32), 'eval/episode_forward_reward': Array(5618.031, dtype=float32), 'eval/episode_reward': Array(5604.668, dtype=float32), 'eval/episode_reward_alive': Array(369.27734, dtype=float32), 'eval/episode_reward_linvel': Array(5618.031, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.34827, dtype=float32), 'eval/episode_x_position': Array(6803.5674, dtype=float32), 'eval/episode_x_velocity': Array(1123.6061, dtype=float32), 'eval/episode_y_position': Array(-73.24814, dtype=float32), 'eval/episode_y_velocity': Array(-148.63483, dtype=float32), 'eval/episode_distance_from_origin_std': Array(440.99988, dtype=float32), 'eval/episode_distance_reward_std': Array(5.144619, dtype=float32), 'eval/episode_forward_reward_std': Array(857.4298, dtype=float32), 'eval/episode_reward_std': Array(852.69867, dtype=float32), 'eval/episode_reward_alive_std': Array(43.45507, dtype=float32), 'eval/episode_reward_linvel_std': Array(857.4298, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.983671, dtype=float32), 'eval/episode_x_position_std': Array(445.30765, dtype=float32), 'eval/episode_x_velocity_std': Array(171.48611, dtype=float32), 'eval/episode_y_position_std': Array(358.832, dtype=float32), 'eval/episode_y_velocity_std': Array(111.90937, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44480204582214, 'eval/sps': 938.1082905379852, 'num_steps': 42598400}
{'eval/walltime': 71293.95762777328, 'training/sps': 2936.2484310691634, 'training/walltime': 14515.394784212112, 'training/entropy_loss': Array(0.01862946, dtype=float32), 'training/policy_loss': Array(0.01687652, dtype=float32), 'training/total_loss': Array(0.21433336, dtype=float32), 'training/v_loss': Array(0.17882738, dtype=float32), 'eval/episode_distance_from_origin': Array(6825.6025, dtype=float32), 'eval/episode_distance_reward': Array(33.135483, dtype=float32), 'eval/episode_forward_reward': Array(5522.549, dtype=float32), 'eval/episode_reward': Array(5505.2295, dtype=float32), 'eval/episode_reward_alive': Array(367.32422, dtype=float32), 'eval/episode_reward_linvel': Array(5522.549, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.77844, dtype=float32), 'eval/episode_x_position': Array(6775.8613, dtype=float32), 'eval/episode_x_velocity': Array(1104.5098, dtype=float32), 'eval/episode_y_position': Array(-124.11018, dtype=float32), 'eval/episode_y_velocity': Array(-162.89111, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.95248, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8756833, dtype=float32), 'eval/episode_forward_reward_std': Array(812.6087, dtype=float32), 'eval/episode_reward_std': Array(807.41534, dtype=float32), 'eval/episode_reward_alive_std': Array(42.874023, dtype=float32), 'eval/episode_reward_linvel_std': Array(812.6087, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.150566, dtype=float32), 'eval/episode_x_position_std': Array(470.0689, dtype=float32), 'eval/episode_x_velocity_std': Array(162.52176, dtype=float32), 'eval/episode_y_position_std': Array(326.78165, dtype=float32), 'eval/episode_y_velocity_std': Array(92.81916, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2733383178711, 'eval/sps': 939.2886501497989, 'num_steps': 42680320}
{'eval/walltime': 71430.40439891815, 'training/sps': 2936.0795965276375, 'training/walltime': 14543.295935153961, 'training/entropy_loss': Array(0.01705075, dtype=float32), 'training/policy_loss': Array(0.00744568, dtype=float32), 'training/total_loss': Array(0.17342773, dtype=float32), 'training/v_loss': Array(0.1489313, dtype=float32), 'eval/episode_distance_from_origin': Array(6783.831, dtype=float32), 'eval/episode_distance_reward': Array(33.096397, dtype=float32), 'eval/episode_forward_reward': Array(5516.035, dtype=float32), 'eval/episode_reward': Array(5501.953, dtype=float32), 'eval/episode_reward_alive': Array(372.53906, dtype=float32), 'eval/episode_reward_linvel': Array(5516.035, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.71783, dtype=float32), 'eval/episode_x_position': Array(6734.4414, dtype=float32), 'eval/episode_x_velocity': Array(1103.207, dtype=float32), 'eval/episode_y_position': Array(-99.942764, dtype=float32), 'eval/episode_y_velocity': Array(-164.83041, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.39734, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3415847, dtype=float32), 'eval/episode_forward_reward_std': Array(890.25854, dtype=float32), 'eval/episode_reward_std': Array(884.9092, dtype=float32), 'eval/episode_reward_alive_std': Array(43.16124, dtype=float32), 'eval/episode_reward_linvel_std': Array(890.25854, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.446726, dtype=float32), 'eval/episode_x_position_std': Array(474.95056, dtype=float32), 'eval/episode_x_velocity_std': Array(178.05167, dtype=float32), 'eval/episode_y_position_std': Array(310.10458, dtype=float32), 'eval/episode_y_velocity_std': Array(94.89541, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44677114486694, 'eval/sps': 938.0947524518633, 'num_steps': 42762240}
{'eval/walltime': 71566.65401768684, 'training/sps': 2938.0066779450726, 'training/walltime': 14571.178785324097, 'training/entropy_loss': Array(0.01852725, dtype=float32), 'training/policy_loss': Array(0.00893951, dtype=float32), 'training/total_loss': Array(0.22214988, dtype=float32), 'training/v_loss': Array(0.19468312, dtype=float32), 'eval/episode_distance_from_origin': Array(6806.903, dtype=float32), 'eval/episode_distance_reward': Array(33.461155, dtype=float32), 'eval/episode_forward_reward': Array(5576.827, dtype=float32), 'eval/episode_reward': Array(5571.6426, dtype=float32), 'eval/episode_reward_alive': Array(381.7539, dtype=float32), 'eval/episode_reward_linvel': Array(5576.827, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.39996, dtype=float32), 'eval/episode_x_position': Array(6759.1826, dtype=float32), 'eval/episode_x_velocity': Array(1115.3655, dtype=float32), 'eval/episode_y_position': Array(-24.020826, dtype=float32), 'eval/episode_y_velocity': Array(-143.40701, dtype=float32), 'eval/episode_distance_from_origin_std': Array(397.53223, dtype=float32), 'eval/episode_distance_reward_std': Array(4.865549, dtype=float32), 'eval/episode_forward_reward_std': Array(810.91907, dtype=float32), 'eval/episode_reward_std': Array(813.9452, dtype=float32), 'eval/episode_reward_alive_std': Array(41.426327, dtype=float32), 'eval/episode_reward_linvel_std': Array(810.91907, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.743755, dtype=float32), 'eval/episode_x_position_std': Array(400.1275, dtype=float32), 'eval/episode_x_velocity_std': Array(162.18379, dtype=float32), 'eval/episode_y_position_std': Array(318.30612, dtype=float32), 'eval/episode_y_velocity_std': Array(93.746925, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24961876869202, 'eval/sps': 939.4521698978314, 'num_steps': 42844160}
{'eval/walltime': 71703.17320990562, 'training/sps': 2938.7953211490544, 'training/walltime': 14599.054152965546, 'training/entropy_loss': Array(0.01881269, dtype=float32), 'training/policy_loss': Array(0.00794522, dtype=float32), 'training/total_loss': Array(0.2688731, dtype=float32), 'training/v_loss': Array(0.2421152, dtype=float32), 'eval/episode_distance_from_origin': Array(6858.3193, dtype=float32), 'eval/episode_distance_reward': Array(33.648598, dtype=float32), 'eval/episode_forward_reward': Array(5608.0674, dtype=float32), 'eval/episode_reward': Array(5603.2725, dtype=float32), 'eval/episode_reward_alive': Array(382.21094, dtype=float32), 'eval/episode_reward_linvel': Array(5608.0674, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.6549, dtype=float32), 'eval/episode_x_position': Array(6809.309, dtype=float32), 'eval/episode_x_velocity': Array(1121.6135, dtype=float32), 'eval/episode_y_position': Array(-64.60624, dtype=float32), 'eval/episode_y_velocity': Array(-150.68208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(426.9143, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1310506, dtype=float32), 'eval/episode_forward_reward_std': Array(855.16956, dtype=float32), 'eval/episode_reward_std': Array(861.39246, dtype=float32), 'eval/episode_reward_alive_std': Array(37.80075, dtype=float32), 'eval/episode_reward_linvel_std': Array(855.16956, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.392683, dtype=float32), 'eval/episode_x_position_std': Array(428.2831, dtype=float32), 'eval/episode_x_velocity_std': Array(171.03392, dtype=float32), 'eval/episode_y_position_std': Array(341.21292, dtype=float32), 'eval/episode_y_velocity_std': Array(104.76178, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51919221878052, 'eval/sps': 937.5971093857047, 'num_steps': 42926080}
{'eval/walltime': 71839.49848818779, 'training/sps': 2943.555628960343, 'training/walltime': 14626.884440660477, 'training/entropy_loss': Array(0.01892176, dtype=float32), 'training/policy_loss': Array(0.00720054, dtype=float32), 'training/total_loss': Array(0.26673657, dtype=float32), 'training/v_loss': Array(0.24061428, dtype=float32), 'eval/episode_distance_from_origin': Array(6796.2656, dtype=float32), 'eval/episode_distance_reward': Array(33.29435, dtype=float32), 'eval/episode_forward_reward': Array(5549.028, dtype=float32), 'eval/episode_reward': Array(5535.388, dtype=float32), 'eval/episode_reward_alive': Array(373.5, dtype=float32), 'eval/episode_reward_linvel': Array(5549.028, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.4332, dtype=float32), 'eval/episode_x_position': Array(6744.888, dtype=float32), 'eval/episode_x_velocity': Array(1109.8055, dtype=float32), 'eval/episode_y_position': Array(-159.9236, dtype=float32), 'eval/episode_y_velocity': Array(-170.58983, dtype=float32), 'eval/episode_distance_from_origin_std': Array(434.2634, dtype=float32), 'eval/episode_distance_reward_std': Array(5.313188, dtype=float32), 'eval/episode_forward_reward_std': Array(885.5257, dtype=float32), 'eval/episode_reward_std': Array(882.24915, dtype=float32), 'eval/episode_reward_alive_std': Array(42.084225, dtype=float32), 'eval/episode_reward_linvel_std': Array(885.5257, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.721601, dtype=float32), 'eval/episode_x_position_std': Array(436.97745, dtype=float32), 'eval/episode_x_velocity_std': Array(177.1052, dtype=float32), 'eval/episode_y_position_std': Array(342.72223, dtype=float32), 'eval/episode_y_velocity_std': Array(108.6501, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32527828216553, 'eval/sps': 938.930780944867, 'num_steps': 43008000}
{'eval/walltime': 71976.01022386551, 'training/sps': 2933.6093925188925, 'training/walltime': 14654.80908536911, 'training/entropy_loss': Array(0.0154911, dtype=float32), 'training/policy_loss': Array(0.00561392, dtype=float32), 'training/total_loss': Array(0.07307017, dtype=float32), 'training/v_loss': Array(0.05196515, dtype=float32), 'eval/episode_distance_from_origin': Array(6820.676, dtype=float32), 'eval/episode_distance_reward': Array(33.081398, dtype=float32), 'eval/episode_forward_reward': Array(5513.535, dtype=float32), 'eval/episode_reward': Array(5504.8125, dtype=float32), 'eval/episode_reward_alive': Array(380.83594, dtype=float32), 'eval/episode_reward_linvel': Array(5513.535, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.63928, dtype=float32), 'eval/episode_x_position': Array(6770.8564, dtype=float32), 'eval/episode_x_velocity': Array(1102.707, dtype=float32), 'eval/episode_y_position': Array(-79.766884, dtype=float32), 'eval/episode_y_velocity': Array(-140.44974, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.89258, dtype=float32), 'eval/episode_distance_reward_std': Array(5.431994, dtype=float32), 'eval/episode_forward_reward_std': Array(905.32654, dtype=float32), 'eval/episode_reward_std': Array(906.45337, dtype=float32), 'eval/episode_reward_alive_std': Array(44.521328, dtype=float32), 'eval/episode_reward_linvel_std': Array(905.32654, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.703474, dtype=float32), 'eval/episode_x_position_std': Array(471.0652, dtype=float32), 'eval/episode_x_velocity_std': Array(181.06528, dtype=float32), 'eval/episode_y_position_std': Array(375.00458, dtype=float32), 'eval/episode_y_velocity_std': Array(116.3336, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51173567771912, 'eval/sps': 937.6483227946507, 'num_steps': 43089920}
{'eval/walltime': 72112.35587310791, 'training/sps': 2938.0466477286627, 'training/walltime': 14682.691556215286, 'training/entropy_loss': Array(0.01767994, dtype=float32), 'training/policy_loss': Array(0.01244783, dtype=float32), 'training/total_loss': Array(0.195002, dtype=float32), 'training/v_loss': Array(0.16487424, dtype=float32), 'eval/episode_distance_from_origin': Array(6782.998, dtype=float32), 'eval/episode_distance_reward': Array(32.887638, dtype=float32), 'eval/episode_forward_reward': Array(5481.2417, dtype=float32), 'eval/episode_reward': Array(5464.2466, dtype=float32), 'eval/episode_reward_alive': Array(371.89844, dtype=float32), 'eval/episode_reward_linvel': Array(5481.2417, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.781, dtype=float32), 'eval/episode_x_position': Array(6731.94, dtype=float32), 'eval/episode_x_velocity': Array(1096.2483, dtype=float32), 'eval/episode_y_position': Array(-123.5293, dtype=float32), 'eval/episode_y_velocity': Array(-160.62817, dtype=float32), 'eval/episode_distance_from_origin_std': Array(463.83365, dtype=float32), 'eval/episode_distance_reward_std': Array(5.535873, dtype=float32), 'eval/episode_forward_reward_std': Array(922.63904, dtype=float32), 'eval/episode_reward_std': Array(926.49176, dtype=float32), 'eval/episode_reward_alive_std': Array(44.496635, dtype=float32), 'eval/episode_reward_linvel_std': Array(922.63904, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.230429, dtype=float32), 'eval/episode_x_position_std': Array(465.75464, dtype=float32), 'eval/episode_x_velocity_std': Array(184.52774, dtype=float32), 'eval/episode_y_position_std': Array(353.1282, dtype=float32), 'eval/episode_y_velocity_std': Array(111.83598, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34564924240112, 'eval/sps': 938.7904983490608, 'num_steps': 43171840}
{'eval/walltime': 72249.05344724655, 'training/sps': 2939.8138659276215, 'training/walltime': 14710.557265996933, 'training/entropy_loss': Array(0.01686181, dtype=float32), 'training/policy_loss': Array(0.01006677, dtype=float32), 'training/total_loss': Array(0.1586889, dtype=float32), 'training/v_loss': Array(0.1317603, dtype=float32), 'eval/episode_distance_from_origin': Array(6795.83, dtype=float32), 'eval/episode_distance_reward': Array(32.74954, dtype=float32), 'eval/episode_forward_reward': Array(5458.2236, dtype=float32), 'eval/episode_reward': Array(5450.2485, dtype=float32), 'eval/episode_reward_alive': Array(381.375, dtype=float32), 'eval/episode_reward_linvel': Array(5458.2236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.1003, dtype=float32), 'eval/episode_x_position': Array(6742.284, dtype=float32), 'eval/episode_x_velocity': Array(1091.6449, dtype=float32), 'eval/episode_y_position': Array(-184.79866, dtype=float32), 'eval/episode_y_velocity': Array(-176.63284, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.4168, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0070124, dtype=float32), 'eval/episode_forward_reward_std': Array(834.49603, dtype=float32), 'eval/episode_reward_std': Array(832.13855, dtype=float32), 'eval/episode_reward_alive_std': Array(39.812008, dtype=float32), 'eval/episode_reward_linvel_std': Array(834.49603, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.778267, dtype=float32), 'eval/episode_x_position_std': Array(437.5025, dtype=float32), 'eval/episode_x_velocity_std': Array(166.89932, dtype=float32), 'eval/episode_y_position_std': Array(342.12344, dtype=float32), 'eval/episode_y_velocity_std': Array(96.69499, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69757413864136, 'eval/sps': 936.3736028715468, 'num_steps': 43253760}
{'eval/walltime': 72385.39265561104, 'training/sps': 2941.0260611045614, 'training/walltime': 14738.411490440369, 'training/entropy_loss': Array(0.01717985, dtype=float32), 'training/policy_loss': Array(0.00745779, dtype=float32), 'training/total_loss': Array(0.1946145, dtype=float32), 'training/v_loss': Array(0.16997686, dtype=float32), 'eval/episode_distance_from_origin': Array(6920.536, dtype=float32), 'eval/episode_distance_reward': Array(33.85684, dtype=float32), 'eval/episode_forward_reward': Array(5642.7744, dtype=float32), 'eval/episode_reward': Array(5625.196, dtype=float32), 'eval/episode_reward_alive': Array(370.15234, dtype=float32), 'eval/episode_reward_linvel': Array(5642.7744, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.58826, dtype=float32), 'eval/episode_x_position': Array(6869.8545, dtype=float32), 'eval/episode_x_velocity': Array(1128.5549, dtype=float32), 'eval/episode_y_position': Array(-195.70177, dtype=float32), 'eval/episode_y_velocity': Array(-173.40768, dtype=float32), 'eval/episode_distance_from_origin_std': Array(398.4287, dtype=float32), 'eval/episode_distance_reward_std': Array(4.502584, dtype=float32), 'eval/episode_forward_reward_std': Array(750.42554, dtype=float32), 'eval/episode_reward_std': Array(756.6154, dtype=float32), 'eval/episode_reward_alive_std': Array(43.782425, dtype=float32), 'eval/episode_reward_linvel_std': Array(750.42554, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.162071, dtype=float32), 'eval/episode_x_position_std': Array(400.50446, dtype=float32), 'eval/episode_x_velocity_std': Array(150.08513, dtype=float32), 'eval/episode_y_position_std': Array(309.68542, dtype=float32), 'eval/episode_y_velocity_std': Array(88.43527, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3392083644867, 'eval/sps': 938.8348482837541, 'num_steps': 43335680}
{'eval/walltime': 72521.97185897827, 'training/sps': 2949.7173300243135, 'training/walltime': 14766.183643102646, 'training/entropy_loss': Array(0.01700895, dtype=float32), 'training/policy_loss': Array(0.00692943, dtype=float32), 'training/total_loss': Array(0.23513944, dtype=float32), 'training/v_loss': Array(0.21120104, dtype=float32), 'eval/episode_distance_from_origin': Array(6860.2334, dtype=float32), 'eval/episode_distance_reward': Array(33.631104, dtype=float32), 'eval/episode_forward_reward': Array(5605.1523, dtype=float32), 'eval/episode_reward': Array(5589.8735, dtype=float32), 'eval/episode_reward_alive': Array(372.96094, dtype=float32), 'eval/episode_reward_linvel': Array(5605.1523, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.87094, dtype=float32), 'eval/episode_x_position': Array(6809.47, dtype=float32), 'eval/episode_x_velocity': Array(1121.0305, dtype=float32), 'eval/episode_y_position': Array(-117.18348, dtype=float32), 'eval/episode_y_velocity': Array(-161.89478, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.36865, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4918456, dtype=float32), 'eval/episode_forward_reward_std': Array(748.6353, dtype=float32), 'eval/episode_reward_std': Array(748.2102, dtype=float32), 'eval/episode_reward_alive_std': Array(38.294327, dtype=float32), 'eval/episode_reward_linvel_std': Array(748.6353, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.150581, dtype=float32), 'eval/episode_x_position_std': Array(420.89716, dtype=float32), 'eval/episode_x_velocity_std': Array(149.72707, dtype=float32), 'eval/episode_y_position_std': Array(345.08502, dtype=float32), 'eval/episode_y_velocity_std': Array(109.11028, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57920336723328, 'eval/sps': 937.1851412534193, 'num_steps': 43417600}
{'eval/walltime': 72658.24436807632, 'training/sps': 2949.663545473646, 'training/walltime': 14793.956302165985, 'training/entropy_loss': Array(0.01716684, dtype=float32), 'training/policy_loss': Array(0.01057972, dtype=float32), 'training/total_loss': Array(0.26622534, dtype=float32), 'training/v_loss': Array(0.23847876, dtype=float32), 'eval/episode_distance_from_origin': Array(6834.5654, dtype=float32), 'eval/episode_distance_reward': Array(33.11271, dtype=float32), 'eval/episode_forward_reward': Array(5518.753, dtype=float32), 'eval/episode_reward': Array(5509.286, dtype=float32), 'eval/episode_reward_alive': Array(384.26562, dtype=float32), 'eval/episode_reward_linvel': Array(5518.753, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.84528, dtype=float32), 'eval/episode_x_position': Array(6782.095, dtype=float32), 'eval/episode_x_velocity': Array(1103.7507, dtype=float32), 'eval/episode_y_position': Array(-165.13141, dtype=float32), 'eval/episode_y_velocity': Array(-167.08214, dtype=float32), 'eval/episode_distance_from_origin_std': Array(499.71503, dtype=float32), 'eval/episode_distance_reward_std': Array(5.980169, dtype=float32), 'eval/episode_forward_reward_std': Array(996.6884, dtype=float32), 'eval/episode_reward_std': Array(997.1484, dtype=float32), 'eval/episode_reward_alive_std': Array(43.058365, dtype=float32), 'eval/episode_reward_linvel_std': Array(996.6884, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.338165, dtype=float32), 'eval/episode_x_position_std': Array(500.6695, dtype=float32), 'eval/episode_x_velocity_std': Array(199.33763, dtype=float32), 'eval/episode_y_position_std': Array(358.31052, dtype=float32), 'eval/episode_y_velocity_std': Array(102.89266, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27250909805298, 'eval/sps': 939.2943657322651, 'num_steps': 43499520}
{'eval/walltime': 72794.7015838623, 'training/sps': 2954.832594817353, 'training/walltime': 14821.68037700653, 'training/entropy_loss': Array(0.01322937, dtype=float32), 'training/policy_loss': Array(0.00500225, dtype=float32), 'training/total_loss': Array(0.10194721, dtype=float32), 'training/v_loss': Array(0.08371559, dtype=float32), 'eval/episode_distance_from_origin': Array(6807.847, dtype=float32), 'eval/episode_distance_reward': Array(33.21027, dtype=float32), 'eval/episode_forward_reward': Array(5535.0137, dtype=float32), 'eval/episode_reward': Array(5517.6772, dtype=float32), 'eval/episode_reward_alive': Array(372.2461, dtype=float32), 'eval/episode_reward_linvel': Array(5535.0137, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.79294, dtype=float32), 'eval/episode_x_position': Array(6758.3467, dtype=float32), 'eval/episode_x_velocity': Array(1107.0027, dtype=float32), 'eval/episode_y_position': Array(-186.108, dtype=float32), 'eval/episode_y_velocity': Array(-172.15057, dtype=float32), 'eval/episode_distance_from_origin_std': Array(499.04102, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5322356, dtype=float32), 'eval/episode_forward_reward_std': Array(922.0351, dtype=float32), 'eval/episode_reward_std': Array(920.4354, dtype=float32), 'eval/episode_reward_alive_std': Array(45.88543, dtype=float32), 'eval/episode_reward_linvel_std': Array(922.0351, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.031635, dtype=float32), 'eval/episode_x_position_std': Array(500.02588, dtype=float32), 'eval/episode_x_velocity_std': Array(184.407, dtype=float32), 'eval/episode_y_position_std': Array(306.2001, dtype=float32), 'eval/episode_y_velocity_std': Array(83.129456, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45721578598022, 'eval/sps': 938.022949264592, 'num_steps': 43581440}
{'eval/walltime': 72930.95168590546, 'training/sps': 2962.574489937314, 'training/walltime': 14849.332002401352, 'training/entropy_loss': Array(0.01923677, dtype=float32), 'training/policy_loss': Array(0.01067563, dtype=float32), 'training/total_loss': Array(0.14373054, dtype=float32), 'training/v_loss': Array(0.11381814, dtype=float32), 'eval/episode_distance_from_origin': Array(6824.733, dtype=float32), 'eval/episode_distance_reward': Array(32.740013, dtype=float32), 'eval/episode_forward_reward': Array(5456.639, dtype=float32), 'eval/episode_reward': Array(5442.3555, dtype=float32), 'eval/episode_reward_alive': Array(378.32422, dtype=float32), 'eval/episode_reward_linvel': Array(5456.639, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.3473, dtype=float32), 'eval/episode_x_position': Array(6773.0083, dtype=float32), 'eval/episode_x_velocity': Array(1091.3275, dtype=float32), 'eval/episode_y_position': Array(-125.53465, dtype=float32), 'eval/episode_y_velocity': Array(-155.65541, dtype=float32), 'eval/episode_distance_from_origin_std': Array(504.376, dtype=float32), 'eval/episode_distance_reward_std': Array(5.748361, dtype=float32), 'eval/episode_forward_reward_std': Array(958.0538, dtype=float32), 'eval/episode_reward_std': Array(967.12665, dtype=float32), 'eval/episode_reward_alive_std': Array(47.19986, dtype=float32), 'eval/episode_reward_linvel_std': Array(958.0538, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.12834, dtype=float32), 'eval/episode_x_position_std': Array(505.9392, dtype=float32), 'eval/episode_x_velocity_std': Array(191.61078, dtype=float32), 'eval/episode_y_position_std': Array(372.96436, dtype=float32), 'eval/episode_y_velocity_std': Array(114.8557, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25010204315186, 'eval/sps': 939.4488376930613, 'num_steps': 43663360}
{'eval/walltime': 73067.39552617073, 'training/sps': 2946.370905027761, 'training/walltime': 14877.135698080063, 'training/entropy_loss': Array(0.01735236, dtype=float32), 'training/policy_loss': Array(0.01902046, dtype=float32), 'training/total_loss': Array(0.21862347, dtype=float32), 'training/v_loss': Array(0.18225065, dtype=float32), 'eval/episode_distance_from_origin': Array(6781.067, dtype=float32), 'eval/episode_distance_reward': Array(32.955067, dtype=float32), 'eval/episode_forward_reward': Array(5492.4795, dtype=float32), 'eval/episode_reward': Array(5490.399, dtype=float32), 'eval/episode_reward_alive': Array(388.11328, dtype=float32), 'eval/episode_reward_linvel': Array(5492.4795, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.1485, dtype=float32), 'eval/episode_x_position': Array(6726.9775, dtype=float32), 'eval/episode_x_velocity': Array(1098.4958, dtype=float32), 'eval/episode_y_position': Array(-192.89143, dtype=float32), 'eval/episode_y_velocity': Array(-173.31543, dtype=float32), 'eval/episode_distance_from_origin_std': Array(475.8251, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2093287, dtype=float32), 'eval/episode_forward_reward_std': Array(868.2158, dtype=float32), 'eval/episode_reward_std': Array(869.0009, dtype=float32), 'eval/episode_reward_alive_std': Array(38.359077, dtype=float32), 'eval/episode_reward_linvel_std': Array(868.2158, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.684404, dtype=float32), 'eval/episode_x_position_std': Array(476.13077, dtype=float32), 'eval/episode_x_velocity_std': Array(173.64311, dtype=float32), 'eval/episode_y_position_std': Array(353.9267, dtype=float32), 'eval/episode_y_velocity_std': Array(116.071526, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44384026527405, 'eval/sps': 938.1149031802569, 'num_steps': 43745280}
{'eval/walltime': 73203.65354990959, 'training/sps': 2955.82167990759, 'training/walltime': 14904.850495815277, 'training/entropy_loss': Array(0.01781111, dtype=float32), 'training/policy_loss': Array(0.00740927, dtype=float32), 'training/total_loss': Array(0.22729489, dtype=float32), 'training/v_loss': Array(0.20207453, dtype=float32), 'eval/episode_distance_from_origin': Array(6878.325, dtype=float32), 'eval/episode_distance_reward': Array(33.698967, dtype=float32), 'eval/episode_forward_reward': Array(5616.463, dtype=float32), 'eval/episode_reward': Array(5608.9854, dtype=float32), 'eval/episode_reward_alive': Array(384.26953, dtype=float32), 'eval/episode_reward_linvel': Array(5616.463, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.4458, dtype=float32), 'eval/episode_x_position': Array(6828.093, dtype=float32), 'eval/episode_x_velocity': Array(1123.2927, dtype=float32), 'eval/episode_y_position': Array(-162.91168, dtype=float32), 'eval/episode_y_velocity': Array(-156.28226, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.06363, dtype=float32), 'eval/episode_distance_reward_std': Array(5.032731, dtype=float32), 'eval/episode_forward_reward_std': Array(838.7833, dtype=float32), 'eval/episode_reward_std': Array(835.18317, dtype=float32), 'eval/episode_reward_alive_std': Array(44.384106, dtype=float32), 'eval/episode_reward_linvel_std': Array(838.7833, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.253866, dtype=float32), 'eval/episode_x_position_std': Array(437.94934, dtype=float32), 'eval/episode_x_velocity_std': Array(167.75667, dtype=float32), 'eval/episode_y_position_std': Array(335.97214, dtype=float32), 'eval/episode_y_velocity_std': Array(113.62302, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25802373886108, 'eval/sps': 939.3942205217389, 'num_steps': 43827200}
{'eval/walltime': 73340.20080947876, 'training/sps': 2927.2837306780657, 'training/walltime': 14932.835483789444, 'training/entropy_loss': Array(0.01761175, dtype=float32), 'training/policy_loss': Array(0.00784153, dtype=float32), 'training/total_loss': Array(0.23265897, dtype=float32), 'training/v_loss': Array(0.20720568, dtype=float32), 'eval/episode_distance_from_origin': Array(6893.7383, dtype=float32), 'eval/episode_distance_reward': Array(33.808754, dtype=float32), 'eval/episode_forward_reward': Array(5634.7603, dtype=float32), 'eval/episode_reward': Array(5630.426, dtype=float32), 'eval/episode_reward_alive': Array(385.0664, dtype=float32), 'eval/episode_reward_linvel': Array(5634.7603, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.20987, dtype=float32), 'eval/episode_x_position': Array(6840.8984, dtype=float32), 'eval/episode_x_velocity': Array(1126.9521, dtype=float32), 'eval/episode_y_position': Array(-172.80832, dtype=float32), 'eval/episode_y_velocity': Array(-161.25357, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.41614, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6623883, dtype=float32), 'eval/episode_forward_reward_std': Array(943.7249, dtype=float32), 'eval/episode_reward_std': Array(953.5235, dtype=float32), 'eval/episode_reward_alive_std': Array(34.48847, dtype=float32), 'eval/episode_reward_linvel_std': Array(943.7249, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.945257, dtype=float32), 'eval/episode_x_position_std': Array(487.6301, dtype=float32), 'eval/episode_x_velocity_std': Array(188.74506, dtype=float32), 'eval/episode_y_position_std': Array(366.05, dtype=float32), 'eval/episode_y_velocity_std': Array(118.06764, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5472595691681, 'eval/sps': 937.4043858797586, 'num_steps': 43909120}
{'eval/walltime': 73476.55319356918, 'training/sps': 2934.4908337799156, 'training/walltime': 14960.751740694046, 'training/entropy_loss': Array(0.01805722, dtype=float32), 'training/policy_loss': Array(0.00768741, dtype=float32), 'training/total_loss': Array(0.25680354, dtype=float32), 'training/v_loss': Array(0.23105891, dtype=float32), 'eval/episode_distance_from_origin': Array(6855.0806, dtype=float32), 'eval/episode_distance_reward': Array(33.396408, dtype=float32), 'eval/episode_forward_reward': Array(5566.036, dtype=float32), 'eval/episode_reward': Array(5555.126, dtype=float32), 'eval/episode_reward_alive': Array(381.07812, dtype=float32), 'eval/episode_reward_linvel': Array(5566.036, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.38446, dtype=float32), 'eval/episode_x_position': Array(6802.447, dtype=float32), 'eval/episode_x_velocity': Array(1113.2073, dtype=float32), 'eval/episode_y_position': Array(-155.04138, dtype=float32), 'eval/episode_y_velocity': Array(-165.51395, dtype=float32), 'eval/episode_distance_from_origin_std': Array(444.07727, dtype=float32), 'eval/episode_distance_reward_std': Array(4.943363, dtype=float32), 'eval/episode_forward_reward_std': Array(823.8884, dtype=float32), 'eval/episode_reward_std': Array(824.7448, dtype=float32), 'eval/episode_reward_alive_std': Array(39.059822, dtype=float32), 'eval/episode_reward_linvel_std': Array(823.8884, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.534113, dtype=float32), 'eval/episode_x_position_std': Array(445.81018, dtype=float32), 'eval/episode_x_velocity_std': Array(164.77774, dtype=float32), 'eval/episode_y_position_std': Array(365.3714, dtype=float32), 'eval/episode_y_velocity_std': Array(118.72137, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35238409042358, 'eval/sps': 938.7441287063627, 'num_steps': 43991040}
{'eval/walltime': 73613.11923480034, 'training/sps': 2930.972493330238, 'training/walltime': 14988.701508283615, 'training/entropy_loss': Array(0.01465194, dtype=float32), 'training/policy_loss': Array(0.00557521, dtype=float32), 'training/total_loss': Array(0.15866432, dtype=float32), 'training/v_loss': Array(0.13843715, dtype=float32), 'eval/episode_distance_from_origin': Array(6781.374, dtype=float32), 'eval/episode_distance_reward': Array(32.501125, dtype=float32), 'eval/episode_forward_reward': Array(5416.823, dtype=float32), 'eval/episode_reward': Array(5399.559, dtype=float32), 'eval/episode_reward_alive': Array(382.26562, dtype=float32), 'eval/episode_reward_linvel': Array(5416.823, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.03214, dtype=float32), 'eval/episode_x_position': Array(6728.977, dtype=float32), 'eval/episode_x_velocity': Array(1083.3649, dtype=float32), 'eval/episode_y_position': Array(-103.45567, dtype=float32), 'eval/episode_y_velocity': Array(-154.15839, dtype=float32), 'eval/episode_distance_from_origin_std': Array(577.4953, dtype=float32), 'eval/episode_distance_reward_std': Array(6.591901, dtype=float32), 'eval/episode_forward_reward_std': Array(1098.6423, dtype=float32), 'eval/episode_reward_std': Array(1099.6819, dtype=float32), 'eval/episode_reward_alive_std': Array(44.661877, dtype=float32), 'eval/episode_reward_linvel_std': Array(1098.6423, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.19007, dtype=float32), 'eval/episode_x_position_std': Array(579.85376, dtype=float32), 'eval/episode_x_velocity_std': Array(219.72856, dtype=float32), 'eval/episode_y_position_std': Array(384.4472, dtype=float32), 'eval/episode_y_velocity_std': Array(122.49774, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5660412311554, 'eval/sps': 937.2754664781102, 'num_steps': 44072960}
{'eval/walltime': 73749.52145910263, 'training/sps': 2946.5737237973444, 'training/walltime': 15016.503290176392, 'training/entropy_loss': Array(0.0192796, dtype=float32), 'training/policy_loss': Array(0.01478373, dtype=float32), 'training/total_loss': Array(0.14466682, dtype=float32), 'training/v_loss': Array(0.1106035, dtype=float32), 'eval/episode_distance_from_origin': Array(6832.9385, dtype=float32), 'eval/episode_distance_reward': Array(33.33285, dtype=float32), 'eval/episode_forward_reward': Array(5555.4424, dtype=float32), 'eval/episode_reward': Array(5546.0215, dtype=float32), 'eval/episode_reward_alive': Array(384.26172, dtype=float32), 'eval/episode_reward_linvel': Array(5555.4424, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.01535, dtype=float32), 'eval/episode_x_position': Array(6781.054, dtype=float32), 'eval/episode_x_velocity': Array(1111.0884, dtype=float32), 'eval/episode_y_position': Array(-132.51393, dtype=float32), 'eval/episode_y_velocity': Array(-159.4282, dtype=float32), 'eval/episode_distance_from_origin_std': Array(459.45322, dtype=float32), 'eval/episode_distance_reward_std': Array(5.241874, dtype=float32), 'eval/episode_forward_reward_std': Array(873.6406, dtype=float32), 'eval/episode_reward_std': Array(876.5315, dtype=float32), 'eval/episode_reward_alive_std': Array(41.414677, dtype=float32), 'eval/episode_reward_linvel_std': Array(873.6406, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.12112, dtype=float32), 'eval/episode_x_position_std': Array(461.2146, dtype=float32), 'eval/episode_x_velocity_std': Array(174.72807, dtype=float32), 'eval/episode_y_position_std': Array(365.1691, dtype=float32), 'eval/episode_y_velocity_std': Array(125.85588, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40222430229187, 'eval/sps': 938.401119591195, 'num_steps': 44154880}
{'eval/walltime': 73886.04827165604, 'training/sps': 2929.0110798189303, 'training/walltime': 15044.471774339676, 'training/entropy_loss': Array(0.01715347, dtype=float32), 'training/policy_loss': Array(0.01200883, dtype=float32), 'training/total_loss': Array(0.19646728, dtype=float32), 'training/v_loss': Array(0.167305, dtype=float32), 'eval/episode_distance_from_origin': Array(6913.414, dtype=float32), 'eval/episode_distance_reward': Array(33.6547, dtype=float32), 'eval/episode_forward_reward': Array(5609.085, dtype=float32), 'eval/episode_reward': Array(5594.743, dtype=float32), 'eval/episode_reward_alive': Array(375.96484, dtype=float32), 'eval/episode_reward_linvel': Array(5609.085, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.96136, dtype=float32), 'eval/episode_x_position': Array(6858.712, dtype=float32), 'eval/episode_x_velocity': Array(1121.8169, dtype=float32), 'eval/episode_y_position': Array(-176.36938, dtype=float32), 'eval/episode_y_velocity': Array(-176.34756, dtype=float32), 'eval/episode_distance_from_origin_std': Array(469.4583, dtype=float32), 'eval/episode_distance_reward_std': Array(5.263724, dtype=float32), 'eval/episode_forward_reward_std': Array(877.2819, dtype=float32), 'eval/episode_reward_std': Array(882.24097, dtype=float32), 'eval/episode_reward_alive_std': Array(43.932972, dtype=float32), 'eval/episode_reward_linvel_std': Array(877.2819, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.870766, dtype=float32), 'eval/episode_x_position_std': Array(474.56845, dtype=float32), 'eval/episode_x_velocity_std': Array(175.45624, dtype=float32), 'eval/episode_y_position_std': Array(364.55606, dtype=float32), 'eval/episode_y_velocity_std': Array(111.736275, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52681255340576, 'eval/sps': 937.544776780969, 'num_steps': 44236800}
{'eval/walltime': 74022.33138895035, 'training/sps': 2943.4529990583533, 'training/walltime': 15072.303032398224, 'training/entropy_loss': Array(0.01762202, dtype=float32), 'training/policy_loss': Array(0.00593951, dtype=float32), 'training/total_loss': Array(0.16367976, dtype=float32), 'training/v_loss': Array(0.14011824, dtype=float32), 'eval/episode_distance_from_origin': Array(6888.223, dtype=float32), 'eval/episode_distance_reward': Array(33.34214, dtype=float32), 'eval/episode_forward_reward': Array(5556.9917, dtype=float32), 'eval/episode_reward': Array(5539.301, dtype=float32), 'eval/episode_reward_alive': Array(378.72266, dtype=float32), 'eval/episode_reward_linvel': Array(5556.9917, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.75626, dtype=float32), 'eval/episode_x_position': Array(6835.0103, dtype=float32), 'eval/episode_x_velocity': Array(1111.3982, dtype=float32), 'eval/episode_y_position': Array(-207.35596, dtype=float32), 'eval/episode_y_velocity': Array(-178.87807, dtype=float32), 'eval/episode_distance_from_origin_std': Array(469.54834, dtype=float32), 'eval/episode_distance_reward_std': Array(5.233028, dtype=float32), 'eval/episode_forward_reward_std': Array(872.16565, dtype=float32), 'eval/episode_reward_std': Array(874.4888, dtype=float32), 'eval/episode_reward_alive_std': Array(39.89918, dtype=float32), 'eval/episode_reward_linvel_std': Array(872.16565, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.11036, dtype=float32), 'eval/episode_x_position_std': Array(470.94174, dtype=float32), 'eval/episode_x_velocity_std': Array(174.4332, dtype=float32), 'eval/episode_y_position_std': Array(331.56558, dtype=float32), 'eval/episode_y_velocity_std': Array(92.746216, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28311729431152, 'eval/sps': 939.2212516211847, 'num_steps': 44318720}
{'eval/walltime': 74158.78857588768, 'training/sps': 2930.147611659088, 'training/walltime': 15100.26066827774, 'training/entropy_loss': Array(0.01730885, dtype=float32), 'training/policy_loss': Array(0.00842612, dtype=float32), 'training/total_loss': Array(0.21824354, dtype=float32), 'training/v_loss': Array(0.19250856, dtype=float32), 'eval/episode_distance_from_origin': Array(6804.263, dtype=float32), 'eval/episode_distance_reward': Array(33.026543, dtype=float32), 'eval/episode_forward_reward': Array(5504.3916, dtype=float32), 'eval/episode_reward': Array(5486.9834, dtype=float32), 'eval/episode_reward_alive': Array(377.1914, dtype=float32), 'eval/episode_reward_linvel': Array(5504.3916, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.62592, dtype=float32), 'eval/episode_x_position': Array(6751.25, dtype=float32), 'eval/episode_x_velocity': Array(1100.8783, dtype=float32), 'eval/episode_y_position': Array(-214.46524, dtype=float32), 'eval/episode_y_velocity': Array(-178.9161, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.37097, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1932044, dtype=float32), 'eval/episode_forward_reward_std': Array(865.5275, dtype=float32), 'eval/episode_reward_std': Array(875.42004, dtype=float32), 'eval/episode_reward_alive_std': Array(41.50316, dtype=float32), 'eval/episode_reward_linvel_std': Array(865.5275, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.243736, dtype=float32), 'eval/episode_x_position_std': Array(458.64236, dtype=float32), 'eval/episode_x_velocity_std': Array(173.10544, dtype=float32), 'eval/episode_y_position_std': Array(340.34705, dtype=float32), 'eval/episode_y_velocity_std': Array(94.91829, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45718693733215, 'eval/sps': 938.0231475736334, 'num_steps': 44400640}
{'eval/walltime': 74295.06359124184, 'training/sps': 2923.744899170792, 'training/walltime': 15128.279528617859, 'training/entropy_loss': Array(0.01778172, dtype=float32), 'training/policy_loss': Array(0.00717103, dtype=float32), 'training/total_loss': Array(0.25292173, dtype=float32), 'training/v_loss': Array(0.227969, dtype=float32), 'eval/episode_distance_from_origin': Array(6894.7676, dtype=float32), 'eval/episode_distance_reward': Array(33.548885, dtype=float32), 'eval/episode_forward_reward': Array(5591.45, dtype=float32), 'eval/episode_reward': Array(5579.927, dtype=float32), 'eval/episode_reward_alive': Array(376.34766, dtype=float32), 'eval/episode_reward_linvel': Array(5591.45, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.4195, dtype=float32), 'eval/episode_x_position': Array(6843.285, dtype=float32), 'eval/episode_x_velocity': Array(1118.29, dtype=float32), 'eval/episode_y_position': Array(-125.38075, dtype=float32), 'eval/episode_y_velocity': Array(-155.75453, dtype=float32), 'eval/episode_distance_from_origin_std': Array(510.82883, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9017434, dtype=float32), 'eval/episode_forward_reward_std': Array(983.61725, dtype=float32), 'eval/episode_reward_std': Array(979.12646, dtype=float32), 'eval/episode_reward_alive_std': Array(46.482803, dtype=float32), 'eval/episode_reward_linvel_std': Array(983.61725, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.538551, dtype=float32), 'eval/episode_x_position_std': Array(514.45636, dtype=float32), 'eval/episode_x_velocity_std': Array(196.72336, dtype=float32), 'eval/episode_y_position_std': Array(379.61642, dtype=float32), 'eval/episode_y_velocity_std': Array(114.89111, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2750153541565, 'eval/sps': 939.2770910159057, 'num_steps': 44482560}
{'eval/walltime': 74431.5166375637, 'training/sps': 2931.559956531358, 'training/walltime': 15156.223695278168, 'training/entropy_loss': Array(0.01555362, dtype=float32), 'training/policy_loss': Array(0.07602192, dtype=float32), 'training/total_loss': Array(0.2557788, dtype=float32), 'training/v_loss': Array(0.16420327, dtype=float32), 'eval/episode_distance_from_origin': Array(6805.0015, dtype=float32), 'eval/episode_distance_reward': Array(32.811626, dtype=float32), 'eval/episode_forward_reward': Array(5468.5737, dtype=float32), 'eval/episode_reward': Array(5455.536, dtype=float32), 'eval/episode_reward_alive': Array(378.22266, dtype=float32), 'eval/episode_reward_linvel': Array(5468.5737, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.07056, dtype=float32), 'eval/episode_x_position': Array(6752.6606, dtype=float32), 'eval/episode_x_velocity': Array(1093.7147, dtype=float32), 'eval/episode_y_position': Array(-197.38344, dtype=float32), 'eval/episode_y_velocity': Array(-172.05676, dtype=float32), 'eval/episode_distance_from_origin_std': Array(438.65976, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8400326, dtype=float32), 'eval/episode_forward_reward_std': Array(806.6659, dtype=float32), 'eval/episode_reward_std': Array(812.4336, dtype=float32), 'eval/episode_reward_alive_std': Array(45.518665, dtype=float32), 'eval/episode_reward_linvel_std': Array(806.6659, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.26621, dtype=float32), 'eval/episode_x_position_std': Array(440.59714, dtype=float32), 'eval/episode_x_velocity_std': Array(161.33333, dtype=float32), 'eval/episode_y_position_std': Array(357.27084, dtype=float32), 'eval/episode_y_velocity_std': Array(102.36893, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4530463218689, 'eval/sps': 938.0516115270183, 'num_steps': 44564480}
{'eval/walltime': 74567.8145160675, 'training/sps': 2952.3915815298487, 'training/walltime': 15183.970692157745, 'training/entropy_loss': Array(0.0165171, dtype=float32), 'training/policy_loss': Array(0.00666162, dtype=float32), 'training/total_loss': Array(0.08701447, dtype=float32), 'training/v_loss': Array(0.06383574, dtype=float32), 'eval/episode_distance_from_origin': Array(6883.454, dtype=float32), 'eval/episode_distance_reward': Array(33.173965, dtype=float32), 'eval/episode_forward_reward': Array(5528.964, dtype=float32), 'eval/episode_reward': Array(5520.7407, dtype=float32), 'eval/episode_reward_alive': Array(380.4922, dtype=float32), 'eval/episode_reward_linvel': Array(5528.964, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.88852, dtype=float32), 'eval/episode_x_position': Array(6830.871, dtype=float32), 'eval/episode_x_velocity': Array(1105.7926, dtype=float32), 'eval/episode_y_position': Array(-165.0492, dtype=float32), 'eval/episode_y_velocity': Array(-163.08577, dtype=float32), 'eval/episode_distance_from_origin_std': Array(524.24005, dtype=float32), 'eval/episode_distance_reward_std': Array(5.951355, dtype=float32), 'eval/episode_forward_reward_std': Array(991.8871, dtype=float32), 'eval/episode_reward_std': Array(989.2794, dtype=float32), 'eval/episode_reward_alive_std': Array(47.853252, dtype=float32), 'eval/episode_reward_linvel_std': Array(991.8871, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.892374, dtype=float32), 'eval/episode_x_position_std': Array(527.1274, dtype=float32), 'eval/episode_x_velocity_std': Array(198.37746, dtype=float32), 'eval/episode_y_position_std': Array(379.56387, dtype=float32), 'eval/episode_y_velocity_std': Array(111.79214, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29787850379944, 'eval/sps': 939.1195329311885, 'num_steps': 44646400}
{'eval/walltime': 74704.26668453217, 'training/sps': 2952.6884504376685, 'training/walltime': 15211.714899301529, 'training/entropy_loss': Array(0.01912435, dtype=float32), 'training/policy_loss': Array(0.00693832, dtype=float32), 'training/total_loss': Array(0.20312488, dtype=float32), 'training/v_loss': Array(0.17706221, dtype=float32), 'eval/episode_distance_from_origin': Array(6946.58, dtype=float32), 'eval/episode_distance_reward': Array(33.818787, dtype=float32), 'eval/episode_forward_reward': Array(5636.4326, dtype=float32), 'eval/episode_reward': Array(5628.1943, dtype=float32), 'eval/episode_reward_alive': Array(380.5, dtype=float32), 'eval/episode_reward_linvel': Array(5636.4326, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.55737, dtype=float32), 'eval/episode_x_position': Array(6892.863, dtype=float32), 'eval/episode_x_velocity': Array(1127.2865, dtype=float32), 'eval/episode_y_position': Array(-150.56264, dtype=float32), 'eval/episode_y_velocity': Array(-154.00659, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.93362, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2118235, dtype=float32), 'eval/episode_forward_reward_std': Array(868.6318, dtype=float32), 'eval/episode_reward_std': Array(872.5597, dtype=float32), 'eval/episode_reward_alive_std': Array(42.782837, dtype=float32), 'eval/episode_reward_linvel_std': Array(868.6318, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.25965, dtype=float32), 'eval/episode_x_position_std': Array(493.9626, dtype=float32), 'eval/episode_x_velocity_std': Array(173.72636, dtype=float32), 'eval/episode_y_position_std': Array(415.0761, dtype=float32), 'eval/episode_y_velocity_std': Array(127.13979, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45216846466064, 'eval/sps': 938.0576464283185, 'num_steps': 44728320}
{'eval/walltime': 74840.54350376129, 'training/sps': 2954.396739277309, 'training/walltime': 15239.443064212799, 'training/entropy_loss': Array(0.01717969, dtype=float32), 'training/policy_loss': Array(0.00577612, dtype=float32), 'training/total_loss': Array(0.18235347, dtype=float32), 'training/v_loss': Array(0.15939766, dtype=float32), 'eval/episode_distance_from_origin': Array(6865.1357, dtype=float32), 'eval/episode_distance_reward': Array(33.348145, dtype=float32), 'eval/episode_forward_reward': Array(5557.9917, dtype=float32), 'eval/episode_reward': Array(5556.57, dtype=float32), 'eval/episode_reward_alive': Array(387.38672, dtype=float32), 'eval/episode_reward_linvel': Array(5557.9917, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.1574, dtype=float32), 'eval/episode_x_position': Array(6811.2734, dtype=float32), 'eval/episode_x_velocity': Array(1111.5984, dtype=float32), 'eval/episode_y_position': Array(-177.81555, dtype=float32), 'eval/episode_y_velocity': Array(-165.97345, dtype=float32), 'eval/episode_distance_from_origin_std': Array(484.31552, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7563806, dtype=float32), 'eval/episode_forward_reward_std': Array(959.39075, dtype=float32), 'eval/episode_reward_std': Array(952.9576, dtype=float32), 'eval/episode_reward_alive_std': Array(41.29066, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.39075, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.54975, dtype=float32), 'eval/episode_x_position_std': Array(485.49634, dtype=float32), 'eval/episode_x_velocity_std': Array(191.87811, dtype=float32), 'eval/episode_y_position_std': Array(401.321, dtype=float32), 'eval/episode_y_velocity_std': Array(125.75265, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27681922912598, 'eval/sps': 939.2646579517685, 'num_steps': 44810240}
{'eval/walltime': 74977.00892186165, 'training/sps': 2949.646883802678, 'training/walltime': 15267.215880155563, 'training/entropy_loss': Array(0.01729645, dtype=float32), 'training/policy_loss': Array(0.00794612, dtype=float32), 'training/total_loss': Array(0.22489035, dtype=float32), 'training/v_loss': Array(0.19964778, dtype=float32), 'eval/episode_distance_from_origin': Array(6923.106, dtype=float32), 'eval/episode_distance_reward': Array(34.290207, dtype=float32), 'eval/episode_forward_reward': Array(5715.0034, dtype=float32), 'eval/episode_reward': Array(5708.5283, dtype=float32), 'eval/episode_reward_alive': Array(376.8164, dtype=float32), 'eval/episode_reward_linvel': Array(5715.0034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.58148, dtype=float32), 'eval/episode_x_position': Array(6870.3276, dtype=float32), 'eval/episode_x_velocity': Array(1143.0005, dtype=float32), 'eval/episode_y_position': Array(-155.5582, dtype=float32), 'eval/episode_y_velocity': Array(-160.71454, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.15897, dtype=float32), 'eval/episode_distance_reward_std': Array(5.221358, dtype=float32), 'eval/episode_forward_reward_std': Array(870.22107, dtype=float32), 'eval/episode_reward_std': Array(865.68384, dtype=float32), 'eval/episode_reward_alive_std': Array(39.4207, dtype=float32), 'eval/episode_reward_linvel_std': Array(870.22107, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.977916, dtype=float32), 'eval/episode_x_position_std': Array(476.12305, dtype=float32), 'eval/episode_x_velocity_std': Array(174.0442, dtype=float32), 'eval/episode_y_position_std': Array(392.45847, dtype=float32), 'eval/episode_y_velocity_std': Array(118.28903, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46541810035706, 'eval/sps': 937.9665689799041, 'num_steps': 44892160}
{'eval/walltime': 75113.34813117981, 'training/sps': 2958.7830518755172, 'training/walltime': 15294.902938842773, 'training/entropy_loss': Array(0.01758942, dtype=float32), 'training/policy_loss': Array(0.0070474, dtype=float32), 'training/total_loss': Array(0.24470732, dtype=float32), 'training/v_loss': Array(0.22007051, dtype=float32), 'eval/episode_distance_from_origin': Array(6899.019, dtype=float32), 'eval/episode_distance_reward': Array(33.987457, dtype=float32), 'eval/episode_forward_reward': Array(5664.545, dtype=float32), 'eval/episode_reward': Array(5660.11, dtype=float32), 'eval/episode_reward_alive': Array(383.60938, dtype=float32), 'eval/episode_reward_linvel': Array(5664.545, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.03046, dtype=float32), 'eval/episode_x_position': Array(6851.332, dtype=float32), 'eval/episode_x_velocity': Array(1132.9089, dtype=float32), 'eval/episode_y_position': Array(-119.191864, dtype=float32), 'eval/episode_y_velocity': Array(-156.41974, dtype=float32), 'eval/episode_distance_from_origin_std': Array(495.392, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9856057, dtype=float32), 'eval/episode_forward_reward_std': Array(997.5937, dtype=float32), 'eval/episode_reward_std': Array(996.33276, dtype=float32), 'eval/episode_reward_alive_std': Array(46.439766, dtype=float32), 'eval/episode_reward_linvel_std': Array(997.5937, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.13533, dtype=float32), 'eval/episode_x_position_std': Array(496.941, dtype=float32), 'eval/episode_x_velocity_std': Array(199.5188, dtype=float32), 'eval/episode_y_position_std': Array(332.68246, dtype=float32), 'eval/episode_y_velocity_std': Array(100.27938, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.339209318161, 'eval/sps': 938.8348417167314, 'num_steps': 44974080}
{'eval/walltime': 75249.90672492981, 'training/sps': 2945.931732725102, 'training/walltime': 15322.710779428482, 'training/entropy_loss': Array(0.018516, dtype=float32), 'training/policy_loss': Array(0.00463826, dtype=float32), 'training/total_loss': Array(0.24977843, dtype=float32), 'training/v_loss': Array(0.22662416, dtype=float32), 'eval/episode_distance_from_origin': Array(6914.9424, dtype=float32), 'eval/episode_distance_reward': Array(33.91646, dtype=float32), 'eval/episode_forward_reward': Array(5652.7114, dtype=float32), 'eval/episode_reward': Array(5649.9434, dtype=float32), 'eval/episode_reward_alive': Array(384.96875, dtype=float32), 'eval/episode_reward_linvel': Array(5652.7114, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.65317, dtype=float32), 'eval/episode_x_position': Array(6862.4062, dtype=float32), 'eval/episode_x_velocity': Array(1130.5422, dtype=float32), 'eval/episode_y_position': Array(-154.67899, dtype=float32), 'eval/episode_y_velocity': Array(-161.4721, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.219, dtype=float32), 'eval/episode_distance_reward_std': Array(4.967651, dtype=float32), 'eval/episode_forward_reward_std': Array(827.93677, dtype=float32), 'eval/episode_reward_std': Array(828.18195, dtype=float32), 'eval/episode_reward_alive_std': Array(40.14596, dtype=float32), 'eval/episode_reward_linvel_std': Array(827.93677, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.774593, dtype=float32), 'eval/episode_x_position_std': Array(422.41162, dtype=float32), 'eval/episode_x_velocity_std': Array(165.58731, dtype=float32), 'eval/episode_y_position_std': Array(386.21124, dtype=float32), 'eval/episode_y_velocity_std': Array(118.37889, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55859375, 'eval/sps': 937.3265825681513, 'num_steps': 45056000}
{'eval/walltime': 75386.24049568176, 'training/sps': 2953.438766513553, 'training/walltime': 15350.447938203812, 'training/entropy_loss': Array(0.01507065, dtype=float32), 'training/policy_loss': Array(0.00589695, dtype=float32), 'training/total_loss': Array(0.05564905, dtype=float32), 'training/v_loss': Array(0.03468145, dtype=float32), 'eval/episode_distance_from_origin': Array(6910.4946, dtype=float32), 'eval/episode_distance_reward': Array(33.72452, dtype=float32), 'eval/episode_forward_reward': Array(5620.7227, dtype=float32), 'eval/episode_reward': Array(5619.5703, dtype=float32), 'eval/episode_reward_alive': Array(387.10547, dtype=float32), 'eval/episode_reward_linvel': Array(5620.7227, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.9817, dtype=float32), 'eval/episode_x_position': Array(6858.0664, dtype=float32), 'eval/episode_x_velocity': Array(1124.1445, dtype=float32), 'eval/episode_y_position': Array(-228.51968, dtype=float32), 'eval/episode_y_velocity': Array(-177.74506, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.1658, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5093007, dtype=float32), 'eval/episode_forward_reward_std': Array(918.2101, dtype=float32), 'eval/episode_reward_std': Array(920.89374, dtype=float32), 'eval/episode_reward_alive_std': Array(41.859726, dtype=float32), 'eval/episode_reward_linvel_std': Array(918.2101, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.074509, dtype=float32), 'eval/episode_x_position_std': Array(485.3395, dtype=float32), 'eval/episode_x_velocity_std': Array(183.64206, dtype=float32), 'eval/episode_y_position_std': Array(334.83304, dtype=float32), 'eval/episode_y_velocity_std': Array(96.42489, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33377075195312, 'eval/sps': 938.8722932991001, 'num_steps': 45137920}
{'eval/walltime': 75522.92683768272, 'training/sps': 2950.879595801306, 'training/walltime': 15378.20915222168, 'training/entropy_loss': Array(0.01810408, dtype=float32), 'training/policy_loss': Array(0.00659343, dtype=float32), 'training/total_loss': Array(0.17593372, dtype=float32), 'training/v_loss': Array(0.1512362, dtype=float32), 'eval/episode_distance_from_origin': Array(6880.3467, dtype=float32), 'eval/episode_distance_reward': Array(33.12599, dtype=float32), 'eval/episode_forward_reward': Array(5520.9683, dtype=float32), 'eval/episode_reward': Array(5516.219, dtype=float32), 'eval/episode_reward_alive': Array(385.54297, dtype=float32), 'eval/episode_reward_linvel': Array(5520.9683, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.4181, dtype=float32), 'eval/episode_x_position': Array(6829.3936, dtype=float32), 'eval/episode_x_velocity': Array(1104.1937, dtype=float32), 'eval/episode_y_position': Array(-187.4277, dtype=float32), 'eval/episode_y_velocity': Array(-173.76154, dtype=float32), 'eval/episode_distance_from_origin_std': Array(496.5089, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7116227, dtype=float32), 'eval/episode_forward_reward_std': Array(951.9294, dtype=float32), 'eval/episode_reward_std': Array(948.3682, dtype=float32), 'eval/episode_reward_alive_std': Array(45.18089, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.9294, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.38182, dtype=float32), 'eval/episode_x_position_std': Array(498.05725, dtype=float32), 'eval/episode_x_velocity_std': Array(190.38596, dtype=float32), 'eval/episode_y_position_std': Array(326.8599, dtype=float32), 'eval/episode_y_velocity_std': Array(99.76869, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6863420009613, 'eval/sps': 936.4505489443839, 'num_steps': 45219840}
{'eval/walltime': 75659.32557320595, 'training/sps': 2932.7430242285427, 'training/walltime': 15406.14204621315, 'training/entropy_loss': Array(0.01784666, dtype=float32), 'training/policy_loss': Array(0.00795253, dtype=float32), 'training/total_loss': Array(0.17624465, dtype=float32), 'training/v_loss': Array(0.15044546, dtype=float32), 'eval/episode_distance_from_origin': Array(6869.739, dtype=float32), 'eval/episode_distance_reward': Array(32.984062, dtype=float32), 'eval/episode_forward_reward': Array(5497.3125, dtype=float32), 'eval/episode_reward': Array(5496.593, dtype=float32), 'eval/episode_reward_alive': Array(392.72266, dtype=float32), 'eval/episode_reward_linvel': Array(5497.3125, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.4266, dtype=float32), 'eval/episode_x_position': Array(6817.6416, dtype=float32), 'eval/episode_x_velocity': Array(1099.4626, dtype=float32), 'eval/episode_y_position': Array(-141.36406, dtype=float32), 'eval/episode_y_velocity': Array(-141.00333, dtype=float32), 'eval/episode_distance_from_origin_std': Array(499.95462, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5292416, dtype=float32), 'eval/episode_forward_reward_std': Array(921.5334, dtype=float32), 'eval/episode_reward_std': Array(923.65826, dtype=float32), 'eval/episode_reward_alive_std': Array(46.49617, dtype=float32), 'eval/episode_reward_linvel_std': Array(921.5334, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.8124, dtype=float32), 'eval/episode_x_position_std': Array(499.60526, dtype=float32), 'eval/episode_x_velocity_std': Array(184.30663, dtype=float32), 'eval/episode_y_position_std': Array(408.62314, dtype=float32), 'eval/episode_y_velocity_std': Array(140.09007, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39873552322388, 'eval/sps': 938.4251218238466, 'num_steps': 45301760}
{'eval/walltime': 75795.85245966911, 'training/sps': 2925.94783233728, 'training/walltime': 15434.13981127739, 'training/entropy_loss': Array(0.01838834, dtype=float32), 'training/policy_loss': Array(0.00838648, dtype=float32), 'training/total_loss': Array(0.2205837, dtype=float32), 'training/v_loss': Array(0.19380888, dtype=float32), 'eval/episode_distance_from_origin': Array(6962.97, dtype=float32), 'eval/episode_distance_reward': Array(34.139153, dtype=float32), 'eval/episode_forward_reward': Array(5689.8267, dtype=float32), 'eval/episode_reward': Array(5686.9854, dtype=float32), 'eval/episode_reward_alive': Array(384.90625, dtype=float32), 'eval/episode_reward_linvel': Array(5689.8267, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.88684, dtype=float32), 'eval/episode_x_position': Array(6911.9297, dtype=float32), 'eval/episode_x_velocity': Array(1137.9653, dtype=float32), 'eval/episode_y_position': Array(-194.14932, dtype=float32), 'eval/episode_y_velocity': Array(-162.1267, dtype=float32), 'eval/episode_distance_from_origin_std': Array(465.86038, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4175663, dtype=float32), 'eval/episode_forward_reward_std': Array(902.92175, dtype=float32), 'eval/episode_reward_std': Array(902.4106, dtype=float32), 'eval/episode_reward_alive_std': Array(46.105762, dtype=float32), 'eval/episode_reward_linvel_std': Array(902.92175, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.827576, dtype=float32), 'eval/episode_x_position_std': Array(467.1236, dtype=float32), 'eval/episode_x_velocity_std': Array(180.58437, dtype=float32), 'eval/episode_y_position_std': Array(353.84036, dtype=float32), 'eval/episode_y_velocity_std': Array(117.633766, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52688646316528, 'eval/sps': 937.5442692347209, 'num_steps': 45383680}
{'eval/walltime': 75932.21515083313, 'training/sps': 2936.5793569223415, 'training/walltime': 15462.036213874817, 'training/entropy_loss': Array(0.01821827, dtype=float32), 'training/policy_loss': Array(0.00735116, dtype=float32), 'training/total_loss': Array(0.24425021, dtype=float32), 'training/v_loss': Array(0.2186808, dtype=float32), 'eval/episode_distance_from_origin': Array(6888.079, dtype=float32), 'eval/episode_distance_reward': Array(33.173798, dtype=float32), 'eval/episode_forward_reward': Array(5528.935, dtype=float32), 'eval/episode_reward': Array(5525.9287, dtype=float32), 'eval/episode_reward_alive': Array(388.27734, dtype=float32), 'eval/episode_reward_linvel': Array(5528.935, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.45718, dtype=float32), 'eval/episode_x_position': Array(6835.772, dtype=float32), 'eval/episode_x_velocity': Array(1105.7871, dtype=float32), 'eval/episode_y_position': Array(-254.91876, dtype=float32), 'eval/episode_y_velocity': Array(-178.19504, dtype=float32), 'eval/episode_distance_from_origin_std': Array(455.51923, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9761333, dtype=float32), 'eval/episode_forward_reward_std': Array(829.34894, dtype=float32), 'eval/episode_reward_std': Array(825.33386, dtype=float32), 'eval/episode_reward_alive_std': Array(42.210354, dtype=float32), 'eval/episode_reward_linvel_std': Array(829.34894, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.777613, dtype=float32), 'eval/episode_x_position_std': Array(456.04556, dtype=float32), 'eval/episode_x_velocity_std': Array(165.86984, dtype=float32), 'eval/episode_y_position_std': Array(328.06982, dtype=float32), 'eval/episode_y_velocity_std': Array(109.20635, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.36269116401672, 'eval/sps': 938.6731730458583, 'num_steps': 45465600}
{'eval/walltime': 76068.89120364189, 'training/sps': 2925.9643768448045, 'training/walltime': 15490.03382062912, 'training/entropy_loss': Array(0.01806617, dtype=float32), 'training/policy_loss': Array(0.00970957, dtype=float32), 'training/total_loss': Array(0.2734444, dtype=float32), 'training/v_loss': Array(0.2456687, dtype=float32), 'eval/episode_distance_from_origin': Array(6908.6562, dtype=float32), 'eval/episode_distance_reward': Array(33.269226, dtype=float32), 'eval/episode_forward_reward': Array(5544.84, dtype=float32), 'eval/episode_reward': Array(5534.0244, dtype=float32), 'eval/episode_reward_alive': Array(383.76953, dtype=float32), 'eval/episode_reward_linvel': Array(5544.84, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.85382, dtype=float32), 'eval/episode_x_position': Array(6854.6846, dtype=float32), 'eval/episode_x_velocity': Array(1108.9678, dtype=float32), 'eval/episode_y_position': Array(-203.77005, dtype=float32), 'eval/episode_y_velocity': Array(-165.32024, dtype=float32), 'eval/episode_distance_from_origin_std': Array(496.49356, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8240385, dtype=float32), 'eval/episode_forward_reward_std': Array(970.6656, dtype=float32), 'eval/episode_reward_std': Array(974.85516, dtype=float32), 'eval/episode_reward_alive_std': Array(48.439995, dtype=float32), 'eval/episode_reward_linvel_std': Array(970.6656, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.34493, dtype=float32), 'eval/episode_x_position_std': Array(499.53397, dtype=float32), 'eval/episode_x_velocity_std': Array(194.13326, dtype=float32), 'eval/episode_y_position_std': Array(397.20605, dtype=float32), 'eval/episode_y_velocity_std': Array(124.480484, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6760528087616, 'eval/sps': 936.5210464418283, 'num_steps': 45547520}
{'eval/walltime': 76205.23620009422, 'training/sps': 2955.2769161570977, 'training/walltime': 15517.753727197647, 'training/entropy_loss': Array(0.01320748, dtype=float32), 'training/policy_loss': Array(0.06661144, dtype=float32), 'training/total_loss': Array(0.1497373, dtype=float32), 'training/v_loss': Array(0.06991836, dtype=float32), 'eval/episode_distance_from_origin': Array(7208.6943, dtype=float32), 'eval/episode_distance_reward': Array(36.419334, dtype=float32), 'eval/episode_forward_reward': Array(6069.8555, dtype=float32), 'eval/episode_reward': Array(6066.8516, dtype=float32), 'eval/episode_reward_alive': Array(374.0078, dtype=float32), 'eval/episode_reward_linvel': Array(6069.8555, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.43152, dtype=float32), 'eval/episode_x_position': Array(7160.8213, dtype=float32), 'eval/episode_x_velocity': Array(1213.971, dtype=float32), 'eval/episode_y_position': Array(-152.5716, dtype=float32), 'eval/episode_y_velocity': Array(-144.62802, dtype=float32), 'eval/episode_distance_from_origin_std': Array(419.00995, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1464505, dtype=float32), 'eval/episode_forward_reward_std': Array(857.73517, dtype=float32), 'eval/episode_reward_std': Array(860.3256, dtype=float32), 'eval/episode_reward_alive_std': Array(43.699257, dtype=float32), 'eval/episode_reward_linvel_std': Array(857.73517, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.078557, dtype=float32), 'eval/episode_x_position_std': Array(424.48972, dtype=float32), 'eval/episode_x_velocity_std': Array(171.5471, dtype=float32), 'eval/episode_y_position_std': Array(393.88803, dtype=float32), 'eval/episode_y_velocity_std': Array(123.78109, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34499645233154, 'eval/sps': 938.7949930729648, 'num_steps': 45629440}
{'eval/walltime': 76341.81647276878, 'training/sps': 2946.7864267170658, 'training/walltime': 15545.553502321243, 'training/entropy_loss': Array(0.01903772, dtype=float32), 'training/policy_loss': Array(0.01428827, dtype=float32), 'training/total_loss': Array(0.15704201, dtype=float32), 'training/v_loss': Array(0.12371601, dtype=float32), 'eval/episode_distance_from_origin': Array(7220.404, dtype=float32), 'eval/episode_distance_reward': Array(36.63992, dtype=float32), 'eval/episode_forward_reward': Array(6106.621, dtype=float32), 'eval/episode_reward': Array(6100.84, dtype=float32), 'eval/episode_reward_alive': Array(372.71094, dtype=float32), 'eval/episode_reward_linvel': Array(6106.621, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.1319, dtype=float32), 'eval/episode_x_position': Array(7170.0996, dtype=float32), 'eval/episode_x_velocity': Array(1221.3242, dtype=float32), 'eval/episode_y_position': Array(-217.02417, dtype=float32), 'eval/episode_y_velocity': Array(-152.27213, dtype=float32), 'eval/episode_distance_from_origin_std': Array(410.79556, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1121793, dtype=float32), 'eval/episode_forward_reward_std': Array(852.0253, dtype=float32), 'eval/episode_reward_std': Array(856.7489, dtype=float32), 'eval/episode_reward_alive_std': Array(46.70965, dtype=float32), 'eval/episode_reward_linvel_std': Array(852.0253, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.51571, dtype=float32), 'eval/episode_x_position_std': Array(417.10043, dtype=float32), 'eval/episode_x_velocity_std': Array(170.40497, dtype=float32), 'eval/episode_y_position_std': Array(404.9809, dtype=float32), 'eval/episode_y_velocity_std': Array(120.28429, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58027267456055, 'eval/sps': 937.1778038911566, 'num_steps': 45711360}
{'eval/walltime': 76478.10735630989, 'training/sps': 2949.959359450082, 'training/walltime': 15573.32337641716, 'training/entropy_loss': Array(0.01799445, dtype=float32), 'training/policy_loss': Array(0.00711945, dtype=float32), 'training/total_loss': Array(0.26697296, dtype=float32), 'training/v_loss': Array(0.24185908, dtype=float32), 'eval/episode_distance_from_origin': Array(7122.569, dtype=float32), 'eval/episode_distance_reward': Array(35.47664, dtype=float32), 'eval/episode_forward_reward': Array(5912.74, dtype=float32), 'eval/episode_reward': Array(5901.9136, dtype=float32), 'eval/episode_reward_alive': Array(367.42188, dtype=float32), 'eval/episode_reward_linvel': Array(5912.74, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.72562, dtype=float32), 'eval/episode_x_position': Array(7072.376, dtype=float32), 'eval/episode_x_velocity': Array(1182.5481, dtype=float32), 'eval/episode_y_position': Array(-244.88474, dtype=float32), 'eval/episode_y_velocity': Array(-166.92792, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.04422, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1937337, dtype=float32), 'eval/episode_forward_reward_std': Array(865.6165, dtype=float32), 'eval/episode_reward_std': Array(860.61536, dtype=float32), 'eval/episode_reward_alive_std': Array(48.804752, dtype=float32), 'eval/episode_reward_linvel_std': Array(865.6165, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.681286, dtype=float32), 'eval/episode_x_position_std': Array(433.49487, dtype=float32), 'eval/episode_x_velocity_std': Array(173.12329, dtype=float32), 'eval/episode_y_position_std': Array(367.28256, dtype=float32), 'eval/episode_y_velocity_std': Array(109.78944, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29088354110718, 'eval/sps': 939.1677320911451, 'num_steps': 45793280}
{'eval/walltime': 76614.696464777, 'training/sps': 2936.608947389122, 'training/walltime': 15601.219497919083, 'training/entropy_loss': Array(0.0182972, dtype=float32), 'training/policy_loss': Array(0.00702586, dtype=float32), 'training/total_loss': Array(0.27639684, dtype=float32), 'training/v_loss': Array(0.25107378, dtype=float32), 'eval/episode_distance_from_origin': Array(7193.1074, dtype=float32), 'eval/episode_distance_reward': Array(35.77056, dtype=float32), 'eval/episode_forward_reward': Array(5961.729, dtype=float32), 'eval/episode_reward': Array(5964.7124, dtype=float32), 'eval/episode_reward_alive': Array(386.375, dtype=float32), 'eval/episode_reward_linvel': Array(5961.729, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.16232, dtype=float32), 'eval/episode_x_position': Array(7144.4424, dtype=float32), 'eval/episode_x_velocity': Array(1192.3458, dtype=float32), 'eval/episode_y_position': Array(-215.66672, dtype=float32), 'eval/episode_y_velocity': Array(-151.67726, dtype=float32), 'eval/episode_distance_from_origin_std': Array(417.28845, dtype=float32), 'eval/episode_distance_reward_std': Array(5.116962, dtype=float32), 'eval/episode_forward_reward_std': Array(852.8217, dtype=float32), 'eval/episode_reward_std': Array(858.8524, dtype=float32), 'eval/episode_reward_alive_std': Array(48.722065, dtype=float32), 'eval/episode_reward_linvel_std': Array(852.8217, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.15267, dtype=float32), 'eval/episode_x_position_std': Array(422.67746, dtype=float32), 'eval/episode_x_velocity_std': Array(170.56425, dtype=float32), 'eval/episode_y_position_std': Array(380.24493, dtype=float32), 'eval/episode_y_velocity_std': Array(109.961624, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58910846710205, 'eval/sps': 937.1171789354584, 'num_steps': 45875200}
{'eval/walltime': 76750.96657681465, 'training/sps': 2943.4727679964767, 'training/walltime': 15629.050569057465, 'training/entropy_loss': Array(0.01866505, dtype=float32), 'training/policy_loss': Array(0.1896058, dtype=float32), 'training/total_loss': Array(0.4701037, dtype=float32), 'training/v_loss': Array(0.26183286, dtype=float32), 'eval/episode_distance_from_origin': Array(7224.5176, dtype=float32), 'eval/episode_distance_reward': Array(35.74587, dtype=float32), 'eval/episode_forward_reward': Array(5957.6123, dtype=float32), 'eval/episode_reward': Array(5941.261, dtype=float32), 'eval/episode_reward_alive': Array(383.21094, dtype=float32), 'eval/episode_reward_linvel': Array(5957.6123, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.30804, dtype=float32), 'eval/episode_x_position': Array(7180.0415, dtype=float32), 'eval/episode_x_velocity': Array(1191.5225, dtype=float32), 'eval/episode_y_position': Array(-85.64166, dtype=float32), 'eval/episode_y_velocity': Array(-111.61756, dtype=float32), 'eval/episode_distance_from_origin_std': Array(534.57263, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5640054, dtype=float32), 'eval/episode_forward_reward_std': Array(1093.9933, dtype=float32), 'eval/episode_reward_std': Array(1105.7166, dtype=float32), 'eval/episode_reward_alive_std': Array(53.87959, dtype=float32), 'eval/episode_reward_linvel_std': Array(1093.9933, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.752663, dtype=float32), 'eval/episode_x_position_std': Array(535.92993, dtype=float32), 'eval/episode_x_velocity_std': Array(218.79861, dtype=float32), 'eval/episode_y_position_std': Array(416.13373, dtype=float32), 'eval/episode_y_velocity_std': Array(127.848145, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2701120376587, 'eval/sps': 939.310888396619, 'num_steps': 45957120}
{'eval/walltime': 76887.54029130936, 'training/sps': 2941.1873078070116, 'training/walltime': 15656.903266429901, 'training/entropy_loss': Array(0.01920617, dtype=float32), 'training/policy_loss': Array(0.12686807, dtype=float32), 'training/total_loss': Array(0.4265962, dtype=float32), 'training/v_loss': Array(0.28052196, dtype=float32), 'eval/episode_distance_from_origin': Array(7377.626, dtype=float32), 'eval/episode_distance_reward': Array(38.04944, dtype=float32), 'eval/episode_forward_reward': Array(6341.54, dtype=float32), 'eval/episode_reward': Array(6372.277, dtype=float32), 'eval/episode_reward_alive': Array(418.98438, dtype=float32), 'eval/episode_reward_linvel': Array(6341.54, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.29626, dtype=float32), 'eval/episode_x_position': Array(7318.3486, dtype=float32), 'eval/episode_x_velocity': Array(1268.308, dtype=float32), 'eval/episode_y_position': Array(486.9679, dtype=float32), 'eval/episode_y_velocity': Array(85.27037, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.08176, dtype=float32), 'eval/episode_distance_reward_std': Array(7.1067734, dtype=float32), 'eval/episode_forward_reward_std': Array(1184.4547, dtype=float32), 'eval/episode_reward_std': Array(1181.0377, dtype=float32), 'eval/episode_reward_alive_std': Array(41.41529, dtype=float32), 'eval/episode_reward_linvel_std': Array(1184.4547, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.68685, dtype=float32), 'eval/episode_x_position_std': Array(495.03598, dtype=float32), 'eval/episode_x_velocity_std': Array(236.89082, dtype=float32), 'eval/episode_y_position_std': Array(443.33527, dtype=float32), 'eval/episode_y_velocity_std': Array(156.91101, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5737144947052, 'eval/sps': 937.222806552299, 'num_steps': 46039040}
{'eval/walltime': 77023.81933784485, 'training/sps': 2947.610792105401, 'training/walltime': 15684.695266723633, 'training/entropy_loss': Array(0.01429836, dtype=float32), 'training/policy_loss': Array(0.0015643, dtype=float32), 'training/total_loss': Array(0.1550856, dtype=float32), 'training/v_loss': Array(0.13922293, dtype=float32), 'eval/episode_distance_from_origin': Array(7378.04, dtype=float32), 'eval/episode_distance_reward': Array(37.58823, dtype=float32), 'eval/episode_forward_reward': Array(6264.6733, dtype=float32), 'eval/episode_reward': Array(6294.9463, dtype=float32), 'eval/episode_reward_alive': Array(421.5, dtype=float32), 'eval/episode_reward_linvel': Array(6264.6733, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.81467, dtype=float32), 'eval/episode_x_position': Array(7322.1543, dtype=float32), 'eval/episode_x_velocity': Array(1252.9346, dtype=float32), 'eval/episode_y_position': Array(405.56934, dtype=float32), 'eval/episode_y_velocity': Array(62.6808, dtype=float32), 'eval/episode_distance_from_origin_std': Array(477.33603, dtype=float32), 'eval/episode_distance_reward_std': Array(7.462716, dtype=float32), 'eval/episode_forward_reward_std': Array(1243.7781, dtype=float32), 'eval/episode_reward_std': Array(1243.5745, dtype=float32), 'eval/episode_reward_alive_std': Array(42.677113, dtype=float32), 'eval/episode_reward_linvel_std': Array(1243.7781, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.499992, dtype=float32), 'eval/episode_x_position_std': Array(487.9496, dtype=float32), 'eval/episode_x_velocity_std': Array(248.7556, dtype=float32), 'eval/episode_y_position_std': Array(475.48254, dtype=float32), 'eval/episode_y_velocity_std': Array(160.82106, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27904653549194, 'eval/sps': 939.2493068746575, 'num_steps': 46120960}
{'eval/walltime': 77160.40515232086, 'training/sps': 2940.6895517617254, 'training/walltime': 15712.552678585052, 'training/entropy_loss': Array(0.01844114, dtype=float32), 'training/policy_loss': Array(0.00469823, dtype=float32), 'training/total_loss': Array(0.13897195, dtype=float32), 'training/v_loss': Array(0.11583258, dtype=float32), 'eval/episode_distance_from_origin': Array(7393.1104, dtype=float32), 'eval/episode_distance_reward': Array(38.366173, dtype=float32), 'eval/episode_forward_reward': Array(6394.33, dtype=float32), 'eval/episode_reward': Array(6423.0396, dtype=float32), 'eval/episode_reward_alive': Array(417.90234, dtype=float32), 'eval/episode_reward_linvel': Array(6394.33, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.55948, dtype=float32), 'eval/episode_x_position': Array(7338.5776, dtype=float32), 'eval/episode_x_velocity': Array(1278.8661, dtype=float32), 'eval/episode_y_position': Array(358.1855, dtype=float32), 'eval/episode_y_velocity': Array(45.627464, dtype=float32), 'eval/episode_distance_from_origin_std': Array(454.3598, dtype=float32), 'eval/episode_distance_reward_std': Array(6.8466735, dtype=float32), 'eval/episode_forward_reward_std': Array(1141.1056, dtype=float32), 'eval/episode_reward_std': Array(1156.5742, dtype=float32), 'eval/episode_reward_alive_std': Array(44.398014, dtype=float32), 'eval/episode_reward_linvel_std': Array(1141.1056, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.49328, dtype=float32), 'eval/episode_x_position_std': Array(462.27142, dtype=float32), 'eval/episode_x_velocity_std': Array(228.22118, dtype=float32), 'eval/episode_y_position_std': Array(486.72086, dtype=float32), 'eval/episode_y_velocity_std': Array(168.76698, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58581447601318, 'eval/sps': 937.1397790542809, 'num_steps': 46202880}
{'eval/walltime': 77296.68405461311, 'training/sps': 2947.5588796312018, 'training/walltime': 15740.345168352127, 'training/entropy_loss': Array(0.01803057, dtype=float32), 'training/policy_loss': Array(0.00973062, dtype=float32), 'training/total_loss': Array(0.32377213, dtype=float32), 'training/v_loss': Array(0.29601094, dtype=float32), 'eval/episode_distance_from_origin': Array(7359.6797, dtype=float32), 'eval/episode_distance_reward': Array(37.709957, dtype=float32), 'eval/episode_forward_reward': Array(6284.9595, dtype=float32), 'eval/episode_reward': Array(6316.902, dtype=float32), 'eval/episode_reward_alive': Array(422.23438, dtype=float32), 'eval/episode_reward_linvel': Array(6284.9595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.0023, dtype=float32), 'eval/episode_x_position': Array(7304.3086, dtype=float32), 'eval/episode_x_velocity': Array(1256.9918, dtype=float32), 'eval/episode_y_position': Array(396.18622, dtype=float32), 'eval/episode_y_velocity': Array(62.424812, dtype=float32), 'eval/episode_distance_from_origin_std': Array(512.88654, dtype=float32), 'eval/episode_distance_reward_std': Array(7.3988767, dtype=float32), 'eval/episode_forward_reward_std': Array(1233.1381, dtype=float32), 'eval/episode_reward_std': Array(1237.0712, dtype=float32), 'eval/episode_reward_alive_std': Array(44.93741, dtype=float32), 'eval/episode_reward_linvel_std': Array(1233.1381, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.842928, dtype=float32), 'eval/episode_x_position_std': Array(523.99365, dtype=float32), 'eval/episode_x_velocity_std': Array(246.62755, dtype=float32), 'eval/episode_y_position_std': Array(472.51102, dtype=float32), 'eval/episode_y_velocity_std': Array(156.47397, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2789022922516, 'eval/sps': 939.2503010150655, 'num_steps': 46284800}
{'eval/walltime': 77433.14482927322, 'training/sps': 2927.2440033212033, 'training/walltime': 15768.33053612709, 'training/entropy_loss': Array(0.01841085, dtype=float32), 'training/policy_loss': Array(0.00590026, dtype=float32), 'training/total_loss': Array(0.38303652, dtype=float32), 'training/v_loss': Array(0.35872543, dtype=float32), 'eval/episode_distance_from_origin': Array(7394.4146, dtype=float32), 'eval/episode_distance_reward': Array(37.709877, dtype=float32), 'eval/episode_forward_reward': Array(6284.9473, dtype=float32), 'eval/episode_reward': Array(6321.929, dtype=float32), 'eval/episode_reward_alive': Array(425.85938, dtype=float32), 'eval/episode_reward_linvel': Array(6284.9473, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.5869, dtype=float32), 'eval/episode_x_position': Array(7333.503, dtype=float32), 'eval/episode_x_velocity': Array(1256.9894, dtype=float32), 'eval/episode_y_position': Array(435.63867, dtype=float32), 'eval/episode_y_velocity': Array(64.94449, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.45505, dtype=float32), 'eval/episode_distance_reward_std': Array(6.7982974, dtype=float32), 'eval/episode_forward_reward_std': Array(1133.0428, dtype=float32), 'eval/episode_reward_std': Array(1139.6796, dtype=float32), 'eval/episode_reward_alive_std': Array(48.85113, dtype=float32), 'eval/episode_reward_linvel_std': Array(1133.0428, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.536242, dtype=float32), 'eval/episode_x_position_std': Array(496.5068, dtype=float32), 'eval/episode_x_velocity_std': Array(226.60858, dtype=float32), 'eval/episode_y_position_std': Array(505.7636, dtype=float32), 'eval/episode_y_velocity_std': Array(171.81276, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46077466011047, 'eval/sps': 937.9984857833019, 'num_steps': 46366720}
{'eval/walltime': 77569.62916898727, 'training/sps': 2936.235132355054, 'training/walltime': 15796.230209112167, 'training/entropy_loss': Array(0.01872309, dtype=float32), 'training/policy_loss': Array(0.0046357, dtype=float32), 'training/total_loss': Array(0.4293087, dtype=float32), 'training/v_loss': Array(0.40594995, dtype=float32), 'eval/episode_distance_from_origin': Array(7395.1113, dtype=float32), 'eval/episode_distance_reward': Array(38.372223, dtype=float32), 'eval/episode_forward_reward': Array(6395.3384, dtype=float32), 'eval/episode_reward': Array(6433.701, dtype=float32), 'eval/episode_reward_alive': Array(429.25, dtype=float32), 'eval/episode_reward_linvel': Array(6395.3384, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.25977, dtype=float32), 'eval/episode_x_position': Array(7339.3994, dtype=float32), 'eval/episode_x_velocity': Array(1279.0676, dtype=float32), 'eval/episode_y_position': Array(413.92902, dtype=float32), 'eval/episode_y_velocity': Array(59.629128, dtype=float32), 'eval/episode_distance_from_origin_std': Array(522.91547, dtype=float32), 'eval/episode_distance_reward_std': Array(7.64693, dtype=float32), 'eval/episode_forward_reward_std': Array(1274.4796, dtype=float32), 'eval/episode_reward_std': Array(1286.4861, dtype=float32), 'eval/episode_reward_alive_std': Array(40.64682, dtype=float32), 'eval/episode_reward_linvel_std': Array(1274.4796, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.636456, dtype=float32), 'eval/episode_x_position_std': Array(531.06995, dtype=float32), 'eval/episode_x_velocity_std': Array(254.89597, dtype=float32), 'eval/episode_y_position_std': Array(465.79782, dtype=float32), 'eval/episode_y_velocity_std': Array(161.9627, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4843397140503, 'eval/sps': 937.8365332475072, 'num_steps': 46448640}
{'eval/walltime': 77706.16914868355, 'training/sps': 2926.7858574926895, 'training/walltime': 15824.219957590103, 'training/entropy_loss': Array(0.01892124, dtype=float32), 'training/policy_loss': Array(0.00515059, dtype=float32), 'training/total_loss': Array(0.41859987, dtype=float32), 'training/v_loss': Array(0.39452803, dtype=float32), 'eval/episode_distance_from_origin': Array(7415.42, dtype=float32), 'eval/episode_distance_reward': Array(37.935005, dtype=float32), 'eval/episode_forward_reward': Array(6322.4683, dtype=float32), 'eval/episode_reward': Array(6350.418, dtype=float32), 'eval/episode_reward_alive': Array(417.08203, dtype=float32), 'eval/episode_reward_linvel': Array(6322.4683, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.06696, dtype=float32), 'eval/episode_x_position': Array(7363.8545, dtype=float32), 'eval/episode_x_velocity': Array(1264.4935, dtype=float32), 'eval/episode_y_position': Array(331.44592, dtype=float32), 'eval/episode_y_velocity': Array(34.413784, dtype=float32), 'eval/episode_distance_from_origin_std': Array(558.96826, dtype=float32), 'eval/episode_distance_reward_std': Array(7.696145, dtype=float32), 'eval/episode_forward_reward_std': Array(1282.6829, dtype=float32), 'eval/episode_reward_std': Array(1289.4154, dtype=float32), 'eval/episode_reward_alive_std': Array(46.819622, dtype=float32), 'eval/episode_reward_linvel_std': Array(1282.6829, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.339243, dtype=float32), 'eval/episode_x_position_std': Array(560.877, dtype=float32), 'eval/episode_x_velocity_std': Array(256.53656, dtype=float32), 'eval/episode_y_position_std': Array(472.7449, dtype=float32), 'eval/episode_y_velocity_std': Array(171.263, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5399796962738, 'eval/sps': 937.4543652689084, 'num_steps': 46530560}
{'eval/walltime': 77842.51568436623, 'training/sps': 2932.9364103473554, 'training/walltime': 15852.15100979805, 'training/entropy_loss': Array(0.01601922, dtype=float32), 'training/policy_loss': Array(0.00634388, dtype=float32), 'training/total_loss': Array(0.2804761, dtype=float32), 'training/v_loss': Array(0.25811303, dtype=float32), 'eval/episode_distance_from_origin': Array(7315.1494, dtype=float32), 'eval/episode_distance_reward': Array(37.12841, dtype=float32), 'eval/episode_forward_reward': Array(6188.037, dtype=float32), 'eval/episode_reward': Array(6221.545, dtype=float32), 'eval/episode_reward_alive': Array(428.1797, dtype=float32), 'eval/episode_reward_linvel': Array(6188.037, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.7996, dtype=float32), 'eval/episode_x_position': Array(7265.02, dtype=float32), 'eval/episode_x_velocity': Array(1237.6074, dtype=float32), 'eval/episode_y_position': Array(224.767, dtype=float32), 'eval/episode_y_velocity': Array(10.06762, dtype=float32), 'eval/episode_distance_from_origin_std': Array(513.18243, dtype=float32), 'eval/episode_distance_reward_std': Array(6.627122, dtype=float32), 'eval/episode_forward_reward_std': Array(1104.513, dtype=float32), 'eval/episode_reward_std': Array(1110.3253, dtype=float32), 'eval/episode_reward_alive_std': Array(41.351757, dtype=float32), 'eval/episode_reward_linvel_std': Array(1104.513, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.31725, dtype=float32), 'eval/episode_x_position_std': Array(513.8957, dtype=float32), 'eval/episode_x_velocity_std': Array(220.9026, dtype=float32), 'eval/episode_y_position_std': Array(493.7235, dtype=float32), 'eval/episode_y_velocity_std': Array(169.38931, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34653568267822, 'eval/sps': 938.7843949177905, 'num_steps': 46612480}
{'eval/walltime': 77979.04482626915, 'training/sps': 2942.493869036976, 'training/walltime': 15879.991339683533, 'training/entropy_loss': Array(0.01570914, dtype=float32), 'training/policy_loss': Array(0.00335452, dtype=float32), 'training/total_loss': Array(0.11716883, dtype=float32), 'training/v_loss': Array(0.09810517, dtype=float32), 'eval/episode_distance_from_origin': Array(7364.436, dtype=float32), 'eval/episode_distance_reward': Array(38.02801, dtype=float32), 'eval/episode_forward_reward': Array(6337.9688, dtype=float32), 'eval/episode_reward': Array(6365.2236, dtype=float32), 'eval/episode_reward_alive': Array(420.5664, dtype=float32), 'eval/episode_reward_linvel': Array(6337.9688, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.34015, dtype=float32), 'eval/episode_x_position': Array(7313.743, dtype=float32), 'eval/episode_x_velocity': Array(1267.5935, dtype=float32), 'eval/episode_y_position': Array(239.77509, dtype=float32), 'eval/episode_y_velocity': Array(-0.20994854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(515.2912, dtype=float32), 'eval/episode_distance_reward_std': Array(7.265788, dtype=float32), 'eval/episode_forward_reward_std': Array(1210.9567, dtype=float32), 'eval/episode_reward_std': Array(1224.0066, dtype=float32), 'eval/episode_reward_alive_std': Array(41.103878, dtype=float32), 'eval/episode_reward_linvel_std': Array(1210.9567, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.025898, dtype=float32), 'eval/episode_x_position_std': Array(523.6449, dtype=float32), 'eval/episode_x_velocity_std': Array(242.1913, dtype=float32), 'eval/episode_y_position_std': Array(485.85648, dtype=float32), 'eval/episode_y_velocity_std': Array(163.79802, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52914190292358, 'eval/sps': 937.5287811521729, 'num_steps': 46694400}
{'eval/walltime': 78115.42220044136, 'training/sps': 2959.1012379799163, 'training/walltime': 15907.675421237946, 'training/entropy_loss': Array(0.01914327, dtype=float32), 'training/policy_loss': Array(0.01073344, dtype=float32), 'training/total_loss': Array(0.3357019, dtype=float32), 'training/v_loss': Array(0.30582523, dtype=float32), 'eval/episode_distance_from_origin': Array(7354.4575, dtype=float32), 'eval/episode_distance_reward': Array(36.995415, dtype=float32), 'eval/episode_forward_reward': Array(6165.87, dtype=float32), 'eval/episode_reward': Array(6188.996, dtype=float32), 'eval/episode_reward_alive': Array(424.94922, dtype=float32), 'eval/episode_reward_linvel': Array(6165.87, dtype=float32), 'eval/episode_reward_quadctrl': Array(-438.81906, dtype=float32), 'eval/episode_x_position': Array(7304.7925, dtype=float32), 'eval/episode_x_velocity': Array(1233.1742, dtype=float32), 'eval/episode_y_position': Array(183.15654, dtype=float32), 'eval/episode_y_velocity': Array(-6.307558, dtype=float32), 'eval/episode_distance_from_origin_std': Array(544.9695, dtype=float32), 'eval/episode_distance_reward_std': Array(7.0541854, dtype=float32), 'eval/episode_forward_reward_std': Array(1175.6904, dtype=float32), 'eval/episode_reward_std': Array(1193.241, dtype=float32), 'eval/episode_reward_alive_std': Array(47.553825, dtype=float32), 'eval/episode_reward_linvel_std': Array(1175.6904, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.15189, dtype=float32), 'eval/episode_x_position_std': Array(547.75586, dtype=float32), 'eval/episode_x_velocity_std': Array(235.13803, dtype=float32), 'eval/episode_y_position_std': Array(505.52213, dtype=float32), 'eval/episode_y_velocity_std': Array(170.183, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3773741722107, 'eval/sps': 938.5721112240205, 'num_steps': 46776320}
{'eval/walltime': 78252.010253191, 'training/sps': 2948.7403979300543, 'training/walltime': 15935.456774950027, 'training/entropy_loss': Array(0.01932622, dtype=float32), 'training/policy_loss': Array(0.00528675, dtype=float32), 'training/total_loss': Array(0.32143858, dtype=float32), 'training/v_loss': Array(0.2968256, dtype=float32), 'eval/episode_distance_from_origin': Array(7347.2686, dtype=float32), 'eval/episode_distance_reward': Array(37.325348, dtype=float32), 'eval/episode_forward_reward': Array(6220.8604, dtype=float32), 'eval/episode_reward': Array(6242.517, dtype=float32), 'eval/episode_reward_alive': Array(419.1836, dtype=float32), 'eval/episode_reward_linvel': Array(6220.8604, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.85266, dtype=float32), 'eval/episode_x_position': Array(7299.1274, dtype=float32), 'eval/episode_x_velocity': Array(1244.172, dtype=float32), 'eval/episode_y_position': Array(144.5325, dtype=float32), 'eval/episode_y_velocity': Array(-29.293018, dtype=float32), 'eval/episode_distance_from_origin_std': Array(542.32306, dtype=float32), 'eval/episode_distance_reward_std': Array(6.8038607, dtype=float32), 'eval/episode_forward_reward_std': Array(1133.9692, dtype=float32), 'eval/episode_reward_std': Array(1149.9128, dtype=float32), 'eval/episode_reward_alive_std': Array(40.618504, dtype=float32), 'eval/episode_reward_linvel_std': Array(1133.9692, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.985237, dtype=float32), 'eval/episode_x_position_std': Array(542.67303, dtype=float32), 'eval/episode_x_velocity_std': Array(226.79398, dtype=float32), 'eval/episode_y_position_std': Array(494.95862, dtype=float32), 'eval/episode_y_velocity_std': Array(161.98221, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5880527496338, 'eval/sps': 937.1244221090427, 'num_steps': 46858240}
{'eval/walltime': 78388.34543466568, 'training/sps': 2949.285614924982, 'training/walltime': 15963.232992887497, 'training/entropy_loss': Array(0.0195655, dtype=float32), 'training/policy_loss': Array(0.00446877, dtype=float32), 'training/total_loss': Array(0.33406684, dtype=float32), 'training/v_loss': Array(0.31003258, dtype=float32), 'eval/episode_distance_from_origin': Array(7296.9346, dtype=float32), 'eval/episode_distance_reward': Array(36.58438, dtype=float32), 'eval/episode_forward_reward': Array(6097.3647, dtype=float32), 'eval/episode_reward': Array(6126.032, dtype=float32), 'eval/episode_reward_alive': Array(423.98047, dtype=float32), 'eval/episode_reward_linvel': Array(6097.3647, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.89804, dtype=float32), 'eval/episode_x_position': Array(7250.166, dtype=float32), 'eval/episode_x_velocity': Array(1219.4731, dtype=float32), 'eval/episode_y_position': Array(106.25912, dtype=float32), 'eval/episode_y_velocity': Array(-15.448593, dtype=float32), 'eval/episode_distance_from_origin_std': Array(593.51105, dtype=float32), 'eval/episode_distance_reward_std': Array(7.105791, dtype=float32), 'eval/episode_forward_reward_std': Array(1184.2908, dtype=float32), 'eval/episode_reward_std': Array(1195.8279, dtype=float32), 'eval/episode_reward_alive_std': Array(43.77907, dtype=float32), 'eval/episode_reward_linvel_std': Array(1184.2908, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.007612, dtype=float32), 'eval/episode_x_position_std': Array(596.32086, dtype=float32), 'eval/episode_x_velocity_std': Array(236.85818, dtype=float32), 'eval/episode_y_position_std': Array(479.18637, dtype=float32), 'eval/episode_y_velocity_std': Array(163.4681, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33518147468567, 'eval/sps': 938.8625783563186, 'num_steps': 46940160}
{'eval/walltime': 78524.78631401062, 'training/sps': 2943.495462257937, 'training/walltime': 15991.063849449158, 'training/entropy_loss': Array(0.01950937, dtype=float32), 'training/policy_loss': Array(0.00725689, dtype=float32), 'training/total_loss': Array(0.35794267, dtype=float32), 'training/v_loss': Array(0.3311764, dtype=float32), 'eval/episode_distance_from_origin': Array(7361.1313, dtype=float32), 'eval/episode_distance_reward': Array(37.510532, dtype=float32), 'eval/episode_forward_reward': Array(6251.7236, dtype=float32), 'eval/episode_reward': Array(6283.6396, dtype=float32), 'eval/episode_reward_alive': Array(423.70312, dtype=float32), 'eval/episode_reward_linvel': Array(6251.7236, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.29752, dtype=float32), 'eval/episode_x_position': Array(7311.542, dtype=float32), 'eval/episode_x_velocity': Array(1250.3447, dtype=float32), 'eval/episode_y_position': Array(176.29494, dtype=float32), 'eval/episode_y_velocity': Array(-3.7429109, dtype=float32), 'eval/episode_distance_from_origin_std': Array(511.573, dtype=float32), 'eval/episode_distance_reward_std': Array(6.543957, dtype=float32), 'eval/episode_forward_reward_std': Array(1090.6519, dtype=float32), 'eval/episode_reward_std': Array(1101.4421, dtype=float32), 'eval/episode_reward_alive_std': Array(47.914776, dtype=float32), 'eval/episode_reward_linvel_std': Array(1090.6519, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.50564, dtype=float32), 'eval/episode_x_position_std': Array(513.463, dtype=float32), 'eval/episode_x_velocity_std': Array(218.13022, dtype=float32), 'eval/episode_y_position_std': Array(504.03653, dtype=float32), 'eval/episode_y_velocity_std': Array(174.62384, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44087934494019, 'eval/sps': 938.1352613273581, 'num_steps': 47022080}
{'eval/walltime': 78661.12070417404, 'training/sps': 2948.289210668066, 'training/walltime': 16018.849454641342, 'training/entropy_loss': Array(0.02000519, dtype=float32), 'training/policy_loss': Array(0.00467099, dtype=float32), 'training/total_loss': Array(0.32567105, dtype=float32), 'training/v_loss': Array(0.30099487, dtype=float32), 'eval/episode_distance_from_origin': Array(7312.437, dtype=float32), 'eval/episode_distance_reward': Array(37.217762, dtype=float32), 'eval/episode_forward_reward': Array(6202.9287, dtype=float32), 'eval/episode_reward': Array(6236.8384, dtype=float32), 'eval/episode_reward_alive': Array(428.75, dtype=float32), 'eval/episode_reward_linvel': Array(6202.9287, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.05753, dtype=float32), 'eval/episode_x_position': Array(7260.1943, dtype=float32), 'eval/episode_x_velocity': Array(1240.5857, dtype=float32), 'eval/episode_y_position': Array(131.75922, dtype=float32), 'eval/episode_y_velocity': Array(-4.6911926, dtype=float32), 'eval/episode_distance_from_origin_std': Array(535.2986, dtype=float32), 'eval/episode_distance_reward_std': Array(6.908873, dtype=float32), 'eval/episode_forward_reward_std': Array(1151.4713, dtype=float32), 'eval/episode_reward_std': Array(1169.6597, dtype=float32), 'eval/episode_reward_alive_std': Array(40.247864, dtype=float32), 'eval/episode_reward_linvel_std': Array(1151.4713, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.629704, dtype=float32), 'eval/episode_x_position_std': Array(538.61115, dtype=float32), 'eval/episode_x_velocity_std': Array(230.29443, dtype=float32), 'eval/episode_y_position_std': Array(537.3988, dtype=float32), 'eval/episode_y_velocity_std': Array(178.88002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33439016342163, 'eval/sps': 938.8680276969637, 'num_steps': 47104000}
{'eval/walltime': 78797.65554261208, 'training/sps': 2950.7087704526207, 'training/walltime': 16046.612275838852, 'training/entropy_loss': Array(0.01398665, dtype=float32), 'training/policy_loss': Array(0.0048646, dtype=float32), 'training/total_loss': Array(0.07434305, dtype=float32), 'training/v_loss': Array(0.05549179, dtype=float32), 'eval/episode_distance_from_origin': Array(7363.335, dtype=float32), 'eval/episode_distance_reward': Array(37.054398, dtype=float32), 'eval/episode_forward_reward': Array(6175.702, dtype=float32), 'eval/episode_reward': Array(6210.6396, dtype=float32), 'eval/episode_reward_alive': Array(424.02734, dtype=float32), 'eval/episode_reward_linvel': Array(6175.702, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.14417, dtype=float32), 'eval/episode_x_position': Array(7312.684, dtype=float32), 'eval/episode_x_velocity': Array(1235.1406, dtype=float32), 'eval/episode_y_position': Array(121.61247, dtype=float32), 'eval/episode_y_velocity': Array(-21.50774, dtype=float32), 'eval/episode_distance_from_origin_std': Array(531.05774, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4884133, dtype=float32), 'eval/episode_forward_reward_std': Array(1081.3961, dtype=float32), 'eval/episode_reward_std': Array(1087.8113, dtype=float32), 'eval/episode_reward_alive_std': Array(43.195744, dtype=float32), 'eval/episode_reward_linvel_std': Array(1081.3961, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.085066, dtype=float32), 'eval/episode_x_position_std': Array(534.5039, dtype=float32), 'eval/episode_x_velocity_std': Array(216.27922, dtype=float32), 'eval/episode_y_position_std': Array(522.91925, dtype=float32), 'eval/episode_y_velocity_std': Array(175.8891, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53483843803406, 'eval/sps': 937.4896653801105, 'num_steps': 47185920}
{'eval/walltime': 78933.99679923058, 'training/sps': 2951.733005022984, 'training/walltime': 16074.365463495255, 'training/entropy_loss': Array(0.01809676, dtype=float32), 'training/policy_loss': Array(0.00441025, dtype=float32), 'training/total_loss': Array(0.27590948, dtype=float32), 'training/v_loss': Array(0.25340247, dtype=float32), 'eval/episode_distance_from_origin': Array(7410.2314, dtype=float32), 'eval/episode_distance_reward': Array(38.37455, dtype=float32), 'eval/episode_forward_reward': Array(6395.7256, dtype=float32), 'eval/episode_reward': Array(6434.894, dtype=float32), 'eval/episode_reward_alive': Array(429.0625, dtype=float32), 'eval/episode_reward_linvel': Array(6395.7256, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.2689, dtype=float32), 'eval/episode_x_position': Array(7357.9634, dtype=float32), 'eval/episode_x_velocity': Array(1279.1453, dtype=float32), 'eval/episode_y_position': Array(203.60422, dtype=float32), 'eval/episode_y_velocity': Array(16.792057, dtype=float32), 'eval/episode_distance_from_origin_std': Array(580.4933, dtype=float32), 'eval/episode_distance_reward_std': Array(7.764632, dtype=float32), 'eval/episode_forward_reward_std': Array(1294.0981, dtype=float32), 'eval/episode_reward_std': Array(1301.4535, dtype=float32), 'eval/episode_reward_alive_std': Array(39.31896, dtype=float32), 'eval/episode_reward_linvel_std': Array(1294.0981, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.53723, dtype=float32), 'eval/episode_x_position_std': Array(586.71533, dtype=float32), 'eval/episode_x_velocity_std': Array(258.81955, dtype=float32), 'eval/episode_y_position_std': Array(511.22037, dtype=float32), 'eval/episode_y_velocity_std': Array(177.72664, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34125661849976, 'eval/sps': 938.820744172546, 'num_steps': 47267840}
{'eval/walltime': 79070.5384478569, 'training/sps': 2945.766985313748, 'training/walltime': 16102.174859285355, 'training/entropy_loss': Array(0.0184813, dtype=float32), 'training/policy_loss': Array(0.0128594, dtype=float32), 'training/total_loss': Array(0.37702248, dtype=float32), 'training/v_loss': Array(0.3456818, dtype=float32), 'eval/episode_distance_from_origin': Array(7414.258, dtype=float32), 'eval/episode_distance_reward': Array(38.753304, dtype=float32), 'eval/episode_forward_reward': Array(6458.851, dtype=float32), 'eval/episode_reward': Array(6491.998, dtype=float32), 'eval/episode_reward_alive': Array(422.59766, dtype=float32), 'eval/episode_reward_linvel': Array(6458.851, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.20355, dtype=float32), 'eval/episode_x_position': Array(7367.6226, dtype=float32), 'eval/episode_x_velocity': Array(1291.7701, dtype=float32), 'eval/episode_y_position': Array(113.90297, dtype=float32), 'eval/episode_y_velocity': Array(-15.70451, dtype=float32), 'eval/episode_distance_from_origin_std': Array(608.0978, dtype=float32), 'eval/episode_distance_reward_std': Array(7.4843597, dtype=float32), 'eval/episode_forward_reward_std': Array(1247.3857, dtype=float32), 'eval/episode_reward_std': Array(1256.3606, dtype=float32), 'eval/episode_reward_alive_std': Array(41.090225, dtype=float32), 'eval/episode_reward_linvel_std': Array(1247.3857, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.556269, dtype=float32), 'eval/episode_x_position_std': Array(614.2316, dtype=float32), 'eval/episode_x_velocity_std': Array(249.47711, dtype=float32), 'eval/episode_y_position_std': Array(485.78207, dtype=float32), 'eval/episode_y_velocity_std': Array(166.38962, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54164862632751, 'eval/sps': 937.442906891337, 'num_steps': 47349760}
{'eval/walltime': 79206.80434560776, 'training/sps': 2952.0704741912714, 'training/walltime': 16129.924874305725, 'training/entropy_loss': Array(0.01970579, dtype=float32), 'training/policy_loss': Array(0.00468718, dtype=float32), 'training/total_loss': Array(0.35661775, dtype=float32), 'training/v_loss': Array(0.3322248, dtype=float32), 'eval/episode_distance_from_origin': Array(7337.67, dtype=float32), 'eval/episode_distance_reward': Array(37.529476, dtype=float32), 'eval/episode_forward_reward': Array(6254.88, dtype=float32), 'eval/episode_reward': Array(6285.293, dtype=float32), 'eval/episode_reward_alive': Array(423.66406, dtype=float32), 'eval/episode_reward_linvel': Array(6254.88, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.7805, dtype=float32), 'eval/episode_x_position': Array(7289.718, dtype=float32), 'eval/episode_x_velocity': Array(1250.9761, dtype=float32), 'eval/episode_y_position': Array(27.433487, dtype=float32), 'eval/episode_y_velocity': Array(-50.584404, dtype=float32), 'eval/episode_distance_from_origin_std': Array(542.16785, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5406556, dtype=float32), 'eval/episode_forward_reward_std': Array(1090.1022, dtype=float32), 'eval/episode_reward_std': Array(1102.944, dtype=float32), 'eval/episode_reward_alive_std': Array(42.366386, dtype=float32), 'eval/episode_reward_linvel_std': Array(1090.1022, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.93085, dtype=float32), 'eval/episode_x_position_std': Array(546.2549, dtype=float32), 'eval/episode_x_velocity_std': Array(218.02036, dtype=float32), 'eval/episode_y_position_std': Array(498.96906, dtype=float32), 'eval/episode_y_velocity_std': Array(168.10251, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2658977508545, 'eval/sps': 939.3399384050757, 'num_steps': 47431680}
{'eval/walltime': 79343.24470949173, 'training/sps': 2947.5830529669524, 'training/walltime': 16157.717136144638, 'training/entropy_loss': Array(0.02059096, dtype=float32), 'training/policy_loss': Array(0.00760898, dtype=float32), 'training/total_loss': Array(0.37097037, dtype=float32), 'training/v_loss': Array(0.34277043, dtype=float32), 'eval/episode_distance_from_origin': Array(7350.6465, dtype=float32), 'eval/episode_distance_reward': Array(37.721657, dtype=float32), 'eval/episode_forward_reward': Array(6286.912, dtype=float32), 'eval/episode_reward': Array(6319.973, dtype=float32), 'eval/episode_reward_alive': Array(422.1211, dtype=float32), 'eval/episode_reward_linvel': Array(6286.912, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.78128, dtype=float32), 'eval/episode_x_position': Array(7302.963, dtype=float32), 'eval/episode_x_velocity': Array(1257.3823, dtype=float32), 'eval/episode_y_position': Array(112.30844, dtype=float32), 'eval/episode_y_velocity': Array(-9.970337, dtype=float32), 'eval/episode_distance_from_origin_std': Array(555.54926, dtype=float32), 'eval/episode_distance_reward_std': Array(6.968888, dtype=float32), 'eval/episode_forward_reward_std': Array(1161.4745, dtype=float32), 'eval/episode_reward_std': Array(1174.9761, dtype=float32), 'eval/episode_reward_alive_std': Array(44.882866, dtype=float32), 'eval/episode_reward_linvel_std': Array(1161.4745, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.713562, dtype=float32), 'eval/episode_x_position_std': Array(559.50793, dtype=float32), 'eval/episode_x_velocity_std': Array(232.29486, dtype=float32), 'eval/episode_y_position_std': Array(490.03366, dtype=float32), 'eval/episode_y_velocity_std': Array(175.04259, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44036388397217, 'eval/sps': 938.1388055286207, 'num_steps': 47513600}
{'eval/walltime': 79479.51497936249, 'training/sps': 2953.9725673758257, 'training/walltime': 16185.44928264618, 'training/entropy_loss': Array(0.02023728, dtype=float32), 'training/policy_loss': Array(0.01836843, dtype=float32), 'training/total_loss': Array(0.35565543, dtype=float32), 'training/v_loss': Array(0.31704974, dtype=float32), 'eval/episode_distance_from_origin': Array(7341.211, dtype=float32), 'eval/episode_distance_reward': Array(37.832733, dtype=float32), 'eval/episode_forward_reward': Array(6305.423, dtype=float32), 'eval/episode_reward': Array(6335.7847, dtype=float32), 'eval/episode_reward_alive': Array(417.80078, dtype=float32), 'eval/episode_reward_linvel': Array(6305.423, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.2721, dtype=float32), 'eval/episode_x_position': Array(7292.0586, dtype=float32), 'eval/episode_x_velocity': Array(1261.0847, dtype=float32), 'eval/episode_y_position': Array(53.27841, dtype=float32), 'eval/episode_y_velocity': Array(-36.60478, dtype=float32), 'eval/episode_distance_from_origin_std': Array(562.10474, dtype=float32), 'eval/episode_distance_reward_std': Array(7.457893, dtype=float32), 'eval/episode_forward_reward_std': Array(1242.9747, dtype=float32), 'eval/episode_reward_std': Array(1253.5135, dtype=float32), 'eval/episode_reward_alive_std': Array(41.78761, dtype=float32), 'eval/episode_reward_linvel_std': Array(1242.9747, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.44292, dtype=float32), 'eval/episode_x_position_std': Array(566.89966, dtype=float32), 'eval/episode_x_velocity_std': Array(248.59503, dtype=float32), 'eval/episode_y_position_std': Array(507.19208, dtype=float32), 'eval/episode_y_velocity_std': Array(175.83002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27026987075806, 'eval/sps': 939.3098004531599, 'num_steps': 47595520}
{'eval/walltime': 79615.95276665688, 'training/sps': 2952.865037227352, 'training/walltime': 16213.19183063507, 'training/entropy_loss': Array(0.01289699, dtype=float32), 'training/policy_loss': Array(0.00228468, dtype=float32), 'training/total_loss': Array(0.10177927, dtype=float32), 'training/v_loss': Array(0.08659759, dtype=float32), 'eval/episode_distance_from_origin': Array(7309.508, dtype=float32), 'eval/episode_distance_reward': Array(37.43983, dtype=float32), 'eval/episode_forward_reward': Array(6239.9395, dtype=float32), 'eval/episode_reward': Array(6273.583, dtype=float32), 'eval/episode_reward_alive': Array(418.3672, dtype=float32), 'eval/episode_reward_linvel': Array(6239.9395, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.16364, dtype=float32), 'eval/episode_x_position': Array(7262.167, dtype=float32), 'eval/episode_x_velocity': Array(1247.9879, dtype=float32), 'eval/episode_y_position': Array(73.51691, dtype=float32), 'eval/episode_y_velocity': Array(-34.386635, dtype=float32), 'eval/episode_distance_from_origin_std': Array(514.42584, dtype=float32), 'eval/episode_distance_reward_std': Array(6.809416, dtype=float32), 'eval/episode_forward_reward_std': Array(1134.8955, dtype=float32), 'eval/episode_reward_std': Array(1140.4059, dtype=float32), 'eval/episode_reward_alive_std': Array(39.20297, dtype=float32), 'eval/episode_reward_linvel_std': Array(1134.8955, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.049904, dtype=float32), 'eval/episode_x_position_std': Array(519.3754, dtype=float32), 'eval/episode_x_velocity_std': Array(226.97896, dtype=float32), 'eval/episode_y_position_std': Array(476.11307, dtype=float32), 'eval/episode_y_velocity_std': Array(167.62856, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43778729438782, 'eval/sps': 938.1565220184798, 'num_steps': 47677440}
{'eval/walltime': 79752.21440434456, 'training/sps': 2956.38895299514, 'training/walltime': 16240.901310443878, 'training/entropy_loss': Array(0.01891834, dtype=float32), 'training/policy_loss': Array(0.00564546, dtype=float32), 'training/total_loss': Array(0.25317562, dtype=float32), 'training/v_loss': Array(0.22861183, dtype=float32), 'eval/episode_distance_from_origin': Array(7376.384, dtype=float32), 'eval/episode_distance_reward': Array(38.122963, dtype=float32), 'eval/episode_forward_reward': Array(6353.7954, dtype=float32), 'eval/episode_reward': Array(6377.347, dtype=float32), 'eval/episode_reward_alive': Array(407.53906, dtype=float32), 'eval/episode_reward_linvel': Array(6353.7954, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.1099, dtype=float32), 'eval/episode_x_position': Array(7327.2954, dtype=float32), 'eval/episode_x_velocity': Array(1270.759, dtype=float32), 'eval/episode_y_position': Array(43.809467, dtype=float32), 'eval/episode_y_velocity': Array(-44.033947, dtype=float32), 'eval/episode_distance_from_origin_std': Array(538.47534, dtype=float32), 'eval/episode_distance_reward_std': Array(6.432494, dtype=float32), 'eval/episode_forward_reward_std': Array(1072.0759, dtype=float32), 'eval/episode_reward_std': Array(1077.8656, dtype=float32), 'eval/episode_reward_alive_std': Array(43.373497, dtype=float32), 'eval/episode_reward_linvel_std': Array(1072.0759, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.329472, dtype=float32), 'eval/episode_x_position_std': Array(543.8981, dtype=float32), 'eval/episode_x_velocity_std': Array(214.41516, dtype=float32), 'eval/episode_y_position_std': Array(519.9473, dtype=float32), 'eval/episode_y_velocity_std': Array(174.31966, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2616376876831, 'eval/sps': 939.3693057864232, 'num_steps': 47759360}
{'eval/walltime': 79888.6617500782, 'training/sps': 2948.1743864262685, 'training/walltime': 16268.687997817993, 'training/entropy_loss': Array(0.01920493, dtype=float32), 'training/policy_loss': Array(0.00613512, dtype=float32), 'training/total_loss': Array(0.36966726, dtype=float32), 'training/v_loss': Array(0.3443272, dtype=float32), 'eval/episode_distance_from_origin': Array(7404.5923, dtype=float32), 'eval/episode_distance_reward': Array(38.22885, dtype=float32), 'eval/episode_forward_reward': Array(6371.4414, dtype=float32), 'eval/episode_reward': Array(6388.002, dtype=float32), 'eval/episode_reward_alive': Array(403.0547, dtype=float32), 'eval/episode_reward_linvel': Array(6371.4414, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.72324, dtype=float32), 'eval/episode_x_position': Array(7360.4297, dtype=float32), 'eval/episode_x_velocity': Array(1274.2881, dtype=float32), 'eval/episode_y_position': Array(34.120697, dtype=float32), 'eval/episode_y_velocity': Array(-58.128082, dtype=float32), 'eval/episode_distance_from_origin_std': Array(520.90814, dtype=float32), 'eval/episode_distance_reward_std': Array(6.574049, dtype=float32), 'eval/episode_forward_reward_std': Array(1095.6671, dtype=float32), 'eval/episode_reward_std': Array(1102.395, dtype=float32), 'eval/episode_reward_alive_std': Array(45.0296, dtype=float32), 'eval/episode_reward_linvel_std': Array(1095.6671, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.243994, dtype=float32), 'eval/episode_x_position_std': Array(526.66187, dtype=float32), 'eval/episode_x_velocity_std': Array(219.13339, dtype=float32), 'eval/episode_y_position_std': Array(445.45346, dtype=float32), 'eval/episode_y_velocity_std': Array(157.13283, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44734573364258, 'eval/sps': 938.0908020729655, 'num_steps': 47841280}
{'eval/walltime': 80024.9217569828, 'training/sps': 2952.172336211033, 'training/walltime': 16296.43705534935, 'training/entropy_loss': Array(0.0186834, dtype=float32), 'training/policy_loss': Array(0.00603981, dtype=float32), 'training/total_loss': Array(0.30986622, dtype=float32), 'training/v_loss': Array(0.28514302, dtype=float32), 'eval/episode_distance_from_origin': Array(7319.7666, dtype=float32), 'eval/episode_distance_reward': Array(37.09329, dtype=float32), 'eval/episode_forward_reward': Array(6182.1826, dtype=float32), 'eval/episode_reward': Array(6207.208, dtype=float32), 'eval/episode_reward_alive': Array(410.21484, dtype=float32), 'eval/episode_reward_linvel': Array(6182.1826, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.28308, dtype=float32), 'eval/episode_x_position': Array(7269.9854, dtype=float32), 'eval/episode_x_velocity': Array(1236.4364, dtype=float32), 'eval/episode_y_position': Array(-42.768, dtype=float32), 'eval/episode_y_velocity': Array(-59.006878, dtype=float32), 'eval/episode_distance_from_origin_std': Array(535.83014, dtype=float32), 'eval/episode_distance_reward_std': Array(6.49158, dtype=float32), 'eval/episode_forward_reward_std': Array(1081.9242, dtype=float32), 'eval/episode_reward_std': Array(1087.8931, dtype=float32), 'eval/episode_reward_alive_std': Array(43.644726, dtype=float32), 'eval/episode_reward_linvel_std': Array(1081.9242, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.16411, dtype=float32), 'eval/episode_x_position_std': Array(541.76105, dtype=float32), 'eval/episode_x_velocity_std': Array(216.38489, dtype=float32), 'eval/episode_y_position_std': Array(516.94336, dtype=float32), 'eval/episode_y_velocity_std': Array(180.60222, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26000690460205, 'eval/sps': 939.3805483190308, 'num_steps': 47923200}
{'eval/walltime': 80161.36627292633, 'training/sps': 2945.711374909937, 'training/walltime': 16324.246976137161, 'training/entropy_loss': Array(0.0200047, dtype=float32), 'training/policy_loss': Array(0.00837662, dtype=float32), 'training/total_loss': Array(0.3284143, dtype=float32), 'training/v_loss': Array(0.30003297, dtype=float32), 'eval/episode_distance_from_origin': Array(7340.686, dtype=float32), 'eval/episode_distance_reward': Array(37.87074, dtype=float32), 'eval/episode_forward_reward': Array(6311.7573, dtype=float32), 'eval/episode_reward': Array(6332.6924, dtype=float32), 'eval/episode_reward_alive': Array(410.0586, dtype=float32), 'eval/episode_reward_linvel': Array(6311.7573, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.99365, dtype=float32), 'eval/episode_x_position': Array(7295.8906, dtype=float32), 'eval/episode_x_velocity': Array(1262.3513, dtype=float32), 'eval/episode_y_position': Array(19.968582, dtype=float32), 'eval/episode_y_velocity': Array(-41.465645, dtype=float32), 'eval/episode_distance_from_origin_std': Array(666.7038, dtype=float32), 'eval/episode_distance_reward_std': Array(7.837624, dtype=float32), 'eval/episode_forward_reward_std': Array(1306.2628, dtype=float32), 'eval/episode_reward_std': Array(1313.0122, dtype=float32), 'eval/episode_reward_alive_std': Array(44.546043, dtype=float32), 'eval/episode_reward_linvel_std': Array(1306.2628, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.40496, dtype=float32), 'eval/episode_x_position_std': Array(670.1415, dtype=float32), 'eval/episode_x_velocity_std': Array(261.2526, dtype=float32), 'eval/episode_y_position_std': Array(462.84885, dtype=float32), 'eval/episode_y_velocity_std': Array(165.86607, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44451594352722, 'eval/sps': 938.110257600809, 'num_steps': 48005120}
{'eval/walltime': 80297.65074062347, 'training/sps': 2959.0676502788074, 'training/walltime': 16351.931371927261, 'training/entropy_loss': Array(0.02057862, dtype=float32), 'training/policy_loss': Array(0.00886121, dtype=float32), 'training/total_loss': Array(0.32709616, dtype=float32), 'training/v_loss': Array(0.2976563, dtype=float32), 'eval/episode_distance_from_origin': Array(7359.3135, dtype=float32), 'eval/episode_distance_reward': Array(37.93731, dtype=float32), 'eval/episode_forward_reward': Array(6322.853, dtype=float32), 'eval/episode_reward': Array(6350.1924, dtype=float32), 'eval/episode_reward_alive': Array(413.73828, dtype=float32), 'eval/episode_reward_linvel': Array(6322.853, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.3357, dtype=float32), 'eval/episode_x_position': Array(7313.541, dtype=float32), 'eval/episode_x_velocity': Array(1264.5706, dtype=float32), 'eval/episode_y_position': Array(-41.306053, dtype=float32), 'eval/episode_y_velocity': Array(-66.747765, dtype=float32), 'eval/episode_distance_from_origin_std': Array(554.0502, dtype=float32), 'eval/episode_distance_reward_std': Array(7.6165347, dtype=float32), 'eval/episode_forward_reward_std': Array(1269.4146, dtype=float32), 'eval/episode_reward_std': Array(1279.8795, dtype=float32), 'eval/episode_reward_alive_std': Array(44.309807, dtype=float32), 'eval/episode_reward_linvel_std': Array(1269.4146, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.15523, dtype=float32), 'eval/episode_x_position_std': Array(560.45624, dtype=float32), 'eval/episode_x_velocity_std': Array(253.88283, dtype=float32), 'eval/episode_y_position_std': Array(459.42978, dtype=float32), 'eval/episode_y_velocity_std': Array(164.66939, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28446769714355, 'eval/sps': 939.2119451531805, 'num_steps': 48087040}
{'eval/walltime': 80434.14436984062, 'training/sps': 2944.9974400354827, 'training/walltime': 16379.748034477234, 'training/entropy_loss': Array(0.01507039, dtype=float32), 'training/policy_loss': Array(0.00572842, dtype=float32), 'training/total_loss': Array(0.1615678, dtype=float32), 'training/v_loss': Array(0.140769, dtype=float32), 'eval/episode_distance_from_origin': Array(7330.619, dtype=float32), 'eval/episode_distance_reward': Array(37.765343, dtype=float32), 'eval/episode_forward_reward': Array(6294.191, dtype=float32), 'eval/episode_reward': Array(6322.38, dtype=float32), 'eval/episode_reward_alive': Array(416.15625, dtype=float32), 'eval/episode_reward_linvel': Array(6294.191, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.73312, dtype=float32), 'eval/episode_x_position': Array(7286.851, dtype=float32), 'eval/episode_x_velocity': Array(1258.8383, dtype=float32), 'eval/episode_y_position': Array(7.4646597, dtype=float32), 'eval/episode_y_velocity': Array(-58.68615, dtype=float32), 'eval/episode_distance_from_origin_std': Array(575.1444, dtype=float32), 'eval/episode_distance_reward_std': Array(7.1440477, dtype=float32), 'eval/episode_forward_reward_std': Array(1190.667, dtype=float32), 'eval/episode_reward_std': Array(1200.8641, dtype=float32), 'eval/episode_reward_alive_std': Array(38.814903, dtype=float32), 'eval/episode_reward_linvel_std': Array(1190.667, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.912287, dtype=float32), 'eval/episode_x_position_std': Array(577.07465, dtype=float32), 'eval/episode_x_velocity_std': Array(238.13362, dtype=float32), 'eval/episode_y_position_std': Array(440.45966, dtype=float32), 'eval/episode_y_velocity_std': Array(154.52571, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49362921714783, 'eval/sps': 937.7727058335059, 'num_steps': 48168960}
{'eval/walltime': 80570.52343964577, 'training/sps': 2948.8611124158615, 'training/walltime': 16407.528250932693, 'training/entropy_loss': Array(0.01767022, dtype=float32), 'training/policy_loss': Array(0.00573541, dtype=float32), 'training/total_loss': Array(0.16319838, dtype=float32), 'training/v_loss': Array(0.13979276, dtype=float32), 'eval/episode_distance_from_origin': Array(7249.8945, dtype=float32), 'eval/episode_distance_reward': Array(36.956554, dtype=float32), 'eval/episode_forward_reward': Array(6159.3936, dtype=float32), 'eval/episode_reward': Array(6184.6367, dtype=float32), 'eval/episode_reward_alive': Array(410.44922, dtype=float32), 'eval/episode_reward_linvel': Array(6159.3936, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.1622, dtype=float32), 'eval/episode_x_position': Array(7201.6514, dtype=float32), 'eval/episode_x_velocity': Array(1231.8787, dtype=float32), 'eval/episode_y_position': Array(-23.488892, dtype=float32), 'eval/episode_y_velocity': Array(-66.42107, dtype=float32), 'eval/episode_distance_from_origin_std': Array(592.43774, dtype=float32), 'eval/episode_distance_reward_std': Array(7.5855594, dtype=float32), 'eval/episode_forward_reward_std': Array(1264.2516, dtype=float32), 'eval/episode_reward_std': Array(1272.4883, dtype=float32), 'eval/episode_reward_alive_std': Array(46.144127, dtype=float32), 'eval/episode_reward_linvel_std': Array(1264.2516, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.081247, dtype=float32), 'eval/episode_x_position_std': Array(598.334, dtype=float32), 'eval/episode_x_velocity_std': Array(252.85027, dtype=float32), 'eval/episode_y_position_std': Array(479.55585, dtype=float32), 'eval/episode_y_velocity_std': Array(167.55376, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37906980514526, 'eval/sps': 938.5604417370125, 'num_steps': 48250880}
{'eval/walltime': 80707.08284020424, 'training/sps': 2946.1424736196054, 'training/walltime': 16435.334102392197, 'training/entropy_loss': Array(0.01771656, dtype=float32), 'training/policy_loss': Array(0.00870415, dtype=float32), 'training/total_loss': Array(0.31153753, dtype=float32), 'training/v_loss': Array(0.28511682, dtype=float32), 'eval/episode_distance_from_origin': Array(7259.2954, dtype=float32), 'eval/episode_distance_reward': Array(36.864338, dtype=float32), 'eval/episode_forward_reward': Array(6144.024, dtype=float32), 'eval/episode_reward': Array(6174.2334, dtype=float32), 'eval/episode_reward_alive': Array(414.91016, dtype=float32), 'eval/episode_reward_linvel': Array(6144.024, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.56522, dtype=float32), 'eval/episode_x_position': Array(7214.9395, dtype=float32), 'eval/episode_x_velocity': Array(1228.8047, dtype=float32), 'eval/episode_y_position': Array(-54.957996, dtype=float32), 'eval/episode_y_velocity': Array(-78.09446, dtype=float32), 'eval/episode_distance_from_origin_std': Array(659.6349, dtype=float32), 'eval/episode_distance_reward_std': Array(8.0388975, dtype=float32), 'eval/episode_forward_reward_std': Array(1339.807, dtype=float32), 'eval/episode_reward_std': Array(1349.8881, dtype=float32), 'eval/episode_reward_alive_std': Array(41.247272, dtype=float32), 'eval/episode_reward_linvel_std': Array(1339.807, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.55826, dtype=float32), 'eval/episode_x_position_std': Array(662.3277, dtype=float32), 'eval/episode_x_velocity_std': Array(267.96133, dtype=float32), 'eval/episode_y_position_std': Array(437.11334, dtype=float32), 'eval/episode_y_velocity_std': Array(148.71582, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55940055847168, 'eval/sps': 937.3210447360836, 'num_steps': 48332800}
{'eval/walltime': 80843.45393204689, 'training/sps': 2944.596856982284, 'training/walltime': 16463.154549121857, 'training/entropy_loss': Array(0.01798828, dtype=float32), 'training/policy_loss': Array(0.00500331, dtype=float32), 'training/total_loss': Array(0.34513396, dtype=float32), 'training/v_loss': Array(0.32214236, dtype=float32), 'eval/episode_distance_from_origin': Array(7278.2676, dtype=float32), 'eval/episode_distance_reward': Array(37.06507, dtype=float32), 'eval/episode_forward_reward': Array(6177.48, dtype=float32), 'eval/episode_reward': Array(6203.2334, dtype=float32), 'eval/episode_reward_alive': Array(413.59375, dtype=float32), 'eval/episode_reward_linvel': Array(6177.48, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.90524, dtype=float32), 'eval/episode_x_position': Array(7231.6533, dtype=float32), 'eval/episode_x_velocity': Array(1235.496, dtype=float32), 'eval/episode_y_position': Array(-79.26862, dtype=float32), 'eval/episode_y_velocity': Array(-90.59396, dtype=float32), 'eval/episode_distance_from_origin_std': Array(538.7373, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6779914, dtype=float32), 'eval/episode_forward_reward_std': Array(1112.992, dtype=float32), 'eval/episode_reward_std': Array(1130.8258, dtype=float32), 'eval/episode_reward_alive_std': Array(44.879864, dtype=float32), 'eval/episode_reward_linvel_std': Array(1112.992, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.795422, dtype=float32), 'eval/episode_x_position_std': Array(542.63824, dtype=float32), 'eval/episode_x_velocity_std': Array(222.59846, dtype=float32), 'eval/episode_y_position_std': Array(455.48102, dtype=float32), 'eval/episode_y_velocity_std': Array(156.49677, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37109184265137, 'eval/sps': 938.615349268376, 'num_steps': 48414720}
{'eval/walltime': 80979.98770332336, 'training/sps': 2942.768764128513, 'training/walltime': 16490.99227833748, 'training/entropy_loss': Array(0.01851241, dtype=float32), 'training/policy_loss': Array(0.00655349, dtype=float32), 'training/total_loss': Array(0.3300239, dtype=float32), 'training/v_loss': Array(0.304958, dtype=float32), 'eval/episode_distance_from_origin': Array(7260.041, dtype=float32), 'eval/episode_distance_reward': Array(37.08702, dtype=float32), 'eval/episode_forward_reward': Array(6181.1387, dtype=float32), 'eval/episode_reward': Array(6198.951, dtype=float32), 'eval/episode_reward_alive': Array(408.3828, dtype=float32), 'eval/episode_reward_linvel': Array(6181.1387, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.65646, dtype=float32), 'eval/episode_x_position': Array(7212.241, dtype=float32), 'eval/episode_x_velocity': Array(1236.2275, dtype=float32), 'eval/episode_y_position': Array(-221.25658, dtype=float32), 'eval/episode_y_velocity': Array(-125.20273, dtype=float32), 'eval/episode_distance_from_origin_std': Array(638.78876, dtype=float32), 'eval/episode_distance_reward_std': Array(7.5689044, dtype=float32), 'eval/episode_forward_reward_std': Array(1261.4758, dtype=float32), 'eval/episode_reward_std': Array(1277.2607, dtype=float32), 'eval/episode_reward_alive_std': Array(46.913754, dtype=float32), 'eval/episode_reward_linvel_std': Array(1261.4758, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.828197, dtype=float32), 'eval/episode_x_position_std': Array(640.88995, dtype=float32), 'eval/episode_x_velocity_std': Array(252.29509, dtype=float32), 'eval/episode_y_position_std': Array(427.2041, dtype=float32), 'eval/episode_y_velocity_std': Array(139.42847, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.533771276474, 'eval/sps': 937.4969928927434, 'num_steps': 48496640}
{'eval/walltime': 81116.33532881737, 'training/sps': 2952.264997186477, 'training/walltime': 16518.740464925766, 'training/entropy_loss': Array(0.01915769, dtype=float32), 'training/policy_loss': Array(0.01865767, dtype=float32), 'training/total_loss': Array(0.34268782, dtype=float32), 'training/v_loss': Array(0.30487245, dtype=float32), 'eval/episode_distance_from_origin': Array(7277.8535, dtype=float32), 'eval/episode_distance_reward': Array(37.127106, dtype=float32), 'eval/episode_forward_reward': Array(6187.818, dtype=float32), 'eval/episode_reward': Array(6206.393, dtype=float32), 'eval/episode_reward_alive': Array(405.5, dtype=float32), 'eval/episode_reward_linvel': Array(6187.818, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.05194, dtype=float32), 'eval/episode_x_position': Array(7228.823, dtype=float32), 'eval/episode_x_velocity': Array(1237.5635, dtype=float32), 'eval/episode_y_position': Array(-218.68823, dtype=float32), 'eval/episode_y_velocity': Array(-135.13075, dtype=float32), 'eval/episode_distance_from_origin_std': Array(542.7956, dtype=float32), 'eval/episode_distance_reward_std': Array(6.401749, dtype=float32), 'eval/episode_forward_reward_std': Array(1066.952, dtype=float32), 'eval/episode_reward_std': Array(1076.991, dtype=float32), 'eval/episode_reward_alive_std': Array(35.710697, dtype=float32), 'eval/episode_reward_linvel_std': Array(1066.952, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.00769, dtype=float32), 'eval/episode_x_position_std': Array(544.97784, dtype=float32), 'eval/episode_x_velocity_std': Array(213.39044, dtype=float32), 'eval/episode_y_position_std': Array(428.48624, dtype=float32), 'eval/episode_y_velocity_std': Array(140.28355, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3476254940033, 'eval/sps': 938.7768913190906, 'num_steps': 48578560}
{'eval/walltime': 81252.86417675018, 'training/sps': 2942.1080743337316, 'training/walltime': 16546.584445476532, 'training/entropy_loss': Array(0.01695589, dtype=float32), 'training/policy_loss': Array(0.01602053, dtype=float32), 'training/total_loss': Array(0.23726675, dtype=float32), 'training/v_loss': Array(0.20429033, dtype=float32), 'eval/episode_distance_from_origin': Array(7216.327, dtype=float32), 'eval/episode_distance_reward': Array(35.637833, dtype=float32), 'eval/episode_forward_reward': Array(5939.609, dtype=float32), 'eval/episode_reward': Array(5961.259, dtype=float32), 'eval/episode_reward_alive': Array(413.10547, dtype=float32), 'eval/episode_reward_linvel': Array(5939.609, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.0926, dtype=float32), 'eval/episode_x_position': Array(7168.8447, dtype=float32), 'eval/episode_x_velocity': Array(1187.9216, dtype=float32), 'eval/episode_y_position': Array(-166.0885, dtype=float32), 'eval/episode_y_velocity': Array(-111.14944, dtype=float32), 'eval/episode_distance_from_origin_std': Array(615.91364, dtype=float32), 'eval/episode_distance_reward_std': Array(7.348418, dtype=float32), 'eval/episode_forward_reward_std': Array(1224.7285, dtype=float32), 'eval/episode_reward_std': Array(1230.5939, dtype=float32), 'eval/episode_reward_alive_std': Array(48.104645, dtype=float32), 'eval/episode_reward_linvel_std': Array(1224.7285, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.94745, dtype=float32), 'eval/episode_x_position_std': Array(619.26166, dtype=float32), 'eval/episode_x_velocity_std': Array(244.94594, dtype=float32), 'eval/episode_y_position_std': Array(444.475, dtype=float32), 'eval/episode_y_velocity_std': Array(144.08145, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52884793281555, 'eval/sps': 937.5307998129999, 'num_steps': 48660480}
{'eval/walltime': 81389.25014996529, 'training/sps': 2948.4809332016644, 'training/walltime': 16574.368243932724, 'training/entropy_loss': Array(0.01568743, dtype=float32), 'training/policy_loss': Array(0.00583641, dtype=float32), 'training/total_loss': Array(0.08740554, dtype=float32), 'training/v_loss': Array(0.0658817, dtype=float32), 'eval/episode_distance_from_origin': Array(7247.121, dtype=float32), 'eval/episode_distance_reward': Array(35.761482, dtype=float32), 'eval/episode_forward_reward': Array(5960.2173, dtype=float32), 'eval/episode_reward': Array(5978.935, dtype=float32), 'eval/episode_reward_alive': Array(408.98828, dtype=float32), 'eval/episode_reward_linvel': Array(5960.2173, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.0315, dtype=float32), 'eval/episode_x_position': Array(7198.9775, dtype=float32), 'eval/episode_x_velocity': Array(1192.0435, dtype=float32), 'eval/episode_y_position': Array(-200.8281, dtype=float32), 'eval/episode_y_velocity': Array(-102.8323, dtype=float32), 'eval/episode_distance_from_origin_std': Array(600.60095, dtype=float32), 'eval/episode_distance_reward_std': Array(7.4380746, dtype=float32), 'eval/episode_forward_reward_std': Array(1239.67, dtype=float32), 'eval/episode_reward_std': Array(1252.2576, dtype=float32), 'eval/episode_reward_alive_std': Array(50.354153, dtype=float32), 'eval/episode_reward_linvel_std': Array(1239.67, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.818325, dtype=float32), 'eval/episode_x_position_std': Array(603.32855, dtype=float32), 'eval/episode_x_velocity_std': Array(247.93399, dtype=float32), 'eval/episode_y_position_std': Array(458.11533, dtype=float32), 'eval/episode_y_velocity_std': Array(149.66606, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38597321510315, 'eval/sps': 938.5129348904737, 'num_steps': 48742400}
{'eval/walltime': 81525.83311080933, 'training/sps': 2944.204380204013, 'training/walltime': 16602.192399263382, 'training/entropy_loss': Array(0.01886747, dtype=float32), 'training/policy_loss': Array(0.00642664, dtype=float32), 'training/total_loss': Array(0.2970972, dtype=float32), 'training/v_loss': Array(0.27180308, dtype=float32), 'eval/episode_distance_from_origin': Array(7262.9336, dtype=float32), 'eval/episode_distance_reward': Array(36.304893, dtype=float32), 'eval/episode_forward_reward': Array(6050.785, dtype=float32), 'eval/episode_reward': Array(6065.871, dtype=float32), 'eval/episode_reward_alive': Array(404.52344, dtype=float32), 'eval/episode_reward_linvel': Array(6050.785, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.7426, dtype=float32), 'eval/episode_x_position': Array(7214.6357, dtype=float32), 'eval/episode_x_velocity': Array(1210.1571, dtype=float32), 'eval/episode_y_position': Array(-221.89911, dtype=float32), 'eval/episode_y_velocity': Array(-114.0563, dtype=float32), 'eval/episode_distance_from_origin_std': Array(587.45245, dtype=float32), 'eval/episode_distance_reward_std': Array(6.9025846, dtype=float32), 'eval/episode_forward_reward_std': Array(1150.4232, dtype=float32), 'eval/episode_reward_std': Array(1157.4908, dtype=float32), 'eval/episode_reward_alive_std': Array(46.04413, dtype=float32), 'eval/episode_reward_linvel_std': Array(1150.4232, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.454782, dtype=float32), 'eval/episode_x_position_std': Array(593.57416, dtype=float32), 'eval/episode_x_velocity_std': Array(230.08463, dtype=float32), 'eval/episode_y_position_std': Array(424.41168, dtype=float32), 'eval/episode_y_velocity_std': Array(144.86671, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58296084403992, 'eval/sps': 937.1593587443126, 'num_steps': 48824320}
{'eval/walltime': 81662.25990986824, 'training/sps': 2958.568970278589, 'training/walltime': 16629.881461381912, 'training/entropy_loss': Array(0.01905621, dtype=float32), 'training/policy_loss': Array(0.0063429, dtype=float32), 'training/total_loss': Array(0.31623995, dtype=float32), 'training/v_loss': Array(0.29084083, dtype=float32), 'eval/episode_distance_from_origin': Array(7289.7, dtype=float32), 'eval/episode_distance_reward': Array(37.07292, dtype=float32), 'eval/episode_forward_reward': Array(6178.7896, dtype=float32), 'eval/episode_reward': Array(6198.0566, dtype=float32), 'eval/episode_reward_alive': Array(405.34375, dtype=float32), 'eval/episode_reward_linvel': Array(6178.7896, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.14874, dtype=float32), 'eval/episode_x_position': Array(7243.6953, dtype=float32), 'eval/episode_x_velocity': Array(1235.7578, dtype=float32), 'eval/episode_y_position': Array(-202.86383, dtype=float32), 'eval/episode_y_velocity': Array(-111.94698, dtype=float32), 'eval/episode_distance_from_origin_std': Array(569.4449, dtype=float32), 'eval/episode_distance_reward_std': Array(6.384644, dtype=float32), 'eval/episode_forward_reward_std': Array(1064.1005, dtype=float32), 'eval/episode_reward_std': Array(1074.0209, dtype=float32), 'eval/episode_reward_alive_std': Array(46.97746, dtype=float32), 'eval/episode_reward_linvel_std': Array(1064.1005, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.814117, dtype=float32), 'eval/episode_x_position_std': Array(575.45404, dtype=float32), 'eval/episode_x_velocity_std': Array(212.82005, dtype=float32), 'eval/episode_y_position_std': Array(404.57056, dtype=float32), 'eval/episode_y_velocity_std': Array(141.32597, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42679905891418, 'eval/sps': 938.2320840403565, 'num_steps': 48906240}
{'eval/walltime': 81798.82173585892, 'training/sps': 2952.667644073554, 'training/walltime': 16657.62586402893, 'training/entropy_loss': Array(0.0210482, dtype=float32), 'training/policy_loss': Array(0.00711844, dtype=float32), 'training/total_loss': Array(0.27766222, dtype=float32), 'training/v_loss': Array(0.24949555, dtype=float32), 'eval/episode_distance_from_origin': Array(7211.422, dtype=float32), 'eval/episode_distance_reward': Array(35.922394, dtype=float32), 'eval/episode_forward_reward': Array(5987.036, dtype=float32), 'eval/episode_reward': Array(6005.7725, dtype=float32), 'eval/episode_reward_alive': Array(412.14844, dtype=float32), 'eval/episode_reward_linvel': Array(5987.036, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.3334, dtype=float32), 'eval/episode_x_position': Array(7163.8926, dtype=float32), 'eval/episode_x_velocity': Array(1197.407, dtype=float32), 'eval/episode_y_position': Array(-172.53809, dtype=float32), 'eval/episode_y_velocity': Array(-113.37756, dtype=float32), 'eval/episode_distance_from_origin_std': Array(638.92896, dtype=float32), 'eval/episode_distance_reward_std': Array(7.575884, dtype=float32), 'eval/episode_forward_reward_std': Array(1262.6393, dtype=float32), 'eval/episode_reward_std': Array(1278.0724, dtype=float32), 'eval/episode_reward_alive_std': Array(46.740738, dtype=float32), 'eval/episode_reward_linvel_std': Array(1262.6393, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.449787, dtype=float32), 'eval/episode_x_position_std': Array(639.8099, dtype=float32), 'eval/episode_x_velocity_std': Array(252.5278, dtype=float32), 'eval/episode_y_position_std': Array(444.0001, dtype=float32), 'eval/episode_y_velocity_std': Array(156.60034, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56182599067688, 'eval/sps': 937.3043972679349, 'num_steps': 48988160}
{'eval/walltime': 81935.24080109596, 'training/sps': 2956.7789094073737, 'training/walltime': 16685.331689357758, 'training/entropy_loss': Array(0.02216714, dtype=float32), 'training/policy_loss': Array(0.00819868, dtype=float32), 'training/total_loss': Array(0.31605983, dtype=float32), 'training/v_loss': Array(0.285694, dtype=float32), 'eval/episode_distance_from_origin': Array(7334.2305, dtype=float32), 'eval/episode_distance_reward': Array(37.137856, dtype=float32), 'eval/episode_forward_reward': Array(6189.6113, dtype=float32), 'eval/episode_reward': Array(6208.5205, dtype=float32), 'eval/episode_reward_alive': Array(407.1836, dtype=float32), 'eval/episode_reward_linvel': Array(6189.6113, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.41223, dtype=float32), 'eval/episode_x_position': Array(7284.237, dtype=float32), 'eval/episode_x_velocity': Array(1237.9221, dtype=float32), 'eval/episode_y_position': Array(-292.64023, dtype=float32), 'eval/episode_y_velocity': Array(-135.03505, dtype=float32), 'eval/episode_distance_from_origin_std': Array(587.0116, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5094895, dtype=float32), 'eval/episode_forward_reward_std': Array(1084.908, dtype=float32), 'eval/episode_reward_std': Array(1092.6427, dtype=float32), 'eval/episode_reward_alive_std': Array(49.64691, dtype=float32), 'eval/episode_reward_linvel_std': Array(1084.908, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.464474, dtype=float32), 'eval/episode_x_position_std': Array(592.5022, dtype=float32), 'eval/episode_x_velocity_std': Array(216.98157, dtype=float32), 'eval/episode_y_position_std': Array(419.00778, dtype=float32), 'eval/episode_y_velocity_std': Array(139.75844, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4190652370453, 'eval/sps': 938.2852739650715, 'num_steps': 49070080}
{'eval/walltime': 82071.83862662315, 'training/sps': 2945.3647537568454, 'training/walltime': 16713.144882917404, 'training/entropy_loss': Array(0.02365843, dtype=float32), 'training/policy_loss': Array(0.01074144, dtype=float32), 'training/total_loss': Array(0.2952621, dtype=float32), 'training/v_loss': Array(0.26086226, dtype=float32), 'eval/episode_distance_from_origin': Array(7308.66, dtype=float32), 'eval/episode_distance_reward': Array(37.176643, dtype=float32), 'eval/episode_forward_reward': Array(6196.0757, dtype=float32), 'eval/episode_reward': Array(6210.918, dtype=float32), 'eval/episode_reward_alive': Array(402.34375, dtype=float32), 'eval/episode_reward_linvel': Array(6196.0757, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.67734, dtype=float32), 'eval/episode_x_position': Array(7259.6445, dtype=float32), 'eval/episode_x_velocity': Array(1239.2148, dtype=float32), 'eval/episode_y_position': Array(-266.59583, dtype=float32), 'eval/episode_y_velocity': Array(-125.374855, dtype=float32), 'eval/episode_distance_from_origin_std': Array(553.9205, dtype=float32), 'eval/episode_distance_reward_std': Array(6.7083325, dtype=float32), 'eval/episode_forward_reward_std': Array(1118.0491, dtype=float32), 'eval/episode_reward_std': Array(1128.498, dtype=float32), 'eval/episode_reward_alive_std': Array(43.433758, dtype=float32), 'eval/episode_reward_linvel_std': Array(1118.0491, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.660347, dtype=float32), 'eval/episode_x_position_std': Array(559.06866, dtype=float32), 'eval/episode_x_velocity_std': Array(223.60977, dtype=float32), 'eval/episode_y_position_std': Array(421.82672, dtype=float32), 'eval/episode_y_velocity_std': Array(146.36604, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59782552719116, 'eval/sps': 937.0573763234637, 'num_steps': 49152000}
{'eval/walltime': 82208.23146533966, 'training/sps': 2954.171100221138, 'training/walltime': 16740.875165700912, 'training/entropy_loss': Array(0.01362077, dtype=float32), 'training/policy_loss': Array(0.00333125, dtype=float32), 'training/total_loss': Array(0.05755535, dtype=float32), 'training/v_loss': Array(0.04060334, dtype=float32), 'eval/episode_distance_from_origin': Array(7262.353, dtype=float32), 'eval/episode_distance_reward': Array(36.394905, dtype=float32), 'eval/episode_forward_reward': Array(6065.7856, dtype=float32), 'eval/episode_reward': Array(6085.8647, dtype=float32), 'eval/episode_reward_alive': Array(412.76172, dtype=float32), 'eval/episode_reward_linvel': Array(6065.7856, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.07846, dtype=float32), 'eval/episode_x_position': Array(7211.9883, dtype=float32), 'eval/episode_x_velocity': Array(1213.1571, dtype=float32), 'eval/episode_y_position': Array(-296.85138, dtype=float32), 'eval/episode_y_velocity': Array(-145.0292, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.39655, dtype=float32), 'eval/episode_distance_reward_std': Array(6.716308, dtype=float32), 'eval/episode_forward_reward_std': Array(1119.3779, dtype=float32), 'eval/episode_reward_std': Array(1133.0464, dtype=float32), 'eval/episode_reward_alive_std': Array(45.444286, dtype=float32), 'eval/episode_reward_linvel_std': Array(1119.3779, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.807137, dtype=float32), 'eval/episode_x_position_std': Array(532.3954, dtype=float32), 'eval/episode_x_velocity_std': Array(223.8756, dtype=float32), 'eval/episode_y_position_std': Array(409.7927, dtype=float32), 'eval/episode_y_velocity_std': Array(134.74536, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39283871650696, 'eval/sps': 938.4656936868107, 'num_steps': 49233920}
{'eval/walltime': 82344.77981066704, 'training/sps': 2963.6207067926944, 'training/walltime': 16768.51702952385, 'training/entropy_loss': Array(0.01746123, dtype=float32), 'training/policy_loss': Array(0.01026138, dtype=float32), 'training/total_loss': Array(0.26952332, dtype=float32), 'training/v_loss': Array(0.24180073, dtype=float32), 'eval/episode_distance_from_origin': Array(7303.1836, dtype=float32), 'eval/episode_distance_reward': Array(36.62683, dtype=float32), 'eval/episode_forward_reward': Array(6104.441, dtype=float32), 'eval/episode_reward': Array(6121.051, dtype=float32), 'eval/episode_reward_alive': Array(404.6172, dtype=float32), 'eval/episode_reward_linvel': Array(6104.441, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.6341, dtype=float32), 'eval/episode_x_position': Array(7254.8584, dtype=float32), 'eval/episode_x_velocity': Array(1220.8882, dtype=float32), 'eval/episode_y_position': Array(-246.46751, dtype=float32), 'eval/episode_y_velocity': Array(-127.505, dtype=float32), 'eval/episode_distance_from_origin_std': Array(557.41644, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5596943, dtype=float32), 'eval/episode_forward_reward_std': Array(1093.275, dtype=float32), 'eval/episode_reward_std': Array(1106.6107, dtype=float32), 'eval/episode_reward_alive_std': Array(49.549118, dtype=float32), 'eval/episode_reward_linvel_std': Array(1093.275, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.893394, dtype=float32), 'eval/episode_x_position_std': Array(558.85406, dtype=float32), 'eval/episode_x_velocity_std': Array(218.6551, dtype=float32), 'eval/episode_y_position_std': Array(426.75873, dtype=float32), 'eval/episode_y_velocity_std': Array(136.64674, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54834532737732, 'eval/sps': 937.3969321496903, 'num_steps': 49315840}
{'eval/walltime': 82481.19735836983, 'training/sps': 2950.610227337748, 'training/walltime': 16796.280777931213, 'training/entropy_loss': Array(0.01863201, dtype=float32), 'training/policy_loss': Array(0.00524845, dtype=float32), 'training/total_loss': Array(0.27932408, dtype=float32), 'training/v_loss': Array(0.2554436, dtype=float32), 'eval/episode_distance_from_origin': Array(7412.0728, dtype=float32), 'eval/episode_distance_reward': Array(38.430695, dtype=float32), 'eval/episode_forward_reward': Array(6405.083, dtype=float32), 'eval/episode_reward': Array(6425.1084, dtype=float32), 'eval/episode_reward_alive': Array(401.3789, dtype=float32), 'eval/episode_reward_linvel': Array(6405.083, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.78418, dtype=float32), 'eval/episode_x_position': Array(7364.833, dtype=float32), 'eval/episode_x_velocity': Array(1281.0166, dtype=float32), 'eval/episode_y_position': Array(-169.83708, dtype=float32), 'eval/episode_y_velocity': Array(-106.306015, dtype=float32), 'eval/episode_distance_from_origin_std': Array(503.20355, dtype=float32), 'eval/episode_distance_reward_std': Array(6.586283, dtype=float32), 'eval/episode_forward_reward_std': Array(1097.7079, dtype=float32), 'eval/episode_reward_std': Array(1110.0098, dtype=float32), 'eval/episode_reward_alive_std': Array(48.644028, dtype=float32), 'eval/episode_reward_linvel_std': Array(1097.7079, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.686205, dtype=float32), 'eval/episode_x_position_std': Array(509.24054, dtype=float32), 'eval/episode_x_velocity_std': Array(219.54158, dtype=float32), 'eval/episode_y_position_std': Array(444.88925, dtype=float32), 'eval/episode_y_velocity_std': Array(143.19977, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4175477027893, 'eval/sps': 938.2957116255419, 'num_steps': 49397760}
{'eval/walltime': 82617.76787948608, 'training/sps': 2957.0253819359555, 'training/walltime': 16823.984293937683, 'training/entropy_loss': Array(0.01945567, dtype=float32), 'training/policy_loss': Array(0.00635377, dtype=float32), 'training/total_loss': Array(0.29187587, dtype=float32), 'training/v_loss': Array(0.26606643, dtype=float32), 'eval/episode_distance_from_origin': Array(7317.8906, dtype=float32), 'eval/episode_distance_reward': Array(37.502045, dtype=float32), 'eval/episode_forward_reward': Array(6250.3086, dtype=float32), 'eval/episode_reward': Array(6281.2393, dtype=float32), 'eval/episode_reward_alive': Array(412.19922, dtype=float32), 'eval/episode_reward_linvel': Array(6250.3086, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.76984, dtype=float32), 'eval/episode_x_position': Array(7270.0225, dtype=float32), 'eval/episode_x_velocity': Array(1250.0616, dtype=float32), 'eval/episode_y_position': Array(-85.24995, dtype=float32), 'eval/episode_y_velocity': Array(-91.9608, dtype=float32), 'eval/episode_distance_from_origin_std': Array(546.1918, dtype=float32), 'eval/episode_distance_reward_std': Array(7.0146585, dtype=float32), 'eval/episode_forward_reward_std': Array(1169.1018, dtype=float32), 'eval/episode_reward_std': Array(1174.4808, dtype=float32), 'eval/episode_reward_alive_std': Array(40.35455, dtype=float32), 'eval/episode_reward_linvel_std': Array(1169.1018, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.309362, dtype=float32), 'eval/episode_x_position_std': Array(552.65704, dtype=float32), 'eval/episode_x_velocity_std': Array(233.82043, dtype=float32), 'eval/episode_y_position_std': Array(471.14197, dtype=float32), 'eval/episode_y_velocity_std': Array(159.05034, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5705211162567, 'eval/sps': 937.2447212897358, 'num_steps': 49479680}
{'eval/walltime': 82754.16108250618, 'training/sps': 2954.9607463241914, 'training/walltime': 16851.707166433334, 'training/entropy_loss': Array(0.02069632, dtype=float32), 'training/policy_loss': Array(0.01174662, dtype=float32), 'training/total_loss': Array(0.3498442, dtype=float32), 'training/v_loss': Array(0.31740123, dtype=float32), 'eval/episode_distance_from_origin': Array(7308.853, dtype=float32), 'eval/episode_distance_reward': Array(37.375343, dtype=float32), 'eval/episode_forward_reward': Array(6229.1924, dtype=float32), 'eval/episode_reward': Array(6259.2173, dtype=float32), 'eval/episode_reward_alive': Array(414.89453, dtype=float32), 'eval/episode_reward_linvel': Array(6229.1924, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.24518, dtype=float32), 'eval/episode_x_position': Array(7259.5264, dtype=float32), 'eval/episode_x_velocity': Array(1245.8384, dtype=float32), 'eval/episode_y_position': Array(-77.02954, dtype=float32), 'eval/episode_y_velocity': Array(-87.337234, dtype=float32), 'eval/episode_distance_from_origin_std': Array(587.0128, dtype=float32), 'eval/episode_distance_reward_std': Array(7.8640957, dtype=float32), 'eval/episode_forward_reward_std': Array(1310.674, dtype=float32), 'eval/episode_reward_std': Array(1323.4774, dtype=float32), 'eval/episode_reward_alive_std': Array(39.678524, dtype=float32), 'eval/episode_reward_linvel_std': Array(1310.674, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.261644, dtype=float32), 'eval/episode_x_position_std': Array(592.51605, dtype=float32), 'eval/episode_x_velocity_std': Array(262.13486, dtype=float32), 'eval/episode_y_position_std': Array(490.59653, dtype=float32), 'eval/episode_y_velocity_std': Array(162.59451, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39320302009583, 'eval/sps': 938.4631870632205, 'num_steps': 49561600}
{'eval/walltime': 82890.69860506058, 'training/sps': 2951.413536677081, 'training/walltime': 16879.463358163834, 'training/entropy_loss': Array(0.02162334, dtype=float32), 'training/policy_loss': Array(0.00939323, dtype=float32), 'training/total_loss': Array(0.29077086, dtype=float32), 'training/v_loss': Array(0.2597543, dtype=float32), 'eval/episode_distance_from_origin': Array(7379.1006, dtype=float32), 'eval/episode_distance_reward': Array(38.27144, dtype=float32), 'eval/episode_forward_reward': Array(6378.5405, dtype=float32), 'eval/episode_reward': Array(6399.895, dtype=float32), 'eval/episode_reward_alive': Array(404.58594, dtype=float32), 'eval/episode_reward_linvel': Array(6378.5405, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.50195, dtype=float32), 'eval/episode_x_position': Array(7333.7295, dtype=float32), 'eval/episode_x_velocity': Array(1275.708, dtype=float32), 'eval/episode_y_position': Array(-119.985504, dtype=float32), 'eval/episode_y_velocity': Array(-99.10569, dtype=float32), 'eval/episode_distance_from_origin_std': Array(571.61487, dtype=float32), 'eval/episode_distance_reward_std': Array(7.132724, dtype=float32), 'eval/episode_forward_reward_std': Array(1188.7802, dtype=float32), 'eval/episode_reward_std': Array(1202.078, dtype=float32), 'eval/episode_reward_alive_std': Array(49.386314, dtype=float32), 'eval/episode_reward_linvel_std': Array(1188.7802, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.331738, dtype=float32), 'eval/episode_x_position_std': Array(573.72095, dtype=float32), 'eval/episode_x_velocity_std': Array(237.75604, dtype=float32), 'eval/episode_y_position_std': Array(439.66364, dtype=float32), 'eval/episode_y_velocity_std': Array(152.77995, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53752255439758, 'eval/sps': 937.4712357843158, 'num_steps': 49643520}
{'eval/walltime': 83026.96353578568, 'training/sps': 2941.306699661143, 'training/walltime': 16907.314924955368, 'training/entropy_loss': Array(0.0130894, dtype=float32), 'training/policy_loss': Array(0.00557004, dtype=float32), 'training/total_loss': Array(0.09159924, dtype=float32), 'training/v_loss': Array(0.0729398, dtype=float32), 'eval/episode_distance_from_origin': Array(7400.788, dtype=float32), 'eval/episode_distance_reward': Array(37.773575, dtype=float32), 'eval/episode_forward_reward': Array(6295.5635, dtype=float32), 'eval/episode_reward': Array(6318.284, dtype=float32), 'eval/episode_reward_alive': Array(405.72656, dtype=float32), 'eval/episode_reward_linvel': Array(6295.5635, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.77985, dtype=float32), 'eval/episode_x_position': Array(7355.9, dtype=float32), 'eval/episode_x_velocity': Array(1259.1128, dtype=float32), 'eval/episode_y_position': Array(-133.43674, dtype=float32), 'eval/episode_y_velocity': Array(-95.07948, dtype=float32), 'eval/episode_distance_from_origin_std': Array(560.4114, dtype=float32), 'eval/episode_distance_reward_std': Array(6.807354, dtype=float32), 'eval/episode_forward_reward_std': Array(1134.5529, dtype=float32), 'eval/episode_reward_std': Array(1145.4205, dtype=float32), 'eval/episode_reward_alive_std': Array(48.748592, dtype=float32), 'eval/episode_reward_linvel_std': Array(1134.5529, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.171162, dtype=float32), 'eval/episode_x_position_std': Array(565.1089, dtype=float32), 'eval/episode_x_velocity_std': Array(226.91054, dtype=float32), 'eval/episode_y_position_std': Array(426.8441, dtype=float32), 'eval/episode_y_velocity_std': Array(149.16115, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26493072509766, 'eval/sps': 939.3466045803714, 'num_steps': 49725440}
{'eval/walltime': 83163.48977637291, 'training/sps': 2936.870845249148, 'training/walltime': 16935.208558797836, 'training/entropy_loss': Array(0.01925173, dtype=float32), 'training/policy_loss': Array(0.01033864, dtype=float32), 'training/total_loss': Array(0.21493617, dtype=float32), 'training/v_loss': Array(0.1853458, dtype=float32), 'eval/episode_distance_from_origin': Array(7438.2725, dtype=float32), 'eval/episode_distance_reward': Array(38.483032, dtype=float32), 'eval/episode_forward_reward': Array(6413.8076, dtype=float32), 'eval/episode_reward': Array(6428.836, dtype=float32), 'eval/episode_reward_alive': Array(393.4961, dtype=float32), 'eval/episode_reward_linvel': Array(6413.8076, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.95026, dtype=float32), 'eval/episode_x_position': Array(7395.001, dtype=float32), 'eval/episode_x_velocity': Array(1282.7616, dtype=float32), 'eval/episode_y_position': Array(-111.73546, dtype=float32), 'eval/episode_y_velocity': Array(-96.147964, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.49374, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5445385, dtype=float32), 'eval/episode_forward_reward_std': Array(1090.7494, dtype=float32), 'eval/episode_reward_std': Array(1104.9485, dtype=float32), 'eval/episode_reward_alive_std': Array(48.22597, dtype=float32), 'eval/episode_reward_linvel_std': Array(1090.7494, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.352856, dtype=float32), 'eval/episode_x_position_std': Array(495.42224, dtype=float32), 'eval/episode_x_velocity_std': Array(218.14989, dtype=float32), 'eval/episode_y_position_std': Array(414.86957, dtype=float32), 'eval/episode_y_velocity_std': Array(136.96123, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5262405872345, 'eval/sps': 937.5487045526124, 'num_steps': 49807360}
{'eval/walltime': 83299.95053625107, 'training/sps': 2940.4002993548834, 'training/walltime': 16963.068711042404, 'training/entropy_loss': Array(0.01891156, dtype=float32), 'training/policy_loss': Array(0.0084024, dtype=float32), 'training/total_loss': Array(0.38566887, dtype=float32), 'training/v_loss': Array(0.35835493, dtype=float32), 'eval/episode_distance_from_origin': Array(7336.655, dtype=float32), 'eval/episode_distance_reward': Array(37.488934, dtype=float32), 'eval/episode_forward_reward': Array(6248.123, dtype=float32), 'eval/episode_reward': Array(6273.3438, dtype=float32), 'eval/episode_reward_alive': Array(406.6953, dtype=float32), 'eval/episode_reward_linvel': Array(6248.123, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.9634, dtype=float32), 'eval/episode_x_position': Array(7290.4443, dtype=float32), 'eval/episode_x_velocity': Array(1249.6246, dtype=float32), 'eval/episode_y_position': Array(-102.10899, dtype=float32), 'eval/episode_y_velocity': Array(-90.78749, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.56006, dtype=float32), 'eval/episode_distance_reward_std': Array(6.7896066, dtype=float32), 'eval/episode_forward_reward_std': Array(1131.5934, dtype=float32), 'eval/episode_reward_std': Array(1145.3624, dtype=float32), 'eval/episode_reward_alive_std': Array(42.366344, dtype=float32), 'eval/episode_reward_linvel_std': Array(1131.5934, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.14242, dtype=float32), 'eval/episode_x_position_std': Array(535.8593, dtype=float32), 'eval/episode_x_velocity_std': Array(226.31877, dtype=float32), 'eval/episode_y_position_std': Array(453.9155, dtype=float32), 'eval/episode_y_velocity_std': Array(154.64911, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46075987815857, 'eval/sps': 937.9985873908887, 'num_steps': 49889280}
{'eval/walltime': 83436.42189669609, 'training/sps': 2928.897627420569, 'training/walltime': 16991.038278579712, 'training/entropy_loss': Array(0.0183347, dtype=float32), 'training/policy_loss': Array(0.00577331, dtype=float32), 'training/total_loss': Array(0.28994414, dtype=float32), 'training/v_loss': Array(0.26583615, dtype=float32), 'eval/episode_distance_from_origin': Array(7378.837, dtype=float32), 'eval/episode_distance_reward': Array(38.459038, dtype=float32), 'eval/episode_forward_reward': Array(6409.807, dtype=float32), 'eval/episode_reward': Array(6436.271, dtype=float32), 'eval/episode_reward_alive': Array(412.95312, dtype=float32), 'eval/episode_reward_linvel': Array(6409.807, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.94794, dtype=float32), 'eval/episode_x_position': Array(7331.415, dtype=float32), 'eval/episode_x_velocity': Array(1281.9614, dtype=float32), 'eval/episode_y_position': Array(-170.1222, dtype=float32), 'eval/episode_y_velocity': Array(-100.73934, dtype=float32), 'eval/episode_distance_from_origin_std': Array(589.28766, dtype=float32), 'eval/episode_distance_reward_std': Array(7.2115393, dtype=float32), 'eval/episode_forward_reward_std': Array(1201.916, dtype=float32), 'eval/episode_reward_std': Array(1220.1757, dtype=float32), 'eval/episode_reward_alive_std': Array(40.55159, dtype=float32), 'eval/episode_reward_linvel_std': Array(1201.916, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.203968, dtype=float32), 'eval/episode_x_position_std': Array(595.83057, dtype=float32), 'eval/episode_x_velocity_std': Array(240.38324, dtype=float32), 'eval/episode_y_position_std': Array(440.31802, dtype=float32), 'eval/episode_y_velocity_std': Array(152.59172, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47136044502258, 'eval/sps': 937.9257272925387, 'num_steps': 49971200}
{'eval/walltime': 83573.16312241554, 'training/sps': 2930.6394053943245, 'training/walltime': 17018.99122285843, 'training/entropy_loss': Array(0.0186015, dtype=float32), 'training/policy_loss': Array(0.01000779, dtype=float32), 'training/total_loss': Array(0.33994424, dtype=float32), 'training/v_loss': Array(0.3113349, dtype=float32), 'eval/episode_distance_from_origin': Array(7456.1104, dtype=float32), 'eval/episode_distance_reward': Array(38.80336, dtype=float32), 'eval/episode_forward_reward': Array(6467.1953, dtype=float32), 'eval/episode_reward': Array(6486.878, dtype=float32), 'eval/episode_reward_alive': Array(402.95703, dtype=float32), 'eval/episode_reward_linvel': Array(6467.1953, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.0777, dtype=float32), 'eval/episode_x_position': Array(7409.862, dtype=float32), 'eval/episode_x_velocity': Array(1293.439, dtype=float32), 'eval/episode_y_position': Array(-178.7854, dtype=float32), 'eval/episode_y_velocity': Array(-100.20708, dtype=float32), 'eval/episode_distance_from_origin_std': Array(564.83075, dtype=float32), 'eval/episode_distance_reward_std': Array(7.005862, dtype=float32), 'eval/episode_forward_reward_std': Array(1167.6366, dtype=float32), 'eval/episode_reward_std': Array(1182.9512, dtype=float32), 'eval/episode_reward_alive_std': Array(43.984818, dtype=float32), 'eval/episode_reward_linvel_std': Array(1167.6366, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.504297, dtype=float32), 'eval/episode_x_position_std': Array(569.4999, dtype=float32), 'eval/episode_x_velocity_std': Array(233.5274, dtype=float32), 'eval/episode_y_position_std': Array(435.88718, dtype=float32), 'eval/episode_y_velocity_std': Array(153.22957, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7412257194519, 'eval/sps': 936.0746865222195, 'num_steps': 50053120}
{'eval/walltime': 83709.7416934967, 'training/sps': 2938.1831712054145, 'training/walltime': 17046.872398138046, 'training/entropy_loss': Array(0.0193552, dtype=float32), 'training/policy_loss': Array(0.01387264, dtype=float32), 'training/total_loss': Array(0.40554962, dtype=float32), 'training/v_loss': Array(0.37232178, dtype=float32), 'eval/episode_distance_from_origin': Array(7501.4346, dtype=float32), 'eval/episode_distance_reward': Array(39.41589, dtype=float32), 'eval/episode_forward_reward': Array(6569.281, dtype=float32), 'eval/episode_reward': Array(6603.917, dtype=float32), 'eval/episode_reward_alive': Array(413.82422, dtype=float32), 'eval/episode_reward_linvel': Array(6569.281, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.60345, dtype=float32), 'eval/episode_x_position': Array(7453.1987, dtype=float32), 'eval/episode_x_velocity': Array(1313.8562, dtype=float32), 'eval/episode_y_position': Array(-188.75348, dtype=float32), 'eval/episode_y_velocity': Array(-113.40303, dtype=float32), 'eval/episode_distance_from_origin_std': Array(559.42444, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2943635, dtype=float32), 'eval/episode_forward_reward_std': Array(1049.055, dtype=float32), 'eval/episode_reward_std': Array(1059.1224, dtype=float32), 'eval/episode_reward_alive_std': Array(43.91436, dtype=float32), 'eval/episode_reward_linvel_std': Array(1049.055, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.8636, dtype=float32), 'eval/episode_x_position_std': Array(563.6708, dtype=float32), 'eval/episode_x_velocity_std': Array(209.81102, dtype=float32), 'eval/episode_y_position_std': Array(446.86526, dtype=float32), 'eval/episode_y_velocity_std': Array(155.63918, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5785710811615, 'eval/sps': 937.1894799216803, 'num_steps': 50135040}
{'eval/walltime': 83846.03260159492, 'training/sps': 2943.0626421434704, 'training/walltime': 17074.707347631454, 'training/entropy_loss': Array(0.01457016, dtype=float32), 'training/policy_loss': Array(0.00540592, dtype=float32), 'training/total_loss': Array(0.15825933, dtype=float32), 'training/v_loss': Array(0.13828325, dtype=float32), 'eval/episode_distance_from_origin': Array(7477.9336, dtype=float32), 'eval/episode_distance_reward': Array(38.676544, dtype=float32), 'eval/episode_forward_reward': Array(6446.0566, dtype=float32), 'eval/episode_reward': Array(6467.9307, dtype=float32), 'eval/episode_reward_alive': Array(402.9336, dtype=float32), 'eval/episode_reward_linvel': Array(6446.0566, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.7353, dtype=float32), 'eval/episode_x_position': Array(7428.243, dtype=float32), 'eval/episode_x_velocity': Array(1289.2112, dtype=float32), 'eval/episode_y_position': Array(-266.79218, dtype=float32), 'eval/episode_y_velocity': Array(-120.49638, dtype=float32), 'eval/episode_distance_from_origin_std': Array(504.48587, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1967587, dtype=float32), 'eval/episode_forward_reward_std': Array(1032.7878, dtype=float32), 'eval/episode_reward_std': Array(1042.7158, dtype=float32), 'eval/episode_reward_alive_std': Array(40.684013, dtype=float32), 'eval/episode_reward_linvel_std': Array(1032.7878, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.018337, dtype=float32), 'eval/episode_x_position_std': Array(508.2737, dtype=float32), 'eval/episode_x_velocity_std': Array(206.55746, dtype=float32), 'eval/episode_y_position_std': Array(451.76147, dtype=float32), 'eval/episode_y_velocity_std': Array(146.22218, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29090809822083, 'eval/sps': 939.1675628704021, 'num_steps': 50216960}
{'eval/walltime': 83982.42731690407, 'training/sps': 2936.6996048467945, 'training/walltime': 17102.60260796547, 'training/entropy_loss': Array(0.01779986, dtype=float32), 'training/policy_loss': Array(0.01559159, dtype=float32), 'training/total_loss': Array(0.14747746, dtype=float32), 'training/v_loss': Array(0.11408603, dtype=float32), 'eval/episode_distance_from_origin': Array(7346.3687, dtype=float32), 'eval/episode_distance_reward': Array(37.306152, dtype=float32), 'eval/episode_forward_reward': Array(6217.66, dtype=float32), 'eval/episode_reward': Array(6235.5986, dtype=float32), 'eval/episode_reward_alive': Array(404.59375, dtype=float32), 'eval/episode_reward_linvel': Array(6217.66, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.96185, dtype=float32), 'eval/episode_x_position': Array(7297.368, dtype=float32), 'eval/episode_x_velocity': Array(1243.5322, dtype=float32), 'eval/episode_y_position': Array(-242.53313, dtype=float32), 'eval/episode_y_velocity': Array(-117.29061, dtype=float32), 'eval/episode_distance_from_origin_std': Array(549.91113, dtype=float32), 'eval/episode_distance_reward_std': Array(6.426468, dtype=float32), 'eval/episode_forward_reward_std': Array(1071.07, dtype=float32), 'eval/episode_reward_std': Array(1088.3687, dtype=float32), 'eval/episode_reward_alive_std': Array(43.531273, dtype=float32), 'eval/episode_reward_linvel_std': Array(1071.07, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.03902, dtype=float32), 'eval/episode_x_position_std': Array(552.06915, dtype=float32), 'eval/episode_x_velocity_std': Array(214.21399, dtype=float32), 'eval/episode_y_position_std': Array(437.3164, dtype=float32), 'eval/episode_y_velocity_std': Array(150.54869, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39471530914307, 'eval/sps': 938.4527817656559, 'num_steps': 50298880}
{'eval/walltime': 84118.97531056404, 'training/sps': 2939.9842873927373, 'training/walltime': 17130.466702461243, 'training/entropy_loss': Array(0.01822135, dtype=float32), 'training/policy_loss': Array(0.00714484, dtype=float32), 'training/total_loss': Array(0.23013695, dtype=float32), 'training/v_loss': Array(0.20477076, dtype=float32), 'eval/episode_distance_from_origin': Array(7416.3315, dtype=float32), 'eval/episode_distance_reward': Array(37.836395, dtype=float32), 'eval/episode_forward_reward': Array(6306.033, dtype=float32), 'eval/episode_reward': Array(6324.368, dtype=float32), 'eval/episode_reward_alive': Array(404.73438, dtype=float32), 'eval/episode_reward_linvel': Array(6306.033, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.23615, dtype=float32), 'eval/episode_x_position': Array(7370.26, dtype=float32), 'eval/episode_x_velocity': Array(1261.2068, dtype=float32), 'eval/episode_y_position': Array(-178.84245, dtype=float32), 'eval/episode_y_velocity': Array(-97.575584, dtype=float32), 'eval/episode_distance_from_origin_std': Array(516.6508, dtype=float32), 'eval/episode_distance_reward_std': Array(6.508808, dtype=float32), 'eval/episode_forward_reward_std': Array(1084.7944, dtype=float32), 'eval/episode_reward_std': Array(1098.0657, dtype=float32), 'eval/episode_reward_alive_std': Array(42.966232, dtype=float32), 'eval/episode_reward_linvel_std': Array(1084.7944, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.934624, dtype=float32), 'eval/episode_x_position_std': Array(521.2754, dtype=float32), 'eval/episode_x_velocity_std': Array(216.9589, dtype=float32), 'eval/episode_y_position_std': Array(440.3834, dtype=float32), 'eval/episode_y_velocity_std': Array(151.89256, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54799365997314, 'eval/sps': 937.3993463334288, 'num_steps': 50380800}
{'eval/walltime': 84255.19697117805, 'training/sps': 2936.76308345822, 'training/walltime': 17158.36135983467, 'training/entropy_loss': Array(0.01928465, dtype=float32), 'training/policy_loss': Array(0.00929065, dtype=float32), 'training/total_loss': Array(0.33011997, dtype=float32), 'training/v_loss': Array(0.30154467, dtype=float32), 'eval/episode_distance_from_origin': Array(7523.665, dtype=float32), 'eval/episode_distance_reward': Array(39.2917, dtype=float32), 'eval/episode_forward_reward': Array(6548.5835, dtype=float32), 'eval/episode_reward': Array(6567.735, dtype=float32), 'eval/episode_reward_alive': Array(396.45703, dtype=float32), 'eval/episode_reward_linvel': Array(6548.5835, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.59653, dtype=float32), 'eval/episode_x_position': Array(7481.4272, dtype=float32), 'eval/episode_x_velocity': Array(1309.7164, dtype=float32), 'eval/episode_y_position': Array(-154.17935, dtype=float32), 'eval/episode_y_velocity': Array(-96.802216, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.53506, dtype=float32), 'eval/episode_distance_reward_std': Array(6.317267, dtype=float32), 'eval/episode_forward_reward_std': Array(1052.871, dtype=float32), 'eval/episode_reward_std': Array(1068.6702, dtype=float32), 'eval/episode_reward_alive_std': Array(46.24899, dtype=float32), 'eval/episode_reward_linvel_std': Array(1052.871, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.442528, dtype=float32), 'eval/episode_x_position_std': Array(479.6034, dtype=float32), 'eval/episode_x_velocity_std': Array(210.57426, dtype=float32), 'eval/episode_y_position_std': Array(410.8814, dtype=float32), 'eval/episode_y_velocity_std': Array(152.89653, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22166061401367, 'eval/sps': 939.6449832063795, 'num_steps': 50462720}
{'eval/walltime': 84391.89522743225, 'training/sps': 2950.3041496515566, 'training/walltime': 17186.12798857689, 'training/entropy_loss': Array(0.02046289, dtype=float32), 'training/policy_loss': Array(0.01025272, dtype=float32), 'training/total_loss': Array(0.32487312, dtype=float32), 'training/v_loss': Array(0.2941575, dtype=float32), 'eval/episode_distance_from_origin': Array(7456.05, dtype=float32), 'eval/episode_distance_reward': Array(38.81514, dtype=float32), 'eval/episode_forward_reward': Array(6469.1577, dtype=float32), 'eval/episode_reward': Array(6490.911, dtype=float32), 'eval/episode_reward_alive': Array(404.6914, dtype=float32), 'eval/episode_reward_linvel': Array(6469.1577, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.75372, dtype=float32), 'eval/episode_x_position': Array(7409.172, dtype=float32), 'eval/episode_x_velocity': Array(1293.8315, dtype=float32), 'eval/episode_y_position': Array(-170.70683, dtype=float32), 'eval/episode_y_velocity': Array(-95.86947, dtype=float32), 'eval/episode_distance_from_origin_std': Array(530.10974, dtype=float32), 'eval/episode_distance_reward_std': Array(7.1366887, dtype=float32), 'eval/episode_forward_reward_std': Array(1189.4396, dtype=float32), 'eval/episode_reward_std': Array(1204.1202, dtype=float32), 'eval/episode_reward_alive_std': Array(41.38435, dtype=float32), 'eval/episode_reward_linvel_std': Array(1189.4396, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.748247, dtype=float32), 'eval/episode_x_position_std': Array(537.28375, dtype=float32), 'eval/episode_x_velocity_std': Array(237.88792, dtype=float32), 'eval/episode_y_position_std': Array(448.62927, dtype=float32), 'eval/episode_y_velocity_std': Array(158.58438, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69825625419617, 'eval/sps': 936.3689304271636, 'num_steps': 50544640}
{'eval/walltime': 84528.09727406502, 'training/sps': 2949.305791391421, 'training/walltime': 17213.90401649475, 'training/entropy_loss': Array(0.02086449, dtype=float32), 'training/policy_loss': Array(0.0090969, dtype=float32), 'training/total_loss': Array(0.32561606, dtype=float32), 'training/v_loss': Array(0.29565465, dtype=float32), 'eval/episode_distance_from_origin': Array(7493.076, dtype=float32), 'eval/episode_distance_reward': Array(39.02731, dtype=float32), 'eval/episode_forward_reward': Array(6504.5186, dtype=float32), 'eval/episode_reward': Array(6528.847, dtype=float32), 'eval/episode_reward_alive': Array(400.8789, dtype=float32), 'eval/episode_reward_linvel': Array(6504.5186, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.5774, dtype=float32), 'eval/episode_x_position': Array(7447.7017, dtype=float32), 'eval/episode_x_velocity': Array(1300.9036, dtype=float32), 'eval/episode_y_position': Array(-174.24368, dtype=float32), 'eval/episode_y_velocity': Array(-95.78044, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.40366, dtype=float32), 'eval/episode_distance_reward_std': Array(6.044331, dtype=float32), 'eval/episode_forward_reward_std': Array(1007.3824, dtype=float32), 'eval/episode_reward_std': Array(1017.8422, dtype=float32), 'eval/episode_reward_alive_std': Array(46.266415, dtype=float32), 'eval/episode_reward_linvel_std': Array(1007.3824, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.125975, dtype=float32), 'eval/episode_x_position_std': Array(474.6924, dtype=float32), 'eval/episode_x_velocity_std': Array(201.47643, dtype=float32), 'eval/episode_y_position_std': Array(445.22366, dtype=float32), 'eval/episode_y_velocity_std': Array(152.7166, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20204663276672, 'eval/sps': 939.7802982000601, 'num_steps': 50626560}
{'eval/walltime': 84664.84953975677, 'training/sps': 2940.4756394201113, 'training/walltime': 17241.763454914093, 'training/entropy_loss': Array(0.01756075, dtype=float32), 'training/policy_loss': Array(0.00911354, dtype=float32), 'training/total_loss': Array(0.20656791, dtype=float32), 'training/v_loss': Array(0.17989364, dtype=float32), 'eval/episode_distance_from_origin': Array(7449.6016, dtype=float32), 'eval/episode_distance_reward': Array(38.74353, dtype=float32), 'eval/episode_forward_reward': Array(6457.2227, dtype=float32), 'eval/episode_reward': Array(6486.889, dtype=float32), 'eval/episode_reward_alive': Array(413.14453, dtype=float32), 'eval/episode_reward_linvel': Array(6457.2227, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.22192, dtype=float32), 'eval/episode_x_position': Array(7404.7666, dtype=float32), 'eval/episode_x_velocity': Array(1291.4445, dtype=float32), 'eval/episode_y_position': Array(-94.39296, dtype=float32), 'eval/episode_y_velocity': Array(-77.43007, dtype=float32), 'eval/episode_distance_from_origin_std': Array(512.8229, dtype=float32), 'eval/episode_distance_reward_std': Array(7.1769814, dtype=float32), 'eval/episode_forward_reward_std': Array(1196.1549, dtype=float32), 'eval/episode_reward_std': Array(1212.1372, dtype=float32), 'eval/episode_reward_alive_std': Array(43.923946, dtype=float32), 'eval/episode_reward_linvel_std': Array(1196.1549, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.63593, dtype=float32), 'eval/episode_x_position_std': Array(514.2523, dtype=float32), 'eval/episode_x_velocity_std': Array(239.23099, dtype=float32), 'eval/episode_y_position_std': Array(450.633, dtype=float32), 'eval/episode_y_velocity_std': Array(161.99097, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7522656917572, 'eval/sps': 935.9991174736, 'num_steps': 50708480}
{'eval/walltime': 84801.08414578438, 'training/sps': 2942.098853989826, 'training/walltime': 17269.60752272606, 'training/entropy_loss': Array(0.0155904, dtype=float32), 'training/policy_loss': Array(0.00741656, dtype=float32), 'training/total_loss': Array(0.08143912, dtype=float32), 'training/v_loss': Array(0.05843216, dtype=float32), 'eval/episode_distance_from_origin': Array(7489.169, dtype=float32), 'eval/episode_distance_reward': Array(38.4125, dtype=float32), 'eval/episode_forward_reward': Array(6402.052, dtype=float32), 'eval/episode_reward': Array(6415.797, dtype=float32), 'eval/episode_reward_alive': Array(397.66016, dtype=float32), 'eval/episode_reward_linvel': Array(6402.052, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.3276, dtype=float32), 'eval/episode_x_position': Array(7444.2417, dtype=float32), 'eval/episode_x_velocity': Array(1280.4103, dtype=float32), 'eval/episode_y_position': Array(-214.45712, dtype=float32), 'eval/episode_y_velocity': Array(-115.984085, dtype=float32), 'eval/episode_distance_from_origin_std': Array(542.85834, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3902855, dtype=float32), 'eval/episode_forward_reward_std': Array(1065.0406, dtype=float32), 'eval/episode_reward_std': Array(1082.9026, dtype=float32), 'eval/episode_reward_alive_std': Array(48.782436, dtype=float32), 'eval/episode_reward_linvel_std': Array(1065.0406, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.47069, dtype=float32), 'eval/episode_x_position_std': Array(545.74774, dtype=float32), 'eval/episode_x_velocity_std': Array(213.00818, dtype=float32), 'eval/episode_y_position_std': Array(414.09296, dtype=float32), 'eval/episode_y_velocity_std': Array(143.35544, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23460602760315, 'eval/sps': 939.5556953720356, 'num_steps': 50790400}
{'eval/walltime': 84937.80088186264, 'training/sps': 2948.0939717771735, 'training/walltime': 17297.394968032837, 'training/entropy_loss': Array(0.01916554, dtype=float32), 'training/policy_loss': Array(0.01097589, dtype=float32), 'training/total_loss': Array(0.28838497, dtype=float32), 'training/v_loss': Array(0.25824356, dtype=float32), 'eval/episode_distance_from_origin': Array(7541.173, dtype=float32), 'eval/episode_distance_reward': Array(39.221462, dtype=float32), 'eval/episode_forward_reward': Array(6536.876, dtype=float32), 'eval/episode_reward': Array(6560.4766, dtype=float32), 'eval/episode_reward_alive': Array(406.83594, dtype=float32), 'eval/episode_reward_linvel': Array(6536.876, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.45752, dtype=float32), 'eval/episode_x_position': Array(7494.4517, dtype=float32), 'eval/episode_x_velocity': Array(1307.3754, dtype=float32), 'eval/episode_y_position': Array(-244.9289, dtype=float32), 'eval/episode_y_velocity': Array(-118.097755, dtype=float32), 'eval/episode_distance_from_origin_std': Array(509.6806, dtype=float32), 'eval/episode_distance_reward_std': Array(6.38539, dtype=float32), 'eval/episode_forward_reward_std': Array(1064.225, dtype=float32), 'eval/episode_reward_std': Array(1077.8009, dtype=float32), 'eval/episode_reward_alive_std': Array(40.629234, dtype=float32), 'eval/episode_reward_linvel_std': Array(1064.225, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.26209, dtype=float32), 'eval/episode_x_position_std': Array(511.2965, dtype=float32), 'eval/episode_x_velocity_std': Array(212.84485, dtype=float32), 'eval/episode_y_position_std': Array(424.29666, dtype=float32), 'eval/episode_y_velocity_std': Array(151.93271, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.71673607826233, 'eval/sps': 936.2423626521298, 'num_steps': 50872320}
{'eval/walltime': 85074.33820843697, 'training/sps': 2943.9239451506464, 'training/walltime': 17325.22177386284, 'training/entropy_loss': Array(0.01904341, dtype=float32), 'training/policy_loss': Array(0.01465952, dtype=float32), 'training/total_loss': Array(0.34321606, dtype=float32), 'training/v_loss': Array(0.30951315, dtype=float32), 'eval/episode_distance_from_origin': Array(7490.8467, dtype=float32), 'eval/episode_distance_reward': Array(39.002228, dtype=float32), 'eval/episode_forward_reward': Array(6500.339, dtype=float32), 'eval/episode_reward': Array(6519.957, dtype=float32), 'eval/episode_reward_alive': Array(398.65625, dtype=float32), 'eval/episode_reward_linvel': Array(6500.339, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.0393, dtype=float32), 'eval/episode_x_position': Array(7445.006, dtype=float32), 'eval/episode_x_velocity': Array(1300.0674, dtype=float32), 'eval/episode_y_position': Array(-253.03043, dtype=float32), 'eval/episode_y_velocity': Array(-126.594315, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.8779, dtype=float32), 'eval/episode_distance_reward_std': Array(6.7883773, dtype=float32), 'eval/episode_forward_reward_std': Array(1131.3893, dtype=float32), 'eval/episode_reward_std': Array(1146.6993, dtype=float32), 'eval/episode_reward_alive_std': Array(48.030945, dtype=float32), 'eval/episode_reward_linvel_std': Array(1131.3893, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.30804, dtype=float32), 'eval/episode_x_position_std': Array(536.1056, dtype=float32), 'eval/episode_x_velocity_std': Array(226.27776, dtype=float32), 'eval/episode_y_position_std': Array(401.96494, dtype=float32), 'eval/episode_y_velocity_std': Array(139.8752, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53732657432556, 'eval/sps': 937.4725813920329, 'num_steps': 50954240}
{'eval/walltime': 85210.67724728584, 'training/sps': 2940.4092825867883, 'training/walltime': 17353.081840991974, 'training/entropy_loss': Array(0.01899344, dtype=float32), 'training/policy_loss': Array(0.15411536, dtype=float32), 'training/total_loss': Array(0.45497537, dtype=float32), 'training/v_loss': Array(0.28186655, dtype=float32), 'eval/episode_distance_from_origin': Array(6846.011, dtype=float32), 'eval/episode_distance_reward': Array(29.676914, dtype=float32), 'eval/episode_forward_reward': Array(4946.129, dtype=float32), 'eval/episode_reward': Array(4947.315, dtype=float32), 'eval/episode_reward_alive': Array(413.70703, dtype=float32), 'eval/episode_reward_linvel': Array(4946.129, dtype=float32), 'eval/episode_reward_quadctrl': Array(-442.19772, dtype=float32), 'eval/episode_x_position': Array(6768.737, dtype=float32), 'eval/episode_x_velocity': Array(989.22565, dtype=float32), 'eval/episode_y_position': Array(-658.79663, dtype=float32), 'eval/episode_y_velocity': Array(-218.32938, dtype=float32), 'eval/episode_distance_from_origin_std': Array(522.0159, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0185823, dtype=float32), 'eval/episode_forward_reward_std': Array(1003.0904, dtype=float32), 'eval/episode_reward_std': Array(1021.97577, dtype=float32), 'eval/episode_reward_alive_std': Array(43.517036, dtype=float32), 'eval/episode_reward_linvel_std': Array(1003.0904, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.053513, dtype=float32), 'eval/episode_x_position_std': Array(523.81604, dtype=float32), 'eval/episode_x_velocity_std': Array(200.61803, dtype=float32), 'eval/episode_y_position_std': Array(303.11804, dtype=float32), 'eval/episode_y_velocity_std': Array(81.601616, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33903884887695, 'eval/sps': 938.836015573498, 'num_steps': 51036160}
{'eval/walltime': 85347.1670923233, 'training/sps': 2933.1946988197337, 'training/walltime': 17381.01043367386, 'training/entropy_loss': Array(0.0210753, dtype=float32), 'training/policy_loss': Array(0.00960733, dtype=float32), 'training/total_loss': Array(0.33389628, dtype=float32), 'training/v_loss': Array(0.30321366, dtype=float32), 'eval/episode_distance_from_origin': Array(6817.615, dtype=float32), 'eval/episode_distance_reward': Array(29.095398, dtype=float32), 'eval/episode_forward_reward': Array(4849.21, dtype=float32), 'eval/episode_reward': Array(4849.092, dtype=float32), 'eval/episode_reward_alive': Array(415.8672, dtype=float32), 'eval/episode_reward_linvel': Array(4849.21, dtype=float32), 'eval/episode_reward_quadctrl': Array(-445.08197, dtype=float32), 'eval/episode_x_position': Array(6736.66, dtype=float32), 'eval/episode_x_velocity': Array(969.84204, dtype=float32), 'eval/episode_y_position': Array(-660.7705, dtype=float32), 'eval/episode_y_velocity': Array(-213.24042, dtype=float32), 'eval/episode_distance_from_origin_std': Array(540.45105, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1731553, dtype=float32), 'eval/episode_forward_reward_std': Array(1028.852, dtype=float32), 'eval/episode_reward_std': Array(1050.4194, dtype=float32), 'eval/episode_reward_alive_std': Array(45.313942, dtype=float32), 'eval/episode_reward_linvel_std': Array(1028.852, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.18316, dtype=float32), 'eval/episode_x_position_std': Array(542.756, dtype=float32), 'eval/episode_x_velocity_std': Array(205.77055, dtype=float32), 'eval/episode_y_position_std': Array(375.64896, dtype=float32), 'eval/episode_y_velocity_std': Array(102.55952, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48984503746033, 'eval/sps': 937.7987055730758, 'num_steps': 51118080}
{'eval/walltime': 85484.10965633392, 'training/sps': 2948.9196764207163, 'training/walltime': 17408.790098428726, 'training/entropy_loss': Array(0.02129997, dtype=float32), 'training/policy_loss': Array(0.00650914, dtype=float32), 'training/total_loss': Array(0.260115, dtype=float32), 'training/v_loss': Array(0.2323059, dtype=float32), 'eval/episode_distance_from_origin': Array(6820.448, dtype=float32), 'eval/episode_distance_reward': Array(28.802225, dtype=float32), 'eval/episode_forward_reward': Array(4800.3486, dtype=float32), 'eval/episode_reward': Array(4793.0586, dtype=float32), 'eval/episode_reward_alive': Array(414.33984, dtype=float32), 'eval/episode_reward_linvel': Array(4800.3486, dtype=float32), 'eval/episode_reward_quadctrl': Array(-450.43237, dtype=float32), 'eval/episode_x_position': Array(6743.405, dtype=float32), 'eval/episode_x_velocity': Array(960.0697, dtype=float32), 'eval/episode_y_position': Array(-658.73895, dtype=float32), 'eval/episode_y_velocity': Array(-213.42227, dtype=float32), 'eval/episode_distance_from_origin_std': Array(616.74084, dtype=float32), 'eval/episode_distance_reward_std': Array(6.8053617, dtype=float32), 'eval/episode_forward_reward_std': Array(1134.219, dtype=float32), 'eval/episode_reward_std': Array(1156.7017, dtype=float32), 'eval/episode_reward_alive_std': Array(50.716003, dtype=float32), 'eval/episode_reward_linvel_std': Array(1134.219, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.982395, dtype=float32), 'eval/episode_x_position_std': Array(616.4127, dtype=float32), 'eval/episode_x_velocity_std': Array(226.84366, dtype=float32), 'eval/episode_y_position_std': Array(324.97736, dtype=float32), 'eval/episode_y_velocity_std': Array(84.767166, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.94256401062012, 'eval/sps': 934.6984330603989, 'num_steps': 51200000}
{'eval/walltime': 85620.55987071991, 'training/sps': 2962.514335065923, 'training/walltime': 17436.4422852993, 'training/entropy_loss': Array(0.01343254, dtype=float32), 'training/policy_loss': Array(0.00503343, dtype=float32), 'training/total_loss': Array(0.05415501, dtype=float32), 'training/v_loss': Array(0.03568903, dtype=float32), 'eval/episode_distance_from_origin': Array(6953.658, dtype=float32), 'eval/episode_distance_reward': Array(31.001247, dtype=float32), 'eval/episode_forward_reward': Array(5166.849, dtype=float32), 'eval/episode_reward': Array(5172.038, dtype=float32), 'eval/episode_reward_alive': Array(408.3789, dtype=float32), 'eval/episode_reward_linvel': Array(5166.849, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.1906, dtype=float32), 'eval/episode_x_position': Array(6876.624, dtype=float32), 'eval/episode_x_velocity': Array(1033.3699, dtype=float32), 'eval/episode_y_position': Array(-625.417, dtype=float32), 'eval/episode_y_velocity': Array(-219.41577, dtype=float32), 'eval/episode_distance_from_origin_std': Array(533.6085, dtype=float32), 'eval/episode_distance_reward_std': Array(6.098662, dtype=float32), 'eval/episode_forward_reward_std': Array(1016.43634, dtype=float32), 'eval/episode_reward_std': Array(1035.2754, dtype=float32), 'eval/episode_reward_alive_std': Array(43.821804, dtype=float32), 'eval/episode_reward_linvel_std': Array(1016.43634, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.510784, dtype=float32), 'eval/episode_x_position_std': Array(540.701, dtype=float32), 'eval/episode_x_velocity_std': Array(203.2872, dtype=float32), 'eval/episode_y_position_std': Array(370.15305, dtype=float32), 'eval/episode_y_velocity_std': Array(82.86131, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45021438598633, 'eval/sps': 938.0710801810643, 'num_steps': 51281920}
{'eval/walltime': 85757.05573296547, 'training/sps': 2954.7540779700525, 'training/walltime': 17464.167096853256, 'training/entropy_loss': Array(0.01894504, dtype=float32), 'training/policy_loss': Array(0.00573977, dtype=float32), 'training/total_loss': Array(0.26859224, dtype=float32), 'training/v_loss': Array(0.24390744, dtype=float32), 'eval/episode_distance_from_origin': Array(6974.8325, dtype=float32), 'eval/episode_distance_reward': Array(30.871572, dtype=float32), 'eval/episode_forward_reward': Array(5145.238, dtype=float32), 'eval/episode_reward': Array(5151.133, dtype=float32), 'eval/episode_reward_alive': Array(415.17188, dtype=float32), 'eval/episode_reward_linvel': Array(5145.238, dtype=float32), 'eval/episode_reward_quadctrl': Array(-440.14908, dtype=float32), 'eval/episode_x_position': Array(6902.284, dtype=float32), 'eval/episode_x_velocity': Array(1029.0476, dtype=float32), 'eval/episode_y_position': Array(-590.8889, dtype=float32), 'eval/episode_y_velocity': Array(-197.77637, dtype=float32), 'eval/episode_distance_from_origin_std': Array(490.145, dtype=float32), 'eval/episode_distance_reward_std': Array(6.377756, dtype=float32), 'eval/episode_forward_reward_std': Array(1062.9515, dtype=float32), 'eval/episode_reward_std': Array(1092.999, dtype=float32), 'eval/episode_reward_alive_std': Array(45.552227, dtype=float32), 'eval/episode_reward_linvel_std': Array(1062.9515, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.901924, dtype=float32), 'eval/episode_x_position_std': Array(493.5256, dtype=float32), 'eval/episode_x_velocity_std': Array(212.59026, dtype=float32), 'eval/episode_y_position_std': Array(361.91095, dtype=float32), 'eval/episode_y_velocity_std': Array(111.93502, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4958622455597, 'eval/sps': 937.7573641736084, 'num_steps': 51363840}
{'eval/walltime': 85893.51397132874, 'training/sps': 2954.7247813287076, 'training/walltime': 17491.892183303833, 'training/entropy_loss': Array(0.02250455, dtype=float32), 'training/policy_loss': Array(0.01165158, dtype=float32), 'training/total_loss': Array(0.24836683, dtype=float32), 'training/v_loss': Array(0.21421069, dtype=float32), 'eval/episode_distance_from_origin': Array(6985.0547, dtype=float32), 'eval/episode_distance_reward': Array(31.056469, dtype=float32), 'eval/episode_forward_reward': Array(5176.054, dtype=float32), 'eval/episode_reward': Array(5176.437, dtype=float32), 'eval/episode_reward_alive': Array(409.3828, dtype=float32), 'eval/episode_reward_linvel': Array(5176.054, dtype=float32), 'eval/episode_reward_quadctrl': Array(-440.05603, dtype=float32), 'eval/episode_x_position': Array(6911.8486, dtype=float32), 'eval/episode_x_velocity': Array(1035.2107, dtype=float32), 'eval/episode_y_position': Array(-606.6544, dtype=float32), 'eval/episode_y_velocity': Array(-210.64587, dtype=float32), 'eval/episode_distance_from_origin_std': Array(532.7499, dtype=float32), 'eval/episode_distance_reward_std': Array(6.476935, dtype=float32), 'eval/episode_forward_reward_std': Array(1079.4827, dtype=float32), 'eval/episode_reward_std': Array(1103.2139, dtype=float32), 'eval/episode_reward_alive_std': Array(46.17335, dtype=float32), 'eval/episode_reward_linvel_std': Array(1079.4827, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.061916, dtype=float32), 'eval/episode_x_position_std': Array(537.2713, dtype=float32), 'eval/episode_x_velocity_std': Array(215.89647, dtype=float32), 'eval/episode_y_position_std': Array(337.93896, dtype=float32), 'eval/episode_y_velocity_std': Array(97.62913, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.458238363266, 'eval/sps': 938.0159200007457, 'num_steps': 51445760}
{'eval/walltime': 86030.0196006298, 'training/sps': 2952.471774142026, 'training/walltime': 17519.638426542282, 'training/entropy_loss': Array(0.02511731, dtype=float32), 'training/policy_loss': Array(0.01378223, dtype=float32), 'training/total_loss': Array(0.28723225, dtype=float32), 'training/v_loss': Array(0.24833272, dtype=float32), 'eval/episode_distance_from_origin': Array(6947.7734, dtype=float32), 'eval/episode_distance_reward': Array(31.320751, dtype=float32), 'eval/episode_forward_reward': Array(5220.1006, dtype=float32), 'eval/episode_reward': Array(5230.5234, dtype=float32), 'eval/episode_reward_alive': Array(414.89453, dtype=float32), 'eval/episode_reward_linvel': Array(5220.1006, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.79254, dtype=float32), 'eval/episode_x_position': Array(6876.2573, dtype=float32), 'eval/episode_x_velocity': Array(1044.0201, dtype=float32), 'eval/episode_y_position': Array(-566.83636, dtype=float32), 'eval/episode_y_velocity': Array(-204.17369, dtype=float32), 'eval/episode_distance_from_origin_std': Array(508.5881, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0789165, dtype=float32), 'eval/episode_forward_reward_std': Array(1013.1455, dtype=float32), 'eval/episode_reward_std': Array(1040.1708, dtype=float32), 'eval/episode_reward_alive_std': Array(43.22297, dtype=float32), 'eval/episode_reward_linvel_std': Array(1013.1455, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.340954, dtype=float32), 'eval/episode_x_position_std': Array(514.1852, dtype=float32), 'eval/episode_x_velocity_std': Array(202.62912, dtype=float32), 'eval/episode_y_position_std': Array(368.29684, dtype=float32), 'eval/episode_y_velocity_std': Array(102.71445, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50562930107117, 'eval/sps': 937.6902671001831, 'num_steps': 51527680}
{'eval/walltime': 86166.43315291405, 'training/sps': 2940.338777014964, 'training/walltime': 17547.499161720276, 'training/entropy_loss': Array(0.02578142, dtype=float32), 'training/policy_loss': Array(0.00750531, dtype=float32), 'training/total_loss': Array(0.23274872, dtype=float32), 'training/v_loss': Array(0.199462, dtype=float32), 'eval/episode_distance_from_origin': Array(7055.396, dtype=float32), 'eval/episode_distance_reward': Array(32.11531, dtype=float32), 'eval/episode_forward_reward': Array(5352.5264, dtype=float32), 'eval/episode_reward': Array(5369.743, dtype=float32), 'eval/episode_reward_alive': Array(424.6172, dtype=float32), 'eval/episode_reward_linvel': Array(5352.5264, dtype=float32), 'eval/episode_reward_quadctrl': Array(-439.5175, dtype=float32), 'eval/episode_x_position': Array(6982.3877, dtype=float32), 'eval/episode_x_velocity': Array(1070.5055, dtype=float32), 'eval/episode_y_position': Array(-584.50366, dtype=float32), 'eval/episode_y_velocity': Array(-204.39975, dtype=float32), 'eval/episode_distance_from_origin_std': Array(511.616, dtype=float32), 'eval/episode_distance_reward_std': Array(6.848425, dtype=float32), 'eval/episode_forward_reward_std': Array(1141.3961, dtype=float32), 'eval/episode_reward_std': Array(1165.6273, dtype=float32), 'eval/episode_reward_alive_std': Array(43.966892, dtype=float32), 'eval/episode_reward_linvel_std': Array(1141.3961, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.58919, dtype=float32), 'eval/episode_x_position_std': Array(517.71313, dtype=float32), 'eval/episode_x_velocity_std': Array(228.27928, dtype=float32), 'eval/episode_y_position_std': Array(379.82593, dtype=float32), 'eval/episode_y_velocity_std': Array(103.93884, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41355228424072, 'eval/sps': 938.3231933825045, 'num_steps': 51609600}
{'eval/walltime': 86302.86985516548, 'training/sps': 2950.9449307657615, 'training/walltime': 17575.259761095047, 'training/entropy_loss': Array(0.0268437, dtype=float32), 'training/policy_loss': Array(0.01014716, dtype=float32), 'training/total_loss': Array(0.20557818, dtype=float32), 'training/v_loss': Array(0.16858733, dtype=float32), 'eval/episode_distance_from_origin': Array(6960.2476, dtype=float32), 'eval/episode_distance_reward': Array(30.769583, dtype=float32), 'eval/episode_forward_reward': Array(5128.24, dtype=float32), 'eval/episode_reward': Array(5127.7188, dtype=float32), 'eval/episode_reward_alive': Array(408.01953, dtype=float32), 'eval/episode_reward_linvel': Array(5128.24, dtype=float32), 'eval/episode_reward_quadctrl': Array(-439.31107, dtype=float32), 'eval/episode_x_position': Array(6885.7983, dtype=float32), 'eval/episode_x_velocity': Array(1025.648, dtype=float32), 'eval/episode_y_position': Array(-568.6837, dtype=float32), 'eval/episode_y_velocity': Array(-194.08258, dtype=float32), 'eval/episode_distance_from_origin_std': Array(534.0551, dtype=float32), 'eval/episode_distance_reward_std': Array(6.563472, dtype=float32), 'eval/episode_forward_reward_std': Array(1093.9031, dtype=float32), 'eval/episode_reward_std': Array(1117.1741, dtype=float32), 'eval/episode_reward_alive_std': Array(47.76993, dtype=float32), 'eval/episode_reward_linvel_std': Array(1093.9031, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.775867, dtype=float32), 'eval/episode_x_position_std': Array(536.9711, dtype=float32), 'eval/episode_x_velocity_std': Array(218.78075, dtype=float32), 'eval/episode_y_position_std': Array(431.8423, dtype=float32), 'eval/episode_y_velocity_std': Array(117.59376, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43670225143433, 'eval/sps': 938.1639829150471, 'num_steps': 51691520}
{'eval/walltime': 86439.32784199715, 'training/sps': 2956.248392420149, 'training/walltime': 17602.970558404922, 'training/entropy_loss': Array(0.01501561, dtype=float32), 'training/policy_loss': Array(0.00390746, dtype=float32), 'training/total_loss': Array(0.06919076, dtype=float32), 'training/v_loss': Array(0.05026768, dtype=float32), 'eval/episode_distance_from_origin': Array(6998.7197, dtype=float32), 'eval/episode_distance_reward': Array(30.676329, dtype=float32), 'eval/episode_forward_reward': Array(5112.698, dtype=float32), 'eval/episode_reward': Array(5116.9307, dtype=float32), 'eval/episode_reward_alive': Array(414.97656, dtype=float32), 'eval/episode_reward_linvel': Array(5112.698, dtype=float32), 'eval/episode_reward_quadctrl': Array(-441.41995, dtype=float32), 'eval/episode_x_position': Array(6922.3174, dtype=float32), 'eval/episode_x_velocity': Array(1022.5396, dtype=float32), 'eval/episode_y_position': Array(-662.17737, dtype=float32), 'eval/episode_y_velocity': Array(-220.81247, dtype=float32), 'eval/episode_distance_from_origin_std': Array(464.95804, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7077217, dtype=float32), 'eval/episode_forward_reward_std': Array(951.27936, dtype=float32), 'eval/episode_reward_std': Array(972.0017, dtype=float32), 'eval/episode_reward_alive_std': Array(49.346504, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.27936, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.904427, dtype=float32), 'eval/episode_x_position_std': Array(473.2911, dtype=float32), 'eval/episode_x_velocity_std': Array(190.2559, dtype=float32), 'eval/episode_y_position_std': Array(312.895, dtype=float32), 'eval/episode_y_velocity_std': Array(76.52753, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45798683166504, 'eval/sps': 938.017649035825, 'num_steps': 51773440}
{'eval/walltime': 86575.7134065628, 'training/sps': 2951.7850646321713, 'training/walltime': 17630.723256587982, 'training/entropy_loss': Array(0.02030471, dtype=float32), 'training/policy_loss': Array(0.00568166, dtype=float32), 'training/total_loss': Array(0.25226802, dtype=float32), 'training/v_loss': Array(0.22628164, dtype=float32), 'eval/episode_distance_from_origin': Array(6967.0034, dtype=float32), 'eval/episode_distance_reward': Array(31.00557, dtype=float32), 'eval/episode_forward_reward': Array(5167.5713, dtype=float32), 'eval/episode_reward': Array(5172.032, dtype=float32), 'eval/episode_reward_alive': Array(415.98438, dtype=float32), 'eval/episode_reward_linvel': Array(5167.5713, dtype=float32), 'eval/episode_reward_quadctrl': Array(-442.5287, dtype=float32), 'eval/episode_x_position': Array(6895.749, dtype=float32), 'eval/episode_x_velocity': Array(1033.5143, dtype=float32), 'eval/episode_y_position': Array(-571.27795, dtype=float32), 'eval/episode_y_velocity': Array(-196.3887, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.62643, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1056886, dtype=float32), 'eval/episode_forward_reward_std': Array(1017.60767, dtype=float32), 'eval/episode_reward_std': Array(1038.1909, dtype=float32), 'eval/episode_reward_alive_std': Array(42.85285, dtype=float32), 'eval/episode_reward_linvel_std': Array(1017.60767, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.629143, dtype=float32), 'eval/episode_x_position_std': Array(510.35376, dtype=float32), 'eval/episode_x_velocity_std': Array(203.52144, dtype=float32), 'eval/episode_y_position_std': Array(387.5857, dtype=float32), 'eval/episode_y_velocity_std': Array(109.16986, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38556456565857, 'eval/sps': 938.5157469387341, 'num_steps': 51855360}
{'eval/walltime': 86712.11031484604, 'training/sps': 2943.5559063481537, 'training/walltime': 17658.55354166031, 'training/entropy_loss': Array(0.02103195, dtype=float32), 'training/policy_loss': Array(0.01905659, dtype=float32), 'training/total_loss': Array(0.29915547, dtype=float32), 'training/v_loss': Array(0.25906694, dtype=float32), 'eval/episode_distance_from_origin': Array(6989.378, dtype=float32), 'eval/episode_distance_reward': Array(31.150572, dtype=float32), 'eval/episode_forward_reward': Array(5191.738, dtype=float32), 'eval/episode_reward': Array(5196.093, dtype=float32), 'eval/episode_reward_alive': Array(418.20703, dtype=float32), 'eval/episode_reward_linvel': Array(5191.738, dtype=float32), 'eval/episode_reward_quadctrl': Array(-445.0027, dtype=float32), 'eval/episode_x_position': Array(6918.2017, dtype=float32), 'eval/episode_x_velocity': Array(1038.3477, dtype=float32), 'eval/episode_y_position': Array(-606.4214, dtype=float32), 'eval/episode_y_velocity': Array(-209.03003, dtype=float32), 'eval/episode_distance_from_origin_std': Array(568.1633, dtype=float32), 'eval/episode_distance_reward_std': Array(6.9881916, dtype=float32), 'eval/episode_forward_reward_std': Array(1164.6898, dtype=float32), 'eval/episode_reward_std': Array(1189.5968, dtype=float32), 'eval/episode_reward_alive_std': Array(44.080162, dtype=float32), 'eval/episode_reward_linvel_std': Array(1164.6898, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.01059, dtype=float32), 'eval/episode_x_position_std': Array(572.32477, dtype=float32), 'eval/episode_x_velocity_std': Array(232.93787, dtype=float32), 'eval/episode_y_position_std': Array(320.04123, dtype=float32), 'eval/episode_y_velocity_std': Array(81.68166, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39690828323364, 'eval/sps': 938.4376934277929, 'num_steps': 51937280}
{'eval/walltime': 86848.50834608078, 'training/sps': 2936.4890833306913, 'training/walltime': 17686.450801849365, 'training/entropy_loss': Array(0.02235534, dtype=float32), 'training/policy_loss': Array(0.01051669, dtype=float32), 'training/total_loss': Array(0.25240028, dtype=float32), 'training/v_loss': Array(0.21952826, dtype=float32), 'eval/episode_distance_from_origin': Array(7055.2314, dtype=float32), 'eval/episode_distance_reward': Array(31.391312, dtype=float32), 'eval/episode_forward_reward': Array(5231.8613, dtype=float32), 'eval/episode_reward': Array(5239.2964, dtype=float32), 'eval/episode_reward_alive': Array(411.6875, dtype=float32), 'eval/episode_reward_linvel': Array(5231.8613, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.6433, dtype=float32), 'eval/episode_x_position': Array(6979.841, dtype=float32), 'eval/episode_x_velocity': Array(1046.3722, dtype=float32), 'eval/episode_y_position': Array(-648.1377, dtype=float32), 'eval/episode_y_velocity': Array(-219.07489, dtype=float32), 'eval/episode_distance_from_origin_std': Array(464.28336, dtype=float32), 'eval/episode_distance_reward_std': Array(5.352266, dtype=float32), 'eval/episode_forward_reward_std': Array(892.0383, dtype=float32), 'eval/episode_reward_std': Array(908.8935, dtype=float32), 'eval/episode_reward_alive_std': Array(45.750042, dtype=float32), 'eval/episode_reward_linvel_std': Array(892.0383, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.36956, dtype=float32), 'eval/episode_x_position_std': Array(469.81888, dtype=float32), 'eval/episode_x_velocity_std': Array(178.40775, dtype=float32), 'eval/episode_y_position_std': Array(303.18597, dtype=float32), 'eval/episode_y_velocity_std': Array(74.21444, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3980312347412, 'eval/sps': 938.4299673630319, 'num_steps': 52019200}
{'eval/walltime': 86984.8134765625, 'training/sps': 2947.1681408080512, 'training/walltime': 17714.24697637558, 'training/entropy_loss': Array(0.024991, dtype=float32), 'training/policy_loss': Array(0.00903372, dtype=float32), 'training/total_loss': Array(0.26878515, dtype=float32), 'training/v_loss': Array(0.23476043, dtype=float32), 'eval/episode_distance_from_origin': Array(6966.7847, dtype=float32), 'eval/episode_distance_reward': Array(30.783314, dtype=float32), 'eval/episode_forward_reward': Array(5130.5283, dtype=float32), 'eval/episode_reward': Array(5130.697, dtype=float32), 'eval/episode_reward_alive': Array(399.65234, dtype=float32), 'eval/episode_reward_linvel': Array(5130.5283, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.26697, dtype=float32), 'eval/episode_x_position': Array(6892.705, dtype=float32), 'eval/episode_x_velocity': Array(1026.1057, dtype=float32), 'eval/episode_y_position': Array(-636.8671, dtype=float32), 'eval/episode_y_velocity': Array(-210.20114, dtype=float32), 'eval/episode_distance_from_origin_std': Array(530.3126, dtype=float32), 'eval/episode_distance_reward_std': Array(5.919469, dtype=float32), 'eval/episode_forward_reward_std': Array(986.5713, dtype=float32), 'eval/episode_reward_std': Array(1002.1942, dtype=float32), 'eval/episode_reward_alive_std': Array(45.262367, dtype=float32), 'eval/episode_reward_linvel_std': Array(986.5713, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.95, dtype=float32), 'eval/episode_x_position_std': Array(535.2273, dtype=float32), 'eval/episode_x_velocity_std': Array(197.31432, dtype=float32), 'eval/episode_y_position_std': Array(312.8302, dtype=float32), 'eval/episode_y_velocity_std': Array(101.033356, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30513048171997, 'eval/sps': 939.0695680172231, 'num_steps': 52101120}
{'eval/walltime': 87121.24071574211, 'training/sps': 2956.592593677437, 'training/walltime': 17741.95454764366, 'training/entropy_loss': Array(0.02514793, dtype=float32), 'training/policy_loss': Array(0.00829108, dtype=float32), 'training/total_loss': Array(0.20692253, dtype=float32), 'training/v_loss': Array(0.17348352, dtype=float32), 'eval/episode_distance_from_origin': Array(7078.637, dtype=float32), 'eval/episode_distance_reward': Array(31.42872, dtype=float32), 'eval/episode_forward_reward': Array(5238.0957, dtype=float32), 'eval/episode_reward': Array(5238.4956, dtype=float32), 'eval/episode_reward_alive': Array(410.88672, dtype=float32), 'eval/episode_reward_linvel': Array(5238.0957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-441.91544, dtype=float32), 'eval/episode_x_position': Array(7002.664, dtype=float32), 'eval/episode_x_velocity': Array(1047.6191, dtype=float32), 'eval/episode_y_position': Array(-686.1854, dtype=float32), 'eval/episode_y_velocity': Array(-217.17412, dtype=float32), 'eval/episode_distance_from_origin_std': Array(522.7411, dtype=float32), 'eval/episode_distance_reward_std': Array(6.204185, dtype=float32), 'eval/episode_forward_reward_std': Array(1034.022, dtype=float32), 'eval/episode_reward_std': Array(1055.988, dtype=float32), 'eval/episode_reward_alive_std': Array(45.780052, dtype=float32), 'eval/episode_reward_linvel_std': Array(1034.022, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(53.85374, dtype=float32), 'eval/episode_x_position_std': Array(530.52405, dtype=float32), 'eval/episode_x_velocity_std': Array(206.80437, dtype=float32), 'eval/episode_y_position_std': Array(289.74844, dtype=float32), 'eval/episode_y_velocity_std': Array(80.640274, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4272391796112, 'eval/sps': 938.2290572594784, 'num_steps': 52183040}
{'eval/walltime': 87257.66000556946, 'training/sps': 2953.2139590926213, 'training/walltime': 17769.693817853928, 'training/entropy_loss': Array(0.01743509, dtype=float32), 'training/policy_loss': Array(0.00755303, dtype=float32), 'training/total_loss': Array(0.1037115, dtype=float32), 'training/v_loss': Array(0.07872337, dtype=float32), 'eval/episode_distance_from_origin': Array(7035.216, dtype=float32), 'eval/episode_distance_reward': Array(31.539486, dtype=float32), 'eval/episode_forward_reward': Array(5256.5547, dtype=float32), 'eval/episode_reward': Array(5264.913, dtype=float32), 'eval/episode_reward_alive': Array(412.97266, dtype=float32), 'eval/episode_reward_linvel': Array(5256.5547, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.15414, dtype=float32), 'eval/episode_x_position': Array(6960.9375, dtype=float32), 'eval/episode_x_velocity': Array(1051.311, dtype=float32), 'eval/episode_y_position': Array(-667.18677, dtype=float32), 'eval/episode_y_velocity': Array(-219.4906, dtype=float32), 'eval/episode_distance_from_origin_std': Array(531.3279, dtype=float32), 'eval/episode_distance_reward_std': Array(6.337818, dtype=float32), 'eval/episode_forward_reward_std': Array(1056.2961, dtype=float32), 'eval/episode_reward_std': Array(1077.7817, dtype=float32), 'eval/episode_reward_alive_std': Array(44.309162, dtype=float32), 'eval/episode_reward_linvel_std': Array(1056.2961, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.148823, dtype=float32), 'eval/episode_x_position_std': Array(533.0331, dtype=float32), 'eval/episode_x_velocity_std': Array(211.25919, dtype=float32), 'eval/episode_y_position_std': Array(272.92834, dtype=float32), 'eval/episode_y_velocity_std': Array(79.9421, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4192898273468, 'eval/sps': 938.2837292438459, 'num_steps': 52264960}
{'eval/walltime': 87394.08978652954, 'training/sps': 2959.202413432249, 'training/walltime': 17797.37695288658, 'training/entropy_loss': Array(0.01775008, dtype=float32), 'training/policy_loss': Array(0.00764819, dtype=float32), 'training/total_loss': Array(0.13234347, dtype=float32), 'training/v_loss': Array(0.10694519, dtype=float32), 'eval/episode_distance_from_origin': Array(6996.838, dtype=float32), 'eval/episode_distance_reward': Array(30.729713, dtype=float32), 'eval/episode_forward_reward': Array(5121.595, dtype=float32), 'eval/episode_reward': Array(5117.1772, dtype=float32), 'eval/episode_reward_alive': Array(404.29297, dtype=float32), 'eval/episode_reward_linvel': Array(5121.595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-439.44083, dtype=float32), 'eval/episode_x_position': Array(6922.1416, dtype=float32), 'eval/episode_x_velocity': Array(1024.3191, dtype=float32), 'eval/episode_y_position': Array(-644.1792, dtype=float32), 'eval/episode_y_velocity': Array(-209.2591, dtype=float32), 'eval/episode_distance_from_origin_std': Array(493.16068, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0449142, dtype=float32), 'eval/episode_forward_reward_std': Array(1007.47766, dtype=float32), 'eval/episode_reward_std': Array(1026.6635, dtype=float32), 'eval/episode_reward_alive_std': Array(47.36826, dtype=float32), 'eval/episode_reward_linvel_std': Array(1007.47766, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.992184, dtype=float32), 'eval/episode_x_position_std': Array(496.29773, dtype=float32), 'eval/episode_x_velocity_std': Array(201.49565, dtype=float32), 'eval/episode_y_position_std': Array(337.7291, dtype=float32), 'eval/episode_y_velocity_std': Array(89.15272, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.429780960083, 'eval/sps': 938.2115774080924, 'num_steps': 52346880}
{'eval/walltime': 87530.43854045868, 'training/sps': 2946.307060920653, 'training/walltime': 17825.18125104904, 'training/entropy_loss': Array(0.02068338, dtype=float32), 'training/policy_loss': Array(0.00923373, dtype=float32), 'training/total_loss': Array(0.24663101, dtype=float32), 'training/v_loss': Array(0.21671392, dtype=float32), 'eval/episode_distance_from_origin': Array(7062.883, dtype=float32), 'eval/episode_distance_reward': Array(31.089851, dtype=float32), 'eval/episode_forward_reward': Array(5181.618, dtype=float32), 'eval/episode_reward': Array(5179.6655, dtype=float32), 'eval/episode_reward_alive': Array(406.33594, dtype=float32), 'eval/episode_reward_linvel': Array(5181.618, dtype=float32), 'eval/episode_reward_quadctrl': Array(-439.37836, dtype=float32), 'eval/episode_x_position': Array(6986.7095, dtype=float32), 'eval/episode_x_velocity': Array(1036.3235, dtype=float32), 'eval/episode_y_position': Array(-689.3899, dtype=float32), 'eval/episode_y_velocity': Array(-218.04182, dtype=float32), 'eval/episode_distance_from_origin_std': Array(554.4732, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3351674, dtype=float32), 'eval/episode_forward_reward_std': Array(1055.8539, dtype=float32), 'eval/episode_reward_std': Array(1076.3547, dtype=float32), 'eval/episode_reward_alive_std': Array(48.345074, dtype=float32), 'eval/episode_reward_linvel_std': Array(1055.8539, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.7703, dtype=float32), 'eval/episode_x_position_std': Array(558.6971, dtype=float32), 'eval/episode_x_velocity_std': Array(211.1707, dtype=float32), 'eval/episode_y_position_std': Array(265.08228, dtype=float32), 'eval/episode_y_velocity_std': Array(78.92513, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34875392913818, 'eval/sps': 938.7691219130825, 'num_steps': 52428800}
{'eval/walltime': 87667.04533338547, 'training/sps': 2952.4968146132037, 'training/walltime': 17852.927258968353, 'training/entropy_loss': Array(0.02160504, dtype=float32), 'training/policy_loss': Array(0.00941853, dtype=float32), 'training/total_loss': Array(0.24552414, dtype=float32), 'training/v_loss': Array(0.21450056, dtype=float32), 'eval/episode_distance_from_origin': Array(7086.3257, dtype=float32), 'eval/episode_distance_reward': Array(30.951107, dtype=float32), 'eval/episode_forward_reward': Array(5158.494, dtype=float32), 'eval/episode_reward': Array(5159.9424, dtype=float32), 'eval/episode_reward_alive': Array(406.8125, dtype=float32), 'eval/episode_reward_linvel': Array(5158.494, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.31586, dtype=float32), 'eval/episode_x_position': Array(7007.351, dtype=float32), 'eval/episode_x_velocity': Array(1031.6987, dtype=float32), 'eval/episode_y_position': Array(-725.1859, dtype=float32), 'eval/episode_y_velocity': Array(-230.26208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(557.6986, dtype=float32), 'eval/episode_distance_reward_std': Array(5.981258, dtype=float32), 'eval/episode_forward_reward_std': Array(996.869, dtype=float32), 'eval/episode_reward_std': Array(1009.082, dtype=float32), 'eval/episode_reward_alive_std': Array(44.506187, dtype=float32), 'eval/episode_reward_linvel_std': Array(996.869, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.05283, dtype=float32), 'eval/episode_x_position_std': Array(562.7142, dtype=float32), 'eval/episode_x_velocity_std': Array(199.3737, dtype=float32), 'eval/episode_y_position_std': Array(240.07616, dtype=float32), 'eval/episode_y_velocity_std': Array(57.684704, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60679292678833, 'eval/sps': 936.9958642437279, 'num_steps': 52510720}
{'eval/walltime': 87803.39510655403, 'training/sps': 2940.891261857377, 'training/walltime': 17880.78276014328, 'training/entropy_loss': Array(0.02369339, dtype=float32), 'training/policy_loss': Array(0.00686033, dtype=float32), 'training/total_loss': Array(0.26980072, dtype=float32), 'training/v_loss': Array(0.23924701, dtype=float32), 'eval/episode_distance_from_origin': Array(7118.669, dtype=float32), 'eval/episode_distance_reward': Array(31.704788, dtype=float32), 'eval/episode_forward_reward': Array(5284.1064, dtype=float32), 'eval/episode_reward': Array(5284.3223, dtype=float32), 'eval/episode_reward_alive': Array(409.8828, dtype=float32), 'eval/episode_reward_linvel': Array(5284.1064, dtype=float32), 'eval/episode_reward_quadctrl': Array(-441.37122, dtype=float32), 'eval/episode_x_position': Array(7044.3604, dtype=float32), 'eval/episode_x_velocity': Array(1056.8213, dtype=float32), 'eval/episode_y_position': Array(-685.2793, dtype=float32), 'eval/episode_y_velocity': Array(-207.75488, dtype=float32), 'eval/episode_distance_from_origin_std': Array(562.1531, dtype=float32), 'eval/episode_distance_reward_std': Array(6.9898605, dtype=float32), 'eval/episode_forward_reward_std': Array(1164.9685, dtype=float32), 'eval/episode_reward_std': Array(1191.2961, dtype=float32), 'eval/episode_reward_alive_std': Array(48.31612, dtype=float32), 'eval/episode_reward_linvel_std': Array(1164.9685, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.19386, dtype=float32), 'eval/episode_x_position_std': Array(566.7603, dtype=float32), 'eval/episode_x_velocity_std': Array(232.99358, dtype=float32), 'eval/episode_y_position_std': Array(287.41556, dtype=float32), 'eval/episode_y_velocity_std': Array(88.62418, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34977316856384, 'eval/sps': 938.7621044426576, 'num_steps': 52592640}
{'eval/walltime': 87939.99524736404, 'training/sps': 2946.7405579208607, 'training/walltime': 17908.582967996597, 'training/entropy_loss': Array(0.0238268, dtype=float32), 'training/policy_loss': Array(0.00912566, dtype=float32), 'training/total_loss': Array(0.2111115, dtype=float32), 'training/v_loss': Array(0.17815904, dtype=float32), 'eval/episode_distance_from_origin': Array(7081.202, dtype=float32), 'eval/episode_distance_reward': Array(31.272324, dtype=float32), 'eval/episode_forward_reward': Array(5212.03, dtype=float32), 'eval/episode_reward': Array(5217.2695, dtype=float32), 'eval/episode_reward_alive': Array(408.03516, dtype=float32), 'eval/episode_reward_linvel': Array(5212.03, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.06686, dtype=float32), 'eval/episode_x_position': Array(7003.3022, dtype=float32), 'eval/episode_x_velocity': Array(1042.4059, dtype=float32), 'eval/episode_y_position': Array(-727.46936, dtype=float32), 'eval/episode_y_velocity': Array(-224.55609, dtype=float32), 'eval/episode_distance_from_origin_std': Array(544.2744, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4158607, dtype=float32), 'eval/episode_forward_reward_std': Array(1069.3025, dtype=float32), 'eval/episode_reward_std': Array(1085.8423, dtype=float32), 'eval/episode_reward_alive_std': Array(44.246475, dtype=float32), 'eval/episode_reward_linvel_std': Array(1069.3025, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.290276, dtype=float32), 'eval/episode_x_position_std': Array(552.0122, dtype=float32), 'eval/episode_x_velocity_std': Array(213.86057, dtype=float32), 'eval/episode_y_position_std': Array(237.11157, dtype=float32), 'eval/episode_y_velocity_std': Array(67.364845, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60014081001282, 'eval/sps': 937.0414938153385, 'num_steps': 52674560}
{'eval/walltime': 88076.2816081047, 'training/sps': 2943.763911489427, 'training/walltime': 17936.411286592484, 'training/entropy_loss': Array(0.02003321, dtype=float32), 'training/policy_loss': Array(0.00965171, dtype=float32), 'training/total_loss': Array(0.13526273, dtype=float32), 'training/v_loss': Array(0.1055778, dtype=float32), 'eval/episode_distance_from_origin': Array(7110.0503, dtype=float32), 'eval/episode_distance_reward': Array(31.35011, dtype=float32), 'eval/episode_forward_reward': Array(5224.994, dtype=float32), 'eval/episode_reward': Array(5221.964, dtype=float32), 'eval/episode_reward_alive': Array(400.2539, dtype=float32), 'eval/episode_reward_linvel': Array(5224.994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.6343, dtype=float32), 'eval/episode_x_position': Array(7035.5205, dtype=float32), 'eval/episode_x_velocity': Array(1044.9988, dtype=float32), 'eval/episode_y_position': Array(-695.5216, dtype=float32), 'eval/episode_y_velocity': Array(-221.56787, dtype=float32), 'eval/episode_distance_from_origin_std': Array(505.03253, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8931785, dtype=float32), 'eval/episode_forward_reward_std': Array(982.19104, dtype=float32), 'eval/episode_reward_std': Array(1002.08325, dtype=float32), 'eval/episode_reward_alive_std': Array(47.62455, dtype=float32), 'eval/episode_reward_linvel_std': Array(982.19104, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.747147, dtype=float32), 'eval/episode_x_position_std': Array(508.97647, dtype=float32), 'eval/episode_x_velocity_std': Array(196.438, dtype=float32), 'eval/episode_y_position_std': Array(248.30394, dtype=float32), 'eval/episode_y_velocity_std': Array(70.9993, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28636074066162, 'eval/sps': 939.1988993203092, 'num_steps': 52756480}
{'eval/walltime': 88212.79327464104, 'training/sps': 2958.3065250260734, 'training/walltime': 17964.102805137634, 'training/entropy_loss': Array(0.01624168, dtype=float32), 'training/policy_loss': Array(0.01014938, dtype=float32), 'training/total_loss': Array(0.09529629, dtype=float32), 'training/v_loss': Array(0.06890523, dtype=float32), 'eval/episode_distance_from_origin': Array(7070.7305, dtype=float32), 'eval/episode_distance_reward': Array(30.647738, dtype=float32), 'eval/episode_forward_reward': Array(5107.9326, dtype=float32), 'eval/episode_reward': Array(5103.6597, dtype=float32), 'eval/episode_reward_alive': Array(397.10156, dtype=float32), 'eval/episode_reward_linvel': Array(5107.9326, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.02176, dtype=float32), 'eval/episode_x_position': Array(6994.4824, dtype=float32), 'eval/episode_x_velocity': Array(1021.5865, dtype=float32), 'eval/episode_y_position': Array(-706.98114, dtype=float32), 'eval/episode_y_velocity': Array(-220.74548, dtype=float32), 'eval/episode_distance_from_origin_std': Array(509.69257, dtype=float32), 'eval/episode_distance_reward_std': Array(5.762974, dtype=float32), 'eval/episode_forward_reward_std': Array(960.4893, dtype=float32), 'eval/episode_reward_std': Array(971.97034, dtype=float32), 'eval/episode_reward_alive_std': Array(47.066, dtype=float32), 'eval/episode_reward_linvel_std': Array(960.4893, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.486618, dtype=float32), 'eval/episode_x_position_std': Array(516.38525, dtype=float32), 'eval/episode_x_velocity_std': Array(192.09793, dtype=float32), 'eval/episode_y_position_std': Array(239.11269, dtype=float32), 'eval/episode_y_velocity_std': Array(70.95002, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51166653633118, 'eval/sps': 937.6487977013606, 'num_steps': 52838400}
{'eval/walltime': 88349.06017136574, 'training/sps': 2942.4731305026744, 'training/walltime': 17991.943331241608, 'training/entropy_loss': Array(0.02037578, dtype=float32), 'training/policy_loss': Array(0.01299397, dtype=float32), 'training/total_loss': Array(0.30554745, dtype=float32), 'training/v_loss': Array(0.2721777, dtype=float32), 'eval/episode_distance_from_origin': Array(7067.078, dtype=float32), 'eval/episode_distance_reward': Array(31.204155, dtype=float32), 'eval/episode_forward_reward': Array(5200.667, dtype=float32), 'eval/episode_reward': Array(5205.702, dtype=float32), 'eval/episode_reward_alive': Array(408.41406, dtype=float32), 'eval/episode_reward_linvel': Array(5200.667, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.5832, dtype=float32), 'eval/episode_x_position': Array(6994.44, dtype=float32), 'eval/episode_x_velocity': Array(1040.1335, dtype=float32), 'eval/episode_y_position': Array(-660.65247, dtype=float32), 'eval/episode_y_velocity': Array(-206.49902, dtype=float32), 'eval/episode_distance_from_origin_std': Array(498.4777, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8226223, dtype=float32), 'eval/episode_forward_reward_std': Array(970.42993, dtype=float32), 'eval/episode_reward_std': Array(993.4628, dtype=float32), 'eval/episode_reward_alive_std': Array(49.785206, dtype=float32), 'eval/episode_reward_linvel_std': Array(970.42993, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.531395, dtype=float32), 'eval/episode_x_position_std': Array(504.75443, dtype=float32), 'eval/episode_x_velocity_std': Array(194.08612, dtype=float32), 'eval/episode_y_position_std': Array(281.6804, dtype=float32), 'eval/episode_y_velocity_std': Array(93.56131, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26689672470093, 'eval/sps': 939.3330520955321, 'num_steps': 52920320}
{'eval/walltime': 88485.68694663048, 'training/sps': 2944.539650542184, 'training/walltime': 18019.764318466187, 'training/entropy_loss': Array(0.02007698, dtype=float32), 'training/policy_loss': Array(0.00920924, dtype=float32), 'training/total_loss': Array(0.2905489, dtype=float32), 'training/v_loss': Array(0.26126269, dtype=float32), 'eval/episode_distance_from_origin': Array(7141.6777, dtype=float32), 'eval/episode_distance_reward': Array(32.048553, dtype=float32), 'eval/episode_forward_reward': Array(5341.4004, dtype=float32), 'eval/episode_reward': Array(5349.47, dtype=float32), 'eval/episode_reward_alive': Array(407.5547, dtype=float32), 'eval/episode_reward_linvel': Array(5341.4004, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.53378, dtype=float32), 'eval/episode_x_position': Array(7067.9575, dtype=float32), 'eval/episode_x_velocity': Array(1068.2803, dtype=float32), 'eval/episode_y_position': Array(-687.126, dtype=float32), 'eval/episode_y_velocity': Array(-209.78084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(517.5121, dtype=float32), 'eval/episode_distance_reward_std': Array(5.926519, dtype=float32), 'eval/episode_forward_reward_std': Array(987.7459, dtype=float32), 'eval/episode_reward_std': Array(1004.59314, dtype=float32), 'eval/episode_reward_alive_std': Array(46.36199, dtype=float32), 'eval/episode_reward_linvel_std': Array(987.7459, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.918438, dtype=float32), 'eval/episode_x_position_std': Array(521.73944, dtype=float32), 'eval/episode_x_velocity_std': Array(197.54918, dtype=float32), 'eval/episode_y_position_std': Array(264.931, dtype=float32), 'eval/episode_y_velocity_std': Array(92.98422, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62677526474, 'eval/sps': 936.8588239894852, 'num_steps': 53002240}
{'eval/walltime': 88622.31619429588, 'training/sps': 2930.019829290424, 'training/walltime': 18047.723173618317, 'training/entropy_loss': Array(0.02147875, dtype=float32), 'training/policy_loss': Array(0.00793499, dtype=float32), 'training/total_loss': Array(0.2519316, dtype=float32), 'training/v_loss': Array(0.22251786, dtype=float32), 'eval/episode_distance_from_origin': Array(7131.408, dtype=float32), 'eval/episode_distance_reward': Array(32.163223, dtype=float32), 'eval/episode_forward_reward': Array(5360.5117, dtype=float32), 'eval/episode_reward': Array(5366.08, dtype=float32), 'eval/episode_reward_alive': Array(402.79297, dtype=float32), 'eval/episode_reward_linvel': Array(5360.5117, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.38763, dtype=float32), 'eval/episode_x_position': Array(7056.6543, dtype=float32), 'eval/episode_x_velocity': Array(1072.1024, dtype=float32), 'eval/episode_y_position': Array(-676.0046, dtype=float32), 'eval/episode_y_velocity': Array(-219.51352, dtype=float32), 'eval/episode_distance_from_origin_std': Array(518.8665, dtype=float32), 'eval/episode_distance_reward_std': Array(5.877059, dtype=float32), 'eval/episode_forward_reward_std': Array(979.5015, dtype=float32), 'eval/episode_reward_std': Array(998.1998, dtype=float32), 'eval/episode_reward_alive_std': Array(42.078636, dtype=float32), 'eval/episode_reward_linvel_std': Array(979.5015, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.83747, dtype=float32), 'eval/episode_x_position_std': Array(524.4294, dtype=float32), 'eval/episode_x_velocity_std': Array(195.90039, dtype=float32), 'eval/episode_y_position_std': Array(279.7099, dtype=float32), 'eval/episode_y_velocity_std': Array(91.58437, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62924766540527, 'eval/sps': 936.8418708815725, 'num_steps': 53084160}
{'eval/walltime': 88759.4395763874, 'training/sps': 2932.598470680927, 'training/walltime': 18075.65744447708, 'training/entropy_loss': Array(0.02372889, dtype=float32), 'training/policy_loss': Array(0.01108824, dtype=float32), 'training/total_loss': Array(0.22470368, dtype=float32), 'training/v_loss': Array(0.18988656, dtype=float32), 'eval/episode_distance_from_origin': Array(7146.3447, dtype=float32), 'eval/episode_distance_reward': Array(32.48201, dtype=float32), 'eval/episode_forward_reward': Array(5413.6426, dtype=float32), 'eval/episode_reward': Array(5414.043, dtype=float32), 'eval/episode_reward_alive': Array(398.7422, dtype=float32), 'eval/episode_reward_linvel': Array(5413.6426, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.82397, dtype=float32), 'eval/episode_x_position': Array(7075.309, dtype=float32), 'eval/episode_x_velocity': Array(1082.7285, dtype=float32), 'eval/episode_y_position': Array(-656.4933, dtype=float32), 'eval/episode_y_velocity': Array(-214.6066, dtype=float32), 'eval/episode_distance_from_origin_std': Array(519.5947, dtype=float32), 'eval/episode_distance_reward_std': Array(5.914097, dtype=float32), 'eval/episode_forward_reward_std': Array(985.67584, dtype=float32), 'eval/episode_reward_std': Array(1007.438, dtype=float32), 'eval/episode_reward_alive_std': Array(45.45443, dtype=float32), 'eval/episode_reward_linvel_std': Array(985.67584, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.72623, dtype=float32), 'eval/episode_x_position_std': Array(524.45184, dtype=float32), 'eval/episode_x_velocity_std': Array(197.13518, dtype=float32), 'eval/episode_y_position_std': Array(252.00883, dtype=float32), 'eval/episode_y_velocity_std': Array(89.66284, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.12338209152222, 'eval/sps': 933.4658907010268, 'num_steps': 53166080}
{'eval/walltime': 88895.87079977989, 'training/sps': 2953.622933052085, 'training/walltime': 18103.392873764038, 'training/entropy_loss': Array(0.02394105, dtype=float32), 'training/policy_loss': Array(0.00565271, dtype=float32), 'training/total_loss': Array(0.18116638, dtype=float32), 'training/v_loss': Array(0.15157261, dtype=float32), 'eval/episode_distance_from_origin': Array(7152.125, dtype=float32), 'eval/episode_distance_reward': Array(32.546215, dtype=float32), 'eval/episode_forward_reward': Array(5424.343, dtype=float32), 'eval/episode_reward': Array(5425.325, dtype=float32), 'eval/episode_reward_alive': Array(401.45312, dtype=float32), 'eval/episode_reward_linvel': Array(5424.343, dtype=float32), 'eval/episode_reward_quadctrl': Array(-433.01685, dtype=float32), 'eval/episode_x_position': Array(7083.3374, dtype=float32), 'eval/episode_x_velocity': Array(1084.8684, dtype=float32), 'eval/episode_y_position': Array(-642.848, dtype=float32), 'eval/episode_y_velocity': Array(-216.34558, dtype=float32), 'eval/episode_distance_from_origin_std': Array(525.0299, dtype=float32), 'eval/episode_distance_reward_std': Array(5.605446, dtype=float32), 'eval/episode_forward_reward_std': Array(934.2336, dtype=float32), 'eval/episode_reward_std': Array(944.18677, dtype=float32), 'eval/episode_reward_alive_std': Array(47.516624, dtype=float32), 'eval/episode_reward_linvel_std': Array(934.2336, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.52455, dtype=float32), 'eval/episode_x_position_std': Array(526.08, dtype=float32), 'eval/episode_x_velocity_std': Array(186.84663, dtype=float32), 'eval/episode_y_position_std': Array(248.84709, dtype=float32), 'eval/episode_y_velocity_std': Array(70.038864, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43122339248657, 'eval/sps': 938.2016580747681, 'num_steps': 53248000}
{'eval/walltime': 89033.08609890938, 'training/sps': 2951.407350829746, 'training/walltime': 18131.14912366867, 'training/entropy_loss': Array(0.0136619, dtype=float32), 'training/policy_loss': Array(0.00947039, dtype=float32), 'training/total_loss': Array(0.05554946, dtype=float32), 'training/v_loss': Array(0.03241716, dtype=float32), 'eval/episode_distance_from_origin': Array(7162.335, dtype=float32), 'eval/episode_distance_reward': Array(32.83591, dtype=float32), 'eval/episode_forward_reward': Array(5472.6255, dtype=float32), 'eval/episode_reward': Array(5473.0557, dtype=float32), 'eval/episode_reward_alive': Array(397.13672, dtype=float32), 'eval/episode_reward_linvel': Array(5472.6255, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.5419, dtype=float32), 'eval/episode_x_position': Array(7092.5522, dtype=float32), 'eval/episode_x_velocity': Array(1094.5249, dtype=float32), 'eval/episode_y_position': Array(-637.14905, dtype=float32), 'eval/episode_y_velocity': Array(-211.4492, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.3653, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1736965, dtype=float32), 'eval/episode_forward_reward_std': Array(1028.9432, dtype=float32), 'eval/episode_reward_std': Array(1040.1093, dtype=float32), 'eval/episode_reward_alive_std': Array(44.41115, dtype=float32), 'eval/episode_reward_linvel_std': Array(1028.9432, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.88208, dtype=float32), 'eval/episode_x_position_std': Array(491.96625, dtype=float32), 'eval/episode_x_velocity_std': Array(205.78856, dtype=float32), 'eval/episode_y_position_std': Array(271.38583, dtype=float32), 'eval/episode_y_velocity_std': Array(88.38781, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.21529912948608, 'eval/sps': 932.840585649346, 'num_steps': 53329920}
{'eval/walltime': 89169.64388656616, 'training/sps': 2946.0626244567675, 'training/walltime': 18158.955728769302, 'training/entropy_loss': Array(0.01889106, dtype=float32), 'training/policy_loss': Array(0.00687156, dtype=float32), 'training/total_loss': Array(0.22906353, dtype=float32), 'training/v_loss': Array(0.20330091, dtype=float32), 'eval/episode_distance_from_origin': Array(7176.1035, dtype=float32), 'eval/episode_distance_reward': Array(32.992092, dtype=float32), 'eval/episode_forward_reward': Array(5498.6567, dtype=float32), 'eval/episode_reward': Array(5508.422, dtype=float32), 'eval/episode_reward_alive': Array(403.89453, dtype=float32), 'eval/episode_reward_linvel': Array(5498.6567, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.1217, dtype=float32), 'eval/episode_x_position': Array(7106.037, dtype=float32), 'eval/episode_x_velocity': Array(1099.7313, dtype=float32), 'eval/episode_y_position': Array(-621.3788, dtype=float32), 'eval/episode_y_velocity': Array(-202.75186, dtype=float32), 'eval/episode_distance_from_origin_std': Array(510.44672, dtype=float32), 'eval/episode_distance_reward_std': Array(6.64929, dtype=float32), 'eval/episode_forward_reward_std': Array(1108.2069, dtype=float32), 'eval/episode_reward_std': Array(1121.9366, dtype=float32), 'eval/episode_reward_alive_std': Array(47.41339, dtype=float32), 'eval/episode_reward_linvel_std': Array(1108.2069, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.251827, dtype=float32), 'eval/episode_x_position_std': Array(518.29224, dtype=float32), 'eval/episode_x_velocity_std': Array(221.6414, dtype=float32), 'eval/episode_y_position_std': Array(314.91663, dtype=float32), 'eval/episode_y_velocity_std': Array(101.32143, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55778765678406, 'eval/sps': 937.3321155561433, 'num_steps': 53411840}
{'eval/walltime': 89307.08642911911, 'training/sps': 2946.5773625103543, 'training/walltime': 18186.757476329803, 'training/entropy_loss': Array(0.02090935, dtype=float32), 'training/policy_loss': Array(0.0129137, dtype=float32), 'training/total_loss': Array(0.26847887, dtype=float32), 'training/v_loss': Array(0.23465584, dtype=float32), 'eval/episode_distance_from_origin': Array(7200.0005, dtype=float32), 'eval/episode_distance_reward': Array(32.98739, dtype=float32), 'eval/episode_forward_reward': Array(5497.872, dtype=float32), 'eval/episode_reward': Array(5509.354, dtype=float32), 'eval/episode_reward_alive': Array(404.35156, dtype=float32), 'eval/episode_reward_linvel': Array(5497.872, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.8564, dtype=float32), 'eval/episode_x_position': Array(7129.576, dtype=float32), 'eval/episode_x_velocity': Array(1099.5745, dtype=float32), 'eval/episode_y_position': Array(-670.13354, dtype=float32), 'eval/episode_y_velocity': Array(-213.99567, dtype=float32), 'eval/episode_distance_from_origin_std': Array(521.6006, dtype=float32), 'eval/episode_distance_reward_std': Array(6.350867, dtype=float32), 'eval/episode_forward_reward_std': Array(1058.4717, dtype=float32), 'eval/episode_reward_std': Array(1078.1769, dtype=float32), 'eval/episode_reward_alive_std': Array(47.88554, dtype=float32), 'eval/episode_reward_linvel_std': Array(1058.4717, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.305634, dtype=float32), 'eval/episode_x_position_std': Array(529.365, dtype=float32), 'eval/episode_x_velocity_std': Array(211.69427, dtype=float32), 'eval/episode_y_position_std': Array(229.00935, dtype=float32), 'eval/episode_y_velocity_std': Array(79.59908, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.442542552948, 'eval/sps': 931.2982546920625, 'num_steps': 53493760}
{'eval/walltime': 89443.74400782585, 'training/sps': 2945.6222309139885, 'training/walltime': 18214.5682387352, 'training/entropy_loss': Array(0.02082732, dtype=float32), 'training/policy_loss': Array(0.00721157, dtype=float32), 'training/total_loss': Array(0.2711907, dtype=float32), 'training/v_loss': Array(0.24315181, dtype=float32), 'eval/episode_distance_from_origin': Array(7189.7993, dtype=float32), 'eval/episode_distance_reward': Array(32.72818, dtype=float32), 'eval/episode_forward_reward': Array(5454.67, dtype=float32), 'eval/episode_reward': Array(5462.743, dtype=float32), 'eval/episode_reward_alive': Array(403.22266, dtype=float32), 'eval/episode_reward_linvel': Array(5454.67, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.87833, dtype=float32), 'eval/episode_x_position': Array(7120.2676, dtype=float32), 'eval/episode_x_velocity': Array(1090.9342, dtype=float32), 'eval/episode_y_position': Array(-656.3047, dtype=float32), 'eval/episode_y_velocity': Array(-209.3448, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.1173, dtype=float32), 'eval/episode_distance_reward_std': Array(5.254053, dtype=float32), 'eval/episode_forward_reward_std': Array(875.6677, dtype=float32), 'eval/episode_reward_std': Array(896.2968, dtype=float32), 'eval/episode_reward_alive_std': Array(46.486004, dtype=float32), 'eval/episode_reward_linvel_std': Array(875.6677, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.28036, dtype=float32), 'eval/episode_x_position_std': Array(461.54337, dtype=float32), 'eval/episode_x_velocity_std': Array(175.13356, dtype=float32), 'eval/episode_y_position_std': Array(252.99292, dtype=float32), 'eval/episode_y_velocity_std': Array(81.23355, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65757870674133, 'eval/sps': 936.6476503632488, 'num_steps': 53575680}
{'eval/walltime': 89580.83485627174, 'training/sps': 2954.9463373015055, 'training/walltime': 18242.291246414185, 'training/entropy_loss': Array(0.02201886, dtype=float32), 'training/policy_loss': Array(0.00739391, dtype=float32), 'training/total_loss': Array(0.24301963, dtype=float32), 'training/v_loss': Array(0.21360685, dtype=float32), 'eval/episode_distance_from_origin': Array(7153.2, dtype=float32), 'eval/episode_distance_reward': Array(32.525692, dtype=float32), 'eval/episode_forward_reward': Array(5420.9214, dtype=float32), 'eval/episode_reward': Array(5426.2275, dtype=float32), 'eval/episode_reward_alive': Array(403.89453, dtype=float32), 'eval/episode_reward_linvel': Array(5420.9214, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.1145, dtype=float32), 'eval/episode_x_position': Array(7081.7983, dtype=float32), 'eval/episode_x_velocity': Array(1084.1843, dtype=float32), 'eval/episode_y_position': Array(-666.48846, dtype=float32), 'eval/episode_y_velocity': Array(-219.13127, dtype=float32), 'eval/episode_distance_from_origin_std': Array(439.63135, dtype=float32), 'eval/episode_distance_reward_std': Array(5.248579, dtype=float32), 'eval/episode_forward_reward_std': Array(874.75586, dtype=float32), 'eval/episode_reward_std': Array(883.8971, dtype=float32), 'eval/episode_reward_alive_std': Array(41.396317, dtype=float32), 'eval/episode_reward_linvel_std': Array(874.75586, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.739475, dtype=float32), 'eval/episode_x_position_std': Array(447.98312, dtype=float32), 'eval/episode_x_velocity_std': Array(174.95128, dtype=float32), 'eval/episode_y_position_std': Array(255.62592, dtype=float32), 'eval/episode_y_velocity_std': Array(69.87551, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.09084844589233, 'eval/sps': 933.68741568858, 'num_steps': 53657600}
{'eval/walltime': 89717.15198779106, 'training/sps': 2956.4973967523833, 'training/walltime': 18269.99970984459, 'training/entropy_loss': Array(0.02236791, dtype=float32), 'training/policy_loss': Array(0.00697086, dtype=float32), 'training/total_loss': Array(0.20020473, dtype=float32), 'training/v_loss': Array(0.17086595, dtype=float32), 'eval/episode_distance_from_origin': Array(7096.6396, dtype=float32), 'eval/episode_distance_reward': Array(31.926077, dtype=float32), 'eval/episode_forward_reward': Array(5320.9863, dtype=float32), 'eval/episode_reward': Array(5326.49, dtype=float32), 'eval/episode_reward_alive': Array(401.8164, dtype=float32), 'eval/episode_reward_linvel': Array(5320.9863, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.23938, dtype=float32), 'eval/episode_x_position': Array(7022.7305, dtype=float32), 'eval/episode_x_velocity': Array(1064.1975, dtype=float32), 'eval/episode_y_position': Array(-669.20703, dtype=float32), 'eval/episode_y_velocity': Array(-226.33426, dtype=float32), 'eval/episode_distance_from_origin_std': Array(514.1069, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7837634, dtype=float32), 'eval/episode_forward_reward_std': Array(963.954, dtype=float32), 'eval/episode_reward_std': Array(977.4399, dtype=float32), 'eval/episode_reward_alive_std': Array(43.05941, dtype=float32), 'eval/episode_reward_linvel_std': Array(963.954, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.32304, dtype=float32), 'eval/episode_x_position_std': Array(518.89075, dtype=float32), 'eval/episode_x_velocity_std': Array(192.79091, dtype=float32), 'eval/episode_y_position_std': Array(277.15112, dtype=float32), 'eval/episode_y_velocity_std': Array(67.90402, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31713151931763, 'eval/sps': 938.9868945552232, 'num_steps': 53739520}
{'eval/walltime': 89854.21476626396, 'training/sps': 2955.9177996358876, 'training/walltime': 18297.713606357574, 'training/entropy_loss': Array(0.01387879, dtype=float32), 'training/policy_loss': Array(0.00439499, dtype=float32), 'training/total_loss': Array(0.06595388, dtype=float32), 'training/v_loss': Array(0.0476801, dtype=float32), 'eval/episode_distance_from_origin': Array(7240.416, dtype=float32), 'eval/episode_distance_reward': Array(33.15837, dtype=float32), 'eval/episode_forward_reward': Array(5526.3677, dtype=float32), 'eval/episode_reward': Array(5529.2197, dtype=float32), 'eval/episode_reward_alive': Array(398.89062, dtype=float32), 'eval/episode_reward_linvel': Array(5526.3677, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.1974, dtype=float32), 'eval/episode_x_position': Array(7173.7607, dtype=float32), 'eval/episode_x_velocity': Array(1105.2734, dtype=float32), 'eval/episode_y_position': Array(-631.3983, dtype=float32), 'eval/episode_y_velocity': Array(-208.21051, dtype=float32), 'eval/episode_distance_from_origin_std': Array(546.9344, dtype=float32), 'eval/episode_distance_reward_std': Array(5.694295, dtype=float32), 'eval/episode_forward_reward_std': Array(949.043, dtype=float32), 'eval/episode_reward_std': Array(954.5458, dtype=float32), 'eval/episode_reward_alive_std': Array(47.679996, dtype=float32), 'eval/episode_reward_linvel_std': Array(949.043, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.432, dtype=float32), 'eval/episode_x_position_std': Array(553.9874, dtype=float32), 'eval/episode_x_velocity_std': Array(189.80855, dtype=float32), 'eval/episode_y_position_std': Array(239.16818, dtype=float32), 'eval/episode_y_velocity_std': Array(85.02281, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.0627784729004, 'eval/sps': 933.8786315739816, 'num_steps': 53821440}
{'eval/walltime': 89990.5223827362, 'training/sps': 2955.377372696473, 'training/walltime': 18325.432570695877, 'training/entropy_loss': Array(0.01978452, dtype=float32), 'training/policy_loss': Array(0.0124002, dtype=float32), 'training/total_loss': Array(0.2155998, dtype=float32), 'training/v_loss': Array(0.18341509, dtype=float32), 'eval/episode_distance_from_origin': Array(7212.414, dtype=float32), 'eval/episode_distance_reward': Array(33.428852, dtype=float32), 'eval/episode_forward_reward': Array(5571.4487, dtype=float32), 'eval/episode_reward': Array(5583.957, dtype=float32), 'eval/episode_reward_alive': Array(407.90234, dtype=float32), 'eval/episode_reward_linvel': Array(5571.4487, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.82324, dtype=float32), 'eval/episode_x_position': Array(7145.826, dtype=float32), 'eval/episode_x_velocity': Array(1114.2897, dtype=float32), 'eval/episode_y_position': Array(-606.5415, dtype=float32), 'eval/episode_y_velocity': Array(-195.36969, dtype=float32), 'eval/episode_distance_from_origin_std': Array(505.9478, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2282357, dtype=float32), 'eval/episode_forward_reward_std': Array(1038.032, dtype=float32), 'eval/episode_reward_std': Array(1057.9839, dtype=float32), 'eval/episode_reward_alive_std': Array(44.516415, dtype=float32), 'eval/episode_reward_linvel_std': Array(1038.032, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.731266, dtype=float32), 'eval/episode_x_position_std': Array(512.4181, dtype=float32), 'eval/episode_x_velocity_std': Array(207.60645, dtype=float32), 'eval/episode_y_position_std': Array(300.38443, dtype=float32), 'eval/episode_y_velocity_std': Array(97.94689, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30761647224426, 'eval/sps': 939.0524411822878, 'num_steps': 53903360}
{'eval/walltime': 90127.60951948166, 'training/sps': 2958.7077643833904, 'training/walltime': 18353.12033390999, 'training/entropy_loss': Array(0.02069777, dtype=float32), 'training/policy_loss': Array(0.01011739, dtype=float32), 'training/total_loss': Array(0.29141152, dtype=float32), 'training/v_loss': Array(0.26059633, dtype=float32), 'eval/episode_distance_from_origin': Array(7235.4893, dtype=float32), 'eval/episode_distance_reward': Array(33.560608, dtype=float32), 'eval/episode_forward_reward': Array(5593.406, dtype=float32), 'eval/episode_reward': Array(5595.163, dtype=float32), 'eval/episode_reward_alive': Array(387.95703, dtype=float32), 'eval/episode_reward_linvel': Array(5593.406, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.7606, dtype=float32), 'eval/episode_x_position': Array(7168.7617, dtype=float32), 'eval/episode_x_velocity': Array(1118.6812, dtype=float32), 'eval/episode_y_position': Array(-621.5563, dtype=float32), 'eval/episode_y_velocity': Array(-206.71042, dtype=float32), 'eval/episode_distance_from_origin_std': Array(501.38065, dtype=float32), 'eval/episode_distance_reward_std': Array(5.744613, dtype=float32), 'eval/episode_forward_reward_std': Array(957.4286, dtype=float32), 'eval/episode_reward_std': Array(976.577, dtype=float32), 'eval/episode_reward_alive_std': Array(46.97132, dtype=float32), 'eval/episode_reward_linvel_std': Array(957.4286, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.68803, dtype=float32), 'eval/episode_x_position_std': Array(504.49173, dtype=float32), 'eval/episode_x_velocity_std': Array(191.4859, dtype=float32), 'eval/episode_y_position_std': Array(287.16733, dtype=float32), 'eval/episode_y_velocity_std': Array(87.769455, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.08713674545288, 'eval/sps': 933.7126957263239, 'num_steps': 53985280}
{'eval/walltime': 90263.91940021515, 'training/sps': 2947.748711671297, 'training/walltime': 18380.91103386879, 'training/entropy_loss': Array(0.02068725, dtype=float32), 'training/policy_loss': Array(0.12655163, dtype=float32), 'training/total_loss': Array(0.38238233, dtype=float32), 'training/v_loss': Array(0.23514344, dtype=float32), 'eval/episode_distance_from_origin': Array(7159.382, dtype=float32), 'eval/episode_distance_reward': Array(32.83162, dtype=float32), 'eval/episode_forward_reward': Array(5471.908, dtype=float32), 'eval/episode_reward': Array(5483.449, dtype=float32), 'eval/episode_reward_alive': Array(403.10156, dtype=float32), 'eval/episode_reward_linvel': Array(5471.908, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.39285, dtype=float32), 'eval/episode_x_position': Array(7093.6406, dtype=float32), 'eval/episode_x_velocity': Array(1094.3818, dtype=float32), 'eval/episode_y_position': Array(-586.61084, dtype=float32), 'eval/episode_y_velocity': Array(-215.83246, dtype=float32), 'eval/episode_distance_from_origin_std': Array(518.847, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9460406, dtype=float32), 'eval/episode_forward_reward_std': Array(991.0007, dtype=float32), 'eval/episode_reward_std': Array(1005.22217, dtype=float32), 'eval/episode_reward_alive_std': Array(40.23395, dtype=float32), 'eval/episode_reward_linvel_std': Array(991.0007, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.498165, dtype=float32), 'eval/episode_x_position_std': Array(523.0767, dtype=float32), 'eval/episode_x_velocity_std': Array(198.20021, dtype=float32), 'eval/episode_y_position_std': Array(273.4649, dtype=float32), 'eval/episode_y_velocity_std': Array(87.50136, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30988073349, 'eval/sps': 939.0368424594452, 'num_steps': 54067200}
{'eval/walltime': 90400.95094799995, 'training/sps': 2953.112177467373, 'training/walltime': 18408.651260137558, 'training/entropy_loss': Array(0.02204036, dtype=float32), 'training/policy_loss': Array(0.00848336, dtype=float32), 'training/total_loss': Array(0.28565124, dtype=float32), 'training/v_loss': Array(0.25512755, dtype=float32), 'eval/episode_distance_from_origin': Array(7155.6675, dtype=float32), 'eval/episode_distance_reward': Array(33.00528, dtype=float32), 'eval/episode_forward_reward': Array(5500.853, dtype=float32), 'eval/episode_reward': Array(5504.9644, dtype=float32), 'eval/episode_reward_alive': Array(407.0547, dtype=float32), 'eval/episode_reward_linvel': Array(5500.853, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.9483, dtype=float32), 'eval/episode_x_position': Array(7093.8867, dtype=float32), 'eval/episode_x_velocity': Array(1100.1704, dtype=float32), 'eval/episode_y_position': Array(-534.965, dtype=float32), 'eval/episode_y_velocity': Array(-192.79013, dtype=float32), 'eval/episode_distance_from_origin_std': Array(554.13824, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5091434, dtype=float32), 'eval/episode_forward_reward_std': Array(1084.8506, dtype=float32), 'eval/episode_reward_std': Array(1096.74, dtype=float32), 'eval/episode_reward_alive_std': Array(40.252438, dtype=float32), 'eval/episode_reward_linvel_std': Array(1084.8506, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.20544, dtype=float32), 'eval/episode_x_position_std': Array(559.79193, dtype=float32), 'eval/episode_x_velocity_std': Array(216.97006, dtype=float32), 'eval/episode_y_position_std': Array(317.52094, dtype=float32), 'eval/episode_y_velocity_std': Array(94.4848, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 137.0315477848053, 'eval/sps': 934.0914706809817, 'num_steps': 54149120}
{'eval/walltime': 90537.39467263222, 'training/sps': 2944.279991025533, 'training/walltime': 18436.474700927734, 'training/entropy_loss': Array(0.02216302, dtype=float32), 'training/policy_loss': Array(0.01155294, dtype=float32), 'training/total_loss': Array(0.23055172, dtype=float32), 'training/v_loss': Array(0.19683576, dtype=float32), 'eval/episode_distance_from_origin': Array(7269.259, dtype=float32), 'eval/episode_distance_reward': Array(33.47969, dtype=float32), 'eval/episode_forward_reward': Array(5579.921, dtype=float32), 'eval/episode_reward': Array(5581.0073, dtype=float32), 'eval/episode_reward_alive': Array(404.3047, dtype=float32), 'eval/episode_reward_linvel': Array(5579.921, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.69824, dtype=float32), 'eval/episode_x_position': Array(7204.2656, dtype=float32), 'eval/episode_x_velocity': Array(1115.9841, dtype=float32), 'eval/episode_y_position': Array(-609.2553, dtype=float32), 'eval/episode_y_velocity': Array(-211.1048, dtype=float32), 'eval/episode_distance_from_origin_std': Array(434.37088, dtype=float32), 'eval/episode_distance_reward_std': Array(4.958437, dtype=float32), 'eval/episode_forward_reward_std': Array(826.39984, dtype=float32), 'eval/episode_reward_std': Array(835.24475, dtype=float32), 'eval/episode_reward_alive_std': Array(45.559208, dtype=float32), 'eval/episode_reward_linvel_std': Array(826.39984, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.828136, dtype=float32), 'eval/episode_x_position_std': Array(441.36124, dtype=float32), 'eval/episode_x_velocity_std': Array(165.28001, dtype=float32), 'eval/episode_y_position_std': Array(245.06924, dtype=float32), 'eval/episode_y_velocity_std': Array(72.37557, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44372463226318, 'eval/sps': 938.1156982116963, 'num_steps': 54231040}
{'eval/walltime': 90673.9978363514, 'training/sps': 2963.421234113233, 'training/walltime': 18464.118425369263, 'training/entropy_loss': Array(0.01669705, dtype=float32), 'training/policy_loss': Array(0.00380588, dtype=float32), 'training/total_loss': Array(0.11369003, dtype=float32), 'training/v_loss': Array(0.09318711, dtype=float32), 'eval/episode_distance_from_origin': Array(7252.914, dtype=float32), 'eval/episode_distance_reward': Array(33.3947, dtype=float32), 'eval/episode_forward_reward': Array(5565.755, dtype=float32), 'eval/episode_reward': Array(5567.3984, dtype=float32), 'eval/episode_reward_alive': Array(404.3789, dtype=float32), 'eval/episode_reward_linvel': Array(5565.755, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.13107, dtype=float32), 'eval/episode_x_position': Array(7189.4395, dtype=float32), 'eval/episode_x_velocity': Array(1113.151, dtype=float32), 'eval/episode_y_position': Array(-581.72314, dtype=float32), 'eval/episode_y_velocity': Array(-206.95181, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.45914, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4451394, dtype=float32), 'eval/episode_forward_reward_std': Array(907.51807, dtype=float32), 'eval/episode_reward_std': Array(919.40845, dtype=float32), 'eval/episode_reward_alive_std': Array(40.10936, dtype=float32), 'eval/episode_reward_linvel_std': Array(907.51807, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.234383, dtype=float32), 'eval/episode_x_position_std': Array(487.71848, dtype=float32), 'eval/episode_x_velocity_std': Array(181.50351, dtype=float32), 'eval/episode_y_position_std': Array(277.56406, dtype=float32), 'eval/episode_y_velocity_std': Array(86.85684, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60316371917725, 'eval/sps': 937.0207579023335, 'num_steps': 54312960}
{'eval/walltime': 90810.53959727287, 'training/sps': 2960.2238573476902, 'training/walltime': 18491.792008161545, 'training/entropy_loss': Array(0.01838257, dtype=float32), 'training/policy_loss': Array(0.00725959, dtype=float32), 'training/total_loss': Array(0.21389872, dtype=float32), 'training/v_loss': Array(0.18825656, dtype=float32), 'eval/episode_distance_from_origin': Array(7291.5283, dtype=float32), 'eval/episode_distance_reward': Array(34.481964, dtype=float32), 'eval/episode_forward_reward': Array(5746.9653, dtype=float32), 'eval/episode_reward': Array(5755.171, dtype=float32), 'eval/episode_reward_alive': Array(403.1953, dtype=float32), 'eval/episode_reward_linvel': Array(5746.9653, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.4713, dtype=float32), 'eval/episode_x_position': Array(7232.0635, dtype=float32), 'eval/episode_x_velocity': Array(1149.3928, dtype=float32), 'eval/episode_y_position': Array(-527.42505, dtype=float32), 'eval/episode_y_velocity': Array(-202.5828, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.39993, dtype=float32), 'eval/episode_distance_reward_std': Array(6.125741, dtype=float32), 'eval/episode_forward_reward_std': Array(1020.9501, dtype=float32), 'eval/episode_reward_std': Array(1034.263, dtype=float32), 'eval/episode_reward_alive_std': Array(46.891342, dtype=float32), 'eval/episode_reward_linvel_std': Array(1020.9501, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.32949, dtype=float32), 'eval/episode_x_position_std': Array(465.43152, dtype=float32), 'eval/episode_x_velocity_std': Array(204.18993, dtype=float32), 'eval/episode_y_position_std': Array(294.11633, dtype=float32), 'eval/episode_y_velocity_std': Array(89.67496, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54176092147827, 'eval/sps': 937.4421359162753, 'num_steps': 54394880}
{'eval/walltime': 90947.23690676689, 'training/sps': 2966.753446707753, 'training/walltime': 18519.404683589935, 'training/entropy_loss': Array(0.0200223, dtype=float32), 'training/policy_loss': Array(0.01077022, dtype=float32), 'training/total_loss': Array(0.2924626, dtype=float32), 'training/v_loss': Array(0.26167008, dtype=float32), 'eval/episode_distance_from_origin': Array(7292.8896, dtype=float32), 'eval/episode_distance_reward': Array(34.772858, dtype=float32), 'eval/episode_forward_reward': Array(5795.4478, dtype=float32), 'eval/episode_reward': Array(5801.67, dtype=float32), 'eval/episode_reward_alive': Array(401.83203, dtype=float32), 'eval/episode_reward_linvel': Array(5795.4478, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.3828, dtype=float32), 'eval/episode_x_position': Array(7230.661, dtype=float32), 'eval/episode_x_velocity': Array(1159.0895, dtype=float32), 'eval/episode_y_position': Array(-564.47144, dtype=float32), 'eval/episode_y_velocity': Array(-213.41568, dtype=float32), 'eval/episode_distance_from_origin_std': Array(504.89645, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2200446, dtype=float32), 'eval/episode_forward_reward_std': Array(1036.6681, dtype=float32), 'eval/episode_reward_std': Array(1056.8569, dtype=float32), 'eval/episode_reward_alive_std': Array(43.925198, dtype=float32), 'eval/episode_reward_linvel_std': Array(1036.6681, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.645063, dtype=float32), 'eval/episode_x_position_std': Array(513.24756, dtype=float32), 'eval/episode_x_velocity_std': Array(207.33362, dtype=float32), 'eval/episode_y_position_std': Array(266.93777, dtype=float32), 'eval/episode_y_velocity_std': Array(78.5183, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69730949401855, 'eval/sps': 936.3754156814687, 'num_steps': 54476800}
{'eval/walltime': 91083.7813000679, 'training/sps': 2952.0148791617958, 'training/walltime': 18547.15522122383, 'training/entropy_loss': Array(0.0206542, dtype=float32), 'training/policy_loss': Array(0.00577072, dtype=float32), 'training/total_loss': Array(0.22945553, dtype=float32), 'training/v_loss': Array(0.20303062, dtype=float32), 'eval/episode_distance_from_origin': Array(7229.7627, dtype=float32), 'eval/episode_distance_reward': Array(33.45955, dtype=float32), 'eval/episode_forward_reward': Array(5576.5645, dtype=float32), 'eval/episode_reward': Array(5582.7217, dtype=float32), 'eval/episode_reward_alive': Array(398.85156, dtype=float32), 'eval/episode_reward_linvel': Array(5576.5645, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.15317, dtype=float32), 'eval/episode_x_position': Array(7165.367, dtype=float32), 'eval/episode_x_velocity': Array(1115.3127, dtype=float32), 'eval/episode_y_position': Array(-578.5385, dtype=float32), 'eval/episode_y_velocity': Array(-197.68094, dtype=float32), 'eval/episode_distance_from_origin_std': Array(505.55432, dtype=float32), 'eval/episode_distance_reward_std': Array(5.393606, dtype=float32), 'eval/episode_forward_reward_std': Array(898.92773, dtype=float32), 'eval/episode_reward_std': Array(918.76984, dtype=float32), 'eval/episode_reward_alive_std': Array(46.86043, dtype=float32), 'eval/episode_reward_linvel_std': Array(898.92773, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.750015, dtype=float32), 'eval/episode_x_position_std': Array(510.48627, dtype=float32), 'eval/episode_x_velocity_std': Array(179.78545, dtype=float32), 'eval/episode_y_position_std': Array(301.2898, dtype=float32), 'eval/episode_y_velocity_std': Array(107.21081, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54439330101013, 'eval/sps': 937.4240633800749, 'num_steps': 54558720}
{'eval/walltime': 91220.45772314072, 'training/sps': 2955.1476189181185, 'training/walltime': 18574.87634062767, 'training/entropy_loss': Array(0.02164314, dtype=float32), 'training/policy_loss': Array(0.00823511, dtype=float32), 'training/total_loss': Array(0.2850365, dtype=float32), 'training/v_loss': Array(0.25515828, dtype=float32), 'eval/episode_distance_from_origin': Array(7197.82, dtype=float32), 'eval/episode_distance_reward': Array(33.537956, dtype=float32), 'eval/episode_forward_reward': Array(5589.631, dtype=float32), 'eval/episode_reward': Array(5595.163, dtype=float32), 'eval/episode_reward_alive': Array(403.02734, dtype=float32), 'eval/episode_reward_linvel': Array(5589.631, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.03348, dtype=float32), 'eval/episode_x_position': Array(7135.866, dtype=float32), 'eval/episode_x_velocity': Array(1117.9265, dtype=float32), 'eval/episode_y_position': Array(-566.28546, dtype=float32), 'eval/episode_y_velocity': Array(-202.90924, dtype=float32), 'eval/episode_distance_from_origin_std': Array(504.69278, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7970176, dtype=float32), 'eval/episode_forward_reward_std': Array(966.16205, dtype=float32), 'eval/episode_reward_std': Array(981.2899, dtype=float32), 'eval/episode_reward_alive_std': Array(40.95068, dtype=float32), 'eval/episode_reward_linvel_std': Array(966.16205, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.18343, dtype=float32), 'eval/episode_x_position_std': Array(510.38507, dtype=float32), 'eval/episode_x_velocity_std': Array(193.2325, dtype=float32), 'eval/episode_y_position_std': Array(273.73978, dtype=float32), 'eval/episode_y_velocity_std': Array(85.223206, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67642307281494, 'eval/sps': 936.5185093540783, 'num_steps': 54640640}
{'eval/walltime': 91356.99120736122, 'training/sps': 2947.8781968635503, 'training/walltime': 18602.665819883347, 'training/entropy_loss': Array(0.02152819, dtype=float32), 'training/policy_loss': Array(0.01237449, dtype=float32), 'training/total_loss': Array(0.23985006, dtype=float32), 'training/v_loss': Array(0.20594737, dtype=float32), 'eval/episode_distance_from_origin': Array(7228.0605, dtype=float32), 'eval/episode_distance_reward': Array(33.478523, dtype=float32), 'eval/episode_forward_reward': Array(5579.7275, dtype=float32), 'eval/episode_reward': Array(5589.7393, dtype=float32), 'eval/episode_reward_alive': Array(408.58594, dtype=float32), 'eval/episode_reward_linvel': Array(5579.7275, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.052, dtype=float32), 'eval/episode_x_position': Array(7164.623, dtype=float32), 'eval/episode_x_velocity': Array(1115.9453, dtype=float32), 'eval/episode_y_position': Array(-576.3895, dtype=float32), 'eval/episode_y_velocity': Array(-206.9202, dtype=float32), 'eval/episode_distance_from_origin_std': Array(569.99603, dtype=float32), 'eval/episode_distance_reward_std': Array(6.436576, dtype=float32), 'eval/episode_forward_reward_std': Array(1072.7559, dtype=float32), 'eval/episode_reward_std': Array(1087.9208, dtype=float32), 'eval/episode_reward_alive_std': Array(40.921375, dtype=float32), 'eval/episode_reward_linvel_std': Array(1072.7559, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.946247, dtype=float32), 'eval/episode_x_position_std': Array(575.98145, dtype=float32), 'eval/episode_x_velocity_std': Array(214.55103, dtype=float32), 'eval/episode_y_position_std': Array(290.01538, dtype=float32), 'eval/episode_y_velocity_std': Array(85.601, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53348422050476, 'eval/sps': 937.4989639411605, 'num_steps': 54722560}
{'eval/walltime': 91493.55966639519, 'training/sps': 2960.0398102541453, 'training/walltime': 18630.341123342514, 'training/entropy_loss': Array(0.0183665, dtype=float32), 'training/policy_loss': Array(0.00447483, dtype=float32), 'training/total_loss': Array(0.16541275, dtype=float32), 'training/v_loss': Array(0.14257142, dtype=float32), 'eval/episode_distance_from_origin': Array(7093.7036, dtype=float32), 'eval/episode_distance_reward': Array(32.54949, dtype=float32), 'eval/episode_forward_reward': Array(5424.8877, dtype=float32), 'eval/episode_reward': Array(5427.753, dtype=float32), 'eval/episode_reward_alive': Array(405.75, dtype=float32), 'eval/episode_reward_linvel': Array(5424.8877, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.43448, dtype=float32), 'eval/episode_x_position': Array(7033.3286, dtype=float32), 'eval/episode_x_velocity': Array(1084.9777, dtype=float32), 'eval/episode_y_position': Array(-505.31766, dtype=float32), 'eval/episode_y_velocity': Array(-185.07323, dtype=float32), 'eval/episode_distance_from_origin_std': Array(605.91986, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6037855, dtype=float32), 'eval/episode_forward_reward_std': Array(1100.6229, dtype=float32), 'eval/episode_reward_std': Array(1122.3989, dtype=float32), 'eval/episode_reward_alive_std': Array(42.871857, dtype=float32), 'eval/episode_reward_linvel_std': Array(1100.6229, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.1492, dtype=float32), 'eval/episode_x_position_std': Array(611.4795, dtype=float32), 'eval/episode_x_velocity_std': Array(220.12466, dtype=float32), 'eval/episode_y_position_std': Array(334.4315, dtype=float32), 'eval/episode_y_velocity_std': Array(109.03592, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56845903396606, 'eval/sps': 937.2588729888575, 'num_steps': 54804480}
{'eval/walltime': 91630.00229144096, 'training/sps': 2954.8126984059827, 'training/walltime': 18658.065384864807, 'training/entropy_loss': Array(0.01668414, dtype=float32), 'training/policy_loss': Array(0.00548922, dtype=float32), 'training/total_loss': Array(0.07579075, dtype=float32), 'training/v_loss': Array(0.05361738, dtype=float32), 'eval/episode_distance_from_origin': Array(7200.7744, dtype=float32), 'eval/episode_distance_reward': Array(33.75718, dtype=float32), 'eval/episode_forward_reward': Array(5626.168, dtype=float32), 'eval/episode_reward': Array(5623.83, dtype=float32), 'eval/episode_reward_alive': Array(397.3828, dtype=float32), 'eval/episode_reward_linvel': Array(5626.168, dtype=float32), 'eval/episode_reward_quadctrl': Array(-433.47833, dtype=float32), 'eval/episode_x_position': Array(7143.669, dtype=float32), 'eval/episode_x_velocity': Array(1125.2336, dtype=float32), 'eval/episode_y_position': Array(-490.51062, dtype=float32), 'eval/episode_y_velocity': Array(-191.42758, dtype=float32), 'eval/episode_distance_from_origin_std': Array(589.3807, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5376062, dtype=float32), 'eval/episode_forward_reward_std': Array(1089.5941, dtype=float32), 'eval/episode_reward_std': Array(1103.7817, dtype=float32), 'eval/episode_reward_alive_std': Array(39.832485, dtype=float32), 'eval/episode_reward_linvel_std': Array(1089.5941, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.993923, dtype=float32), 'eval/episode_x_position_std': Array(596.1704, dtype=float32), 'eval/episode_x_velocity_std': Array(217.91885, dtype=float32), 'eval/episode_y_position_std': Array(303.33478, dtype=float32), 'eval/episode_y_velocity_std': Array(91.13106, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44262504577637, 'eval/sps': 938.1232584542853, 'num_steps': 54886400}
{'eval/walltime': 91766.55512547493, 'training/sps': 2959.601576022235, 'training/walltime': 18685.744786262512, 'training/entropy_loss': Array(0.02010738, dtype=float32), 'training/policy_loss': Array(0.0109033, dtype=float32), 'training/total_loss': Array(0.44265753, dtype=float32), 'training/v_loss': Array(0.41164684, dtype=float32), 'eval/episode_distance_from_origin': Array(7257.338, dtype=float32), 'eval/episode_distance_reward': Array(34.386887, dtype=float32), 'eval/episode_forward_reward': Array(5731.12, dtype=float32), 'eval/episode_reward': Array(5733.818, dtype=float32), 'eval/episode_reward_alive': Array(401.23828, dtype=float32), 'eval/episode_reward_linvel': Array(5731.12, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.92712, dtype=float32), 'eval/episode_x_position': Array(7197.2363, dtype=float32), 'eval/episode_x_velocity': Array(1146.2239, dtype=float32), 'eval/episode_y_position': Array(-489.86807, dtype=float32), 'eval/episode_y_velocity': Array(-192.56, dtype=float32), 'eval/episode_distance_from_origin_std': Array(641.05975, dtype=float32), 'eval/episode_distance_reward_std': Array(7.313782, dtype=float32), 'eval/episode_forward_reward_std': Array(1218.9556, dtype=float32), 'eval/episode_reward_std': Array(1243.9149, dtype=float32), 'eval/episode_reward_alive_std': Array(48.61532, dtype=float32), 'eval/episode_reward_linvel_std': Array(1218.9556, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.102898, dtype=float32), 'eval/episode_x_position_std': Array(646.17706, dtype=float32), 'eval/episode_x_velocity_std': Array(243.79105, dtype=float32), 'eval/episode_y_position_std': Array(355.9198, dtype=float32), 'eval/episode_y_velocity_std': Array(106.42427, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55283403396606, 'eval/sps': 937.3661184370685, 'num_steps': 54968320}
{'eval/walltime': 91902.9841504097, 'training/sps': 2954.9237456599335, 'training/walltime': 18713.468005895615, 'training/entropy_loss': Array(0.02019683, dtype=float32), 'training/policy_loss': Array(0.01198008, dtype=float32), 'training/total_loss': Array(0.27680814, dtype=float32), 'training/v_loss': Array(0.24463125, dtype=float32), 'eval/episode_distance_from_origin': Array(7217.8506, dtype=float32), 'eval/episode_distance_reward': Array(33.819283, dtype=float32), 'eval/episode_forward_reward': Array(5636.5176, dtype=float32), 'eval/episode_reward': Array(5638.2085, dtype=float32), 'eval/episode_reward_alive': Array(400.5703, dtype=float32), 'eval/episode_reward_linvel': Array(5636.5176, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.6986, dtype=float32), 'eval/episode_x_position': Array(7157.2163, dtype=float32), 'eval/episode_x_velocity': Array(1127.3035, dtype=float32), 'eval/episode_y_position': Array(-526.58826, dtype=float32), 'eval/episode_y_velocity': Array(-201.13156, dtype=float32), 'eval/episode_distance_from_origin_std': Array(560.4526, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2929997, dtype=float32), 'eval/episode_forward_reward_std': Array(1048.8254, dtype=float32), 'eval/episode_reward_std': Array(1070.7234, dtype=float32), 'eval/episode_reward_alive_std': Array(41.04693, dtype=float32), 'eval/episode_reward_linvel_std': Array(1048.8254, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.329304, dtype=float32), 'eval/episode_x_position_std': Array(568.33325, dtype=float32), 'eval/episode_x_velocity_std': Array(209.76512, dtype=float32), 'eval/episode_y_position_std': Array(284.99554, dtype=float32), 'eval/episode_y_velocity_std': Array(94.36314, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42902493476868, 'eval/sps': 938.2167765341804, 'num_steps': 55050240}
{'eval/walltime': 92039.55970573425, 'training/sps': 2961.2973304520046, 'training/walltime': 18741.131556987762, 'training/entropy_loss': Array(0.02029129, dtype=float32), 'training/policy_loss': Array(0.00620763, dtype=float32), 'training/total_loss': Array(0.24385403, dtype=float32), 'training/v_loss': Array(0.21735512, dtype=float32), 'eval/episode_distance_from_origin': Array(7304.964, dtype=float32), 'eval/episode_distance_reward': Array(34.416164, dtype=float32), 'eval/episode_forward_reward': Array(5735.998, dtype=float32), 'eval/episode_reward': Array(5743.085, dtype=float32), 'eval/episode_reward_alive': Array(400.5078, dtype=float32), 'eval/episode_reward_linvel': Array(5735.998, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.83728, dtype=float32), 'eval/episode_x_position': Array(7244.9497, dtype=float32), 'eval/episode_x_velocity': Array(1147.1997, dtype=float32), 'eval/episode_y_position': Array(-525.6362, dtype=float32), 'eval/episode_y_velocity': Array(-186.57686, dtype=float32), 'eval/episode_distance_from_origin_std': Array(535.8672, dtype=float32), 'eval/episode_distance_reward_std': Array(6.205568, dtype=float32), 'eval/episode_forward_reward_std': Array(1034.2543, dtype=float32), 'eval/episode_reward_std': Array(1050.1812, dtype=float32), 'eval/episode_reward_alive_std': Array(42.207077, dtype=float32), 'eval/episode_reward_linvel_std': Array(1034.2543, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.98888, dtype=float32), 'eval/episode_x_position_std': Array(544.12805, dtype=float32), 'eval/episode_x_velocity_std': Array(206.85083, dtype=float32), 'eval/episode_y_position_std': Array(303.13187, dtype=float32), 'eval/episode_y_velocity_std': Array(103.984726, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57555532455444, 'eval/sps': 937.2101742205937, 'num_steps': 55132160}
{'eval/walltime': 92175.99786138535, 'training/sps': 2951.3604507816526, 'training/walltime': 18768.888247966766, 'training/entropy_loss': Array(0.02100796, dtype=float32), 'training/policy_loss': Array(0.00557064, dtype=float32), 'training/total_loss': Array(0.2455604, dtype=float32), 'training/v_loss': Array(0.2189818, dtype=float32), 'eval/episode_distance_from_origin': Array(7288.6523, dtype=float32), 'eval/episode_distance_reward': Array(34.55413, dtype=float32), 'eval/episode_forward_reward': Array(5758.995, dtype=float32), 'eval/episode_reward': Array(5768.048, dtype=float32), 'eval/episode_reward_alive': Array(401.60547, dtype=float32), 'eval/episode_reward_linvel': Array(5758.995, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.10532, dtype=float32), 'eval/episode_x_position': Array(7230.41, dtype=float32), 'eval/episode_x_velocity': Array(1151.7988, dtype=float32), 'eval/episode_y_position': Array(-486.612, dtype=float32), 'eval/episode_y_velocity': Array(-191.13268, dtype=float32), 'eval/episode_distance_from_origin_std': Array(551.2345, dtype=float32), 'eval/episode_distance_reward_std': Array(6.092011, dtype=float32), 'eval/episode_forward_reward_std': Array(1015.32916, dtype=float32), 'eval/episode_reward_std': Array(1026.2018, dtype=float32), 'eval/episode_reward_alive_std': Array(41.844376, dtype=float32), 'eval/episode_reward_linvel_std': Array(1015.32916, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.184603, dtype=float32), 'eval/episode_x_position_std': Array(557.4623, dtype=float32), 'eval/episode_x_velocity_std': Array(203.06577, dtype=float32), 'eval/episode_y_position_std': Array(334.19196, dtype=float32), 'eval/episode_y_velocity_std': Array(105.9712, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43815565109253, 'eval/sps': 938.1539891768175, 'num_steps': 55214080}
{'eval/walltime': 92312.60205101967, 'training/sps': 2961.8229976618145, 'training/walltime': 18796.546889305115, 'training/entropy_loss': Array(0.02070983, dtype=float32), 'training/policy_loss': Array(0.00721036, dtype=float32), 'training/total_loss': Array(0.19140776, dtype=float32), 'training/v_loss': Array(0.16348755, dtype=float32), 'eval/episode_distance_from_origin': Array(7219.4453, dtype=float32), 'eval/episode_distance_reward': Array(33.356754, dtype=float32), 'eval/episode_forward_reward': Array(5559.4316, dtype=float32), 'eval/episode_reward': Array(5564.645, dtype=float32), 'eval/episode_reward_alive': Array(399.4961, dtype=float32), 'eval/episode_reward_linvel': Array(5559.4316, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.63898, dtype=float32), 'eval/episode_x_position': Array(7154.318, dtype=float32), 'eval/episode_x_velocity': Array(1111.8862, dtype=float32), 'eval/episode_y_position': Array(-609.5237, dtype=float32), 'eval/episode_y_velocity': Array(-217.22699, dtype=float32), 'eval/episode_distance_from_origin_std': Array(512.83417, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9732723, dtype=float32), 'eval/episode_forward_reward_std': Array(995.5383, dtype=float32), 'eval/episode_reward_std': Array(1010.89264, dtype=float32), 'eval/episode_reward_alive_std': Array(42.83519, dtype=float32), 'eval/episode_reward_linvel_std': Array(995.5383, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.535824, dtype=float32), 'eval/episode_x_position_std': Array(518.2612, dtype=float32), 'eval/episode_x_velocity_std': Array(199.1075, dtype=float32), 'eval/episode_y_position_std': Array(220.14879, dtype=float32), 'eval/episode_y_velocity_std': Array(72.22336, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60418963432312, 'eval/sps': 937.0137207551559, 'num_steps': 55296000}
{'eval/walltime': 92448.90309524536, 'training/sps': 2949.3265504028595, 'training/walltime': 18824.322721719742, 'training/entropy_loss': Array(0.01466731, dtype=float32), 'training/policy_loss': Array(0.00491542, dtype=float32), 'training/total_loss': Array(0.05466795, dtype=float32), 'training/v_loss': Array(0.03508522, dtype=float32), 'eval/episode_distance_from_origin': Array(7245.5713, dtype=float32), 'eval/episode_distance_reward': Array(33.775616, dtype=float32), 'eval/episode_forward_reward': Array(5629.241, dtype=float32), 'eval/episode_reward': Array(5632.491, dtype=float32), 'eval/episode_reward_alive': Array(399.79297, dtype=float32), 'eval/episode_reward_linvel': Array(5629.241, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.31876, dtype=float32), 'eval/episode_x_position': Array(7183.885, dtype=float32), 'eval/episode_x_velocity': Array(1125.8481, dtype=float32), 'eval/episode_y_position': Array(-516.1798, dtype=float32), 'eval/episode_y_velocity': Array(-183.51576, dtype=float32), 'eval/episode_distance_from_origin_std': Array(513.8933, dtype=float32), 'eval/episode_distance_reward_std': Array(5.914606, dtype=float32), 'eval/episode_forward_reward_std': Array(985.7602, dtype=float32), 'eval/episode_reward_std': Array(1000.75757, dtype=float32), 'eval/episode_reward_alive_std': Array(44.05193, dtype=float32), 'eval/episode_reward_linvel_std': Array(985.7602, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.244896, dtype=float32), 'eval/episode_x_position_std': Array(517.9702, dtype=float32), 'eval/episode_x_velocity_std': Array(197.15207, dtype=float32), 'eval/episode_y_position_std': Array(349.73038, dtype=float32), 'eval/episode_y_velocity_std': Array(126.76767, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30104422569275, 'eval/sps': 939.0977209833584, 'num_steps': 55377920}
{'eval/walltime': 92585.52690887451, 'training/sps': 2942.7823489268867, 'training/walltime': 18852.16032242775, 'training/entropy_loss': Array(0.01929657, dtype=float32), 'training/policy_loss': Array(0.00939636, dtype=float32), 'training/total_loss': Array(0.30581295, dtype=float32), 'training/v_loss': Array(0.27712, dtype=float32), 'eval/episode_distance_from_origin': Array(7276.4585, dtype=float32), 'eval/episode_distance_reward': Array(34.51053, dtype=float32), 'eval/episode_forward_reward': Array(5751.7256, dtype=float32), 'eval/episode_reward': Array(5751.0645, dtype=float32), 'eval/episode_reward_alive': Array(399.4453, dtype=float32), 'eval/episode_reward_linvel': Array(5751.7256, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.61533, dtype=float32), 'eval/episode_x_position': Array(7220.0747, dtype=float32), 'eval/episode_x_velocity': Array(1150.345, dtype=float32), 'eval/episode_y_position': Array(-499.6199, dtype=float32), 'eval/episode_y_velocity': Array(-183.10193, dtype=float32), 'eval/episode_distance_from_origin_std': Array(536.3338, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3064566, dtype=float32), 'eval/episode_forward_reward_std': Array(1051.0695, dtype=float32), 'eval/episode_reward_std': Array(1074.2118, dtype=float32), 'eval/episode_reward_alive_std': Array(47.132717, dtype=float32), 'eval/episode_reward_linvel_std': Array(1051.0695, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.05922, dtype=float32), 'eval/episode_x_position_std': Array(540.16583, dtype=float32), 'eval/episode_x_velocity_std': Array(210.21376, dtype=float32), 'eval/episode_y_position_std': Array(289.81848, dtype=float32), 'eval/episode_y_velocity_std': Array(94.47278, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6238136291504, 'eval/sps': 936.8791325606037, 'num_steps': 55459840}
{'eval/walltime': 92721.8625266552, 'training/sps': 2947.244965707437, 'training/walltime': 18879.955772399902, 'training/entropy_loss': Array(0.02052045, dtype=float32), 'training/policy_loss': Array(0.01209091, dtype=float32), 'training/total_loss': Array(0.3067858, dtype=float32), 'training/v_loss': Array(0.27417442, dtype=float32), 'eval/episode_distance_from_origin': Array(7229.3047, dtype=float32), 'eval/episode_distance_reward': Array(33.600258, dtype=float32), 'eval/episode_forward_reward': Array(5600.0156, dtype=float32), 'eval/episode_reward': Array(5603.751, dtype=float32), 'eval/episode_reward_alive': Array(405.64453, dtype=float32), 'eval/episode_reward_linvel': Array(5600.0156, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.50958, dtype=float32), 'eval/episode_x_position': Array(7170.9053, dtype=float32), 'eval/episode_x_velocity': Array(1120.0032, dtype=float32), 'eval/episode_y_position': Array(-517.5529, dtype=float32), 'eval/episode_y_velocity': Array(-191.8979, dtype=float32), 'eval/episode_distance_from_origin_std': Array(570.9166, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4301667, dtype=float32), 'eval/episode_forward_reward_std': Array(1071.6865, dtype=float32), 'eval/episode_reward_std': Array(1086.089, dtype=float32), 'eval/episode_reward_alive_std': Array(48.4081, dtype=float32), 'eval/episode_reward_linvel_std': Array(1071.6865, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.813137, dtype=float32), 'eval/episode_x_position_std': Array(572.8376, dtype=float32), 'eval/episode_x_velocity_std': Array(214.33736, dtype=float32), 'eval/episode_y_position_std': Array(304.23483, dtype=float32), 'eval/episode_y_velocity_std': Array(101.90639, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33561778068542, 'eval/sps': 938.8595737755455, 'num_steps': 55541760}
{'eval/walltime': 92858.43133115768, 'training/sps': 2937.5359403547764, 'training/walltime': 18907.84309077263, 'training/entropy_loss': Array(0.02097479, dtype=float32), 'training/policy_loss': Array(0.00820751, dtype=float32), 'training/total_loss': Array(0.24207741, dtype=float32), 'training/v_loss': Array(0.21289513, dtype=float32), 'eval/episode_distance_from_origin': Array(7326.543, dtype=float32), 'eval/episode_distance_reward': Array(35.338814, dtype=float32), 'eval/episode_forward_reward': Array(5889.772, dtype=float32), 'eval/episode_reward': Array(5908.0625, dtype=float32), 'eval/episode_reward_alive': Array(414.08203, dtype=float32), 'eval/episode_reward_linvel': Array(5889.772, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.1309, dtype=float32), 'eval/episode_x_position': Array(7269.412, dtype=float32), 'eval/episode_x_velocity': Array(1177.9545, dtype=float32), 'eval/episode_y_position': Array(-512.28766, dtype=float32), 'eval/episode_y_velocity': Array(-184.60164, dtype=float32), 'eval/episode_distance_from_origin_std': Array(583.3664, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5697656, dtype=float32), 'eval/episode_forward_reward_std': Array(1094.9546, dtype=float32), 'eval/episode_reward_std': Array(1110.205, dtype=float32), 'eval/episode_reward_alive_std': Array(34.129566, dtype=float32), 'eval/episode_reward_linvel_std': Array(1094.9546, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.543877, dtype=float32), 'eval/episode_x_position_std': Array(586.192, dtype=float32), 'eval/episode_x_velocity_std': Array(218.99095, dtype=float32), 'eval/episode_y_position_std': Array(301.1066, dtype=float32), 'eval/episode_y_velocity_std': Array(98.996994, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56880450248718, 'eval/sps': 937.2565020708581, 'num_steps': 55623680}
{'eval/walltime': 92994.75954031944, 'training/sps': 2948.4652969385024, 'training/walltime': 18935.627036571503, 'training/entropy_loss': Array(0.0210843, dtype=float32), 'training/policy_loss': Array(0.00674465, dtype=float32), 'training/total_loss': Array(0.24128303, dtype=float32), 'training/v_loss': Array(0.21345408, dtype=float32), 'eval/episode_distance_from_origin': Array(7281.874, dtype=float32), 'eval/episode_distance_reward': Array(34.494717, dtype=float32), 'eval/episode_forward_reward': Array(5749.09, dtype=float32), 'eval/episode_reward': Array(5761.2188, dtype=float32), 'eval/episode_reward_alive': Array(407.17188, dtype=float32), 'eval/episode_reward_linvel': Array(5749.09, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.53775, dtype=float32), 'eval/episode_x_position': Array(7222.1353, dtype=float32), 'eval/episode_x_velocity': Array(1149.8181, dtype=float32), 'eval/episode_y_position': Array(-516.4437, dtype=float32), 'eval/episode_y_velocity': Array(-190.31802, dtype=float32), 'eval/episode_distance_from_origin_std': Array(527.94977, dtype=float32), 'eval/episode_distance_reward_std': Array(6.102909, dtype=float32), 'eval/episode_forward_reward_std': Array(1017.14545, dtype=float32), 'eval/episode_reward_std': Array(1030.7291, dtype=float32), 'eval/episode_reward_alive_std': Array(37.68089, dtype=float32), 'eval/episode_reward_linvel_std': Array(1017.14545, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.258347, dtype=float32), 'eval/episode_x_position_std': Array(533.7096, dtype=float32), 'eval/episode_x_velocity_std': Array(203.42915, dtype=float32), 'eval/episode_y_position_std': Array(313.99173, dtype=float32), 'eval/episode_y_velocity_std': Array(106.77463, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32820916175842, 'eval/sps': 938.9105951514649, 'num_steps': 55705600}
{'eval/walltime': 93131.38107156754, 'training/sps': 2935.566889109603, 'training/walltime': 18963.53306055069, 'training/entropy_loss': Array(0.02056382, dtype=float32), 'training/policy_loss': Array(0.00483246, dtype=float32), 'training/total_loss': Array(0.19575855, dtype=float32), 'training/v_loss': Array(0.17036228, dtype=float32), 'eval/episode_distance_from_origin': Array(7324.3975, dtype=float32), 'eval/episode_distance_reward': Array(34.353996, dtype=float32), 'eval/episode_forward_reward': Array(5725.6377, dtype=float32), 'eval/episode_reward': Array(5730.2354, dtype=float32), 'eval/episode_reward_alive': Array(397.8828, dtype=float32), 'eval/episode_reward_linvel': Array(5725.6377, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.63837, dtype=float32), 'eval/episode_x_position': Array(7263.8774, dtype=float32), 'eval/episode_x_velocity': Array(1145.1274, dtype=float32), 'eval/episode_y_position': Array(-547.62225, dtype=float32), 'eval/episode_y_velocity': Array(-197.38394, dtype=float32), 'eval/episode_distance_from_origin_std': Array(526.27234, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2874856, dtype=float32), 'eval/episode_forward_reward_std': Array(1047.9058, dtype=float32), 'eval/episode_reward_std': Array(1069.5417, dtype=float32), 'eval/episode_reward_alive_std': Array(49.587696, dtype=float32), 'eval/episode_reward_linvel_std': Array(1047.9058, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.73862, dtype=float32), 'eval/episode_x_position_std': Array(530.588, dtype=float32), 'eval/episode_x_velocity_std': Array(209.5813, dtype=float32), 'eval/episode_y_position_std': Array(310.58203, dtype=float32), 'eval/episode_y_velocity_std': Array(92.281456, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62153124809265, 'eval/sps': 936.8947839382893, 'num_steps': 55787520}
{'eval/walltime': 93267.74295926094, 'training/sps': 2953.4506983064443, 'training/walltime': 18991.270107269287, 'training/entropy_loss': Array(0.01449151, dtype=float32), 'training/policy_loss': Array(0.00375528, dtype=float32), 'training/total_loss': Array(0.07038091, dtype=float32), 'training/v_loss': Array(0.05213413, dtype=float32), 'eval/episode_distance_from_origin': Array(7296.3223, dtype=float32), 'eval/episode_distance_reward': Array(34.243423, dtype=float32), 'eval/episode_forward_reward': Array(5707.209, dtype=float32), 'eval/episode_reward': Array(5720.897, dtype=float32), 'eval/episode_reward_alive': Array(409.42578, dtype=float32), 'eval/episode_reward_linvel': Array(5707.209, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.98096, dtype=float32), 'eval/episode_x_position': Array(7238.801, dtype=float32), 'eval/episode_x_velocity': Array(1141.4419, dtype=float32), 'eval/episode_y_position': Array(-497.6975, dtype=float32), 'eval/episode_y_velocity': Array(-187.5171, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.76956, dtype=float32), 'eval/episode_distance_reward_std': Array(6.143993, dtype=float32), 'eval/episode_forward_reward_std': Array(1023.9913, dtype=float32), 'eval/episode_reward_std': Array(1040.4972, dtype=float32), 'eval/episode_reward_alive_std': Array(45.86423, dtype=float32), 'eval/episode_reward_linvel_std': Array(1023.9913, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.679775, dtype=float32), 'eval/episode_x_position_std': Array(487.13132, dtype=float32), 'eval/episode_x_velocity_std': Array(204.79826, dtype=float32), 'eval/episode_y_position_std': Array(333.12112, dtype=float32), 'eval/episode_y_velocity_std': Array(109.39731, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.36188769340515, 'eval/sps': 938.6787038897119, 'num_steps': 55869440}
{'eval/walltime': 93404.43667125702, 'training/sps': 2949.7125187087327, 'training/walltime': 19019.042305231094, 'training/entropy_loss': Array(0.01978554, dtype=float32), 'training/policy_loss': Array(0.00739103, dtype=float32), 'training/total_loss': Array(0.25843525, dtype=float32), 'training/v_loss': Array(0.23125869, dtype=float32), 'eval/episode_distance_from_origin': Array(7297.494, dtype=float32), 'eval/episode_distance_reward': Array(34.002586, dtype=float32), 'eval/episode_forward_reward': Array(5667.0693, dtype=float32), 'eval/episode_reward': Array(5671.5146, dtype=float32), 'eval/episode_reward_alive': Array(398.95703, dtype=float32), 'eval/episode_reward_linvel': Array(5667.0693, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.51398, dtype=float32), 'eval/episode_x_position': Array(7236.302, dtype=float32), 'eval/episode_x_velocity': Array(1133.4136, dtype=float32), 'eval/episode_y_position': Array(-539.65356, dtype=float32), 'eval/episode_y_velocity': Array(-188.14607, dtype=float32), 'eval/episode_distance_from_origin_std': Array(538.3821, dtype=float32), 'eval/episode_distance_reward_std': Array(6.026853, dtype=float32), 'eval/episode_forward_reward_std': Array(1004.46893, dtype=float32), 'eval/episode_reward_std': Array(1019.1821, dtype=float32), 'eval/episode_reward_alive_std': Array(47.23764, dtype=float32), 'eval/episode_reward_linvel_std': Array(1004.46893, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.275993, dtype=float32), 'eval/episode_x_position_std': Array(544.07367, dtype=float32), 'eval/episode_x_velocity_std': Array(200.89363, dtype=float32), 'eval/episode_y_position_std': Array(338.33585, dtype=float32), 'eval/episode_y_velocity_std': Array(111.4333, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6937119960785, 'eval/sps': 936.4000591605275, 'num_steps': 55951360}
{'eval/walltime': 93540.8845012188, 'training/sps': 2951.694817310176, 'training/walltime': 19046.795851945877, 'training/entropy_loss': Array(0.02113308, dtype=float32), 'training/policy_loss': Array(0.01140777, dtype=float32), 'training/total_loss': Array(0.3102302, dtype=float32), 'training/v_loss': Array(0.27768934, dtype=float32), 'eval/episode_distance_from_origin': Array(7377.574, dtype=float32), 'eval/episode_distance_reward': Array(34.53082, dtype=float32), 'eval/episode_forward_reward': Array(5755.108, dtype=float32), 'eval/episode_reward': Array(5769.447, dtype=float32), 'eval/episode_reward_alive': Array(404.58984, dtype=float32), 'eval/episode_reward_linvel': Array(5755.108, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.78217, dtype=float32), 'eval/episode_x_position': Array(7312.7, dtype=float32), 'eval/episode_x_velocity': Array(1151.0216, dtype=float32), 'eval/episode_y_position': Array(-600.72687, dtype=float32), 'eval/episode_y_velocity': Array(-205.64214, dtype=float32), 'eval/episode_distance_from_origin_std': Array(508.9409, dtype=float32), 'eval/episode_distance_reward_std': Array(5.847027, dtype=float32), 'eval/episode_forward_reward_std': Array(974.49744, dtype=float32), 'eval/episode_reward_std': Array(985.37994, dtype=float32), 'eval/episode_reward_alive_std': Array(40.691265, dtype=float32), 'eval/episode_reward_linvel_std': Array(974.49744, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.05778, dtype=float32), 'eval/episode_x_position_std': Array(515.69794, dtype=float32), 'eval/episode_x_velocity_std': Array(194.89955, dtype=float32), 'eval/episode_y_position_std': Array(307.84592, dtype=float32), 'eval/episode_y_velocity_std': Array(98.35705, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44782996177673, 'eval/sps': 938.08747296206, 'num_steps': 56033280}
{'eval/walltime': 93677.59581851959, 'training/sps': 2935.022720674195, 'training/walltime': 19074.70704984665, 'training/entropy_loss': Array(0.02012281, dtype=float32), 'training/policy_loss': Array(0.00516744, dtype=float32), 'training/total_loss': Array(0.22444734, dtype=float32), 'training/v_loss': Array(0.19915709, dtype=float32), 'eval/episode_distance_from_origin': Array(7312.5205, dtype=float32), 'eval/episode_distance_reward': Array(34.82848, dtype=float32), 'eval/episode_forward_reward': Array(5804.718, dtype=float32), 'eval/episode_reward': Array(5811.9697, dtype=float32), 'eval/episode_reward_alive': Array(398.7422, dtype=float32), 'eval/episode_reward_linvel': Array(5804.718, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.31836, dtype=float32), 'eval/episode_x_position': Array(7252.697, dtype=float32), 'eval/episode_x_velocity': Array(1160.9434, dtype=float32), 'eval/episode_y_position': Array(-502.76138, dtype=float32), 'eval/episode_y_velocity': Array(-184.5703, dtype=float32), 'eval/episode_distance_from_origin_std': Array(520.26935, dtype=float32), 'eval/episode_distance_reward_std': Array(6.332724, dtype=float32), 'eval/episode_forward_reward_std': Array(1055.4474, dtype=float32), 'eval/episode_reward_std': Array(1079.5449, dtype=float32), 'eval/episode_reward_alive_std': Array(46.60958, dtype=float32), 'eval/episode_reward_linvel_std': Array(1055.4474, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.440235, dtype=float32), 'eval/episode_x_position_std': Array(526.1896, dtype=float32), 'eval/episode_x_velocity_std': Array(211.0895, dtype=float32), 'eval/episode_y_position_std': Array(368.31213, dtype=float32), 'eval/episode_y_velocity_std': Array(112.96663, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7113173007965, 'eval/sps': 936.2794721549673, 'num_steps': 56115200}
{'eval/walltime': 93814.03633022308, 'training/sps': 2954.780173559571, 'training/walltime': 19102.431616544724, 'training/entropy_loss': Array(0.02110765, dtype=float32), 'training/policy_loss': Array(0.00954252, dtype=float32), 'training/total_loss': Array(0.26952374, dtype=float32), 'training/v_loss': Array(0.2388736, dtype=float32), 'eval/episode_distance_from_origin': Array(7393.2554, dtype=float32), 'eval/episode_distance_reward': Array(35.05925, dtype=float32), 'eval/episode_forward_reward': Array(5843.1797, dtype=float32), 'eval/episode_reward': Array(5854.96, dtype=float32), 'eval/episode_reward_alive': Array(404.17188, dtype=float32), 'eval/episode_reward_linvel': Array(5843.1797, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.45035, dtype=float32), 'eval/episode_x_position': Array(7335.901, dtype=float32), 'eval/episode_x_velocity': Array(1168.6357, dtype=float32), 'eval/episode_y_position': Array(-522.18036, dtype=float32), 'eval/episode_y_velocity': Array(-193.11925, dtype=float32), 'eval/episode_distance_from_origin_std': Array(478.2911, dtype=float32), 'eval/episode_distance_reward_std': Array(5.922035, dtype=float32), 'eval/episode_forward_reward_std': Array(986.9986, dtype=float32), 'eval/episode_reward_std': Array(1004.31476, dtype=float32), 'eval/episode_reward_alive_std': Array(49.109306, dtype=float32), 'eval/episode_reward_linvel_std': Array(986.9986, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.088055, dtype=float32), 'eval/episode_x_position_std': Array(485.0039, dtype=float32), 'eval/episode_x_velocity_std': Array(197.39984, dtype=float32), 'eval/episode_y_position_std': Array(305.11102, dtype=float32), 'eval/episode_y_velocity_std': Array(91.14936, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4405117034912, 'eval/sps': 938.1377891499418, 'num_steps': 56197120}
{'eval/walltime': 93950.72613501549, 'training/sps': 2941.5289675477457, 'training/walltime': 19130.28107881546, 'training/entropy_loss': Array(0.02137252, dtype=float32), 'training/policy_loss': Array(0.00646033, dtype=float32), 'training/total_loss': Array(0.21747844, dtype=float32), 'training/v_loss': Array(0.1896456, dtype=float32), 'eval/episode_distance_from_origin': Array(7414.4404, dtype=float32), 'eval/episode_distance_reward': Array(35.27162, dtype=float32), 'eval/episode_forward_reward': Array(5878.576, dtype=float32), 'eval/episode_reward': Array(5894.997, dtype=float32), 'eval/episode_reward_alive': Array(410.07812, dtype=float32), 'eval/episode_reward_linvel': Array(5878.576, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.92953, dtype=float32), 'eval/episode_x_position': Array(7352.545, dtype=float32), 'eval/episode_x_velocity': Array(1175.7153, dtype=float32), 'eval/episode_y_position': Array(-556.5208, dtype=float32), 'eval/episode_y_velocity': Array(-197.4015, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.2945, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9851336, dtype=float32), 'eval/episode_forward_reward_std': Array(997.5156, dtype=float32), 'eval/episode_reward_std': Array(1015.7977, dtype=float32), 'eval/episode_reward_alive_std': Array(42.728767, dtype=float32), 'eval/episode_reward_linvel_std': Array(997.5156, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.351196, dtype=float32), 'eval/episode_x_position_std': Array(486.28806, dtype=float32), 'eval/episode_x_velocity_std': Array(199.50319, dtype=float32), 'eval/episode_y_position_std': Array(328.77484, dtype=float32), 'eval/episode_y_velocity_std': Array(101.17932, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.68980479240417, 'eval/sps': 936.4268256465674, 'num_steps': 56279040}
{'eval/walltime': 94087.16482186317, 'training/sps': 2960.530542831108, 'training/walltime': 19157.951794862747, 'training/entropy_loss': Array(0.01640676, dtype=float32), 'training/policy_loss': Array(0.00766948, dtype=float32), 'training/total_loss': Array(0.10871607, dtype=float32), 'training/v_loss': Array(0.08463983, dtype=float32), 'eval/episode_distance_from_origin': Array(7360.46, dtype=float32), 'eval/episode_distance_reward': Array(35.33787, dtype=float32), 'eval/episode_forward_reward': Array(5889.6147, dtype=float32), 'eval/episode_reward': Array(5900.2104, dtype=float32), 'eval/episode_reward_alive': Array(400.95703, dtype=float32), 'eval/episode_reward_linvel': Array(5889.6147, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.69916, dtype=float32), 'eval/episode_x_position': Array(7306.29, dtype=float32), 'eval/episode_x_velocity': Array(1177.9229, dtype=float32), 'eval/episode_y_position': Array(-455.76813, dtype=float32), 'eval/episode_y_velocity': Array(-176.6543, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.88284, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7945166, dtype=float32), 'eval/episode_forward_reward_std': Array(965.7465, dtype=float32), 'eval/episode_reward_std': Array(980.50006, dtype=float32), 'eval/episode_reward_alive_std': Array(42.45876, dtype=float32), 'eval/episode_reward_linvel_std': Array(965.7465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.789577, dtype=float32), 'eval/episode_x_position_std': Array(477.35168, dtype=float32), 'eval/episode_x_velocity_std': Array(193.14922, dtype=float32), 'eval/episode_y_position_std': Array(323.27646, dtype=float32), 'eval/episode_y_velocity_std': Array(109.255905, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43868684768677, 'eval/sps': 938.1503366628903, 'num_steps': 56360960}
{'eval/walltime': 94223.75443100929, 'training/sps': 2944.922701018646, 'training/walltime': 19185.769163370132, 'training/entropy_loss': Array(0.01857643, dtype=float32), 'training/policy_loss': Array(0.01057308, dtype=float32), 'training/total_loss': Array(0.18804473, dtype=float32), 'training/v_loss': Array(0.15889522, dtype=float32), 'eval/episode_distance_from_origin': Array(7409.786, dtype=float32), 'eval/episode_distance_reward': Array(35.742943, dtype=float32), 'eval/episode_forward_reward': Array(5957.128, dtype=float32), 'eval/episode_reward': Array(5971.19, dtype=float32), 'eval/episode_reward_alive': Array(401.3164, dtype=float32), 'eval/episode_reward_linvel': Array(5957.128, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.9981, dtype=float32), 'eval/episode_x_position': Array(7350.639, dtype=float32), 'eval/episode_x_velocity': Array(1191.4258, dtype=float32), 'eval/episode_y_position': Array(-511.20004, dtype=float32), 'eval/episode_y_velocity': Array(-185.50414, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.4237, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0517344, dtype=float32), 'eval/episode_forward_reward_std': Array(1008.6177, dtype=float32), 'eval/episode_reward_std': Array(1024.7323, dtype=float32), 'eval/episode_reward_alive_std': Array(41.294334, dtype=float32), 'eval/episode_reward_linvel_std': Array(1008.6177, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.79201, dtype=float32), 'eval/episode_x_position_std': Array(485.99274, dtype=float32), 'eval/episode_x_velocity_std': Array(201.72342, dtype=float32), 'eval/episode_y_position_std': Array(333.1153, dtype=float32), 'eval/episode_y_velocity_std': Array(117.36324, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58960914611816, 'eval/sps': 937.1137438651768, 'num_steps': 56442880}
{'eval/walltime': 94360.21545910835, 'training/sps': 2945.852955755558, 'training/walltime': 19213.57774758339, 'training/entropy_loss': Array(0.01969301, dtype=float32), 'training/policy_loss': Array(0.0140053, dtype=float32), 'training/total_loss': Array(0.25995523, dtype=float32), 'training/v_loss': Array(0.22625694, dtype=float32), 'eval/episode_distance_from_origin': Array(7351.8687, dtype=float32), 'eval/episode_distance_reward': Array(35.118576, dtype=float32), 'eval/episode_forward_reward': Array(5853.0664, dtype=float32), 'eval/episode_reward': Array(5856.385, dtype=float32), 'eval/episode_reward_alive': Array(397.98438, dtype=float32), 'eval/episode_reward_linvel': Array(5853.0664, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.7853, dtype=float32), 'eval/episode_x_position': Array(7296.9023, dtype=float32), 'eval/episode_x_velocity': Array(1170.6133, dtype=float32), 'eval/episode_y_position': Array(-454.33078, dtype=float32), 'eval/episode_y_velocity': Array(-185.31163, dtype=float32), 'eval/episode_distance_from_origin_std': Array(497.99832, dtype=float32), 'eval/episode_distance_reward_std': Array(6.538183, dtype=float32), 'eval/episode_forward_reward_std': Array(1089.6888, dtype=float32), 'eval/episode_reward_std': Array(1108.001, dtype=float32), 'eval/episode_reward_alive_std': Array(44.568058, dtype=float32), 'eval/episode_reward_linvel_std': Array(1089.6888, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.88803, dtype=float32), 'eval/episode_x_position_std': Array(500.6997, dtype=float32), 'eval/episode_x_velocity_std': Array(217.93779, dtype=float32), 'eval/episode_y_position_std': Array(339.62, dtype=float32), 'eval/episode_y_velocity_std': Array(102.04236, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46102809906006, 'eval/sps': 937.9967437082622, 'num_steps': 56524800}
{'eval/walltime': 94497.03180909157, 'training/sps': 2940.118148126984, 'training/walltime': 19241.440573453903, 'training/entropy_loss': Array(0.02098425, dtype=float32), 'training/policy_loss': Array(0.0259269, dtype=float32), 'training/total_loss': Array(0.2622937, dtype=float32), 'training/v_loss': Array(0.21538258, dtype=float32), 'eval/episode_distance_from_origin': Array(7449.8887, dtype=float32), 'eval/episode_distance_reward': Array(35.94525, dtype=float32), 'eval/episode_forward_reward': Array(5990.8457, dtype=float32), 'eval/episode_reward': Array(5998.842, dtype=float32), 'eval/episode_reward_alive': Array(393.51562, dtype=float32), 'eval/episode_reward_linvel': Array(5990.8457, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.46457, dtype=float32), 'eval/episode_x_position': Array(7392.5176, dtype=float32), 'eval/episode_x_velocity': Array(1198.169, dtype=float32), 'eval/episode_y_position': Array(-494.8558, dtype=float32), 'eval/episode_y_velocity': Array(-195.20358, dtype=float32), 'eval/episode_distance_from_origin_std': Array(447.9594, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6617994, dtype=float32), 'eval/episode_forward_reward_std': Array(943.62756, dtype=float32), 'eval/episode_reward_std': Array(956.15485, dtype=float32), 'eval/episode_reward_alive_std': Array(42.388405, dtype=float32), 'eval/episode_reward_linvel_std': Array(943.62756, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.715229, dtype=float32), 'eval/episode_x_position_std': Array(454.37485, dtype=float32), 'eval/episode_x_velocity_std': Array(188.72546, dtype=float32), 'eval/episode_y_position_std': Array(327.86664, dtype=float32), 'eval/episode_y_velocity_std': Array(97.18265, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.81634998321533, 'eval/sps': 935.5606988178173, 'num_steps': 56606720}
{'eval/walltime': 94633.64501428604, 'training/sps': 2944.3484906679982, 'training/walltime': 19269.263366937637, 'training/entropy_loss': Array(0.02172706, dtype=float32), 'training/policy_loss': Array(0.00853375, dtype=float32), 'training/total_loss': Array(0.29038382, dtype=float32), 'training/v_loss': Array(0.26012298, dtype=float32), 'eval/episode_distance_from_origin': Array(7338.103, dtype=float32), 'eval/episode_distance_reward': Array(34.794106, dtype=float32), 'eval/episode_forward_reward': Array(5798.9883, dtype=float32), 'eval/episode_reward': Array(5804.061, dtype=float32), 'eval/episode_reward_alive': Array(397.5, dtype=float32), 'eval/episode_reward_linvel': Array(5798.9883, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.2215, dtype=float32), 'eval/episode_x_position': Array(7282.2197, dtype=float32), 'eval/episode_x_velocity': Array(1159.7976, dtype=float32), 'eval/episode_y_position': Array(-498.76483, dtype=float32), 'eval/episode_y_velocity': Array(-188.65839, dtype=float32), 'eval/episode_distance_from_origin_std': Array(507.47372, dtype=float32), 'eval/episode_distance_reward_std': Array(5.716391, dtype=float32), 'eval/episode_forward_reward_std': Array(952.72473, dtype=float32), 'eval/episode_reward_std': Array(964.6884, dtype=float32), 'eval/episode_reward_alive_std': Array(45.883984, dtype=float32), 'eval/episode_reward_linvel_std': Array(952.72473, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.692974, dtype=float32), 'eval/episode_x_position_std': Array(510.9405, dtype=float32), 'eval/episode_x_velocity_std': Array(190.54507, dtype=float32), 'eval/episode_y_position_std': Array(279.78513, dtype=float32), 'eval/episode_y_velocity_std': Array(95.07219, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.61320519447327, 'eval/sps': 936.95188410072, 'num_steps': 56688640}
{'eval/walltime': 94770.27232193947, 'training/sps': 2943.2967480589214, 'training/walltime': 19297.09610247612, 'training/entropy_loss': Array(0.02152136, dtype=float32), 'training/policy_loss': Array(0.00780173, dtype=float32), 'training/total_loss': Array(0.24482054, dtype=float32), 'training/v_loss': Array(0.21549748, dtype=float32), 'eval/episode_distance_from_origin': Array(7413.513, dtype=float32), 'eval/episode_distance_reward': Array(35.33969, dtype=float32), 'eval/episode_forward_reward': Array(5889.918, dtype=float32), 'eval/episode_reward': Array(5899.219, dtype=float32), 'eval/episode_reward_alive': Array(399.7422, dtype=float32), 'eval/episode_reward_linvel': Array(5889.918, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.78177, dtype=float32), 'eval/episode_x_position': Array(7354.966, dtype=float32), 'eval/episode_x_velocity': Array(1177.9839, dtype=float32), 'eval/episode_y_position': Array(-529.7655, dtype=float32), 'eval/episode_y_velocity': Array(-205.16704, dtype=float32), 'eval/episode_distance_from_origin_std': Array(477.6108, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9168735, dtype=float32), 'eval/episode_forward_reward_std': Array(986.13885, dtype=float32), 'eval/episode_reward_std': Array(1001.8332, dtype=float32), 'eval/episode_reward_alive_std': Array(42.616932, dtype=float32), 'eval/episode_reward_linvel_std': Array(986.13885, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.698406, dtype=float32), 'eval/episode_x_position_std': Array(483.92072, dtype=float32), 'eval/episode_x_velocity_std': Array(197.2278, dtype=float32), 'eval/episode_y_position_std': Array(276.0054, dtype=float32), 'eval/episode_y_velocity_std': Array(95.605, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62730765342712, 'eval/sps': 936.8551733793115, 'num_steps': 56770560}
{'eval/walltime': 94906.85031342506, 'training/sps': 2951.9482287570077, 'training/walltime': 19324.84726667404, 'training/entropy_loss': Array(0.01819112, dtype=float32), 'training/policy_loss': Array(0.00751064, dtype=float32), 'training/total_loss': Array(0.16200742, dtype=float32), 'training/v_loss': Array(0.13630566, dtype=float32), 'eval/episode_distance_from_origin': Array(7402.12, dtype=float32), 'eval/episode_distance_reward': Array(36.046978, dtype=float32), 'eval/episode_forward_reward': Array(6007.799, dtype=float32), 'eval/episode_reward': Array(6020.2246, dtype=float32), 'eval/episode_reward_alive': Array(395.09766, dtype=float32), 'eval/episode_reward_linvel': Array(6007.799, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.71878, dtype=float32), 'eval/episode_x_position': Array(7347.7803, dtype=float32), 'eval/episode_x_velocity': Array(1201.5598, dtype=float32), 'eval/episode_y_position': Array(-484.12628, dtype=float32), 'eval/episode_y_velocity': Array(-189.6279, dtype=float32), 'eval/episode_distance_from_origin_std': Array(438.07336, dtype=float32), 'eval/episode_distance_reward_std': Array(5.194633, dtype=float32), 'eval/episode_forward_reward_std': Array(865.7664, dtype=float32), 'eval/episode_reward_std': Array(875.34656, dtype=float32), 'eval/episode_reward_alive_std': Array(39.430866, dtype=float32), 'eval/episode_reward_linvel_std': Array(865.7664, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.95569, dtype=float32), 'eval/episode_x_position_std': Array(442.89462, dtype=float32), 'eval/episode_x_velocity_std': Array(173.15317, dtype=float32), 'eval/episode_y_position_std': Array(292.37006, dtype=float32), 'eval/episode_y_velocity_std': Array(92.010605, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5779914855957, 'eval/sps': 937.1934570695427, 'num_steps': 56852480}
{'eval/walltime': 95043.6251783371, 'training/sps': 2954.955943301016, 'training/walltime': 19352.570184230804, 'training/entropy_loss': Array(0.01699562, dtype=float32), 'training/policy_loss': Array(0.00694695, dtype=float32), 'training/total_loss': Array(0.06754567, dtype=float32), 'training/v_loss': Array(0.0436031, dtype=float32), 'eval/episode_distance_from_origin': Array(7462.427, dtype=float32), 'eval/episode_distance_reward': Array(36.0616, dtype=float32), 'eval/episode_forward_reward': Array(6010.2363, dtype=float32), 'eval/episode_reward': Array(6023.0327, dtype=float32), 'eval/episode_reward_alive': Array(395.1836, dtype=float32), 'eval/episode_reward_linvel': Array(6010.2363, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.4488, dtype=float32), 'eval/episode_x_position': Array(7409.076, dtype=float32), 'eval/episode_x_velocity': Array(1202.0475, dtype=float32), 'eval/episode_y_position': Array(-438.25024, dtype=float32), 'eval/episode_y_velocity': Array(-176.7048, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.03146, dtype=float32), 'eval/episode_distance_reward_std': Array(5.975799, dtype=float32), 'eval/episode_forward_reward_std': Array(995.9608, dtype=float32), 'eval/episode_reward_std': Array(1005.9161, dtype=float32), 'eval/episode_reward_alive_std': Array(40.86199, dtype=float32), 'eval/episode_reward_linvel_std': Array(995.9608, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.00372, dtype=float32), 'eval/episode_x_position_std': Array(509.4601, dtype=float32), 'eval/episode_x_velocity_std': Array(199.19228, dtype=float32), 'eval/episode_y_position_std': Array(334.8131, dtype=float32), 'eval/episode_y_velocity_std': Array(117.99774, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.77486491203308, 'eval/sps': 935.8444629597942, 'num_steps': 56934400}
{'eval/walltime': 95180.20683264732, 'training/sps': 2943.1129090009454, 'training/walltime': 19380.404658317566, 'training/entropy_loss': Array(0.01973872, dtype=float32), 'training/policy_loss': Array(0.0103075, dtype=float32), 'training/total_loss': Array(0.26077366, dtype=float32), 'training/v_loss': Array(0.23072746, dtype=float32), 'eval/episode_distance_from_origin': Array(7442.166, dtype=float32), 'eval/episode_distance_reward': Array(36.125923, dtype=float32), 'eval/episode_forward_reward': Array(6020.956, dtype=float32), 'eval/episode_reward': Array(6030.5205, dtype=float32), 'eval/episode_reward_alive': Array(400.19922, dtype=float32), 'eval/episode_reward_linvel': Array(6020.956, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.76135, dtype=float32), 'eval/episode_x_position': Array(7390.3555, dtype=float32), 'eval/episode_x_velocity': Array(1204.1912, dtype=float32), 'eval/episode_y_position': Array(-431.80347, dtype=float32), 'eval/episode_y_velocity': Array(-170.24458, dtype=float32), 'eval/episode_distance_from_origin_std': Array(441.684, dtype=float32), 'eval/episode_distance_reward_std': Array(5.485302, dtype=float32), 'eval/episode_forward_reward_std': Array(914.21, dtype=float32), 'eval/episode_reward_std': Array(929.4611, dtype=float32), 'eval/episode_reward_alive_std': Array(37.80291, dtype=float32), 'eval/episode_reward_linvel_std': Array(914.21, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.097855, dtype=float32), 'eval/episode_x_position_std': Array(444.54205, dtype=float32), 'eval/episode_x_velocity_std': Array(182.84189, dtype=float32), 'eval/episode_y_position_std': Array(315.84387, dtype=float32), 'eval/episode_y_velocity_std': Array(117.0146, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58165431022644, 'eval/sps': 937.1683235675679, 'num_steps': 57016320}
{'eval/walltime': 95316.87069916725, 'training/sps': 2948.2496194532414, 'training/walltime': 19408.190636634827, 'training/entropy_loss': Array(0.02009622, dtype=float32), 'training/policy_loss': Array(0.05690364, dtype=float32), 'training/total_loss': Array(0.3193202, dtype=float32), 'training/v_loss': Array(0.24232036, dtype=float32), 'eval/episode_distance_from_origin': Array(7498.2354, dtype=float32), 'eval/episode_distance_reward': Array(36.25711, dtype=float32), 'eval/episode_forward_reward': Array(6042.8213, dtype=float32), 'eval/episode_reward': Array(6051.9697, dtype=float32), 'eval/episode_reward_alive': Array(391.2539, dtype=float32), 'eval/episode_reward_linvel': Array(6042.8213, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.3622, dtype=float32), 'eval/episode_x_position': Array(7444.757, dtype=float32), 'eval/episode_x_velocity': Array(1208.5642, dtype=float32), 'eval/episode_y_position': Array(-437.20746, dtype=float32), 'eval/episode_y_velocity': Array(-183.97354, dtype=float32), 'eval/episode_distance_from_origin_std': Array(466.72214, dtype=float32), 'eval/episode_distance_reward_std': Array(6.065652, dtype=float32), 'eval/episode_forward_reward_std': Array(1010.9344, dtype=float32), 'eval/episode_reward_std': Array(1027.6614, dtype=float32), 'eval/episode_reward_alive_std': Array(46.221657, dtype=float32), 'eval/episode_reward_linvel_std': Array(1010.9344, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.270702, dtype=float32), 'eval/episode_x_position_std': Array(472.71243, dtype=float32), 'eval/episode_x_velocity_std': Array(202.18675, dtype=float32), 'eval/episode_y_position_std': Array(337.115, dtype=float32), 'eval/episode_y_velocity_std': Array(101.27781, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66386651992798, 'eval/sps': 936.6045558306764, 'num_steps': 57098240}
{'eval/walltime': 95453.3324496746, 'training/sps': 2955.40675854204, 'training/walltime': 19435.909325361252, 'training/entropy_loss': Array(0.0203642, dtype=float32), 'training/policy_loss': Array(0.00761236, dtype=float32), 'training/total_loss': Array(0.2834228, dtype=float32), 'training/v_loss': Array(0.25544623, dtype=float32), 'eval/episode_distance_from_origin': Array(7451.8506, dtype=float32), 'eval/episode_distance_reward': Array(36.14197, dtype=float32), 'eval/episode_forward_reward': Array(6023.633, dtype=float32), 'eval/episode_reward': Array(6031.509, dtype=float32), 'eval/episode_reward_alive': Array(390.5, dtype=float32), 'eval/episode_reward_linvel': Array(6023.633, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.76544, dtype=float32), 'eval/episode_x_position': Array(7401.6167, dtype=float32), 'eval/episode_x_velocity': Array(1204.7266, dtype=float32), 'eval/episode_y_position': Array(-404.0714, dtype=float32), 'eval/episode_y_velocity': Array(-170.84612, dtype=float32), 'eval/episode_distance_from_origin_std': Array(539.583, dtype=float32), 'eval/episode_distance_reward_std': Array(6.502814, dtype=float32), 'eval/episode_forward_reward_std': Array(1083.796, dtype=float32), 'eval/episode_reward_std': Array(1091.5715, dtype=float32), 'eval/episode_reward_alive_std': Array(40.85225, dtype=float32), 'eval/episode_reward_linvel_std': Array(1083.796, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.047832, dtype=float32), 'eval/episode_x_position_std': Array(542.92664, dtype=float32), 'eval/episode_x_velocity_std': Array(216.75914, dtype=float32), 'eval/episode_y_position_std': Array(317.05606, dtype=float32), 'eval/episode_y_velocity_std': Array(115.689476, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46175050735474, 'eval/sps': 937.9917780924357, 'num_steps': 57180160}
{'eval/walltime': 95589.9855518341, 'training/sps': 2954.17043983995, 'training/walltime': 19463.639614343643, 'training/entropy_loss': Array(0.02076393, dtype=float32), 'training/policy_loss': Array(0.01131884, dtype=float32), 'training/total_loss': Array(0.26229537, dtype=float32), 'training/v_loss': Array(0.2302126, dtype=float32), 'eval/episode_distance_from_origin': Array(7424.585, dtype=float32), 'eval/episode_distance_reward': Array(35.616276, dtype=float32), 'eval/episode_forward_reward': Array(5936.0166, dtype=float32), 'eval/episode_reward': Array(5942.0947, dtype=float32), 'eval/episode_reward_alive': Array(396.01953, dtype=float32), 'eval/episode_reward_linvel': Array(5936.0166, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.55728, dtype=float32), 'eval/episode_x_position': Array(7373.204, dtype=float32), 'eval/episode_x_velocity': Array(1187.2031, dtype=float32), 'eval/episode_y_position': Array(-376.78815, dtype=float32), 'eval/episode_y_velocity': Array(-165.2544, dtype=float32), 'eval/episode_distance_from_origin_std': Array(514.1094, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0072055, dtype=float32), 'eval/episode_forward_reward_std': Array(1001.194, dtype=float32), 'eval/episode_reward_std': Array(1021.4104, dtype=float32), 'eval/episode_reward_alive_std': Array(51.07005, dtype=float32), 'eval/episode_reward_linvel_std': Array(1001.194, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.65333, dtype=float32), 'eval/episode_x_position_std': Array(516.55115, dtype=float32), 'eval/episode_x_velocity_std': Array(200.23875, dtype=float32), 'eval/episode_y_position_std': Array(354.56247, dtype=float32), 'eval/episode_y_velocity_std': Array(120.22778, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65310215950012, 'eval/sps': 936.6783335119586, 'num_steps': 57262080}
{'eval/walltime': 95726.42698907852, 'training/sps': 2938.1575186971627, 'training/walltime': 19491.52103304863, 'training/entropy_loss': Array(0.02126835, dtype=float32), 'training/policy_loss': Array(0.00755345, dtype=float32), 'training/total_loss': Array(0.2146084, dtype=float32), 'training/v_loss': Array(0.1857866, dtype=float32), 'eval/episode_distance_from_origin': Array(7445.91, dtype=float32), 'eval/episode_distance_reward': Array(35.852802, dtype=float32), 'eval/episode_forward_reward': Array(5975.4375, dtype=float32), 'eval/episode_reward': Array(5984.083, dtype=float32), 'eval/episode_reward_alive': Array(395.64844, dtype=float32), 'eval/episode_reward_linvel': Array(5975.4375, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.85596, dtype=float32), 'eval/episode_x_position': Array(7392.0786, dtype=float32), 'eval/episode_x_velocity': Array(1195.0874, dtype=float32), 'eval/episode_y_position': Array(-436.31946, dtype=float32), 'eval/episode_y_velocity': Array(-173.18307, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.71088, dtype=float32), 'eval/episode_distance_reward_std': Array(6.05924, dtype=float32), 'eval/episode_forward_reward_std': Array(1009.8674, dtype=float32), 'eval/episode_reward_std': Array(1026.2024, dtype=float32), 'eval/episode_reward_alive_std': Array(51.249443, dtype=float32), 'eval/episode_reward_linvel_std': Array(1009.8674, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.98507, dtype=float32), 'eval/episode_x_position_std': Array(491.79062, dtype=float32), 'eval/episode_x_velocity_std': Array(201.97343, dtype=float32), 'eval/episode_y_position_std': Array(334.6381, dtype=float32), 'eval/episode_y_velocity_std': Array(107.41599, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44143724441528, 'eval/sps': 938.1314253580189, 'num_steps': 57344000}
{'eval/walltime': 95862.98566913605, 'training/sps': 2935.2637989331038, 'training/walltime': 19519.429938554764, 'training/entropy_loss': Array(0.01484301, dtype=float32), 'training/policy_loss': Array(0.00880359, dtype=float32), 'training/total_loss': Array(0.05357607, dtype=float32), 'training/v_loss': Array(0.02992946, dtype=float32), 'eval/episode_distance_from_origin': Array(7441.823, dtype=float32), 'eval/episode_distance_reward': Array(36.392162, dtype=float32), 'eval/episode_forward_reward': Array(6065.331, dtype=float32), 'eval/episode_reward': Array(6079.834, dtype=float32), 'eval/episode_reward_alive': Array(399.6289, dtype=float32), 'eval/episode_reward_linvel': Array(6065.331, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.51706, dtype=float32), 'eval/episode_x_position': Array(7389.629, dtype=float32), 'eval/episode_x_velocity': Array(1213.066, dtype=float32), 'eval/episode_y_position': Array(-391.70575, dtype=float32), 'eval/episode_y_velocity': Array(-167.69254, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.68378, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1813927, dtype=float32), 'eval/episode_forward_reward_std': Array(1030.2251, dtype=float32), 'eval/episode_reward_std': Array(1042.2032, dtype=float32), 'eval/episode_reward_alive_std': Array(41.4261, dtype=float32), 'eval/episode_reward_linvel_std': Array(1030.2251, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.775917, dtype=float32), 'eval/episode_x_position_std': Array(484.85663, dtype=float32), 'eval/episode_x_velocity_std': Array(206.04495, dtype=float32), 'eval/episode_y_position_std': Array(361.51794, dtype=float32), 'eval/episode_y_velocity_std': Array(124.37421, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55868005752563, 'eval/sps': 937.3259901610043, 'num_steps': 57425920}
{'eval/walltime': 95999.40360808372, 'training/sps': 2942.2970285339647, 'training/walltime': 19547.272130966187, 'training/entropy_loss': Array(0.01897525, dtype=float32), 'training/policy_loss': Array(0.00975576, dtype=float32), 'training/total_loss': Array(0.22248118, dtype=float32), 'training/v_loss': Array(0.19375017, dtype=float32), 'eval/episode_distance_from_origin': Array(7523.088, dtype=float32), 'eval/episode_distance_reward': Array(37.053635, dtype=float32), 'eval/episode_forward_reward': Array(6175.574, dtype=float32), 'eval/episode_reward': Array(6183.246, dtype=float32), 'eval/episode_reward_alive': Array(389.66016, dtype=float32), 'eval/episode_reward_linvel': Array(6175.574, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.04187, dtype=float32), 'eval/episode_x_position': Array(7473.0117, dtype=float32), 'eval/episode_x_velocity': Array(1235.1149, dtype=float32), 'eval/episode_y_position': Array(-350.5447, dtype=float32), 'eval/episode_y_velocity': Array(-161.02344, dtype=float32), 'eval/episode_distance_from_origin_std': Array(527.1556, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3175664, dtype=float32), 'eval/episode_forward_reward_std': Array(1052.9213, dtype=float32), 'eval/episode_reward_std': Array(1070.2753, dtype=float32), 'eval/episode_reward_alive_std': Array(47.408127, dtype=float32), 'eval/episode_reward_linvel_std': Array(1052.9213, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.512558, dtype=float32), 'eval/episode_x_position_std': Array(531.0789, dtype=float32), 'eval/episode_x_velocity_std': Array(210.58427, dtype=float32), 'eval/episode_y_position_std': Array(358.19882, dtype=float32), 'eval/episode_y_velocity_std': Array(126.013435, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4179389476776, 'eval/sps': 938.2930206055505, 'num_steps': 57507840}
{'eval/walltime': 96135.9778251648, 'training/sps': 2934.0293896857306, 'training/walltime': 19575.192778348923, 'training/entropy_loss': Array(0.01981611, dtype=float32), 'training/policy_loss': Array(0.01264431, dtype=float32), 'training/total_loss': Array(0.30688417, dtype=float32), 'training/v_loss': Array(0.27442378, dtype=float32), 'eval/episode_distance_from_origin': Array(7438.103, dtype=float32), 'eval/episode_distance_reward': Array(35.908463, dtype=float32), 'eval/episode_forward_reward': Array(5984.714, dtype=float32), 'eval/episode_reward': Array(5993.097, dtype=float32), 'eval/episode_reward_alive': Array(397.16797, dtype=float32), 'eval/episode_reward_linvel': Array(5984.714, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.69333, dtype=float32), 'eval/episode_x_position': Array(7386.6523, dtype=float32), 'eval/episode_x_velocity': Array(1196.9429, dtype=float32), 'eval/episode_y_position': Array(-429.61246, dtype=float32), 'eval/episode_y_velocity': Array(-175.2526, dtype=float32), 'eval/episode_distance_from_origin_std': Array(493.6724, dtype=float32), 'eval/episode_distance_reward_std': Array(6.366565, dtype=float32), 'eval/episode_forward_reward_std': Array(1061.0863, dtype=float32), 'eval/episode_reward_std': Array(1076.1473, dtype=float32), 'eval/episode_reward_alive_std': Array(49.175003, dtype=float32), 'eval/episode_reward_linvel_std': Array(1061.0863, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.545547, dtype=float32), 'eval/episode_x_position_std': Array(493.5757, dtype=float32), 'eval/episode_x_velocity_std': Array(212.21736, dtype=float32), 'eval/episode_y_position_std': Array(312.84583, dtype=float32), 'eval/episode_y_velocity_std': Array(98.71133, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57421708106995, 'eval/sps': 937.2193576187201, 'num_steps': 57589760}
{'eval/walltime': 96272.39483213425, 'training/sps': 2951.8579460982683, 'training/walltime': 19602.944791316986, 'training/entropy_loss': Array(0.01952488, dtype=float32), 'training/policy_loss': Array(0.0076924, dtype=float32), 'training/total_loss': Array(0.2554081, dtype=float32), 'training/v_loss': Array(0.22819082, dtype=float32), 'eval/episode_distance_from_origin': Array(7442.0615, dtype=float32), 'eval/episode_distance_reward': Array(36.104176, dtype=float32), 'eval/episode_forward_reward': Array(6017.332, dtype=float32), 'eval/episode_reward': Array(6022.055, dtype=float32), 'eval/episode_reward_alive': Array(392.48047, dtype=float32), 'eval/episode_reward_linvel': Array(6017.332, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.8613, dtype=float32), 'eval/episode_x_position': Array(7390.5503, dtype=float32), 'eval/episode_x_velocity': Array(1203.4666, dtype=float32), 'eval/episode_y_position': Array(-405.25198, dtype=float32), 'eval/episode_y_velocity': Array(-168.01213, dtype=float32), 'eval/episode_distance_from_origin_std': Array(456.892, dtype=float32), 'eval/episode_distance_reward_std': Array(5.181776, dtype=float32), 'eval/episode_forward_reward_std': Array(863.62354, dtype=float32), 'eval/episode_reward_std': Array(883.999, dtype=float32), 'eval/episode_reward_alive_std': Array(48.027473, dtype=float32), 'eval/episode_reward_linvel_std': Array(863.62354, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.3141, dtype=float32), 'eval/episode_x_position_std': Array(458.65027, dtype=float32), 'eval/episode_x_velocity_std': Array(172.7246, dtype=float32), 'eval/episode_y_position_std': Array(329.33093, dtype=float32), 'eval/episode_y_velocity_std': Array(112.92924, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4170069694519, 'eval/sps': 938.2994308668806, 'num_steps': 57671680}
{'eval/walltime': 96408.95674085617, 'training/sps': 2949.21159471969, 'training/walltime': 19630.72170639038, 'training/entropy_loss': Array(0.01963114, dtype=float32), 'training/policy_loss': Array(0.00684239, dtype=float32), 'training/total_loss': Array(0.27984643, dtype=float32), 'training/v_loss': Array(0.2533729, dtype=float32), 'eval/episode_distance_from_origin': Array(7406.3975, dtype=float32), 'eval/episode_distance_reward': Array(35.809845, dtype=float32), 'eval/episode_forward_reward': Array(5968.277, dtype=float32), 'eval/episode_reward': Array(5984.5117, dtype=float32), 'eval/episode_reward_alive': Array(400.46875, dtype=float32), 'eval/episode_reward_linvel': Array(5968.277, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.044, dtype=float32), 'eval/episode_x_position': Array(7354.5225, dtype=float32), 'eval/episode_x_velocity': Array(1193.6554, dtype=float32), 'eval/episode_y_position': Array(-431.00327, dtype=float32), 'eval/episode_y_velocity': Array(-181.94334, dtype=float32), 'eval/episode_distance_from_origin_std': Array(486.30753, dtype=float32), 'eval/episode_distance_reward_std': Array(5.999874, dtype=float32), 'eval/episode_forward_reward_std': Array(999.9717, dtype=float32), 'eval/episode_reward_std': Array(1013.12067, dtype=float32), 'eval/episode_reward_alive_std': Array(44.11525, dtype=float32), 'eval/episode_reward_linvel_std': Array(999.9717, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.48253, dtype=float32), 'eval/episode_x_position_std': Array(488.54285, dtype=float32), 'eval/episode_x_velocity_std': Array(199.99438, dtype=float32), 'eval/episode_y_position_std': Array(295.40002, dtype=float32), 'eval/episode_y_velocity_std': Array(96.47864, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56190872192383, 'eval/sps': 937.3038294349112, 'num_steps': 57753600}
{'eval/walltime': 96545.39754104614, 'training/sps': 2954.6483028086286, 'training/walltime': 19658.44751048088, 'training/entropy_loss': Array(0.01964735, dtype=float32), 'training/policy_loss': Array(0.00914507, dtype=float32), 'training/total_loss': Array(0.25537375, dtype=float32), 'training/v_loss': Array(0.22658132, dtype=float32), 'eval/episode_distance_from_origin': Array(7444.105, dtype=float32), 'eval/episode_distance_reward': Array(36.22794, dtype=float32), 'eval/episode_forward_reward': Array(6037.9595, dtype=float32), 'eval/episode_reward': Array(6047.6655, dtype=float32), 'eval/episode_reward_alive': Array(386.9336, dtype=float32), 'eval/episode_reward_linvel': Array(6037.9595, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.4552, dtype=float32), 'eval/episode_x_position': Array(7394.6816, dtype=float32), 'eval/episode_x_velocity': Array(1207.5918, dtype=float32), 'eval/episode_y_position': Array(-350.96155, dtype=float32), 'eval/episode_y_velocity': Array(-162.95087, dtype=float32), 'eval/episode_distance_from_origin_std': Array(478.78604, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7219744, dtype=float32), 'eval/episode_forward_reward_std': Array(953.6564, dtype=float32), 'eval/episode_reward_std': Array(963.1333, dtype=float32), 'eval/episode_reward_alive_std': Array(44.43589, dtype=float32), 'eval/episode_reward_linvel_std': Array(953.6564, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.708195, dtype=float32), 'eval/episode_x_position_std': Array(480.81262, dtype=float32), 'eval/episode_x_velocity_std': Array(190.73126, dtype=float32), 'eval/episode_y_position_std': Array(355.4453, dtype=float32), 'eval/episode_y_velocity_std': Array(118.744, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44080018997192, 'eval/sps': 938.1358055785405, 'num_steps': 57835520}
{'eval/walltime': 96681.96296954155, 'training/sps': 2949.1497031116623, 'training/walltime': 19686.2250084877, 'training/entropy_loss': Array(0.01419172, dtype=float32), 'training/policy_loss': Array(0.00762486, dtype=float32), 'training/total_loss': Array(0.09117796, dtype=float32), 'training/v_loss': Array(0.06936137, dtype=float32), 'eval/episode_distance_from_origin': Array(7500.584, dtype=float32), 'eval/episode_distance_reward': Array(37.11548, dtype=float32), 'eval/episode_forward_reward': Array(6185.881, dtype=float32), 'eval/episode_reward': Array(6196.8716, dtype=float32), 'eval/episode_reward_alive': Array(394.14844, dtype=float32), 'eval/episode_reward_linvel': Array(6185.881, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.2736, dtype=float32), 'eval/episode_x_position': Array(7452.9795, dtype=float32), 'eval/episode_x_velocity': Array(1237.1763, dtype=float32), 'eval/episode_y_position': Array(-358.49295, dtype=float32), 'eval/episode_y_velocity': Array(-150.40236, dtype=float32), 'eval/episode_distance_from_origin_std': Array(518.7979, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5006595, dtype=float32), 'eval/episode_forward_reward_std': Array(1083.4347, dtype=float32), 'eval/episode_reward_std': Array(1100.5981, dtype=float32), 'eval/episode_reward_alive_std': Array(46.565575, dtype=float32), 'eval/episode_reward_linvel_std': Array(1083.4347, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.913055, dtype=float32), 'eval/episode_x_position_std': Array(518.73865, dtype=float32), 'eval/episode_x_velocity_std': Array(216.68713, dtype=float32), 'eval/episode_y_position_std': Array(331.14984, dtype=float32), 'eval/episode_y_velocity_std': Array(126.97349, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5654284954071, 'eval/sps': 937.2796718043822, 'num_steps': 57917440}
{'eval/walltime': 96818.37684440613, 'training/sps': 2958.3845430497477, 'training/walltime': 19713.915796756744, 'training/entropy_loss': Array(0.01952474, dtype=float32), 'training/policy_loss': Array(0.01126414, dtype=float32), 'training/total_loss': Array(0.13567099, dtype=float32), 'training/v_loss': Array(0.10488211, dtype=float32), 'eval/episode_distance_from_origin': Array(7497.629, dtype=float32), 'eval/episode_distance_reward': Array(36.854576, dtype=float32), 'eval/episode_forward_reward': Array(6142.3975, dtype=float32), 'eval/episode_reward': Array(6146.068, dtype=float32), 'eval/episode_reward_alive': Array(386.6797, dtype=float32), 'eval/episode_reward_linvel': Array(6142.3975, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.8639, dtype=float32), 'eval/episode_x_position': Array(7448.238, dtype=float32), 'eval/episode_x_velocity': Array(1228.4795, dtype=float32), 'eval/episode_y_position': Array(-368.8604, dtype=float32), 'eval/episode_y_velocity': Array(-168.05695, dtype=float32), 'eval/episode_distance_from_origin_std': Array(460.0111, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9830956, dtype=float32), 'eval/episode_forward_reward_std': Array(997.176, dtype=float32), 'eval/episode_reward_std': Array(1013.79517, dtype=float32), 'eval/episode_reward_alive_std': Array(46.133797, dtype=float32), 'eval/episode_reward_linvel_std': Array(997.176, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.873737, dtype=float32), 'eval/episode_x_position_std': Array(463.53268, dtype=float32), 'eval/episode_x_velocity_std': Array(199.4352, dtype=float32), 'eval/episode_y_position_std': Array(327.27295, dtype=float32), 'eval/episode_y_velocity_std': Array(116.46914, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41387486457825, 'eval/sps': 938.3209745128131, 'num_steps': 57999360}
{'eval/walltime': 96954.94003224373, 'training/sps': 2932.2806782003804, 'training/walltime': 19741.853095054626, 'training/entropy_loss': Array(0.02046135, dtype=float32), 'training/policy_loss': Array(0.01269375, dtype=float32), 'training/total_loss': Array(0.36257398, dtype=float32), 'training/v_loss': Array(0.3294189, dtype=float32), 'eval/episode_distance_from_origin': Array(7480.6665, dtype=float32), 'eval/episode_distance_reward': Array(36.554794, dtype=float32), 'eval/episode_forward_reward': Array(6092.4365, dtype=float32), 'eval/episode_reward': Array(6093.882, dtype=float32), 'eval/episode_reward_alive': Array(384.375, dtype=float32), 'eval/episode_reward_linvel': Array(6092.4365, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.48358, dtype=float32), 'eval/episode_x_position': Array(7433.163, dtype=float32), 'eval/episode_x_velocity': Array(1218.4873, dtype=float32), 'eval/episode_y_position': Array(-316.67285, dtype=float32), 'eval/episode_y_velocity': Array(-152.13002, dtype=float32), 'eval/episode_distance_from_origin_std': Array(503.51498, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0248914, dtype=float32), 'eval/episode_forward_reward_std': Array(1004.1417, dtype=float32), 'eval/episode_reward_std': Array(1016.1801, dtype=float32), 'eval/episode_reward_alive_std': Array(47.17686, dtype=float32), 'eval/episode_reward_linvel_std': Array(1004.1417, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.76914, dtype=float32), 'eval/episode_x_position_std': Array(503.2629, dtype=float32), 'eval/episode_x_velocity_std': Array(200.82841, dtype=float32), 'eval/episode_y_position_std': Array(349.19714, dtype=float32), 'eval/episode_y_velocity_std': Array(119.39482, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5631878376007, 'eval/sps': 937.2950502020798, 'num_steps': 58081280}
{'eval/walltime': 97091.36220932007, 'training/sps': 2936.740894497575, 'training/walltime': 19769.74796319008, 'training/entropy_loss': Array(0.01926488, dtype=float32), 'training/policy_loss': Array(0.00948902, dtype=float32), 'training/total_loss': Array(0.25661027, dtype=float32), 'training/v_loss': Array(0.22785638, dtype=float32), 'eval/episode_distance_from_origin': Array(7405.249, dtype=float32), 'eval/episode_distance_reward': Array(36.26799, dtype=float32), 'eval/episode_forward_reward': Array(6044.6343, dtype=float32), 'eval/episode_reward': Array(6047.2935, dtype=float32), 'eval/episode_reward_alive': Array(381.59766, dtype=float32), 'eval/episode_reward_linvel': Array(6044.6343, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.2072, dtype=float32), 'eval/episode_x_position': Array(7358.0493, dtype=float32), 'eval/episode_x_velocity': Array(1208.9269, dtype=float32), 'eval/episode_y_position': Array(-317.56696, dtype=float32), 'eval/episode_y_velocity': Array(-160.08038, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.72705, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7223125, dtype=float32), 'eval/episode_forward_reward_std': Array(953.71136, dtype=float32), 'eval/episode_reward_std': Array(961.542, dtype=float32), 'eval/episode_reward_alive_std': Array(42.32058, dtype=float32), 'eval/episode_reward_linvel_std': Array(953.71136, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.773975, dtype=float32), 'eval/episode_x_position_std': Array(483.7698, dtype=float32), 'eval/episode_x_velocity_std': Array(190.74231, dtype=float32), 'eval/episode_y_position_std': Array(330.4396, dtype=float32), 'eval/episode_y_velocity_std': Array(120.26547, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42217707633972, 'eval/sps': 938.2638713379658, 'num_steps': 58163200}
{'eval/walltime': 97227.91353154182, 'training/sps': 2925.802552686795, 'training/walltime': 19797.747118473053, 'training/entropy_loss': Array(0.01968333, dtype=float32), 'training/policy_loss': Array(0.00825271, dtype=float32), 'training/total_loss': Array(0.30633503, dtype=float32), 'training/v_loss': Array(0.27839896, dtype=float32), 'eval/episode_distance_from_origin': Array(7543.423, dtype=float32), 'eval/episode_distance_reward': Array(37.671036, dtype=float32), 'eval/episode_forward_reward': Array(6278.4736, dtype=float32), 'eval/episode_reward': Array(6280.832, dtype=float32), 'eval/episode_reward_alive': Array(381.6875, dtype=float32), 'eval/episode_reward_linvel': Array(6278.4736, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.99896, dtype=float32), 'eval/episode_x_position': Array(7495.025, dtype=float32), 'eval/episode_x_velocity': Array(1255.6946, dtype=float32), 'eval/episode_y_position': Array(-326.04047, dtype=float32), 'eval/episode_y_velocity': Array(-159.44736, dtype=float32), 'eval/episode_distance_from_origin_std': Array(454.81424, dtype=float32), 'eval/episode_distance_reward_std': Array(5.998877, dtype=float32), 'eval/episode_forward_reward_std': Array(999.8058, dtype=float32), 'eval/episode_reward_std': Array(1016.3971, dtype=float32), 'eval/episode_reward_alive_std': Array(46.279762, dtype=float32), 'eval/episode_reward_linvel_std': Array(999.8058, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.654165, dtype=float32), 'eval/episode_x_position_std': Array(456.08035, dtype=float32), 'eval/episode_x_velocity_std': Array(199.96106, dtype=float32), 'eval/episode_y_position_std': Array(352.52728, dtype=float32), 'eval/episode_y_velocity_std': Array(121.86009, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55132222175598, 'eval/sps': 937.3764963779051, 'num_steps': 58245120}
{'eval/walltime': 97364.32787418365, 'training/sps': 2940.6361965939473, 'training/walltime': 19825.60503578186, 'training/entropy_loss': Array(0.01996499, dtype=float32), 'training/policy_loss': Array(0.00848045, dtype=float32), 'training/total_loss': Array(0.24008252, dtype=float32), 'training/v_loss': Array(0.21163708, dtype=float32), 'eval/episode_distance_from_origin': Array(7536.3467, dtype=float32), 'eval/episode_distance_reward': Array(37.95263, dtype=float32), 'eval/episode_forward_reward': Array(6325.4053, dtype=float32), 'eval/episode_reward': Array(6335.294, dtype=float32), 'eval/episode_reward_alive': Array(386.60938, dtype=float32), 'eval/episode_reward_linvel': Array(6325.4053, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.67218, dtype=float32), 'eval/episode_x_position': Array(7489.788, dtype=float32), 'eval/episode_x_velocity': Array(1265.081, dtype=float32), 'eval/episode_y_position': Array(-251.80896, dtype=float32), 'eval/episode_y_velocity': Array(-144.12294, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.79617, dtype=float32), 'eval/episode_distance_reward_std': Array(5.212472, dtype=float32), 'eval/episode_forward_reward_std': Array(868.74054, dtype=float32), 'eval/episode_reward_std': Array(881.93085, dtype=float32), 'eval/episode_reward_alive_std': Array(39.914406, dtype=float32), 'eval/episode_reward_linvel_std': Array(868.74054, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.657322, dtype=float32), 'eval/episode_x_position_std': Array(455.7418, dtype=float32), 'eval/episode_x_velocity_std': Array(173.74821, dtype=float32), 'eval/episode_y_position_std': Array(383.78937, dtype=float32), 'eval/episode_y_velocity_std': Array(125.968864, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41434264183044, 'eval/sps': 938.3177569244083, 'num_steps': 58327040}
{'eval/walltime': 97500.96803998947, 'training/sps': 2935.9977831168076, 'training/walltime': 19853.506964206696, 'training/entropy_loss': Array(0.01553203, dtype=float32), 'training/policy_loss': Array(0.00553847, dtype=float32), 'training/total_loss': Array(0.12066218, dtype=float32), 'training/v_loss': Array(0.09959168, dtype=float32), 'eval/episode_distance_from_origin': Array(7556.2085, dtype=float32), 'eval/episode_distance_reward': Array(38.392754, dtype=float32), 'eval/episode_forward_reward': Array(6398.76, dtype=float32), 'eval/episode_reward': Array(6400.9893, dtype=float32), 'eval/episode_reward_alive': Array(377.51172, dtype=float32), 'eval/episode_reward_linvel': Array(6398.76, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.67493, dtype=float32), 'eval/episode_x_position': Array(7513.113, dtype=float32), 'eval/episode_x_velocity': Array(1279.7518, dtype=float32), 'eval/episode_y_position': Array(-249.71721, dtype=float32), 'eval/episode_y_velocity': Array(-143.39984, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.11115, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2385044, dtype=float32), 'eval/episode_forward_reward_std': Array(1039.7433, dtype=float32), 'eval/episode_reward_std': Array(1058.644, dtype=float32), 'eval/episode_reward_alive_std': Array(48.522606, dtype=float32), 'eval/episode_reward_linvel_std': Array(1039.7433, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.21227, dtype=float32), 'eval/episode_x_position_std': Array(477.61676, dtype=float32), 'eval/episode_x_velocity_std': Array(207.94856, dtype=float32), 'eval/episode_y_position_std': Array(332.80423, dtype=float32), 'eval/episode_y_velocity_std': Array(126.94718, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64016580581665, 'eval/sps': 936.7670131629126, 'num_steps': 58408960}
{'eval/walltime': 97637.42063117027, 'training/sps': 2941.6655881904276, 'training/walltime': 19881.35513305664, 'training/entropy_loss': Array(0.01859212, dtype=float32), 'training/policy_loss': Array(0.00958066, dtype=float32), 'training/total_loss': Array(0.09982657, dtype=float32), 'training/v_loss': Array(0.07165378, dtype=float32), 'eval/episode_distance_from_origin': Array(7632.353, dtype=float32), 'eval/episode_distance_reward': Array(38.206398, dtype=float32), 'eval/episode_forward_reward': Array(6367.7, dtype=float32), 'eval/episode_reward': Array(6369.908, dtype=float32), 'eval/episode_reward_alive': Array(380.48828, dtype=float32), 'eval/episode_reward_linvel': Array(6367.7, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.48654, dtype=float32), 'eval/episode_x_position': Array(7589.8203, dtype=float32), 'eval/episode_x_velocity': Array(1273.5398, dtype=float32), 'eval/episode_y_position': Array(-242.55559, dtype=float32), 'eval/episode_y_velocity': Array(-124.47945, dtype=float32), 'eval/episode_distance_from_origin_std': Array(466.25085, dtype=float32), 'eval/episode_distance_reward_std': Array(5.777523, dtype=float32), 'eval/episode_forward_reward_std': Array(962.91376, dtype=float32), 'eval/episode_reward_std': Array(978.0756, dtype=float32), 'eval/episode_reward_alive_std': Array(45.575764, dtype=float32), 'eval/episode_reward_linvel_std': Array(962.91376, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.33201, dtype=float32), 'eval/episode_x_position_std': Array(465.86246, dtype=float32), 'eval/episode_x_velocity_std': Array(192.58281, dtype=float32), 'eval/episode_y_position_std': Array(349.77142, dtype=float32), 'eval/episode_y_velocity_std': Array(134.06317, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4525911808014, 'eval/sps': 938.0547404218833, 'num_steps': 58490880}
{'eval/walltime': 97774.07378220558, 'training/sps': 2929.3648011120076, 'training/walltime': 19909.320240020752, 'training/entropy_loss': Array(0.01892199, dtype=float32), 'training/policy_loss': Array(0.01225612, dtype=float32), 'training/total_loss': Array(0.2543222, dtype=float32), 'training/v_loss': Array(0.22314408, dtype=float32), 'eval/episode_distance_from_origin': Array(7539.374, dtype=float32), 'eval/episode_distance_reward': Array(39.00015, dtype=float32), 'eval/episode_forward_reward': Array(6499.991, dtype=float32), 'eval/episode_reward': Array(6511.155, dtype=float32), 'eval/episode_reward_alive': Array(387.48047, dtype=float32), 'eval/episode_reward_linvel': Array(6499.991, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.31638, dtype=float32), 'eval/episode_x_position': Array(7496.544, dtype=float32), 'eval/episode_x_velocity': Array(1299.9982, dtype=float32), 'eval/episode_y_position': Array(-193.4015, dtype=float32), 'eval/episode_y_velocity': Array(-134.3897, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.16376, dtype=float32), 'eval/episode_distance_reward_std': Array(6.532787, dtype=float32), 'eval/episode_forward_reward_std': Array(1088.7925, dtype=float32), 'eval/episode_reward_std': Array(1108.3918, dtype=float32), 'eval/episode_reward_alive_std': Array(39.044415, dtype=float32), 'eval/episode_reward_linvel_std': Array(1088.7925, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.978357, dtype=float32), 'eval/episode_x_position_std': Array(482.05765, dtype=float32), 'eval/episode_x_velocity_std': Array(217.75851, dtype=float32), 'eval/episode_y_position_std': Array(352.30484, dtype=float32), 'eval/episode_y_velocity_std': Array(130.68332, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65315103530884, 'eval/sps': 936.6779984965513, 'num_steps': 58572800}
{'eval/walltime': 97910.52987408638, 'training/sps': 2937.3148781243553, 'training/walltime': 19937.20965719223, 'training/entropy_loss': Array(0.01924157, dtype=float32), 'training/policy_loss': Array(0.01421946, dtype=float32), 'training/total_loss': Array(0.30317852, dtype=float32), 'training/v_loss': Array(0.2697175, dtype=float32), 'eval/episode_distance_from_origin': Array(7500.5664, dtype=float32), 'eval/episode_distance_reward': Array(37.10881, dtype=float32), 'eval/episode_forward_reward': Array(6184.7705, dtype=float32), 'eval/episode_reward': Array(6190.2, dtype=float32), 'eval/episode_reward_alive': Array(379.125, dtype=float32), 'eval/episode_reward_linvel': Array(6184.7705, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.80423, dtype=float32), 'eval/episode_x_position': Array(7455.33, dtype=float32), 'eval/episode_x_velocity': Array(1236.9539, dtype=float32), 'eval/episode_y_position': Array(-230.74332, dtype=float32), 'eval/episode_y_velocity': Array(-136.68338, dtype=float32), 'eval/episode_distance_from_origin_std': Array(467.41925, dtype=float32), 'eval/episode_distance_reward_std': Array(5.884265, dtype=float32), 'eval/episode_forward_reward_std': Array(980.70447, dtype=float32), 'eval/episode_reward_std': Array(986.7899, dtype=float32), 'eval/episode_reward_alive_std': Array(50.00324, dtype=float32), 'eval/episode_reward_linvel_std': Array(980.70447, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.60075, dtype=float32), 'eval/episode_x_position_std': Array(469.93085, dtype=float32), 'eval/episode_x_velocity_std': Array(196.14078, dtype=float32), 'eval/episode_y_position_std': Array(384.40414, dtype=float32), 'eval/episode_y_velocity_std': Array(130.96332, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45609188079834, 'eval/sps': 938.0306751846214, 'num_steps': 58654720}
{'eval/walltime': 98047.08877754211, 'training/sps': 2942.862726116635, 'training/walltime': 19965.04649758339, 'training/entropy_loss': Array(0.01888786, dtype=float32), 'training/policy_loss': Array(0.00856095, dtype=float32), 'training/total_loss': Array(0.27669746, dtype=float32), 'training/v_loss': Array(0.24924865, dtype=float32), 'eval/episode_distance_from_origin': Array(7615.416, dtype=float32), 'eval/episode_distance_reward': Array(39.0764, dtype=float32), 'eval/episode_forward_reward': Array(6512.6997, dtype=float32), 'eval/episode_reward': Array(6520.8013, dtype=float32), 'eval/episode_reward_alive': Array(381.05078, dtype=float32), 'eval/episode_reward_linvel': Array(6512.6997, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.0259, dtype=float32), 'eval/episode_x_position': Array(7573.223, dtype=float32), 'eval/episode_x_velocity': Array(1302.5398, dtype=float32), 'eval/episode_y_position': Array(-253.47467, dtype=float32), 'eval/episode_y_velocity': Array(-145.1366, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.97876, dtype=float32), 'eval/episode_distance_reward_std': Array(5.894407, dtype=float32), 'eval/episode_forward_reward_std': Array(982.39636, dtype=float32), 'eval/episode_reward_std': Array(999.72833, dtype=float32), 'eval/episode_reward_alive_std': Array(44.219524, dtype=float32), 'eval/episode_reward_linvel_std': Array(982.39636, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.47872, dtype=float32), 'eval/episode_x_position_std': Array(454.0703, dtype=float32), 'eval/episode_x_velocity_std': Array(196.47922, dtype=float32), 'eval/episode_y_position_std': Array(295.0212, dtype=float32), 'eval/episode_y_velocity_std': Array(122.696785, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.55890345573425, 'eval/sps': 937.3244567791317, 'num_steps': 58736640}
{'eval/walltime': 98183.51130485535, 'training/sps': 2959.596502974094, 'training/walltime': 19992.72594642639, 'training/entropy_loss': Array(0.01952665, dtype=float32), 'training/policy_loss': Array(0.00712201, dtype=float32), 'training/total_loss': Array(0.28602013, dtype=float32), 'training/v_loss': Array(0.25937146, dtype=float32), 'eval/episode_distance_from_origin': Array(7528.9004, dtype=float32), 'eval/episode_distance_reward': Array(38.088593, dtype=float32), 'eval/episode_forward_reward': Array(6348.0654, dtype=float32), 'eval/episode_reward': Array(6354.514, dtype=float32), 'eval/episode_reward_alive': Array(386.44922, dtype=float32), 'eval/episode_reward_linvel': Array(6348.0654, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.08868, dtype=float32), 'eval/episode_x_position': Array(7484.4263, dtype=float32), 'eval/episode_x_velocity': Array(1269.613, dtype=float32), 'eval/episode_y_position': Array(-222.77472, dtype=float32), 'eval/episode_y_velocity': Array(-133.82776, dtype=float32), 'eval/episode_distance_from_origin_std': Array(496.00275, dtype=float32), 'eval/episode_distance_reward_std': Array(6.285353, dtype=float32), 'eval/episode_forward_reward_std': Array(1047.5516, dtype=float32), 'eval/episode_reward_std': Array(1067.548, dtype=float32), 'eval/episode_reward_alive_std': Array(46.14891, dtype=float32), 'eval/episode_reward_linvel_std': Array(1047.5516, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.40219, dtype=float32), 'eval/episode_x_position_std': Array(497.66864, dtype=float32), 'eval/episode_x_velocity_std': Array(209.51031, dtype=float32), 'eval/episode_y_position_std': Array(362.90192, dtype=float32), 'eval/episode_y_velocity_std': Array(139.62555, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42252731323242, 'eval/sps': 938.2614625376797, 'num_steps': 58818560}
{'eval/walltime': 98320.0738389492, 'training/sps': 2948.6354071403107, 'training/walltime': 20020.50828933716, 'training/entropy_loss': Array(0.01662559, dtype=float32), 'training/policy_loss': Array(0.01462603, dtype=float32), 'training/total_loss': Array(0.18076773, dtype=float32), 'training/v_loss': Array(0.14951612, dtype=float32), 'eval/episode_distance_from_origin': Array(7519.616, dtype=float32), 'eval/episode_distance_reward': Array(37.97171, dtype=float32), 'eval/episode_forward_reward': Array(6328.586, dtype=float32), 'eval/episode_reward': Array(6335.6553, dtype=float32), 'eval/episode_reward_alive': Array(383.39062, dtype=float32), 'eval/episode_reward_linvel': Array(6328.586, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.29175, dtype=float32), 'eval/episode_x_position': Array(7475.5723, dtype=float32), 'eval/episode_x_velocity': Array(1265.717, dtype=float32), 'eval/episode_y_position': Array(-209.77414, dtype=float32), 'eval/episode_y_velocity': Array(-129.24521, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.42886, dtype=float32), 'eval/episode_distance_reward_std': Array(6.350843, dtype=float32), 'eval/episode_forward_reward_std': Array(1058.4663, dtype=float32), 'eval/episode_reward_std': Array(1078.7175, dtype=float32), 'eval/episode_reward_alive_std': Array(46.14375, dtype=float32), 'eval/episode_reward_linvel_std': Array(1058.4663, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.72915, dtype=float32), 'eval/episode_x_position_std': Array(433.91626, dtype=float32), 'eval/episode_x_velocity_std': Array(211.69316, dtype=float32), 'eval/episode_y_position_std': Array(381.46817, dtype=float32), 'eval/episode_y_velocity_std': Array(132.17752, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5625340938568, 'eval/sps': 937.2995371631582, 'num_steps': 58900480}
{'eval/walltime': 98456.53008198738, 'training/sps': 2968.3294689035015, 'training/walltime': 20048.106303930283, 'training/entropy_loss': Array(0.01675909, dtype=float32), 'training/policy_loss': Array(0.00680249, dtype=float32), 'training/total_loss': Array(0.08108605, dtype=float32), 'training/v_loss': Array(0.05752447, dtype=float32), 'eval/episode_distance_from_origin': Array(7565.377, dtype=float32), 'eval/episode_distance_reward': Array(38.28492, dtype=float32), 'eval/episode_forward_reward': Array(6380.787, dtype=float32), 'eval/episode_reward': Array(6387.1875, dtype=float32), 'eval/episode_reward_alive': Array(381.25, dtype=float32), 'eval/episode_reward_linvel': Array(6380.787, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.13385, dtype=float32), 'eval/episode_x_position': Array(7522.2676, dtype=float32), 'eval/episode_x_velocity': Array(1276.1575, dtype=float32), 'eval/episode_y_position': Array(-213.52393, dtype=float32), 'eval/episode_y_velocity': Array(-129.62903, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.6225, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0096173, dtype=float32), 'eval/episode_forward_reward_std': Array(1001.5969, dtype=float32), 'eval/episode_reward_std': Array(1020.8556, dtype=float32), 'eval/episode_reward_alive_std': Array(47.206825, dtype=float32), 'eval/episode_reward_linvel_std': Array(1001.5969, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.044197, dtype=float32), 'eval/episode_x_position_std': Array(434.0961, dtype=float32), 'eval/episode_x_velocity_std': Array(200.31934, dtype=float32), 'eval/episode_y_position_std': Array(356.88818, dtype=float32), 'eval/episode_y_velocity_std': Array(140.01352, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4562430381775, 'eval/sps': 938.0296360950549, 'num_steps': 58982400}
{'eval/walltime': 98593.22473144531, 'training/sps': 2953.4412290246164, 'training/walltime': 20075.84343957901, 'training/entropy_loss': Array(0.01879653, dtype=float32), 'training/policy_loss': Array(0.01070761, dtype=float32), 'training/total_loss': Array(0.24212904, dtype=float32), 'training/v_loss': Array(0.21262491, dtype=float32), 'eval/episode_distance_from_origin': Array(7647.632, dtype=float32), 'eval/episode_distance_reward': Array(38.881187, dtype=float32), 'eval/episode_forward_reward': Array(6480.165, dtype=float32), 'eval/episode_reward': Array(6487.344, dtype=float32), 'eval/episode_reward_alive': Array(377.91016, dtype=float32), 'eval/episode_reward_linvel': Array(6480.165, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.61133, dtype=float32), 'eval/episode_x_position': Array(7604.149, dtype=float32), 'eval/episode_x_velocity': Array(1296.0327, dtype=float32), 'eval/episode_y_position': Array(-201.96484, dtype=float32), 'eval/episode_y_velocity': Array(-123.22014, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.99817, dtype=float32), 'eval/episode_distance_reward_std': Array(5.807712, dtype=float32), 'eval/episode_forward_reward_std': Array(967.94714, dtype=float32), 'eval/episode_reward_std': Array(979.8731, dtype=float32), 'eval/episode_reward_alive_std': Array(48.24208, dtype=float32), 'eval/episode_reward_linvel_std': Array(967.94714, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.047976, dtype=float32), 'eval/episode_x_position_std': Array(429.4251, dtype=float32), 'eval/episode_x_velocity_std': Array(193.5891, dtype=float32), 'eval/episode_y_position_std': Array(394.31122, dtype=float32), 'eval/episode_y_velocity_std': Array(138.11635, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69464945793152, 'eval/sps': 936.3936372607815, 'num_steps': 59064320}
{'eval/walltime': 98729.69736742973, 'training/sps': 2961.372877408408, 'training/walltime': 20103.506284952164, 'training/entropy_loss': Array(0.0194711, dtype=float32), 'training/policy_loss': Array(0.01145589, dtype=float32), 'training/total_loss': Array(0.25439486, dtype=float32), 'training/v_loss': Array(0.22346789, dtype=float32), 'eval/episode_distance_from_origin': Array(7501.499, dtype=float32), 'eval/episode_distance_reward': Array(37.983437, dtype=float32), 'eval/episode_forward_reward': Array(6330.5405, dtype=float32), 'eval/episode_reward': Array(6337.767, dtype=float32), 'eval/episode_reward_alive': Array(381.36328, dtype=float32), 'eval/episode_reward_linvel': Array(6330.5405, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.11923, dtype=float32), 'eval/episode_x_position': Array(7460.4883, dtype=float32), 'eval/episode_x_velocity': Array(1266.1079, dtype=float32), 'eval/episode_y_position': Array(-237.08075, dtype=float32), 'eval/episode_y_velocity': Array(-146.03735, dtype=float32), 'eval/episode_distance_from_origin_std': Array(422.73468, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0707607, dtype=float32), 'eval/episode_forward_reward_std': Array(1011.78625, dtype=float32), 'eval/episode_reward_std': Array(1028.8018, dtype=float32), 'eval/episode_reward_alive_std': Array(44.351875, dtype=float32), 'eval/episode_reward_linvel_std': Array(1011.78625, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.347347, dtype=float32), 'eval/episode_x_position_std': Array(424.73938, dtype=float32), 'eval/episode_x_velocity_std': Array(202.35725, dtype=float32), 'eval/episode_y_position_std': Array(298.1616, dtype=float32), 'eval/episode_y_velocity_std': Array(110.008156, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47263598442078, 'eval/sps': 937.91696098412, 'num_steps': 59146240}
{'eval/walltime': 98866.46397900581, 'training/sps': 2943.971946029969, 'training/walltime': 20131.33263707161, 'training/entropy_loss': Array(0.0188192, dtype=float32), 'training/policy_loss': Array(0.01083395, dtype=float32), 'training/total_loss': Array(0.32716706, dtype=float32), 'training/v_loss': Array(0.29751393, dtype=float32), 'eval/episode_distance_from_origin': Array(7572.556, dtype=float32), 'eval/episode_distance_reward': Array(38.006683, dtype=float32), 'eval/episode_forward_reward': Array(6334.4136, dtype=float32), 'eval/episode_reward': Array(6343.3203, dtype=float32), 'eval/episode_reward_alive': Array(383.73438, dtype=float32), 'eval/episode_reward_linvel': Array(6334.4136, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.83408, dtype=float32), 'eval/episode_x_position': Array(7531.2783, dtype=float32), 'eval/episode_x_velocity': Array(1266.8828, dtype=float32), 'eval/episode_y_position': Array(-190.0777, dtype=float32), 'eval/episode_y_velocity': Array(-116.31064, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.34366, dtype=float32), 'eval/episode_distance_reward_std': Array(5.832596, dtype=float32), 'eval/episode_forward_reward_std': Array(972.0937, dtype=float32), 'eval/episode_reward_std': Array(981.48425, dtype=float32), 'eval/episode_reward_alive_std': Array(48.066475, dtype=float32), 'eval/episode_reward_linvel_std': Array(972.0937, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.149267, dtype=float32), 'eval/episode_x_position_std': Array(471.684, dtype=float32), 'eval/episode_x_velocity_std': Array(194.4187, dtype=float32), 'eval/episode_y_position_std': Array(362.84378, dtype=float32), 'eval/episode_y_velocity_std': Array(125.50367, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.76661157608032, 'eval/sps': 935.900937552996, 'num_steps': 59228160}
{'eval/walltime': 99003.03093123436, 'training/sps': 2942.465318979885, 'training/walltime': 20159.173237085342, 'training/entropy_loss': Array(0.01896138, dtype=float32), 'training/policy_loss': Array(0.0096341, dtype=float32), 'training/total_loss': Array(0.27328348, dtype=float32), 'training/v_loss': Array(0.24468797, dtype=float32), 'eval/episode_distance_from_origin': Array(7588.119, dtype=float32), 'eval/episode_distance_reward': Array(39.05287, dtype=float32), 'eval/episode_forward_reward': Array(6508.7773, dtype=float32), 'eval/episode_reward': Array(6517.925, dtype=float32), 'eval/episode_reward_alive': Array(380.02344, dtype=float32), 'eval/episode_reward_linvel': Array(6508.7773, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.92932, dtype=float32), 'eval/episode_x_position': Array(7546.4556, dtype=float32), 'eval/episode_x_velocity': Array(1301.7555, dtype=float32), 'eval/episode_y_position': Array(-206.4732, dtype=float32), 'eval/episode_y_velocity': Array(-112.380104, dtype=float32), 'eval/episode_distance_from_origin_std': Array(401.28644, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0726776, dtype=float32), 'eval/episode_forward_reward_std': Array(1012.1062, dtype=float32), 'eval/episode_reward_std': Array(1033.0579, dtype=float32), 'eval/episode_reward_alive_std': Array(49.356953, dtype=float32), 'eval/episode_reward_linvel_std': Array(1012.1062, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.779974, dtype=float32), 'eval/episode_x_position_std': Array(403.9135, dtype=float32), 'eval/episode_x_velocity_std': Array(202.42131, dtype=float32), 'eval/episode_y_position_std': Array(379.16086, dtype=float32), 'eval/episode_y_velocity_std': Array(138.52608, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56695222854614, 'eval/sps': 937.2692141931287, 'num_steps': 59310080}
{'eval/walltime': 99139.82539367676, 'training/sps': 2932.53457129112, 'training/walltime': 20187.10811662674, 'training/entropy_loss': Array(0.01911338, dtype=float32), 'training/policy_loss': Array(0.00630861, dtype=float32), 'training/total_loss': Array(0.24593318, dtype=float32), 'training/v_loss': Array(0.2205112, dtype=float32), 'eval/episode_distance_from_origin': Array(7616.581, dtype=float32), 'eval/episode_distance_reward': Array(38.4963, dtype=float32), 'eval/episode_forward_reward': Array(6416.018, dtype=float32), 'eval/episode_reward': Array(6419.8506, dtype=float32), 'eval/episode_reward_alive': Array(377.8789, dtype=float32), 'eval/episode_reward_linvel': Array(6416.018, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.5428, dtype=float32), 'eval/episode_x_position': Array(7572.593, dtype=float32), 'eval/episode_x_velocity': Array(1283.2035, dtype=float32), 'eval/episode_y_position': Array(-300.8909, dtype=float32), 'eval/episode_y_velocity': Array(-142.65897, dtype=float32), 'eval/episode_distance_from_origin_std': Array(428.769, dtype=float32), 'eval/episode_distance_reward_std': Array(6.072946, dtype=float32), 'eval/episode_forward_reward_std': Array(1012.1513, dtype=float32), 'eval/episode_reward_std': Array(1029.0541, dtype=float32), 'eval/episode_reward_alive_std': Array(48.97587, dtype=float32), 'eval/episode_reward_linvel_std': Array(1012.1513, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.51622, dtype=float32), 'eval/episode_x_position_std': Array(431.93335, dtype=float32), 'eval/episode_x_velocity_std': Array(202.43018, dtype=float32), 'eval/episode_y_position_std': Array(352.07346, dtype=float32), 'eval/episode_y_velocity_std': Array(120.52908, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.79446244239807, 'eval/sps': 935.7103914487674, 'num_steps': 59392000}
{'eval/walltime': 99276.26150274277, 'training/sps': 2947.496981516214, 'training/walltime': 20214.901190042496, 'training/entropy_loss': Array(0.01426577, dtype=float32), 'training/policy_loss': Array(0.00397689, dtype=float32), 'training/total_loss': Array(0.05108164, dtype=float32), 'training/v_loss': Array(0.03283899, dtype=float32), 'eval/episode_distance_from_origin': Array(7543.0967, dtype=float32), 'eval/episode_distance_reward': Array(38.375687, dtype=float32), 'eval/episode_forward_reward': Array(6395.914, dtype=float32), 'eval/episode_reward': Array(6399.8936, dtype=float32), 'eval/episode_reward_alive': Array(375.4922, dtype=float32), 'eval/episode_reward_linvel': Array(6395.914, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.88754, dtype=float32), 'eval/episode_x_position': Array(7499.8833, dtype=float32), 'eval/episode_x_velocity': Array(1279.1827, dtype=float32), 'eval/episode_y_position': Array(-210.01976, dtype=float32), 'eval/episode_y_velocity': Array(-129.7614, dtype=float32), 'eval/episode_distance_from_origin_std': Array(398.57648, dtype=float32), 'eval/episode_distance_reward_std': Array(5.182381, dtype=float32), 'eval/episode_forward_reward_std': Array(863.7249, dtype=float32), 'eval/episode_reward_std': Array(876.8694, dtype=float32), 'eval/episode_reward_alive_std': Array(41.759167, dtype=float32), 'eval/episode_reward_linvel_std': Array(863.7249, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.330084, dtype=float32), 'eval/episode_x_position_std': Array(404.01486, dtype=float32), 'eval/episode_x_velocity_std': Array(172.74512, dtype=float32), 'eval/episode_y_position_std': Array(380.2892, dtype=float32), 'eval/episode_y_velocity_std': Array(130.43085, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43610906600952, 'eval/sps': 938.168061785403, 'num_steps': 59473920}
{'eval/walltime': 99413.0366384983, 'training/sps': 2942.08525030927, 'training/walltime': 20242.745386600494, 'training/entropy_loss': Array(0.01870901, dtype=float32), 'training/policy_loss': Array(0.0105457, dtype=float32), 'training/total_loss': Array(0.18930906, dtype=float32), 'training/v_loss': Array(0.16005436, dtype=float32), 'eval/episode_distance_from_origin': Array(7605.9707, dtype=float32), 'eval/episode_distance_reward': Array(38.858223, dtype=float32), 'eval/episode_forward_reward': Array(6476.338, dtype=float32), 'eval/episode_reward': Array(6485.5166, dtype=float32), 'eval/episode_reward_alive': Array(385.40625, dtype=float32), 'eval/episode_reward_linvel': Array(6476.338, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.0857, dtype=float32), 'eval/episode_x_position': Array(7564.0625, dtype=float32), 'eval/episode_x_velocity': Array(1295.2676, dtype=float32), 'eval/episode_y_position': Array(-230.59706, dtype=float32), 'eval/episode_y_velocity': Array(-136.11017, dtype=float32), 'eval/episode_distance_from_origin_std': Array(414.46573, dtype=float32), 'eval/episode_distance_reward_std': Array(5.669157, dtype=float32), 'eval/episode_forward_reward_std': Array(944.85425, dtype=float32), 'eval/episode_reward_std': Array(961.3982, dtype=float32), 'eval/episode_reward_alive_std': Array(43.110672, dtype=float32), 'eval/episode_reward_linvel_std': Array(944.85425, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.767498, dtype=float32), 'eval/episode_x_position_std': Array(418.43677, dtype=float32), 'eval/episode_x_velocity_std': Array(188.97087, dtype=float32), 'eval/episode_y_position_std': Array(346.09552, dtype=float32), 'eval/episode_y_velocity_std': Array(122.82777, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.77513575553894, 'eval/sps': 935.8426097911325, 'num_steps': 59555840}
{'eval/walltime': 99549.4878025055, 'training/sps': 2951.8697636827274, 'training/walltime': 20270.4972884655, 'training/entropy_loss': Array(0.01938292, dtype=float32), 'training/policy_loss': Array(0.01500792, dtype=float32), 'training/total_loss': Array(0.26861742, dtype=float32), 'training/v_loss': Array(0.23422655, dtype=float32), 'eval/episode_distance_from_origin': Array(7516.368, dtype=float32), 'eval/episode_distance_reward': Array(38.316154, dtype=float32), 'eval/episode_forward_reward': Array(6385.9907, dtype=float32), 'eval/episode_reward': Array(6390.287, dtype=float32), 'eval/episode_reward_alive': Array(377.27344, dtype=float32), 'eval/episode_reward_linvel': Array(6385.9907, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.294, dtype=float32), 'eval/episode_x_position': Array(7472.6445, dtype=float32), 'eval/episode_x_velocity': Array(1277.198, dtype=float32), 'eval/episode_y_position': Array(-236.58093, dtype=float32), 'eval/episode_y_velocity': Array(-143.95657, dtype=float32), 'eval/episode_distance_from_origin_std': Array(431.85358, dtype=float32), 'eval/episode_distance_reward_std': Array(5.158326, dtype=float32), 'eval/episode_forward_reward_std': Array(859.71674, dtype=float32), 'eval/episode_reward_std': Array(872.1251, dtype=float32), 'eval/episode_reward_alive_std': Array(41.583256, dtype=float32), 'eval/episode_reward_linvel_std': Array(859.71674, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.208197, dtype=float32), 'eval/episode_x_position_std': Array(434.07504, dtype=float32), 'eval/episode_x_velocity_std': Array(171.94324, dtype=float32), 'eval/episode_y_position_std': Array(356.42148, dtype=float32), 'eval/episode_y_velocity_std': Array(123.16151, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4511640071869, 'eval/sps': 938.0645517487724, 'num_steps': 59637760}
{'eval/walltime': 99686.28789973259, 'training/sps': 2945.49445884494, 'training/walltime': 20298.309257268906, 'training/entropy_loss': Array(0.01920753, dtype=float32), 'training/policy_loss': Array(0.01003222, dtype=float32), 'training/total_loss': Array(0.2787731, dtype=float32), 'training/v_loss': Array(0.24953334, dtype=float32), 'eval/episode_distance_from_origin': Array(7553.008, dtype=float32), 'eval/episode_distance_reward': Array(38.80325, dtype=float32), 'eval/episode_forward_reward': Array(6467.1753, dtype=float32), 'eval/episode_reward': Array(6482.17, dtype=float32), 'eval/episode_reward_alive': Array(390.58594, dtype=float32), 'eval/episode_reward_linvel': Array(6467.1753, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.39487, dtype=float32), 'eval/episode_x_position': Array(7511.2935, dtype=float32), 'eval/episode_x_velocity': Array(1293.435, dtype=float32), 'eval/episode_y_position': Array(-227.00034, dtype=float32), 'eval/episode_y_velocity': Array(-144.99939, dtype=float32), 'eval/episode_distance_from_origin_std': Array(463.53882, dtype=float32), 'eval/episode_distance_reward_std': Array(6.8786254, dtype=float32), 'eval/episode_forward_reward_std': Array(1146.4305, dtype=float32), 'eval/episode_reward_std': Array(1163.799, dtype=float32), 'eval/episode_reward_alive_std': Array(40.229862, dtype=float32), 'eval/episode_reward_linvel_std': Array(1146.4305, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.860273, dtype=float32), 'eval/episode_x_position_std': Array(466.1549, dtype=float32), 'eval/episode_x_velocity_std': Array(229.28612, dtype=float32), 'eval/episode_y_position_std': Array(331.53372, dtype=float32), 'eval/episode_y_velocity_std': Array(115.93648, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.80009722709656, 'eval/sps': 935.6718496150785, 'num_steps': 59719680}
{'eval/walltime': 99823.10673356056, 'training/sps': 2950.987432992064, 'training/walltime': 20326.06945681572, 'training/entropy_loss': Array(0.02059701, dtype=float32), 'training/policy_loss': Array(0.0097566, dtype=float32), 'training/total_loss': Array(0.30350786, dtype=float32), 'training/v_loss': Array(0.27315426, dtype=float32), 'eval/episode_distance_from_origin': Array(7551.006, dtype=float32), 'eval/episode_distance_reward': Array(38.718407, dtype=float32), 'eval/episode_forward_reward': Array(6453.033, dtype=float32), 'eval/episode_reward': Array(6472.3574, dtype=float32), 'eval/episode_reward_alive': Array(388.48047, dtype=float32), 'eval/episode_reward_linvel': Array(6453.033, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.87567, dtype=float32), 'eval/episode_x_position': Array(7509.9824, dtype=float32), 'eval/episode_x_velocity': Array(1290.6066, dtype=float32), 'eval/episode_y_position': Array(-169.88931, dtype=float32), 'eval/episode_y_velocity': Array(-113.974625, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.889, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3100953, dtype=float32), 'eval/episode_forward_reward_std': Array(1051.6749, dtype=float32), 'eval/episode_reward_std': Array(1063.8788, dtype=float32), 'eval/episode_reward_alive_std': Array(42.796913, dtype=float32), 'eval/episode_reward_linvel_std': Array(1051.6749, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.962633, dtype=float32), 'eval/episode_x_position_std': Array(416.3165, dtype=float32), 'eval/episode_x_velocity_std': Array(210.33502, dtype=float32), 'eval/episode_y_position_std': Array(363.33334, dtype=float32), 'eval/episode_y_velocity_std': Array(134.7473, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8188338279724, 'eval/sps': 935.5437144051332, 'num_steps': 59801600}
{'eval/walltime': 99959.59462809563, 'training/sps': 2955.561298051118, 'training/walltime': 20353.786696195602, 'training/entropy_loss': Array(0.02092667, dtype=float32), 'training/policy_loss': Array(0.01115289, dtype=float32), 'training/total_loss': Array(0.2696615, dtype=float32), 'training/v_loss': Array(0.23758194, dtype=float32), 'eval/episode_distance_from_origin': Array(7606.916, dtype=float32), 'eval/episode_distance_reward': Array(39.166183, dtype=float32), 'eval/episode_forward_reward': Array(6527.663, dtype=float32), 'eval/episode_reward': Array(6540.5845, dtype=float32), 'eval/episode_reward_alive': Array(386.19922, dtype=float32), 'eval/episode_reward_linvel': Array(6527.663, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.44403, dtype=float32), 'eval/episode_x_position': Array(7566.032, dtype=float32), 'eval/episode_x_velocity': Array(1305.5327, dtype=float32), 'eval/episode_y_position': Array(-144.47491, dtype=float32), 'eval/episode_y_velocity': Array(-121.17374, dtype=float32), 'eval/episode_distance_from_origin_std': Array(402.3655, dtype=float32), 'eval/episode_distance_reward_std': Array(5.63998, dtype=float32), 'eval/episode_forward_reward_std': Array(939.9916, dtype=float32), 'eval/episode_reward_std': Array(951.1683, dtype=float32), 'eval/episode_reward_alive_std': Array(43.528873, dtype=float32), 'eval/episode_reward_linvel_std': Array(939.9916, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.749113, dtype=float32), 'eval/episode_x_position_std': Array(405.00653, dtype=float32), 'eval/episode_x_velocity_std': Array(187.9984, dtype=float32), 'eval/episode_y_position_std': Array(358.59778, dtype=float32), 'eval/episode_y_velocity_std': Array(130.12642, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4878945350647, 'eval/sps': 937.8121073375918, 'num_steps': 59883520}
{'eval/walltime': 100096.3971889019, 'training/sps': 2951.4588411936325, 'training/walltime': 20381.5424618721, 'training/entropy_loss': Array(0.01427957, dtype=float32), 'training/policy_loss': Array(0.0081091, dtype=float32), 'training/total_loss': Array(0.0848283, dtype=float32), 'training/v_loss': Array(0.06243963, dtype=float32), 'eval/episode_distance_from_origin': Array(7572.2285, dtype=float32), 'eval/episode_distance_reward': Array(39.23252, dtype=float32), 'eval/episode_forward_reward': Array(6538.719, dtype=float32), 'eval/episode_reward': Array(6550.552, dtype=float32), 'eval/episode_reward_alive': Array(386.10938, dtype=float32), 'eval/episode_reward_linvel': Array(6538.719, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.51, dtype=float32), 'eval/episode_x_position': Array(7531.4565, dtype=float32), 'eval/episode_x_velocity': Array(1307.744, dtype=float32), 'eval/episode_y_position': Array(-94.6984, dtype=float32), 'eval/episode_y_velocity': Array(-115.044075, dtype=float32), 'eval/episode_distance_from_origin_std': Array(427.12692, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9800096, dtype=float32), 'eval/episode_forward_reward_std': Array(996.6618, dtype=float32), 'eval/episode_reward_std': Array(1009.01825, dtype=float32), 'eval/episode_reward_alive_std': Array(37.94877, dtype=float32), 'eval/episode_reward_linvel_std': Array(996.6618, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.133255, dtype=float32), 'eval/episode_x_position_std': Array(429.10098, dtype=float32), 'eval/episode_x_velocity_std': Array(199.3324, dtype=float32), 'eval/episode_y_position_std': Array(364.7534, dtype=float32), 'eval/episode_y_velocity_std': Array(133.05817, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.8025608062744, 'eval/sps': 935.6549997719729, 'num_steps': 59965440}
{'eval/walltime': 100232.90759277344, 'training/sps': 2956.1640777507014, 'training/walltime': 20409.254049539566, 'training/entropy_loss': Array(0.01886132, dtype=float32), 'training/policy_loss': Array(0.00935425, dtype=float32), 'training/total_loss': Array(0.10627624, dtype=float32), 'training/v_loss': Array(0.07806067, dtype=float32), 'eval/episode_distance_from_origin': Array(7553.7095, dtype=float32), 'eval/episode_distance_reward': Array(38.475693, dtype=float32), 'eval/episode_forward_reward': Array(6412.582, dtype=float32), 'eval/episode_reward': Array(6420.241, dtype=float32), 'eval/episode_reward_alive': Array(379.625, dtype=float32), 'eval/episode_reward_linvel': Array(6412.582, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.4414, dtype=float32), 'eval/episode_x_position': Array(7515.508, dtype=float32), 'eval/episode_x_velocity': Array(1282.5166, dtype=float32), 'eval/episode_y_position': Array(-97.693375, dtype=float32), 'eval/episode_y_velocity': Array(-104.40062, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.4494, dtype=float32), 'eval/episode_distance_reward_std': Array(6.123008, dtype=float32), 'eval/episode_forward_reward_std': Array(1020.49445, dtype=float32), 'eval/episode_reward_std': Array(1026.6086, dtype=float32), 'eval/episode_reward_alive_std': Array(42.18787, dtype=float32), 'eval/episode_reward_linvel_std': Array(1020.49445, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.653622, dtype=float32), 'eval/episode_x_position_std': Array(473.90155, dtype=float32), 'eval/episode_x_velocity_std': Array(204.09886, dtype=float32), 'eval/episode_y_position_std': Array(347.57962, dtype=float32), 'eval/episode_y_velocity_std': Array(130.01074, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51040387153625, 'eval/sps': 937.6574705650639, 'num_steps': 60047360}
{'eval/walltime': 100369.66383290291, 'training/sps': 2950.1279703307596, 'training/walltime': 20437.022336483, 'training/entropy_loss': Array(0.01904876, dtype=float32), 'training/policy_loss': Array(0.01224823, dtype=float32), 'training/total_loss': Array(0.27443328, dtype=float32), 'training/v_loss': Array(0.24313632, dtype=float32), 'eval/episode_distance_from_origin': Array(7535.0522, dtype=float32), 'eval/episode_distance_reward': Array(38.170822, dtype=float32), 'eval/episode_forward_reward': Array(6361.7705, dtype=float32), 'eval/episode_reward': Array(6364.082, dtype=float32), 'eval/episode_reward_alive': Array(379.96484, dtype=float32), 'eval/episode_reward_linvel': Array(6361.7705, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.82318, dtype=float32), 'eval/episode_x_position': Array(7493.6914, dtype=float32), 'eval/episode_x_velocity': Array(1272.354, dtype=float32), 'eval/episode_y_position': Array(-136.92786, dtype=float32), 'eval/episode_y_velocity': Array(-121.5329, dtype=float32), 'eval/episode_distance_from_origin_std': Array(437.91452, dtype=float32), 'eval/episode_distance_reward_std': Array(6.070313, dtype=float32), 'eval/episode_forward_reward_std': Array(1011.71265, dtype=float32), 'eval/episode_reward_std': Array(1030.5493, dtype=float32), 'eval/episode_reward_alive_std': Array(42.960564, dtype=float32), 'eval/episode_reward_linvel_std': Array(1011.71265, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.507248, dtype=float32), 'eval/episode_x_position_std': Array(438.2524, dtype=float32), 'eval/episode_x_velocity_std': Array(202.34245, dtype=float32), 'eval/episode_y_position_std': Array(357.9063, dtype=float32), 'eval/episode_y_velocity_std': Array(131.18048, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.75624012947083, 'eval/sps': 935.9719152765457, 'num_steps': 60129280}
{'eval/walltime': 100506.02862215042, 'training/sps': 2955.377779416991, 'training/walltime': 20464.741297006607, 'training/entropy_loss': Array(0.01945293, dtype=float32), 'training/policy_loss': Array(0.01199582, dtype=float32), 'training/total_loss': Array(0.30454898, dtype=float32), 'training/v_loss': Array(0.27310023, dtype=float32), 'eval/episode_distance_from_origin': Array(7571.753, dtype=float32), 'eval/episode_distance_reward': Array(38.965736, dtype=float32), 'eval/episode_forward_reward': Array(6494.256, dtype=float32), 'eval/episode_reward': Array(6496.078, dtype=float32), 'eval/episode_reward_alive': Array(374.28125, dtype=float32), 'eval/episode_reward_linvel': Array(6494.256, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.4251, dtype=float32), 'eval/episode_x_position': Array(7528.6436, dtype=float32), 'eval/episode_x_velocity': Array(1298.8512, dtype=float32), 'eval/episode_y_position': Array(-131.33376, dtype=float32), 'eval/episode_y_velocity': Array(-118.25368, dtype=float32), 'eval/episode_distance_from_origin_std': Array(463.04333, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0021267, dtype=float32), 'eval/episode_forward_reward_std': Array(1000.34875, dtype=float32), 'eval/episode_reward_std': Array(1013.11096, dtype=float32), 'eval/episode_reward_alive_std': Array(44.85557, dtype=float32), 'eval/episode_reward_linvel_std': Array(1000.34875, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.218412, dtype=float32), 'eval/episode_x_position_std': Array(467.67612, dtype=float32), 'eval/episode_x_velocity_std': Array(200.06981, dtype=float32), 'eval/episode_y_position_std': Array(400.3253, dtype=float32), 'eval/episode_y_velocity_std': Array(138.8791, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.36478924751282, 'eval/sps': 938.6587307935476, 'num_steps': 60211200}
{'eval/walltime': 100642.55421447754, 'training/sps': 2938.8631133596646, 'training/walltime': 20492.61602163315, 'training/entropy_loss': Array(0.02062288, dtype=float32), 'training/policy_loss': Array(0.00594825, dtype=float32), 'training/total_loss': Array(0.28904408, dtype=float32), 'training/v_loss': Array(0.26247293, dtype=float32), 'eval/episode_distance_from_origin': Array(7493.4443, dtype=float32), 'eval/episode_distance_reward': Array(38.34437, dtype=float32), 'eval/episode_forward_reward': Array(6390.6953, dtype=float32), 'eval/episode_reward': Array(6398.587, dtype=float32), 'eval/episode_reward_alive': Array(384.20312, dtype=float32), 'eval/episode_reward_linvel': Array(6390.6953, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.65628, dtype=float32), 'eval/episode_x_position': Array(7451.899, dtype=float32), 'eval/episode_x_velocity': Array(1278.1389, dtype=float32), 'eval/episode_y_position': Array(-142.98141, dtype=float32), 'eval/episode_y_velocity': Array(-122.59138, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.6641, dtype=float32), 'eval/episode_distance_reward_std': Array(6.432245, dtype=float32), 'eval/episode_forward_reward_std': Array(1072.034, dtype=float32), 'eval/episode_reward_std': Array(1088.4375, dtype=float32), 'eval/episode_reward_alive_std': Array(44.00299, dtype=float32), 'eval/episode_reward_linvel_std': Array(1072.034, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.018377, dtype=float32), 'eval/episode_x_position_std': Array(453.78424, dtype=float32), 'eval/episode_x_velocity_std': Array(214.40671, dtype=float32), 'eval/episode_y_position_std': Array(337.9074, dtype=float32), 'eval/episode_y_velocity_std': Array(130.20468, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52559232711792, 'eval/sps': 937.5531562852301, 'num_steps': 60293120}
{'eval/walltime': 100778.79854154587, 'training/sps': 2937.8339235138346, 'training/walltime': 20520.500511407852, 'training/entropy_loss': Array(0.02045116, dtype=float32), 'training/policy_loss': Array(0.00939286, dtype=float32), 'training/total_loss': Array(0.28958935, dtype=float32), 'training/v_loss': Array(0.25974533, dtype=float32), 'eval/episode_distance_from_origin': Array(7556.621, dtype=float32), 'eval/episode_distance_reward': Array(39.096634, dtype=float32), 'eval/episode_forward_reward': Array(6516.072, dtype=float32), 'eval/episode_reward': Array(6524.7734, dtype=float32), 'eval/episode_reward_alive': Array(381.78906, dtype=float32), 'eval/episode_reward_linvel': Array(6516.072, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.18396, dtype=float32), 'eval/episode_x_position': Array(7516.577, dtype=float32), 'eval/episode_x_velocity': Array(1303.2142, dtype=float32), 'eval/episode_y_position': Array(-76.94672, dtype=float32), 'eval/episode_y_velocity': Array(-109.48263, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.17847, dtype=float32), 'eval/episode_distance_reward_std': Array(5.638933, dtype=float32), 'eval/episode_forward_reward_std': Array(939.8177, dtype=float32), 'eval/episode_reward_std': Array(953.71826, dtype=float32), 'eval/episode_reward_alive_std': Array(47.151665, dtype=float32), 'eval/episode_reward_linvel_std': Array(939.8177, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.152098, dtype=float32), 'eval/episode_x_position_std': Array(436.15015, dtype=float32), 'eval/episode_x_velocity_std': Array(187.96341, dtype=float32), 'eval/episode_y_position_std': Array(357.94455, dtype=float32), 'eval/episode_y_velocity_std': Array(132.02385, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24432706832886, 'eval/sps': 939.4886580180753, 'num_steps': 60375040}
{'eval/walltime': 100915.34161520004, 'training/sps': 2937.713080338908, 'training/walltime': 20548.38614821434, 'training/entropy_loss': Array(0.01577586, dtype=float32), 'training/policy_loss': Array(0.00682867, dtype=float32), 'training/total_loss': Array(0.1492556, dtype=float32), 'training/v_loss': Array(0.12665108, dtype=float32), 'eval/episode_distance_from_origin': Array(7511.1055, dtype=float32), 'eval/episode_distance_reward': Array(38.443047, dtype=float32), 'eval/episode_forward_reward': Array(6407.1416, dtype=float32), 'eval/episode_reward': Array(6414.8374, dtype=float32), 'eval/episode_reward_alive': Array(383.3828, dtype=float32), 'eval/episode_reward_linvel': Array(6407.1416, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.12878, dtype=float32), 'eval/episode_x_position': Array(7470.4326, dtype=float32), 'eval/episode_x_velocity': Array(1281.4281, dtype=float32), 'eval/episode_y_position': Array(-79.82794, dtype=float32), 'eval/episode_y_velocity': Array(-112.39614, dtype=float32), 'eval/episode_distance_from_origin_std': Array(454.8291, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0271645, dtype=float32), 'eval/episode_forward_reward_std': Array(1004.51935, dtype=float32), 'eval/episode_reward_std': Array(1015.6929, dtype=float32), 'eval/episode_reward_alive_std': Array(45.893837, dtype=float32), 'eval/episode_reward_linvel_std': Array(1004.51935, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.193739, dtype=float32), 'eval/episode_x_position_std': Array(457.8489, dtype=float32), 'eval/episode_x_velocity_std': Array(200.90396, dtype=float32), 'eval/episode_y_position_std': Array(347.20248, dtype=float32), 'eval/episode_y_velocity_std': Array(129.93571, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5430736541748, 'eval/sps': 937.4331232954956, 'num_steps': 60456960}
{'eval/walltime': 101051.59754872322, 'training/sps': 2932.5759191094494, 'training/walltime': 20576.320633888245, 'training/entropy_loss': Array(0.01831089, dtype=float32), 'training/policy_loss': Array(0.00753873, dtype=float32), 'training/total_loss': Array(0.07902429, dtype=float32), 'training/v_loss': Array(0.05317467, dtype=float32), 'eval/episode_distance_from_origin': Array(7502.276, dtype=float32), 'eval/episode_distance_reward': Array(38.53166, dtype=float32), 'eval/episode_forward_reward': Array(6421.9087, dtype=float32), 'eval/episode_reward': Array(6432.5283, dtype=float32), 'eval/episode_reward_alive': Array(390.76562, dtype=float32), 'eval/episode_reward_linvel': Array(6421.9087, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.6778, dtype=float32), 'eval/episode_x_position': Array(7461.835, dtype=float32), 'eval/episode_x_velocity': Array(1284.3818, dtype=float32), 'eval/episode_y_position': Array(-40.406715, dtype=float32), 'eval/episode_y_velocity': Array(-113.46699, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.56262, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9764028, dtype=float32), 'eval/episode_forward_reward_std': Array(996.0608, dtype=float32), 'eval/episode_reward_std': Array(1012.19635, dtype=float32), 'eval/episode_reward_alive_std': Array(40.037624, dtype=float32), 'eval/episode_reward_linvel_std': Array(996.0608, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.517864, dtype=float32), 'eval/episode_x_position_std': Array(462.37967, dtype=float32), 'eval/episode_x_velocity_std': Array(199.21213, dtype=float32), 'eval/episode_y_position_std': Array(358.71484, dtype=float32), 'eval/episode_y_velocity_std': Array(128.72981, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2559335231781, 'eval/sps': 939.4086311714733, 'num_steps': 60538880}
{'eval/walltime': 101188.18958210945, 'training/sps': 2951.938819828898, 'training/walltime': 20604.07188653946, 'training/entropy_loss': Array(0.01808184, dtype=float32), 'training/policy_loss': Array(0.00826548, dtype=float32), 'training/total_loss': Array(0.19595037, dtype=float32), 'training/v_loss': Array(0.16960306, dtype=float32), 'eval/episode_distance_from_origin': Array(7595.2803, dtype=float32), 'eval/episode_distance_reward': Array(39.749687, dtype=float32), 'eval/episode_forward_reward': Array(6624.913, dtype=float32), 'eval/episode_reward': Array(6637.9785, dtype=float32), 'eval/episode_reward_alive': Array(385.28125, dtype=float32), 'eval/episode_reward_linvel': Array(6624.913, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.96503, dtype=float32), 'eval/episode_x_position': Array(7554.5596, dtype=float32), 'eval/episode_x_velocity': Array(1324.9825, dtype=float32), 'eval/episode_y_position': Array(-31.265945, dtype=float32), 'eval/episode_y_velocity': Array(-102.68349, dtype=float32), 'eval/episode_distance_from_origin_std': Array(391.40915, dtype=float32), 'eval/episode_distance_reward_std': Array(5.489934, dtype=float32), 'eval/episode_forward_reward_std': Array(914.98303, dtype=float32), 'eval/episode_reward_std': Array(935.3247, dtype=float32), 'eval/episode_reward_alive_std': Array(43.75695, dtype=float32), 'eval/episode_reward_linvel_std': Array(914.98303, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.536306, dtype=float32), 'eval/episode_x_position_std': Array(393.6613, dtype=float32), 'eval/episode_x_velocity_std': Array(182.99667, dtype=float32), 'eval/episode_y_position_std': Array(369.44083, dtype=float32), 'eval/episode_y_velocity_std': Array(140.35274, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59203338623047, 'eval/sps': 937.0971119381798, 'num_steps': 60620800}
{'eval/walltime': 101324.43715548515, 'training/sps': 2958.986487395961, 'training/walltime': 20631.757041692734, 'training/entropy_loss': Array(0.01885358, dtype=float32), 'training/policy_loss': Array(0.00630731, dtype=float32), 'training/total_loss': Array(0.2625646, dtype=float32), 'training/v_loss': Array(0.23740369, dtype=float32), 'eval/episode_distance_from_origin': Array(7482.347, dtype=float32), 'eval/episode_distance_reward': Array(38.39213, dtype=float32), 'eval/episode_forward_reward': Array(6398.656, dtype=float32), 'eval/episode_reward': Array(6411.2036, dtype=float32), 'eval/episode_reward_alive': Array(384.96094, dtype=float32), 'eval/episode_reward_linvel': Array(6398.656, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.80447, dtype=float32), 'eval/episode_x_position': Array(7443.5938, dtype=float32), 'eval/episode_x_velocity': Array(1279.7311, dtype=float32), 'eval/episode_y_position': Array(-26.365383, dtype=float32), 'eval/episode_y_velocity': Array(-102.090164, dtype=float32), 'eval/episode_distance_from_origin_std': Array(433.2985, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4674964, dtype=float32), 'eval/episode_forward_reward_std': Array(911.2433, dtype=float32), 'eval/episode_reward_std': Array(917.48755, dtype=float32), 'eval/episode_reward_alive_std': Array(41.382675, dtype=float32), 'eval/episode_reward_linvel_std': Array(911.2433, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.457804, dtype=float32), 'eval/episode_x_position_std': Array(435.16595, dtype=float32), 'eval/episode_x_velocity_std': Array(182.24863, dtype=float32), 'eval/episode_y_position_std': Array(326.32895, dtype=float32), 'eval/episode_y_velocity_std': Array(131.63106, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2475733757019, 'eval/sps': 939.4662732600802, 'num_steps': 60702720}
{'eval/walltime': 101461.05275917053, 'training/sps': 2950.168929195578, 'training/walltime': 20659.524943113327, 'training/entropy_loss': Array(0.01843696, dtype=float32), 'training/policy_loss': Array(0.00559538, dtype=float32), 'training/total_loss': Array(0.25721636, dtype=float32), 'training/v_loss': Array(0.23318401, dtype=float32), 'eval/episode_distance_from_origin': Array(7588.3794, dtype=float32), 'eval/episode_distance_reward': Array(39.63899, dtype=float32), 'eval/episode_forward_reward': Array(6606.4624, dtype=float32), 'eval/episode_reward': Array(6622.8027, dtype=float32), 'eval/episode_reward_alive': Array(389.71875, dtype=float32), 'eval/episode_reward_linvel': Array(6606.4624, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.017, dtype=float32), 'eval/episode_x_position': Array(7550.3613, dtype=float32), 'eval/episode_x_velocity': Array(1321.2925, dtype=float32), 'eval/episode_y_position': Array(30.558537, dtype=float32), 'eval/episode_y_velocity': Array(-81.12454, dtype=float32), 'eval/episode_distance_from_origin_std': Array(432.05618, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9142804, dtype=float32), 'eval/episode_forward_reward_std': Array(985.70764, dtype=float32), 'eval/episode_reward_std': Array(1008.4595, dtype=float32), 'eval/episode_reward_alive_std': Array(44.64608, dtype=float32), 'eval/episode_reward_linvel_std': Array(985.70764, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.084322, dtype=float32), 'eval/episode_x_position_std': Array(433.60898, dtype=float32), 'eval/episode_x_velocity_std': Array(197.14151, dtype=float32), 'eval/episode_y_position_std': Array(356.23056, dtype=float32), 'eval/episode_y_velocity_std': Array(129.78027, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.61560368537903, 'eval/sps': 936.935434511416, 'num_steps': 60784640}
{'eval/walltime': 101597.38619160652, 'training/sps': 2950.143066972338, 'training/walltime': 20687.29308795929, 'training/entropy_loss': Array(0.01879693, dtype=float32), 'training/policy_loss': Array(0.010459, dtype=float32), 'training/total_loss': Array(0.28567806, dtype=float32), 'training/v_loss': Array(0.25642213, dtype=float32), 'eval/episode_distance_from_origin': Array(7550.478, dtype=float32), 'eval/episode_distance_reward': Array(39.13557, dtype=float32), 'eval/episode_forward_reward': Array(6522.5615, dtype=float32), 'eval/episode_reward': Array(6542.6426, dtype=float32), 'eval/episode_reward_alive': Array(393.95312, dtype=float32), 'eval/episode_reward_linvel': Array(6522.5615, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.00735, dtype=float32), 'eval/episode_x_position': Array(7509.121, dtype=float32), 'eval/episode_x_velocity': Array(1304.5123, dtype=float32), 'eval/episode_y_position': Array(-44.358566, dtype=float32), 'eval/episode_y_velocity': Array(-101.361336, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.92532, dtype=float32), 'eval/episode_distance_reward_std': Array(6.013942, dtype=float32), 'eval/episode_forward_reward_std': Array(1002.3167, dtype=float32), 'eval/episode_reward_std': Array(1017.6262, dtype=float32), 'eval/episode_reward_alive_std': Array(36.226147, dtype=float32), 'eval/episode_reward_linvel_std': Array(1002.3167, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.077341, dtype=float32), 'eval/episode_x_position_std': Array(431.19586, dtype=float32), 'eval/episode_x_velocity_std': Array(200.46341, dtype=float32), 'eval/episode_y_position_std': Array(384.62912, dtype=float32), 'eval/episode_y_velocity_std': Array(141.57924, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33343243598938, 'eval/sps': 938.8746231420378, 'num_steps': 60866560}
{'eval/walltime': 101734.00873398781, 'training/sps': 2942.09112003008, 'training/walltime': 20715.13722896576, 'training/entropy_loss': Array(0.01636573, dtype=float32), 'training/policy_loss': Array(0.00581144, dtype=float32), 'training/total_loss': Array(0.18191355, dtype=float32), 'training/v_loss': Array(0.1597364, dtype=float32), 'eval/episode_distance_from_origin': Array(7504.7583, dtype=float32), 'eval/episode_distance_reward': Array(38.82296, dtype=float32), 'eval/episode_forward_reward': Array(6470.459, dtype=float32), 'eval/episode_reward': Array(6487.7134, dtype=float32), 'eval/episode_reward_alive': Array(385.3203, dtype=float32), 'eval/episode_reward_linvel': Array(6470.459, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.8886, dtype=float32), 'eval/episode_x_position': Array(7465.3623, dtype=float32), 'eval/episode_x_velocity': Array(1294.0917, dtype=float32), 'eval/episode_y_position': Array(-62.039803, dtype=float32), 'eval/episode_y_velocity': Array(-106.56348, dtype=float32), 'eval/episode_distance_from_origin_std': Array(412.5293, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6868615, dtype=float32), 'eval/episode_forward_reward_std': Array(947.8039, dtype=float32), 'eval/episode_reward_std': Array(956.6505, dtype=float32), 'eval/episode_reward_alive_std': Array(40.480305, dtype=float32), 'eval/episode_reward_linvel_std': Array(947.8039, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.508413, dtype=float32), 'eval/episode_x_position_std': Array(416.28802, dtype=float32), 'eval/episode_x_velocity_std': Array(189.56088, dtype=float32), 'eval/episode_y_position_std': Array(338.99164, dtype=float32), 'eval/episode_y_velocity_std': Array(124.37347, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62254238128662, 'eval/sps': 936.8878500502296, 'num_steps': 60948480}
{'eval/walltime': 101870.33538103104, 'training/sps': 2947.3423234477896, 'training/walltime': 20742.931760787964, 'training/entropy_loss': Array(0.0165976, dtype=float32), 'training/policy_loss': Array(0.00474286, dtype=float32), 'training/total_loss': Array(0.08517364, dtype=float32), 'training/v_loss': Array(0.06383318, dtype=float32), 'eval/episode_distance_from_origin': Array(7579.456, dtype=float32), 'eval/episode_distance_reward': Array(39.425896, dtype=float32), 'eval/episode_forward_reward': Array(6570.9463, dtype=float32), 'eval/episode_reward': Array(6577.3315, dtype=float32), 'eval/episode_reward_alive': Array(378.82812, dtype=float32), 'eval/episode_reward_linvel': Array(6570.9463, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.8703, dtype=float32), 'eval/episode_x_position': Array(7538.4297, dtype=float32), 'eval/episode_x_velocity': Array(1314.1895, dtype=float32), 'eval/episode_y_position': Array(-29.162346, dtype=float32), 'eval/episode_y_velocity': Array(-94.96225, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.90167, dtype=float32), 'eval/episode_distance_reward_std': Array(5.897828, dtype=float32), 'eval/episode_forward_reward_std': Array(982.9655, dtype=float32), 'eval/episode_reward_std': Array(1001.53265, dtype=float32), 'eval/episode_reward_alive_std': Array(45.92123, dtype=float32), 'eval/episode_reward_linvel_std': Array(982.9655, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.555117, dtype=float32), 'eval/episode_x_position_std': Array(482.45456, dtype=float32), 'eval/episode_x_velocity_std': Array(196.59322, dtype=float32), 'eval/episode_y_position_std': Array(384.30884, dtype=float32), 'eval/episode_y_velocity_std': Array(143.12303, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32664704322815, 'eval/sps': 938.9213537938197, 'num_steps': 61030400}
{'eval/walltime': 102006.94133138657, 'training/sps': 2959.53830437457, 'training/walltime': 20770.611753940582, 'training/entropy_loss': Array(0.01880074, dtype=float32), 'training/policy_loss': Array(0.00860185, dtype=float32), 'training/total_loss': Array(0.1976239, dtype=float32), 'training/v_loss': Array(0.1702213, dtype=float32), 'eval/episode_distance_from_origin': Array(7525.529, dtype=float32), 'eval/episode_distance_reward': Array(38.559776, dtype=float32), 'eval/episode_forward_reward': Array(6426.5957, dtype=float32), 'eval/episode_reward': Array(6436.7554, dtype=float32), 'eval/episode_reward_alive': Array(381.66016, dtype=float32), 'eval/episode_reward_linvel': Array(6426.5957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.0598, dtype=float32), 'eval/episode_x_position': Array(7485.9834, dtype=float32), 'eval/episode_x_velocity': Array(1285.3191, dtype=float32), 'eval/episode_y_position': Array(-13.3564, dtype=float32), 'eval/episode_y_velocity': Array(-92.99161, dtype=float32), 'eval/episode_distance_from_origin_std': Array(438.9958, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9321494, dtype=float32), 'eval/episode_forward_reward_std': Array(988.68585, dtype=float32), 'eval/episode_reward_std': Array(1006.63574, dtype=float32), 'eval/episode_reward_alive_std': Array(51.66247, dtype=float32), 'eval/episode_reward_linvel_std': Array(988.68585, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.437593, dtype=float32), 'eval/episode_x_position_std': Array(439.98666, dtype=float32), 'eval/episode_x_velocity_std': Array(197.73701, dtype=float32), 'eval/episode_y_position_std': Array(354.48184, dtype=float32), 'eval/episode_y_velocity_std': Array(134.20435, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60595035552979, 'eval/sps': 937.0016435365225, 'num_steps': 61112320}
{'eval/walltime': 102143.28731775284, 'training/sps': 2942.2657864315456, 'training/walltime': 20798.454241991043, 'training/entropy_loss': Array(0.01935621, dtype=float32), 'training/policy_loss': Array(0.01079984, dtype=float32), 'training/total_loss': Array(0.26784664, dtype=float32), 'training/v_loss': Array(0.23769057, dtype=float32), 'eval/episode_distance_from_origin': Array(7626.3174, dtype=float32), 'eval/episode_distance_reward': Array(39.98133, dtype=float32), 'eval/episode_forward_reward': Array(6663.5205, dtype=float32), 'eval/episode_reward': Array(6676.435, dtype=float32), 'eval/episode_reward_alive': Array(384.8789, dtype=float32), 'eval/episode_reward_linvel': Array(6663.5205, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.94513, dtype=float32), 'eval/episode_x_position': Array(7583.551, dtype=float32), 'eval/episode_x_velocity': Array(1332.7039, dtype=float32), 'eval/episode_y_position': Array(-47.77673, dtype=float32), 'eval/episode_y_velocity': Array(-99.704865, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.31952, dtype=float32), 'eval/episode_distance_reward_std': Array(6.318038, dtype=float32), 'eval/episode_forward_reward_std': Array(1053.0009, dtype=float32), 'eval/episode_reward_std': Array(1069.5571, dtype=float32), 'eval/episode_reward_alive_std': Array(44.34769, dtype=float32), 'eval/episode_reward_linvel_std': Array(1053.0009, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.227118, dtype=float32), 'eval/episode_x_position_std': Array(418.48254, dtype=float32), 'eval/episode_x_velocity_std': Array(210.60028, dtype=float32), 'eval/episode_y_position_std': Array(420.64893, dtype=float32), 'eval/episode_y_velocity_std': Array(145.50989, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34598636627197, 'eval/sps': 938.7881771315821, 'num_steps': 61194240}
{'eval/walltime': 102279.91870212555, 'training/sps': 2942.3016645153707, 'training/walltime': 20826.296390533447, 'training/entropy_loss': Array(0.01948182, dtype=float32), 'training/policy_loss': Array(0.01539913, dtype=float32), 'training/total_loss': Array(0.26063228, dtype=float32), 'training/v_loss': Array(0.22575133, dtype=float32), 'eval/episode_distance_from_origin': Array(7536.0566, dtype=float32), 'eval/episode_distance_reward': Array(39.33575, dtype=float32), 'eval/episode_forward_reward': Array(6555.9233, dtype=float32), 'eval/episode_reward': Array(6572.694, dtype=float32), 'eval/episode_reward_alive': Array(388.48828, dtype=float32), 'eval/episode_reward_linvel': Array(6555.9233, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.05377, dtype=float32), 'eval/episode_x_position': Array(7497.57, dtype=float32), 'eval/episode_x_velocity': Array(1311.1846, dtype=float32), 'eval/episode_y_position': Array(-37.785965, dtype=float32), 'eval/episode_y_velocity': Array(-97.267136, dtype=float32), 'eval/episode_distance_from_origin_std': Array(502.78326, dtype=float32), 'eval/episode_distance_reward_std': Array(6.27018, dtype=float32), 'eval/episode_forward_reward_std': Array(1045.023, dtype=float32), 'eval/episode_reward_std': Array(1061.6357, dtype=float32), 'eval/episode_reward_alive_std': Array(35.04185, dtype=float32), 'eval/episode_reward_linvel_std': Array(1045.023, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.461494, dtype=float32), 'eval/episode_x_position_std': Array(504.5102, dtype=float32), 'eval/episode_x_velocity_std': Array(209.00471, dtype=float32), 'eval/episode_y_position_std': Array(344.57794, dtype=float32), 'eval/episode_y_velocity_std': Array(130.30847, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63138437271118, 'eval/sps': 936.8272200977926, 'num_steps': 61276160}
{'eval/walltime': 102416.25145125389, 'training/sps': 2935.3435151629888, 'training/walltime': 20854.20453810692, 'training/entropy_loss': Array(0.01978008, dtype=float32), 'training/policy_loss': Array(0.01057825, dtype=float32), 'training/total_loss': Array(0.27802712, dtype=float32), 'training/v_loss': Array(0.24766879, dtype=float32), 'eval/episode_distance_from_origin': Array(7551.826, dtype=float32), 'eval/episode_distance_reward': Array(39.30568, dtype=float32), 'eval/episode_forward_reward': Array(6550.913, dtype=float32), 'eval/episode_reward': Array(6568.37, dtype=float32), 'eval/episode_reward_alive': Array(385.44922, dtype=float32), 'eval/episode_reward_linvel': Array(6550.913, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.29666, dtype=float32), 'eval/episode_x_position': Array(7512.2935, dtype=float32), 'eval/episode_x_velocity': Array(1310.1826, dtype=float32), 'eval/episode_y_position': Array(48.163887, dtype=float32), 'eval/episode_y_velocity': Array(-75.1565, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.68582, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9516196, dtype=float32), 'eval/episode_forward_reward_std': Array(991.9314, dtype=float32), 'eval/episode_reward_std': Array(998.14685, dtype=float32), 'eval/episode_reward_alive_std': Array(42.738342, dtype=float32), 'eval/episode_reward_linvel_std': Array(991.9314, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.422977, dtype=float32), 'eval/episode_x_position_std': Array(433.55453, dtype=float32), 'eval/episode_x_velocity_std': Array(198.38623, dtype=float32), 'eval/episode_y_position_std': Array(358.7056, dtype=float32), 'eval/episode_y_velocity_std': Array(143.06326, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33274912834167, 'eval/sps': 938.879328836116, 'num_steps': 61358080}
{'eval/walltime': 102552.8611831665, 'training/sps': 2941.9472808280107, 'training/walltime': 20882.050040483475, 'training/entropy_loss': Array(0.0199336, dtype=float32), 'training/policy_loss': Array(0.01359023, dtype=float32), 'training/total_loss': Array(0.25329912, dtype=float32), 'training/v_loss': Array(0.21977527, dtype=float32), 'eval/episode_distance_from_origin': Array(7425.992, dtype=float32), 'eval/episode_distance_reward': Array(38.137756, dtype=float32), 'eval/episode_forward_reward': Array(6356.259, dtype=float32), 'eval/episode_reward': Array(6367.84, dtype=float32), 'eval/episode_reward_alive': Array(384.28906, dtype=float32), 'eval/episode_reward_linvel': Array(6356.259, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.8461, dtype=float32), 'eval/episode_x_position': Array(7384.4365, dtype=float32), 'eval/episode_x_velocity': Array(1271.252, dtype=float32), 'eval/episode_y_position': Array(-44.893486, dtype=float32), 'eval/episode_y_velocity': Array(-105.26959, dtype=float32), 'eval/episode_distance_from_origin_std': Array(412.22842, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3051524, dtype=float32), 'eval/episode_forward_reward_std': Array(884.18665, dtype=float32), 'eval/episode_reward_std': Array(896.5278, dtype=float32), 'eval/episode_reward_alive_std': Array(38.730114, dtype=float32), 'eval/episode_reward_linvel_std': Array(884.18665, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.15326, dtype=float32), 'eval/episode_x_position_std': Array(413.03558, dtype=float32), 'eval/episode_x_velocity_std': Array(176.83745, dtype=float32), 'eval/episode_y_position_std': Array(387.58807, dtype=float32), 'eval/episode_y_velocity_std': Array(131.14949, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60973191261292, 'eval/sps': 936.9757059612676, 'num_steps': 61440000}
{'eval/walltime': 102689.19020986557, 'training/sps': 2946.5183861446035, 'training/walltime': 20909.85234451294, 'training/entropy_loss': Array(0.01467881, dtype=float32), 'training/policy_loss': Array(0.00704947, dtype=float32), 'training/total_loss': Array(0.06425063, dtype=float32), 'training/v_loss': Array(0.04252236, dtype=float32), 'eval/episode_distance_from_origin': Array(7452.283, dtype=float32), 'eval/episode_distance_reward': Array(37.87744, dtype=float32), 'eval/episode_forward_reward': Array(6312.875, dtype=float32), 'eval/episode_reward': Array(6321.9375, dtype=float32), 'eval/episode_reward_alive': Array(386.48438, dtype=float32), 'eval/episode_reward_linvel': Array(6312.875, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.29874, dtype=float32), 'eval/episode_x_position': Array(7410.9624, dtype=float32), 'eval/episode_x_velocity': Array(1262.5748, dtype=float32), 'eval/episode_y_position': Array(-53.420586, dtype=float32), 'eval/episode_y_velocity': Array(-104.79785, dtype=float32), 'eval/episode_distance_from_origin_std': Array(507.416, dtype=float32), 'eval/episode_distance_reward_std': Array(6.515495, dtype=float32), 'eval/episode_forward_reward_std': Array(1085.9093, dtype=float32), 'eval/episode_reward_std': Array(1104.0085, dtype=float32), 'eval/episode_reward_alive_std': Array(41.094112, dtype=float32), 'eval/episode_reward_linvel_std': Array(1085.9093, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.666285, dtype=float32), 'eval/episode_x_position_std': Array(510.89142, dtype=float32), 'eval/episode_x_velocity_std': Array(217.18184, dtype=float32), 'eval/episode_y_position_std': Array(384.32285, dtype=float32), 'eval/episode_y_velocity_std': Array(132.91049, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32902669906616, 'eval/sps': 938.9049646965373, 'num_steps': 61521920}
{'eval/walltime': 102825.79950141907, 'training/sps': 2941.9314618933495, 'training/walltime': 20937.697996616364, 'training/entropy_loss': Array(0.0182871, dtype=float32), 'training/policy_loss': Array(0.00773389, dtype=float32), 'training/total_loss': Array(0.2014879, dtype=float32), 'training/v_loss': Array(0.17546692, dtype=float32), 'eval/episode_distance_from_origin': Array(7550.175, dtype=float32), 'eval/episode_distance_reward': Array(39.38717, dtype=float32), 'eval/episode_forward_reward': Array(6564.493, dtype=float32), 'eval/episode_reward': Array(6576.3564, dtype=float32), 'eval/episode_reward_alive': Array(383.21875, dtype=float32), 'eval/episode_reward_linvel': Array(6564.493, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.74234, dtype=float32), 'eval/episode_x_position': Array(7509.582, dtype=float32), 'eval/episode_x_velocity': Array(1312.8987, dtype=float32), 'eval/episode_y_position': Array(-21.8561, dtype=float32), 'eval/episode_y_velocity': Array(-97.83416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.81326, dtype=float32), 'eval/episode_distance_reward_std': Array(6.008752, dtype=float32), 'eval/episode_forward_reward_std': Array(1001.4542, dtype=float32), 'eval/episode_reward_std': Array(1019.60284, dtype=float32), 'eval/episode_reward_alive_std': Array(44.056946, dtype=float32), 'eval/episode_reward_linvel_std': Array(1001.4542, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.235434, dtype=float32), 'eval/episode_x_position_std': Array(493.8404, dtype=float32), 'eval/episode_x_velocity_std': Array(200.29076, dtype=float32), 'eval/episode_y_position_std': Array(381.00104, dtype=float32), 'eval/episode_y_velocity_std': Array(131.57137, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60929155349731, 'eval/sps': 936.9787262960378, 'num_steps': 61603840}
{'eval/walltime': 102962.27591347694, 'training/sps': 2934.1106925426684, 'training/walltime': 20965.61787033081, 'training/entropy_loss': Array(0.01886778, dtype=float32), 'training/policy_loss': Array(0.00932303, dtype=float32), 'training/total_loss': Array(0.30257428, dtype=float32), 'training/v_loss': Array(0.2743835, dtype=float32), 'eval/episode_distance_from_origin': Array(7506.896, dtype=float32), 'eval/episode_distance_reward': Array(39.0735, dtype=float32), 'eval/episode_forward_reward': Array(6512.2163, dtype=float32), 'eval/episode_reward': Array(6527.07, dtype=float32), 'eval/episode_reward_alive': Array(387.17188, dtype=float32), 'eval/episode_reward_linvel': Array(6512.2163, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.39084, dtype=float32), 'eval/episode_x_position': Array(7467.0815, dtype=float32), 'eval/episode_x_velocity': Array(1302.4431, dtype=float32), 'eval/episode_y_position': Array(-16.163342, dtype=float32), 'eval/episode_y_velocity': Array(-94.87639, dtype=float32), 'eval/episode_distance_from_origin_std': Array(414.5644, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5277896, dtype=float32), 'eval/episode_forward_reward_std': Array(921.29224, dtype=float32), 'eval/episode_reward_std': Array(942.75745, dtype=float32), 'eval/episode_reward_alive_std': Array(43.533813, dtype=float32), 'eval/episode_reward_linvel_std': Array(921.29224, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.3853, dtype=float32), 'eval/episode_x_position_std': Array(415.93875, dtype=float32), 'eval/episode_x_velocity_std': Array(184.25848, dtype=float32), 'eval/episode_y_position_std': Array(363.72522, dtype=float32), 'eval/episode_y_velocity_std': Array(137.64255, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4764120578766, 'eval/sps': 937.8910103946612, 'num_steps': 61685760}
{'eval/walltime': 103099.04269480705, 'training/sps': 2950.376831335212, 'training/walltime': 20993.383815050125, 'training/entropy_loss': Array(0.01935997, dtype=float32), 'training/policy_loss': Array(0.01895875, dtype=float32), 'training/total_loss': Array(0.2620729, dtype=float32), 'training/v_loss': Array(0.22375415, dtype=float32), 'eval/episode_distance_from_origin': Array(7529.676, dtype=float32), 'eval/episode_distance_reward': Array(39.0748, dtype=float32), 'eval/episode_forward_reward': Array(6512.431, dtype=float32), 'eval/episode_reward': Array(6528.293, dtype=float32), 'eval/episode_reward_alive': Array(385.8828, dtype=float32), 'eval/episode_reward_linvel': Array(6512.431, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.09637, dtype=float32), 'eval/episode_x_position': Array(7489.131, dtype=float32), 'eval/episode_x_velocity': Array(1302.4863, dtype=float32), 'eval/episode_y_position': Array(-55.850426, dtype=float32), 'eval/episode_y_velocity': Array(-96.35048, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.14175, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0790334, dtype=float32), 'eval/episode_forward_reward_std': Array(1013.1661, dtype=float32), 'eval/episode_reward_std': Array(1029.4347, dtype=float32), 'eval/episode_reward_alive_std': Array(41.74567, dtype=float32), 'eval/episode_reward_linvel_std': Array(1013.1661, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.819489, dtype=float32), 'eval/episode_x_position_std': Array(427.459, dtype=float32), 'eval/episode_x_velocity_std': Array(202.63313, dtype=float32), 'eval/episode_y_position_std': Array(389.4307, dtype=float32), 'eval/episode_y_velocity_std': Array(139.15195, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.76678133010864, 'eval/sps': 935.8997759189156, 'num_steps': 61767680}
{'eval/walltime': 103235.32693648338, 'training/sps': 2958.7514841661673, 'training/walltime': 21021.071169137955, 'training/entropy_loss': Array(0.02047284, dtype=float32), 'training/policy_loss': Array(0.01064871, dtype=float32), 'training/total_loss': Array(0.2876436, dtype=float32), 'training/v_loss': Array(0.25652206, dtype=float32), 'eval/episode_distance_from_origin': Array(7569.0303, dtype=float32), 'eval/episode_distance_reward': Array(39.5617, dtype=float32), 'eval/episode_forward_reward': Array(6593.581, dtype=float32), 'eval/episode_reward': Array(6602.874, dtype=float32), 'eval/episode_reward_alive': Array(378.01953, dtype=float32), 'eval/episode_reward_linvel': Array(6593.581, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.28873, dtype=float32), 'eval/episode_x_position': Array(7530.76, dtype=float32), 'eval/episode_x_velocity': Array(1318.7163, dtype=float32), 'eval/episode_y_position': Array(-102.72693, dtype=float32), 'eval/episode_y_velocity': Array(-107.78546, dtype=float32), 'eval/episode_distance_from_origin_std': Array(444.87546, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6356907, dtype=float32), 'eval/episode_forward_reward_std': Array(1105.9421, dtype=float32), 'eval/episode_reward_std': Array(1122.9036, dtype=float32), 'eval/episode_reward_alive_std': Array(40.7905, dtype=float32), 'eval/episode_reward_linvel_std': Array(1105.9421, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.764149, dtype=float32), 'eval/episode_x_position_std': Array(446.65945, dtype=float32), 'eval/episode_x_velocity_std': Array(221.18837, dtype=float32), 'eval/episode_y_position_std': Array(350.82394, dtype=float32), 'eval/episode_y_velocity_std': Array(125.508354, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28424167633057, 'eval/sps': 939.2135027906946, 'num_steps': 61849600}
{'eval/walltime': 103372.12333679199, 'training/sps': 2947.307611679727, 'training/walltime': 21048.86602830887, 'training/entropy_loss': Array(0.02061177, dtype=float32), 'training/policy_loss': Array(0.19439244, dtype=float32), 'training/total_loss': Array(0.4511949, dtype=float32), 'training/v_loss': Array(0.2361907, dtype=float32), 'eval/episode_distance_from_origin': Array(7304.7456, dtype=float32), 'eval/episode_distance_reward': Array(35.62224, dtype=float32), 'eval/episode_forward_reward': Array(5937.007, dtype=float32), 'eval/episode_reward': Array(5904.1113, dtype=float32), 'eval/episode_reward_alive': Array(341.875, dtype=float32), 'eval/episode_reward_linvel': Array(5937.007, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.39288, dtype=float32), 'eval/episode_x_position': Array(7248.8516, dtype=float32), 'eval/episode_x_velocity': Array(1187.4014, dtype=float32), 'eval/episode_y_position': Array(-413.60013, dtype=float32), 'eval/episode_y_velocity': Array(-169.46597, dtype=float32), 'eval/episode_distance_from_origin_std': Array(395.31677, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7742944, dtype=float32), 'eval/episode_forward_reward_std': Array(795.7122, dtype=float32), 'eval/episode_reward_std': Array(817.4278, dtype=float32), 'eval/episode_reward_alive_std': Array(42.52651, dtype=float32), 'eval/episode_reward_linvel_std': Array(795.7122, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.399397, dtype=float32), 'eval/episode_x_position_std': Array(400.20627, dtype=float32), 'eval/episode_x_velocity_std': Array(159.14232, dtype=float32), 'eval/episode_y_position_std': Array(402.29242, dtype=float32), 'eval/episode_y_velocity_std': Array(122.963615, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.796400308609, 'eval/sps': 935.6971361178762, 'num_steps': 61931520}
{'eval/walltime': 103508.4124314785, 'training/sps': 2964.523116761134, 'training/walltime': 21076.49947786331, 'training/entropy_loss': Array(0.01391576, dtype=float32), 'training/policy_loss': Array(0.00574064, dtype=float32), 'training/total_loss': Array(0.10185139, dtype=float32), 'training/v_loss': Array(0.08219498, dtype=float32), 'eval/episode_distance_from_origin': Array(7323.9316, dtype=float32), 'eval/episode_distance_reward': Array(35.423874, dtype=float32), 'eval/episode_forward_reward': Array(5903.9463, dtype=float32), 'eval/episode_reward': Array(5865.4404, dtype=float32), 'eval/episode_reward_alive': Array(333.3125, dtype=float32), 'eval/episode_reward_linvel': Array(5903.9463, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.24323, dtype=float32), 'eval/episode_x_position': Array(7265.664, dtype=float32), 'eval/episode_x_velocity': Array(1180.7894, dtype=float32), 'eval/episode_y_position': Array(-482.68167, dtype=float32), 'eval/episode_y_velocity': Array(-187.09045, dtype=float32), 'eval/episode_distance_from_origin_std': Array(382.34415, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1758547, dtype=float32), 'eval/episode_forward_reward_std': Array(862.6364, dtype=float32), 'eval/episode_reward_std': Array(885.36365, dtype=float32), 'eval/episode_reward_alive_std': Array(45.10149, dtype=float32), 'eval/episode_reward_linvel_std': Array(862.6364, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.434875, dtype=float32), 'eval/episode_x_position_std': Array(389.2149, dtype=float32), 'eval/episode_x_velocity_std': Array(172.52733, dtype=float32), 'eval/episode_y_position_std': Array(359.11813, dtype=float32), 'eval/episode_y_velocity_std': Array(91.669975, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28909468650818, 'eval/sps': 939.1800590826821, 'num_steps': 62013440}
{'eval/walltime': 103645.22321867943, 'training/sps': 2958.366712906853, 'training/walltime': 21104.19043302536, 'training/entropy_loss': Array(0.0169484, dtype=float32), 'training/policy_loss': Array(0.00553135, dtype=float32), 'training/total_loss': Array(0.09467781, dtype=float32), 'training/v_loss': Array(0.07219806, dtype=float32), 'eval/episode_distance_from_origin': Array(7248.255, dtype=float32), 'eval/episode_distance_reward': Array(34.737488, dtype=float32), 'eval/episode_forward_reward': Array(5789.548, dtype=float32), 'eval/episode_reward': Array(5751.958, dtype=float32), 'eval/episode_reward_alive': Array(338.72656, dtype=float32), 'eval/episode_reward_linvel': Array(5789.548, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.05432, dtype=float32), 'eval/episode_x_position': Array(7187.9243, dtype=float32), 'eval/episode_x_velocity': Array(1157.9097, dtype=float32), 'eval/episode_y_position': Array(-493.0974, dtype=float32), 'eval/episode_y_velocity': Array(-184.7141, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.4413, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9839153, dtype=float32), 'eval/episode_forward_reward_std': Array(997.3132, dtype=float32), 'eval/episode_reward_std': Array(1030.3179, dtype=float32), 'eval/episode_reward_alive_std': Array(44.41085, dtype=float32), 'eval/episode_reward_linvel_std': Array(997.3132, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.540707, dtype=float32), 'eval/episode_x_position_std': Array(441.04367, dtype=float32), 'eval/episode_x_velocity_std': Array(199.46268, dtype=float32), 'eval/episode_y_position_std': Array(362.43793, dtype=float32), 'eval/episode_y_velocity_std': Array(97.883125, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.81078720092773, 'eval/sps': 935.5987390965909, 'num_steps': 62095360}
{'eval/walltime': 103781.49685192108, 'training/sps': 2959.747248753576, 'training/walltime': 21131.868472099304, 'training/entropy_loss': Array(0.01812815, dtype=float32), 'training/policy_loss': Array(0.00538528, dtype=float32), 'training/total_loss': Array(0.17559223, dtype=float32), 'training/v_loss': Array(0.15207878, dtype=float32), 'eval/episode_distance_from_origin': Array(7232.099, dtype=float32), 'eval/episode_distance_reward': Array(34.68818, dtype=float32), 'eval/episode_forward_reward': Array(5781.33, dtype=float32), 'eval/episode_reward': Array(5745.9844, dtype=float32), 'eval/episode_reward_alive': Array(338.45312, dtype=float32), 'eval/episode_reward_linvel': Array(5781.33, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.48682, dtype=float32), 'eval/episode_x_position': Array(7170.127, dtype=float32), 'eval/episode_x_velocity': Array(1156.2659, dtype=float32), 'eval/episode_y_position': Array(-552.2284, dtype=float32), 'eval/episode_y_velocity': Array(-198.44571, dtype=float32), 'eval/episode_distance_from_origin_std': Array(370.4541, dtype=float32), 'eval/episode_distance_reward_std': Array(4.708497, dtype=float32), 'eval/episode_forward_reward_std': Array(784.7444, dtype=float32), 'eval/episode_reward_std': Array(803.3437, dtype=float32), 'eval/episode_reward_alive_std': Array(43.13788, dtype=float32), 'eval/episode_reward_linvel_std': Array(784.7444, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.137165, dtype=float32), 'eval/episode_x_position_std': Array(375.28705, dtype=float32), 'eval/episode_x_velocity_std': Array(156.94875, dtype=float32), 'eval/episode_y_position_std': Array(301.47742, dtype=float32), 'eval/episode_y_velocity_std': Array(95.05557, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27363324165344, 'eval/sps': 939.2866173386466, 'num_steps': 62177280}
{'eval/walltime': 103918.25526118279, 'training/sps': 2943.0794059748137, 'training/walltime': 21159.703263044357, 'training/entropy_loss': Array(0.01853857, dtype=float32), 'training/policy_loss': Array(0.00510099, dtype=float32), 'training/total_loss': Array(0.22802371, dtype=float32), 'training/v_loss': Array(0.20438415, dtype=float32), 'eval/episode_distance_from_origin': Array(7232.2354, dtype=float32), 'eval/episode_distance_reward': Array(34.164715, dtype=float32), 'eval/episode_forward_reward': Array(5694.0884, dtype=float32), 'eval/episode_reward': Array(5655.157, dtype=float32), 'eval/episode_reward_alive': Array(337.7578, dtype=float32), 'eval/episode_reward_linvel': Array(5694.0884, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.85303, dtype=float32), 'eval/episode_x_position': Array(7170.6465, dtype=float32), 'eval/episode_x_velocity': Array(1138.8176, dtype=float32), 'eval/episode_y_position': Array(-550.3479, dtype=float32), 'eval/episode_y_velocity': Array(-197.37416, dtype=float32), 'eval/episode_distance_from_origin_std': Array(447.5492, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5028176, dtype=float32), 'eval/episode_forward_reward_std': Array(917.12933, dtype=float32), 'eval/episode_reward_std': Array(940.936, dtype=float32), 'eval/episode_reward_alive_std': Array(45.995964, dtype=float32), 'eval/episode_reward_linvel_std': Array(917.12933, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.244312, dtype=float32), 'eval/episode_x_position_std': Array(452.04727, dtype=float32), 'eval/episode_x_velocity_std': Array(183.42601, dtype=float32), 'eval/episode_y_position_std': Array(310.44843, dtype=float32), 'eval/episode_y_velocity_std': Array(91.637184, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7584092617035, 'eval/sps': 935.9570697773821, 'num_steps': 62259200}
{'eval/walltime': 104054.52836108208, 'training/sps': 2948.3178738532856, 'training/walltime': 21187.48859810829, 'training/entropy_loss': Array(0.01928186, dtype=float32), 'training/policy_loss': Array(0.00715519, dtype=float32), 'training/total_loss': Array(0.28205448, dtype=float32), 'training/v_loss': Array(0.25561744, dtype=float32), 'eval/episode_distance_from_origin': Array(7297.917, dtype=float32), 'eval/episode_distance_reward': Array(35.284557, dtype=float32), 'eval/episode_forward_reward': Array(5880.7266, dtype=float32), 'eval/episode_reward': Array(5847.033, dtype=float32), 'eval/episode_reward_alive': Array(339.35547, dtype=float32), 'eval/episode_reward_linvel': Array(5880.7266, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.3336, dtype=float32), 'eval/episode_x_position': Array(7237.915, dtype=float32), 'eval/episode_x_velocity': Array(1176.1454, dtype=float32), 'eval/episode_y_position': Array(-528.277, dtype=float32), 'eval/episode_y_velocity': Array(-198.08038, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.9421, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2793326, dtype=float32), 'eval/episode_forward_reward_std': Array(879.88293, dtype=float32), 'eval/episode_reward_std': Array(898.01495, dtype=float32), 'eval/episode_reward_alive_std': Array(47.4006, dtype=float32), 'eval/episode_reward_linvel_std': Array(879.88293, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.795702, dtype=float32), 'eval/episode_x_position_std': Array(423.99075, dtype=float32), 'eval/episode_x_velocity_std': Array(175.97664, dtype=float32), 'eval/episode_y_position_std': Array(317.63486, dtype=float32), 'eval/episode_y_velocity_std': Array(85.06668, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.273099899292, 'eval/sps': 939.2902934958847, 'num_steps': 62341120}
{'eval/walltime': 104191.29008793831, 'training/sps': 2943.010309967812, 'training/walltime': 21215.32404255867, 'training/entropy_loss': Array(0.02033698, dtype=float32), 'training/policy_loss': Array(0.00267636, dtype=float32), 'training/total_loss': Array(0.25083315, dtype=float32), 'training/v_loss': Array(0.22781982, dtype=float32), 'eval/episode_distance_from_origin': Array(7336.988, dtype=float32), 'eval/episode_distance_reward': Array(35.187164, dtype=float32), 'eval/episode_forward_reward': Array(5864.4946, dtype=float32), 'eval/episode_reward': Array(5831.367, dtype=float32), 'eval/episode_reward_alive': Array(340.72266, dtype=float32), 'eval/episode_reward_linvel': Array(5864.4946, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.03638, dtype=float32), 'eval/episode_x_position': Array(7275.3896, dtype=float32), 'eval/episode_x_velocity': Array(1172.8989, dtype=float32), 'eval/episode_y_position': Array(-551.3132, dtype=float32), 'eval/episode_y_velocity': Array(-194.90001, dtype=float32), 'eval/episode_distance_from_origin_std': Array(347.77435, dtype=float32), 'eval/episode_distance_reward_std': Array(4.794516, dtype=float32), 'eval/episode_forward_reward_std': Array(799.0803, dtype=float32), 'eval/episode_reward_std': Array(813.78186, dtype=float32), 'eval/episode_reward_alive_std': Array(42.174664, dtype=float32), 'eval/episode_reward_linvel_std': Array(799.0803, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.412868, dtype=float32), 'eval/episode_x_position_std': Array(352.27042, dtype=float32), 'eval/episode_x_velocity_std': Array(159.8161, dtype=float32), 'eval/episode_y_position_std': Array(337.26974, dtype=float32), 'eval/episode_y_velocity_std': Array(91.95234, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7617268562317, 'eval/sps': 935.9343651353402, 'num_steps': 62423040}
{'eval/walltime': 104327.60769057274, 'training/sps': 2951.661067903128, 'training/walltime': 21243.07790660858, 'training/entropy_loss': Array(0.01575447, dtype=float32), 'training/policy_loss': Array(0.0085331, dtype=float32), 'training/total_loss': Array(0.13811645, dtype=float32), 'training/v_loss': Array(0.11382888, dtype=float32), 'eval/episode_distance_from_origin': Array(7269.998, dtype=float32), 'eval/episode_distance_reward': Array(34.55297, dtype=float32), 'eval/episode_forward_reward': Array(5758.7974, dtype=float32), 'eval/episode_reward': Array(5719.908, dtype=float32), 'eval/episode_reward_alive': Array(335.6953, dtype=float32), 'eval/episode_reward_linvel': Array(5758.7974, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.13663, dtype=float32), 'eval/episode_x_position': Array(7209.217, dtype=float32), 'eval/episode_x_velocity': Array(1151.7593, dtype=float32), 'eval/episode_y_position': Array(-516.6676, dtype=float32), 'eval/episode_y_velocity': Array(-188.1641, dtype=float32), 'eval/episode_distance_from_origin_std': Array(358.93106, dtype=float32), 'eval/episode_distance_reward_std': Array(4.725214, dtype=float32), 'eval/episode_forward_reward_std': Array(787.53094, dtype=float32), 'eval/episode_reward_std': Array(813.9319, dtype=float32), 'eval/episode_reward_alive_std': Array(48.178593, dtype=float32), 'eval/episode_reward_linvel_std': Array(787.53094, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.515123, dtype=float32), 'eval/episode_x_position_std': Array(368.27277, dtype=float32), 'eval/episode_x_velocity_std': Array(157.50638, dtype=float32), 'eval/episode_y_position_std': Array(355.72958, dtype=float32), 'eval/episode_y_velocity_std': Array(100.6468, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31760263442993, 'eval/sps': 938.9836494063376, 'num_steps': 62504960}
{'eval/walltime': 104464.338504076, 'training/sps': 2938.157116702557, 'training/walltime': 21270.959329128265, 'training/entropy_loss': Array(0.01663813, dtype=float32), 'training/policy_loss': Array(0.00503005, dtype=float32), 'training/total_loss': Array(0.10570718, dtype=float32), 'training/v_loss': Array(0.084039, dtype=float32), 'eval/episode_distance_from_origin': Array(7288.9688, dtype=float32), 'eval/episode_distance_reward': Array(35.29837, dtype=float32), 'eval/episode_forward_reward': Array(5883.0293, dtype=float32), 'eval/episode_reward': Array(5851.1196, dtype=float32), 'eval/episode_reward_alive': Array(346.91406, dtype=float32), 'eval/episode_reward_linvel': Array(5883.0293, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.12213, dtype=float32), 'eval/episode_x_position': Array(7233.291, dtype=float32), 'eval/episode_x_velocity': Array(1176.606, dtype=float32), 'eval/episode_y_position': Array(-433.2015, dtype=float32), 'eval/episode_y_velocity': Array(-170.04126, dtype=float32), 'eval/episode_distance_from_origin_std': Array(420.8948, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6655703, dtype=float32), 'eval/episode_forward_reward_std': Array(944.2565, dtype=float32), 'eval/episode_reward_std': Array(975.20734, dtype=float32), 'eval/episode_reward_alive_std': Array(45.019703, dtype=float32), 'eval/episode_reward_linvel_std': Array(944.2565, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.59334, dtype=float32), 'eval/episode_x_position_std': Array(421.71243, dtype=float32), 'eval/episode_x_velocity_std': Array(188.8513, dtype=float32), 'eval/episode_y_position_std': Array(395.1791, dtype=float32), 'eval/episode_y_velocity_std': Array(113.543655, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.73081350326538, 'eval/sps': 936.1459697374149, 'num_steps': 62586880}
{'eval/walltime': 104600.67492938042, 'training/sps': 2946.228087036665, 'training/walltime': 21298.764372587204, 'training/entropy_loss': Array(0.01770993, dtype=float32), 'training/policy_loss': Array(0.00630776, dtype=float32), 'training/total_loss': Array(0.21803328, dtype=float32), 'training/v_loss': Array(0.19401559, dtype=float32), 'eval/episode_distance_from_origin': Array(7277.8384, dtype=float32), 'eval/episode_distance_reward': Array(35.258217, dtype=float32), 'eval/episode_forward_reward': Array(5876.3374, dtype=float32), 'eval/episode_reward': Array(5849.545, dtype=float32), 'eval/episode_reward_alive': Array(348.28125, dtype=float32), 'eval/episode_reward_linvel': Array(5876.3374, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.33173, dtype=float32), 'eval/episode_x_position': Array(7223.7407, dtype=float32), 'eval/episode_x_velocity': Array(1175.2675, dtype=float32), 'eval/episode_y_position': Array(-469.92395, dtype=float32), 'eval/episode_y_velocity': Array(-190.12575, dtype=float32), 'eval/episode_distance_from_origin_std': Array(389.99646, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2278595, dtype=float32), 'eval/episode_forward_reward_std': Array(871.30414, dtype=float32), 'eval/episode_reward_std': Array(902.12915, dtype=float32), 'eval/episode_reward_alive_std': Array(46.20791, dtype=float32), 'eval/episode_reward_linvel_std': Array(871.30414, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.423576, dtype=float32), 'eval/episode_x_position_std': Array(391.80875, dtype=float32), 'eval/episode_x_velocity_std': Array(174.26091, dtype=float32), 'eval/episode_y_position_std': Array(292.74606, dtype=float32), 'eval/episode_y_velocity_std': Array(71.51601, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33642530441284, 'eval/sps': 938.8540128890777, 'num_steps': 62668800}
{'eval/walltime': 104737.45922327042, 'training/sps': 2935.1265436995322, 'training/walltime': 21326.67458319664, 'training/entropy_loss': Array(0.0191519, dtype=float32), 'training/policy_loss': Array(0.00634109, dtype=float32), 'training/total_loss': Array(0.25978148, dtype=float32), 'training/v_loss': Array(0.23428848, dtype=float32), 'eval/episode_distance_from_origin': Array(7296.4404, dtype=float32), 'eval/episode_distance_reward': Array(35.401604, dtype=float32), 'eval/episode_forward_reward': Array(5900.234, dtype=float32), 'eval/episode_reward': Array(5878.8604, dtype=float32), 'eval/episode_reward_alive': Array(352.28516, dtype=float32), 'eval/episode_reward_linvel': Array(5900.234, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.06024, dtype=float32), 'eval/episode_x_position': Array(7238.629, dtype=float32), 'eval/episode_x_velocity': Array(1180.0469, dtype=float32), 'eval/episode_y_position': Array(-489.9333, dtype=float32), 'eval/episode_y_velocity': Array(-197.4898, dtype=float32), 'eval/episode_distance_from_origin_std': Array(399.42337, dtype=float32), 'eval/episode_distance_reward_std': Array(4.730924, dtype=float32), 'eval/episode_forward_reward_std': Array(788.4821, dtype=float32), 'eval/episode_reward_std': Array(808.9448, dtype=float32), 'eval/episode_reward_alive_std': Array(46.222572, dtype=float32), 'eval/episode_reward_linvel_std': Array(788.4821, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.076385, dtype=float32), 'eval/episode_x_position_std': Array(398.27917, dtype=float32), 'eval/episode_x_velocity_std': Array(157.69647, dtype=float32), 'eval/episode_y_position_std': Array(346.2332, dtype=float32), 'eval/episode_y_velocity_std': Array(91.05258, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7842938899994, 'eval/sps': 935.7799522139316, 'num_steps': 62750720}
{'eval/walltime': 104873.79760146141, 'training/sps': 2946.1867070181847, 'training/walltime': 21354.48001718521, 'training/entropy_loss': Array(0.01875837, dtype=float32), 'training/policy_loss': Array(0.00664882, dtype=float32), 'training/total_loss': Array(0.24866487, dtype=float32), 'training/v_loss': Array(0.22325769, dtype=float32), 'eval/episode_distance_from_origin': Array(7342.8364, dtype=float32), 'eval/episode_distance_reward': Array(35.88157, dtype=float32), 'eval/episode_forward_reward': Array(5980.228, dtype=float32), 'eval/episode_reward': Array(5946.215, dtype=float32), 'eval/episode_reward_alive': Array(345.4297, dtype=float32), 'eval/episode_reward_linvel': Array(5980.228, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.3252, dtype=float32), 'eval/episode_x_position': Array(7287.4165, dtype=float32), 'eval/episode_x_velocity': Array(1196.0457, dtype=float32), 'eval/episode_y_position': Array(-483.53558, dtype=float32), 'eval/episode_y_velocity': Array(-190.07758, dtype=float32), 'eval/episode_distance_from_origin_std': Array(354.7035, dtype=float32), 'eval/episode_distance_reward_std': Array(5.278114, dtype=float32), 'eval/episode_forward_reward_std': Array(879.6797, dtype=float32), 'eval/episode_reward_std': Array(911.7985, dtype=float32), 'eval/episode_reward_alive_std': Array(47.467495, dtype=float32), 'eval/episode_reward_linvel_std': Array(879.6797, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.7417, dtype=float32), 'eval/episode_x_position_std': Array(358.19794, dtype=float32), 'eval/episode_x_velocity_std': Array(175.93594, dtype=float32), 'eval/episode_y_position_std': Array(312.59967, dtype=float32), 'eval/episode_y_velocity_std': Array(78.16216, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33837819099426, 'eval/sps': 938.840564911861, 'num_steps': 62832640}
{'eval/walltime': 105010.42965555191, 'training/sps': 2935.912412008578, 'training/walltime': 21382.38275694847, 'training/entropy_loss': Array(0.01954672, dtype=float32), 'training/policy_loss': Array(0.0050155, dtype=float32), 'training/total_loss': Array(0.24436492, dtype=float32), 'training/v_loss': Array(0.21980268, dtype=float32), 'eval/episode_distance_from_origin': Array(7304.4883, dtype=float32), 'eval/episode_distance_reward': Array(35.754242, dtype=float32), 'eval/episode_forward_reward': Array(5959.008, dtype=float32), 'eval/episode_reward': Array(5933.263, dtype=float32), 'eval/episode_reward_alive': Array(346.57812, dtype=float32), 'eval/episode_reward_linvel': Array(5959.008, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.0771, dtype=float32), 'eval/episode_x_position': Array(7252.0566, dtype=float32), 'eval/episode_x_velocity': Array(1191.8015, dtype=float32), 'eval/episode_y_position': Array(-427.1023, dtype=float32), 'eval/episode_y_velocity': Array(-182.71652, dtype=float32), 'eval/episode_distance_from_origin_std': Array(352.56158, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9804735, dtype=float32), 'eval/episode_forward_reward_std': Array(830.0725, dtype=float32), 'eval/episode_reward_std': Array(849.49634, dtype=float32), 'eval/episode_reward_alive_std': Array(42.232265, dtype=float32), 'eval/episode_reward_linvel_std': Array(830.0725, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.128265, dtype=float32), 'eval/episode_x_position_std': Array(354.07397, dtype=float32), 'eval/episode_x_velocity_std': Array(166.01453, dtype=float32), 'eval/episode_y_position_std': Array(328.32822, dtype=float32), 'eval/episode_y_velocity_std': Array(84.30766, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63205409049988, 'eval/sps': 936.822628131007, 'num_steps': 62914560}
{'eval/walltime': 105146.7669365406, 'training/sps': 2941.33986018993, 'training/walltime': 21410.234009742737, 'training/entropy_loss': Array(0.01721199, dtype=float32), 'training/policy_loss': Array(0.0068799, dtype=float32), 'training/total_loss': Array(0.17616385, dtype=float32), 'training/v_loss': Array(0.15207197, dtype=float32), 'eval/episode_distance_from_origin': Array(7350.421, dtype=float32), 'eval/episode_distance_reward': Array(36.328182, dtype=float32), 'eval/episode_forward_reward': Array(6054.664, dtype=float32), 'eval/episode_reward': Array(6037.605, dtype=float32), 'eval/episode_reward_alive': Array(359.45703, dtype=float32), 'eval/episode_reward_linvel': Array(6054.664, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.84363, dtype=float32), 'eval/episode_x_position': Array(7296.329, dtype=float32), 'eval/episode_x_velocity': Array(1210.9326, dtype=float32), 'eval/episode_y_position': Array(-493.5567, dtype=float32), 'eval/episode_y_velocity': Array(-197.3275, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.85275, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0715604, dtype=float32), 'eval/episode_forward_reward_std': Array(845.25543, dtype=float32), 'eval/episode_reward_std': Array(861.0367, dtype=float32), 'eval/episode_reward_alive_std': Array(43.563084, dtype=float32), 'eval/episode_reward_linvel_std': Array(845.25543, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.084831, dtype=float32), 'eval/episode_x_position_std': Array(453.37576, dtype=float32), 'eval/episode_x_velocity_std': Array(169.0511, dtype=float32), 'eval/episode_y_position_std': Array(256.9011, dtype=float32), 'eval/episode_y_velocity_std': Array(72.96882, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33728098869324, 'eval/sps': 938.8481204243418, 'num_steps': 62996480}
{'eval/walltime': 105283.3966987133, 'training/sps': 2938.784311808279, 'training/walltime': 21438.109481811523, 'training/entropy_loss': Array(0.01502848, dtype=float32), 'training/policy_loss': Array(0.00859723, dtype=float32), 'training/total_loss': Array(0.08038051, dtype=float32), 'training/v_loss': Array(0.05675481, dtype=float32), 'eval/episode_distance_from_origin': Array(7315.3516, dtype=float32), 'eval/episode_distance_reward': Array(35.410072, dtype=float32), 'eval/episode_forward_reward': Array(5901.646, dtype=float32), 'eval/episode_reward': Array(5872.8154, dtype=float32), 'eval/episode_reward_alive': Array(351.6953, dtype=float32), 'eval/episode_reward_linvel': Array(5901.646, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.93634, dtype=float32), 'eval/episode_x_position': Array(7259.663, dtype=float32), 'eval/episode_x_velocity': Array(1180.3293, dtype=float32), 'eval/episode_y_position': Array(-476.5726, dtype=float32), 'eval/episode_y_velocity': Array(-186.81418, dtype=float32), 'eval/episode_distance_from_origin_std': Array(411.55157, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3041873, dtype=float32), 'eval/episode_forward_reward_std': Array(884.02466, dtype=float32), 'eval/episode_reward_std': Array(903.4394, dtype=float32), 'eval/episode_reward_alive_std': Array(46.988956, dtype=float32), 'eval/episode_reward_linvel_std': Array(884.02466, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.33216, dtype=float32), 'eval/episode_x_position_std': Array(414.75235, dtype=float32), 'eval/episode_x_velocity_std': Array(176.80489, dtype=float32), 'eval/episode_y_position_std': Array(334.12903, dtype=float32), 'eval/episode_y_velocity_std': Array(89.50764, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.62976217269897, 'eval/sps': 936.8383430120371, 'num_steps': 63078400}
{'eval/walltime': 105419.73792290688, 'training/sps': 2940.5375449682733, 'training/walltime': 21465.96833372116, 'training/entropy_loss': Array(0.01755274, dtype=float32), 'training/policy_loss': Array(0.00596622, dtype=float32), 'training/total_loss': Array(0.17203495, dtype=float32), 'training/v_loss': Array(0.14851598, dtype=float32), 'eval/episode_distance_from_origin': Array(7261.5293, dtype=float32), 'eval/episode_distance_reward': Array(34.68448, dtype=float32), 'eval/episode_forward_reward': Array(5780.715, dtype=float32), 'eval/episode_reward': Array(5756.045, dtype=float32), 'eval/episode_reward_alive': Array(353.53516, dtype=float32), 'eval/episode_reward_linvel': Array(5780.715, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.88925, dtype=float32), 'eval/episode_x_position': Array(7207.2207, dtype=float32), 'eval/episode_x_velocity': Array(1156.1431, dtype=float32), 'eval/episode_y_position': Array(-460.3768, dtype=float32), 'eval/episode_y_velocity': Array(-179.43565, dtype=float32), 'eval/episode_distance_from_origin_std': Array(398.35706, dtype=float32), 'eval/episode_distance_reward_std': Array(5.004078, dtype=float32), 'eval/episode_forward_reward_std': Array(834.007, dtype=float32), 'eval/episode_reward_std': Array(863.04553, dtype=float32), 'eval/episode_reward_alive_std': Array(47.9283, dtype=float32), 'eval/episode_reward_linvel_std': Array(834.007, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.756947, dtype=float32), 'eval/episode_x_position_std': Array(398.73495, dtype=float32), 'eval/episode_x_velocity_std': Array(166.80145, dtype=float32), 'eval/episode_y_position_std': Array(317.79608, dtype=float32), 'eval/episode_y_velocity_std': Array(90.30003, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.341224193573, 'eval/sps': 938.8209674446638, 'num_steps': 63160320}
{'eval/walltime': 105556.37017226219, 'training/sps': 2927.2738299113503, 'training/walltime': 21493.953416347504, 'training/entropy_loss': Array(0.0197237, dtype=float32), 'training/policy_loss': Array(0.00898996, dtype=float32), 'training/total_loss': Array(0.26294285, dtype=float32), 'training/v_loss': Array(0.23422918, dtype=float32), 'eval/episode_distance_from_origin': Array(7356.1533, dtype=float32), 'eval/episode_distance_reward': Array(36.06838, dtype=float32), 'eval/episode_forward_reward': Array(6011.363, dtype=float32), 'eval/episode_reward': Array(5994.7656, dtype=float32), 'eval/episode_reward_alive': Array(359.98828, dtype=float32), 'eval/episode_reward_linvel': Array(6011.363, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.65442, dtype=float32), 'eval/episode_x_position': Array(7304.7515, dtype=float32), 'eval/episode_x_velocity': Array(1202.2727, dtype=float32), 'eval/episode_y_position': Array(-419.35672, dtype=float32), 'eval/episode_y_velocity': Array(-174.30795, dtype=float32), 'eval/episode_distance_from_origin_std': Array(377.21466, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0233364, dtype=float32), 'eval/episode_forward_reward_std': Array(837.21533, dtype=float32), 'eval/episode_reward_std': Array(854.599, dtype=float32), 'eval/episode_reward_alive_std': Array(45.309845, dtype=float32), 'eval/episode_reward_linvel_std': Array(837.21533, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.868904, dtype=float32), 'eval/episode_x_position_std': Array(380.84982, dtype=float32), 'eval/episode_x_velocity_std': Array(167.44322, dtype=float32), 'eval/episode_y_position_std': Array(331.68906, dtype=float32), 'eval/episode_y_velocity_std': Array(84.51204, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63224935531616, 'eval/sps': 936.8212892926343, 'num_steps': 63242240}
{'eval/walltime': 105692.71083545685, 'training/sps': 2935.153171314492, 'training/walltime': 21521.86337375641, 'training/entropy_loss': Array(0.0200416, dtype=float32), 'training/policy_loss': Array(0.00900913, dtype=float32), 'training/total_loss': Array(0.2701229, dtype=float32), 'training/v_loss': Array(0.24107213, dtype=float32), 'eval/episode_distance_from_origin': Array(7406.444, dtype=float32), 'eval/episode_distance_reward': Array(37.008896, dtype=float32), 'eval/episode_forward_reward': Array(6168.1143, dtype=float32), 'eval/episode_reward': Array(6147.1846, dtype=float32), 'eval/episode_reward_alive': Array(357.02344, dtype=float32), 'eval/episode_reward_linvel': Array(6168.1143, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.9629, dtype=float32), 'eval/episode_x_position': Array(7355.4683, dtype=float32), 'eval/episode_x_velocity': Array(1233.6229, dtype=float32), 'eval/episode_y_position': Array(-395.30017, dtype=float32), 'eval/episode_y_velocity': Array(-170.5208, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.471, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9924517, dtype=float32), 'eval/episode_forward_reward_std': Array(832.06995, dtype=float32), 'eval/episode_reward_std': Array(857.1243, dtype=float32), 'eval/episode_reward_alive_std': Array(48.493874, dtype=float32), 'eval/episode_reward_linvel_std': Array(832.06995, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.770391, dtype=float32), 'eval/episode_x_position_std': Array(424.2825, dtype=float32), 'eval/episode_x_velocity_std': Array(166.41403, dtype=float32), 'eval/episode_y_position_std': Array(367.75412, dtype=float32), 'eval/episode_y_velocity_std': Array(108.00594, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34066319465637, 'eval/sps': 938.8248303974565, 'num_steps': 63324160}
{'eval/walltime': 105829.35890102386, 'training/sps': 2931.5786655963193, 'training/walltime': 21549.80736207962, 'training/entropy_loss': Array(0.02050543, dtype=float32), 'training/policy_loss': Array(0.00563711, dtype=float32), 'training/total_loss': Array(0.2611217, dtype=float32), 'training/v_loss': Array(0.23497914, dtype=float32), 'eval/episode_distance_from_origin': Array(7371.6807, dtype=float32), 'eval/episode_distance_reward': Array(36.531757, dtype=float32), 'eval/episode_forward_reward': Array(6088.5938, dtype=float32), 'eval/episode_reward': Array(6078.3936, dtype=float32), 'eval/episode_reward_alive': Array(363.54688, dtype=float32), 'eval/episode_reward_linvel': Array(6088.5938, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.27808, dtype=float32), 'eval/episode_x_position': Array(7318.6465, dtype=float32), 'eval/episode_x_velocity': Array(1217.7186, dtype=float32), 'eval/episode_y_position': Array(-460.00592, dtype=float32), 'eval/episode_y_velocity': Array(-187.12727, dtype=float32), 'eval/episode_distance_from_origin_std': Array(454.4344, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2250943, dtype=float32), 'eval/episode_forward_reward_std': Array(1037.5088, dtype=float32), 'eval/episode_reward_std': Array(1058.68, dtype=float32), 'eval/episode_reward_alive_std': Array(45.063904, dtype=float32), 'eval/episode_reward_linvel_std': Array(1037.5088, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.395187, dtype=float32), 'eval/episode_x_position_std': Array(458.27615, dtype=float32), 'eval/episode_x_velocity_std': Array(207.50186, dtype=float32), 'eval/episode_y_position_std': Array(298.99872, dtype=float32), 'eval/episode_y_velocity_std': Array(84.6287, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6480655670166, 'eval/sps': 936.7128577259273, 'num_steps': 63406080}
{'eval/walltime': 105965.68210077286, 'training/sps': 2927.246148022287, 'training/walltime': 21577.792709350586, 'training/entropy_loss': Array(0.02140602, dtype=float32), 'training/policy_loss': Array(0.00735219, dtype=float32), 'training/total_loss': Array(0.24233189, dtype=float32), 'training/v_loss': Array(0.21357366, dtype=float32), 'eval/episode_distance_from_origin': Array(7354.4507, dtype=float32), 'eval/episode_distance_reward': Array(36.649025, dtype=float32), 'eval/episode_forward_reward': Array(6108.137, dtype=float32), 'eval/episode_reward': Array(6097.9854, dtype=float32), 'eval/episode_reward_alive': Array(367.36328, dtype=float32), 'eval/episode_reward_linvel': Array(6108.137, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.16455, dtype=float32), 'eval/episode_x_position': Array(7308.0957, dtype=float32), 'eval/episode_x_velocity': Array(1221.6274, dtype=float32), 'eval/episode_y_position': Array(-372.85516, dtype=float32), 'eval/episode_y_velocity': Array(-158.59256, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.1751, dtype=float32), 'eval/episode_distance_reward_std': Array(5.38052, dtype=float32), 'eval/episode_forward_reward_std': Array(896.7483, dtype=float32), 'eval/episode_reward_std': Array(917.27484, dtype=float32), 'eval/episode_reward_alive_std': Array(43.6304, dtype=float32), 'eval/episode_reward_linvel_std': Array(896.7483, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.45927, dtype=float32), 'eval/episode_x_position_std': Array(421.14365, dtype=float32), 'eval/episode_x_velocity_std': Array(179.34962, dtype=float32), 'eval/episode_y_position_std': Array(284.1803, dtype=float32), 'eval/episode_y_velocity_std': Array(98.909454, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32319974899292, 'eval/sps': 938.9450969144053, 'num_steps': 63488000}
{'eval/walltime': 106102.30372166634, 'training/sps': 2936.9237375189728, 'training/walltime': 21605.685840845108, 'training/entropy_loss': Array(0.01337827, dtype=float32), 'training/policy_loss': Array(0.00636048, dtype=float32), 'training/total_loss': Array(0.0528717, dtype=float32), 'training/v_loss': Array(0.03313296, dtype=float32), 'eval/episode_distance_from_origin': Array(7427.1606, dtype=float32), 'eval/episode_distance_reward': Array(37.20586, dtype=float32), 'eval/episode_forward_reward': Array(6200.943, dtype=float32), 'eval/episode_reward': Array(6192.908, dtype=float32), 'eval/episode_reward_alive': Array(367.13672, dtype=float32), 'eval/episode_reward_linvel': Array(6200.943, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.3772, dtype=float32), 'eval/episode_x_position': Array(7377.941, dtype=float32), 'eval/episode_x_velocity': Array(1240.1886, dtype=float32), 'eval/episode_y_position': Array(-408.69925, dtype=float32), 'eval/episode_y_velocity': Array(-179.1485, dtype=float32), 'eval/episode_distance_from_origin_std': Array(399.21786, dtype=float32), 'eval/episode_distance_reward_std': Array(4.564978, dtype=float32), 'eval/episode_forward_reward_std': Array(760.8248, dtype=float32), 'eval/episode_reward_std': Array(774.0711, dtype=float32), 'eval/episode_reward_alive_std': Array(44.68508, dtype=float32), 'eval/episode_reward_linvel_std': Array(760.8248, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.423092, dtype=float32), 'eval/episode_x_position_std': Array(401.68924, dtype=float32), 'eval/episode_x_velocity_std': Array(152.16495, dtype=float32), 'eval/episode_y_position_std': Array(300.84772, dtype=float32), 'eval/episode_y_velocity_std': Array(90.63617, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6216208934784, 'eval/sps': 936.8941691871704, 'num_steps': 63569920}
{'eval/walltime': 106238.60235118866, 'training/sps': 2936.4975658506046, 'training/walltime': 21633.583020448685, 'training/entropy_loss': Array(0.01735784, dtype=float32), 'training/policy_loss': Array(0.00790253, dtype=float32), 'training/total_loss': Array(0.14932865, dtype=float32), 'training/v_loss': Array(0.12406828, dtype=float32), 'eval/episode_distance_from_origin': Array(7393.116, dtype=float32), 'eval/episode_distance_reward': Array(36.395382, dtype=float32), 'eval/episode_forward_reward': Array(6065.8643, dtype=float32), 'eval/episode_reward': Array(6049.2275, dtype=float32), 'eval/episode_reward_alive': Array(362.5703, dtype=float32), 'eval/episode_reward_linvel': Array(6065.8643, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.60202, dtype=float32), 'eval/episode_x_position': Array(7342.1035, dtype=float32), 'eval/episode_x_velocity': Array(1213.1726, dtype=float32), 'eval/episode_y_position': Array(-427.36566, dtype=float32), 'eval/episode_y_velocity': Array(-171.54236, dtype=float32), 'eval/episode_distance_from_origin_std': Array(384.9833, dtype=float32), 'eval/episode_distance_reward_std': Array(5.081007, dtype=float32), 'eval/episode_forward_reward_std': Array(846.8293, dtype=float32), 'eval/episode_reward_std': Array(864.25854, dtype=float32), 'eval/episode_reward_alive_std': Array(45.716335, dtype=float32), 'eval/episode_reward_linvel_std': Array(846.8293, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.04133, dtype=float32), 'eval/episode_x_position_std': Array(384.0133, dtype=float32), 'eval/episode_x_velocity_std': Array(169.36578, dtype=float32), 'eval/episode_y_position_std': Array(302.73648, dtype=float32), 'eval/episode_y_velocity_std': Array(104.94487, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2986295223236, 'eval/sps': 939.1143582924697, 'num_steps': 63651840}
{'eval/walltime': 106375.21778035164, 'training/sps': 2930.7606172409687, 'training/walltime': 21661.53480863571, 'training/entropy_loss': Array(0.01885258, dtype=float32), 'training/policy_loss': Array(0.00819379, dtype=float32), 'training/total_loss': Array(0.28997403, dtype=float32), 'training/v_loss': Array(0.26292768, dtype=float32), 'eval/episode_distance_from_origin': Array(7429.0996, dtype=float32), 'eval/episode_distance_reward': Array(36.646072, dtype=float32), 'eval/episode_forward_reward': Array(6107.6455, dtype=float32), 'eval/episode_reward': Array(6097.922, dtype=float32), 'eval/episode_reward_alive': Array(364.48828, dtype=float32), 'eval/episode_reward_linvel': Array(6107.6455, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.8573, dtype=float32), 'eval/episode_x_position': Array(7377.2944, dtype=float32), 'eval/episode_x_velocity': Array(1221.529, dtype=float32), 'eval/episode_y_position': Array(-438.03375, dtype=float32), 'eval/episode_y_velocity': Array(-179.79663, dtype=float32), 'eval/episode_distance_from_origin_std': Array(386.94067, dtype=float32), 'eval/episode_distance_reward_std': Array(4.941786, dtype=float32), 'eval/episode_forward_reward_std': Array(823.62384, dtype=float32), 'eval/episode_reward_std': Array(837.5358, dtype=float32), 'eval/episode_reward_alive_std': Array(41.734627, dtype=float32), 'eval/episode_reward_linvel_std': Array(823.62384, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.30103, dtype=float32), 'eval/episode_x_position_std': Array(388.70984, dtype=float32), 'eval/episode_x_velocity_std': Array(164.72485, dtype=float32), 'eval/episode_y_position_std': Array(315.31567, dtype=float32), 'eval/episode_y_velocity_std': Array(87.78527, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.61542916297913, 'eval/sps': 936.936631420298, 'num_steps': 63733760}
{'eval/walltime': 106511.51067590714, 'training/sps': 2939.1784623984813, 'training/walltime': 21689.406542539597, 'training/entropy_loss': Array(0.01906247, dtype=float32), 'training/policy_loss': Array(0.0130766, dtype=float32), 'training/total_loss': Array(0.24622723, dtype=float32), 'training/v_loss': Array(0.21408816, dtype=float32), 'eval/episode_distance_from_origin': Array(7410.636, dtype=float32), 'eval/episode_distance_reward': Array(36.946663, dtype=float32), 'eval/episode_forward_reward': Array(6157.743, dtype=float32), 'eval/episode_reward': Array(6148.2803, dtype=float32), 'eval/episode_reward_alive': Array(366.41016, dtype=float32), 'eval/episode_reward_linvel': Array(6157.743, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.82016, dtype=float32), 'eval/episode_x_position': Array(7363.3438, dtype=float32), 'eval/episode_x_velocity': Array(1231.5488, dtype=float32), 'eval/episode_y_position': Array(-361.99432, dtype=float32), 'eval/episode_y_velocity': Array(-156.60117, dtype=float32), 'eval/episode_distance_from_origin_std': Array(381.96823, dtype=float32), 'eval/episode_distance_reward_std': Array(4.975552, dtype=float32), 'eval/episode_forward_reward_std': Array(829.25433, dtype=float32), 'eval/episode_reward_std': Array(853.4643, dtype=float32), 'eval/episode_reward_alive_std': Array(45.15193, dtype=float32), 'eval/episode_reward_linvel_std': Array(829.25433, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.761307, dtype=float32), 'eval/episode_x_position_std': Array(382.81793, dtype=float32), 'eval/episode_x_velocity_std': Array(165.85081, dtype=float32), 'eval/episode_y_position_std': Array(328.17776, dtype=float32), 'eval/episode_y_velocity_std': Array(107.23803, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29289555549622, 'eval/sps': 939.1538676928359, 'num_steps': 63815680}
{'eval/walltime': 106648.11556768417, 'training/sps': 2931.7400787167967, 'training/walltime': 21717.348992347717, 'training/entropy_loss': Array(0.02009612, dtype=float32), 'training/policy_loss': Array(0.01252188, dtype=float32), 'training/total_loss': Array(0.27426472, dtype=float32), 'training/v_loss': Array(0.24164672, dtype=float32), 'eval/episode_distance_from_origin': Array(7460.6104, dtype=float32), 'eval/episode_distance_reward': Array(36.963913, dtype=float32), 'eval/episode_forward_reward': Array(6160.618, dtype=float32), 'eval/episode_reward': Array(6152.731, dtype=float32), 'eval/episode_reward_alive': Array(364.6953, dtype=float32), 'eval/episode_reward_linvel': Array(6160.618, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.5462, dtype=float32), 'eval/episode_x_position': Array(7414.1914, dtype=float32), 'eval/episode_x_velocity': Array(1232.1235, dtype=float32), 'eval/episode_y_position': Array(-381.77557, dtype=float32), 'eval/episode_y_velocity': Array(-166.58371, dtype=float32), 'eval/episode_distance_from_origin_std': Array(374.78436, dtype=float32), 'eval/episode_distance_reward_std': Array(4.4834065, dtype=float32), 'eval/episode_forward_reward_std': Array(747.23035, dtype=float32), 'eval/episode_reward_std': Array(757.2255, dtype=float32), 'eval/episode_reward_alive_std': Array(47.72006, dtype=float32), 'eval/episode_reward_linvel_std': Array(747.23035, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.52586, dtype=float32), 'eval/episode_x_position_std': Array(375.51514, dtype=float32), 'eval/episode_x_velocity_std': Array(149.44598, dtype=float32), 'eval/episode_y_position_std': Array(287.17694, dtype=float32), 'eval/episode_y_velocity_std': Array(90.27319, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.60489177703857, 'eval/sps': 937.0089045487247, 'num_steps': 63897600}
{'eval/walltime': 106784.42041873932, 'training/sps': 2948.425220283408, 'training/walltime': 21745.13331580162, 'training/entropy_loss': Array(0.02111159, dtype=float32), 'training/policy_loss': Array(0.0067557, dtype=float32), 'training/total_loss': Array(0.23652536, dtype=float32), 'training/v_loss': Array(0.20865807, dtype=float32), 'eval/episode_distance_from_origin': Array(7439.3447, dtype=float32), 'eval/episode_distance_reward': Array(37.349445, dtype=float32), 'eval/episode_forward_reward': Array(6224.874, dtype=float32), 'eval/episode_reward': Array(6216.115, dtype=float32), 'eval/episode_reward_alive': Array(362.0703, dtype=float32), 'eval/episode_reward_linvel': Array(6224.874, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.17792, dtype=float32), 'eval/episode_x_position': Array(7391.5156, dtype=float32), 'eval/episode_x_velocity': Array(1244.9746, dtype=float32), 'eval/episode_y_position': Array(-376.11902, dtype=float32), 'eval/episode_y_velocity': Array(-168.09557, dtype=float32), 'eval/episode_distance_from_origin_std': Array(390.12933, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9472923, dtype=float32), 'eval/episode_forward_reward_std': Array(824.5432, dtype=float32), 'eval/episode_reward_std': Array(840.4329, dtype=float32), 'eval/episode_reward_alive_std': Array(46.201782, dtype=float32), 'eval/episode_reward_linvel_std': Array(824.5432, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.635733, dtype=float32), 'eval/episode_x_position_std': Array(392.37234, dtype=float32), 'eval/episode_x_velocity_std': Array(164.9086, dtype=float32), 'eval/episode_y_position_std': Array(312.32803, dtype=float32), 'eval/episode_y_velocity_std': Array(98.46641, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30485105514526, 'eval/sps': 939.0714931210676, 'num_steps': 63979520}
{'eval/walltime': 106921.03783679008, 'training/sps': 2940.9079254460125, 'training/walltime': 21772.988659143448, 'training/entropy_loss': Array(0.0142415, dtype=float32), 'training/policy_loss': Array(0.00532363, dtype=float32), 'training/total_loss': Array(0.09086494, dtype=float32), 'training/v_loss': Array(0.07129982, dtype=float32), 'eval/episode_distance_from_origin': Array(7488.9727, dtype=float32), 'eval/episode_distance_reward': Array(37.6605, dtype=float32), 'eval/episode_forward_reward': Array(6276.716, dtype=float32), 'eval/episode_reward': Array(6263.676, dtype=float32), 'eval/episode_reward_alive': Array(358.83594, dtype=float32), 'eval/episode_reward_linvel': Array(6276.716, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.53632, dtype=float32), 'eval/episode_x_position': Array(7438.813, dtype=float32), 'eval/episode_x_velocity': Array(1255.343, dtype=float32), 'eval/episode_y_position': Array(-425.05695, dtype=float32), 'eval/episode_y_velocity': Array(-171.38255, dtype=float32), 'eval/episode_distance_from_origin_std': Array(391.7523, dtype=float32), 'eval/episode_distance_reward_std': Array(5.366528, dtype=float32), 'eval/episode_forward_reward_std': Array(894.4155, dtype=float32), 'eval/episode_reward_std': Array(918.0318, dtype=float32), 'eval/episode_reward_alive_std': Array(42.791603, dtype=float32), 'eval/episode_reward_linvel_std': Array(894.4155, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.092995, dtype=float32), 'eval/episode_x_position_std': Array(393.70453, dtype=float32), 'eval/episode_x_velocity_std': Array(178.88315, dtype=float32), 'eval/episode_y_position_std': Array(317.87, dtype=float32), 'eval/episode_y_velocity_std': Array(100.59027, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.617418050766, 'eval/sps': 936.9229914185333, 'num_steps': 64061440}
{'eval/walltime': 107057.34827494621, 'training/sps': 2956.7251977938154, 'training/walltime': 21800.694987773895, 'training/entropy_loss': Array(0.01704601, dtype=float32), 'training/policy_loss': Array(0.0088963, dtype=float32), 'training/total_loss': Array(0.08805189, dtype=float32), 'training/v_loss': Array(0.06210957, dtype=float32), 'eval/episode_distance_from_origin': Array(7428.8447, dtype=float32), 'eval/episode_distance_reward': Array(36.94222, dtype=float32), 'eval/episode_forward_reward': Array(6157.003, dtype=float32), 'eval/episode_reward': Array(6144.366, dtype=float32), 'eval/episode_reward_alive': Array(357.89844, dtype=float32), 'eval/episode_reward_linvel': Array(6157.003, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.47766, dtype=float32), 'eval/episode_x_position': Array(7380.676, dtype=float32), 'eval/episode_x_velocity': Array(1231.4006, dtype=float32), 'eval/episode_y_position': Array(-384.15433, dtype=float32), 'eval/episode_y_velocity': Array(-170.20334, dtype=float32), 'eval/episode_distance_from_origin_std': Array(406.61774, dtype=float32), 'eval/episode_distance_reward_std': Array(5.177881, dtype=float32), 'eval/episode_forward_reward_std': Array(862.9743, dtype=float32), 'eval/episode_reward_std': Array(876.5965, dtype=float32), 'eval/episode_reward_alive_std': Array(44.659927, dtype=float32), 'eval/episode_reward_linvel_std': Array(862.9743, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.357101, dtype=float32), 'eval/episode_x_position_std': Array(405.62946, dtype=float32), 'eval/episode_x_velocity_std': Array(172.59492, dtype=float32), 'eval/episode_y_position_std': Array(313.56384, dtype=float32), 'eval/episode_y_velocity_std': Array(94.685974, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31043815612793, 'eval/sps': 939.0330023984717, 'num_steps': 64143360}
{'eval/walltime': 107194.00394845009, 'training/sps': 2934.3162372385414, 'training/walltime': 21828.612905740738, 'training/entropy_loss': Array(0.01841415, dtype=float32), 'training/policy_loss': Array(0.00638417, dtype=float32), 'training/total_loss': Array(0.25360134, dtype=float32), 'training/v_loss': Array(0.22880301, dtype=float32), 'eval/episode_distance_from_origin': Array(7439.495, dtype=float32), 'eval/episode_distance_reward': Array(36.871002, dtype=float32), 'eval/episode_forward_reward': Array(6145.1333, dtype=float32), 'eval/episode_reward': Array(6140.63, dtype=float32), 'eval/episode_reward_alive': Array(365.63672, dtype=float32), 'eval/episode_reward_linvel': Array(6145.1333, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.01154, dtype=float32), 'eval/episode_x_position': Array(7389.8926, dtype=float32), 'eval/episode_x_velocity': Array(1229.0266, dtype=float32), 'eval/episode_y_position': Array(-395.61682, dtype=float32), 'eval/episode_y_velocity': Array(-175.01181, dtype=float32), 'eval/episode_distance_from_origin_std': Array(387.42767, dtype=float32), 'eval/episode_distance_reward_std': Array(4.7724857, dtype=float32), 'eval/episode_forward_reward_std': Array(795.4097, dtype=float32), 'eval/episode_reward_std': Array(811.6538, dtype=float32), 'eval/episode_reward_alive_std': Array(41.73216, dtype=float32), 'eval/episode_reward_linvel_std': Array(795.4097, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.512928, dtype=float32), 'eval/episode_x_position_std': Array(388.50293, dtype=float32), 'eval/episode_x_velocity_std': Array(159.08195, dtype=float32), 'eval/episode_y_position_std': Array(321.041, dtype=float32), 'eval/episode_y_velocity_std': Array(97.46877, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65567350387573, 'eval/sps': 936.6607087584238, 'num_steps': 64225280}
{'eval/walltime': 107330.31766653061, 'training/sps': 2946.5517400974077, 'training/walltime': 21856.41489505768, 'training/entropy_loss': Array(0.01957485, dtype=float32), 'training/policy_loss': Array(0.06650339, dtype=float32), 'training/total_loss': Array(0.3487622, dtype=float32), 'training/v_loss': Array(0.26268396, dtype=float32), 'eval/episode_distance_from_origin': Array(7369.1133, dtype=float32), 'eval/episode_distance_reward': Array(35.372364, dtype=float32), 'eval/episode_forward_reward': Array(5895.3623, dtype=float32), 'eval/episode_reward': Array(5846.05, dtype=float32), 'eval/episode_reward_alive': Array(338.26172, dtype=float32), 'eval/episode_reward_linvel': Array(5895.3623, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.9477, dtype=float32), 'eval/episode_x_position': Array(7323.419, dtype=float32), 'eval/episode_x_velocity': Array(1179.0725, dtype=float32), 'eval/episode_y_position': Array(-403.0944, dtype=float32), 'eval/episode_y_velocity': Array(-163.1921, dtype=float32), 'eval/episode_distance_from_origin_std': Array(492.35327, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4622493, dtype=float32), 'eval/episode_forward_reward_std': Array(1077.0331, dtype=float32), 'eval/episode_reward_std': Array(1135.7203, dtype=float32), 'eval/episode_reward_alive_std': Array(55.193832, dtype=float32), 'eval/episode_reward_linvel_std': Array(1077.0331, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.44113, dtype=float32), 'eval/episode_x_position_std': Array(490.2343, dtype=float32), 'eval/episode_x_velocity_std': Array(215.40652, dtype=float32), 'eval/episode_y_position_std': Array(280.45325, dtype=float32), 'eval/episode_y_velocity_std': Array(98.71928, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31371808052063, 'eval/sps': 939.0104077741486, 'num_steps': 64307200}
{'eval/walltime': 107466.96370100975, 'training/sps': 2926.031080017621, 'training/walltime': 21884.411863565445, 'training/entropy_loss': Array(0.0212178, dtype=float32), 'training/policy_loss': Array(0.09151388, dtype=float32), 'training/total_loss': Array(0.34621775, dtype=float32), 'training/v_loss': Array(0.23348609, dtype=float32), 'eval/episode_distance_from_origin': Array(7360.5293, dtype=float32), 'eval/episode_distance_reward': Array(35.01725, dtype=float32), 'eval/episode_forward_reward': Array(5836.1777, dtype=float32), 'eval/episode_reward': Array(5766.7695, dtype=float32), 'eval/episode_reward_alive': Array(331.64062, dtype=float32), 'eval/episode_reward_linvel': Array(5836.1777, dtype=float32), 'eval/episode_reward_quadctrl': Array(-436.06625, dtype=float32), 'eval/episode_x_position': Array(7319.1587, dtype=float32), 'eval/episode_x_velocity': Array(1167.2354, dtype=float32), 'eval/episode_y_position': Array(-311.55185, dtype=float32), 'eval/episode_y_velocity': Array(-128.74109, dtype=float32), 'eval/episode_distance_from_origin_std': Array(536.9167, dtype=float32), 'eval/episode_distance_reward_std': Array(6.20115, dtype=float32), 'eval/episode_forward_reward_std': Array(1033.5167, dtype=float32), 'eval/episode_reward_std': Array(1101.9696, dtype=float32), 'eval/episode_reward_alive_std': Array(59.501736, dtype=float32), 'eval/episode_reward_linvel_std': Array(1033.5167, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.714893, dtype=float32), 'eval/episode_x_position_std': Array(532.86194, dtype=float32), 'eval/episode_x_velocity_std': Array(206.70334, dtype=float32), 'eval/episode_y_position_std': Array(322.7651, dtype=float32), 'eval/episode_y_velocity_std': Array(108.788284, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64603447914124, 'eval/sps': 936.7267808970993, 'num_steps': 64389120}
{'eval/walltime': 107603.27751231194, 'training/sps': 2948.9139059660233, 'training/walltime': 21912.19158267975, 'training/entropy_loss': Array(0.02263943, dtype=float32), 'training/policy_loss': Array(0.00558152, dtype=float32), 'training/total_loss': Array(0.2265242, dtype=float32), 'training/v_loss': Array(0.19830325, dtype=float32), 'eval/episode_distance_from_origin': Array(7381.171, dtype=float32), 'eval/episode_distance_reward': Array(35.64334, dtype=float32), 'eval/episode_forward_reward': Array(5940.5244, dtype=float32), 'eval/episode_reward': Array(5887.908, dtype=float32), 'eval/episode_reward_alive': Array(335.16406, dtype=float32), 'eval/episode_reward_linvel': Array(5940.5244, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.42303, dtype=float32), 'eval/episode_x_position': Array(7337.131, dtype=float32), 'eval/episode_x_velocity': Array(1188.1049, dtype=float32), 'eval/episode_y_position': Array(-380.5985, dtype=float32), 'eval/episode_y_velocity': Array(-154.518, dtype=float32), 'eval/episode_distance_from_origin_std': Array(504.83902, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3393908, dtype=float32), 'eval/episode_forward_reward_std': Array(1056.5569, dtype=float32), 'eval/episode_reward_std': Array(1102.3091, dtype=float32), 'eval/episode_reward_alive_std': Array(53.92867, dtype=float32), 'eval/episode_reward_linvel_std': Array(1056.5569, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.829014, dtype=float32), 'eval/episode_x_position_std': Array(501.55148, dtype=float32), 'eval/episode_x_velocity_std': Array(211.31148, dtype=float32), 'eval/episode_y_position_std': Array(283.9102, dtype=float32), 'eval/episode_y_velocity_std': Array(97.48444, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31381130218506, 'eval/sps': 939.0097656080152, 'num_steps': 64471040}
{'eval/walltime': 107739.94090795517, 'training/sps': 2927.1121850525556, 'training/walltime': 21940.17821073532, 'training/entropy_loss': Array(0.01746089, dtype=float32), 'training/policy_loss': Array(0.03973217, dtype=float32), 'training/total_loss': Array(0.16788131, dtype=float32), 'training/v_loss': Array(0.11068824, dtype=float32), 'eval/episode_distance_from_origin': Array(7416.9307, dtype=float32), 'eval/episode_distance_reward': Array(36.033215, dtype=float32), 'eval/episode_forward_reward': Array(6005.5044, dtype=float32), 'eval/episode_reward': Array(5957.3584, dtype=float32), 'eval/episode_reward_alive': Array(339.8086, dtype=float32), 'eval/episode_reward_linvel': Array(6005.5044, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.9873, dtype=float32), 'eval/episode_x_position': Array(7374.1016, dtype=float32), 'eval/episode_x_velocity': Array(1201.1008, dtype=float32), 'eval/episode_y_position': Array(-339.63895, dtype=float32), 'eval/episode_y_velocity': Array(-143.02191, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.67343, dtype=float32), 'eval/episode_distance_reward_std': Array(5.992721, dtype=float32), 'eval/episode_forward_reward_std': Array(998.7794, dtype=float32), 'eval/episode_reward_std': Array(1045.4415, dtype=float32), 'eval/episode_reward_alive_std': Array(52.94363, dtype=float32), 'eval/episode_reward_linvel_std': Array(998.7794, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.50055, dtype=float32), 'eval/episode_x_position_std': Array(487.3144, dtype=float32), 'eval/episode_x_velocity_std': Array(199.75612, dtype=float32), 'eval/episode_y_position_std': Array(320.9501, dtype=float32), 'eval/episode_y_velocity_std': Array(107.278824, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66339564323425, 'eval/sps': 936.6077829219872, 'num_steps': 64552960}
{'eval/walltime': 107876.25064015388, 'training/sps': 2954.1288110217633, 'training/walltime': 21967.908890485764, 'training/entropy_loss': Array(0.01605044, dtype=float32), 'training/policy_loss': Array(0.00544334, dtype=float32), 'training/total_loss': Array(0.095227, dtype=float32), 'training/v_loss': Array(0.07373321, dtype=float32), 'eval/episode_distance_from_origin': Array(7488.8887, dtype=float32), 'eval/episode_distance_reward': Array(36.900585, dtype=float32), 'eval/episode_forward_reward': Array(6150.0645, dtype=float32), 'eval/episode_reward': Array(6100.374, dtype=float32), 'eval/episode_reward_alive': Array(337.61328, dtype=float32), 'eval/episode_reward_linvel': Array(6150.0645, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.20404, dtype=float32), 'eval/episode_x_position': Array(7449.69, dtype=float32), 'eval/episode_x_velocity': Array(1230.0127, dtype=float32), 'eval/episode_y_position': Array(-281.62076, dtype=float32), 'eval/episode_y_velocity': Array(-133.07346, dtype=float32), 'eval/episode_distance_from_origin_std': Array(497.44104, dtype=float32), 'eval/episode_distance_reward_std': Array(6.624219, dtype=float32), 'eval/episode_forward_reward_std': Array(1104.0309, dtype=float32), 'eval/episode_reward_std': Array(1150.5736, dtype=float32), 'eval/episode_reward_alive_std': Array(52.29141, dtype=float32), 'eval/episode_reward_linvel_std': Array(1104.0309, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.18742, dtype=float32), 'eval/episode_x_position_std': Array(496.97833, dtype=float32), 'eval/episode_x_velocity_std': Array(220.80615, dtype=float32), 'eval/episode_y_position_std': Array(311.8781, dtype=float32), 'eval/episode_y_velocity_std': Array(100.39321, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3097321987152, 'eval/sps': 939.037865714525, 'num_steps': 64634880}
{'eval/walltime': 108012.90876364708, 'training/sps': 2937.2975019291334, 'training/walltime': 21995.7984726429, 'training/entropy_loss': Array(0.019106, dtype=float32), 'training/policy_loss': Array(0.00546278, dtype=float32), 'training/total_loss': Array(0.29256928, dtype=float32), 'training/v_loss': Array(0.26800048, dtype=float32), 'eval/episode_distance_from_origin': Array(7449.549, dtype=float32), 'eval/episode_distance_reward': Array(36.406998, dtype=float32), 'eval/episode_forward_reward': Array(6067.801, dtype=float32), 'eval/episode_reward': Array(6026.876, dtype=float32), 'eval/episode_reward_alive': Array(342.76953, dtype=float32), 'eval/episode_reward_linvel': Array(6067.801, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.1026, dtype=float32), 'eval/episode_x_position': Array(7410.45, dtype=float32), 'eval/episode_x_velocity': Array(1213.5602, dtype=float32), 'eval/episode_y_position': Array(-271.60333, dtype=float32), 'eval/episode_y_velocity': Array(-123.762924, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.22116, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6257415, dtype=float32), 'eval/episode_forward_reward_std': Array(1104.2831, dtype=float32), 'eval/episode_reward_std': Array(1140.6885, dtype=float32), 'eval/episode_reward_alive_std': Array(50.192284, dtype=float32), 'eval/episode_reward_linvel_std': Array(1104.2831, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.97729, dtype=float32), 'eval/episode_x_position_std': Array(485.4749, dtype=float32), 'eval/episode_x_velocity_std': Array(220.85669, dtype=float32), 'eval/episode_y_position_std': Array(315.76694, dtype=float32), 'eval/episode_y_velocity_std': Array(108.57122, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65812349319458, 'eval/sps': 936.6439164253142, 'num_steps': 64716800}
{'eval/walltime': 108149.20898771286, 'training/sps': 2951.325492201909, 'training/walltime': 22023.555492401123, 'training/entropy_loss': Array(0.01965827, dtype=float32), 'training/policy_loss': Array(0.0037467, dtype=float32), 'training/total_loss': Array(0.20576358, dtype=float32), 'training/v_loss': Array(0.18235862, dtype=float32), 'eval/episode_distance_from_origin': Array(7458.033, dtype=float32), 'eval/episode_distance_reward': Array(36.18724, dtype=float32), 'eval/episode_forward_reward': Array(6031.174, dtype=float32), 'eval/episode_reward': Array(5972.6797, dtype=float32), 'eval/episode_reward_alive': Array(331.30078, dtype=float32), 'eval/episode_reward_linvel': Array(6031.174, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.982, dtype=float32), 'eval/episode_x_position': Array(7418.543, dtype=float32), 'eval/episode_x_velocity': Array(1206.2347, dtype=float32), 'eval/episode_y_position': Array(-279.21017, dtype=float32), 'eval/episode_y_velocity': Array(-128.93668, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.81604, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8299246, dtype=float32), 'eval/episode_forward_reward_std': Array(971.64703, dtype=float32), 'eval/episode_reward_std': Array(1024.2578, dtype=float32), 'eval/episode_reward_alive_std': Array(55.209488, dtype=float32), 'eval/episode_reward_linvel_std': Array(971.64703, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.597923, dtype=float32), 'eval/episode_x_position_std': Array(483.85962, dtype=float32), 'eval/episode_x_velocity_std': Array(194.32932, dtype=float32), 'eval/episode_y_position_std': Array(316.3675, dtype=float32), 'eval/episode_y_velocity_std': Array(106.45255, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30022406578064, 'eval/sps': 939.1033718200285, 'num_steps': 64798720}
{'eval/walltime': 108285.86070752144, 'training/sps': 2938.367852334774, 'training/walltime': 22051.434915304184, 'training/entropy_loss': Array(0.02044763, dtype=float32), 'training/policy_loss': Array(0.00440743, dtype=float32), 'training/total_loss': Array(0.2193785, dtype=float32), 'training/v_loss': Array(0.19452345, dtype=float32), 'eval/episode_distance_from_origin': Array(7392.9766, dtype=float32), 'eval/episode_distance_reward': Array(35.001297, dtype=float32), 'eval/episode_forward_reward': Array(5833.5195, dtype=float32), 'eval/episode_reward': Array(5772.244, dtype=float32), 'eval/episode_reward_alive': Array(331.4414, dtype=float32), 'eval/episode_reward_linvel': Array(5833.5195, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.71805, dtype=float32), 'eval/episode_x_position': Array(7355.3267, dtype=float32), 'eval/episode_x_velocity': Array(1166.7039, dtype=float32), 'eval/episode_y_position': Array(-248.62042, dtype=float32), 'eval/episode_y_velocity': Array(-115.360214, dtype=float32), 'eval/episode_distance_from_origin_std': Array(564.1068, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6103544, dtype=float32), 'eval/episode_forward_reward_std': Array(1101.7177, dtype=float32), 'eval/episode_reward_std': Array(1150.5231, dtype=float32), 'eval/episode_reward_alive_std': Array(60.91838, dtype=float32), 'eval/episode_reward_linvel_std': Array(1101.7177, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.32395, dtype=float32), 'eval/episode_x_position_std': Array(562.28217, dtype=float32), 'eval/episode_x_velocity_std': Array(220.34358, dtype=float32), 'eval/episode_y_position_std': Array(313.49036, dtype=float32), 'eval/episode_y_velocity_std': Array(107.22296, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6517198085785, 'eval/sps': 936.6878088274498, 'num_steps': 64880640}
{'eval/walltime': 108422.17016458511, 'training/sps': 2948.862403127287, 'training/walltime': 22079.215119600296, 'training/entropy_loss': Array(0.02151978, dtype=float32), 'training/policy_loss': Array(0.00627103, dtype=float32), 'training/total_loss': Array(0.22201273, dtype=float32), 'training/v_loss': Array(0.19422194, dtype=float32), 'eval/episode_distance_from_origin': Array(7480.684, dtype=float32), 'eval/episode_distance_reward': Array(36.238434, dtype=float32), 'eval/episode_forward_reward': Array(6039.708, dtype=float32), 'eval/episode_reward': Array(5992.6743, dtype=float32), 'eval/episode_reward_alive': Array(339.875, dtype=float32), 'eval/episode_reward_linvel': Array(6039.708, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.14722, dtype=float32), 'eval/episode_x_position': Array(7440.064, dtype=float32), 'eval/episode_x_velocity': Array(1207.9415, dtype=float32), 'eval/episode_y_position': Array(-262.49463, dtype=float32), 'eval/episode_y_velocity': Array(-121.659775, dtype=float32), 'eval/episode_distance_from_origin_std': Array(477.08655, dtype=float32), 'eval/episode_distance_reward_std': Array(5.928503, dtype=float32), 'eval/episode_forward_reward_std': Array(988.07605, dtype=float32), 'eval/episode_reward_std': Array(1027.2817, dtype=float32), 'eval/episode_reward_alive_std': Array(55.487293, dtype=float32), 'eval/episode_reward_linvel_std': Array(988.07605, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.536137, dtype=float32), 'eval/episode_x_position_std': Array(474.34296, dtype=float32), 'eval/episode_x_velocity_std': Array(197.61522, dtype=float32), 'eval/episode_y_position_std': Array(345.6627, dtype=float32), 'eval/episode_y_velocity_std': Array(126.508934, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30945706367493, 'eval/sps': 939.0397611238867, 'num_steps': 64962560}
{'eval/walltime': 108558.8293607235, 'training/sps': 2927.0858527462537, 'training/walltime': 22107.201999425888, 'training/entropy_loss': Array(0.01913083, dtype=float32), 'training/policy_loss': Array(0.00335858, dtype=float32), 'training/total_loss': Array(0.16222274, dtype=float32), 'training/v_loss': Array(0.13973333, dtype=float32), 'eval/episode_distance_from_origin': Array(7521.2295, dtype=float32), 'eval/episode_distance_reward': Array(37.13208, dtype=float32), 'eval/episode_forward_reward': Array(6188.6475, dtype=float32), 'eval/episode_reward': Array(6143.6045, dtype=float32), 'eval/episode_reward_alive': Array(342.875, dtype=float32), 'eval/episode_reward_linvel': Array(6188.6475, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.05023, dtype=float32), 'eval/episode_x_position': Array(7484.5537, dtype=float32), 'eval/episode_x_velocity': Array(1237.7294, dtype=float32), 'eval/episode_y_position': Array(-251.1409, dtype=float32), 'eval/episode_y_velocity': Array(-125.092224, dtype=float32), 'eval/episode_distance_from_origin_std': Array(532.82825, dtype=float32), 'eval/episode_distance_reward_std': Array(7.074254, dtype=float32), 'eval/episode_forward_reward_std': Array(1179.0339, dtype=float32), 'eval/episode_reward_std': Array(1236.7097, dtype=float32), 'eval/episode_reward_alive_std': Array(60.1972, dtype=float32), 'eval/episode_reward_linvel_std': Array(1179.0339, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.40989, dtype=float32), 'eval/episode_x_position_std': Array(531.5831, dtype=float32), 'eval/episode_x_velocity_std': Array(235.8069, dtype=float32), 'eval/episode_y_position_std': Array(279.55133, dtype=float32), 'eval/episode_y_velocity_std': Array(103.192604, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65919613838196, 'eval/sps': 936.6365646581618, 'num_steps': 65044480}
{'eval/walltime': 108695.07132554054, 'training/sps': 2943.51951855716, 'training/walltime': 22135.032628536224, 'training/entropy_loss': Array(0.01465687, dtype=float32), 'training/policy_loss': Array(0.00375951, dtype=float32), 'training/total_loss': Array(0.06057736, dtype=float32), 'training/v_loss': Array(0.04216099, dtype=float32), 'eval/episode_distance_from_origin': Array(7462.7217, dtype=float32), 'eval/episode_distance_reward': Array(36.481102, dtype=float32), 'eval/episode_forward_reward': Array(6080.1514, dtype=float32), 'eval/episode_reward': Array(6029.815, dtype=float32), 'eval/episode_reward_alive': Array(335.9453, dtype=float32), 'eval/episode_reward_linvel': Array(6080.1514, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.76248, dtype=float32), 'eval/episode_x_position': Array(7426.341, dtype=float32), 'eval/episode_x_velocity': Array(1216.0302, dtype=float32), 'eval/episode_y_position': Array(-249.19507, dtype=float32), 'eval/episode_y_velocity': Array(-107.119736, dtype=float32), 'eval/episode_distance_from_origin_std': Array(442.8006, dtype=float32), 'eval/episode_distance_reward_std': Array(6.032902, dtype=float32), 'eval/episode_forward_reward_std': Array(1005.47675, dtype=float32), 'eval/episode_reward_std': Array(1057.5272, dtype=float32), 'eval/episode_reward_alive_std': Array(55.513554, dtype=float32), 'eval/episode_reward_linvel_std': Array(1005.47675, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.924892, dtype=float32), 'eval/episode_x_position_std': Array(441.1007, dtype=float32), 'eval/episode_x_velocity_std': Array(201.09532, dtype=float32), 'eval/episode_y_position_std': Array(289.16144, dtype=float32), 'eval/episode_y_velocity_std': Array(111.78607, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24196481704712, 'eval/sps': 939.504947479913, 'num_steps': 65126400}
{'eval/walltime': 108831.71989059448, 'training/sps': 2924.7397170803506, 'training/walltime': 22163.04195857048, 'training/entropy_loss': Array(0.01727683, dtype=float32), 'training/policy_loss': Array(0.0059512, dtype=float32), 'training/total_loss': Array(0.20021944, dtype=float32), 'training/v_loss': Array(0.1769914, dtype=float32), 'eval/episode_distance_from_origin': Array(7528.0947, dtype=float32), 'eval/episode_distance_reward': Array(37.456367, dtype=float32), 'eval/episode_forward_reward': Array(6242.697, dtype=float32), 'eval/episode_reward': Array(6202.994, dtype=float32), 'eval/episode_reward_alive': Array(344.1328, dtype=float32), 'eval/episode_reward_linvel': Array(6242.697, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.2907, dtype=float32), 'eval/episode_x_position': Array(7492.2954, dtype=float32), 'eval/episode_x_velocity': Array(1248.5393, dtype=float32), 'eval/episode_y_position': Array(-204.9302, dtype=float32), 'eval/episode_y_velocity': Array(-109.90044, dtype=float32), 'eval/episode_distance_from_origin_std': Array(532.0177, dtype=float32), 'eval/episode_distance_reward_std': Array(6.9576464, dtype=float32), 'eval/episode_forward_reward_std': Array(1159.6007, dtype=float32), 'eval/episode_reward_std': Array(1206.6189, dtype=float32), 'eval/episode_reward_alive_std': Array(52.8629, dtype=float32), 'eval/episode_reward_linvel_std': Array(1159.6007, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.668224, dtype=float32), 'eval/episode_x_position_std': Array(531.44916, dtype=float32), 'eval/episode_x_velocity_std': Array(231.92006, dtype=float32), 'eval/episode_y_position_std': Array(301.66168, dtype=float32), 'eval/episode_y_velocity_std': Array(108.159706, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.64856505393982, 'eval/sps': 936.7094337907907, 'num_steps': 65208320}
{'eval/walltime': 108968.05280160904, 'training/sps': 2937.756885155078, 'training/walltime': 22190.927179574966, 'training/entropy_loss': Array(0.01938418, dtype=float32), 'training/policy_loss': Array(0.00648279, dtype=float32), 'training/total_loss': Array(0.29562807, dtype=float32), 'training/v_loss': Array(0.2697611, dtype=float32), 'eval/episode_distance_from_origin': Array(7524.5317, dtype=float32), 'eval/episode_distance_reward': Array(37.287304, dtype=float32), 'eval/episode_forward_reward': Array(6214.5176, dtype=float32), 'eval/episode_reward': Array(6163.772, dtype=float32), 'eval/episode_reward_alive': Array(337.33594, dtype=float32), 'eval/episode_reward_linvel': Array(6214.5176, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.3686, dtype=float32), 'eval/episode_x_position': Array(7485.7983, dtype=float32), 'eval/episode_x_velocity': Array(1242.9034, dtype=float32), 'eval/episode_y_position': Array(-267.96753, dtype=float32), 'eval/episode_y_velocity': Array(-136.46008, dtype=float32), 'eval/episode_distance_from_origin_std': Array(484.9596, dtype=float32), 'eval/episode_distance_reward_std': Array(6.374995, dtype=float32), 'eval/episode_forward_reward_std': Array(1062.4922, dtype=float32), 'eval/episode_reward_std': Array(1120.8684, dtype=float32), 'eval/episode_reward_alive_std': Array(58.400093, dtype=float32), 'eval/episode_reward_linvel_std': Array(1062.4922, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.178833, dtype=float32), 'eval/episode_x_position_std': Array(483.12833, dtype=float32), 'eval/episode_x_velocity_std': Array(212.49837, dtype=float32), 'eval/episode_y_position_std': Array(299.24948, dtype=float32), 'eval/episode_y_velocity_std': Array(108.54746, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33291101455688, 'eval/sps': 938.878213979696, 'num_steps': 65290240}
{'eval/walltime': 109104.71824526787, 'training/sps': 2933.068553419208, 'training/walltime': 22218.856973409653, 'training/entropy_loss': Array(0.01972356, dtype=float32), 'training/policy_loss': Array(0.00323599, dtype=float32), 'training/total_loss': Array(0.24652, dtype=float32), 'training/v_loss': Array(0.22356045, dtype=float32), 'eval/episode_distance_from_origin': Array(7534.7783, dtype=float32), 'eval/episode_distance_reward': Array(36.996468, dtype=float32), 'eval/episode_forward_reward': Array(6166.044, dtype=float32), 'eval/episode_reward': Array(6113.5938, dtype=float32), 'eval/episode_reward_alive': Array(337.32812, dtype=float32), 'eval/episode_reward_linvel': Array(6166.044, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.77548, dtype=float32), 'eval/episode_x_position': Array(7496.9927, dtype=float32), 'eval/episode_x_velocity': Array(1233.2087, dtype=float32), 'eval/episode_y_position': Array(-243.96658, dtype=float32), 'eval/episode_y_velocity': Array(-127.18158, dtype=float32), 'eval/episode_distance_from_origin_std': Array(444.93036, dtype=float32), 'eval/episode_distance_reward_std': Array(6.272707, dtype=float32), 'eval/episode_forward_reward_std': Array(1045.4452, dtype=float32), 'eval/episode_reward_std': Array(1097.5201, dtype=float32), 'eval/episode_reward_alive_std': Array(57.552876, dtype=float32), 'eval/episode_reward_linvel_std': Array(1045.4452, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.01162, dtype=float32), 'eval/episode_x_position_std': Array(443.4658, dtype=float32), 'eval/episode_x_velocity_std': Array(209.08885, dtype=float32), 'eval/episode_y_position_std': Array(315.8595, dtype=float32), 'eval/episode_y_velocity_std': Array(103.029236, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66544365882874, 'eval/sps': 936.5937472792235, 'num_steps': 65372160}
{'eval/walltime': 109241.26295495033, 'training/sps': 2935.4486398812114, 'training/walltime': 22246.76412153244, 'training/entropy_loss': Array(0.02008757, dtype=float32), 'training/policy_loss': Array(0.00425405, dtype=float32), 'training/total_loss': Array(0.24776508, dtype=float32), 'training/v_loss': Array(0.22342345, dtype=float32), 'eval/episode_distance_from_origin': Array(7489.2085, dtype=float32), 'eval/episode_distance_reward': Array(37.14987, dtype=float32), 'eval/episode_forward_reward': Array(6191.611, dtype=float32), 'eval/episode_reward': Array(6154.3994, dtype=float32), 'eval/episode_reward_alive': Array(342.39062, dtype=float32), 'eval/episode_reward_linvel': Array(6191.611, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.75208, dtype=float32), 'eval/episode_x_position': Array(7450.882, dtype=float32), 'eval/episode_x_velocity': Array(1238.3221, dtype=float32), 'eval/episode_y_position': Array(-243.62686, dtype=float32), 'eval/episode_y_velocity': Array(-127.57306, dtype=float32), 'eval/episode_distance_from_origin_std': Array(432.39307, dtype=float32), 'eval/episode_distance_reward_std': Array(5.042081, dtype=float32), 'eval/episode_forward_reward_std': Array(840.34216, dtype=float32), 'eval/episode_reward_std': Array(860.1517, dtype=float32), 'eval/episode_reward_alive_std': Array(46.75296, dtype=float32), 'eval/episode_reward_linvel_std': Array(840.34216, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.848726, dtype=float32), 'eval/episode_x_position_std': Array(431.17172, dtype=float32), 'eval/episode_x_velocity_std': Array(168.06848, dtype=float32), 'eval/episode_y_position_std': Array(315.6641, dtype=float32), 'eval/episode_y_velocity_std': Array(105.16519, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5447096824646, 'eval/sps': 937.4218913179766, 'num_steps': 65454080}
{'eval/walltime': 109377.97222304344, 'training/sps': 2930.116751970866, 'training/walltime': 22274.722051858902, 'training/entropy_loss': Array(0.02092863, dtype=float32), 'training/policy_loss': Array(0.00664267, dtype=float32), 'training/total_loss': Array(0.20824975, dtype=float32), 'training/v_loss': Array(0.18067847, dtype=float32), 'eval/episode_distance_from_origin': Array(7476.796, dtype=float32), 'eval/episode_distance_reward': Array(36.089966, dtype=float32), 'eval/episode_forward_reward': Array(6014.962, dtype=float32), 'eval/episode_reward': Array(5955.8213, dtype=float32), 'eval/episode_reward_alive': Array(330.86328, dtype=float32), 'eval/episode_reward_linvel': Array(6014.962, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.09418, dtype=float32), 'eval/episode_x_position': Array(7441.511, dtype=float32), 'eval/episode_x_velocity': Array(1202.9923, dtype=float32), 'eval/episode_y_position': Array(-199.13544, dtype=float32), 'eval/episode_y_velocity': Array(-111.40474, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.37253, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4523234, dtype=float32), 'eval/episode_forward_reward_std': Array(1075.3776, dtype=float32), 'eval/episode_reward_std': Array(1135.6627, dtype=float32), 'eval/episode_reward_alive_std': Array(60.33888, dtype=float32), 'eval/episode_reward_linvel_std': Array(1075.3776, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.496044, dtype=float32), 'eval/episode_x_position_std': Array(475.829, dtype=float32), 'eval/episode_x_velocity_std': Array(215.07544, dtype=float32), 'eval/episode_y_position_std': Array(301.6851, dtype=float32), 'eval/episode_y_velocity_std': Array(114.44141, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70926809310913, 'eval/sps': 936.2935065442858, 'num_steps': 65536000}
{'eval/walltime': 109514.51036858559, 'training/sps': 2954.6351926027064, 'training/walltime': 22302.44797897339, 'training/entropy_loss': Array(0.01314264, dtype=float32), 'training/policy_loss': Array(0.00129827, dtype=float32), 'training/total_loss': Array(0.033652, dtype=float32), 'training/v_loss': Array(0.01921109, dtype=float32), 'eval/episode_distance_from_origin': Array(7435.307, dtype=float32), 'eval/episode_distance_reward': Array(35.76522, dtype=float32), 'eval/episode_forward_reward': Array(5960.84, dtype=float32), 'eval/episode_reward': Array(5903.6123, dtype=float32), 'eval/episode_reward_alive': Array(331.03516, dtype=float32), 'eval/episode_reward_linvel': Array(5960.84, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.02734, dtype=float32), 'eval/episode_x_position': Array(7398.9824, dtype=float32), 'eval/episode_x_velocity': Array(1192.1678, dtype=float32), 'eval/episode_y_position': Array(-227.49344, dtype=float32), 'eval/episode_y_velocity': Array(-118.05516, dtype=float32), 'eval/episode_distance_from_origin_std': Array(580.66614, dtype=float32), 'eval/episode_distance_reward_std': Array(7.335251, dtype=float32), 'eval/episode_forward_reward_std': Array(1222.533, dtype=float32), 'eval/episode_reward_std': Array(1289.7347, dtype=float32), 'eval/episode_reward_alive_std': Array(61.821888, dtype=float32), 'eval/episode_reward_linvel_std': Array(1222.533, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.24522, dtype=float32), 'eval/episode_x_position_std': Array(577.25415, dtype=float32), 'eval/episode_x_velocity_std': Array(244.50656, dtype=float32), 'eval/episode_y_position_std': Array(288.91925, dtype=float32), 'eval/episode_y_velocity_std': Array(109.253105, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.53814554214478, 'eval/sps': 937.4669583489448, 'num_steps': 65617920}
{'eval/walltime': 109651.09534072876, 'training/sps': 2929.9811769447097, 'training/walltime': 22330.40720295906, 'training/entropy_loss': Array(0.01676028, dtype=float32), 'training/policy_loss': Array(0.00918113, dtype=float32), 'training/total_loss': Array(0.16882509, dtype=float32), 'training/v_loss': Array(0.1428837, dtype=float32), 'eval/episode_distance_from_origin': Array(7561.2505, dtype=float32), 'eval/episode_distance_reward': Array(37.376114, dtype=float32), 'eval/episode_forward_reward': Array(6229.3193, dtype=float32), 'eval/episode_reward': Array(6190.8833, dtype=float32), 'eval/episode_reward_alive': Array(339.8086, dtype=float32), 'eval/episode_reward_linvel': Array(6229.3193, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.61926, dtype=float32), 'eval/episode_x_position': Array(7524.575, dtype=float32), 'eval/episode_x_velocity': Array(1245.8635, dtype=float32), 'eval/episode_y_position': Array(-186.41655, dtype=float32), 'eval/episode_y_velocity': Array(-111.32926, dtype=float32), 'eval/episode_distance_from_origin_std': Array(375.51434, dtype=float32), 'eval/episode_distance_reward_std': Array(5.371117, dtype=float32), 'eval/episode_forward_reward_std': Array(895.17957, dtype=float32), 'eval/episode_reward_std': Array(932.4736, dtype=float32), 'eval/episode_reward_alive_std': Array(50.737534, dtype=float32), 'eval/episode_reward_linvel_std': Array(895.17957, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.463844, dtype=float32), 'eval/episode_x_position_std': Array(374.73932, dtype=float32), 'eval/episode_x_velocity_std': Array(179.03601, dtype=float32), 'eval/episode_y_position_std': Array(329.70135, dtype=float32), 'eval/episode_y_velocity_std': Array(118.4882, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58497214317322, 'eval/sps': 937.1455584866676, 'num_steps': 65699840}
{'eval/walltime': 109787.57597899437, 'training/sps': 2938.5326778610906, 'training/walltime': 22358.28506207466, 'training/entropy_loss': Array(0.01980108, dtype=float32), 'training/policy_loss': Array(0.00726609, dtype=float32), 'training/total_loss': Array(0.30551392, dtype=float32), 'training/v_loss': Array(0.27844673, dtype=float32), 'eval/episode_distance_from_origin': Array(7509.826, dtype=float32), 'eval/episode_distance_reward': Array(36.53207, dtype=float32), 'eval/episode_forward_reward': Array(6088.647, dtype=float32), 'eval/episode_reward': Array(6039.0977, dtype=float32), 'eval/episode_reward_alive': Array(336.65625, dtype=float32), 'eval/episode_reward_linvel': Array(6088.647, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.73804, dtype=float32), 'eval/episode_x_position': Array(7475.9766, dtype=float32), 'eval/episode_x_velocity': Array(1217.7294, dtype=float32), 'eval/episode_y_position': Array(-143.4932, dtype=float32), 'eval/episode_y_velocity': Array(-88.227806, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.25003, dtype=float32), 'eval/episode_distance_reward_std': Array(6.799748, dtype=float32), 'eval/episode_forward_reward_std': Array(1133.2836, dtype=float32), 'eval/episode_reward_std': Array(1189.6351, dtype=float32), 'eval/episode_reward_alive_std': Array(60.20433, dtype=float32), 'eval/episode_reward_linvel_std': Array(1133.2836, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.19655, dtype=float32), 'eval/episode_x_position_std': Array(504.20197, dtype=float32), 'eval/episode_x_velocity_std': Array(226.6566, dtype=float32), 'eval/episode_y_position_std': Array(309.92505, dtype=float32), 'eval/episode_y_velocity_std': Array(113.26479, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48063826560974, 'eval/sps': 937.8619680169925, 'num_steps': 65781760}
{'eval/walltime': 109924.26954054832, 'training/sps': 2930.91051484181, 'training/walltime': 22386.235420703888, 'training/entropy_loss': Array(0.02004288, dtype=float32), 'training/policy_loss': Array(0.00458016, dtype=float32), 'training/total_loss': Array(0.21192417, dtype=float32), 'training/v_loss': Array(0.18730111, dtype=float32), 'eval/episode_distance_from_origin': Array(7496.5664, dtype=float32), 'eval/episode_distance_reward': Array(37.17109, dtype=float32), 'eval/episode_forward_reward': Array(6195.1484, dtype=float32), 'eval/episode_reward': Array(6150.9033, dtype=float32), 'eval/episode_reward_alive': Array(334.125, dtype=float32), 'eval/episode_reward_linvel': Array(6195.1484, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.54105, dtype=float32), 'eval/episode_x_position': Array(7462.273, dtype=float32), 'eval/episode_x_velocity': Array(1239.0295, dtype=float32), 'eval/episode_y_position': Array(-204.20947, dtype=float32), 'eval/episode_y_velocity': Array(-119.72194, dtype=float32), 'eval/episode_distance_from_origin_std': Array(466.8201, dtype=float32), 'eval/episode_distance_reward_std': Array(5.751151, dtype=float32), 'eval/episode_forward_reward_std': Array(958.51825, dtype=float32), 'eval/episode_reward_std': Array(1000.3128, dtype=float32), 'eval/episode_reward_alive_std': Array(50.39252, dtype=float32), 'eval/episode_reward_linvel_std': Array(958.51825, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.381428, dtype=float32), 'eval/episode_x_position_std': Array(464.51273, dtype=float32), 'eval/episode_x_velocity_std': Array(191.70366, dtype=float32), 'eval/episode_y_position_std': Array(268.08124, dtype=float32), 'eval/episode_y_velocity_std': Array(105.085396, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69356155395508, 'eval/sps': 936.4010897431801, 'num_steps': 65863680}
{'eval/walltime': 110060.75660681725, 'training/sps': 2952.4085279130873, 'training/walltime': 22413.982258319855, 'training/entropy_loss': Array(0.0210522, dtype=float32), 'training/policy_loss': Array(0.00436846, dtype=float32), 'training/total_loss': Array(0.2472283, dtype=float32), 'training/v_loss': Array(0.22180764, dtype=float32), 'eval/episode_distance_from_origin': Array(7506.1914, dtype=float32), 'eval/episode_distance_reward': Array(36.516945, dtype=float32), 'eval/episode_forward_reward': Array(6086.126, dtype=float32), 'eval/episode_reward': Array(6029.6333, dtype=float32), 'eval/episode_reward_alive': Array(331.7578, dtype=float32), 'eval/episode_reward_linvel': Array(6086.126, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.76703, dtype=float32), 'eval/episode_x_position': Array(7468.3867, dtype=float32), 'eval/episode_x_velocity': Array(1217.2251, dtype=float32), 'eval/episode_y_position': Array(-191.33958, dtype=float32), 'eval/episode_y_velocity': Array(-107.284515, dtype=float32), 'eval/episode_distance_from_origin_std': Array(446.68985, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7714095, dtype=float32), 'eval/episode_forward_reward_std': Array(961.8952, dtype=float32), 'eval/episode_reward_std': Array(1019.76373, dtype=float32), 'eval/episode_reward_alive_std': Array(55.64722, dtype=float32), 'eval/episode_reward_linvel_std': Array(961.8952, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.18224, dtype=float32), 'eval/episode_x_position_std': Array(447.20624, dtype=float32), 'eval/episode_x_velocity_std': Array(192.37907, dtype=float32), 'eval/episode_y_position_std': Array(348.61905, dtype=float32), 'eval/episode_y_velocity_std': Array(119.88419, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4870662689209, 'eval/sps': 937.8177984117644, 'num_steps': 65945600}
{'eval/walltime': 110197.46355199814, 'training/sps': 2935.25281603602, 'training/walltime': 22441.891268253326, 'training/entropy_loss': Array(0.02233513, dtype=float32), 'training/policy_loss': Array(0.00385626, dtype=float32), 'training/total_loss': Array(0.21837613, dtype=float32), 'training/v_loss': Array(0.19218472, dtype=float32), 'eval/episode_distance_from_origin': Array(7445.21, dtype=float32), 'eval/episode_distance_reward': Array(36.442028, dtype=float32), 'eval/episode_forward_reward': Array(6073.6387, dtype=float32), 'eval/episode_reward': Array(6030.49, dtype=float32), 'eval/episode_reward_alive': Array(344.45312, dtype=float32), 'eval/episode_reward_linvel': Array(6073.6387, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.04327, dtype=float32), 'eval/episode_x_position': Array(7409.3906, dtype=float32), 'eval/episode_x_velocity': Array(1214.7275, dtype=float32), 'eval/episode_y_position': Array(-217.95747, dtype=float32), 'eval/episode_y_velocity': Array(-118.3099, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.0132, dtype=float32), 'eval/episode_distance_reward_std': Array(6.747688, dtype=float32), 'eval/episode_forward_reward_std': Array(1124.607, dtype=float32), 'eval/episode_reward_std': Array(1173.2424, dtype=float32), 'eval/episode_reward_alive_std': Array(57.817646, dtype=float32), 'eval/episode_reward_linvel_std': Array(1124.607, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.57506, dtype=float32), 'eval/episode_x_position_std': Array(525.9856, dtype=float32), 'eval/episode_x_velocity_std': Array(224.92125, dtype=float32), 'eval/episode_y_position_std': Array(296.7282, dtype=float32), 'eval/episode_y_velocity_std': Array(102.48341, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70694518089294, 'eval/sps': 936.3094159600175, 'num_steps': 66027520}
{'eval/walltime': 110333.81976985931, 'training/sps': 2950.2776010831963, 'training/walltime': 22469.658146858215, 'training/entropy_loss': Array(0.01499372, dtype=float32), 'training/policy_loss': Array(0.00618547, dtype=float32), 'training/total_loss': Array(0.07321825, dtype=float32), 'training/v_loss': Array(0.05203906, dtype=float32), 'eval/episode_distance_from_origin': Array(7522.244, dtype=float32), 'eval/episode_distance_reward': Array(36.88388, dtype=float32), 'eval/episode_forward_reward': Array(6147.2793, dtype=float32), 'eval/episode_reward': Array(6106.8286, dtype=float32), 'eval/episode_reward_alive': Array(344.60938, dtype=float32), 'eval/episode_reward_linvel': Array(6147.2793, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.94376, dtype=float32), 'eval/episode_x_position': Array(7483.9243, dtype=float32), 'eval/episode_x_velocity': Array(1229.4558, dtype=float32), 'eval/episode_y_position': Array(-241.7499, dtype=float32), 'eval/episode_y_velocity': Array(-128.37405, dtype=float32), 'eval/episode_distance_from_origin_std': Array(494.37878, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8281026, dtype=float32), 'eval/episode_forward_reward_std': Array(971.3438, dtype=float32), 'eval/episode_reward_std': Array(1021.47473, dtype=float32), 'eval/episode_reward_alive_std': Array(52.45574, dtype=float32), 'eval/episode_reward_linvel_std': Array(971.3438, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.908558, dtype=float32), 'eval/episode_x_position_std': Array(491.8539, dtype=float32), 'eval/episode_x_velocity_std': Array(194.26881, dtype=float32), 'eval/episode_y_position_std': Array(311.59406, dtype=float32), 'eval/episode_y_velocity_std': Array(108.45134, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35621786117554, 'eval/sps': 938.7177351187387, 'num_steps': 66109440}
{'eval/walltime': 110470.54042983055, 'training/sps': 2940.7524730795426, 'training/walltime': 22497.514962673187, 'training/entropy_loss': Array(0.01641968, dtype=float32), 'training/policy_loss': Array(0.00606503, dtype=float32), 'training/total_loss': Array(0.09739569, dtype=float32), 'training/v_loss': Array(0.07491097, dtype=float32), 'eval/episode_distance_from_origin': Array(7459.541, dtype=float32), 'eval/episode_distance_reward': Array(36.72592, dtype=float32), 'eval/episode_forward_reward': Array(6120.954, dtype=float32), 'eval/episode_reward': Array(6082.787, dtype=float32), 'eval/episode_reward_alive': Array(340.96875, dtype=float32), 'eval/episode_reward_linvel': Array(6120.954, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.86163, dtype=float32), 'eval/episode_x_position': Array(7425.686, dtype=float32), 'eval/episode_x_velocity': Array(1224.1907, dtype=float32), 'eval/episode_y_position': Array(-166.24098, dtype=float32), 'eval/episode_y_velocity': Array(-111.1881, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.71414, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0292177, dtype=float32), 'eval/episode_forward_reward_std': Array(1004.86316, dtype=float32), 'eval/episode_reward_std': Array(1045.1431, dtype=float32), 'eval/episode_reward_alive_std': Array(54.682487, dtype=float32), 'eval/episode_reward_linvel_std': Array(1004.86316, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.83362, dtype=float32), 'eval/episode_x_position_std': Array(488.15247, dtype=float32), 'eval/episode_x_velocity_std': Array(200.97263, dtype=float32), 'eval/episode_y_position_std': Array(286.34113, dtype=float32), 'eval/episode_y_velocity_std': Array(97.4546, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.72065997123718, 'eval/sps': 936.2154924276126, 'num_steps': 66191360}
{'eval/walltime': 110606.86170482635, 'training/sps': 2950.7313990500516, 'training/walltime': 22525.277570962906, 'training/entropy_loss': Array(0.01899051, dtype=float32), 'training/policy_loss': Array(0.00767498, dtype=float32), 'training/total_loss': Array(0.33648488, dtype=float32), 'training/v_loss': Array(0.3098194, dtype=float32), 'eval/episode_distance_from_origin': Array(7447.6157, dtype=float32), 'eval/episode_distance_reward': Array(36.09469, dtype=float32), 'eval/episode_forward_reward': Array(6015.7505, dtype=float32), 'eval/episode_reward': Array(5977.4717, dtype=float32), 'eval/episode_reward_alive': Array(341.85156, dtype=float32), 'eval/episode_reward_linvel': Array(6015.7505, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.2246, dtype=float32), 'eval/episode_x_position': Array(7411.0327, dtype=float32), 'eval/episode_x_velocity': Array(1203.1501, dtype=float32), 'eval/episode_y_position': Array(-210.48755, dtype=float32), 'eval/episode_y_velocity': Array(-116.45517, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.57428, dtype=float32), 'eval/episode_distance_reward_std': Array(5.772076, dtype=float32), 'eval/episode_forward_reward_std': Array(962.00415, dtype=float32), 'eval/episode_reward_std': Array(1001.01337, dtype=float32), 'eval/episode_reward_alive_std': Array(51.599358, dtype=float32), 'eval/episode_reward_linvel_std': Array(962.00415, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.831367, dtype=float32), 'eval/episode_x_position_std': Array(455.2979, dtype=float32), 'eval/episode_x_velocity_std': Array(192.4009, dtype=float32), 'eval/episode_y_position_std': Array(308.55038, dtype=float32), 'eval/episode_y_velocity_std': Array(104.87924, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32127499580383, 'eval/sps': 938.958354108264, 'num_steps': 66273280}
{'eval/walltime': 110743.54040384293, 'training/sps': 2937.365978386823, 'training/walltime': 22553.166502952576, 'training/entropy_loss': Array(0.01975568, dtype=float32), 'training/policy_loss': Array(0.00831953, dtype=float32), 'training/total_loss': Array(0.2767693, dtype=float32), 'training/v_loss': Array(0.2486941, dtype=float32), 'eval/episode_distance_from_origin': Array(7485.463, dtype=float32), 'eval/episode_distance_reward': Array(36.011326, dtype=float32), 'eval/episode_forward_reward': Array(6001.8574, dtype=float32), 'eval/episode_reward': Array(5943.5137, dtype=float32), 'eval/episode_reward_alive': Array(326.57812, dtype=float32), 'eval/episode_reward_linvel': Array(6001.8574, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.9334, dtype=float32), 'eval/episode_x_position': Array(7449.0933, dtype=float32), 'eval/episode_x_velocity': Array(1200.3715, dtype=float32), 'eval/episode_y_position': Array(-198.39429, dtype=float32), 'eval/episode_y_velocity': Array(-115.0254, dtype=float32), 'eval/episode_distance_from_origin_std': Array(508.74582, dtype=float32), 'eval/episode_distance_reward_std': Array(6.166491, dtype=float32), 'eval/episode_forward_reward_std': Array(1027.7407, dtype=float32), 'eval/episode_reward_std': Array(1083.2493, dtype=float32), 'eval/episode_reward_alive_std': Array(58.59602, dtype=float32), 'eval/episode_reward_linvel_std': Array(1027.7407, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.65842, dtype=float32), 'eval/episode_x_position_std': Array(507.0851, dtype=float32), 'eval/episode_x_velocity_std': Array(205.5481, dtype=float32), 'eval/episode_y_position_std': Array(317.10483, dtype=float32), 'eval/episode_y_velocity_std': Array(108.97102, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67869901657104, 'eval/sps': 936.502914653008, 'num_steps': 66355200}
{'eval/walltime': 110879.8440310955, 'training/sps': 2952.1975491607573, 'training/walltime': 22580.915323495865, 'training/entropy_loss': Array(0.02041286, dtype=float32), 'training/policy_loss': Array(0.005209, dtype=float32), 'training/total_loss': Array(0.24107993, dtype=float32), 'training/v_loss': Array(0.21545807, dtype=float32), 'eval/episode_distance_from_origin': Array(7544.5244, dtype=float32), 'eval/episode_distance_reward': Array(37.461876, dtype=float32), 'eval/episode_forward_reward': Array(6243.612, dtype=float32), 'eval/episode_reward': Array(6201.168, dtype=float32), 'eval/episode_reward_alive': Array(340.47266, dtype=float32), 'eval/episode_reward_linvel': Array(6243.612, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.378, dtype=float32), 'eval/episode_x_position': Array(7507.8394, dtype=float32), 'eval/episode_x_velocity': Array(1248.7224, dtype=float32), 'eval/episode_y_position': Array(-192.71448, dtype=float32), 'eval/episode_y_velocity': Array(-112.131744, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.55396, dtype=float32), 'eval/episode_distance_reward_std': Array(6.199892, dtype=float32), 'eval/episode_forward_reward_std': Array(1033.3098, dtype=float32), 'eval/episode_reward_std': Array(1090.9845, dtype=float32), 'eval/episode_reward_alive_std': Array(59.004776, dtype=float32), 'eval/episode_reward_linvel_std': Array(1033.3098, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.010353, dtype=float32), 'eval/episode_x_position_std': Array(505.25308, dtype=float32), 'eval/episode_x_velocity_std': Array(206.66187, dtype=float32), 'eval/episode_y_position_std': Array(329.25208, dtype=float32), 'eval/episode_y_velocity_std': Array(120.32123, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30362725257874, 'eval/sps': 939.0799245775637, 'num_steps': 66437120}
{'eval/walltime': 111016.54751825333, 'training/sps': 2940.965141893875, 'training/walltime': 22608.770124912262, 'training/entropy_loss': Array(0.02133474, dtype=float32), 'training/policy_loss': Array(0.00653804, dtype=float32), 'training/total_loss': Array(0.22884573, dtype=float32), 'training/v_loss': Array(0.20097294, dtype=float32), 'eval/episode_distance_from_origin': Array(7490.4004, dtype=float32), 'eval/episode_distance_reward': Array(36.783104, dtype=float32), 'eval/episode_forward_reward': Array(6130.4844, dtype=float32), 'eval/episode_reward': Array(6093.046, dtype=float32), 'eval/episode_reward_alive': Array(340.73047, dtype=float32), 'eval/episode_reward_linvel': Array(6130.4844, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.95242, dtype=float32), 'eval/episode_x_position': Array(7455.743, dtype=float32), 'eval/episode_x_velocity': Array(1226.097, dtype=float32), 'eval/episode_y_position': Array(-124.86849, dtype=float32), 'eval/episode_y_velocity': Array(-99.516914, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.8899, dtype=float32), 'eval/episode_distance_reward_std': Array(5.996038, dtype=float32), 'eval/episode_forward_reward_std': Array(999.3326, dtype=float32), 'eval/episode_reward_std': Array(1032.856, dtype=float32), 'eval/episode_reward_alive_std': Array(51.827534, dtype=float32), 'eval/episode_reward_linvel_std': Array(999.3326, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.61045, dtype=float32), 'eval/episode_x_position_std': Array(504.66434, dtype=float32), 'eval/episode_x_velocity_std': Array(199.86641, dtype=float32), 'eval/episode_y_position_std': Array(318.88342, dtype=float32), 'eval/episode_y_velocity_std': Array(115.62405, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70348715782166, 'eval/sps': 936.3331006488983, 'num_steps': 66519040}
{'eval/walltime': 111152.8822915554, 'training/sps': 2954.120683506538, 'training/walltime': 22636.50088095665, 'training/entropy_loss': Array(0.01666708, dtype=float32), 'training/policy_loss': Array(0.00733887, dtype=float32), 'training/total_loss': Array(0.11700902, dtype=float32), 'training/v_loss': Array(0.09300307, dtype=float32), 'eval/episode_distance_from_origin': Array(7478.5127, dtype=float32), 'eval/episode_distance_reward': Array(36.614014, dtype=float32), 'eval/episode_forward_reward': Array(6102.3037, dtype=float32), 'eval/episode_reward': Array(6053.5444, dtype=float32), 'eval/episode_reward_alive': Array(336.9922, dtype=float32), 'eval/episode_reward_linvel': Array(6102.3037, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.36536, dtype=float32), 'eval/episode_x_position': Array(7442.0513, dtype=float32), 'eval/episode_x_velocity': Array(1220.4607, dtype=float32), 'eval/episode_y_position': Array(-185.34918, dtype=float32), 'eval/episode_y_velocity': Array(-107.98953, dtype=float32), 'eval/episode_distance_from_origin_std': Array(470.66156, dtype=float32), 'eval/episode_distance_reward_std': Array(6.367944, dtype=float32), 'eval/episode_forward_reward_std': Array(1061.3159, dtype=float32), 'eval/episode_reward_std': Array(1108.5844, dtype=float32), 'eval/episode_reward_alive_std': Array(53.479916, dtype=float32), 'eval/episode_reward_linvel_std': Array(1061.3159, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.462692, dtype=float32), 'eval/episode_x_position_std': Array(467.6247, dtype=float32), 'eval/episode_x_velocity_std': Array(212.26312, dtype=float32), 'eval/episode_y_position_std': Array(314.00232, dtype=float32), 'eval/episode_y_velocity_std': Array(114.0943, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33477330207825, 'eval/sps': 938.8653892165074, 'num_steps': 66600960}
{'eval/walltime': 111289.55615592003, 'training/sps': 2950.650236721067, 'training/walltime': 22664.264252901077, 'training/entropy_loss': Array(0.01620528, dtype=float32), 'training/policy_loss': Array(0.00571622, dtype=float32), 'training/total_loss': Array(0.08324797, dtype=float32), 'training/v_loss': Array(0.06132648, dtype=float32), 'eval/episode_distance_from_origin': Array(7507.507, dtype=float32), 'eval/episode_distance_reward': Array(37.202477, dtype=float32), 'eval/episode_forward_reward': Array(6200.381, dtype=float32), 'eval/episode_reward': Array(6157.444, dtype=float32), 'eval/episode_reward_alive': Array(342.20312, dtype=float32), 'eval/episode_reward_linvel': Array(6200.381, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.34265, dtype=float32), 'eval/episode_x_position': Array(7472.08, dtype=float32), 'eval/episode_x_velocity': Array(1240.076, dtype=float32), 'eval/episode_y_position': Array(-158.35548, dtype=float32), 'eval/episode_y_velocity': Array(-104.61055, dtype=float32), 'eval/episode_distance_from_origin_std': Array(525.3729, dtype=float32), 'eval/episode_distance_reward_std': Array(6.550599, dtype=float32), 'eval/episode_forward_reward_std': Array(1091.7593, dtype=float32), 'eval/episode_reward_std': Array(1137.8063, dtype=float32), 'eval/episode_reward_alive_std': Array(49.39111, dtype=float32), 'eval/episode_reward_linvel_std': Array(1091.7593, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.692524, dtype=float32), 'eval/episode_x_position_std': Array(525.6429, dtype=float32), 'eval/episode_x_velocity_std': Array(218.35176, dtype=float32), 'eval/episode_y_position_std': Array(302.41855, dtype=float32), 'eval/episode_y_velocity_std': Array(113.274704, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67386436462402, 'eval/sps': 936.5360421690899, 'num_steps': 66682880}
{'eval/walltime': 111425.87786221504, 'training/sps': 2950.7951816342484, 'training/walltime': 22692.026261091232, 'training/entropy_loss': Array(0.01898242, dtype=float32), 'training/policy_loss': Array(0.00844824, dtype=float32), 'training/total_loss': Array(0.25987566, dtype=float32), 'training/v_loss': Array(0.232445, dtype=float32), 'eval/episode_distance_from_origin': Array(7469.096, dtype=float32), 'eval/episode_distance_reward': Array(36.466633, dtype=float32), 'eval/episode_forward_reward': Array(6077.739, dtype=float32), 'eval/episode_reward': Array(6032.9917, dtype=float32), 'eval/episode_reward_alive': Array(342.6953, dtype=float32), 'eval/episode_reward_linvel': Array(6077.739, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.90872, dtype=float32), 'eval/episode_x_position': Array(7434.248, dtype=float32), 'eval/episode_x_velocity': Array(1215.5477, dtype=float32), 'eval/episode_y_position': Array(-135.13333, dtype=float32), 'eval/episode_y_velocity': Array(-103.07934, dtype=float32), 'eval/episode_distance_from_origin_std': Array(520.1859, dtype=float32), 'eval/episode_distance_reward_std': Array(6.987669, dtype=float32), 'eval/episode_forward_reward_std': Array(1164.6031, dtype=float32), 'eval/episode_reward_std': Array(1217.0377, dtype=float32), 'eval/episode_reward_alive_std': Array(63.07548, dtype=float32), 'eval/episode_reward_linvel_std': Array(1164.6031, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.933617, dtype=float32), 'eval/episode_x_position_std': Array(517.93756, dtype=float32), 'eval/episode_x_velocity_std': Array(232.92073, dtype=float32), 'eval/episode_y_position_std': Array(310.17007, dtype=float32), 'eval/episode_y_velocity_std': Array(115.92072, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32170629501343, 'eval/sps': 938.9553834001722, 'num_steps': 66764800}
{'eval/walltime': 111562.56872415543, 'training/sps': 2949.4495915182933, 'training/walltime': 22719.800934791565, 'training/entropy_loss': Array(0.02002703, dtype=float32), 'training/policy_loss': Array(0.01168186, dtype=float32), 'training/total_loss': Array(0.2537259, dtype=float32), 'training/v_loss': Array(0.22201699, dtype=float32), 'eval/episode_distance_from_origin': Array(7563.301, dtype=float32), 'eval/episode_distance_reward': Array(37.378807, dtype=float32), 'eval/episode_forward_reward': Array(6229.769, dtype=float32), 'eval/episode_reward': Array(6178.387, dtype=float32), 'eval/episode_reward_alive': Array(338.0078, dtype=float32), 'eval/episode_reward_linvel': Array(6229.769, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.76883, dtype=float32), 'eval/episode_x_position': Array(7529.045, dtype=float32), 'eval/episode_x_velocity': Array(1245.9537, dtype=float32), 'eval/episode_y_position': Array(-91.543785, dtype=float32), 'eval/episode_y_velocity': Array(-92.481094, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.57587, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6423693, dtype=float32), 'eval/episode_forward_reward_std': Array(1107.0535, dtype=float32), 'eval/episode_reward_std': Array(1168.2314, dtype=float32), 'eval/episode_reward_alive_std': Array(54.90222, dtype=float32), 'eval/episode_reward_linvel_std': Array(1107.0535, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.655754, dtype=float32), 'eval/episode_x_position_std': Array(471.6842, dtype=float32), 'eval/episode_x_velocity_std': Array(221.41074, dtype=float32), 'eval/episode_y_position_std': Array(319.59998, dtype=float32), 'eval/episode_y_velocity_std': Array(114.02526, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.6908619403839, 'eval/sps': 936.4195834526647, 'num_steps': 66846720}
{'eval/walltime': 111698.89739322662, 'training/sps': 2955.469446909529, 'training/walltime': 22747.519035577774, 'training/entropy_loss': Array(0.02066396, dtype=float32), 'training/policy_loss': Array(0.00443617, dtype=float32), 'training/total_loss': Array(0.23058829, dtype=float32), 'training/v_loss': Array(0.20548816, dtype=float32), 'eval/episode_distance_from_origin': Array(7551.4424, dtype=float32), 'eval/episode_distance_reward': Array(37.456234, dtype=float32), 'eval/episode_forward_reward': Array(6242.6733, dtype=float32), 'eval/episode_reward': Array(6192.9434, dtype=float32), 'eval/episode_reward_alive': Array(339.0547, dtype=float32), 'eval/episode_reward_linvel': Array(6242.6733, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.24066, dtype=float32), 'eval/episode_x_position': Array(7517.2534, dtype=float32), 'eval/episode_x_velocity': Array(1248.5345, dtype=float32), 'eval/episode_y_position': Array(-130.7839, dtype=float32), 'eval/episode_y_velocity': Array(-104.34384, dtype=float32), 'eval/episode_distance_from_origin_std': Array(552.64417, dtype=float32), 'eval/episode_distance_reward_std': Array(7.2874656, dtype=float32), 'eval/episode_forward_reward_std': Array(1214.5702, dtype=float32), 'eval/episode_reward_std': Array(1273.3655, dtype=float32), 'eval/episode_reward_alive_std': Array(56.896465, dtype=float32), 'eval/episode_reward_linvel_std': Array(1214.5702, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.428295, dtype=float32), 'eval/episode_x_position_std': Array(551.6452, dtype=float32), 'eval/episode_x_velocity_std': Array(242.91411, dtype=float32), 'eval/episode_y_position_std': Array(297.5927, dtype=float32), 'eval/episode_y_velocity_std': Array(106.63334, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3286690711975, 'eval/sps': 938.907427704382, 'num_steps': 66928640}
{'eval/walltime': 111835.57292556763, 'training/sps': 2947.1952148713376, 'training/walltime': 22775.31495475769, 'training/entropy_loss': Array(0.02120776, dtype=float32), 'training/policy_loss': Array(0.0189841, dtype=float32), 'training/total_loss': Array(0.25426477, dtype=float32), 'training/v_loss': Array(0.21407291, dtype=float32), 'eval/episode_distance_from_origin': Array(7633.238, dtype=float32), 'eval/episode_distance_reward': Array(38.366245, dtype=float32), 'eval/episode_forward_reward': Array(6394.34, dtype=float32), 'eval/episode_reward': Array(6355.4014, dtype=float32), 'eval/episode_reward_alive': Array(345.5625, dtype=float32), 'eval/episode_reward_linvel': Array(6394.34, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.86646, dtype=float32), 'eval/episode_x_position': Array(7599.1445, dtype=float32), 'eval/episode_x_velocity': Array(1278.8677, dtype=float32), 'eval/episode_y_position': Array(-97.47761, dtype=float32), 'eval/episode_y_velocity': Array(-91.697624, dtype=float32), 'eval/episode_distance_from_origin_std': Array(456.76678, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1911287, dtype=float32), 'eval/episode_forward_reward_std': Array(1031.8478, dtype=float32), 'eval/episode_reward_std': Array(1070.9366, dtype=float32), 'eval/episode_reward_alive_std': Array(49.70039, dtype=float32), 'eval/episode_reward_linvel_std': Array(1031.8478, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.489243, dtype=float32), 'eval/episode_x_position_std': Array(455.1599, dtype=float32), 'eval/episode_x_velocity_std': Array(206.36961, dtype=float32), 'eval/episode_y_position_std': Array(308.13214, dtype=float32), 'eval/episode_y_velocity_std': Array(121.483826, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.67553234100342, 'eval/sps': 936.5246127642065, 'num_steps': 67010560}
{'eval/walltime': 111971.8947558403, 'training/sps': 2950.397934774414, 'training/walltime': 22803.08070087433, 'training/entropy_loss': Array(0.01904025, dtype=float32), 'training/policy_loss': Array(0.00934395, dtype=float32), 'training/total_loss': Array(0.18227223, dtype=float32), 'training/v_loss': Array(0.15388802, dtype=float32), 'eval/episode_distance_from_origin': Array(7602.249, dtype=float32), 'eval/episode_distance_reward': Array(37.709396, dtype=float32), 'eval/episode_forward_reward': Array(6284.866, dtype=float32), 'eval/episode_reward': Array(6238.576, dtype=float32), 'eval/episode_reward_alive': Array(335.7422, dtype=float32), 'eval/episode_reward_linvel': Array(6284.866, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.74158, dtype=float32), 'eval/episode_x_position': Array(7569.1924, dtype=float32), 'eval/episode_x_velocity': Array(1256.9731, dtype=float32), 'eval/episode_y_position': Array(-68.565506, dtype=float32), 'eval/episode_y_velocity': Array(-86.06043, dtype=float32), 'eval/episode_distance_from_origin_std': Array(508.20352, dtype=float32), 'eval/episode_distance_reward_std': Array(6.303569, dtype=float32), 'eval/episode_forward_reward_std': Array(1050.5879, dtype=float32), 'eval/episode_reward_std': Array(1089.9542, dtype=float32), 'eval/episode_reward_alive_std': Array(53.855095, dtype=float32), 'eval/episode_reward_linvel_std': Array(1050.5879, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.948029, dtype=float32), 'eval/episode_x_position_std': Array(508.3708, dtype=float32), 'eval/episode_x_velocity_std': Array(210.11758, dtype=float32), 'eval/episode_y_position_std': Array(301.02457, dtype=float32), 'eval/episode_y_velocity_std': Array(105.3929, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32183027267456, 'eval/sps': 938.9545294687651, 'num_steps': 67092480}
{'eval/walltime': 112108.37625288963, 'training/sps': 2946.0495398121543, 'training/walltime': 22830.887429475784, 'training/entropy_loss': Array(0.01486423, dtype=float32), 'training/policy_loss': Array(0.00783298, dtype=float32), 'training/total_loss': Array(0.05521638, dtype=float32), 'training/v_loss': Array(0.03251917, dtype=float32), 'eval/episode_distance_from_origin': Array(7552.352, dtype=float32), 'eval/episode_distance_reward': Array(37.212074, dtype=float32), 'eval/episode_forward_reward': Array(6201.9795, dtype=float32), 'eval/episode_reward': Array(6158.2656, dtype=float32), 'eval/episode_reward_alive': Array(337.28516, dtype=float32), 'eval/episode_reward_linvel': Array(6201.9795, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.21045, dtype=float32), 'eval/episode_x_position': Array(7518.482, dtype=float32), 'eval/episode_x_velocity': Array(1240.3958, dtype=float32), 'eval/episode_y_position': Array(-129.90063, dtype=float32), 'eval/episode_y_velocity': Array(-113.4917, dtype=float32), 'eval/episode_distance_from_origin_std': Array(481.34525, dtype=float32), 'eval/episode_distance_reward_std': Array(6.565383, dtype=float32), 'eval/episode_forward_reward_std': Array(1094.2217, dtype=float32), 'eval/episode_reward_std': Array(1135.309, dtype=float32), 'eval/episode_reward_alive_std': Array(52.357307, dtype=float32), 'eval/episode_reward_linvel_std': Array(1094.2217, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.73322, dtype=float32), 'eval/episode_x_position_std': Array(479.14978, dtype=float32), 'eval/episode_x_velocity_std': Array(218.84442, dtype=float32), 'eval/episode_y_position_std': Array(280.3788, dtype=float32), 'eval/episode_y_velocity_std': Array(104.95149, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48149704933167, 'eval/sps': 937.8560666998985, 'num_steps': 67174400}
{'eval/walltime': 112244.67329668999, 'training/sps': 2952.394067663716, 'training/walltime': 22858.63440299034, 'training/entropy_loss': Array(0.01782134, dtype=float32), 'training/policy_loss': Array(0.00886107, dtype=float32), 'training/total_loss': Array(0.23791239, dtype=float32), 'training/v_loss': Array(0.21122998, dtype=float32), 'eval/episode_distance_from_origin': Array(7635.185, dtype=float32), 'eval/episode_distance_reward': Array(38.04265, dtype=float32), 'eval/episode_forward_reward': Array(6340.4097, dtype=float32), 'eval/episode_reward': Array(6296.883, dtype=float32), 'eval/episode_reward_alive': Array(344.4922, dtype=float32), 'eval/episode_reward_linvel': Array(6340.4097, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.06082, dtype=float32), 'eval/episode_x_position': Array(7599.5264, dtype=float32), 'eval/episode_x_velocity': Array(1268.0818, dtype=float32), 'eval/episode_y_position': Array(-109.20503, dtype=float32), 'eval/episode_y_velocity': Array(-91.528854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(507.0879, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5303936, dtype=float32), 'eval/episode_forward_reward_std': Array(1088.3927, dtype=float32), 'eval/episode_reward_std': Array(1144.1917, dtype=float32), 'eval/episode_reward_alive_std': Array(55.31589, dtype=float32), 'eval/episode_reward_linvel_std': Array(1088.3927, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.898422, dtype=float32), 'eval/episode_x_position_std': Array(505.41693, dtype=float32), 'eval/episode_x_velocity_std': Array(217.67828, dtype=float32), 'eval/episode_y_position_std': Array(331.80777, dtype=float32), 'eval/episode_y_velocity_std': Array(120.72684, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.297043800354, 'eval/sps': 939.125284239419, 'num_steps': 67256320}
{'eval/walltime': 112381.30496120453, 'training/sps': 2946.2269754703043, 'training/walltime': 22886.439456939697, 'training/entropy_loss': Array(0.02087515, dtype=float32), 'training/policy_loss': Array(0.0093921, dtype=float32), 'training/total_loss': Array(0.34871045, dtype=float32), 'training/v_loss': Array(0.31844318, dtype=float32), 'eval/episode_distance_from_origin': Array(7494.4023, dtype=float32), 'eval/episode_distance_reward': Array(36.18453, dtype=float32), 'eval/episode_forward_reward': Array(6030.723, dtype=float32), 'eval/episode_reward': Array(5970.823, dtype=float32), 'eval/episode_reward_alive': Array(328.26562, dtype=float32), 'eval/episode_reward_linvel': Array(6030.723, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.34912, dtype=float32), 'eval/episode_x_position': Array(7460.1357, dtype=float32), 'eval/episode_x_velocity': Array(1206.1445, dtype=float32), 'eval/episode_y_position': Array(-94.216484, dtype=float32), 'eval/episode_y_velocity': Array(-87.98099, dtype=float32), 'eval/episode_distance_from_origin_std': Array(552.56915, dtype=float32), 'eval/episode_distance_reward_std': Array(6.748457, dtype=float32), 'eval/episode_forward_reward_std': Array(1124.7357, dtype=float32), 'eval/episode_reward_std': Array(1196.2428, dtype=float32), 'eval/episode_reward_alive_std': Array(63.091015, dtype=float32), 'eval/episode_reward_linvel_std': Array(1124.7357, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.41816, dtype=float32), 'eval/episode_x_position_std': Array(551.9638, dtype=float32), 'eval/episode_x_velocity_std': Array(224.94713, dtype=float32), 'eval/episode_y_position_std': Array(311.36646, dtype=float32), 'eval/episode_y_velocity_std': Array(115.12299, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.63166451454163, 'eval/sps': 936.8252992802926, 'num_steps': 67338240}
{'eval/walltime': 112517.70175337791, 'training/sps': 2947.589172221526, 'training/walltime': 22914.231661081314, 'training/entropy_loss': Array(0.02144768, dtype=float32), 'training/policy_loss': Array(0.01117892, dtype=float32), 'training/total_loss': Array(0.2617959, dtype=float32), 'training/v_loss': Array(0.22916931, dtype=float32), 'eval/episode_distance_from_origin': Array(7487.628, dtype=float32), 'eval/episode_distance_reward': Array(36.81774, dtype=float32), 'eval/episode_forward_reward': Array(6136.2583, dtype=float32), 'eval/episode_reward': Array(6097.0596, dtype=float32), 'eval/episode_reward_alive': Array(348.6836, dtype=float32), 'eval/episode_reward_linvel': Array(6136.2583, dtype=float32), 'eval/episode_reward_quadctrl': Array(-424.7002, dtype=float32), 'eval/episode_x_position': Array(7452.8755, dtype=float32), 'eval/episode_x_velocity': Array(1227.2516, dtype=float32), 'eval/episode_y_position': Array(-74.63106, dtype=float32), 'eval/episode_y_velocity': Array(-73.92488, dtype=float32), 'eval/episode_distance_from_origin_std': Array(499.91718, dtype=float32), 'eval/episode_distance_reward_std': Array(6.965052, dtype=float32), 'eval/episode_forward_reward_std': Array(1160.8344, dtype=float32), 'eval/episode_reward_std': Array(1217.3074, dtype=float32), 'eval/episode_reward_alive_std': Array(59.45363, dtype=float32), 'eval/episode_reward_linvel_std': Array(1160.8344, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.002094, dtype=float32), 'eval/episode_x_position_std': Array(497.5998, dtype=float32), 'eval/episode_x_velocity_std': Array(232.16696, dtype=float32), 'eval/episode_y_position_std': Array(337.311, dtype=float32), 'eval/episode_y_velocity_std': Array(130.89024, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39679217338562, 'eval/sps': 938.4384922871812, 'num_steps': 67420160}
{'eval/walltime': 112654.2462105751, 'training/sps': 2939.5468156167026, 'training/walltime': 22942.099902391434, 'training/entropy_loss': Array(0.02164686, dtype=float32), 'training/policy_loss': Array(0.00767814, dtype=float32), 'training/total_loss': Array(0.235877, dtype=float32), 'training/v_loss': Array(0.20655201, dtype=float32), 'eval/episode_distance_from_origin': Array(7497.2373, dtype=float32), 'eval/episode_distance_reward': Array(36.483414, dtype=float32), 'eval/episode_forward_reward': Array(6080.537, dtype=float32), 'eval/episode_reward': Array(6028.961, dtype=float32), 'eval/episode_reward_alive': Array(341.1836, dtype=float32), 'eval/episode_reward_linvel': Array(6080.537, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.24274, dtype=float32), 'eval/episode_x_position': Array(7463.654, dtype=float32), 'eval/episode_x_velocity': Array(1216.1074, dtype=float32), 'eval/episode_y_position': Array(-85.903336, dtype=float32), 'eval/episode_y_velocity': Array(-95.78112, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.4494, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9082503, dtype=float32), 'eval/episode_forward_reward_std': Array(984.70184, dtype=float32), 'eval/episode_reward_std': Array(1038.6626, dtype=float32), 'eval/episode_reward_alive_std': Array(51.219536, dtype=float32), 'eval/episode_reward_linvel_std': Array(984.70184, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.273388, dtype=float32), 'eval/episode_x_position_std': Array(458.25534, dtype=float32), 'eval/episode_x_velocity_std': Array(196.9404, dtype=float32), 'eval/episode_y_position_std': Array(301.97815, dtype=float32), 'eval/episode_y_velocity_std': Array(103.758705, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.54445719718933, 'eval/sps': 937.4236247111082, 'num_steps': 67502080}
{'eval/walltime': 112790.7200665474, 'training/sps': 2944.6665574663552, 'training/walltime': 22969.91969060898, 'training/entropy_loss': Array(0.02317422, dtype=float32), 'training/policy_loss': Array(0.00752061, dtype=float32), 'training/total_loss': Array(0.20380273, dtype=float32), 'training/v_loss': Array(0.17310789, dtype=float32), 'eval/episode_distance_from_origin': Array(7495.7334, dtype=float32), 'eval/episode_distance_reward': Array(37.247444, dtype=float32), 'eval/episode_forward_reward': Array(6207.875, dtype=float32), 'eval/episode_reward': Array(6164.3496, dtype=float32), 'eval/episode_reward_alive': Array(345.5664, dtype=float32), 'eval/episode_reward_linvel': Array(6207.875, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.33926, dtype=float32), 'eval/episode_x_position': Array(7461.8647, dtype=float32), 'eval/episode_x_velocity': Array(1241.5751, dtype=float32), 'eval/episode_y_position': Array(-91.3166, dtype=float32), 'eval/episode_y_velocity': Array(-99.38988, dtype=float32), 'eval/episode_distance_from_origin_std': Array(486.46866, dtype=float32), 'eval/episode_distance_reward_std': Array(6.125406, dtype=float32), 'eval/episode_forward_reward_std': Array(1020.89417, dtype=float32), 'eval/episode_reward_std': Array(1060.0645, dtype=float32), 'eval/episode_reward_alive_std': Array(52.148167, dtype=float32), 'eval/episode_reward_linvel_std': Array(1020.89417, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.84022, dtype=float32), 'eval/episode_x_position_std': Array(486.53577, dtype=float32), 'eval/episode_x_velocity_std': Array(204.17874, dtype=float32), 'eval/episode_y_position_std': Array(287.2027, dtype=float32), 'eval/episode_y_velocity_std': Array(109.58103, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47385597229004, 'eval/sps': 937.9085766140396, 'num_steps': 67584000}
{'eval/walltime': 112927.42305278778, 'training/sps': 2948.4363272775513, 'training/walltime': 22997.703909397125, 'training/entropy_loss': Array(0.01380201, dtype=float32), 'training/policy_loss': Array(0.00440922, dtype=float32), 'training/total_loss': Array(0.04161531, dtype=float32), 'training/v_loss': Array(0.02340408, dtype=float32), 'eval/episode_distance_from_origin': Array(7443.325, dtype=float32), 'eval/episode_distance_reward': Array(36.472885, dtype=float32), 'eval/episode_forward_reward': Array(6078.783, dtype=float32), 'eval/episode_reward': Array(6023.573, dtype=float32), 'eval/episode_reward_alive': Array(334.23438, dtype=float32), 'eval/episode_reward_linvel': Array(6078.783, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.9172, dtype=float32), 'eval/episode_x_position': Array(7406.8003, dtype=float32), 'eval/episode_x_velocity': Array(1215.7566, dtype=float32), 'eval/episode_y_position': Array(-109.30877, dtype=float32), 'eval/episode_y_velocity': Array(-102.33048, dtype=float32), 'eval/episode_distance_from_origin_std': Array(532.7497, dtype=float32), 'eval/episode_distance_reward_std': Array(6.9073095, dtype=float32), 'eval/episode_forward_reward_std': Array(1151.2097, dtype=float32), 'eval/episode_reward_std': Array(1214.2963, dtype=float32), 'eval/episode_reward_alive_std': Array(58.947502, dtype=float32), 'eval/episode_reward_linvel_std': Array(1151.2097, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.996117, dtype=float32), 'eval/episode_x_position_std': Array(530.27155, dtype=float32), 'eval/episode_x_velocity_std': Array(230.24203, dtype=float32), 'eval/episode_y_position_std': Array(337.41885, dtype=float32), 'eval/episode_y_velocity_std': Array(114.95091, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70298624038696, 'eval/sps': 936.3365316315542, 'num_steps': 67665920}
{'eval/walltime': 113063.84020423889, 'training/sps': 2955.6966319038484, 'training/walltime': 23025.41987967491, 'training/entropy_loss': Array(0.01728541, dtype=float32), 'training/policy_loss': Array(0.02185383, dtype=float32), 'training/total_loss': Array(0.2150098, dtype=float32), 'training/v_loss': Array(0.17587054, dtype=float32), 'eval/episode_distance_from_origin': Array(7518.0586, dtype=float32), 'eval/episode_distance_reward': Array(37.072594, dtype=float32), 'eval/episode_forward_reward': Array(6178.7324, dtype=float32), 'eval/episode_reward': Array(6128.864, dtype=float32), 'eval/episode_reward_alive': Array(342.90625, dtype=float32), 'eval/episode_reward_linvel': Array(6178.7324, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.84708, dtype=float32), 'eval/episode_x_position': Array(7483.119, dtype=float32), 'eval/episode_x_velocity': Array(1235.7465, dtype=float32), 'eval/episode_y_position': Array(-113.02382, dtype=float32), 'eval/episode_y_velocity': Array(-104.585815, dtype=float32), 'eval/episode_distance_from_origin_std': Array(529.31995, dtype=float32), 'eval/episode_distance_reward_std': Array(6.6147103, dtype=float32), 'eval/episode_forward_reward_std': Array(1102.4446, dtype=float32), 'eval/episode_reward_std': Array(1160.8424, dtype=float32), 'eval/episode_reward_alive_std': Array(57.768047, dtype=float32), 'eval/episode_reward_linvel_std': Array(1102.4446, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.654476, dtype=float32), 'eval/episode_x_position_std': Array(528.0411, dtype=float32), 'eval/episode_x_velocity_std': Array(220.4889, dtype=float32), 'eval/episode_y_position_std': Array(307.5086, dtype=float32), 'eval/episode_y_velocity_std': Array(114.64738, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41715145111084, 'eval/sps': 938.2984370984511, 'num_steps': 67747840}
{'eval/walltime': 113200.56438159943, 'training/sps': 2949.8294887702245, 'training/walltime': 23053.190976381302, 'training/entropy_loss': Array(0.02089535, dtype=float32), 'training/policy_loss': Array(0.00963465, dtype=float32), 'training/total_loss': Array(0.2834536, dtype=float32), 'training/v_loss': Array(0.25292364, dtype=float32), 'eval/episode_distance_from_origin': Array(7501.0815, dtype=float32), 'eval/episode_distance_reward': Array(36.31522, dtype=float32), 'eval/episode_forward_reward': Array(6052.504, dtype=float32), 'eval/episode_reward': Array(5996.753, dtype=float32), 'eval/episode_reward_alive': Array(338.65625, dtype=float32), 'eval/episode_reward_linvel': Array(6052.504, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.72232, dtype=float32), 'eval/episode_x_position': Array(7467.385, dtype=float32), 'eval/episode_x_velocity': Array(1210.5007, dtype=float32), 'eval/episode_y_position': Array(-98.52678, dtype=float32), 'eval/episode_y_velocity': Array(-91.82234, dtype=float32), 'eval/episode_distance_from_origin_std': Array(497.45032, dtype=float32), 'eval/episode_distance_reward_std': Array(6.353045, dtype=float32), 'eval/episode_forward_reward_std': Array(1058.8334, dtype=float32), 'eval/episode_reward_std': Array(1099.8704, dtype=float32), 'eval/episode_reward_alive_std': Array(52.941513, dtype=float32), 'eval/episode_reward_linvel_std': Array(1058.8334, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.05405, dtype=float32), 'eval/episode_x_position_std': Array(494.6938, dtype=float32), 'eval/episode_x_velocity_std': Array(211.76666, dtype=float32), 'eval/episode_y_position_std': Array(312.51678, dtype=float32), 'eval/episode_y_velocity_std': Array(105.02419, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.72417736053467, 'eval/sps': 936.1914071896044, 'num_steps': 67829760}
{'eval/walltime': 113336.98018455505, 'training/sps': 2954.660879568997, 'training/walltime': 23080.916662454605, 'training/entropy_loss': Array(0.02054544, dtype=float32), 'training/policy_loss': Array(0.00543388, dtype=float32), 'training/total_loss': Array(0.23753503, dtype=float32), 'training/v_loss': Array(0.21155572, dtype=float32), 'eval/episode_distance_from_origin': Array(7525.3115, dtype=float32), 'eval/episode_distance_reward': Array(37.086113, dtype=float32), 'eval/episode_forward_reward': Array(6180.986, dtype=float32), 'eval/episode_reward': Array(6131.037, dtype=float32), 'eval/episode_reward_alive': Array(335.25, dtype=float32), 'eval/episode_reward_linvel': Array(6180.986, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.285, dtype=float32), 'eval/episode_x_position': Array(7489.96, dtype=float32), 'eval/episode_x_velocity': Array(1236.1973, dtype=float32), 'eval/episode_y_position': Array(-149.28955, dtype=float32), 'eval/episode_y_velocity': Array(-107.573456, dtype=float32), 'eval/episode_distance_from_origin_std': Array(516.4664, dtype=float32), 'eval/episode_distance_reward_std': Array(6.402029, dtype=float32), 'eval/episode_forward_reward_std': Array(1066.9967, dtype=float32), 'eval/episode_reward_std': Array(1125.132, dtype=float32), 'eval/episode_reward_alive_std': Array(58.243896, dtype=float32), 'eval/episode_reward_linvel_std': Array(1066.9967, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.058865, dtype=float32), 'eval/episode_x_position_std': Array(516.03796, dtype=float32), 'eval/episode_x_velocity_std': Array(213.39934, dtype=float32), 'eval/episode_y_position_std': Array(299.1328, dtype=float32), 'eval/episode_y_velocity_std': Array(113.44606, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.41580295562744, 'eval/sps': 938.3077123523227, 'num_steps': 67911680}
{'eval/walltime': 113473.72805809975, 'training/sps': 2946.7210988629627, 'training/walltime': 23108.71705389023, 'training/entropy_loss': Array(0.02056528, dtype=float32), 'training/policy_loss': Array(0.00625088, dtype=float32), 'training/total_loss': Array(0.25123328, dtype=float32), 'training/v_loss': Array(0.22441715, dtype=float32), 'eval/episode_distance_from_origin': Array(7458.584, dtype=float32), 'eval/episode_distance_reward': Array(36.18203, dtype=float32), 'eval/episode_forward_reward': Array(6030.3066, dtype=float32), 'eval/episode_reward': Array(5968.8413, dtype=float32), 'eval/episode_reward_alive': Array(337.7422, dtype=float32), 'eval/episode_reward_linvel': Array(6030.3066, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.3892, dtype=float32), 'eval/episode_x_position': Array(7423.73, dtype=float32), 'eval/episode_x_velocity': Array(1206.0613, dtype=float32), 'eval/episode_y_position': Array(-125.43167, dtype=float32), 'eval/episode_y_velocity': Array(-100.104095, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.5138, dtype=float32), 'eval/episode_distance_reward_std': Array(6.339792, dtype=float32), 'eval/episode_forward_reward_std': Array(1056.6223, dtype=float32), 'eval/episode_reward_std': Array(1125.2338, dtype=float32), 'eval/episode_reward_alive_std': Array(58.30148, dtype=float32), 'eval/episode_reward_linvel_std': Array(1056.6223, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.72687, dtype=float32), 'eval/episode_x_position_std': Array(470.38272, dtype=float32), 'eval/episode_x_velocity_std': Array(211.32445, dtype=float32), 'eval/episode_y_position_std': Array(304.49597, dtype=float32), 'eval/episode_y_velocity_std': Array(112.037674, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.747873544693, 'eval/sps': 936.0291804330402, 'num_steps': 67993600}
{'eval/walltime': 113610.11391878128, 'training/sps': 2954.291548527781, 'training/walltime': 23136.446206092834, 'training/entropy_loss': Array(0.02163219, dtype=float32), 'training/policy_loss': Array(0.01056229, dtype=float32), 'training/total_loss': Array(0.22166325, dtype=float32), 'training/v_loss': Array(0.18946879, dtype=float32), 'eval/episode_distance_from_origin': Array(7580.201, dtype=float32), 'eval/episode_distance_reward': Array(37.166595, dtype=float32), 'eval/episode_forward_reward': Array(6194.4004, dtype=float32), 'eval/episode_reward': Array(6135.9165, dtype=float32), 'eval/episode_reward_alive': Array(329.36328, dtype=float32), 'eval/episode_reward_linvel': Array(6194.4004, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.0138, dtype=float32), 'eval/episode_x_position': Array(7545.1855, dtype=float32), 'eval/episode_x_velocity': Array(1238.8801, dtype=float32), 'eval/episode_y_position': Array(-88.24576, dtype=float32), 'eval/episode_y_velocity': Array(-90.76951, dtype=float32), 'eval/episode_distance_from_origin_std': Array(504.25424, dtype=float32), 'eval/episode_distance_reward_std': Array(6.685275, dtype=float32), 'eval/episode_forward_reward_std': Array(1114.2053, dtype=float32), 'eval/episode_reward_std': Array(1172.6216, dtype=float32), 'eval/episode_reward_alive_std': Array(61.63402, dtype=float32), 'eval/episode_reward_linvel_std': Array(1114.2053, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.583214, dtype=float32), 'eval/episode_x_position_std': Array(500.90137, dtype=float32), 'eval/episode_x_velocity_std': Array(222.8411, dtype=float32), 'eval/episode_y_position_std': Array(334.04755, dtype=float32), 'eval/episode_y_velocity_std': Array(117.48507, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3858606815338, 'eval/sps': 938.5137092684768, 'num_steps': 68075520}
{'eval/walltime': 113746.83148026466, 'training/sps': 2950.8953843968998, 'training/walltime': 23164.207271575928, 'training/entropy_loss': Array(0.01508741, dtype=float32), 'training/policy_loss': Array(0.00693912, dtype=float32), 'training/total_loss': Array(0.09415412, dtype=float32), 'training/v_loss': Array(0.07212759, dtype=float32), 'eval/episode_distance_from_origin': Array(7496.1997, dtype=float32), 'eval/episode_distance_reward': Array(36.81373, dtype=float32), 'eval/episode_forward_reward': Array(6135.588, dtype=float32), 'eval/episode_reward': Array(6092.5635, dtype=float32), 'eval/episode_reward_alive': Array(346.14453, dtype=float32), 'eval/episode_reward_linvel': Array(6135.588, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.9829, dtype=float32), 'eval/episode_x_position': Array(7461.7397, dtype=float32), 'eval/episode_x_velocity': Array(1227.1177, dtype=float32), 'eval/episode_y_position': Array(-125.27938, dtype=float32), 'eval/episode_y_velocity': Array(-106.45236, dtype=float32), 'eval/episode_distance_from_origin_std': Array(492.44717, dtype=float32), 'eval/episode_distance_reward_std': Array(6.100865, dtype=float32), 'eval/episode_forward_reward_std': Array(1016.80457, dtype=float32), 'eval/episode_reward_std': Array(1053.8333, dtype=float32), 'eval/episode_reward_alive_std': Array(47.500294, dtype=float32), 'eval/episode_reward_linvel_std': Array(1016.80457, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.358475, dtype=float32), 'eval/episode_x_position_std': Array(489.58347, dtype=float32), 'eval/episode_x_velocity_std': Array(203.36087, dtype=float32), 'eval/episode_y_position_std': Array(307.11, dtype=float32), 'eval/episode_y_velocity_std': Array(109.9412, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.71756148338318, 'eval/sps': 936.2367102748339, 'num_steps': 68157440}
{'eval/walltime': 113883.2409555912, 'training/sps': 2957.1473101842303, 'training/walltime': 23191.909645318985, 'training/entropy_loss': Array(0.01718175, dtype=float32), 'training/policy_loss': Array(0.00844917, dtype=float32), 'training/total_loss': Array(0.1293023, dtype=float32), 'training/v_loss': Array(0.10367137, dtype=float32), 'eval/episode_distance_from_origin': Array(7531.16, dtype=float32), 'eval/episode_distance_reward': Array(37.066147, dtype=float32), 'eval/episode_forward_reward': Array(6177.6587, dtype=float32), 'eval/episode_reward': Array(6128.912, dtype=float32), 'eval/episode_reward_alive': Array(339.29688, dtype=float32), 'eval/episode_reward_linvel': Array(6177.6587, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.10904, dtype=float32), 'eval/episode_x_position': Array(7497.6416, dtype=float32), 'eval/episode_x_velocity': Array(1235.5317, dtype=float32), 'eval/episode_y_position': Array(-88.55524, dtype=float32), 'eval/episode_y_velocity': Array(-90.47104, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.54733, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2318993, dtype=float32), 'eval/episode_forward_reward_std': Array(1038.6418, dtype=float32), 'eval/episode_reward_std': Array(1091.8857, dtype=float32), 'eval/episode_reward_alive_std': Array(59.6332, dtype=float32), 'eval/episode_reward_linvel_std': Array(1038.6418, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.897575, dtype=float32), 'eval/episode_x_position_std': Array(487.72632, dtype=float32), 'eval/episode_x_velocity_std': Array(207.72842, dtype=float32), 'eval/episode_y_position_std': Array(299.86038, dtype=float32), 'eval/episode_y_velocity_std': Array(110.10173, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4094753265381, 'eval/sps': 938.3512376511425, 'num_steps': 68239360}
{'eval/walltime': 114019.93638968468, 'training/sps': 2945.2863858080414, 'training/walltime': 23219.7235789299, 'training/entropy_loss': Array(0.01951058, dtype=float32), 'training/policy_loss': Array(0.01313566, dtype=float32), 'training/total_loss': Array(0.35246795, dtype=float32), 'training/v_loss': Array(0.3198217, dtype=float32), 'eval/episode_distance_from_origin': Array(7488.413, dtype=float32), 'eval/episode_distance_reward': Array(36.862762, dtype=float32), 'eval/episode_forward_reward': Array(6143.76, dtype=float32), 'eval/episode_reward': Array(6091.488, dtype=float32), 'eval/episode_reward_alive': Array(339.5078, dtype=float32), 'eval/episode_reward_linvel': Array(6143.76, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.6419, dtype=float32), 'eval/episode_x_position': Array(7452.7285, dtype=float32), 'eval/episode_x_velocity': Array(1228.7517, dtype=float32), 'eval/episode_y_position': Array(-101.19542, dtype=float32), 'eval/episode_y_velocity': Array(-91.97793, dtype=float32), 'eval/episode_distance_from_origin_std': Array(566.2107, dtype=float32), 'eval/episode_distance_reward_std': Array(6.872597, dtype=float32), 'eval/episode_forward_reward_std': Array(1145.4241, dtype=float32), 'eval/episode_reward_std': Array(1212.6954, dtype=float32), 'eval/episode_reward_alive_std': Array(59.057537, dtype=float32), 'eval/episode_reward_linvel_std': Array(1145.4241, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.18699, dtype=float32), 'eval/episode_x_position_std': Array(566.0782, dtype=float32), 'eval/episode_x_velocity_std': Array(229.08492, dtype=float32), 'eval/episode_y_position_std': Array(331.10776, dtype=float32), 'eval/episode_y_velocity_std': Array(124.24239, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69543409347534, 'eval/sps': 936.3882623356006, 'num_steps': 68321280}
{'eval/walltime': 114156.33483958244, 'training/sps': 2950.8773656441176, 'training/walltime': 23247.484813928604, 'training/entropy_loss': Array(0.01961791, dtype=float32), 'training/policy_loss': Array(0.09481093, dtype=float32), 'training/total_loss': Array(0.35429102, dtype=float32), 'training/v_loss': Array(0.2398622, dtype=float32), 'eval/episode_distance_from_origin': Array(7643.8237, dtype=float32), 'eval/episode_distance_reward': Array(38.979645, dtype=float32), 'eval/episode_forward_reward': Array(6496.5728, dtype=float32), 'eval/episode_reward': Array(6493.04, dtype=float32), 'eval/episode_reward_alive': Array(379.17188, dtype=float32), 'eval/episode_reward_linvel': Array(6496.5728, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.6839, dtype=float32), 'eval/episode_x_position': Array(7604.6553, dtype=float32), 'eval/episode_x_velocity': Array(1299.3147, dtype=float32), 'eval/episode_y_position': Array(-195.33957, dtype=float32), 'eval/episode_y_velocity': Array(-133.12491, dtype=float32), 'eval/episode_distance_from_origin_std': Array(408.71097, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9402924, dtype=float32), 'eval/episode_forward_reward_std': Array(823.3775, dtype=float32), 'eval/episode_reward_std': Array(847.32153, dtype=float32), 'eval/episode_reward_alive_std': Array(50.54625, dtype=float32), 'eval/episode_reward_linvel_std': Array(823.3775, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.878036, dtype=float32), 'eval/episode_x_position_std': Array(408.0437, dtype=float32), 'eval/episode_x_velocity_std': Array(164.67543, dtype=float32), 'eval/episode_y_position_std': Array(314.811, dtype=float32), 'eval/episode_y_velocity_std': Array(110.992035, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3984498977661, 'eval/sps': 938.4270869349252, 'num_steps': 68403200}
{'eval/walltime': 114293.02993965149, 'training/sps': 2947.763126452263, 'training/walltime': 23275.275377988815, 'training/entropy_loss': Array(0.01878356, dtype=float32), 'training/policy_loss': Array(0.00621033, dtype=float32), 'training/total_loss': Array(0.26135123, dtype=float32), 'training/v_loss': Array(0.23635733, dtype=float32), 'eval/episode_distance_from_origin': Array(7689.8306, dtype=float32), 'eval/episode_distance_reward': Array(39.499878, dtype=float32), 'eval/episode_forward_reward': Array(6583.2783, dtype=float32), 'eval/episode_reward': Array(6583.908, dtype=float32), 'eval/episode_reward_alive': Array(375.6211, dtype=float32), 'eval/episode_reward_linvel': Array(6583.2783, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.49106, dtype=float32), 'eval/episode_x_position': Array(7652.61, dtype=float32), 'eval/episode_x_velocity': Array(1316.6555, dtype=float32), 'eval/episode_y_position': Array(-155.95514, dtype=float32), 'eval/episode_y_velocity': Array(-117.33127, dtype=float32), 'eval/episode_distance_from_origin_std': Array(477.56332, dtype=float32), 'eval/episode_distance_reward_std': Array(5.427207, dtype=float32), 'eval/episode_forward_reward_std': Array(904.52936, dtype=float32), 'eval/episode_reward_std': Array(923.19495, dtype=float32), 'eval/episode_reward_alive_std': Array(48.15254, dtype=float32), 'eval/episode_reward_linvel_std': Array(904.52936, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(20.94542, dtype=float32), 'eval/episode_x_position_std': Array(476.40518, dtype=float32), 'eval/episode_x_velocity_std': Array(180.90584, dtype=float32), 'eval/episode_y_position_std': Array(311.06516, dtype=float32), 'eval/episode_y_velocity_std': Array(112.908485, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69510006904602, 'eval/sps': 936.3905504684949, 'num_steps': 68485120}
{'eval/walltime': 114429.42700219154, 'training/sps': 2944.9052851767374, 'training/walltime': 23303.09291100502, 'training/entropy_loss': Array(0.01817477, dtype=float32), 'training/policy_loss': Array(0.00440842, dtype=float32), 'training/total_loss': Array(0.28550288, dtype=float32), 'training/v_loss': Array(0.26291966, dtype=float32), 'eval/episode_distance_from_origin': Array(7548.781, dtype=float32), 'eval/episode_distance_reward': Array(38.261147, dtype=float32), 'eval/episode_forward_reward': Array(6376.8247, dtype=float32), 'eval/episode_reward': Array(6378.753, dtype=float32), 'eval/episode_reward_alive': Array(380.35547, dtype=float32), 'eval/episode_reward_linvel': Array(6376.8247, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.6878, dtype=float32), 'eval/episode_x_position': Array(7508.8457, dtype=float32), 'eval/episode_x_velocity': Array(1275.365, dtype=float32), 'eval/episode_y_position': Array(-147.68594, dtype=float32), 'eval/episode_y_velocity': Array(-114.324875, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.01056, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1912384, dtype=float32), 'eval/episode_forward_reward_std': Array(865.2012, dtype=float32), 'eval/episode_reward_std': Array(877.1201, dtype=float32), 'eval/episode_reward_alive_std': Array(46.475555, dtype=float32), 'eval/episode_reward_linvel_std': Array(865.2012, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.759745, dtype=float32), 'eval/episode_x_position_std': Array(449.92322, dtype=float32), 'eval/episode_x_velocity_std': Array(173.04024, dtype=float32), 'eval/episode_y_position_std': Array(351.86832, dtype=float32), 'eval/episode_y_velocity_std': Array(126.44064, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.39706254005432, 'eval/sps': 938.4366321115717, 'num_steps': 68567040}
{'eval/walltime': 114566.12587332726, 'training/sps': 2938.6637925700143, 'training/walltime': 23330.969526290894, 'training/entropy_loss': Array(0.01531028, dtype=float32), 'training/policy_loss': Array(0.00327979, dtype=float32), 'training/total_loss': Array(0.14176549, dtype=float32), 'training/v_loss': Array(0.12317541, dtype=float32), 'eval/episode_distance_from_origin': Array(7662.964, dtype=float32), 'eval/episode_distance_reward': Array(39.643257, dtype=float32), 'eval/episode_forward_reward': Array(6607.1733, dtype=float32), 'eval/episode_reward': Array(6617.4395, dtype=float32), 'eval/episode_reward_alive': Array(390.08203, dtype=float32), 'eval/episode_reward_linvel': Array(6607.1733, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.45966, dtype=float32), 'eval/episode_x_position': Array(7624.8467, dtype=float32), 'eval/episode_x_velocity': Array(1321.4348, dtype=float32), 'eval/episode_y_position': Array(-153.68596, dtype=float32), 'eval/episode_y_velocity': Array(-115.79403, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.7736, dtype=float32), 'eval/episode_distance_reward_std': Array(5.785721, dtype=float32), 'eval/episode_forward_reward_std': Array(964.2812, dtype=float32), 'eval/episode_reward_std': Array(980.2035, dtype=float32), 'eval/episode_reward_alive_std': Array(42.569557, dtype=float32), 'eval/episode_reward_linvel_std': Array(964.2812, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.777706, dtype=float32), 'eval/episode_x_position_std': Array(475.791, dtype=float32), 'eval/episode_x_velocity_std': Array(192.85623, dtype=float32), 'eval/episode_y_position_std': Array(322.5851, dtype=float32), 'eval/episode_y_velocity_std': Array(121.54226, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.69887113571167, 'eval/sps': 936.364718571263, 'num_steps': 68648960}
{'eval/walltime': 114702.54669976234, 'training/sps': 2948.629410061351, 'training/walltime': 23358.751925706863, 'training/entropy_loss': Array(0.01656971, dtype=float32), 'training/policy_loss': Array(0.00677376, dtype=float32), 'training/total_loss': Array(0.08627024, dtype=float32), 'training/v_loss': Array(0.06292677, dtype=float32), 'eval/episode_distance_from_origin': Array(7679.531, dtype=float32), 'eval/episode_distance_reward': Array(39.783794, dtype=float32), 'eval/episode_forward_reward': Array(6630.5967, dtype=float32), 'eval/episode_reward': Array(6637.182, dtype=float32), 'eval/episode_reward_alive': Array(380.8711, dtype=float32), 'eval/episode_reward_linvel': Array(6630.5967, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.0692, dtype=float32), 'eval/episode_x_position': Array(7640.79, dtype=float32), 'eval/episode_x_velocity': Array(1326.1194, dtype=float32), 'eval/episode_y_position': Array(-202.6513, dtype=float32), 'eval/episode_y_velocity': Array(-127.794815, dtype=float32), 'eval/episode_distance_from_origin_std': Array(473.12097, dtype=float32), 'eval/episode_distance_reward_std': Array(5.833114, dtype=float32), 'eval/episode_forward_reward_std': Array(972.18024, dtype=float32), 'eval/episode_reward_std': Array(985.6391, dtype=float32), 'eval/episode_reward_alive_std': Array(45.835823, dtype=float32), 'eval/episode_reward_linvel_std': Array(972.18024, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.42247, dtype=float32), 'eval/episode_x_position_std': Array(470.8355, dtype=float32), 'eval/episode_x_velocity_std': Array(194.436, dtype=float32), 'eval/episode_y_position_std': Array(319.05545, dtype=float32), 'eval/episode_y_velocity_std': Array(115.33961, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4208264350891, 'eval/sps': 938.2731606665948, 'num_steps': 68730880}
{'eval/walltime': 114839.2771589756, 'training/sps': 2937.410224866022, 'training/walltime': 23386.640437602997, 'training/entropy_loss': Array(0.01845277, dtype=float32), 'training/policy_loss': Array(0.00469889, dtype=float32), 'training/total_loss': Array(0.33524197, dtype=float32), 'training/v_loss': Array(0.3120903, dtype=float32), 'eval/episode_distance_from_origin': Array(7714.088, dtype=float32), 'eval/episode_distance_reward': Array(39.486435, dtype=float32), 'eval/episode_forward_reward': Array(6581.037, dtype=float32), 'eval/episode_reward': Array(6587.4194, dtype=float32), 'eval/episode_reward_alive': Array(380.34766, dtype=float32), 'eval/episode_reward_linvel': Array(6581.037, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.45233, dtype=float32), 'eval/episode_x_position': Array(7674.6787, dtype=float32), 'eval/episode_x_velocity': Array(1316.2074, dtype=float32), 'eval/episode_y_position': Array(-212.86174, dtype=float32), 'eval/episode_y_velocity': Array(-138.35144, dtype=float32), 'eval/episode_distance_from_origin_std': Array(462.2092, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0565104, dtype=float32), 'eval/episode_forward_reward_std': Array(1009.41223, dtype=float32), 'eval/episode_reward_std': Array(1023.6712, dtype=float32), 'eval/episode_reward_alive_std': Array(47.879555, dtype=float32), 'eval/episode_reward_linvel_std': Array(1009.41223, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.04824, dtype=float32), 'eval/episode_x_position_std': Array(460.89096, dtype=float32), 'eval/episode_x_velocity_std': Array(201.88245, dtype=float32), 'eval/episode_y_position_std': Array(309.5071, dtype=float32), 'eval/episode_y_velocity_std': Array(110.377785, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.73045921325684, 'eval/sps': 936.1483954380637, 'num_steps': 68812800}
{'eval/walltime': 114975.61963582039, 'training/sps': 2945.195904291616, 'training/walltime': 23414.4552257061, 'training/entropy_loss': Array(0.01909836, dtype=float32), 'training/policy_loss': Array(0.0122311, dtype=float32), 'training/total_loss': Array(0.26396528, dtype=float32), 'training/v_loss': Array(0.23263583, dtype=float32), 'eval/episode_distance_from_origin': Array(7671.4854, dtype=float32), 'eval/episode_distance_reward': Array(38.93995, dtype=float32), 'eval/episode_forward_reward': Array(6489.957, dtype=float32), 'eval/episode_reward': Array(6495.414, dtype=float32), 'eval/episode_reward_alive': Array(379.4336, dtype=float32), 'eval/episode_reward_linvel': Array(6489.957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.91577, dtype=float32), 'eval/episode_x_position': Array(7634.756, dtype=float32), 'eval/episode_x_velocity': Array(1297.9915, dtype=float32), 'eval/episode_y_position': Array(-151.73964, dtype=float32), 'eval/episode_y_velocity': Array(-120.334305, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.72894, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8841777, dtype=float32), 'eval/episode_forward_reward_std': Array(980.6888, dtype=float32), 'eval/episode_reward_std': Array(1001.91516, dtype=float32), 'eval/episode_reward_alive_std': Array(52.001778, dtype=float32), 'eval/episode_reward_linvel_std': Array(980.6888, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.230427, dtype=float32), 'eval/episode_x_position_std': Array(471.50168, dtype=float32), 'eval/episode_x_velocity_std': Array(196.13782, dtype=float32), 'eval/episode_y_position_std': Array(319.96243, dtype=float32), 'eval/episode_y_velocity_std': Array(109.54165, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3424768447876, 'eval/sps': 938.8123419946032, 'num_steps': 68894720}
{'eval/walltime': 115111.76019525528, 'training/sps': 2938.9704762771357, 'training/walltime': 23442.32893204689, 'training/entropy_loss': Array(0.01913388, dtype=float32), 'training/policy_loss': Array(0.00406299, dtype=float32), 'training/total_loss': Array(0.24993731, dtype=float32), 'training/v_loss': Array(0.22674043, dtype=float32), 'eval/episode_distance_from_origin': Array(7698.1196, dtype=float32), 'eval/episode_distance_reward': Array(39.672783, dtype=float32), 'eval/episode_forward_reward': Array(6612.0947, dtype=float32), 'eval/episode_reward': Array(6611.1963, dtype=float32), 'eval/episode_reward_alive': Array(375.3828, dtype=float32), 'eval/episode_reward_linvel': Array(6612.0947, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.95453, dtype=float32), 'eval/episode_x_position': Array(7660.4336, dtype=float32), 'eval/episode_x_velocity': Array(1322.419, dtype=float32), 'eval/episode_y_position': Array(-163.14577, dtype=float32), 'eval/episode_y_velocity': Array(-127.38342, dtype=float32), 'eval/episode_distance_from_origin_std': Array(475.4449, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4773917, dtype=float32), 'eval/episode_forward_reward_std': Array(912.89276, dtype=float32), 'eval/episode_reward_std': Array(930.193, dtype=float32), 'eval/episode_reward_alive_std': Array(53.986378, dtype=float32), 'eval/episode_reward_linvel_std': Array(912.89276, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.587475, dtype=float32), 'eval/episode_x_position_std': Array(474.1304, dtype=float32), 'eval/episode_x_velocity_std': Array(182.57861, dtype=float32), 'eval/episode_y_position_std': Array(310.85574, dtype=float32), 'eval/episode_y_velocity_std': Array(116.50335, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.14055943489075, 'eval/sps': 940.2047452377043, 'num_steps': 68976640}
{'eval/walltime': 115248.0178847313, 'training/sps': 2949.5295484291673, 'training/walltime': 23470.10285282135, 'training/entropy_loss': Array(0.01943118, dtype=float32), 'training/policy_loss': Array(0.0053498, dtype=float32), 'training/total_loss': Array(0.26045755, dtype=float32), 'training/v_loss': Array(0.23567656, dtype=float32), 'eval/episode_distance_from_origin': Array(7643.073, dtype=float32), 'eval/episode_distance_reward': Array(38.76069, dtype=float32), 'eval/episode_forward_reward': Array(6460.081, dtype=float32), 'eval/episode_reward': Array(6463.7446, dtype=float32), 'eval/episode_reward_alive': Array(376.8125, dtype=float32), 'eval/episode_reward_linvel': Array(6460.081, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.90894, dtype=float32), 'eval/episode_x_position': Array(7605.2666, dtype=float32), 'eval/episode_x_velocity': Array(1292.0161, dtype=float32), 'eval/episode_y_position': Array(-194.7947, dtype=float32), 'eval/episode_y_velocity': Array(-124.33403, dtype=float32), 'eval/episode_distance_from_origin_std': Array(446.22174, dtype=float32), 'eval/episode_distance_reward_std': Array(5.509244, dtype=float32), 'eval/episode_forward_reward_std': Array(918.2018, dtype=float32), 'eval/episode_reward_std': Array(925.179, dtype=float32), 'eval/episode_reward_alive_std': Array(46.684402, dtype=float32), 'eval/episode_reward_linvel_std': Array(918.2018, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.332558, dtype=float32), 'eval/episode_x_position_std': Array(444.414, dtype=float32), 'eval/episode_x_velocity_std': Array(183.64018, dtype=float32), 'eval/episode_y_position_std': Array(300.30432, dtype=float32), 'eval/episode_y_velocity_std': Array(101.32483, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25768947601318, 'eval/sps': 939.3965250125068, 'num_steps': 69058560}
{'eval/walltime': 115384.22710847855, 'training/sps': 2949.046834627721, 'training/walltime': 23497.881319761276, 'training/entropy_loss': Array(0.01687833, dtype=float32), 'training/policy_loss': Array(0.00643387, dtype=float32), 'training/total_loss': Array(0.18487892, dtype=float32), 'training/v_loss': Array(0.1615667, dtype=float32), 'eval/episode_distance_from_origin': Array(7658.9473, dtype=float32), 'eval/episode_distance_reward': Array(38.72782, dtype=float32), 'eval/episode_forward_reward': Array(6454.602, dtype=float32), 'eval/episode_reward': Array(6455.342, dtype=float32), 'eval/episode_reward_alive': Array(374.28516, dtype=float32), 'eval/episode_reward_linvel': Array(6454.602, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.27505, dtype=float32), 'eval/episode_x_position': Array(7619.881, dtype=float32), 'eval/episode_x_velocity': Array(1290.9207, dtype=float32), 'eval/episode_y_position': Array(-211.99133, dtype=float32), 'eval/episode_y_velocity': Array(-121.8488, dtype=float32), 'eval/episode_distance_from_origin_std': Array(433.96167, dtype=float32), 'eval/episode_distance_reward_std': Array(5.949048, dtype=float32), 'eval/episode_forward_reward_std': Array(991.50085, dtype=float32), 'eval/episode_reward_std': Array(1008.4628, dtype=float32), 'eval/episode_reward_alive_std': Array(48.679382, dtype=float32), 'eval/episode_reward_linvel_std': Array(991.50085, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.258966, dtype=float32), 'eval/episode_x_position_std': Array(432.93423, dtype=float32), 'eval/episode_x_velocity_std': Array(198.30008, dtype=float32), 'eval/episode_y_position_std': Array(314.79443, dtype=float32), 'eval/episode_y_velocity_std': Array(121.97673, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20922374725342, 'eval/sps': 939.730779447901, 'num_steps': 69140480}
{'eval/walltime': 115520.50822997093, 'training/sps': 2962.2889612116687, 'training/walltime': 23525.535610437393, 'training/entropy_loss': Array(0.01534069, dtype=float32), 'training/policy_loss': Array(0.00668096, dtype=float32), 'training/total_loss': Array(0.05483037, dtype=float32), 'training/v_loss': Array(0.03280873, dtype=float32), 'eval/episode_distance_from_origin': Array(7721.1333, dtype=float32), 'eval/episode_distance_reward': Array(39.49686, dtype=float32), 'eval/episode_forward_reward': Array(6582.7754, dtype=float32), 'eval/episode_reward': Array(6574.665, dtype=float32), 'eval/episode_reward_alive': Array(364.53516, dtype=float32), 'eval/episode_reward_linvel': Array(6582.7754, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.14258, dtype=float32), 'eval/episode_x_position': Array(7683.047, dtype=float32), 'eval/episode_x_velocity': Array(1316.5552, dtype=float32), 'eval/episode_y_position': Array(-209.27203, dtype=float32), 'eval/episode_y_velocity': Array(-142.44719, dtype=float32), 'eval/episode_distance_from_origin_std': Array(444.43243, dtype=float32), 'eval/episode_distance_reward_std': Array(5.493248, dtype=float32), 'eval/episode_forward_reward_std': Array(915.53516, dtype=float32), 'eval/episode_reward_std': Array(935.2104, dtype=float32), 'eval/episode_reward_alive_std': Array(54.57697, dtype=float32), 'eval/episode_reward_linvel_std': Array(915.53516, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.361444, dtype=float32), 'eval/episode_x_position_std': Array(442.72015, dtype=float32), 'eval/episode_x_velocity_std': Array(183.10698, dtype=float32), 'eval/episode_y_position_std': Array(275.06702, dtype=float32), 'eval/episode_y_velocity_std': Array(97.01099, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28112149238586, 'eval/sps': 939.2350062745224, 'num_steps': 69222400}
{'eval/walltime': 115656.71245241165, 'training/sps': 2972.3829496137373, 'training/walltime': 23553.095989227295, 'training/entropy_loss': Array(0.01775181, dtype=float32), 'training/policy_loss': Array(0.0069547, dtype=float32), 'training/total_loss': Array(0.23603997, dtype=float32), 'training/v_loss': Array(0.21133345, dtype=float32), 'eval/episode_distance_from_origin': Array(7709.1777, dtype=float32), 'eval/episode_distance_reward': Array(39.26688, dtype=float32), 'eval/episode_forward_reward': Array(6544.4463, dtype=float32), 'eval/episode_reward': Array(6541.0137, dtype=float32), 'eval/episode_reward_alive': Array(370.79688, dtype=float32), 'eval/episode_reward_linvel': Array(6544.4463, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.4957, dtype=float32), 'eval/episode_x_position': Array(7670.8784, dtype=float32), 'eval/episode_x_velocity': Array(1308.8892, dtype=float32), 'eval/episode_y_position': Array(-182.69489, dtype=float32), 'eval/episode_y_velocity': Array(-120.01788, dtype=float32), 'eval/episode_distance_from_origin_std': Array(475.38937, dtype=float32), 'eval/episode_distance_reward_std': Array(6.185798, dtype=float32), 'eval/episode_forward_reward_std': Array(1030.9586, dtype=float32), 'eval/episode_reward_std': Array(1052.942, dtype=float32), 'eval/episode_reward_alive_std': Array(52.317665, dtype=float32), 'eval/episode_reward_linvel_std': Array(1030.9586, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.015854, dtype=float32), 'eval/episode_x_position_std': Array(473.23755, dtype=float32), 'eval/episode_x_velocity_std': Array(206.19182, dtype=float32), 'eval/episode_y_position_std': Array(313.17822, dtype=float32), 'eval/episode_y_velocity_std': Array(123.9868, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2042224407196, 'eval/sps': 939.765285585839, 'num_steps': 69304320}
{'eval/walltime': 115792.98359489441, 'training/sps': 2951.278239861434, 'training/walltime': 23580.85345339775, 'training/entropy_loss': Array(0.01935751, dtype=float32), 'training/policy_loss': Array(0.00510686, dtype=float32), 'training/total_loss': Array(0.3473523, dtype=float32), 'training/v_loss': Array(0.3228879, dtype=float32), 'eval/episode_distance_from_origin': Array(7677.286, dtype=float32), 'eval/episode_distance_reward': Array(38.92819, dtype=float32), 'eval/episode_forward_reward': Array(6487.997, dtype=float32), 'eval/episode_reward': Array(6488.0522, dtype=float32), 'eval/episode_reward_alive': Array(367.1953, dtype=float32), 'eval/episode_reward_linvel': Array(6487.997, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.0686, dtype=float32), 'eval/episode_x_position': Array(7640.6504, dtype=float32), 'eval/episode_x_velocity': Array(1297.5994, dtype=float32), 'eval/episode_y_position': Array(-168.24176, dtype=float32), 'eval/episode_y_velocity': Array(-129.83063, dtype=float32), 'eval/episode_distance_from_origin_std': Array(532.5619, dtype=float32), 'eval/episode_distance_reward_std': Array(6.445227, dtype=float32), 'eval/episode_forward_reward_std': Array(1074.1959, dtype=float32), 'eval/episode_reward_std': Array(1088.061, dtype=float32), 'eval/episode_reward_alive_std': Array(49.256275, dtype=float32), 'eval/episode_reward_linvel_std': Array(1074.1959, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.087784, dtype=float32), 'eval/episode_x_position_std': Array(530.21985, dtype=float32), 'eval/episode_x_velocity_std': Array(214.83931, dtype=float32), 'eval/episode_y_position_std': Array(297.10547, dtype=float32), 'eval/episode_y_velocity_std': Array(110.34615, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27114248275757, 'eval/sps': 939.3037855846544, 'num_steps': 69386240}
{'eval/walltime': 115929.18726181984, 'training/sps': 2946.837174685481, 'training/walltime': 23608.65274977684, 'training/entropy_loss': Array(0.01875288, dtype=float32), 'training/policy_loss': Array(0.0067946, dtype=float32), 'training/total_loss': Array(0.27390438, dtype=float32), 'training/v_loss': Array(0.2483569, dtype=float32), 'eval/episode_distance_from_origin': Array(7758.7393, dtype=float32), 'eval/episode_distance_reward': Array(39.71099, dtype=float32), 'eval/episode_forward_reward': Array(6618.464, dtype=float32), 'eval/episode_reward': Array(6616.4287, dtype=float32), 'eval/episode_reward_alive': Array(369.5586, dtype=float32), 'eval/episode_reward_linvel': Array(6618.464, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.30402, dtype=float32), 'eval/episode_x_position': Array(7722.119, dtype=float32), 'eval/episode_x_velocity': Array(1323.6926, dtype=float32), 'eval/episode_y_position': Array(-139.66489, dtype=float32), 'eval/episode_y_velocity': Array(-119.29648, dtype=float32), 'eval/episode_distance_from_origin_std': Array(432.27216, dtype=float32), 'eval/episode_distance_reward_std': Array(5.315053, dtype=float32), 'eval/episode_forward_reward_std': Array(885.8369, dtype=float32), 'eval/episode_reward_std': Array(907.5456, dtype=float32), 'eval/episode_reward_alive_std': Array(49.340916, dtype=float32), 'eval/episode_reward_linvel_std': Array(885.8369, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.07924, dtype=float32), 'eval/episode_x_position_std': Array(430.84937, dtype=float32), 'eval/episode_x_velocity_std': Array(177.16733, dtype=float32), 'eval/episode_y_position_std': Array(316.9221, dtype=float32), 'eval/episode_y_velocity_std': Array(111.00144, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2036669254303, 'eval/sps': 939.7691184781266, 'num_steps': 69468160}
{'eval/walltime': 116065.44562792778, 'training/sps': 2949.6903108923434, 'training/walltime': 23636.42515683174, 'training/entropy_loss': Array(0.01872857, dtype=float32), 'training/policy_loss': Array(0.00824342, dtype=float32), 'training/total_loss': Array(0.25699985, dtype=float32), 'training/v_loss': Array(0.23002785, dtype=float32), 'eval/episode_distance_from_origin': Array(7811.762, dtype=float32), 'eval/episode_distance_reward': Array(40.129997, dtype=float32), 'eval/episode_forward_reward': Array(6688.297, dtype=float32), 'eval/episode_reward': Array(6690.823, dtype=float32), 'eval/episode_reward_alive': Array(374.53125, dtype=float32), 'eval/episode_reward_linvel': Array(6688.297, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.13483, dtype=float32), 'eval/episode_x_position': Array(7773.8022, dtype=float32), 'eval/episode_x_velocity': Array(1337.6594, dtype=float32), 'eval/episode_y_position': Array(-170.6224, dtype=float32), 'eval/episode_y_velocity': Array(-124.56967, dtype=float32), 'eval/episode_distance_from_origin_std': Array(408.49765, dtype=float32), 'eval/episode_distance_reward_std': Array(5.209251, dtype=float32), 'eval/episode_forward_reward_std': Array(868.20337, dtype=float32), 'eval/episode_reward_std': Array(890.4256, dtype=float32), 'eval/episode_reward_alive_std': Array(46.305447, dtype=float32), 'eval/episode_reward_linvel_std': Array(868.20337, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.968157, dtype=float32), 'eval/episode_x_position_std': Array(407.27625, dtype=float32), 'eval/episode_x_velocity_std': Array(173.64049, dtype=float32), 'eval/episode_y_position_std': Array(326.25592, dtype=float32), 'eval/episode_y_velocity_std': Array(120.9048, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25836610794067, 'eval/sps': 939.3918601563255, 'num_steps': 69550080}
{'eval/walltime': 116202.0636985302, 'training/sps': 2955.5987723126827, 'training/walltime': 23664.14204478264, 'training/entropy_loss': Array(0.0191085, dtype=float32), 'training/policy_loss': Array(0.10907756, dtype=float32), 'training/total_loss': Array(0.3405562, dtype=float32), 'training/v_loss': Array(0.21237016, dtype=float32), 'eval/episode_distance_from_origin': Array(7738.6436, dtype=float32), 'eval/episode_distance_reward': Array(39.400917, dtype=float32), 'eval/episode_forward_reward': Array(6566.786, dtype=float32), 'eval/episode_reward': Array(6558.5156, dtype=float32), 'eval/episode_reward_alive': Array(356.64453, dtype=float32), 'eval/episode_reward_linvel': Array(6566.786, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.31567, dtype=float32), 'eval/episode_x_position': Array(7702.875, dtype=float32), 'eval/episode_x_velocity': Array(1313.357, dtype=float32), 'eval/episode_y_position': Array(-76.49368, dtype=float32), 'eval/episode_y_velocity': Array(-100.8109, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.47507, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7654967, dtype=float32), 'eval/episode_forward_reward_std': Array(960.9091, dtype=float32), 'eval/episode_reward_std': Array(974.8924, dtype=float32), 'eval/episode_reward_alive_std': Array(52.474514, dtype=float32), 'eval/episode_reward_linvel_std': Array(960.9091, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.648115, dtype=float32), 'eval/episode_x_position_std': Array(444.0519, dtype=float32), 'eval/episode_x_velocity_std': Array(192.18185, dtype=float32), 'eval/episode_y_position_std': Array(320.155, dtype=float32), 'eval/episode_y_velocity_std': Array(123.70891, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.618070602417, 'eval/sps': 936.9185162371593, 'num_steps': 69632000}
{'eval/walltime': 116338.52356266975, 'training/sps': 2974.850243417936, 'training/walltime': 23691.679565429688, 'training/entropy_loss': Array(0.01339631, dtype=float32), 'training/policy_loss': Array(0.00459302, dtype=float32), 'training/total_loss': Array(0.03765017, dtype=float32), 'training/v_loss': Array(0.01966083, dtype=float32), 'eval/episode_distance_from_origin': Array(7773.994, dtype=float32), 'eval/episode_distance_reward': Array(39.989624, dtype=float32), 'eval/episode_forward_reward': Array(6664.904, dtype=float32), 'eval/episode_reward': Array(6664.624, dtype=float32), 'eval/episode_reward_alive': Array(366.6211, dtype=float32), 'eval/episode_reward_linvel': Array(6664.904, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.89023, dtype=float32), 'eval/episode_x_position': Array(7736.749, dtype=float32), 'eval/episode_x_velocity': Array(1332.9807, dtype=float32), 'eval/episode_y_position': Array(-58.58277, dtype=float32), 'eval/episode_y_velocity': Array(-99.06284, dtype=float32), 'eval/episode_distance_from_origin_std': Array(448.86853, dtype=float32), 'eval/episode_distance_reward_std': Array(5.480801, dtype=float32), 'eval/episode_forward_reward_std': Array(913.46124, dtype=float32), 'eval/episode_reward_std': Array(931.215, dtype=float32), 'eval/episode_reward_alive_std': Array(47.78548, dtype=float32), 'eval/episode_reward_linvel_std': Array(913.46124, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.183771, dtype=float32), 'eval/episode_x_position_std': Array(449.31714, dtype=float32), 'eval/episode_x_velocity_std': Array(182.69225, dtype=float32), 'eval/episode_y_position_std': Array(359.5813, dtype=float32), 'eval/episode_y_velocity_std': Array(122.69206, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45986413955688, 'eval/sps': 938.0047445239647, 'num_steps': 69713920}
{'eval/walltime': 116475.08571839333, 'training/sps': 2965.4997098819877, 'training/walltime': 23719.303914785385, 'training/entropy_loss': Array(0.01673343, dtype=float32), 'training/policy_loss': Array(0.00842909, dtype=float32), 'training/total_loss': Array(0.18103835, dtype=float32), 'training/v_loss': Array(0.15587582, dtype=float32), 'eval/episode_distance_from_origin': Array(7807.0586, dtype=float32), 'eval/episode_distance_reward': Array(40.075417, dtype=float32), 'eval/episode_forward_reward': Array(6679.202, dtype=float32), 'eval/episode_reward': Array(6679.2236, dtype=float32), 'eval/episode_reward_alive': Array(366.61328, dtype=float32), 'eval/episode_reward_linvel': Array(6679.202, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.6673, dtype=float32), 'eval/episode_x_position': Array(7770.696, dtype=float32), 'eval/episode_x_velocity': Array(1335.8405, dtype=float32), 'eval/episode_y_position': Array(-108.72031, dtype=float32), 'eval/episode_y_velocity': Array(-113.470665, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.1625, dtype=float32), 'eval/episode_distance_reward_std': Array(5.690308, dtype=float32), 'eval/episode_forward_reward_std': Array(948.37775, dtype=float32), 'eval/episode_reward_std': Array(971.0892, dtype=float32), 'eval/episode_reward_alive_std': Array(49.332108, dtype=float32), 'eval/episode_reward_linvel_std': Array(948.37775, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.117424, dtype=float32), 'eval/episode_x_position_std': Array(448.8577, dtype=float32), 'eval/episode_x_velocity_std': Array(189.6756, dtype=float32), 'eval/episode_y_position_std': Array(315.25693, dtype=float32), 'eval/episode_y_velocity_std': Array(112.5118, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56215572357178, 'eval/sps': 937.3021341219654, 'num_steps': 69795840}
{'eval/walltime': 116611.34284806252, 'training/sps': 2977.059491069191, 'training/walltime': 23746.821000099182, 'training/entropy_loss': Array(0.01886676, dtype=float32), 'training/policy_loss': Array(0.00821679, dtype=float32), 'training/total_loss': Array(0.34948516, dtype=float32), 'training/v_loss': Array(0.32240164, dtype=float32), 'eval/episode_distance_from_origin': Array(7793.006, dtype=float32), 'eval/episode_distance_reward': Array(40.22036, dtype=float32), 'eval/episode_forward_reward': Array(6703.3584, dtype=float32), 'eval/episode_reward': Array(6704.5415, dtype=float32), 'eval/episode_reward_alive': Array(369.6172, dtype=float32), 'eval/episode_reward_linvel': Array(6703.3584, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.65512, dtype=float32), 'eval/episode_x_position': Array(7755.204, dtype=float32), 'eval/episode_x_velocity': Array(1340.6718, dtype=float32), 'eval/episode_y_position': Array(-98.51729, dtype=float32), 'eval/episode_y_velocity': Array(-104.365555, dtype=float32), 'eval/episode_distance_from_origin_std': Array(445.6172, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0744267, dtype=float32), 'eval/episode_forward_reward_std': Array(1012.39923, dtype=float32), 'eval/episode_reward_std': Array(1037.767, dtype=float32), 'eval/episode_reward_alive_std': Array(46.900055, dtype=float32), 'eval/episode_reward_linvel_std': Array(1012.39923, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.687458, dtype=float32), 'eval/episode_x_position_std': Array(448.37357, dtype=float32), 'eval/episode_x_velocity_std': Array(202.47987, dtype=float32), 'eval/episode_y_position_std': Array(337.76733, dtype=float32), 'eval/episode_y_velocity_std': Array(133.9735, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25712966918945, 'eval/sps': 939.4003844845664, 'num_steps': 69877760}
{'eval/walltime': 116747.84047722816, 'training/sps': 2941.335479029364, 'training/walltime': 23774.67229437828, 'training/entropy_loss': Array(0.01932404, dtype=float32), 'training/policy_loss': Array(0.00474684, dtype=float32), 'training/total_loss': Array(0.26936606, dtype=float32), 'training/v_loss': Array(0.24529517, dtype=float32), 'eval/episode_distance_from_origin': Array(7861.4355, dtype=float32), 'eval/episode_distance_reward': Array(40.921463, dtype=float32), 'eval/episode_forward_reward': Array(6820.2095, dtype=float32), 'eval/episode_reward': Array(6817.4478, dtype=float32), 'eval/episode_reward_alive': Array(360.96484, dtype=float32), 'eval/episode_reward_linvel': Array(6820.2095, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.64905, dtype=float32), 'eval/episode_x_position': Array(7824.691, dtype=float32), 'eval/episode_x_velocity': Array(1364.042, dtype=float32), 'eval/episode_y_position': Array(-126.93904, dtype=float32), 'eval/episode_y_velocity': Array(-113.01869, dtype=float32), 'eval/episode_distance_from_origin_std': Array(424.43628, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6224675, dtype=float32), 'eval/episode_forward_reward_std': Array(937.072, dtype=float32), 'eval/episode_reward_std': Array(953.6495, dtype=float32), 'eval/episode_reward_alive_std': Array(50.92508, dtype=float32), 'eval/episode_reward_linvel_std': Array(937.072, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.507406, dtype=float32), 'eval/episode_x_position_std': Array(423.23993, dtype=float32), 'eval/episode_x_velocity_std': Array(187.41463, dtype=float32), 'eval/episode_y_position_std': Array(314.9334, dtype=float32), 'eval/episode_y_velocity_std': Array(116.085304, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4976291656494, 'eval/sps': 937.7452251911501, 'num_steps': 69959680}
{'eval/walltime': 116884.10800933838, 'training/sps': 2953.1841091906713, 'training/walltime': 23802.411844968796, 'training/entropy_loss': Array(0.01920453, dtype=float32), 'training/policy_loss': Array(0.00785497, dtype=float32), 'training/total_loss': Array(0.25075635, dtype=float32), 'training/v_loss': Array(0.22369684, dtype=float32), 'eval/episode_distance_from_origin': Array(7822.76, dtype=float32), 'eval/episode_distance_reward': Array(40.800694, dtype=float32), 'eval/episode_forward_reward': Array(6800.079, dtype=float32), 'eval/episode_reward': Array(6796.8516, dtype=float32), 'eval/episode_reward_alive': Array(361.20703, dtype=float32), 'eval/episode_reward_linvel': Array(6800.079, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.23557, dtype=float32), 'eval/episode_x_position': Array(7786.076, dtype=float32), 'eval/episode_x_velocity': Array(1360.0159, dtype=float32), 'eval/episode_y_position': Array(-85.83387, dtype=float32), 'eval/episode_y_velocity': Array(-105.5585, dtype=float32), 'eval/episode_distance_from_origin_std': Array(474.7638, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9427404, dtype=float32), 'eval/episode_forward_reward_std': Array(990.4509, dtype=float32), 'eval/episode_reward_std': Array(1017.27924, dtype=float32), 'eval/episode_reward_alive_std': Array(47.332005, dtype=float32), 'eval/episode_reward_linvel_std': Array(990.4509, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.034153, dtype=float32), 'eval/episode_x_position_std': Array(475.1956, dtype=float32), 'eval/episode_x_velocity_std': Array(198.09018, dtype=float32), 'eval/episode_y_position_std': Array(323.32352, dtype=float32), 'eval/episode_y_velocity_std': Array(122.00527, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26753211021423, 'eval/sps': 939.328672192233, 'num_steps': 70041600}
{'eval/walltime': 117020.57580208778, 'training/sps': 2943.35541903228, 'training/walltime': 23830.244025707245, 'training/entropy_loss': Array(0.01971335, dtype=float32), 'training/policy_loss': Array(0.00815883, dtype=float32), 'training/total_loss': Array(0.26010913, dtype=float32), 'training/v_loss': Array(0.23223695, dtype=float32), 'eval/episode_distance_from_origin': Array(7850.836, dtype=float32), 'eval/episode_distance_reward': Array(40.471214, dtype=float32), 'eval/episode_forward_reward': Array(6745.166, dtype=float32), 'eval/episode_reward': Array(6747.9507, dtype=float32), 'eval/episode_reward_alive': Array(367.19922, dtype=float32), 'eval/episode_reward_linvel': Array(6745.166, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.8861, dtype=float32), 'eval/episode_x_position': Array(7813.337, dtype=float32), 'eval/episode_x_velocity': Array(1349.0332, dtype=float32), 'eval/episode_y_position': Array(-90.03879, dtype=float32), 'eval/episode_y_velocity': Array(-112.01189, dtype=float32), 'eval/episode_distance_from_origin_std': Array(425.9455, dtype=float32), 'eval/episode_distance_reward_std': Array(5.497238, dtype=float32), 'eval/episode_forward_reward_std': Array(916.20074, dtype=float32), 'eval/episode_reward_std': Array(933.375, dtype=float32), 'eval/episode_reward_alive_std': Array(49.961636, dtype=float32), 'eval/episode_reward_linvel_std': Array(916.20074, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.178656, dtype=float32), 'eval/episode_x_position_std': Array(424.2732, dtype=float32), 'eval/episode_x_velocity_std': Array(183.2402, dtype=float32), 'eval/episode_y_position_std': Array(324.83786, dtype=float32), 'eval/episode_y_velocity_std': Array(123.39094, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4677927494049, 'eval/sps': 937.9502476093076, 'num_steps': 70123520}
{'eval/walltime': 117156.8607866764, 'training/sps': 2952.063017437074, 'training/walltime': 23857.994110822678, 'training/entropy_loss': Array(0.01422916, dtype=float32), 'training/policy_loss': Array(0.01015026, dtype=float32), 'training/total_loss': Array(0.0863279, dtype=float32), 'training/v_loss': Array(0.06194848, dtype=float32), 'eval/episode_distance_from_origin': Array(7764.32, dtype=float32), 'eval/episode_distance_reward': Array(39.923607, dtype=float32), 'eval/episode_forward_reward': Array(6653.8994, dtype=float32), 'eval/episode_reward': Array(6658.8, dtype=float32), 'eval/episode_reward_alive': Array(371.46094, dtype=float32), 'eval/episode_reward_linvel': Array(6653.8994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-406.48508, dtype=float32), 'eval/episode_x_position': Array(7727.531, dtype=float32), 'eval/episode_x_velocity': Array(1330.7799, dtype=float32), 'eval/episode_y_position': Array(-122.35602, dtype=float32), 'eval/episode_y_velocity': Array(-124.68359, dtype=float32), 'eval/episode_distance_from_origin_std': Array(501.6761, dtype=float32), 'eval/episode_distance_reward_std': Array(6.9517703, dtype=float32), 'eval/episode_forward_reward_std': Array(1158.6205, dtype=float32), 'eval/episode_reward_std': Array(1183.087, dtype=float32), 'eval/episode_reward_alive_std': Array(50.485092, dtype=float32), 'eval/episode_reward_linvel_std': Array(1158.6205, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.850178, dtype=float32), 'eval/episode_x_position_std': Array(502.39075, dtype=float32), 'eval/episode_x_velocity_std': Array(231.72429, dtype=float32), 'eval/episode_y_position_std': Array(290.93698, dtype=float32), 'eval/episode_y_velocity_std': Array(118.04719, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28498458862305, 'eval/sps': 939.2083829804778, 'num_steps': 70205440}
{'eval/walltime': 117293.32082462311, 'training/sps': 2950.961100222178, 'training/walltime': 23885.754558086395, 'training/entropy_loss': Array(0.01650147, dtype=float32), 'training/policy_loss': Array(0.01233069, dtype=float32), 'training/total_loss': Array(0.08340801, dtype=float32), 'training/v_loss': Array(0.05457585, dtype=float32), 'eval/episode_distance_from_origin': Array(7718.793, dtype=float32), 'eval/episode_distance_reward': Array(38.83056, dtype=float32), 'eval/episode_forward_reward': Array(6471.727, dtype=float32), 'eval/episode_reward': Array(6471.728, dtype=float32), 'eval/episode_reward_alive': Array(365.78125, dtype=float32), 'eval/episode_reward_linvel': Array(6471.727, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.61053, dtype=float32), 'eval/episode_x_position': Array(7681.5664, dtype=float32), 'eval/episode_x_velocity': Array(1294.3452, dtype=float32), 'eval/episode_y_position': Array(-67.20106, dtype=float32), 'eval/episode_y_velocity': Array(-101.8492, dtype=float32), 'eval/episode_distance_from_origin_std': Array(419.476, dtype=float32), 'eval/episode_distance_reward_std': Array(5.732996, dtype=float32), 'eval/episode_forward_reward_std': Array(955.4933, dtype=float32), 'eval/episode_reward_std': Array(975.3937, dtype=float32), 'eval/episode_reward_alive_std': Array(51.392475, dtype=float32), 'eval/episode_reward_linvel_std': Array(955.4933, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.461704, dtype=float32), 'eval/episode_x_position_std': Array(419.01428, dtype=float32), 'eval/episode_x_velocity_std': Array(191.09862, dtype=float32), 'eval/episode_y_position_std': Array(332.2692, dtype=float32), 'eval/episode_y_velocity_std': Array(119.72042, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46003794670105, 'eval/sps': 938.0035498011117, 'num_steps': 70287360}
{'eval/walltime': 117429.58425211906, 'training/sps': 2950.978790520109, 'training/walltime': 23913.514838933945, 'training/entropy_loss': Array(0.01770901, dtype=float32), 'training/policy_loss': Array(0.00682893, dtype=float32), 'training/total_loss': Array(0.34685418, dtype=float32), 'training/v_loss': Array(0.32231623, dtype=float32), 'eval/episode_distance_from_origin': Array(7674.8867, dtype=float32), 'eval/episode_distance_reward': Array(38.659832, dtype=float32), 'eval/episode_forward_reward': Array(6443.271, dtype=float32), 'eval/episode_reward': Array(6442.1973, dtype=float32), 'eval/episode_reward_alive': Array(363.97266, dtype=float32), 'eval/episode_reward_linvel': Array(6443.271, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.7066, dtype=float32), 'eval/episode_x_position': Array(7635.913, dtype=float32), 'eval/episode_x_velocity': Array(1288.6539, dtype=float32), 'eval/episode_y_position': Array(-153.44377, dtype=float32), 'eval/episode_y_velocity': Array(-131.30704, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.12625, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2035704, dtype=float32), 'eval/episode_forward_reward_std': Array(867.2549, dtype=float32), 'eval/episode_reward_std': Array(879.0509, dtype=float32), 'eval/episode_reward_alive_std': Array(48.956703, dtype=float32), 'eval/episode_reward_linvel_std': Array(867.2549, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.631317, dtype=float32), 'eval/episode_x_position_std': Array(464.93735, dtype=float32), 'eval/episode_x_velocity_std': Array(173.45085, dtype=float32), 'eval/episode_y_position_std': Array(331.1977, dtype=float32), 'eval/episode_y_velocity_std': Array(111.83666, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26342749595642, 'eval/sps': 939.3569672522611, 'num_steps': 70369280}
{'eval/walltime': 117566.15575909615, 'training/sps': 2937.020941759859, 'training/walltime': 23941.40704727173, 'training/entropy_loss': Array(0.01907539, dtype=float32), 'training/policy_loss': Array(0.00656437, dtype=float32), 'training/total_loss': Array(0.28543186, dtype=float32), 'training/v_loss': Array(0.2597921, dtype=float32), 'eval/episode_distance_from_origin': Array(7752.54, dtype=float32), 'eval/episode_distance_reward': Array(39.40821, dtype=float32), 'eval/episode_forward_reward': Array(6568.002, dtype=float32), 'eval/episode_reward': Array(6565.5547, dtype=float32), 'eval/episode_reward_alive': Array(362.375, dtype=float32), 'eval/episode_reward_linvel': Array(6568.002, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.23004, dtype=float32), 'eval/episode_x_position': Array(7716.1343, dtype=float32), 'eval/episode_x_velocity': Array(1313.6003, dtype=float32), 'eval/episode_y_position': Array(-99.769005, dtype=float32), 'eval/episode_y_velocity': Array(-111.53183, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.0732, dtype=float32), 'eval/episode_distance_reward_std': Array(5.569462, dtype=float32), 'eval/episode_forward_reward_std': Array(928.2385, dtype=float32), 'eval/episode_reward_std': Array(948.59796, dtype=float32), 'eval/episode_reward_alive_std': Array(51.430096, dtype=float32), 'eval/episode_reward_linvel_std': Array(928.2385, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.200073, dtype=float32), 'eval/episode_x_position_std': Array(455.95416, dtype=float32), 'eval/episode_x_velocity_std': Array(185.64755, dtype=float32), 'eval/episode_y_position_std': Array(324.31686, dtype=float32), 'eval/episode_y_velocity_std': Array(112.14781, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5715069770813, 'eval/sps': 937.2379556555693, 'num_steps': 70451200}
{'eval/walltime': 117702.38272953033, 'training/sps': 2956.4787498632318, 'training/walltime': 23969.11568546295, 'training/entropy_loss': Array(0.0183087, dtype=float32), 'training/policy_loss': Array(0.00499159, dtype=float32), 'training/total_loss': Array(0.28168285, dtype=float32), 'training/v_loss': Array(0.25838256, dtype=float32), 'eval/episode_distance_from_origin': Array(7761.3364, dtype=float32), 'eval/episode_distance_reward': Array(39.500793, dtype=float32), 'eval/episode_forward_reward': Array(6583.431, dtype=float32), 'eval/episode_reward': Array(6575.748, dtype=float32), 'eval/episode_reward_alive': Array(357.5078, dtype=float32), 'eval/episode_reward_linvel': Array(6583.431, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.6918, dtype=float32), 'eval/episode_x_position': Array(7723.4355, dtype=float32), 'eval/episode_x_velocity': Array(1316.686, dtype=float32), 'eval/episode_y_position': Array(-169.93015, dtype=float32), 'eval/episode_y_velocity': Array(-130.53445, dtype=float32), 'eval/episode_distance_from_origin_std': Array(379.68408, dtype=float32), 'eval/episode_distance_reward_std': Array(4.992963, dtype=float32), 'eval/episode_forward_reward_std': Array(832.15533, dtype=float32), 'eval/episode_reward_std': Array(850.953, dtype=float32), 'eval/episode_reward_alive_std': Array(47.513565, dtype=float32), 'eval/episode_reward_linvel_std': Array(832.15533, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.857296, dtype=float32), 'eval/episode_x_position_std': Array(379.5861, dtype=float32), 'eval/episode_x_velocity_std': Array(166.43112, dtype=float32), 'eval/episode_y_position_std': Array(301.7381, dtype=float32), 'eval/episode_y_velocity_std': Array(101.83117, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22697043418884, 'eval/sps': 939.6083579634234, 'num_steps': 70533120}
{'eval/walltime': 117838.56635951996, 'training/sps': 2938.758196373201, 'training/walltime': 23996.991405248642, 'training/entropy_loss': Array(0.01790414, dtype=float32), 'training/policy_loss': Array(0.00625197, dtype=float32), 'training/total_loss': Array(0.26461726, dtype=float32), 'training/v_loss': Array(0.24046117, dtype=float32), 'eval/episode_distance_from_origin': Array(7733.592, dtype=float32), 'eval/episode_distance_reward': Array(39.486702, dtype=float32), 'eval/episode_forward_reward': Array(6581.082, dtype=float32), 'eval/episode_reward': Array(6585.372, dtype=float32), 'eval/episode_reward_alive': Array(365.32812, dtype=float32), 'eval/episode_reward_linvel': Array(6581.082, dtype=float32), 'eval/episode_reward_quadctrl': Array(-400.52545, dtype=float32), 'eval/episode_x_position': Array(7696.291, dtype=float32), 'eval/episode_x_velocity': Array(1316.2166, dtype=float32), 'eval/episode_y_position': Array(-133.26337, dtype=float32), 'eval/episode_y_velocity': Array(-111.783295, dtype=float32), 'eval/episode_distance_from_origin_std': Array(442.4025, dtype=float32), 'eval/episode_distance_reward_std': Array(5.586608, dtype=float32), 'eval/episode_forward_reward_std': Array(931.0952, dtype=float32), 'eval/episode_reward_std': Array(941.0378, dtype=float32), 'eval/episode_reward_alive_std': Array(47.255886, dtype=float32), 'eval/episode_reward_linvel_std': Array(931.0952, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.483307, dtype=float32), 'eval/episode_x_position_std': Array(441.1251, dtype=float32), 'eval/episode_x_velocity_std': Array(186.21907, dtype=float32), 'eval/episode_y_position_std': Array(312.64816, dtype=float32), 'eval/episode_y_velocity_std': Array(121.099525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.18362998962402, 'eval/sps': 939.9073883531556, 'num_steps': 70615040}
{'eval/walltime': 117974.79896330833, 'training/sps': 2957.039302269043, 'training/walltime': 24024.69479084015, 'training/entropy_loss': Array(0.01508793, dtype=float32), 'training/policy_loss': Array(0.00601104, dtype=float32), 'training/total_loss': Array(0.12760326, dtype=float32), 'training/v_loss': Array(0.1065043, dtype=float32), 'eval/episode_distance_from_origin': Array(7776.3955, dtype=float32), 'eval/episode_distance_reward': Array(40.27477, dtype=float32), 'eval/episode_forward_reward': Array(6712.4253, dtype=float32), 'eval/episode_reward': Array(6711.0557, dtype=float32), 'eval/episode_reward_alive': Array(363.10547, dtype=float32), 'eval/episode_reward_linvel': Array(6712.4253, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.7495, dtype=float32), 'eval/episode_x_position': Array(7739.1055, dtype=float32), 'eval/episode_x_velocity': Array(1342.485, dtype=float32), 'eval/episode_y_position': Array(-39.609596, dtype=float32), 'eval/episode_y_velocity': Array(-105.46343, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.39764, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1744127, dtype=float32), 'eval/episode_forward_reward_std': Array(1029.0627, dtype=float32), 'eval/episode_reward_std': Array(1055.3077, dtype=float32), 'eval/episode_reward_alive_std': Array(48.84688, dtype=float32), 'eval/episode_reward_linvel_std': Array(1029.0627, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.003876, dtype=float32), 'eval/episode_x_position_std': Array(454.61554, dtype=float32), 'eval/episode_x_velocity_std': Array(205.81247, dtype=float32), 'eval/episode_y_position_std': Array(327.81482, dtype=float32), 'eval/episode_y_velocity_std': Array(120.16466, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23260378837585, 'eval/sps': 939.569504219677, 'num_steps': 70696960}
{'eval/walltime': 118111.11966466904, 'training/sps': 2950.022450133702, 'training/walltime': 24052.464071035385, 'training/entropy_loss': Array(0.01605246, dtype=float32), 'training/policy_loss': Array(0.00660774, dtype=float32), 'training/total_loss': Array(0.08746478, dtype=float32), 'training/v_loss': Array(0.06480458, dtype=float32), 'eval/episode_distance_from_origin': Array(7813.847, dtype=float32), 'eval/episode_distance_reward': Array(40.04111, dtype=float32), 'eval/episode_forward_reward': Array(6673.4844, dtype=float32), 'eval/episode_reward': Array(6669.051, dtype=float32), 'eval/episode_reward_alive': Array(360.60938, dtype=float32), 'eval/episode_reward_linvel': Array(6673.4844, dtype=float32), 'eval/episode_reward_quadctrl': Array(-405.0836, dtype=float32), 'eval/episode_x_position': Array(7777.3135, dtype=float32), 'eval/episode_x_velocity': Array(1334.6965, dtype=float32), 'eval/episode_y_position': Array(-97.05699, dtype=float32), 'eval/episode_y_velocity': Array(-98.74788, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.7763, dtype=float32), 'eval/episode_distance_reward_std': Array(5.501064, dtype=float32), 'eval/episode_forward_reward_std': Array(916.83856, dtype=float32), 'eval/episode_reward_std': Array(942.7564, dtype=float32), 'eval/episode_reward_alive_std': Array(49.67173, dtype=float32), 'eval/episode_reward_linvel_std': Array(916.83856, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.229958, dtype=float32), 'eval/episode_x_position_std': Array(431.04083, dtype=float32), 'eval/episode_x_velocity_std': Array(183.36772, dtype=float32), 'eval/episode_y_position_std': Array(320.43375, dtype=float32), 'eval/episode_y_velocity_std': Array(135.56645, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32070136070251, 'eval/sps': 938.9623052284182, 'num_steps': 70778880}
{'eval/walltime': 118247.3713722229, 'training/sps': 2948.617846142524, 'training/walltime': 24080.246579408646, 'training/entropy_loss': Array(0.01757503, dtype=float32), 'training/policy_loss': Array(0.01092908, dtype=float32), 'training/total_loss': Array(0.28880417, dtype=float32), 'training/v_loss': Array(0.26030007, dtype=float32), 'eval/episode_distance_from_origin': Array(7769.602, dtype=float32), 'eval/episode_distance_reward': Array(39.027496, dtype=float32), 'eval/episode_forward_reward': Array(6504.5493, dtype=float32), 'eval/episode_reward': Array(6495.7705, dtype=float32), 'eval/episode_reward_alive': Array(353.3203, dtype=float32), 'eval/episode_reward_linvel': Array(6504.5493, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.12656, dtype=float32), 'eval/episode_x_position': Array(7732.535, dtype=float32), 'eval/episode_x_velocity': Array(1300.9098, dtype=float32), 'eval/episode_y_position': Array(13.898771, dtype=float32), 'eval/episode_y_velocity': Array(-77.46737, dtype=float32), 'eval/episode_distance_from_origin_std': Array(474.96738, dtype=float32), 'eval/episode_distance_reward_std': Array(5.739678, dtype=float32), 'eval/episode_forward_reward_std': Array(956.60657, dtype=float32), 'eval/episode_reward_std': Array(970.8578, dtype=float32), 'eval/episode_reward_alive_std': Array(51.74629, dtype=float32), 'eval/episode_reward_linvel_std': Array(956.60657, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.510473, dtype=float32), 'eval/episode_x_position_std': Array(473.89886, dtype=float32), 'eval/episode_x_velocity_std': Array(191.32121, dtype=float32), 'eval/episode_y_position_std': Array(365.30872, dtype=float32), 'eval/episode_y_velocity_std': Array(133.52237, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25170755386353, 'eval/sps': 939.4377677754869, 'num_steps': 70860800}
{'eval/walltime': 118383.62376260757, 'training/sps': 2941.193274651858, 'training/walltime': 24108.09922027588, 'training/entropy_loss': Array(0.01890105, dtype=float32), 'training/policy_loss': Array(0.00789998, dtype=float32), 'training/total_loss': Array(0.2884074, dtype=float32), 'training/v_loss': Array(0.2616063, dtype=float32), 'eval/episode_distance_from_origin': Array(7757.5723, dtype=float32), 'eval/episode_distance_reward': Array(39.660057, dtype=float32), 'eval/episode_forward_reward': Array(6609.9756, dtype=float32), 'eval/episode_reward': Array(6616.664, dtype=float32), 'eval/episode_reward_alive': Array(363.90234, dtype=float32), 'eval/episode_reward_linvel': Array(6609.9756, dtype=float32), 'eval/episode_reward_quadctrl': Array(-396.87408, dtype=float32), 'eval/episode_x_position': Array(7723.0933, dtype=float32), 'eval/episode_x_velocity': Array(1321.9951, dtype=float32), 'eval/episode_y_position': Array(-24.37604, dtype=float32), 'eval/episode_y_velocity': Array(-86.07451, dtype=float32), 'eval/episode_distance_from_origin_std': Array(488.10608, dtype=float32), 'eval/episode_distance_reward_std': Array(6.671259, dtype=float32), 'eval/episode_forward_reward_std': Array(1111.8696, dtype=float32), 'eval/episode_reward_std': Array(1124.098, dtype=float32), 'eval/episode_reward_alive_std': Array(53.516026, dtype=float32), 'eval/episode_reward_linvel_std': Array(1111.8696, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.161148, dtype=float32), 'eval/episode_x_position_std': Array(485.68625, dtype=float32), 'eval/episode_x_velocity_std': Array(222.37396, dtype=float32), 'eval/episode_y_position_std': Array(312.25192, dtype=float32), 'eval/episode_y_velocity_std': Array(122.44537, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25239038467407, 'eval/sps': 939.4330597696265, 'num_steps': 70942720}
{'eval/walltime': 118519.87576174736, 'training/sps': 2957.2939377009443, 'training/walltime': 24135.800220489502, 'training/entropy_loss': Array(0.01829744, dtype=float32), 'training/policy_loss': Array(0.00714301, dtype=float32), 'training/total_loss': Array(0.27333394, dtype=float32), 'training/v_loss': Array(0.24789348, dtype=float32), 'eval/episode_distance_from_origin': Array(7814.724, dtype=float32), 'eval/episode_distance_reward': Array(40.060593, dtype=float32), 'eval/episode_forward_reward': Array(6676.7314, dtype=float32), 'eval/episode_reward': Array(6679.015, dtype=float32), 'eval/episode_reward_alive': Array(361.2461, dtype=float32), 'eval/episode_reward_linvel': Array(6676.7314, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.02335, dtype=float32), 'eval/episode_x_position': Array(7778.4746, dtype=float32), 'eval/episode_x_velocity': Array(1335.3464, dtype=float32), 'eval/episode_y_position': Array(8.680834, dtype=float32), 'eval/episode_y_velocity': Array(-78.22169, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.2272, dtype=float32), 'eval/episode_distance_reward_std': Array(5.721166, dtype=float32), 'eval/episode_forward_reward_std': Array(953.52234, dtype=float32), 'eval/episode_reward_std': Array(968.9581, dtype=float32), 'eval/episode_reward_alive_std': Array(49.7456, dtype=float32), 'eval/episode_reward_linvel_std': Array(953.52234, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.792168, dtype=float32), 'eval/episode_x_position_std': Array(456.21173, dtype=float32), 'eval/episode_x_velocity_std': Array(190.70445, dtype=float32), 'eval/episode_y_position_std': Array(340.09506, dtype=float32), 'eval/episode_y_velocity_std': Array(131.12822, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25199913978577, 'eval/sps': 939.4357573328539, 'num_steps': 71024640}
{'eval/walltime': 118656.09772205353, 'training/sps': 2946.9958997334475, 'training/walltime': 24163.598019599915, 'training/entropy_loss': Array(0.01835373, dtype=float32), 'training/policy_loss': Array(0.0059329, dtype=float32), 'training/total_loss': Array(0.26543617, dtype=float32), 'training/v_loss': Array(0.24114954, dtype=float32), 'eval/episode_distance_from_origin': Array(7853.3423, dtype=float32), 'eval/episode_distance_reward': Array(40.23577, dtype=float32), 'eval/episode_forward_reward': Array(6705.9277, dtype=float32), 'eval/episode_reward': Array(6706.574, dtype=float32), 'eval/episode_reward_alive': Array(363.53125, dtype=float32), 'eval/episode_reward_linvel': Array(6705.9277, dtype=float32), 'eval/episode_reward_quadctrl': Array(-403.11993, dtype=float32), 'eval/episode_x_position': Array(7817.295, dtype=float32), 'eval/episode_x_velocity': Array(1341.1854, dtype=float32), 'eval/episode_y_position': Array(-42.534157, dtype=float32), 'eval/episode_y_velocity': Array(-102.78786, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.91574, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6427965, dtype=float32), 'eval/episode_forward_reward_std': Array(940.46106, dtype=float32), 'eval/episode_reward_std': Array(960.7444, dtype=float32), 'eval/episode_reward_alive_std': Array(52.44505, dtype=float32), 'eval/episode_reward_linvel_std': Array(940.46106, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.742321, dtype=float32), 'eval/episode_x_position_std': Array(417.8461, dtype=float32), 'eval/episode_x_velocity_std': Array(188.09224, dtype=float32), 'eval/episode_y_position_std': Array(311.45645, dtype=float32), 'eval/episode_y_velocity_std': Array(125.634926, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2219603061676, 'eval/sps': 939.6429159609198, 'num_steps': 71106560}
{'eval/walltime': 118792.34943032265, 'training/sps': 2950.945868488018, 'training/walltime': 24191.3586101532, 'training/entropy_loss': Array(0.01656508, dtype=float32), 'training/policy_loss': Array(0.00956157, dtype=float32), 'training/total_loss': Array(0.1860505, dtype=float32), 'training/v_loss': Array(0.15992385, dtype=float32), 'eval/episode_distance_from_origin': Array(7792.1313, dtype=float32), 'eval/episode_distance_reward': Array(40.378063, dtype=float32), 'eval/episode_forward_reward': Array(6729.6406, dtype=float32), 'eval/episode_reward': Array(6737.578, dtype=float32), 'eval/episode_reward_alive': Array(366.22266, dtype=float32), 'eval/episode_reward_linvel': Array(6729.6406, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.66357, dtype=float32), 'eval/episode_x_position': Array(7755.45, dtype=float32), 'eval/episode_x_velocity': Array(1345.9281, dtype=float32), 'eval/episode_y_position': Array(-4.034661, dtype=float32), 'eval/episode_y_velocity': Array(-84.69736, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.6912, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1037903, dtype=float32), 'eval/episode_forward_reward_std': Array(1017.2924, dtype=float32), 'eval/episode_reward_std': Array(1034.7043, dtype=float32), 'eval/episode_reward_alive_std': Array(44.019207, dtype=float32), 'eval/episode_reward_linvel_std': Array(1017.2924, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.028584, dtype=float32), 'eval/episode_x_position_std': Array(453.23145, dtype=float32), 'eval/episode_x_velocity_std': Array(203.4585, dtype=float32), 'eval/episode_y_position_std': Array(331.16644, dtype=float32), 'eval/episode_y_velocity_std': Array(133.45477, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25170826911926, 'eval/sps': 939.4377628438918, 'num_steps': 71188480}
{'eval/walltime': 118928.49354720116, 'training/sps': 2939.7668808714398, 'training/walltime': 24219.22476530075, 'training/entropy_loss': Array(0.0150028, dtype=float32), 'training/policy_loss': Array(0.00711393, dtype=float32), 'training/total_loss': Array(0.05034017, dtype=float32), 'training/v_loss': Array(0.02822344, dtype=float32), 'eval/episode_distance_from_origin': Array(7745.946, dtype=float32), 'eval/episode_distance_reward': Array(39.184784, dtype=float32), 'eval/episode_forward_reward': Array(6530.7637, dtype=float32), 'eval/episode_reward': Array(6527.463, dtype=float32), 'eval/episode_reward_alive': Array(356.7539, dtype=float32), 'eval/episode_reward_linvel': Array(6530.7637, dtype=float32), 'eval/episode_reward_quadctrl': Array(-399.23904, dtype=float32), 'eval/episode_x_position': Array(7709.135, dtype=float32), 'eval/episode_x_velocity': Array(1306.1526, dtype=float32), 'eval/episode_y_position': Array(28.859932, dtype=float32), 'eval/episode_y_velocity': Array(-85.12092, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.77576, dtype=float32), 'eval/episode_distance_reward_std': Array(5.455349, dtype=float32), 'eval/episode_forward_reward_std': Array(909.21924, dtype=float32), 'eval/episode_reward_std': Array(928.2218, dtype=float32), 'eval/episode_reward_alive_std': Array(48.107952, dtype=float32), 'eval/episode_reward_linvel_std': Array(909.21924, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.8194, dtype=float32), 'eval/episode_x_position_std': Array(467.10666, dtype=float32), 'eval/episode_x_velocity_std': Array(181.84401, dtype=float32), 'eval/episode_y_position_std': Array(343.4418, dtype=float32), 'eval/episode_y_velocity_std': Array(120.097145, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.14411687850952, 'eval/sps': 940.1801777025954, 'num_steps': 71270400}
{'eval/walltime': 119064.73748993874, 'training/sps': 2962.5751540811634, 'training/walltime': 24246.87638449669, 'training/entropy_loss': Array(0.01718263, dtype=float32), 'training/policy_loss': Array(0.0059983, dtype=float32), 'training/total_loss': Array(0.20222896, dtype=float32), 'training/v_loss': Array(0.17904803, dtype=float32), 'eval/episode_distance_from_origin': Array(7694.5986, dtype=float32), 'eval/episode_distance_reward': Array(39.542213, dtype=float32), 'eval/episode_forward_reward': Array(6590.3345, dtype=float32), 'eval/episode_reward': Array(6595.618, dtype=float32), 'eval/episode_reward_alive': Array(364.71094, dtype=float32), 'eval/episode_reward_linvel': Array(6590.3345, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.96918, dtype=float32), 'eval/episode_x_position': Array(7659.656, dtype=float32), 'eval/episode_x_velocity': Array(1318.0668, dtype=float32), 'eval/episode_y_position': Array(-23.684486, dtype=float32), 'eval/episode_y_velocity': Array(-114.95972, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.79398, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6252255, dtype=float32), 'eval/episode_forward_reward_std': Array(937.53284, dtype=float32), 'eval/episode_reward_std': Array(951.28143, dtype=float32), 'eval/episode_reward_alive_std': Array(45.742382, dtype=float32), 'eval/episode_reward_linvel_std': Array(937.53284, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.005182, dtype=float32), 'eval/episode_x_position_std': Array(472.82147, dtype=float32), 'eval/episode_x_velocity_std': Array(187.50655, dtype=float32), 'eval/episode_y_position_std': Array(267.1067, dtype=float32), 'eval/episode_y_velocity_std': Array(101.4595, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24394273757935, 'eval/sps': 939.4913082230887, 'num_steps': 71352320}
{'eval/walltime': 119200.88242530823, 'training/sps': 2951.989796141043, 'training/walltime': 24274.62715792656, 'training/entropy_loss': Array(0.01899913, dtype=float32), 'training/policy_loss': Array(0.00852469, dtype=float32), 'training/total_loss': Array(0.30860946, dtype=float32), 'training/v_loss': Array(0.28108564, dtype=float32), 'eval/episode_distance_from_origin': Array(7689.0747, dtype=float32), 'eval/episode_distance_reward': Array(39.42572, dtype=float32), 'eval/episode_forward_reward': Array(6570.918, dtype=float32), 'eval/episode_reward': Array(6577.2373, dtype=float32), 'eval/episode_reward_alive': Array(365.79688, dtype=float32), 'eval/episode_reward_linvel': Array(6570.918, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.90414, dtype=float32), 'eval/episode_x_position': Array(7651.933, dtype=float32), 'eval/episode_x_velocity': Array(1314.1836, dtype=float32), 'eval/episode_y_position': Array(49.26764, dtype=float32), 'eval/episode_y_velocity': Array(-73.70748, dtype=float32), 'eval/episode_distance_from_origin_std': Array(491.4493, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2867427, dtype=float32), 'eval/episode_forward_reward_std': Array(881.1191, dtype=float32), 'eval/episode_reward_std': Array(898.25916, dtype=float32), 'eval/episode_reward_alive_std': Array(50.20444, dtype=float32), 'eval/episode_reward_linvel_std': Array(881.1191, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(21.137642, dtype=float32), 'eval/episode_x_position_std': Array(492.53815, dtype=float32), 'eval/episode_x_velocity_std': Array(176.22385, dtype=float32), 'eval/episode_y_position_std': Array(343.83527, dtype=float32), 'eval/episode_y_velocity_std': Array(130.63895, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.14493536949158, 'eval/sps': 940.1745254247867, 'num_steps': 71434240}
{'eval/walltime': 119337.1084496975, 'training/sps': 2962.916486786258, 'training/walltime': 24302.275591611862, 'training/entropy_loss': Array(0.01831117, dtype=float32), 'training/policy_loss': Array(0.00637499, dtype=float32), 'training/total_loss': Array(0.2522406, dtype=float32), 'training/v_loss': Array(0.22755443, dtype=float32), 'eval/episode_distance_from_origin': Array(7754.9707, dtype=float32), 'eval/episode_distance_reward': Array(39.899284, dtype=float32), 'eval/episode_forward_reward': Array(6649.8457, dtype=float32), 'eval/episode_reward': Array(6658.136, dtype=float32), 'eval/episode_reward_alive': Array(365.92188, dtype=float32), 'eval/episode_reward_linvel': Array(6649.8457, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.53088, dtype=float32), 'eval/episode_x_position': Array(7717.2383, dtype=float32), 'eval/episode_x_velocity': Array(1329.9691, dtype=float32), 'eval/episode_y_position': Array(-128.22528, dtype=float32), 'eval/episode_y_velocity': Array(-125.09732, dtype=float32), 'eval/episode_distance_from_origin_std': Array(421.99454, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5205894, dtype=float32), 'eval/episode_forward_reward_std': Array(920.09265, dtype=float32), 'eval/episode_reward_std': Array(928.4658, dtype=float32), 'eval/episode_reward_alive_std': Array(47.627968, dtype=float32), 'eval/episode_reward_linvel_std': Array(920.09265, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.809092, dtype=float32), 'eval/episode_x_position_std': Array(420.31528, dtype=float32), 'eval/episode_x_velocity_std': Array(184.01851, dtype=float32), 'eval/episode_y_position_std': Array(314.45905, dtype=float32), 'eval/episode_y_velocity_std': Array(114.751015, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22602438926697, 'eval/sps': 939.6148832343441, 'num_steps': 71516160}
{'eval/walltime': 119473.27236676216, 'training/sps': 2952.0250240839737, 'training/walltime': 24330.026033878326, 'training/entropy_loss': Array(0.01814359, dtype=float32), 'training/policy_loss': Array(0.01054727, dtype=float32), 'training/total_loss': Array(0.25127125, dtype=float32), 'training/v_loss': Array(0.22258037, dtype=float32), 'eval/episode_distance_from_origin': Array(7750.5176, dtype=float32), 'eval/episode_distance_reward': Array(39.200394, dtype=float32), 'eval/episode_forward_reward': Array(6533.3643, dtype=float32), 'eval/episode_reward': Array(6535.338, dtype=float32), 'eval/episode_reward_alive': Array(365.1172, dtype=float32), 'eval/episode_reward_linvel': Array(6533.3643, dtype=float32), 'eval/episode_reward_quadctrl': Array(-402.3443, dtype=float32), 'eval/episode_x_position': Array(7713.3896, dtype=float32), 'eval/episode_x_velocity': Array(1306.6727, dtype=float32), 'eval/episode_y_position': Array(-28.821121, dtype=float32), 'eval/episode_y_velocity': Array(-93.85712, dtype=float32), 'eval/episode_distance_from_origin_std': Array(449.5974, dtype=float32), 'eval/episode_distance_reward_std': Array(5.208696, dtype=float32), 'eval/episode_forward_reward_std': Array(868.1106, dtype=float32), 'eval/episode_reward_std': Array(887.30524, dtype=float32), 'eval/episode_reward_alive_std': Array(49.0534, dtype=float32), 'eval/episode_reward_linvel_std': Array(868.1106, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.11315, dtype=float32), 'eval/episode_x_position_std': Array(447.04544, dtype=float32), 'eval/episode_x_velocity_std': Array(173.62218, dtype=float32), 'eval/episode_y_position_std': Array(344.5274, dtype=float32), 'eval/episode_y_velocity_std': Array(131.62706, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.16391706466675, 'eval/sps': 940.043462022398, 'num_steps': 71598080}
{'eval/walltime': 119609.51537942886, 'training/sps': 2958.6028523662985, 'training/walltime': 24357.714778900146, 'training/entropy_loss': Array(0.0192229, dtype=float32), 'training/policy_loss': Array(0.02263948, dtype=float32), 'training/total_loss': Array(0.25119767, dtype=float32), 'training/v_loss': Array(0.2093353, dtype=float32), 'eval/episode_distance_from_origin': Array(7711.9346, dtype=float32), 'eval/episode_distance_reward': Array(39.10637, dtype=float32), 'eval/episode_forward_reward': Array(6517.6934, dtype=float32), 'eval/episode_reward': Array(6510.9326, dtype=float32), 'eval/episode_reward_alive': Array(362.72266, dtype=float32), 'eval/episode_reward_linvel': Array(6517.6934, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.59003, dtype=float32), 'eval/episode_x_position': Array(7675.953, dtype=float32), 'eval/episode_x_velocity': Array(1303.5387, dtype=float32), 'eval/episode_y_position': Array(-34.859627, dtype=float32), 'eval/episode_y_velocity': Array(-103.10276, dtype=float32), 'eval/episode_distance_from_origin_std': Array(459.8416, dtype=float32), 'eval/episode_distance_reward_std': Array(5.972736, dtype=float32), 'eval/episode_forward_reward_std': Array(995.451, dtype=float32), 'eval/episode_reward_std': Array(1016.5947, dtype=float32), 'eval/episode_reward_alive_std': Array(43.62401, dtype=float32), 'eval/episode_reward_linvel_std': Array(995.451, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.433603, dtype=float32), 'eval/episode_x_position_std': Array(458.53415, dtype=float32), 'eval/episode_x_velocity_std': Array(199.09029, dtype=float32), 'eval/episode_y_position_std': Array(321.9219, dtype=float32), 'eval/episode_y_velocity_std': Array(115.9348, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24301266670227, 'eval/sps': 939.4977217153327, 'num_steps': 71680000}
{'eval/walltime': 119745.57956504822, 'training/sps': 2956.0765125836474, 'training/walltime': 24385.42718744278, 'training/entropy_loss': Array(0.01366599, dtype=float32), 'training/policy_loss': Array(0.00597899, dtype=float32), 'training/total_loss': Array(0.05223693, dtype=float32), 'training/v_loss': Array(0.03259195, dtype=float32), 'eval/episode_distance_from_origin': Array(7673.2754, dtype=float32), 'eval/episode_distance_reward': Array(38.660187, dtype=float32), 'eval/episode_forward_reward': Array(6443.329, dtype=float32), 'eval/episode_reward': Array(6428.5537, dtype=float32), 'eval/episode_reward_alive': Array(358.03125, dtype=float32), 'eval/episode_reward_linvel': Array(6443.329, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.46646, dtype=float32), 'eval/episode_x_position': Array(7638.8496, dtype=float32), 'eval/episode_x_velocity': Array(1288.6658, dtype=float32), 'eval/episode_y_position': Array(20.34581, dtype=float32), 'eval/episode_y_velocity': Array(-78.83472, dtype=float32), 'eval/episode_distance_from_origin_std': Array(494.44888, dtype=float32), 'eval/episode_distance_reward_std': Array(6.625775, dtype=float32), 'eval/episode_forward_reward_std': Array(1104.2883, dtype=float32), 'eval/episode_reward_std': Array(1151.4908, dtype=float32), 'eval/episode_reward_alive_std': Array(54.217327, dtype=float32), 'eval/episode_reward_linvel_std': Array(1104.2883, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.174023, dtype=float32), 'eval/episode_x_position_std': Array(492.79697, dtype=float32), 'eval/episode_x_velocity_std': Array(220.85771, dtype=float32), 'eval/episode_y_position_std': Array(306.7607, dtype=float32), 'eval/episode_y_velocity_std': Array(114.25016, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.06418561935425, 'eval/sps': 940.7324889893202, 'num_steps': 71761920}
{'eval/walltime': 119881.79159545898, 'training/sps': 2953.630626198788, 'training/walltime': 24413.162544488907, 'training/entropy_loss': Array(0.01737108, dtype=float32), 'training/policy_loss': Array(0.01087687, dtype=float32), 'training/total_loss': Array(0.1933099, dtype=float32), 'training/v_loss': Array(0.16506197, dtype=float32), 'eval/episode_distance_from_origin': Array(7712.6543, dtype=float32), 'eval/episode_distance_reward': Array(38.9478, dtype=float32), 'eval/episode_forward_reward': Array(6491.2637, dtype=float32), 'eval/episode_reward': Array(6475.5176, dtype=float32), 'eval/episode_reward_alive': Array(355.38672, dtype=float32), 'eval/episode_reward_linvel': Array(6491.2637, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.08182, dtype=float32), 'eval/episode_x_position': Array(7677.5376, dtype=float32), 'eval/episode_x_velocity': Array(1298.2529, dtype=float32), 'eval/episode_y_position': Array(-34.93896, dtype=float32), 'eval/episode_y_velocity': Array(-96.29031, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.38107, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5241685, dtype=float32), 'eval/episode_forward_reward_std': Array(920.68933, dtype=float32), 'eval/episode_reward_std': Array(947.56104, dtype=float32), 'eval/episode_reward_alive_std': Array(50.82861, dtype=float32), 'eval/episode_reward_linvel_std': Array(920.68933, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.886345, dtype=float32), 'eval/episode_x_position_std': Array(468.83902, dtype=float32), 'eval/episode_x_velocity_std': Array(184.1378, dtype=float32), 'eval/episode_y_position_std': Array(296.90207, dtype=float32), 'eval/episode_y_velocity_std': Array(117.012024, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2120304107666, 'eval/sps': 939.7114161942814, 'num_steps': 71843840}
{'eval/walltime': 120017.86385917664, 'training/sps': 2953.4856057009447, 'training/walltime': 24440.899263381958, 'training/entropy_loss': Array(0.02061066, dtype=float32), 'training/policy_loss': Array(0.01277783, dtype=float32), 'training/total_loss': Array(0.29959527, dtype=float32), 'training/v_loss': Array(0.26620677, dtype=float32), 'eval/episode_distance_from_origin': Array(7657.343, dtype=float32), 'eval/episode_distance_reward': Array(38.16893, dtype=float32), 'eval/episode_forward_reward': Array(6361.455, dtype=float32), 'eval/episode_reward': Array(6348.509, dtype=float32), 'eval/episode_reward_alive': Array(360.51562, dtype=float32), 'eval/episode_reward_linvel': Array(6361.455, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.63013, dtype=float32), 'eval/episode_x_position': Array(7620.085, dtype=float32), 'eval/episode_x_velocity': Array(1272.291, dtype=float32), 'eval/episode_y_position': Array(-126.772705, dtype=float32), 'eval/episode_y_velocity': Array(-123.82032, dtype=float32), 'eval/episode_distance_from_origin_std': Array(493.73306, dtype=float32), 'eval/episode_distance_reward_std': Array(5.313349, dtype=float32), 'eval/episode_forward_reward_std': Array(885.5524, dtype=float32), 'eval/episode_reward_std': Array(910.1399, dtype=float32), 'eval/episode_reward_alive_std': Array(45.20612, dtype=float32), 'eval/episode_reward_linvel_std': Array(885.5524, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.544249, dtype=float32), 'eval/episode_x_position_std': Array(492.60367, dtype=float32), 'eval/episode_x_velocity_std': Array(177.1105, dtype=float32), 'eval/episode_y_position_std': Array(301.55307, dtype=float32), 'eval/episode_y_velocity_std': Array(107.42724, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.07226371765137, 'eval/sps': 940.6766412411479, 'num_steps': 71925760}
{'eval/walltime': 120154.12367153168, 'training/sps': 2950.556511569288, 'training/walltime': 24468.66351723671, 'training/entropy_loss': Array(0.01988467, dtype=float32), 'training/policy_loss': Array(0.0076663, dtype=float32), 'training/total_loss': Array(0.24026053, dtype=float32), 'training/v_loss': Array(0.21270956, dtype=float32), 'eval/episode_distance_from_origin': Array(7655.9307, dtype=float32), 'eval/episode_distance_reward': Array(39.163277, dtype=float32), 'eval/episode_forward_reward': Array(6527.177, dtype=float32), 'eval/episode_reward': Array(6522.336, dtype=float32), 'eval/episode_reward_alive': Array(370.38672, dtype=float32), 'eval/episode_reward_linvel': Array(6527.177, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.39026, dtype=float32), 'eval/episode_x_position': Array(7616.04, dtype=float32), 'eval/episode_x_velocity': Array(1305.4353, dtype=float32), 'eval/episode_y_position': Array(-38.066498, dtype=float32), 'eval/episode_y_velocity': Array(-116.687256, dtype=float32), 'eval/episode_distance_from_origin_std': Array(479.91974, dtype=float32), 'eval/episode_distance_reward_std': Array(5.785813, dtype=float32), 'eval/episode_forward_reward_std': Array(964.29663, dtype=float32), 'eval/episode_reward_std': Array(997.55634, dtype=float32), 'eval/episode_reward_alive_std': Array(48.053974, dtype=float32), 'eval/episode_reward_linvel_std': Array(964.29663, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.581873, dtype=float32), 'eval/episode_x_position_std': Array(479.81555, dtype=float32), 'eval/episode_x_velocity_std': Array(192.85945, dtype=float32), 'eval/episode_y_position_std': Array(365.34628, dtype=float32), 'eval/episode_y_velocity_std': Array(124.87039, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2598123550415, 'eval/sps': 939.381889551414, 'num_steps': 72007680}
{'eval/walltime': 120290.30927968025, 'training/sps': 2961.7301186835325, 'training/walltime': 24496.32302594185, 'training/entropy_loss': Array(0.01998245, dtype=float32), 'training/policy_loss': Array(0.00726469, dtype=float32), 'training/total_loss': Array(0.2531309, dtype=float32), 'training/v_loss': Array(0.22588378, dtype=float32), 'eval/episode_distance_from_origin': Array(7704.7563, dtype=float32), 'eval/episode_distance_reward': Array(39.474846, dtype=float32), 'eval/episode_forward_reward': Array(6579.1045, dtype=float32), 'eval/episode_reward': Array(6569.089, dtype=float32), 'eval/episode_reward_alive': Array(367.14453, dtype=float32), 'eval/episode_reward_linvel': Array(6579.1045, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.63492, dtype=float32), 'eval/episode_x_position': Array(7665.866, dtype=float32), 'eval/episode_x_velocity': Array(1315.8208, dtype=float32), 'eval/episode_y_position': Array(-64.79008, dtype=float32), 'eval/episode_y_velocity': Array(-104.53902, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.58868, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2796693, dtype=float32), 'eval/episode_forward_reward_std': Array(879.94073, dtype=float32), 'eval/episode_reward_std': Array(910.0559, dtype=float32), 'eval/episode_reward_alive_std': Array(43.192207, dtype=float32), 'eval/episode_reward_linvel_std': Array(879.94073, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.064579, dtype=float32), 'eval/episode_x_position_std': Array(458.13342, dtype=float32), 'eval/episode_x_velocity_std': Array(175.9882, dtype=float32), 'eval/episode_y_position_std': Array(364.6402, dtype=float32), 'eval/episode_y_velocity_std': Array(121.27941, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.18560814857483, 'eval/sps': 939.8937357635871, 'num_steps': 72089600}
{'eval/walltime': 120426.5267367363, 'training/sps': 2959.432135428022, 'training/walltime': 24524.00401210785, 'training/entropy_loss': Array(0.02115268, dtype=float32), 'training/policy_loss': Array(0.0160936, dtype=float32), 'training/total_loss': Array(0.24670734, dtype=float32), 'training/v_loss': Array(0.20946103, dtype=float32), 'eval/episode_distance_from_origin': Array(7633.4463, dtype=float32), 'eval/episode_distance_reward': Array(38.06466, dtype=float32), 'eval/episode_forward_reward': Array(6344.076, dtype=float32), 'eval/episode_reward': Array(6322.332, dtype=float32), 'eval/episode_reward_alive': Array(358.65625, dtype=float32), 'eval/episode_reward_linvel': Array(6344.076, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.4642, dtype=float32), 'eval/episode_x_position': Array(7596.126, dtype=float32), 'eval/episode_x_velocity': Array(1268.8152, dtype=float32), 'eval/episode_y_position': Array(-21.691708, dtype=float32), 'eval/episode_y_velocity': Array(-93.1612, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.39365, dtype=float32), 'eval/episode_distance_reward_std': Array(6.136584, dtype=float32), 'eval/episode_forward_reward_std': Array(1022.7559, dtype=float32), 'eval/episode_reward_std': Array(1083.9303, dtype=float32), 'eval/episode_reward_alive_std': Array(55.89142, dtype=float32), 'eval/episode_reward_linvel_std': Array(1022.7559, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.460743, dtype=float32), 'eval/episode_x_position_std': Array(451.7491, dtype=float32), 'eval/episode_x_velocity_std': Array(204.55107, dtype=float32), 'eval/episode_y_position_std': Array(343.6045, dtype=float32), 'eval/episode_y_velocity_std': Array(117.23596, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21745705604553, 'eval/sps': 939.673979872752, 'num_steps': 72171520}
{'eval/walltime': 120562.68289422989, 'training/sps': 2961.481125559637, 'training/walltime': 24551.66584634781, 'training/entropy_loss': Array(0.01488233, dtype=float32), 'training/policy_loss': Array(0.02343604, dtype=float32), 'training/total_loss': Array(0.10969839, dtype=float32), 'training/v_loss': Array(0.07138, dtype=float32), 'eval/episode_distance_from_origin': Array(7663.603, dtype=float32), 'eval/episode_distance_reward': Array(38.23264, dtype=float32), 'eval/episode_forward_reward': Array(6372.0703, dtype=float32), 'eval/episode_reward': Array(6353.415, dtype=float32), 'eval/episode_reward_alive': Array(363.6797, dtype=float32), 'eval/episode_reward_linvel': Array(6372.0703, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.5675, dtype=float32), 'eval/episode_x_position': Array(7625.2715, dtype=float32), 'eval/episode_x_velocity': Array(1274.4143, dtype=float32), 'eval/episode_y_position': Array(-157.31917, dtype=float32), 'eval/episode_y_velocity': Array(-133.43219, dtype=float32), 'eval/episode_distance_from_origin_std': Array(390.39868, dtype=float32), 'eval/episode_distance_reward_std': Array(4.677258, dtype=float32), 'eval/episode_forward_reward_std': Array(779.53815, dtype=float32), 'eval/episode_reward_std': Array(806.3513, dtype=float32), 'eval/episode_reward_alive_std': Array(43.690838, dtype=float32), 'eval/episode_reward_linvel_std': Array(779.53815, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.326733, dtype=float32), 'eval/episode_x_position_std': Array(390.0188, dtype=float32), 'eval/episode_x_velocity_std': Array(155.90767, dtype=float32), 'eval/episode_y_position_std': Array(294.11023, dtype=float32), 'eval/episode_y_velocity_std': Array(93.60234, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1561574935913, 'eval/sps': 940.0970353178834, 'num_steps': 72253440}
{'eval/walltime': 120698.91258335114, 'training/sps': 2954.068668468083, 'training/walltime': 24579.397090673447, 'training/entropy_loss': Array(0.01754186, dtype=float32), 'training/policy_loss': Array(0.01393006, dtype=float32), 'training/total_loss': Array(0.14044815, dtype=float32), 'training/v_loss': Array(0.10897624, dtype=float32), 'eval/episode_distance_from_origin': Array(7616.6113, dtype=float32), 'eval/episode_distance_reward': Array(37.793858, dtype=float32), 'eval/episode_forward_reward': Array(6298.9404, dtype=float32), 'eval/episode_reward': Array(6261.939, dtype=float32), 'eval/episode_reward_alive': Array(360.34766, dtype=float32), 'eval/episode_reward_linvel': Array(6298.9404, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.14313, dtype=float32), 'eval/episode_x_position': Array(7578.3525, dtype=float32), 'eval/episode_x_velocity': Array(1259.7882, dtype=float32), 'eval/episode_y_position': Array(-155.80034, dtype=float32), 'eval/episode_y_velocity': Array(-130.59903, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.69226, dtype=float32), 'eval/episode_distance_reward_std': Array(5.41052, dtype=float32), 'eval/episode_forward_reward_std': Array(901.7477, dtype=float32), 'eval/episode_reward_std': Array(947.88525, dtype=float32), 'eval/episode_reward_alive_std': Array(50.318073, dtype=float32), 'eval/episode_reward_linvel_std': Array(901.7477, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.586334, dtype=float32), 'eval/episode_x_position_std': Array(434.85056, dtype=float32), 'eval/episode_x_velocity_std': Array(180.34944, dtype=float32), 'eval/episode_y_position_std': Array(313.89996, dtype=float32), 'eval/episode_y_velocity_std': Array(94.42019, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22968912124634, 'eval/sps': 939.5896065363418, 'num_steps': 72335360}
{'eval/walltime': 120834.9653866291, 'training/sps': 2959.1861535352873, 'training/walltime': 24607.080377817154, 'training/entropy_loss': Array(0.02105554, dtype=float32), 'training/policy_loss': Array(0.00847442, dtype=float32), 'training/total_loss': Array(0.39818698, dtype=float32), 'training/v_loss': Array(0.36865705, dtype=float32), 'eval/episode_distance_from_origin': Array(7568.8125, dtype=float32), 'eval/episode_distance_reward': Array(37.017723, dtype=float32), 'eval/episode_forward_reward': Array(6169.5864, dtype=float32), 'eval/episode_reward': Array(6136.311, dtype=float32), 'eval/episode_reward_alive': Array(362.8086, dtype=float32), 'eval/episode_reward_linvel': Array(6169.5864, dtype=float32), 'eval/episode_reward_quadctrl': Array(-433.1013, dtype=float32), 'eval/episode_x_position': Array(7530.774, dtype=float32), 'eval/episode_x_velocity': Array(1233.9174, dtype=float32), 'eval/episode_y_position': Array(-126.54544, dtype=float32), 'eval/episode_y_velocity': Array(-116.03441, dtype=float32), 'eval/episode_distance_from_origin_std': Array(454.75397, dtype=float32), 'eval/episode_distance_reward_std': Array(5.0309615, dtype=float32), 'eval/episode_forward_reward_std': Array(838.4876, dtype=float32), 'eval/episode_reward_std': Array(874.3901, dtype=float32), 'eval/episode_reward_alive_std': Array(43.84334, dtype=float32), 'eval/episode_reward_linvel_std': Array(838.4876, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.295937, dtype=float32), 'eval/episode_x_position_std': Array(450.31976, dtype=float32), 'eval/episode_x_velocity_std': Array(167.69757, dtype=float32), 'eval/episode_y_position_std': Array(328.3596, dtype=float32), 'eval/episode_y_velocity_std': Array(110.17053, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.05280327796936, 'eval/sps': 940.8111918023719, 'num_steps': 72417280}
{'eval/walltime': 120971.17564558983, 'training/sps': 2960.600234387232, 'training/walltime': 24634.750442504883, 'training/entropy_loss': Array(0.02248045, dtype=float32), 'training/policy_loss': Array(0.00671641, dtype=float32), 'training/total_loss': Array(0.2519421, dtype=float32), 'training/v_loss': Array(0.22274525, dtype=float32), 'eval/episode_distance_from_origin': Array(7629.44, dtype=float32), 'eval/episode_distance_reward': Array(37.62546, dtype=float32), 'eval/episode_forward_reward': Array(6270.8745, dtype=float32), 'eval/episode_reward': Array(6230.075, dtype=float32), 'eval/episode_reward_alive': Array(355.8047, dtype=float32), 'eval/episode_reward_linvel': Array(6270.8745, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.22977, dtype=float32), 'eval/episode_x_position': Array(7590.621, dtype=float32), 'eval/episode_x_velocity': Array(1254.1749, dtype=float32), 'eval/episode_y_position': Array(-191.15909, dtype=float32), 'eval/episode_y_velocity': Array(-127.76352, dtype=float32), 'eval/episode_distance_from_origin_std': Array(486.57974, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8757305, dtype=float32), 'eval/episode_forward_reward_std': Array(979.2813, dtype=float32), 'eval/episode_reward_std': Array(1034.7274, dtype=float32), 'eval/episode_reward_alive_std': Array(52.103798, dtype=float32), 'eval/episode_reward_linvel_std': Array(979.2813, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.84485, dtype=float32), 'eval/episode_x_position_std': Array(485.3902, dtype=float32), 'eval/episode_x_velocity_std': Array(195.8563, dtype=float32), 'eval/episode_y_position_std': Array(303.9088, dtype=float32), 'eval/episode_y_velocity_std': Array(106.44814, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21025896072388, 'eval/sps': 939.7236373870246, 'num_steps': 72499200}
{'eval/walltime': 121107.23473358154, 'training/sps': 2959.727795999949, 'training/walltime': 24662.428663492203, 'training/entropy_loss': Array(0.02197333, dtype=float32), 'training/policy_loss': Array(0.00895784, dtype=float32), 'training/total_loss': Array(0.25060755, dtype=float32), 'training/v_loss': Array(0.21967639, dtype=float32), 'eval/episode_distance_from_origin': Array(7565.3037, dtype=float32), 'eval/episode_distance_reward': Array(37.603535, dtype=float32), 'eval/episode_forward_reward': Array(6267.221, dtype=float32), 'eval/episode_reward': Array(6232.3267, dtype=float32), 'eval/episode_reward_alive': Array(359.79688, dtype=float32), 'eval/episode_reward_linvel': Array(6267.221, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.29538, dtype=float32), 'eval/episode_x_position': Array(7525.3716, dtype=float32), 'eval/episode_x_velocity': Array(1253.4443, dtype=float32), 'eval/episode_y_position': Array(-151.19485, dtype=float32), 'eval/episode_y_velocity': Array(-123.809525, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.9884, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6148343, dtype=float32), 'eval/episode_forward_reward_std': Array(935.79926, dtype=float32), 'eval/episode_reward_std': Array(985.3054, dtype=float32), 'eval/episode_reward_alive_std': Array(46.59409, dtype=float32), 'eval/episode_reward_linvel_std': Array(935.79926, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.514843, dtype=float32), 'eval/episode_x_position_std': Array(457.2276, dtype=float32), 'eval/episode_x_velocity_std': Array(187.15982, dtype=float32), 'eval/episode_y_position_std': Array(343.0352, dtype=float32), 'eval/episode_y_velocity_std': Array(106.02161, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.05908799171448, 'eval/sps': 940.7677347344468, 'num_steps': 72581120}
{'eval/walltime': 121243.43192577362, 'training/sps': 2952.4679432664702, 'training/walltime': 24690.174942731857, 'training/entropy_loss': Array(0.02269012, dtype=float32), 'training/policy_loss': Array(0.00880812, dtype=float32), 'training/total_loss': Array(0.25475907, dtype=float32), 'training/v_loss': Array(0.22326083, dtype=float32), 'eval/episode_distance_from_origin': Array(7564.15, dtype=float32), 'eval/episode_distance_reward': Array(37.760845, dtype=float32), 'eval/episode_forward_reward': Array(6293.4395, dtype=float32), 'eval/episode_reward': Array(6257.994, dtype=float32), 'eval/episode_reward_alive': Array(362.64453, dtype=float32), 'eval/episode_reward_linvel': Array(6293.4395, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.8507, dtype=float32), 'eval/episode_x_position': Array(7527.8506, dtype=float32), 'eval/episode_x_velocity': Array(1258.688, dtype=float32), 'eval/episode_y_position': Array(-75.56915, dtype=float32), 'eval/episode_y_velocity': Array(-107.6511, dtype=float32), 'eval/episode_distance_from_origin_std': Array(539.57416, dtype=float32), 'eval/episode_distance_reward_std': Array(6.041348, dtype=float32), 'eval/episode_forward_reward_std': Array(1006.8844, dtype=float32), 'eval/episode_reward_std': Array(1060.6073, dtype=float32), 'eval/episode_reward_alive_std': Array(49.294838, dtype=float32), 'eval/episode_reward_linvel_std': Array(1006.8844, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.447365, dtype=float32), 'eval/episode_x_position_std': Array(538.8358, dtype=float32), 'eval/episode_x_velocity_std': Array(201.37679, dtype=float32), 'eval/episode_y_position_std': Array(314.3645, dtype=float32), 'eval/episode_y_velocity_std': Array(101.39284, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.19719219207764, 'eval/sps': 939.8137945419813, 'num_steps': 72663040}
{'eval/walltime': 121379.49471712112, 'training/sps': 2961.7808209991376, 'training/walltime': 24717.8339779377, 'training/entropy_loss': Array(0.01798436, dtype=float32), 'training/policy_loss': Array(0.01024287, dtype=float32), 'training/total_loss': Array(0.1288529, dtype=float32), 'training/v_loss': Array(0.10062567, dtype=float32), 'eval/episode_distance_from_origin': Array(7595.567, dtype=float32), 'eval/episode_distance_reward': Array(38.14499, dtype=float32), 'eval/episode_forward_reward': Array(6357.4624, dtype=float32), 'eval/episode_reward': Array(6334.942, dtype=float32), 'eval/episode_reward_alive': Array(369.66406, dtype=float32), 'eval/episode_reward_linvel': Array(6357.4624, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.3298, dtype=float32), 'eval/episode_x_position': Array(7554.8896, dtype=float32), 'eval/episode_x_velocity': Array(1271.4924, dtype=float32), 'eval/episode_y_position': Array(-195.23921, dtype=float32), 'eval/episode_y_velocity': Array(-137.12854, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.38416, dtype=float32), 'eval/episode_distance_reward_std': Array(5.730601, dtype=float32), 'eval/episode_forward_reward_std': Array(955.0934, dtype=float32), 'eval/episode_reward_std': Array(997.01587, dtype=float32), 'eval/episode_reward_alive_std': Array(46.015625, dtype=float32), 'eval/episode_reward_linvel_std': Array(955.0934, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.991264, dtype=float32), 'eval/episode_x_position_std': Array(471.918, dtype=float32), 'eval/episode_x_velocity_std': Array(191.0188, dtype=float32), 'eval/episode_y_position_std': Array(328.23798, dtype=float32), 'eval/episode_y_velocity_std': Array(105.37278, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.06279134750366, 'eval/sps': 940.7421289269942, 'num_steps': 72744960}
{'eval/walltime': 121515.70293831825, 'training/sps': 2965.2355730180147, 'training/walltime': 24745.46078801155, 'training/entropy_loss': Array(0.01654769, dtype=float32), 'training/policy_loss': Array(0.00886748, dtype=float32), 'training/total_loss': Array(0.08718393, dtype=float32), 'training/v_loss': Array(0.06176876, dtype=float32), 'eval/episode_distance_from_origin': Array(7522.101, dtype=float32), 'eval/episode_distance_reward': Array(36.763515, dtype=float32), 'eval/episode_forward_reward': Array(6127.218, dtype=float32), 'eval/episode_reward': Array(6097.4746, dtype=float32), 'eval/episode_reward_alive': Array(362.29297, dtype=float32), 'eval/episode_reward_linvel': Array(6127.218, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.80048, dtype=float32), 'eval/episode_x_position': Array(7484.342, dtype=float32), 'eval/episode_x_velocity': Array(1225.4435, dtype=float32), 'eval/episode_y_position': Array(-119.78278, dtype=float32), 'eval/episode_y_velocity': Array(-115.21272, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.88583, dtype=float32), 'eval/episode_distance_reward_std': Array(4.8096156, dtype=float32), 'eval/episode_forward_reward_std': Array(801.597, dtype=float32), 'eval/episode_reward_std': Array(830.8079, dtype=float32), 'eval/episode_reward_alive_std': Array(45.62845, dtype=float32), 'eval/episode_reward_linvel_std': Array(801.597, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.063908, dtype=float32), 'eval/episode_x_position_std': Array(427.65958, dtype=float32), 'eval/episode_x_velocity_std': Array(160.31929, dtype=float32), 'eval/episode_y_position_std': Array(326.4509, dtype=float32), 'eval/episode_y_velocity_std': Array(100.859795, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2082211971283, 'eval/sps': 939.737696263951, 'num_steps': 72826880}
{'eval/walltime': 121652.2864792347, 'training/sps': 2960.4993204456373, 'training/walltime': 24773.13179588318, 'training/entropy_loss': Array(0.02098365, dtype=float32), 'training/policy_loss': Array(0.00731244, dtype=float32), 'training/total_loss': Array(0.31390125, dtype=float32), 'training/v_loss': Array(0.2856052, dtype=float32), 'eval/episode_distance_from_origin': Array(7627.03, dtype=float32), 'eval/episode_distance_reward': Array(38.325775, dtype=float32), 'eval/episode_forward_reward': Array(6387.5947, dtype=float32), 'eval/episode_reward': Array(6360.9463, dtype=float32), 'eval/episode_reward_alive': Array(367.72266, dtype=float32), 'eval/episode_reward_linvel': Array(6387.5947, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.6966, dtype=float32), 'eval/episode_x_position': Array(7588.594, dtype=float32), 'eval/episode_x_velocity': Array(1277.5188, dtype=float32), 'eval/episode_y_position': Array(-144.00122, dtype=float32), 'eval/episode_y_velocity': Array(-125.70662, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.15222, dtype=float32), 'eval/episode_distance_reward_std': Array(5.708309, dtype=float32), 'eval/episode_forward_reward_std': Array(951.37897, dtype=float32), 'eval/episode_reward_std': Array(994.9912, dtype=float32), 'eval/episode_reward_alive_std': Array(48.05546, dtype=float32), 'eval/episode_reward_linvel_std': Array(951.37897, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.918167, dtype=float32), 'eval/episode_x_position_std': Array(449.49704, dtype=float32), 'eval/episode_x_velocity_std': Array(190.27562, dtype=float32), 'eval/episode_y_position_std': Array(322.17435, dtype=float32), 'eval/episode_y_velocity_std': Array(105.407906, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58354091644287, 'eval/sps': 937.1553786140748, 'num_steps': 72908800}
{'eval/walltime': 121788.48380851746, 'training/sps': 2961.143823764477, 'training/walltime': 24800.79678106308, 'training/entropy_loss': Array(0.02311067, dtype=float32), 'training/policy_loss': Array(0.01489783, dtype=float32), 'training/total_loss': Array(0.26511192, dtype=float32), 'training/v_loss': Array(0.22710344, dtype=float32), 'eval/episode_distance_from_origin': Array(7554.861, dtype=float32), 'eval/episode_distance_reward': Array(37.19993, dtype=float32), 'eval/episode_forward_reward': Array(6199.954, dtype=float32), 'eval/episode_reward': Array(6162.7207, dtype=float32), 'eval/episode_reward_alive': Array(357.58594, dtype=float32), 'eval/episode_reward_linvel': Array(6199.954, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.0189, dtype=float32), 'eval/episode_x_position': Array(7517.042, dtype=float32), 'eval/episode_x_velocity': Array(1239.9907, dtype=float32), 'eval/episode_y_position': Array(-108.01796, dtype=float32), 'eval/episode_y_velocity': Array(-112.50758, dtype=float32), 'eval/episode_distance_from_origin_std': Array(461.95404, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6474175, dtype=float32), 'eval/episode_forward_reward_std': Array(941.2303, dtype=float32), 'eval/episode_reward_std': Array(988.60236, dtype=float32), 'eval/episode_reward_alive_std': Array(49.056133, dtype=float32), 'eval/episode_reward_linvel_std': Array(941.2303, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.090595, dtype=float32), 'eval/episode_x_position_std': Array(458.85367, dtype=float32), 'eval/episode_x_velocity_std': Array(188.24603, dtype=float32), 'eval/episode_y_position_std': Array(330.7411, dtype=float32), 'eval/episode_y_velocity_std': Array(110.448944, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.19732928276062, 'eval/sps': 939.8128485637037, 'num_steps': 72990720}
{'eval/walltime': 121925.21776914597, 'training/sps': 2959.705309649251, 'training/walltime': 24828.475212335587, 'training/entropy_loss': Array(0.02244662, dtype=float32), 'training/policy_loss': Array(0.00726893, dtype=float32), 'training/total_loss': Array(0.25029945, dtype=float32), 'training/v_loss': Array(0.22058389, dtype=float32), 'eval/episode_distance_from_origin': Array(7564.752, dtype=float32), 'eval/episode_distance_reward': Array(37.921364, dtype=float32), 'eval/episode_forward_reward': Array(6320.192, dtype=float32), 'eval/episode_reward': Array(6294.4883, dtype=float32), 'eval/episode_reward_alive': Array(366.72266, dtype=float32), 'eval/episode_reward_linvel': Array(6320.192, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.34763, dtype=float32), 'eval/episode_x_position': Array(7526.538, dtype=float32), 'eval/episode_x_velocity': Array(1264.0383, dtype=float32), 'eval/episode_y_position': Array(-101.62626, dtype=float32), 'eval/episode_y_velocity': Array(-125.29411, dtype=float32), 'eval/episode_distance_from_origin_std': Array(484.77084, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6494575, dtype=float32), 'eval/episode_forward_reward_std': Array(941.5709, dtype=float32), 'eval/episode_reward_std': Array(990.0035, dtype=float32), 'eval/episode_reward_alive_std': Array(49.45827, dtype=float32), 'eval/episode_reward_linvel_std': Array(941.5709, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.018177, dtype=float32), 'eval/episode_x_position_std': Array(483.71304, dtype=float32), 'eval/episode_x_velocity_std': Array(188.31413, dtype=float32), 'eval/episode_y_position_std': Array(311.78806, dtype=float32), 'eval/episode_y_velocity_std': Array(101.902466, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.73396062850952, 'eval/sps': 936.1244230155909, 'num_steps': 73072640}
{'eval/walltime': 122061.4726896286, 'training/sps': 2962.4849354209146, 'training/walltime': 24856.127673625946, 'training/entropy_loss': Array(0.02208028, dtype=float32), 'training/policy_loss': Array(0.0100863, dtype=float32), 'training/total_loss': Array(0.26072407, dtype=float32), 'training/v_loss': Array(0.22855751, dtype=float32), 'eval/episode_distance_from_origin': Array(7597.7866, dtype=float32), 'eval/episode_distance_reward': Array(38.599884, dtype=float32), 'eval/episode_forward_reward': Array(6433.278, dtype=float32), 'eval/episode_reward': Array(6406.6826, dtype=float32), 'eval/episode_reward_alive': Array(369.70312, dtype=float32), 'eval/episode_reward_linvel': Array(6433.278, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.899, dtype=float32), 'eval/episode_x_position': Array(7560.344, dtype=float32), 'eval/episode_x_velocity': Array(1286.6556, dtype=float32), 'eval/episode_y_position': Array(-84.543915, dtype=float32), 'eval/episode_y_velocity': Array(-125.00969, dtype=float32), 'eval/episode_distance_from_origin_std': Array(443.51974, dtype=float32), 'eval/episode_distance_reward_std': Array(5.75927, dtype=float32), 'eval/episode_forward_reward_std': Array(959.8718, dtype=float32), 'eval/episode_reward_std': Array(1012.5677, dtype=float32), 'eval/episode_reward_alive_std': Array(47.37716, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.8718, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.848194, dtype=float32), 'eval/episode_x_position_std': Array(445.26355, dtype=float32), 'eval/episode_x_velocity_std': Array(191.9744, dtype=float32), 'eval/episode_y_position_std': Array(306.9456, dtype=float32), 'eval/episode_y_velocity_std': Array(103.82878, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2549204826355, 'eval/sps': 939.4156155726683, 'num_steps': 73154560}
{'eval/walltime': 122198.07196450233, 'training/sps': 2948.1472184825734, 'training/walltime': 24883.914617061615, 'training/entropy_loss': Array(0.01960027, dtype=float32), 'training/policy_loss': Array(0.00719315, dtype=float32), 'training/total_loss': Array(0.17494702, dtype=float32), 'training/v_loss': Array(0.14815362, dtype=float32), 'eval/episode_distance_from_origin': Array(7566.438, dtype=float32), 'eval/episode_distance_reward': Array(37.38008, dtype=float32), 'eval/episode_forward_reward': Array(6229.9775, dtype=float32), 'eval/episode_reward': Array(6194.491, dtype=float32), 'eval/episode_reward_alive': Array(361.65625, dtype=float32), 'eval/episode_reward_linvel': Array(6229.9775, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.5229, dtype=float32), 'eval/episode_x_position': Array(7528.1934, dtype=float32), 'eval/episode_x_velocity': Array(1245.9956, dtype=float32), 'eval/episode_y_position': Array(-69.91151, dtype=float32), 'eval/episode_y_velocity': Array(-102.46861, dtype=float32), 'eval/episode_distance_from_origin_std': Array(423.51004, dtype=float32), 'eval/episode_distance_reward_std': Array(4.9559617, dtype=float32), 'eval/episode_forward_reward_std': Array(825.9893, dtype=float32), 'eval/episode_reward_std': Array(863.10455, dtype=float32), 'eval/episode_reward_alive_std': Array(44.951004, dtype=float32), 'eval/episode_reward_linvel_std': Array(825.9893, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.32756, dtype=float32), 'eval/episode_x_position_std': Array(425.98877, dtype=float32), 'eval/episode_x_velocity_std': Array(165.19788, dtype=float32), 'eval/episode_y_position_std': Array(339.5524, dtype=float32), 'eval/episode_y_velocity_std': Array(112.049095, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.59927487373352, 'eval/sps': 937.0474339510051, 'num_steps': 73236480}
{'eval/walltime': 122334.2951271534, 'training/sps': 2962.3731148211887, 'training/walltime': 24911.568122148514, 'training/entropy_loss': Array(0.01573117, dtype=float32), 'training/policy_loss': Array(0.01004967, dtype=float32), 'training/total_loss': Array(0.06869306, dtype=float32), 'training/v_loss': Array(0.04291222, dtype=float32), 'eval/episode_distance_from_origin': Array(7641.328, dtype=float32), 'eval/episode_distance_reward': Array(38.28269, dtype=float32), 'eval/episode_forward_reward': Array(6380.4146, dtype=float32), 'eval/episode_reward': Array(6348.8203, dtype=float32), 'eval/episode_reward_alive': Array(359.48047, dtype=float32), 'eval/episode_reward_linvel': Array(6380.4146, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.35657, dtype=float32), 'eval/episode_x_position': Array(7604.0244, dtype=float32), 'eval/episode_x_velocity': Array(1276.0828, dtype=float32), 'eval/episode_y_position': Array(-127.265076, dtype=float32), 'eval/episode_y_velocity': Array(-118.38332, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.64624, dtype=float32), 'eval/episode_distance_reward_std': Array(5.420564, dtype=float32), 'eval/episode_forward_reward_std': Array(903.4205, dtype=float32), 'eval/episode_reward_std': Array(964.36676, dtype=float32), 'eval/episode_reward_alive_std': Array(52.967907, dtype=float32), 'eval/episode_reward_linvel_std': Array(903.4205, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.141663, dtype=float32), 'eval/episode_x_position_std': Array(477.60526, dtype=float32), 'eval/episode_x_velocity_std': Array(180.68416, dtype=float32), 'eval/episode_y_position_std': Array(315.39075, dtype=float32), 'eval/episode_y_velocity_std': Array(106.64681, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.223162651062, 'eval/sps': 939.6346224017293, 'num_steps': 73318400}
{'eval/walltime': 122471.01537704468, 'training/sps': 2945.735947277235, 'training/walltime': 24939.377810955048, 'training/entropy_loss': Array(0.01882594, dtype=float32), 'training/policy_loss': Array(0.01629792, dtype=float32), 'training/total_loss': Array(0.23387823, dtype=float32), 'training/v_loss': Array(0.19875436, dtype=float32), 'eval/episode_distance_from_origin': Array(7639.174, dtype=float32), 'eval/episode_distance_reward': Array(38.57454, dtype=float32), 'eval/episode_forward_reward': Array(6429.0537, dtype=float32), 'eval/episode_reward': Array(6402.5557, dtype=float32), 'eval/episode_reward_alive': Array(366.98438, dtype=float32), 'eval/episode_reward_linvel': Array(6429.0537, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.05786, dtype=float32), 'eval/episode_x_position': Array(7601.033, dtype=float32), 'eval/episode_x_velocity': Array(1285.8108, dtype=float32), 'eval/episode_y_position': Array(-112.76924, dtype=float32), 'eval/episode_y_velocity': Array(-121.6249, dtype=float32), 'eval/episode_distance_from_origin_std': Array(450.7471, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6354094, dtype=float32), 'eval/episode_forward_reward_std': Array(939.22876, dtype=float32), 'eval/episode_reward_std': Array(979.5883, dtype=float32), 'eval/episode_reward_alive_std': Array(45.596947, dtype=float32), 'eval/episode_reward_linvel_std': Array(939.22876, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.125458, dtype=float32), 'eval/episode_x_position_std': Array(450.57718, dtype=float32), 'eval/episode_x_velocity_std': Array(187.84581, dtype=float32), 'eval/episode_y_position_std': Array(320.54144, dtype=float32), 'eval/episode_y_velocity_std': Array(104.113884, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.72024989128113, 'eval/sps': 936.2183005208416, 'num_steps': 73400320}
{'eval/walltime': 122607.20931768417, 'training/sps': 2960.8629847291036, 'training/walltime': 24967.04542016983, 'training/entropy_loss': Array(0.02327525, dtype=float32), 'training/policy_loss': Array(0.01262369, dtype=float32), 'training/total_loss': Array(0.26667377, dtype=float32), 'training/v_loss': Array(0.23077483, dtype=float32), 'eval/episode_distance_from_origin': Array(7633.6533, dtype=float32), 'eval/episode_distance_reward': Array(38.172585, dtype=float32), 'eval/episode_forward_reward': Array(6362.0615, dtype=float32), 'eval/episode_reward': Array(6327.75, dtype=float32), 'eval/episode_reward_alive': Array(364.54688, dtype=float32), 'eval/episode_reward_linvel': Array(6362.0615, dtype=float32), 'eval/episode_reward_quadctrl': Array(-437.0311, dtype=float32), 'eval/episode_x_position': Array(7594.34, dtype=float32), 'eval/episode_x_velocity': Array(1272.4122, dtype=float32), 'eval/episode_y_position': Array(-93.86204, dtype=float32), 'eval/episode_y_velocity': Array(-115.40371, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.2273, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1069803, dtype=float32), 'eval/episode_forward_reward_std': Array(1017.8246, dtype=float32), 'eval/episode_reward_std': Array(1065.4103, dtype=float32), 'eval/episode_reward_alive_std': Array(46.518997, dtype=float32), 'eval/episode_reward_linvel_std': Array(1017.8246, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.27429, dtype=float32), 'eval/episode_x_position_std': Array(476.9244, dtype=float32), 'eval/episode_x_velocity_std': Array(203.56497, dtype=float32), 'eval/episode_y_position_std': Array(350.19223, dtype=float32), 'eval/episode_y_velocity_std': Array(113.04041, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.19394063949585, 'eval/sps': 939.8362320598011, 'num_steps': 73482240}
{'eval/walltime': 122743.93414497375, 'training/sps': 2960.179175944112, 'training/walltime': 24994.719420671463, 'training/entropy_loss': Array(0.02180227, dtype=float32), 'training/policy_loss': Array(0.00761327, dtype=float32), 'training/total_loss': Array(0.22320652, dtype=float32), 'training/v_loss': Array(0.19379097, dtype=float32), 'eval/episode_distance_from_origin': Array(7535.8477, dtype=float32), 'eval/episode_distance_reward': Array(37.439537, dtype=float32), 'eval/episode_forward_reward': Array(6239.8877, dtype=float32), 'eval/episode_reward': Array(6199.336, dtype=float32), 'eval/episode_reward_alive': Array(357.20312, dtype=float32), 'eval/episode_reward_linvel': Array(6239.8877, dtype=float32), 'eval/episode_reward_quadctrl': Array(-435.1948, dtype=float32), 'eval/episode_x_position': Array(7496.0996, dtype=float32), 'eval/episode_x_velocity': Array(1247.9775, dtype=float32), 'eval/episode_y_position': Array(7.069313, dtype=float32), 'eval/episode_y_velocity': Array(-98.078995, dtype=float32), 'eval/episode_distance_from_origin_std': Array(494.43622, dtype=float32), 'eval/episode_distance_reward_std': Array(6.120343, dtype=float32), 'eval/episode_forward_reward_std': Array(1020.05, dtype=float32), 'eval/episode_reward_std': Array(1084.656, dtype=float32), 'eval/episode_reward_alive_std': Array(57.484795, dtype=float32), 'eval/episode_reward_linvel_std': Array(1020.05, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.432037, dtype=float32), 'eval/episode_x_position_std': Array(498.34308, dtype=float32), 'eval/episode_x_velocity_std': Array(204.01, dtype=float32), 'eval/episode_y_position_std': Array(356.05838, dtype=float32), 'eval/episode_y_velocity_std': Array(121.29058, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7248272895813, 'eval/sps': 936.1869569518473, 'num_steps': 73564160}
{'eval/walltime': 122880.12691354752, 'training/sps': 2960.8434662782565, 'training/walltime': 25022.38721227646, 'training/entropy_loss': Array(0.02169321, dtype=float32), 'training/policy_loss': Array(0.00953001, dtype=float32), 'training/total_loss': Array(0.2505504, dtype=float32), 'training/v_loss': Array(0.21932718, dtype=float32), 'eval/episode_distance_from_origin': Array(7546.1787, dtype=float32), 'eval/episode_distance_reward': Array(37.199646, dtype=float32), 'eval/episode_forward_reward': Array(6199.9062, dtype=float32), 'eval/episode_reward': Array(6163.627, dtype=float32), 'eval/episode_reward_alive': Array(359.59766, dtype=float32), 'eval/episode_reward_linvel': Array(6199.9062, dtype=float32), 'eval/episode_reward_quadctrl': Array(-433.07678, dtype=float32), 'eval/episode_x_position': Array(7508.825, dtype=float32), 'eval/episode_x_velocity': Array(1239.9812, dtype=float32), 'eval/episode_y_position': Array(-97.189064, dtype=float32), 'eval/episode_y_velocity': Array(-118.77084, dtype=float32), 'eval/episode_distance_from_origin_std': Array(456.184, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6888943, dtype=float32), 'eval/episode_forward_reward_std': Array(948.1424, dtype=float32), 'eval/episode_reward_std': Array(999.5285, dtype=float32), 'eval/episode_reward_alive_std': Array(50.466614, dtype=float32), 'eval/episode_reward_linvel_std': Array(948.1424, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.46691, dtype=float32), 'eval/episode_x_position_std': Array(455.3906, dtype=float32), 'eval/episode_x_velocity_std': Array(189.6285, dtype=float32), 'eval/episode_y_position_std': Array(297.4638, dtype=float32), 'eval/episode_y_velocity_std': Array(104.05159, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.192768573761, 'eval/sps': 939.8443202267098, 'num_steps': 73646080}
{'eval/walltime': 123016.83143353462, 'training/sps': 2959.5742990333574, 'training/walltime': 25050.066868782043, 'training/entropy_loss': Array(0.0226783, dtype=float32), 'training/policy_loss': Array(0.02587539, dtype=float32), 'training/total_loss': Array(0.26443103, dtype=float32), 'training/v_loss': Array(0.21587735, dtype=float32), 'eval/episode_distance_from_origin': Array(7537.168, dtype=float32), 'eval/episode_distance_reward': Array(37.805923, dtype=float32), 'eval/episode_forward_reward': Array(6300.9517, dtype=float32), 'eval/episode_reward': Array(6271.8267, dtype=float32), 'eval/episode_reward_alive': Array(344.5039, dtype=float32), 'eval/episode_reward_linvel': Array(6300.9517, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.43512, dtype=float32), 'eval/episode_x_position': Array(7501.3184, dtype=float32), 'eval/episode_x_velocity': Array(1260.1903, dtype=float32), 'eval/episode_y_position': Array(67.79816, dtype=float32), 'eval/episode_y_velocity': Array(-68.26567, dtype=float32), 'eval/episode_distance_from_origin_std': Array(430.40433, dtype=float32), 'eval/episode_distance_reward_std': Array(5.311168, dtype=float32), 'eval/episode_forward_reward_std': Array(885.18805, dtype=float32), 'eval/episode_reward_std': Array(937.4982, dtype=float32), 'eval/episode_reward_alive_std': Array(49.197487, dtype=float32), 'eval/episode_reward_linvel_std': Array(885.18805, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.460785, dtype=float32), 'eval/episode_x_position_std': Array(430.71255, dtype=float32), 'eval/episode_x_velocity_std': Array(177.03764, dtype=float32), 'eval/episode_y_position_std': Array(324.24707, dtype=float32), 'eval/episode_y_velocity_std': Array(122.63848, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70451998710632, 'eval/sps': 936.3260264698832, 'num_steps': 73728000}
{'eval/walltime': 123153.04335284233, 'training/sps': 2964.863977502482, 'training/walltime': 25077.69714140892, 'training/entropy_loss': Array(0.0136046, dtype=float32), 'training/policy_loss': Array(0.00993698, dtype=float32), 'training/total_loss': Array(0.06704289, dtype=float32), 'training/v_loss': Array(0.0435013, dtype=float32), 'eval/episode_distance_from_origin': Array(7519.202, dtype=float32), 'eval/episode_distance_reward': Array(37.578133, dtype=float32), 'eval/episode_forward_reward': Array(6262.988, dtype=float32), 'eval/episode_reward': Array(6233.7036, dtype=float32), 'eval/episode_reward_alive': Array(344.9961, dtype=float32), 'eval/episode_reward_linvel': Array(6262.988, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.8588, dtype=float32), 'eval/episode_x_position': Array(7482.2236, dtype=float32), 'eval/episode_x_velocity': Array(1252.5977, dtype=float32), 'eval/episode_y_position': Array(79.97635, dtype=float32), 'eval/episode_y_velocity': Array(-73.12609, dtype=float32), 'eval/episode_distance_from_origin_std': Array(483.12296, dtype=float32), 'eval/episode_distance_reward_std': Array(6.455836, dtype=float32), 'eval/episode_forward_reward_std': Array(1075.9641, dtype=float32), 'eval/episode_reward_std': Array(1145.9683, dtype=float32), 'eval/episode_reward_alive_std': Array(58.68725, dtype=float32), 'eval/episode_reward_linvel_std': Array(1075.9641, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.256905, dtype=float32), 'eval/episode_x_position_std': Array(484.351, dtype=float32), 'eval/episode_x_velocity_std': Array(215.19283, dtype=float32), 'eval/episode_y_position_std': Array(340.58426, dtype=float32), 'eval/episode_y_velocity_std': Array(114.00013, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21191930770874, 'eval/sps': 939.7121826823566, 'num_steps': 73809920}
{'eval/walltime': 123289.63294267654, 'training/sps': 2951.9223860498164, 'training/walltime': 25105.448548555374, 'training/entropy_loss': Array(0.01729209, dtype=float32), 'training/policy_loss': Array(0.0094417, dtype=float32), 'training/total_loss': Array(0.2258459, dtype=float32), 'training/v_loss': Array(0.19911212, dtype=float32), 'eval/episode_distance_from_origin': Array(7564.7666, dtype=float32), 'eval/episode_distance_reward': Array(37.741188, dtype=float32), 'eval/episode_forward_reward': Array(6290.164, dtype=float32), 'eval/episode_reward': Array(6262.546, dtype=float32), 'eval/episode_reward_alive': Array(350.46484, dtype=float32), 'eval/episode_reward_linvel': Array(6290.164, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.8239, dtype=float32), 'eval/episode_x_position': Array(7529.1016, dtype=float32), 'eval/episode_x_velocity': Array(1258.0328, dtype=float32), 'eval/episode_y_position': Array(21.532606, dtype=float32), 'eval/episode_y_velocity': Array(-82.10041, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.86533, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4117513, dtype=float32), 'eval/episode_forward_reward_std': Array(1068.6183, dtype=float32), 'eval/episode_reward_std': Array(1123.818, dtype=float32), 'eval/episode_reward_alive_std': Array(51.078033, dtype=float32), 'eval/episode_reward_linvel_std': Array(1068.6183, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.56495, dtype=float32), 'eval/episode_x_position_std': Array(486.7777, dtype=float32), 'eval/episode_x_velocity_std': Array(213.72365, dtype=float32), 'eval/episode_y_position_std': Array(313.3571, dtype=float32), 'eval/episode_y_velocity_std': Array(115.68712, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.58958983421326, 'eval/sps': 937.1138763602779, 'num_steps': 73891840}
{'eval/walltime': 123425.8390314579, 'training/sps': 2957.0956211517873, 'training/walltime': 25133.151406526566, 'training/entropy_loss': Array(0.0206791, dtype=float32), 'training/policy_loss': Array(0.00631968, dtype=float32), 'training/total_loss': Array(0.2905299, dtype=float32), 'training/v_loss': Array(0.26353112, dtype=float32), 'eval/episode_distance_from_origin': Array(7521.3677, dtype=float32), 'eval/episode_distance_reward': Array(37.549164, dtype=float32), 'eval/episode_forward_reward': Array(6258.159, dtype=float32), 'eval/episode_reward': Array(6234.4155, dtype=float32), 'eval/episode_reward_alive': Array(348.98047, dtype=float32), 'eval/episode_reward_linvel': Array(6258.159, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.27255, dtype=float32), 'eval/episode_x_position': Array(7483.3057, dtype=float32), 'eval/episode_x_velocity': Array(1251.6317, dtype=float32), 'eval/episode_y_position': Array(84.13156, dtype=float32), 'eval/episode_y_velocity': Array(-74.60776, dtype=float32), 'eval/episode_distance_from_origin_std': Array(477.7681, dtype=float32), 'eval/episode_distance_reward_std': Array(5.600664, dtype=float32), 'eval/episode_forward_reward_std': Array(933.437, dtype=float32), 'eval/episode_reward_std': Array(985.802, dtype=float32), 'eval/episode_reward_alive_std': Array(50.897392, dtype=float32), 'eval/episode_reward_linvel_std': Array(933.437, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.89975, dtype=float32), 'eval/episode_x_position_std': Array(479.5049, dtype=float32), 'eval/episode_x_velocity_std': Array(186.68747, dtype=float32), 'eval/episode_y_position_std': Array(355.97653, dtype=float32), 'eval/episode_y_velocity_std': Array(117.97273, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2060887813568, 'eval/sps': 939.7524086127344, 'num_steps': 73973760}
{'eval/walltime': 123562.43491840363, 'training/sps': 2948.747331786007, 'training/walltime': 25160.932694911957, 'training/entropy_loss': Array(0.01919821, dtype=float32), 'training/policy_loss': Array(0.00408775, dtype=float32), 'training/total_loss': Array(0.23143631, dtype=float32), 'training/v_loss': Array(0.20815036, dtype=float32), 'eval/episode_distance_from_origin': Array(7544.449, dtype=float32), 'eval/episode_distance_reward': Array(38.025238, dtype=float32), 'eval/episode_forward_reward': Array(6337.505, dtype=float32), 'eval/episode_reward': Array(6313.688, dtype=float32), 'eval/episode_reward_alive': Array(350.67188, dtype=float32), 'eval/episode_reward_linvel': Array(6337.505, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.51422, dtype=float32), 'eval/episode_x_position': Array(7506.6816, dtype=float32), 'eval/episode_x_velocity': Array(1267.501, dtype=float32), 'eval/episode_y_position': Array(39.36449, dtype=float32), 'eval/episode_y_velocity': Array(-84.77483, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.25076, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5897207, dtype=float32), 'eval/episode_forward_reward_std': Array(931.6148, dtype=float32), 'eval/episode_reward_std': Array(972.94324, dtype=float32), 'eval/episode_reward_alive_std': Array(46.323437, dtype=float32), 'eval/episode_reward_linvel_std': Array(931.6148, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.73801, dtype=float32), 'eval/episode_x_position_std': Array(472.0172, dtype=float32), 'eval/episode_x_velocity_std': Array(186.32304, dtype=float32), 'eval/episode_y_position_std': Array(338.0219, dtype=float32), 'eval/episode_y_velocity_std': Array(124.4532, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5958869457245, 'eval/sps': 937.0706751284538, 'num_steps': 74055680}
{'eval/walltime': 123698.64396715164, 'training/sps': 2955.978805849111, 'training/walltime': 25188.64601945877, 'training/entropy_loss': Array(0.01913003, dtype=float32), 'training/policy_loss': Array(0.00435021, dtype=float32), 'training/total_loss': Array(0.24346921, dtype=float32), 'training/v_loss': Array(0.21998897, dtype=float32), 'eval/episode_distance_from_origin': Array(7531.834, dtype=float32), 'eval/episode_distance_reward': Array(37.832664, dtype=float32), 'eval/episode_forward_reward': Array(6305.408, dtype=float32), 'eval/episode_reward': Array(6285.5654, dtype=float32), 'eval/episode_reward_alive': Array(351., dtype=float32), 'eval/episode_reward_linvel': Array(6305.408, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.67578, dtype=float32), 'eval/episode_x_position': Array(7495.0464, dtype=float32), 'eval/episode_x_velocity': Array(1261.0815, dtype=float32), 'eval/episode_y_position': Array(15.005522, dtype=float32), 'eval/episode_y_velocity': Array(-75.41145, dtype=float32), 'eval/episode_distance_from_origin_std': Array(416.5425, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4006014, dtype=float32), 'eval/episode_forward_reward_std': Array(900.0939, dtype=float32), 'eval/episode_reward_std': Array(940.88196, dtype=float32), 'eval/episode_reward_alive_std': Array(46.75493, dtype=float32), 'eval/episode_reward_linvel_std': Array(900.0939, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.266193, dtype=float32), 'eval/episode_x_position_std': Array(418.36203, dtype=float32), 'eval/episode_x_velocity_std': Array(180.01889, dtype=float32), 'eval/episode_y_position_std': Array(347.85922, dtype=float32), 'eval/episode_y_velocity_std': Array(122.66434, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20904874801636, 'eval/sps': 939.7319867991816, 'num_steps': 74137600}
{'eval/walltime': 123835.08762335777, 'training/sps': 2943.5735331899054, 'training/walltime': 25216.47613787651, 'training/entropy_loss': Array(0.01990303, dtype=float32), 'training/policy_loss': Array(0.00555599, dtype=float32), 'training/total_loss': Array(0.25770134, dtype=float32), 'training/v_loss': Array(0.23224235, dtype=float32), 'eval/episode_distance_from_origin': Array(7480.9326, dtype=float32), 'eval/episode_distance_reward': Array(38.000153, dtype=float32), 'eval/episode_forward_reward': Array(6333.323, dtype=float32), 'eval/episode_reward': Array(6312.0513, dtype=float32), 'eval/episode_reward_alive': Array(350.0703, dtype=float32), 'eval/episode_reward_linvel': Array(6333.323, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.3423, dtype=float32), 'eval/episode_x_position': Array(7443.6, dtype=float32), 'eval/episode_x_velocity': Array(1266.6647, dtype=float32), 'eval/episode_y_position': Array(68.54791, dtype=float32), 'eval/episode_y_velocity': Array(-73.47028, dtype=float32), 'eval/episode_distance_from_origin_std': Array(499.19894, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1163464, dtype=float32), 'eval/episode_forward_reward_std': Array(1019.3843, dtype=float32), 'eval/episode_reward_std': Array(1066.3912, dtype=float32), 'eval/episode_reward_alive_std': Array(52.14608, dtype=float32), 'eval/episode_reward_linvel_std': Array(1019.3843, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.24869, dtype=float32), 'eval/episode_x_position_std': Array(502.46417, dtype=float32), 'eval/episode_x_velocity_std': Array(203.87694, dtype=float32), 'eval/episode_y_position_std': Array(327.6233, dtype=float32), 'eval/episode_y_velocity_std': Array(117.01177, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44365620613098, 'eval/sps': 938.1161686742342, 'num_steps': 74219520}
{'eval/walltime': 123971.29970860481, 'training/sps': 2951.5135786120495, 'training/walltime': 25244.231388807297, 'training/entropy_loss': Array(0.01479227, dtype=float32), 'training/policy_loss': Array(0.00580979, dtype=float32), 'training/total_loss': Array(0.08723016, dtype=float32), 'training/v_loss': Array(0.06662811, dtype=float32), 'eval/episode_distance_from_origin': Array(7598.7373, dtype=float32), 'eval/episode_distance_reward': Array(38.765903, dtype=float32), 'eval/episode_forward_reward': Array(6460.9487, dtype=float32), 'eval/episode_reward': Array(6436.794, dtype=float32), 'eval/episode_reward_alive': Array(347.27734, dtype=float32), 'eval/episode_reward_linvel': Array(6460.9487, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.19733, dtype=float32), 'eval/episode_x_position': Array(7562.163, dtype=float32), 'eval/episode_x_velocity': Array(1292.1897, dtype=float32), 'eval/episode_y_position': Array(41.09359, dtype=float32), 'eval/episode_y_velocity': Array(-80.68938, dtype=float32), 'eval/episode_distance_from_origin_std': Array(521.28827, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3377542, dtype=float32), 'eval/episode_forward_reward_std': Array(1056.2854, dtype=float32), 'eval/episode_reward_std': Array(1103.5791, dtype=float32), 'eval/episode_reward_alive_std': Array(50.390266, dtype=float32), 'eval/episode_reward_linvel_std': Array(1056.2854, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.49106, dtype=float32), 'eval/episode_x_position_std': Array(524.5301, dtype=float32), 'eval/episode_x_velocity_std': Array(211.25725, dtype=float32), 'eval/episode_y_position_std': Array(328.41052, dtype=float32), 'eval/episode_y_velocity_std': Array(120.20498, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2120852470398, 'eval/sps': 939.7110378851772, 'num_steps': 74301440}
{'eval/walltime': 124107.7377512455, 'training/sps': 2947.467853891053, 'training/walltime': 25272.024736881256, 'training/entropy_loss': Array(0.01773128, dtype=float32), 'training/policy_loss': Array(0.00913418, dtype=float32), 'training/total_loss': Array(0.20095216, dtype=float32), 'training/v_loss': Array(0.1740867, dtype=float32), 'eval/episode_distance_from_origin': Array(7428.0137, dtype=float32), 'eval/episode_distance_reward': Array(36.727535, dtype=float32), 'eval/episode_forward_reward': Array(6121.222, dtype=float32), 'eval/episode_reward': Array(6088.801, dtype=float32), 'eval/episode_reward_alive': Array(341.85547, dtype=float32), 'eval/episode_reward_linvel': Array(6121.222, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.00427, dtype=float32), 'eval/episode_x_position': Array(7394.146, dtype=float32), 'eval/episode_x_velocity': Array(1224.2444, dtype=float32), 'eval/episode_y_position': Array(50.482723, dtype=float32), 'eval/episode_y_velocity': Array(-74.578094, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.22888, dtype=float32), 'eval/episode_distance_reward_std': Array(5.509039, dtype=float32), 'eval/episode_forward_reward_std': Array(918.1661, dtype=float32), 'eval/episode_reward_std': Array(975.7261, dtype=float32), 'eval/episode_reward_alive_std': Array(54.891766, dtype=float32), 'eval/episode_reward_linvel_std': Array(918.1661, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.95244, dtype=float32), 'eval/episode_x_position_std': Array(452.10587, dtype=float32), 'eval/episode_x_velocity_std': Array(183.63324, dtype=float32), 'eval/episode_y_position_std': Array(296.5323, dtype=float32), 'eval/episode_y_velocity_std': Array(96.31915, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43804264068604, 'eval/sps': 938.1547662413489, 'num_steps': 74383360}
{'eval/walltime': 124243.95299053192, 'training/sps': 2957.4416234364194, 'training/walltime': 25299.724353790283, 'training/entropy_loss': Array(0.02083387, dtype=float32), 'training/policy_loss': Array(0.00813585, dtype=float32), 'training/total_loss': Array(0.30119923, dtype=float32), 'training/v_loss': Array(0.27222952, dtype=float32), 'eval/episode_distance_from_origin': Array(7493.2207, dtype=float32), 'eval/episode_distance_reward': Array(37.37854, dtype=float32), 'eval/episode_forward_reward': Array(6229.724, dtype=float32), 'eval/episode_reward': Array(6199.589, dtype=float32), 'eval/episode_reward_alive': Array(340.1797, dtype=float32), 'eval/episode_reward_linvel': Array(6229.724, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.69333, dtype=float32), 'eval/episode_x_position': Array(7455.0977, dtype=float32), 'eval/episode_x_velocity': Array(1245.9447, dtype=float32), 'eval/episode_y_position': Array(14.581707, dtype=float32), 'eval/episode_y_velocity': Array(-81.03105, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.68323, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5165806, dtype=float32), 'eval/episode_forward_reward_std': Array(1086.0894, dtype=float32), 'eval/episode_reward_std': Array(1140.9803, dtype=float32), 'eval/episode_reward_alive_std': Array(57.590816, dtype=float32), 'eval/episode_reward_linvel_std': Array(1086.0894, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.39835, dtype=float32), 'eval/episode_x_position_std': Array(489.42303, dtype=float32), 'eval/episode_x_velocity_std': Array(217.21802, dtype=float32), 'eval/episode_y_position_std': Array(362.84122, dtype=float32), 'eval/episode_y_velocity_std': Array(119.39973, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21523928642273, 'eval/sps': 939.6892790449946, 'num_steps': 74465280}
{'eval/walltime': 124380.39085817337, 'training/sps': 2945.6355390376193, 'training/walltime': 25327.534990549088, 'training/entropy_loss': Array(0.02000995, dtype=float32), 'training/policy_loss': Array(0.00463326, dtype=float32), 'training/total_loss': Array(0.21122576, dtype=float32), 'training/v_loss': Array(0.18658255, dtype=float32), 'eval/episode_distance_from_origin': Array(7519.945, dtype=float32), 'eval/episode_distance_reward': Array(38.087143, dtype=float32), 'eval/episode_forward_reward': Array(6347.8213, dtype=float32), 'eval/episode_reward': Array(6326.523, dtype=float32), 'eval/episode_reward_alive': Array(350.32422, dtype=float32), 'eval/episode_reward_linvel': Array(6347.8213, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.70898, dtype=float32), 'eval/episode_x_position': Array(7484.335, dtype=float32), 'eval/episode_x_velocity': Array(1269.5643, dtype=float32), 'eval/episode_y_position': Array(50.044712, dtype=float32), 'eval/episode_y_velocity': Array(-74.98282, dtype=float32), 'eval/episode_distance_from_origin_std': Array(539.64056, dtype=float32), 'eval/episode_distance_reward_std': Array(6.8479886, dtype=float32), 'eval/episode_forward_reward_std': Array(1141.3241, dtype=float32), 'eval/episode_reward_std': Array(1195.0697, dtype=float32), 'eval/episode_reward_alive_std': Array(54.992027, dtype=float32), 'eval/episode_reward_linvel_std': Array(1141.3241, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.548367, dtype=float32), 'eval/episode_x_position_std': Array(541.97876, dtype=float32), 'eval/episode_x_velocity_std': Array(228.26488, dtype=float32), 'eval/episode_y_position_std': Array(316.9578, dtype=float32), 'eval/episode_y_velocity_std': Array(119.59353, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43786764144897, 'eval/sps': 938.155969546349, 'num_steps': 74547200}
{'eval/walltime': 124516.61043334007, 'training/sps': 2955.821120498897, 'training/walltime': 25355.24979352951, 'training/entropy_loss': Array(0.01922899, dtype=float32), 'training/policy_loss': Array(0.00440608, dtype=float32), 'training/total_loss': Array(0.23820882, dtype=float32), 'training/v_loss': Array(0.21457376, dtype=float32), 'eval/episode_distance_from_origin': Array(7547.7124, dtype=float32), 'eval/episode_distance_reward': Array(38.384842, dtype=float32), 'eval/episode_forward_reward': Array(6397.4395, dtype=float32), 'eval/episode_reward': Array(6372.0674, dtype=float32), 'eval/episode_reward_alive': Array(344.72656, dtype=float32), 'eval/episode_reward_linvel': Array(6397.4395, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.48395, dtype=float32), 'eval/episode_x_position': Array(7509.71, dtype=float32), 'eval/episode_x_velocity': Array(1279.4879, dtype=float32), 'eval/episode_y_position': Array(16.345009, dtype=float32), 'eval/episode_y_velocity': Array(-89.27048, dtype=float32), 'eval/episode_distance_from_origin_std': Array(548.68396, dtype=float32), 'eval/episode_distance_reward_std': Array(6.7593913, dtype=float32), 'eval/episode_forward_reward_std': Array(1126.5585, dtype=float32), 'eval/episode_reward_std': Array(1182.2883, dtype=float32), 'eval/episode_reward_alive_std': Array(54.113445, dtype=float32), 'eval/episode_reward_linvel_std': Array(1126.5585, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.677555, dtype=float32), 'eval/episode_x_position_std': Array(551.1296, dtype=float32), 'eval/episode_x_velocity_std': Array(225.31172, dtype=float32), 'eval/episode_y_position_std': Array(344.53125, dtype=float32), 'eval/episode_y_velocity_std': Array(114.05584, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21957516670227, 'eval/sps': 939.6593686579674, 'num_steps': 74629120}
{'eval/walltime': 124653.03870463371, 'training/sps': 2940.7037969122853, 'training/walltime': 25383.107070446014, 'training/entropy_loss': Array(0.01984282, dtype=float32), 'training/policy_loss': Array(0.01653661, dtype=float32), 'training/total_loss': Array(0.26663935, dtype=float32), 'training/v_loss': Array(0.23025993, dtype=float32), 'eval/episode_distance_from_origin': Array(7487.3955, dtype=float32), 'eval/episode_distance_reward': Array(37.746155, dtype=float32), 'eval/episode_forward_reward': Array(6290.991, dtype=float32), 'eval/episode_reward': Array(6265.395, dtype=float32), 'eval/episode_reward_alive': Array(346.6172, dtype=float32), 'eval/episode_reward_linvel': Array(6290.991, dtype=float32), 'eval/episode_reward_quadctrl': Array(-409.9597, dtype=float32), 'eval/episode_x_position': Array(7450.2983, dtype=float32), 'eval/episode_x_velocity': Array(1258.198, dtype=float32), 'eval/episode_y_position': Array(54.189796, dtype=float32), 'eval/episode_y_velocity': Array(-68.93048, dtype=float32), 'eval/episode_distance_from_origin_std': Array(512.6821, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4794884, dtype=float32), 'eval/episode_forward_reward_std': Array(1079.9089, dtype=float32), 'eval/episode_reward_std': Array(1130.7341, dtype=float32), 'eval/episode_reward_alive_std': Array(52.61288, dtype=float32), 'eval/episode_reward_linvel_std': Array(1079.9089, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.600597, dtype=float32), 'eval/episode_x_position_std': Array(512.6952, dtype=float32), 'eval/episode_x_velocity_std': Array(215.98169, dtype=float32), 'eval/episode_y_position_std': Array(339.53534, dtype=float32), 'eval/episode_y_velocity_std': Array(124.88855, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42827129364014, 'eval/sps': 938.2219593217624, 'num_steps': 74711040}
{'eval/walltime': 124789.22898006439, 'training/sps': 2956.447104112198, 'training/walltime': 25410.81600522995, 'training/entropy_loss': Array(0.01641316, dtype=float32), 'training/policy_loss': Array(0.00683314, dtype=float32), 'training/total_loss': Array(0.14975928, dtype=float32), 'training/v_loss': Array(0.12651297, dtype=float32), 'eval/episode_distance_from_origin': Array(7550.65, dtype=float32), 'eval/episode_distance_reward': Array(37.695557, dtype=float32), 'eval/episode_forward_reward': Array(6282.5596, dtype=float32), 'eval/episode_reward': Array(6251.9854, dtype=float32), 'eval/episode_reward_alive': Array(343.1172, dtype=float32), 'eval/episode_reward_linvel': Array(6282.5596, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.38617, dtype=float32), 'eval/episode_x_position': Array(7512.703, dtype=float32), 'eval/episode_x_velocity': Array(1256.5118, dtype=float32), 'eval/episode_y_position': Array(88.09648, dtype=float32), 'eval/episode_y_velocity': Array(-75.10954, dtype=float32), 'eval/episode_distance_from_origin_std': Array(528.7935, dtype=float32), 'eval/episode_distance_reward_std': Array(6.997375, dtype=float32), 'eval/episode_forward_reward_std': Array(1166.2208, dtype=float32), 'eval/episode_reward_std': Array(1228.9138, dtype=float32), 'eval/episode_reward_alive_std': Array(55.7968, dtype=float32), 'eval/episode_reward_linvel_std': Array(1166.2208, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.577415, dtype=float32), 'eval/episode_x_position_std': Array(531.10156, dtype=float32), 'eval/episode_x_velocity_std': Array(233.24422, dtype=float32), 'eval/episode_y_position_std': Array(346.26938, dtype=float32), 'eval/episode_y_velocity_std': Array(125.249466, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.19027543067932, 'eval/sps': 939.8615253197856, 'num_steps': 74792960}
{'eval/walltime': 124925.66234326363, 'training/sps': 2951.2394301920654, 'training/walltime': 25438.57383441925, 'training/entropy_loss': Array(0.01621908, dtype=float32), 'training/policy_loss': Array(0.00885842, dtype=float32), 'training/total_loss': Array(0.1340062, dtype=float32), 'training/v_loss': Array(0.1089287, dtype=float32), 'eval/episode_distance_from_origin': Array(7489.738, dtype=float32), 'eval/episode_distance_reward': Array(36.600487, dtype=float32), 'eval/episode_forward_reward': Array(6100.048, dtype=float32), 'eval/episode_reward': Array(6067.58, dtype=float32), 'eval/episode_reward_alive': Array(339.33984, dtype=float32), 'eval/episode_reward_linvel': Array(6100.048, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.40778, dtype=float32), 'eval/episode_x_position': Array(7453.5825, dtype=float32), 'eval/episode_x_velocity': Array(1220.0095, dtype=float32), 'eval/episode_y_position': Array(66.048, dtype=float32), 'eval/episode_y_velocity': Array(-70.96234, dtype=float32), 'eval/episode_distance_from_origin_std': Array(508.0447, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2741013, dtype=float32), 'eval/episode_forward_reward_std': Array(1045.6758, dtype=float32), 'eval/episode_reward_std': Array(1081.1956, dtype=float32), 'eval/episode_reward_alive_std': Array(48.905155, dtype=float32), 'eval/episode_reward_linvel_std': Array(1045.6758, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.48861, dtype=float32), 'eval/episode_x_position_std': Array(508.7607, dtype=float32), 'eval/episode_x_velocity_std': Array(209.1351, dtype=float32), 'eval/episode_y_position_std': Array(327.25888, dtype=float32), 'eval/episode_y_velocity_std': Array(103.862144, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.433363199234, 'eval/sps': 938.1869434170677, 'num_steps': 74874880}
{'eval/walltime': 125061.86948919296, 'training/sps': 2944.9200507685455, 'training/walltime': 25466.391227960587, 'training/entropy_loss': Array(0.01997199, dtype=float32), 'training/policy_loss': Array(0.00736246, dtype=float32), 'training/total_loss': Array(0.27180332, dtype=float32), 'training/v_loss': Array(0.2444689, dtype=float32), 'eval/episode_distance_from_origin': Array(7414.1387, dtype=float32), 'eval/episode_distance_reward': Array(36.55487, dtype=float32), 'eval/episode_forward_reward': Array(6092.4443, dtype=float32), 'eval/episode_reward': Array(6065.099, dtype=float32), 'eval/episode_reward_alive': Array(347.94922, dtype=float32), 'eval/episode_reward_linvel': Array(6092.4443, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.8494, dtype=float32), 'eval/episode_x_position': Array(7376.368, dtype=float32), 'eval/episode_x_velocity': Array(1218.489, dtype=float32), 'eval/episode_y_position': Array(122.02727, dtype=float32), 'eval/episode_y_velocity': Array(-56.122646, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.70288, dtype=float32), 'eval/episode_distance_reward_std': Array(5.893622, dtype=float32), 'eval/episode_forward_reward_std': Array(982.26245, dtype=float32), 'eval/episode_reward_std': Array(1025.5463, dtype=float32), 'eval/episode_reward_alive_std': Array(49.952625, dtype=float32), 'eval/episode_reward_linvel_std': Array(982.26245, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.778065, dtype=float32), 'eval/episode_x_position_std': Array(483.91037, dtype=float32), 'eval/episode_x_velocity_std': Array(196.45242, dtype=float32), 'eval/episode_y_position_std': Array(339.9344, dtype=float32), 'eval/episode_y_velocity_std': Array(125.62977, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20714592933655, 'eval/sps': 939.7451148885069, 'num_steps': 74956800}
{'eval/walltime': 125198.32848286629, 'training/sps': 2935.8225306032778, 'training/walltime': 25494.294821977615, 'training/entropy_loss': Array(0.02012238, dtype=float32), 'training/policy_loss': Array(0.05686808, dtype=float32), 'training/total_loss': Array(0.2750191, dtype=float32), 'training/v_loss': Array(0.19802868, dtype=float32), 'eval/episode_distance_from_origin': Array(7407.9775, dtype=float32), 'eval/episode_distance_reward': Array(37.68347, dtype=float32), 'eval/episode_forward_reward': Array(6280.545, dtype=float32), 'eval/episode_reward': Array(6272.158, dtype=float32), 'eval/episode_reward_alive': Array(366.13672, dtype=float32), 'eval/episode_reward_linvel': Array(6280.545, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.2066, dtype=float32), 'eval/episode_x_position': Array(7358.994, dtype=float32), 'eval/episode_x_velocity': Array(1256.1089, dtype=float32), 'eval/episode_y_position': Array(344.66714, dtype=float32), 'eval/episode_y_velocity': Array(-6.1751995, dtype=float32), 'eval/episode_distance_from_origin_std': Array(497.53915, dtype=float32), 'eval/episode_distance_reward_std': Array(6.513272, dtype=float32), 'eval/episode_forward_reward_std': Array(1085.538, dtype=float32), 'eval/episode_reward_std': Array(1140.1377, dtype=float32), 'eval/episode_reward_alive_std': Array(60.187817, dtype=float32), 'eval/episode_reward_linvel_std': Array(1085.538, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.364025, dtype=float32), 'eval/episode_x_position_std': Array(506.5354, dtype=float32), 'eval/episode_x_velocity_std': Array(217.10757, dtype=float32), 'eval/episode_y_position_std': Array(390.65634, dtype=float32), 'eval/episode_y_velocity_std': Array(131.41159, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45899367332458, 'eval/sps': 938.010728017129, 'num_steps': 75038720}
{'eval/walltime': 125334.53274130821, 'training/sps': 2938.025871344646, 'training/walltime': 25522.177489995956, 'training/entropy_loss': Array(0.02001011, dtype=float32), 'training/policy_loss': Array(0.0110773, dtype=float32), 'training/total_loss': Array(0.22100566, dtype=float32), 'training/v_loss': Array(0.18991825, dtype=float32), 'eval/episode_distance_from_origin': Array(7392.2974, dtype=float32), 'eval/episode_distance_reward': Array(37.352074, dtype=float32), 'eval/episode_forward_reward': Array(6225.3115, dtype=float32), 'eval/episode_reward': Array(6219.508, dtype=float32), 'eval/episode_reward_alive': Array(370.42188, dtype=float32), 'eval/episode_reward_linvel': Array(6225.3115, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.57764, dtype=float32), 'eval/episode_x_position': Array(7337.9194, dtype=float32), 'eval/episode_x_velocity': Array(1245.0624, dtype=float32), 'eval/episode_y_position': Array(355.63956, dtype=float32), 'eval/episode_y_velocity': Array(-1.4251244, dtype=float32), 'eval/episode_distance_from_origin_std': Array(486.27887, dtype=float32), 'eval/episode_distance_reward_std': Array(5.640485, dtype=float32), 'eval/episode_forward_reward_std': Array(940.07465, dtype=float32), 'eval/episode_reward_std': Array(984.0972, dtype=float32), 'eval/episode_reward_alive_std': Array(52.653103, dtype=float32), 'eval/episode_reward_linvel_std': Array(940.07465, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.881573, dtype=float32), 'eval/episode_x_position_std': Array(494.10843, dtype=float32), 'eval/episode_x_velocity_std': Array(188.01486, dtype=float32), 'eval/episode_y_position_std': Array(460.01056, dtype=float32), 'eval/episode_y_velocity_std': Array(150.12231, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20425844192505, 'eval/sps': 939.7650371891772, 'num_steps': 75120640}
{'eval/walltime': 125470.979129076, 'training/sps': 2935.2935384231823, 'training/walltime': 25550.086112737656, 'training/entropy_loss': Array(0.02061406, dtype=float32), 'training/policy_loss': Array(0.00627805, dtype=float32), 'training/total_loss': Array(0.24427283, dtype=float32), 'training/v_loss': Array(0.2173807, dtype=float32), 'eval/episode_distance_from_origin': Array(7353.0063, dtype=float32), 'eval/episode_distance_reward': Array(37.614616, dtype=float32), 'eval/episode_forward_reward': Array(6269.0693, dtype=float32), 'eval/episode_reward': Array(6280.5127, dtype=float32), 'eval/episode_reward_alive': Array(377.91016, dtype=float32), 'eval/episode_reward_linvel': Array(6269.0693, dtype=float32), 'eval/episode_reward_quadctrl': Array(-404.08038, dtype=float32), 'eval/episode_x_position': Array(7303.463, dtype=float32), 'eval/episode_x_velocity': Array(1253.8138, dtype=float32), 'eval/episode_y_position': Array(347.5003, dtype=float32), 'eval/episode_y_velocity': Array(-9.298611, dtype=float32), 'eval/episode_distance_from_origin_std': Array(535.2481, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4476438, dtype=float32), 'eval/episode_forward_reward_std': Array(1074.6008, dtype=float32), 'eval/episode_reward_std': Array(1104.297, dtype=float32), 'eval/episode_reward_alive_std': Array(47.35341, dtype=float32), 'eval/episode_reward_linvel_std': Array(1074.6008, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.387537, dtype=float32), 'eval/episode_x_position_std': Array(536.54346, dtype=float32), 'eval/episode_x_velocity_std': Array(214.92027, dtype=float32), 'eval/episode_y_position_std': Array(387.60056, dtype=float32), 'eval/episode_y_velocity_std': Array(130.37633, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44638776779175, 'eval/sps': 938.0973882418489, 'num_steps': 75202560}
{'eval/walltime': 125607.19510650635, 'training/sps': 2950.011533808703, 'training/walltime': 25577.8554956913, 'training/entropy_loss': Array(0.01896034, dtype=float32), 'training/policy_loss': Array(0.01859805, dtype=float32), 'training/total_loss': Array(0.18356371, dtype=float32), 'training/v_loss': Array(0.14600533, dtype=float32), 'eval/episode_distance_from_origin': Array(7265.2935, dtype=float32), 'eval/episode_distance_reward': Array(36.20603, dtype=float32), 'eval/episode_forward_reward': Array(6034.3057, dtype=float32), 'eval/episode_reward': Array(6020.849, dtype=float32), 'eval/episode_reward_alive': Array(363.46094, dtype=float32), 'eval/episode_reward_linvel': Array(6034.3057, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.12372, dtype=float32), 'eval/episode_x_position': Array(7218.215, dtype=float32), 'eval/episode_x_velocity': Array(1206.8613, dtype=float32), 'eval/episode_y_position': Array(261.53082, dtype=float32), 'eval/episode_y_velocity': Array(-28.495617, dtype=float32), 'eval/episode_distance_from_origin_std': Array(505.99136, dtype=float32), 'eval/episode_distance_reward_std': Array(6.051752, dtype=float32), 'eval/episode_forward_reward_std': Array(1008.61914, dtype=float32), 'eval/episode_reward_std': Array(1053.5226, dtype=float32), 'eval/episode_reward_alive_std': Array(51.87412, dtype=float32), 'eval/episode_reward_linvel_std': Array(1008.61914, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.15579, dtype=float32), 'eval/episode_x_position_std': Array(511.4045, dtype=float32), 'eval/episode_x_velocity_std': Array(201.7238, dtype=float32), 'eval/episode_y_position_std': Array(409.20004, dtype=float32), 'eval/episode_y_velocity_std': Array(130.65701, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21597743034363, 'eval/sps': 939.6841869409556, 'num_steps': 75284480}
{'eval/walltime': 125743.95115756989, 'training/sps': 2938.3264917950582, 'training/walltime': 25605.73531103134, 'training/entropy_loss': Array(0.0161096, dtype=float32), 'training/policy_loss': Array(0.00547935, dtype=float32), 'training/total_loss': Array(0.13418749, dtype=float32), 'training/v_loss': Array(0.11259855, dtype=float32), 'eval/episode_distance_from_origin': Array(7396.1836, dtype=float32), 'eval/episode_distance_reward': Array(37.511436, dtype=float32), 'eval/episode_forward_reward': Array(6251.872, dtype=float32), 'eval/episode_reward': Array(6243.9355, dtype=float32), 'eval/episode_reward_alive': Array(369.28516, dtype=float32), 'eval/episode_reward_linvel': Array(6251.872, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.73322, dtype=float32), 'eval/episode_x_position': Array(7346.717, dtype=float32), 'eval/episode_x_velocity': Array(1250.3743, dtype=float32), 'eval/episode_y_position': Array(271.8064, dtype=float32), 'eval/episode_y_velocity': Array(-28.02779, dtype=float32), 'eval/episode_distance_from_origin_std': Array(496.09644, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2425594, dtype=float32), 'eval/episode_forward_reward_std': Array(1040.4205, dtype=float32), 'eval/episode_reward_std': Array(1078.5516, dtype=float32), 'eval/episode_reward_alive_std': Array(53.74788, dtype=float32), 'eval/episode_reward_linvel_std': Array(1040.4205, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.984203, dtype=float32), 'eval/episode_x_position_std': Array(500.44574, dtype=float32), 'eval/episode_x_velocity_std': Array(208.08397, dtype=float32), 'eval/episode_y_position_std': Array(437.13376, dtype=float32), 'eval/episode_y_velocity_std': Array(137.67368, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.7560510635376, 'eval/sps': 935.973209262459, 'num_steps': 75366400}
{'eval/walltime': 125880.14211916924, 'training/sps': 2953.3409040632137, 'training/walltime': 25633.473388910294, 'training/entropy_loss': Array(0.01954327, dtype=float32), 'training/policy_loss': Array(0.00709711, dtype=float32), 'training/total_loss': Array(0.33863354, dtype=float32), 'training/v_loss': Array(0.31199312, dtype=float32), 'eval/episode_distance_from_origin': Array(7364.171, dtype=float32), 'eval/episode_distance_reward': Array(37.261383, dtype=float32), 'eval/episode_forward_reward': Array(6210.1973, dtype=float32), 'eval/episode_reward': Array(6198.204, dtype=float32), 'eval/episode_reward_alive': Array(365.82812, dtype=float32), 'eval/episode_reward_linvel': Array(6210.1973, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.0824, dtype=float32), 'eval/episode_x_position': Array(7315.2427, dtype=float32), 'eval/episode_x_velocity': Array(1242.0396, dtype=float32), 'eval/episode_y_position': Array(222.94293, dtype=float32), 'eval/episode_y_velocity': Array(-30.498528, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.41302, dtype=float32), 'eval/episode_distance_reward_std': Array(5.34367, dtype=float32), 'eval/episode_forward_reward_std': Array(890.60596, dtype=float32), 'eval/episode_reward_std': Array(927.62366, dtype=float32), 'eval/episode_reward_alive_std': Array(46.086594, dtype=float32), 'eval/episode_reward_linvel_std': Array(890.60596, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.12424, dtype=float32), 'eval/episode_x_position_std': Array(488.31033, dtype=float32), 'eval/episode_x_velocity_std': Array(178.1212, dtype=float32), 'eval/episode_y_position_std': Array(465.27692, dtype=float32), 'eval/episode_y_velocity_std': Array(145.48154, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.19096159934998, 'eval/sps': 939.8567900309981, 'num_steps': 75448320}
{'eval/walltime': 126016.92253255844, 'training/sps': 2937.2541627773685, 'training/walltime': 25661.363382577896, 'training/entropy_loss': Array(0.02102057, dtype=float32), 'training/policy_loss': Array(0.00887779, dtype=float32), 'training/total_loss': Array(0.26482582, dtype=float32), 'training/v_loss': Array(0.23492748, dtype=float32), 'eval/episode_distance_from_origin': Array(7325.6406, dtype=float32), 'eval/episode_distance_reward': Array(37.144104, dtype=float32), 'eval/episode_forward_reward': Array(6190.6504, dtype=float32), 'eval/episode_reward': Array(6179.4834, dtype=float32), 'eval/episode_reward_alive': Array(368.57812, dtype=float32), 'eval/episode_reward_linvel': Array(6190.6504, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.88913, dtype=float32), 'eval/episode_x_position': Array(7279.785, dtype=float32), 'eval/episode_x_velocity': Array(1238.1301, dtype=float32), 'eval/episode_y_position': Array(169.45865, dtype=float32), 'eval/episode_y_velocity': Array(-56.86947, dtype=float32), 'eval/episode_distance_from_origin_std': Array(550.8514, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5308557, dtype=float32), 'eval/episode_forward_reward_std': Array(1088.4681, dtype=float32), 'eval/episode_reward_std': Array(1125.1743, dtype=float32), 'eval/episode_reward_alive_std': Array(48.25601, dtype=float32), 'eval/episode_reward_linvel_std': Array(1088.4681, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.855778, dtype=float32), 'eval/episode_x_position_std': Array(555.90765, dtype=float32), 'eval/episode_x_velocity_std': Array(217.69376, dtype=float32), 'eval/episode_y_position_std': Array(424.2237, dtype=float32), 'eval/episode_y_velocity_std': Array(132.5232, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.78041338920593, 'eval/sps': 935.8065005680204, 'num_steps': 75530240}
{'eval/walltime': 126153.12377500534, 'training/sps': 2952.294346537536, 'training/walltime': 25689.111293315887, 'training/entropy_loss': Array(0.02048968, dtype=float32), 'training/policy_loss': Array(0.00640831, dtype=float32), 'training/total_loss': Array(0.23661944, dtype=float32), 'training/v_loss': Array(0.20972145, dtype=float32), 'eval/episode_distance_from_origin': Array(7306.2363, dtype=float32), 'eval/episode_distance_reward': Array(36.379204, dtype=float32), 'eval/episode_forward_reward': Array(6063.1675, dtype=float32), 'eval/episode_reward': Array(6038.911, dtype=float32), 'eval/episode_reward_alive': Array(360.63672, dtype=float32), 'eval/episode_reward_linvel': Array(6063.1675, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.27216, dtype=float32), 'eval/episode_x_position': Array(7266.2725, dtype=float32), 'eval/episode_x_velocity': Array(1212.6335, dtype=float32), 'eval/episode_y_position': Array(66.39079, dtype=float32), 'eval/episode_y_velocity': Array(-79.62092, dtype=float32), 'eval/episode_distance_from_origin_std': Array(476.30997, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9623356, dtype=float32), 'eval/episode_forward_reward_std': Array(993.7151, dtype=float32), 'eval/episode_reward_std': Array(1050.0723, dtype=float32), 'eval/episode_reward_alive_std': Array(54.487194, dtype=float32), 'eval/episode_reward_linvel_std': Array(993.7151, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.327084, dtype=float32), 'eval/episode_x_position_std': Array(476.87628, dtype=float32), 'eval/episode_x_velocity_std': Array(198.74301, dtype=float32), 'eval/episode_y_position_std': Array(366.66345, dtype=float32), 'eval/episode_y_velocity_std': Array(113.29235, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2012424468994, 'eval/sps': 939.7858470336876, 'num_steps': 75612160}
{'eval/walltime': 126289.59264683723, 'training/sps': 2942.888738113703, 'training/walltime': 25716.947887659073, 'training/entropy_loss': Array(0.02029548, dtype=float32), 'training/policy_loss': Array(0.02255568, dtype=float32), 'training/total_loss': Array(0.27313405, dtype=float32), 'training/v_loss': Array(0.2302829, dtype=float32), 'eval/episode_distance_from_origin': Array(7321.8877, dtype=float32), 'eval/episode_distance_reward': Array(36.92417, dtype=float32), 'eval/episode_forward_reward': Array(6153.995, dtype=float32), 'eval/episode_reward': Array(6137.2363, dtype=float32), 'eval/episode_reward_alive': Array(362.2539, dtype=float32), 'eval/episode_reward_linvel': Array(6153.995, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.9368, dtype=float32), 'eval/episode_x_position': Array(7278.8555, dtype=float32), 'eval/episode_x_velocity': Array(1230.7992, dtype=float32), 'eval/episode_y_position': Array(66.811226, dtype=float32), 'eval/episode_y_velocity': Array(-85.29704, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.98273, dtype=float32), 'eval/episode_distance_reward_std': Array(5.82275, dtype=float32), 'eval/episode_forward_reward_std': Array(970.4511, dtype=float32), 'eval/episode_reward_std': Array(1005.60565, dtype=float32), 'eval/episode_reward_alive_std': Array(44.455692, dtype=float32), 'eval/episode_reward_linvel_std': Array(970.4511, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.484138, dtype=float32), 'eval/episode_x_position_std': Array(483.85422, dtype=float32), 'eval/episode_x_velocity_std': Array(194.09033, dtype=float32), 'eval/episode_y_position_std': Array(397.79694, dtype=float32), 'eval/episode_y_velocity_std': Array(125.29619, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46887183189392, 'eval/sps': 937.9428310777998, 'num_steps': 75694080}
{'eval/walltime': 126425.82752251625, 'training/sps': 2952.5322576272433, 'training/walltime': 25744.69356250763, 'training/entropy_loss': Array(0.02136081, dtype=float32), 'training/policy_loss': Array(0.00643289, dtype=float32), 'training/total_loss': Array(0.23663184, dtype=float32), 'training/v_loss': Array(0.20883814, dtype=float32), 'eval/episode_distance_from_origin': Array(7334.4707, dtype=float32), 'eval/episode_distance_reward': Array(37.01505, dtype=float32), 'eval/episode_forward_reward': Array(6169.141, dtype=float32), 'eval/episode_reward': Array(6158.7896, dtype=float32), 'eval/episode_reward_alive': Array(366.32812, dtype=float32), 'eval/episode_reward_linvel': Array(6169.141, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.69406, dtype=float32), 'eval/episode_x_position': Array(7290.6436, dtype=float32), 'eval/episode_x_velocity': Array(1233.8284, dtype=float32), 'eval/episode_y_position': Array(90.89693, dtype=float32), 'eval/episode_y_velocity': Array(-84.61414, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.28354, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8069186, dtype=float32), 'eval/episode_forward_reward_std': Array(967.81305, dtype=float32), 'eval/episode_reward_std': Array(1005.50854, dtype=float32), 'eval/episode_reward_alive_std': Array(47.712326, dtype=float32), 'eval/episode_reward_linvel_std': Array(967.81305, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.631182, dtype=float32), 'eval/episode_x_position_std': Array(451.03842, dtype=float32), 'eval/episode_x_velocity_std': Array(193.56259, dtype=float32), 'eval/episode_y_position_std': Array(415.39273, dtype=float32), 'eval/episode_y_velocity_std': Array(128.82338, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2348756790161, 'eval/sps': 939.5538356975613, 'num_steps': 75776000}
{'eval/walltime': 126562.3055768013, 'training/sps': 2950.1250320761997, 'training/walltime': 25772.46187710762, 'training/entropy_loss': Array(0.01427268, dtype=float32), 'training/policy_loss': Array(0.00727661, dtype=float32), 'training/total_loss': Array(0.07944381, dtype=float32), 'training/v_loss': Array(0.05789451, dtype=float32), 'eval/episode_distance_from_origin': Array(7289.7144, dtype=float32), 'eval/episode_distance_reward': Array(36.52977, dtype=float32), 'eval/episode_forward_reward': Array(6088.2617, dtype=float32), 'eval/episode_reward': Array(6069.087, dtype=float32), 'eval/episode_reward_alive': Array(360.73828, dtype=float32), 'eval/episode_reward_linvel': Array(6088.2617, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.44305, dtype=float32), 'eval/episode_x_position': Array(7247.9497, dtype=float32), 'eval/episode_x_velocity': Array(1217.6525, dtype=float32), 'eval/episode_y_position': Array(-7.1398506, dtype=float32), 'eval/episode_y_velocity': Array(-101.48323, dtype=float32), 'eval/episode_distance_from_origin_std': Array(469.26093, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6967263, dtype=float32), 'eval/episode_forward_reward_std': Array(949.4481, dtype=float32), 'eval/episode_reward_std': Array(993.1256, dtype=float32), 'eval/episode_reward_alive_std': Array(50.090267, dtype=float32), 'eval/episode_reward_linvel_std': Array(949.4481, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.749054, dtype=float32), 'eval/episode_x_position_std': Array(468.61282, dtype=float32), 'eval/episode_x_velocity_std': Array(189.88959, dtype=float32), 'eval/episode_y_position_std': Array(392.59995, dtype=float32), 'eval/episode_y_velocity_std': Array(110.239174, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47805428504944, 'eval/sps': 937.8797248432185, 'num_steps': 75857920}
{'eval/walltime': 126698.55678582191, 'training/sps': 2961.9439175613356, 'training/walltime': 25800.119389295578, 'training/entropy_loss': Array(0.01872097, dtype=float32), 'training/policy_loss': Array(0.00776966, dtype=float32), 'training/total_loss': Array(0.23434313, dtype=float32), 'training/v_loss': Array(0.20785248, dtype=float32), 'eval/episode_distance_from_origin': Array(7298.669, dtype=float32), 'eval/episode_distance_reward': Array(36.11719, dtype=float32), 'eval/episode_forward_reward': Array(6019.498, dtype=float32), 'eval/episode_reward': Array(5999.8926, dtype=float32), 'eval/episode_reward_alive': Array(358.2422, dtype=float32), 'eval/episode_reward_linvel': Array(6019.498, dtype=float32), 'eval/episode_reward_quadctrl': Array(-413.96393, dtype=float32), 'eval/episode_x_position': Array(7257.842, dtype=float32), 'eval/episode_x_velocity': Array(1203.8997, dtype=float32), 'eval/episode_y_position': Array(-22.198599, dtype=float32), 'eval/episode_y_velocity': Array(-100.712074, dtype=float32), 'eval/episode_distance_from_origin_std': Array(527.31366, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7057624, dtype=float32), 'eval/episode_forward_reward_std': Array(950.9548, dtype=float32), 'eval/episode_reward_std': Array(984.9454, dtype=float32), 'eval/episode_reward_alive_std': Array(48.259148, dtype=float32), 'eval/episode_reward_linvel_std': Array(950.9548, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.571774, dtype=float32), 'eval/episode_x_position_std': Array(524.3412, dtype=float32), 'eval/episode_x_velocity_std': Array(190.19083, dtype=float32), 'eval/episode_y_position_std': Array(380.92166, dtype=float32), 'eval/episode_y_velocity_std': Array(106.23681, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25120902061462, 'eval/sps': 939.441205109848, 'num_steps': 75939840}
{'eval/walltime': 126835.0281469822, 'training/sps': 2947.3839634791298, 'training/walltime': 25827.913528442383, 'training/entropy_loss': Array(0.02150453, dtype=float32), 'training/policy_loss': Array(0.00524685, dtype=float32), 'training/total_loss': Array(0.2287308, dtype=float32), 'training/v_loss': Array(0.20197941, dtype=float32), 'eval/episode_distance_from_origin': Array(7279.2427, dtype=float32), 'eval/episode_distance_reward': Array(36.289894, dtype=float32), 'eval/episode_forward_reward': Array(6048.2817, dtype=float32), 'eval/episode_reward': Array(6040.697, dtype=float32), 'eval/episode_reward_alive': Array(367.89844, dtype=float32), 'eval/episode_reward_linvel': Array(6048.2817, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.77283, dtype=float32), 'eval/episode_x_position': Array(7237.49, dtype=float32), 'eval/episode_x_velocity': Array(1209.6562, dtype=float32), 'eval/episode_y_position': Array(28.329254, dtype=float32), 'eval/episode_y_velocity': Array(-84.81948, dtype=float32), 'eval/episode_distance_from_origin_std': Array(444.28372, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4032516, dtype=float32), 'eval/episode_forward_reward_std': Array(900.536, dtype=float32), 'eval/episode_reward_std': Array(925.9746, dtype=float32), 'eval/episode_reward_alive_std': Array(45.627457, dtype=float32), 'eval/episode_reward_linvel_std': Array(900.536, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.862934, dtype=float32), 'eval/episode_x_position_std': Array(444.4224, dtype=float32), 'eval/episode_x_velocity_std': Array(180.10724, dtype=float32), 'eval/episode_y_position_std': Array(394.1735, dtype=float32), 'eval/episode_y_velocity_std': Array(115.96845, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47136116027832, 'eval/sps': 937.9257223768058, 'num_steps': 76021760}
{'eval/walltime': 126971.27733325958, 'training/sps': 2965.2077058809828, 'training/walltime': 25855.540598154068, 'training/entropy_loss': Array(0.02024644, dtype=float32), 'training/policy_loss': Array(0.00534502, dtype=float32), 'training/total_loss': Array(0.21399058, dtype=float32), 'training/v_loss': Array(0.18839912, dtype=float32), 'eval/episode_distance_from_origin': Array(7220.1313, dtype=float32), 'eval/episode_distance_reward': Array(36.0356, dtype=float32), 'eval/episode_forward_reward': Array(6005.8994, dtype=float32), 'eval/episode_reward': Array(5993.665, dtype=float32), 'eval/episode_reward_alive': Array(371.23438, dtype=float32), 'eval/episode_reward_linvel': Array(6005.8994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.50418, dtype=float32), 'eval/episode_x_position': Array(7175.9014, dtype=float32), 'eval/episode_x_velocity': Array(1201.1798, dtype=float32), 'eval/episode_y_position': Array(83.54059, dtype=float32), 'eval/episode_y_velocity': Array(-71.957535, dtype=float32), 'eval/episode_distance_from_origin_std': Array(472.7223, dtype=float32), 'eval/episode_distance_reward_std': Array(5.6180243, dtype=float32), 'eval/episode_forward_reward_std': Array(936.33203, dtype=float32), 'eval/episode_reward_std': Array(985.4344, dtype=float32), 'eval/episode_reward_alive_std': Array(50.075172, dtype=float32), 'eval/episode_reward_linvel_std': Array(936.33203, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.50201, dtype=float32), 'eval/episode_x_position_std': Array(472.3532, dtype=float32), 'eval/episode_x_velocity_std': Array(187.2665, dtype=float32), 'eval/episode_y_position_std': Array(423.60468, dtype=float32), 'eval/episode_y_velocity_std': Array(121.060844, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24918627738953, 'eval/sps': 939.4551519698986, 'num_steps': 76103680}
{'eval/walltime': 127107.73327970505, 'training/sps': 2949.7296369345363, 'training/walltime': 25883.312634944916, 'training/entropy_loss': Array(0.02073316, dtype=float32), 'training/policy_loss': Array(0.00527104, dtype=float32), 'training/total_loss': Array(0.24922596, dtype=float32), 'training/v_loss': Array(0.22322175, dtype=float32), 'eval/episode_distance_from_origin': Array(7174.625, dtype=float32), 'eval/episode_distance_reward': Array(35.447342, dtype=float32), 'eval/episode_forward_reward': Array(5907.8564, dtype=float32), 'eval/episode_reward': Array(5885.0737, dtype=float32), 'eval/episode_reward_alive': Array(362.3086, dtype=float32), 'eval/episode_reward_linvel': Array(5907.8564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.53894, dtype=float32), 'eval/episode_x_position': Array(7132.1777, dtype=float32), 'eval/episode_x_velocity': Array(1181.5713, dtype=float32), 'eval/episode_y_position': Array(37.324314, dtype=float32), 'eval/episode_y_velocity': Array(-95.17139, dtype=float32), 'eval/episode_distance_from_origin_std': Array(521.87494, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2255306, dtype=float32), 'eval/episode_forward_reward_std': Array(1037.5801, dtype=float32), 'eval/episode_reward_std': Array(1104.3599, dtype=float32), 'eval/episode_reward_alive_std': Array(60.011395, dtype=float32), 'eval/episode_reward_linvel_std': Array(1037.5801, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.190292, dtype=float32), 'eval/episode_x_position_std': Array(521.55646, dtype=float32), 'eval/episode_x_velocity_std': Array(207.51614, dtype=float32), 'eval/episode_y_position_std': Array(392.01956, dtype=float32), 'eval/episode_y_velocity_std': Array(121.846664, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4559464454651, 'eval/sps': 938.0316749417401, 'num_steps': 76185600}
{'eval/walltime': 127244.11700892448, 'training/sps': 2962.9697337063276, 'training/walltime': 25910.9605717659, 'training/entropy_loss': Array(0.02179425, dtype=float32), 'training/policy_loss': Array(0.00742876, dtype=float32), 'training/total_loss': Array(0.23041448, dtype=float32), 'training/v_loss': Array(0.20119147, dtype=float32), 'eval/episode_distance_from_origin': Array(7193.2373, dtype=float32), 'eval/episode_distance_reward': Array(35.643986, dtype=float32), 'eval/episode_forward_reward': Array(5940.631, dtype=float32), 'eval/episode_reward': Array(5921.5596, dtype=float32), 'eval/episode_reward_alive': Array(363.59766, dtype=float32), 'eval/episode_reward_linvel': Array(5940.631, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.31268, dtype=float32), 'eval/episode_x_position': Array(7151.825, dtype=float32), 'eval/episode_x_velocity': Array(1188.1261, dtype=float32), 'eval/episode_y_position': Array(40.436954, dtype=float32), 'eval/episode_y_velocity': Array(-81.444214, dtype=float32), 'eval/episode_distance_from_origin_std': Array(607.2257, dtype=float32), 'eval/episode_distance_reward_std': Array(6.9548564, dtype=float32), 'eval/episode_forward_reward_std': Array(1159.1355, dtype=float32), 'eval/episode_reward_std': Array(1212.5974, dtype=float32), 'eval/episode_reward_alive_std': Array(56.680645, dtype=float32), 'eval/episode_reward_linvel_std': Array(1159.1355, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.33962, dtype=float32), 'eval/episode_x_position_std': Array(606.38965, dtype=float32), 'eval/episode_x_velocity_std': Array(231.82713, dtype=float32), 'eval/episode_y_position_std': Array(394.09814, dtype=float32), 'eval/episode_y_velocity_std': Array(117.74694, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38372921943665, 'eval/sps': 938.5283767541837, 'num_steps': 76267520}
{'eval/walltime': 127380.55242681503, 'training/sps': 2951.3006490445705, 'training/walltime': 25938.71782517433, 'training/entropy_loss': Array(0.01519351, dtype=float32), 'training/policy_loss': Array(0.01037992, dtype=float32), 'training/total_loss': Array(0.09351867, dtype=float32), 'training/v_loss': Array(0.06794525, dtype=float32), 'eval/episode_distance_from_origin': Array(7246.78, dtype=float32), 'eval/episode_distance_reward': Array(35.831707, dtype=float32), 'eval/episode_forward_reward': Array(5971.9165, dtype=float32), 'eval/episode_reward': Array(5957.492, dtype=float32), 'eval/episode_reward_alive': Array(364.3828, dtype=float32), 'eval/episode_reward_linvel': Array(5971.9165, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.639, dtype=float32), 'eval/episode_x_position': Array(7205.441, dtype=float32), 'eval/episode_x_velocity': Array(1194.3833, dtype=float32), 'eval/episode_y_position': Array(-35.819275, dtype=float32), 'eval/episode_y_velocity': Array(-101.91569, dtype=float32), 'eval/episode_distance_from_origin_std': Array(537.5615, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2777867, dtype=float32), 'eval/episode_forward_reward_std': Array(1046.2917, dtype=float32), 'eval/episode_reward_std': Array(1087.5914, dtype=float32), 'eval/episode_reward_alive_std': Array(51.112602, dtype=float32), 'eval/episode_reward_linvel_std': Array(1046.2917, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.00072, dtype=float32), 'eval/episode_x_position_std': Array(540.09576, dtype=float32), 'eval/episode_x_velocity_std': Array(209.2583, dtype=float32), 'eval/episode_y_position_std': Array(380.03662, dtype=float32), 'eval/episode_y_velocity_std': Array(109.08875, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4354178905487, 'eval/sps': 938.1728145010281, 'num_steps': 76349440}
{'eval/walltime': 127516.74132108688, 'training/sps': 2971.646340153991, 'training/walltime': 25966.2850356102, 'training/entropy_loss': Array(0.01848017, dtype=float32), 'training/policy_loss': Array(0.00631333, dtype=float32), 'training/total_loss': Array(0.2019068, dtype=float32), 'training/v_loss': Array(0.1771133, dtype=float32), 'eval/episode_distance_from_origin': Array(7159.9834, dtype=float32), 'eval/episode_distance_reward': Array(35.487022, dtype=float32), 'eval/episode_forward_reward': Array(5914.4707, dtype=float32), 'eval/episode_reward': Array(5909.238, dtype=float32), 'eval/episode_reward_alive': Array(373.85156, dtype=float32), 'eval/episode_reward_linvel': Array(5914.4707, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.57123, dtype=float32), 'eval/episode_x_position': Array(7116.7104, dtype=float32), 'eval/episode_x_velocity': Array(1182.8939, dtype=float32), 'eval/episode_y_position': Array(-5.3981285, dtype=float32), 'eval/episode_y_velocity': Array(-99.62647, dtype=float32), 'eval/episode_distance_from_origin_std': Array(464.85577, dtype=float32), 'eval/episode_distance_reward_std': Array(5.31376, dtype=float32), 'eval/episode_forward_reward_std': Array(885.6214, dtype=float32), 'eval/episode_reward_std': Array(915.8266, dtype=float32), 'eval/episode_reward_alive_std': Array(43.832706, dtype=float32), 'eval/episode_reward_linvel_std': Array(885.6214, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.282745, dtype=float32), 'eval/episode_x_position_std': Array(466.1651, dtype=float32), 'eval/episode_x_velocity_std': Array(177.12431, dtype=float32), 'eval/episode_y_position_std': Array(405.83987, dtype=float32), 'eval/episode_y_velocity_std': Array(113.320366, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1888942718506, 'eval/sps': 939.8710569196303, 'num_steps': 76431360}
{'eval/walltime': 127653.20301270485, 'training/sps': 2950.0158648699744, 'training/walltime': 25994.054377794266, 'training/entropy_loss': Array(0.02243235, dtype=float32), 'training/policy_loss': Array(0.00893274, dtype=float32), 'training/total_loss': Array(0.22191197, dtype=float32), 'training/v_loss': Array(0.19054687, dtype=float32), 'eval/episode_distance_from_origin': Array(7264.4946, dtype=float32), 'eval/episode_distance_reward': Array(36.069332, dtype=float32), 'eval/episode_forward_reward': Array(6011.5215, dtype=float32), 'eval/episode_reward': Array(5989.659, dtype=float32), 'eval/episode_reward_alive': Array(359.1836, dtype=float32), 'eval/episode_reward_linvel': Array(6011.5215, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.11475, dtype=float32), 'eval/episode_x_position': Array(7222.371, dtype=float32), 'eval/episode_x_velocity': Array(1202.3042, dtype=float32), 'eval/episode_y_position': Array(-55.03163, dtype=float32), 'eval/episode_y_velocity': Array(-112.83531, dtype=float32), 'eval/episode_distance_from_origin_std': Array(522.5528, dtype=float32), 'eval/episode_distance_reward_std': Array(6.222254, dtype=float32), 'eval/episode_forward_reward_std': Array(1037.0359, dtype=float32), 'eval/episode_reward_std': Array(1086.4753, dtype=float32), 'eval/episode_reward_alive_std': Array(51.09691, dtype=float32), 'eval/episode_reward_linvel_std': Array(1037.0359, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.675667, dtype=float32), 'eval/episode_x_position_std': Array(520.9651, dtype=float32), 'eval/episode_x_velocity_std': Array(207.40724, dtype=float32), 'eval/episode_y_position_std': Array(387.99695, dtype=float32), 'eval/episode_y_velocity_std': Array(105.86448, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4616916179657, 'eval/sps': 937.9921828782923, 'num_steps': 76513280}
{'eval/walltime': 127789.45154595375, 'training/sps': 2952.5163500275, 'training/walltime': 26021.80020213127, 'training/entropy_loss': Array(0.0205301, dtype=float32), 'training/policy_loss': Array(0.00710333, dtype=float32), 'training/total_loss': Array(0.18816662, dtype=float32), 'training/v_loss': Array(0.16053317, dtype=float32), 'eval/episode_distance_from_origin': Array(7282.5195, dtype=float32), 'eval/episode_distance_reward': Array(35.977535, dtype=float32), 'eval/episode_forward_reward': Array(5996.223, dtype=float32), 'eval/episode_reward': Array(5977.579, dtype=float32), 'eval/episode_reward_alive': Array(361.3047, dtype=float32), 'eval/episode_reward_linvel': Array(5996.223, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.9265, dtype=float32), 'eval/episode_x_position': Array(7239.8203, dtype=float32), 'eval/episode_x_velocity': Array(1199.2446, dtype=float32), 'eval/episode_y_position': Array(-25.264824, dtype=float32), 'eval/episode_y_velocity': Array(-102.382545, dtype=float32), 'eval/episode_distance_from_origin_std': Array(493.03583, dtype=float32), 'eval/episode_distance_reward_std': Array(5.747151, dtype=float32), 'eval/episode_forward_reward_std': Array(957.8526, dtype=float32), 'eval/episode_reward_std': Array(1009.73987, dtype=float32), 'eval/episode_reward_alive_std': Array(54.0641, dtype=float32), 'eval/episode_reward_linvel_std': Array(957.8526, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.03135, dtype=float32), 'eval/episode_x_position_std': Array(490.87564, dtype=float32), 'eval/episode_x_velocity_std': Array(191.57036, dtype=float32), 'eval/episode_y_position_std': Array(401.4881, dtype=float32), 'eval/episode_y_velocity_std': Array(106.24985, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24853324890137, 'eval/sps': 939.4596547044453, 'num_steps': 76595200}
{'eval/walltime': 127925.92532014847, 'training/sps': 2951.2530679608667, 'training/walltime': 26049.557903051376, 'training/entropy_loss': Array(0.02015123, dtype=float32), 'training/policy_loss': Array(0.0054929, dtype=float32), 'training/total_loss': Array(0.21662259, dtype=float32), 'training/v_loss': Array(0.19097847, dtype=float32), 'eval/episode_distance_from_origin': Array(7313.246, dtype=float32), 'eval/episode_distance_reward': Array(36.13085, dtype=float32), 'eval/episode_forward_reward': Array(6021.775, dtype=float32), 'eval/episode_reward': Array(5999.7554, dtype=float32), 'eval/episode_reward_alive': Array(359.4961, dtype=float32), 'eval/episode_reward_linvel': Array(6021.775, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.64594, dtype=float32), 'eval/episode_x_position': Array(7271.2725, dtype=float32), 'eval/episode_x_velocity': Array(1204.355, dtype=float32), 'eval/episode_y_position': Array(-55.51667, dtype=float32), 'eval/episode_y_velocity': Array(-99.17908, dtype=float32), 'eval/episode_distance_from_origin_std': Array(484.2423, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7536516, dtype=float32), 'eval/episode_forward_reward_std': Array(958.93536, dtype=float32), 'eval/episode_reward_std': Array(1008.6666, dtype=float32), 'eval/episode_reward_alive_std': Array(58.810455, dtype=float32), 'eval/episode_reward_linvel_std': Array(958.93536, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.32652, dtype=float32), 'eval/episode_x_position_std': Array(482.74554, dtype=float32), 'eval/episode_x_velocity_std': Array(191.787, dtype=float32), 'eval/episode_y_position_std': Array(401.22122, dtype=float32), 'eval/episode_y_velocity_std': Array(124.118164, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4737741947174, 'eval/sps': 937.9091386259514, 'num_steps': 76677120}
{'eval/walltime': 128062.17300081253, 'training/sps': 2962.030324145653, 'training/walltime': 26077.214608430862, 'training/entropy_loss': Array(0.02043519, dtype=float32), 'training/policy_loss': Array(0.00672429, dtype=float32), 'training/total_loss': Array(0.21863651, dtype=float32), 'training/v_loss': Array(0.19147703, dtype=float32), 'eval/episode_distance_from_origin': Array(7358.487, dtype=float32), 'eval/episode_distance_reward': Array(36.892273, dtype=float32), 'eval/episode_forward_reward': Array(6148.6797, dtype=float32), 'eval/episode_reward': Array(6138.2764, dtype=float32), 'eval/episode_reward_alive': Array(364.875, dtype=float32), 'eval/episode_reward_linvel': Array(6148.6797, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.1694, dtype=float32), 'eval/episode_x_position': Array(7316.8564, dtype=float32), 'eval/episode_x_velocity': Array(1229.7357, dtype=float32), 'eval/episode_y_position': Array(-133.46509, dtype=float32), 'eval/episode_y_velocity': Array(-126.05082, dtype=float32), 'eval/episode_distance_from_origin_std': Array(518.69965, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2871118, dtype=float32), 'eval/episode_forward_reward_std': Array(1047.8458, dtype=float32), 'eval/episode_reward_std': Array(1088.0093, dtype=float32), 'eval/episode_reward_alive_std': Array(52.127247, dtype=float32), 'eval/episode_reward_linvel_std': Array(1047.8458, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.956896, dtype=float32), 'eval/episode_x_position_std': Array(519.80914, dtype=float32), 'eval/episode_x_velocity_std': Array(209.56914, dtype=float32), 'eval/episode_y_position_std': Array(359.77426, dtype=float32), 'eval/episode_y_velocity_std': Array(107.67419, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2476806640625, 'eval/sps': 939.4655334765052, 'num_steps': 76759040}
{'eval/walltime': 128198.59799695015, 'training/sps': 2953.8221806999004, 'training/walltime': 26104.94816684723, 'training/entropy_loss': Array(0.01670042, dtype=float32), 'training/policy_loss': Array(0.0067372, dtype=float32), 'training/total_loss': Array(0.13293397, dtype=float32), 'training/v_loss': Array(0.10949636, dtype=float32), 'eval/episode_distance_from_origin': Array(7298.17, dtype=float32), 'eval/episode_distance_reward': Array(36.105476, dtype=float32), 'eval/episode_forward_reward': Array(6017.546, dtype=float32), 'eval/episode_reward': Array(5992.3027, dtype=float32), 'eval/episode_reward_alive': Array(353.28906, dtype=float32), 'eval/episode_reward_linvel': Array(6017.546, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.63763, dtype=float32), 'eval/episode_x_position': Array(7256.4883, dtype=float32), 'eval/episode_x_velocity': Array(1203.509, dtype=float32), 'eval/episode_y_position': Array(-180.54727, dtype=float32), 'eval/episode_y_velocity': Array(-139.11813, dtype=float32), 'eval/episode_distance_from_origin_std': Array(498.41748, dtype=float32), 'eval/episode_distance_reward_std': Array(6.032274, dtype=float32), 'eval/episode_forward_reward_std': Array(1005.3716, dtype=float32), 'eval/episode_reward_std': Array(1056.8527, dtype=float32), 'eval/episode_reward_alive_std': Array(59.257504, dtype=float32), 'eval/episode_reward_linvel_std': Array(1005.3716, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.779785, dtype=float32), 'eval/episode_x_position_std': Array(495.53806, dtype=float32), 'eval/episode_x_velocity_std': Array(201.07436, dtype=float32), 'eval/episode_y_position_std': Array(337.30643, dtype=float32), 'eval/episode_y_velocity_std': Array(103.77665, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.42499613761902, 'eval/sps': 938.2444832241719, 'num_steps': 76840960}
{'eval/walltime': 128334.82288861275, 'training/sps': 2963.974118477538, 'training/walltime': 26132.58673477173, 'training/entropy_loss': Array(0.01667124, dtype=float32), 'training/policy_loss': Array(0.01326946, dtype=float32), 'training/total_loss': Array(0.10792561, dtype=float32), 'training/v_loss': Array(0.07798491, dtype=float32), 'eval/episode_distance_from_origin': Array(7313.5283, dtype=float32), 'eval/episode_distance_reward': Array(35.995396, dtype=float32), 'eval/episode_forward_reward': Array(5999.1997, dtype=float32), 'eval/episode_reward': Array(5976.9297, dtype=float32), 'eval/episode_reward_alive': Array(361.3789, dtype=float32), 'eval/episode_reward_linvel': Array(5999.1997, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.64493, dtype=float32), 'eval/episode_x_position': Array(7271.3267, dtype=float32), 'eval/episode_x_velocity': Array(1199.84, dtype=float32), 'eval/episode_y_position': Array(-234.01257, dtype=float32), 'eval/episode_y_velocity': Array(-149.74146, dtype=float32), 'eval/episode_distance_from_origin_std': Array(464.53522, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0127463, dtype=float32), 'eval/episode_forward_reward_std': Array(1002.1177, dtype=float32), 'eval/episode_reward_std': Array(1056.8341, dtype=float32), 'eval/episode_reward_alive_std': Array(57.91153, dtype=float32), 'eval/episode_reward_linvel_std': Array(1002.1177, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.057922, dtype=float32), 'eval/episode_x_position_std': Array(460.44696, dtype=float32), 'eval/episode_x_velocity_std': Array(200.42351, dtype=float32), 'eval/episode_y_position_std': Array(324.85175, dtype=float32), 'eval/episode_y_velocity_std': Array(95.08705, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22489166259766, 'eval/sps': 939.6226962472534, 'num_steps': 76922880}
{'eval/walltime': 128471.27088785172, 'training/sps': 2949.6990471086065, 'training/walltime': 26160.35905957222, 'training/entropy_loss': Array(0.02153712, dtype=float32), 'training/policy_loss': Array(0.00734025, dtype=float32), 'training/total_loss': Array(0.2577591, dtype=float32), 'training/v_loss': Array(0.22888172, dtype=float32), 'eval/episode_distance_from_origin': Array(7256.285, dtype=float32), 'eval/episode_distance_reward': Array(35.475407, dtype=float32), 'eval/episode_forward_reward': Array(5912.534, dtype=float32), 'eval/episode_reward': Array(5886.8296, dtype=float32), 'eval/episode_reward_alive': Array(356.98047, dtype=float32), 'eval/episode_reward_linvel': Array(5912.534, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.16052, dtype=float32), 'eval/episode_x_position': Array(7214.676, dtype=float32), 'eval/episode_x_velocity': Array(1182.5068, dtype=float32), 'eval/episode_y_position': Array(-215.07278, dtype=float32), 'eval/episode_y_velocity': Array(-147.88358, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.7864, dtype=float32), 'eval/episode_distance_reward_std': Array(5.839005, dtype=float32), 'eval/episode_forward_reward_std': Array(973.15985, dtype=float32), 'eval/episode_reward_std': Array(1020.0863, dtype=float32), 'eval/episode_reward_alive_std': Array(49.64343, dtype=float32), 'eval/episode_reward_linvel_std': Array(973.15985, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.750652, dtype=float32), 'eval/episode_x_position_std': Array(463.8424, dtype=float32), 'eval/episode_x_velocity_std': Array(194.63214, dtype=float32), 'eval/episode_y_position_std': Array(318.60233, dtype=float32), 'eval/episode_y_velocity_std': Array(96.89196, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4479992389679, 'eval/sps': 938.0863091720934, 'num_steps': 77004800}
{'eval/walltime': 128607.52294707298, 'training/sps': 2963.089290745459, 'training/walltime': 26188.005880832672, 'training/entropy_loss': Array(0.01960941, dtype=float32), 'training/policy_loss': Array(0.00596809, dtype=float32), 'training/total_loss': Array(0.19531101, dtype=float32), 'training/v_loss': Array(0.16973352, dtype=float32), 'eval/episode_distance_from_origin': Array(7328.5317, dtype=float32), 'eval/episode_distance_reward': Array(36.426945, dtype=float32), 'eval/episode_forward_reward': Array(6071.124, dtype=float32), 'eval/episode_reward': Array(6048.461, dtype=float32), 'eval/episode_reward_alive': Array(359.3203, dtype=float32), 'eval/episode_reward_linvel': Array(6071.124, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.4104, dtype=float32), 'eval/episode_x_position': Array(7285.626, dtype=float32), 'eval/episode_x_velocity': Array(1214.2246, dtype=float32), 'eval/episode_y_position': Array(-252.8002, dtype=float32), 'eval/episode_y_velocity': Array(-151.15079, dtype=float32), 'eval/episode_distance_from_origin_std': Array(469.32104, dtype=float32), 'eval/episode_distance_reward_std': Array(5.816343, dtype=float32), 'eval/episode_forward_reward_std': Array(969.3837, dtype=float32), 'eval/episode_reward_std': Array(1018.843, dtype=float32), 'eval/episode_reward_alive_std': Array(55.29812, dtype=float32), 'eval/episode_reward_linvel_std': Array(969.3837, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.045914, dtype=float32), 'eval/episode_x_position_std': Array(465.51218, dtype=float32), 'eval/episode_x_velocity_std': Array(193.87666, dtype=float32), 'eval/episode_y_position_std': Array(329.9042, dtype=float32), 'eval/episode_y_velocity_std': Array(100.65963, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2520592212677, 'eval/sps': 939.4353430808213, 'num_steps': 77086720}
{'eval/walltime': 128743.98321294785, 'training/sps': 2954.6106747972854, 'training/walltime': 26215.732038021088, 'training/entropy_loss': Array(0.01966969, dtype=float32), 'training/policy_loss': Array(0.00882163, dtype=float32), 'training/total_loss': Array(0.23662381, dtype=float32), 'training/v_loss': Array(0.20813249, dtype=float32), 'eval/episode_distance_from_origin': Array(7271.0986, dtype=float32), 'eval/episode_distance_reward': Array(35.521652, dtype=float32), 'eval/episode_forward_reward': Array(5920.241, dtype=float32), 'eval/episode_reward': Array(5890.2114, dtype=float32), 'eval/episode_reward_alive': Array(354.25, dtype=float32), 'eval/episode_reward_linvel': Array(5920.241, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.80237, dtype=float32), 'eval/episode_x_position': Array(7227.5024, dtype=float32), 'eval/episode_x_velocity': Array(1184.0482, dtype=float32), 'eval/episode_y_position': Array(-304.10016, dtype=float32), 'eval/episode_y_velocity': Array(-163.02762, dtype=float32), 'eval/episode_distance_from_origin_std': Array(480.14905, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8808007, dtype=float32), 'eval/episode_forward_reward_std': Array(980.1269, dtype=float32), 'eval/episode_reward_std': Array(1045.8861, dtype=float32), 'eval/episode_reward_alive_std': Array(59.501183, dtype=float32), 'eval/episode_reward_linvel_std': Array(980.1269, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.402607, dtype=float32), 'eval/episode_x_position_std': Array(477.7085, dtype=float32), 'eval/episode_x_velocity_std': Array(196.02548, dtype=float32), 'eval/episode_y_position_std': Array(287.74808, dtype=float32), 'eval/episode_y_velocity_std': Array(90.15702, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46026587486267, 'eval/sps': 938.0019830635466, 'num_steps': 77168640}
{'eval/walltime': 128880.2663424015, 'training/sps': 2974.38701455152, 'training/walltime': 26243.273847341537, 'training/entropy_loss': Array(0.02068974, dtype=float32), 'training/policy_loss': Array(0.00519755, dtype=float32), 'training/total_loss': Array(0.2393532, dtype=float32), 'training/v_loss': Array(0.2134659, dtype=float32), 'eval/episode_distance_from_origin': Array(7289.955, dtype=float32), 'eval/episode_distance_reward': Array(35.439133, dtype=float32), 'eval/episode_forward_reward': Array(5906.49, dtype=float32), 'eval/episode_reward': Array(5874.9424, dtype=float32), 'eval/episode_reward_alive': Array(350.34766, dtype=float32), 'eval/episode_reward_linvel': Array(5906.49, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.33484, dtype=float32), 'eval/episode_x_position': Array(7247.289, dtype=float32), 'eval/episode_x_velocity': Array(1181.2981, dtype=float32), 'eval/episode_y_position': Array(-207.54698, dtype=float32), 'eval/episode_y_velocity': Array(-135.43872, dtype=float32), 'eval/episode_distance_from_origin_std': Array(478.22153, dtype=float32), 'eval/episode_distance_reward_std': Array(5.59004, dtype=float32), 'eval/episode_forward_reward_std': Array(931.66675, dtype=float32), 'eval/episode_reward_std': Array(972.285, dtype=float32), 'eval/episode_reward_alive_std': Array(58.243046, dtype=float32), 'eval/episode_reward_linvel_std': Array(931.66675, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.371105, dtype=float32), 'eval/episode_x_position_std': Array(473.24796, dtype=float32), 'eval/episode_x_velocity_std': Array(186.33337, dtype=float32), 'eval/episode_y_position_std': Array(356.67245, dtype=float32), 'eval/episode_y_velocity_std': Array(108.057274, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28312945365906, 'eval/sps': 939.2211678227156, 'num_steps': 77250560}
{'eval/walltime': 129016.7108695507, 'training/sps': 2950.802074474311, 'training/walltime': 26271.03579068184, 'training/entropy_loss': Array(0.01948842, dtype=float32), 'training/policy_loss': Array(0.00719588, dtype=float32), 'training/total_loss': Array(0.17080647, dtype=float32), 'training/v_loss': Array(0.14412218, dtype=float32), 'eval/episode_distance_from_origin': Array(7268.1562, dtype=float32), 'eval/episode_distance_reward': Array(35.203213, dtype=float32), 'eval/episode_forward_reward': Array(5867.1704, dtype=float32), 'eval/episode_reward': Array(5834.537, dtype=float32), 'eval/episode_reward_alive': Array(349.19922, dtype=float32), 'eval/episode_reward_linvel': Array(5867.1704, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.0354, dtype=float32), 'eval/episode_x_position': Array(7227.7886, dtype=float32), 'eval/episode_x_velocity': Array(1173.434, dtype=float32), 'eval/episode_y_position': Array(-175.3536, dtype=float32), 'eval/episode_y_velocity': Array(-134.20921, dtype=float32), 'eval/episode_distance_from_origin_std': Array(509.26266, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1920667, dtype=float32), 'eval/episode_forward_reward_std': Array(1032.0024, dtype=float32), 'eval/episode_reward_std': Array(1082.9343, dtype=float32), 'eval/episode_reward_alive_std': Array(59.696312, dtype=float32), 'eval/episode_reward_linvel_std': Array(1032.0024, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.0148, dtype=float32), 'eval/episode_x_position_std': Array(505.66183, dtype=float32), 'eval/episode_x_velocity_std': Array(206.40053, dtype=float32), 'eval/episode_y_position_std': Array(325.65726, dtype=float32), 'eval/episode_y_velocity_std': Array(101.35267, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44452714920044, 'eval/sps': 938.1101805573597, 'num_steps': 77332480}
{'eval/walltime': 129152.94190573692, 'training/sps': 2975.4280910711695, 'training/walltime': 26298.56796336174, 'training/entropy_loss': Array(0.01599189, dtype=float32), 'training/policy_loss': Array(0.01144264, dtype=float32), 'training/total_loss': Array(0.09313075, dtype=float32), 'training/v_loss': Array(0.06569621, dtype=float32), 'eval/episode_distance_from_origin': Array(7333.7344, dtype=float32), 'eval/episode_distance_reward': Array(36.483383, dtype=float32), 'eval/episode_forward_reward': Array(6080.531, dtype=float32), 'eval/episode_reward': Array(6062.4814, dtype=float32), 'eval/episode_reward_alive': Array(359.7539, dtype=float32), 'eval/episode_reward_linvel': Array(6080.531, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.28656, dtype=float32), 'eval/episode_x_position': Array(7293.8633, dtype=float32), 'eval/episode_x_velocity': Array(1216.106, dtype=float32), 'eval/episode_y_position': Array(-175.92798, dtype=float32), 'eval/episode_y_velocity': Array(-138.08478, dtype=float32), 'eval/episode_distance_from_origin_std': Array(486.09113, dtype=float32), 'eval/episode_distance_reward_std': Array(5.848708, dtype=float32), 'eval/episode_forward_reward_std': Array(974.77875, dtype=float32), 'eval/episode_reward_std': Array(1016.11017, dtype=float32), 'eval/episode_reward_alive_std': Array(52.85065, dtype=float32), 'eval/episode_reward_linvel_std': Array(974.77875, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.455963, dtype=float32), 'eval/episode_x_position_std': Array(483.04648, dtype=float32), 'eval/episode_x_velocity_std': Array(194.95567, dtype=float32), 'eval/episode_y_position_std': Array(316.67114, dtype=float32), 'eval/episode_y_velocity_std': Array(102.8796, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23103618621826, 'eval/sps': 939.5803157881952, 'num_steps': 77414400}
{'eval/walltime': 129289.40500235558, 'training/sps': 2959.598083519891, 'training/walltime': 26326.24739742279, 'training/entropy_loss': Array(0.02159503, dtype=float32), 'training/policy_loss': Array(0.00926448, dtype=float32), 'training/total_loss': Array(0.22618383, dtype=float32), 'training/v_loss': Array(0.19532433, dtype=float32), 'eval/episode_distance_from_origin': Array(7400.177, dtype=float32), 'eval/episode_distance_reward': Array(37.30958, dtype=float32), 'eval/episode_forward_reward': Array(6218.2305, dtype=float32), 'eval/episode_reward': Array(6202.122, dtype=float32), 'eval/episode_reward_alive': Array(354.8125, dtype=float32), 'eval/episode_reward_linvel': Array(6218.2305, dtype=float32), 'eval/episode_reward_quadctrl': Array(-408.23077, dtype=float32), 'eval/episode_x_position': Array(7356.43, dtype=float32), 'eval/episode_x_velocity': Array(1243.646, dtype=float32), 'eval/episode_y_position': Array(-215.438, dtype=float32), 'eval/episode_y_velocity': Array(-150.51956, dtype=float32), 'eval/episode_distance_from_origin_std': Array(402.43015, dtype=float32), 'eval/episode_distance_reward_std': Array(5.3471184, dtype=float32), 'eval/episode_forward_reward_std': Array(891.18115, dtype=float32), 'eval/episode_reward_std': Array(923.5539, dtype=float32), 'eval/episode_reward_alive_std': Array(49.55722, dtype=float32), 'eval/episode_reward_linvel_std': Array(891.18115, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.9509, dtype=float32), 'eval/episode_x_position_std': Array(400.83023, dtype=float32), 'eval/episode_x_velocity_std': Array(178.2362, dtype=float32), 'eval/episode_y_position_std': Array(351.4852, dtype=float32), 'eval/episode_y_velocity_std': Array(101.8434, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46309661865234, 'eval/sps': 937.982525471318, 'num_steps': 77496320}
{'eval/walltime': 129425.67274308205, 'training/sps': 2962.930207138769, 'training/walltime': 26353.895703077316, 'training/entropy_loss': Array(0.020085, dtype=float32), 'training/policy_loss': Array(0.00533738, dtype=float32), 'training/total_loss': Array(0.20663753, dtype=float32), 'training/v_loss': Array(0.18121514, dtype=float32), 'eval/episode_distance_from_origin': Array(7389.646, dtype=float32), 'eval/episode_distance_reward': Array(36.714687, dtype=float32), 'eval/episode_forward_reward': Array(6119.08, dtype=float32), 'eval/episode_reward': Array(6098.5586, dtype=float32), 'eval/episode_reward_alive': Array(358.6172, dtype=float32), 'eval/episode_reward_linvel': Array(6119.08, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.85358, dtype=float32), 'eval/episode_x_position': Array(7347.537, dtype=float32), 'eval/episode_x_velocity': Array(1223.8162, dtype=float32), 'eval/episode_y_position': Array(-216.83533, dtype=float32), 'eval/episode_y_velocity': Array(-144.36206, dtype=float32), 'eval/episode_distance_from_origin_std': Array(460.70203, dtype=float32), 'eval/episode_distance_reward_std': Array(5.137488, dtype=float32), 'eval/episode_forward_reward_std': Array(856.2432, dtype=float32), 'eval/episode_reward_std': Array(884.94653, dtype=float32), 'eval/episode_reward_alive_std': Array(43.24356, dtype=float32), 'eval/episode_reward_linvel_std': Array(856.2432, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.246138, dtype=float32), 'eval/episode_x_position_std': Array(457.3102, dtype=float32), 'eval/episode_x_velocity_std': Array(171.24883, dtype=float32), 'eval/episode_y_position_std': Array(318.91214, dtype=float32), 'eval/episode_y_velocity_std': Array(90.51452, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26774072647095, 'eval/sps': 939.3272341465856, 'num_steps': 77578240}
{'eval/walltime': 129562.13334584236, 'training/sps': 2955.929853185778, 'training/walltime': 26381.609486579895, 'training/entropy_loss': Array(0.01947906, dtype=float32), 'training/policy_loss': Array(0.00904806, dtype=float32), 'training/total_loss': Array(0.26461297, dtype=float32), 'training/v_loss': Array(0.23608583, dtype=float32), 'eval/episode_distance_from_origin': Array(7368.9966, dtype=float32), 'eval/episode_distance_reward': Array(36.459274, dtype=float32), 'eval/episode_forward_reward': Array(6076.512, dtype=float32), 'eval/episode_reward': Array(6053.827, dtype=float32), 'eval/episode_reward_alive': Array(356.98828, dtype=float32), 'eval/episode_reward_linvel': Array(6076.512, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.1316, dtype=float32), 'eval/episode_x_position': Array(7326.2695, dtype=float32), 'eval/episode_x_velocity': Array(1215.3022, dtype=float32), 'eval/episode_y_position': Array(-200.56894, dtype=float32), 'eval/episode_y_velocity': Array(-149.93843, dtype=float32), 'eval/episode_distance_from_origin_std': Array(433.4809, dtype=float32), 'eval/episode_distance_reward_std': Array(5.266475, dtype=float32), 'eval/episode_forward_reward_std': Array(877.74054, dtype=float32), 'eval/episode_reward_std': Array(908.07153, dtype=float32), 'eval/episode_reward_alive_std': Array(47.725964, dtype=float32), 'eval/episode_reward_linvel_std': Array(877.74054, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.691853, dtype=float32), 'eval/episode_x_position_std': Array(429.18527, dtype=float32), 'eval/episode_x_velocity_std': Array(175.54808, dtype=float32), 'eval/episode_y_position_std': Array(324.88077, dtype=float32), 'eval/episode_y_velocity_std': Array(98.90458, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46060276031494, 'eval/sps': 937.9996673825668, 'num_steps': 77660160}
{'eval/walltime': 129698.4222035408, 'training/sps': 2957.0620535160533, 'training/walltime': 26409.312659025192, 'training/entropy_loss': Array(0.02056181, dtype=float32), 'training/policy_loss': Array(0.00963727, dtype=float32), 'training/total_loss': Array(0.2763862, dtype=float32), 'training/v_loss': Array(0.24618712, dtype=float32), 'eval/episode_distance_from_origin': Array(7367.1377, dtype=float32), 'eval/episode_distance_reward': Array(36.85859, dtype=float32), 'eval/episode_forward_reward': Array(6143.0635, dtype=float32), 'eval/episode_reward': Array(6120.1455, dtype=float32), 'eval/episode_reward_alive': Array(355.53906, dtype=float32), 'eval/episode_reward_linvel': Array(6143.0635, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.31625, dtype=float32), 'eval/episode_x_position': Array(7325.93, dtype=float32), 'eval/episode_x_velocity': Array(1228.6128, dtype=float32), 'eval/episode_y_position': Array(-188.19543, dtype=float32), 'eval/episode_y_velocity': Array(-140.9664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(453.68607, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4673095, dtype=float32), 'eval/episode_forward_reward_std': Array(911.2132, dtype=float32), 'eval/episode_reward_std': Array(940.36615, dtype=float32), 'eval/episode_reward_alive_std': Array(46.5227, dtype=float32), 'eval/episode_reward_linvel_std': Array(911.2132, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.82777, dtype=float32), 'eval/episode_x_position_std': Array(453.46973, dtype=float32), 'eval/episode_x_velocity_std': Array(182.24257, dtype=float32), 'eval/episode_y_position_std': Array(330.53918, dtype=float32), 'eval/episode_y_velocity_std': Array(100.10256, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28885769844055, 'eval/sps': 939.1816921910015, 'num_steps': 77742080}
{'eval/walltime': 129834.89319562912, 'training/sps': 2956.463410238536, 'training/walltime': 26437.02144098282, 'training/entropy_loss': Array(0.02244671, dtype=float32), 'training/policy_loss': Array(0.00930678, dtype=float32), 'training/total_loss': Array(0.24831359, dtype=float32), 'training/v_loss': Array(0.2165601, dtype=float32), 'eval/episode_distance_from_origin': Array(7376.9434, dtype=float32), 'eval/episode_distance_reward': Array(36.77633, dtype=float32), 'eval/episode_forward_reward': Array(6129.355, dtype=float32), 'eval/episode_reward': Array(6113.7197, dtype=float32), 'eval/episode_reward_alive': Array(359.32812, dtype=float32), 'eval/episode_reward_linvel': Array(6129.355, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.73938, dtype=float32), 'eval/episode_x_position': Array(7333.3027, dtype=float32), 'eval/episode_x_velocity': Array(1225.871, dtype=float32), 'eval/episode_y_position': Array(-281.32117, dtype=float32), 'eval/episode_y_velocity': Array(-165.6666, dtype=float32), 'eval/episode_distance_from_origin_std': Array(386.3377, dtype=float32), 'eval/episode_distance_reward_std': Array(4.39542, dtype=float32), 'eval/episode_forward_reward_std': Array(732.56525, dtype=float32), 'eval/episode_reward_std': Array(740.1745, dtype=float32), 'eval/episode_reward_alive_std': Array(38.231125, dtype=float32), 'eval/episode_reward_linvel_std': Array(732.56525, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(24.495575, dtype=float32), 'eval/episode_x_position_std': Array(384.84003, dtype=float32), 'eval/episode_x_velocity_std': Array(146.51321, dtype=float32), 'eval/episode_y_position_std': Array(303.23212, dtype=float32), 'eval/episode_y_velocity_std': Array(90.01064, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47099208831787, 'eval/sps': 937.9282589018197, 'num_steps': 77824000}
{'eval/walltime': 129971.1285636425, 'training/sps': 2971.0205065357027, 'training/walltime': 26464.5944583416, 'training/entropy_loss': Array(0.01406384, dtype=float32), 'training/policy_loss': Array(0.00822084, dtype=float32), 'training/total_loss': Array(0.06374867, dtype=float32), 'training/v_loss': Array(0.04146399, dtype=float32), 'eval/episode_distance_from_origin': Array(7421.8594, dtype=float32), 'eval/episode_distance_reward': Array(36.947906, dtype=float32), 'eval/episode_forward_reward': Array(6157.9507, dtype=float32), 'eval/episode_reward': Array(6132.462, dtype=float32), 'eval/episode_reward_alive': Array(349.91797, dtype=float32), 'eval/episode_reward_linvel': Array(6157.9507, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.3553, dtype=float32), 'eval/episode_x_position': Array(7377.028, dtype=float32), 'eval/episode_x_velocity': Array(1231.5902, dtype=float32), 'eval/episode_y_position': Array(-323.4488, dtype=float32), 'eval/episode_y_velocity': Array(-171.61206, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.53674, dtype=float32), 'eval/episode_distance_reward_std': Array(5.782027, dtype=float32), 'eval/episode_forward_reward_std': Array(963.66425, dtype=float32), 'eval/episode_reward_std': Array(1008.52167, dtype=float32), 'eval/episode_reward_alive_std': Array(50.407513, dtype=float32), 'eval/episode_reward_linvel_std': Array(963.66425, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.84596, dtype=float32), 'eval/episode_x_position_std': Array(464.3972, dtype=float32), 'eval/episode_x_velocity_std': Array(192.73291, dtype=float32), 'eval/episode_y_position_std': Array(292.3391, dtype=float32), 'eval/episode_y_velocity_std': Array(87.64376, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23536801338196, 'eval/sps': 939.5504402896829, 'num_steps': 77905920}
{'eval/walltime': 130107.6009452343, 'training/sps': 2955.722922126663, 'training/walltime': 26492.310182094574, 'training/entropy_loss': Array(0.01917442, dtype=float32), 'training/policy_loss': Array(0.01006245, dtype=float32), 'training/total_loss': Array(0.14713436, dtype=float32), 'training/v_loss': Array(0.11789751, dtype=float32), 'eval/episode_distance_from_origin': Array(7393.588, dtype=float32), 'eval/episode_distance_reward': Array(36.265137, dtype=float32), 'eval/episode_forward_reward': Array(6044.1577, dtype=float32), 'eval/episode_reward': Array(6017.33, dtype=float32), 'eval/episode_reward_alive': Array(348.14453, dtype=float32), 'eval/episode_reward_linvel': Array(6044.1577, dtype=float32), 'eval/episode_reward_quadctrl': Array(-411.23666, dtype=float32), 'eval/episode_x_position': Array(7348.5254, dtype=float32), 'eval/episode_x_velocity': Array(1208.8315, dtype=float32), 'eval/episode_y_position': Array(-326.76862, dtype=float32), 'eval/episode_y_velocity': Array(-166.7399, dtype=float32), 'eval/episode_distance_from_origin_std': Array(360.52405, dtype=float32), 'eval/episode_distance_reward_std': Array(4.77885, dtype=float32), 'eval/episode_forward_reward_std': Array(796.4686, dtype=float32), 'eval/episode_reward_std': Array(836.0767, dtype=float32), 'eval/episode_reward_alive_std': Array(51.47011, dtype=float32), 'eval/episode_reward_linvel_std': Array(796.4686, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.36099, dtype=float32), 'eval/episode_x_position_std': Array(355.22464, dtype=float32), 'eval/episode_x_velocity_std': Array(159.2937, dtype=float32), 'eval/episode_y_position_std': Array(305.91153, dtype=float32), 'eval/episode_y_velocity_std': Array(92.72774, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47238159179688, 'eval/sps': 937.9187093170349, 'num_steps': 77987840}
{'eval/walltime': 130243.84143066406, 'training/sps': 2964.159422299909, 'training/walltime': 26519.94702219963, 'training/entropy_loss': Array(0.02166746, dtype=float32), 'training/policy_loss': Array(0.00887466, dtype=float32), 'training/total_loss': Array(0.21815151, dtype=float32), 'training/v_loss': Array(0.1876094, dtype=float32), 'eval/episode_distance_from_origin': Array(7304.2705, dtype=float32), 'eval/episode_distance_reward': Array(35.684654, dtype=float32), 'eval/episode_forward_reward': Array(5947.41, dtype=float32), 'eval/episode_reward': Array(5916.5996, dtype=float32), 'eval/episode_reward_alive': Array(352.64453, dtype=float32), 'eval/episode_reward_linvel': Array(5947.41, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.13947, dtype=float32), 'eval/episode_x_position': Array(7258.461, dtype=float32), 'eval/episode_x_velocity': Array(1189.4819, dtype=float32), 'eval/episode_y_position': Array(-351.59863, dtype=float32), 'eval/episode_y_velocity': Array(-167.04544, dtype=float32), 'eval/episode_distance_from_origin_std': Array(468.82812, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0067015, dtype=float32), 'eval/episode_forward_reward_std': Array(1001.1095, dtype=float32), 'eval/episode_reward_std': Array(1054.9855, dtype=float32), 'eval/episode_reward_alive_std': Array(56.209053, dtype=float32), 'eval/episode_reward_linvel_std': Array(1001.1095, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.582127, dtype=float32), 'eval/episode_x_position_std': Array(465.42053, dtype=float32), 'eval/episode_x_velocity_std': Array(200.22182, dtype=float32), 'eval/episode_y_position_std': Array(279.07236, dtype=float32), 'eval/episode_y_velocity_std': Array(84.39407, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2404854297638, 'eval/sps': 939.5151492321127, 'num_steps': 78069760}
{'eval/walltime': 130380.28162240982, 'training/sps': 2953.344559508958, 'training/walltime': 26547.685065746307, 'training/entropy_loss': Array(0.01992429, dtype=float32), 'training/policy_loss': Array(0.00600763, dtype=float32), 'training/total_loss': Array(0.23442015, dtype=float32), 'training/v_loss': Array(0.20848823, dtype=float32), 'eval/episode_distance_from_origin': Array(7375.4883, dtype=float32), 'eval/episode_distance_reward': Array(36.7461, dtype=float32), 'eval/episode_forward_reward': Array(6124.3184, dtype=float32), 'eval/episode_reward': Array(6100.8545, dtype=float32), 'eval/episode_reward_alive': Array(354.09766, dtype=float32), 'eval/episode_reward_linvel': Array(6124.3184, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.30756, dtype=float32), 'eval/episode_x_position': Array(7327.2993, dtype=float32), 'eval/episode_x_velocity': Array(1224.8635, dtype=float32), 'eval/episode_y_position': Array(-378.98645, dtype=float32), 'eval/episode_y_velocity': Array(-188.59451, dtype=float32), 'eval/episode_distance_from_origin_std': Array(435.79074, dtype=float32), 'eval/episode_distance_reward_std': Array(5.89078, dtype=float32), 'eval/episode_forward_reward_std': Array(981.79114, dtype=float32), 'eval/episode_reward_std': Array(1003.629, dtype=float32), 'eval/episode_reward_alive_std': Array(40.054703, dtype=float32), 'eval/episode_reward_linvel_std': Array(981.79114, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.387709, dtype=float32), 'eval/episode_x_position_std': Array(432.88254, dtype=float32), 'eval/episode_x_velocity_std': Array(196.35812, dtype=float32), 'eval/episode_y_position_std': Array(275.5576, dtype=float32), 'eval/episode_y_velocity_std': Array(77.89802, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44019174575806, 'eval/sps': 938.1399891207609, 'num_steps': 78151680}
{'eval/walltime': 130516.4989285469, 'training/sps': 2961.510786066451, 'training/walltime': 26575.346622943878, 'training/entropy_loss': Array(0.02013915, dtype=float32), 'training/policy_loss': Array(0.00696273, dtype=float32), 'training/total_loss': Array(0.25031906, dtype=float32), 'training/v_loss': Array(0.22321719, dtype=float32), 'eval/episode_distance_from_origin': Array(7341.4253, dtype=float32), 'eval/episode_distance_reward': Array(36.36946, dtype=float32), 'eval/episode_forward_reward': Array(6061.544, dtype=float32), 'eval/episode_reward': Array(6036.5786, dtype=float32), 'eval/episode_reward_alive': Array(351.60938, dtype=float32), 'eval/episode_reward_linvel': Array(6061.544, dtype=float32), 'eval/episode_reward_quadctrl': Array(-412.94482, dtype=float32), 'eval/episode_x_position': Array(7294.581, dtype=float32), 'eval/episode_x_velocity': Array(1212.3088, dtype=float32), 'eval/episode_y_position': Array(-297.98047, dtype=float32), 'eval/episode_y_velocity': Array(-161.86908, dtype=float32), 'eval/episode_distance_from_origin_std': Array(460.95538, dtype=float32), 'eval/episode_distance_reward_std': Array(5.475452, dtype=float32), 'eval/episode_forward_reward_std': Array(912.5688, dtype=float32), 'eval/episode_reward_std': Array(948.7168, dtype=float32), 'eval/episode_reward_alive_std': Array(51.65816, dtype=float32), 'eval/episode_reward_linvel_std': Array(912.5688, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.35843, dtype=float32), 'eval/episode_x_position_std': Array(458.3239, dtype=float32), 'eval/episode_x_velocity_std': Array(182.51387, dtype=float32), 'eval/episode_y_position_std': Array(346.99777, dtype=float32), 'eval/episode_y_velocity_std': Array(102.331924, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21730613708496, 'eval/sps': 939.6750209638171, 'num_steps': 78233600}
{'eval/walltime': 130652.93073177338, 'training/sps': 2959.246147834866, 'training/walltime': 26603.02934885025, 'training/entropy_loss': Array(0.02152876, dtype=float32), 'training/policy_loss': Array(0.00726092, dtype=float32), 'training/total_loss': Array(0.22435537, dtype=float32), 'training/v_loss': Array(0.1955657, dtype=float32), 'eval/episode_distance_from_origin': Array(7399.8213, dtype=float32), 'eval/episode_distance_reward': Array(36.548653, dtype=float32), 'eval/episode_forward_reward': Array(6091.408, dtype=float32), 'eval/episode_reward': Array(6060.256, dtype=float32), 'eval/episode_reward_alive': Array(352.02734, dtype=float32), 'eval/episode_reward_linvel': Array(6091.408, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.72855, dtype=float32), 'eval/episode_x_position': Array(7354.742, dtype=float32), 'eval/episode_x_velocity': Array(1218.2817, dtype=float32), 'eval/episode_y_position': Array(-302.22287, dtype=float32), 'eval/episode_y_velocity': Array(-160.8157, dtype=float32), 'eval/episode_distance_from_origin_std': Array(497.9684, dtype=float32), 'eval/episode_distance_reward_std': Array(6.214247, dtype=float32), 'eval/episode_forward_reward_std': Array(1035.7014, dtype=float32), 'eval/episode_reward_std': Array(1080.4167, dtype=float32), 'eval/episode_reward_alive_std': Array(55.76602, dtype=float32), 'eval/episode_reward_linvel_std': Array(1035.7014, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.915386, dtype=float32), 'eval/episode_x_position_std': Array(495.61865, dtype=float32), 'eval/episode_x_velocity_std': Array(207.1402, dtype=float32), 'eval/episode_y_position_std': Array(309.33652, dtype=float32), 'eval/episode_y_velocity_std': Array(94.69363, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43180322647095, 'eval/sps': 938.1976707258314, 'num_steps': 78315520}
{'eval/walltime': 130789.14167952538, 'training/sps': 2965.264489884755, 'training/walltime': 26630.65588951111, 'training/entropy_loss': Array(0.01551074, dtype=float32), 'training/policy_loss': Array(0.00733708, dtype=float32), 'training/total_loss': Array(0.08162922, dtype=float32), 'training/v_loss': Array(0.05878141, dtype=float32), 'eval/episode_distance_from_origin': Array(7286.8545, dtype=float32), 'eval/episode_distance_reward': Array(35.480644, dtype=float32), 'eval/episode_forward_reward': Array(5913.41, dtype=float32), 'eval/episode_reward': Array(5873.608, dtype=float32), 'eval/episode_reward_alive': Array(343.0703, dtype=float32), 'eval/episode_reward_linvel': Array(5913.41, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.3515, dtype=float32), 'eval/episode_x_position': Array(7240.714, dtype=float32), 'eval/episode_x_velocity': Array(1182.6818, dtype=float32), 'eval/episode_y_position': Array(-265.87772, dtype=float32), 'eval/episode_y_velocity': Array(-164.05838, dtype=float32), 'eval/episode_distance_from_origin_std': Array(528.4375, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1368356, dtype=float32), 'eval/episode_forward_reward_std': Array(1022.799, dtype=float32), 'eval/episode_reward_std': Array(1066.2805, dtype=float32), 'eval/episode_reward_alive_std': Array(52.06733, dtype=float32), 'eval/episode_reward_linvel_std': Array(1022.799, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.952667, dtype=float32), 'eval/episode_x_position_std': Array(525.27435, dtype=float32), 'eval/episode_x_velocity_std': Array(204.55974, dtype=float32), 'eval/episode_y_position_std': Array(341.64273, dtype=float32), 'eval/episode_y_velocity_std': Array(91.04357, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2109477519989, 'eval/sps': 939.7188853942292, 'num_steps': 78397440}
{'eval/walltime': 130925.58193016052, 'training/sps': 2958.88751802483, 'training/walltime': 26658.341970682144, 'training/entropy_loss': Array(0.01807724, dtype=float32), 'training/policy_loss': Array(0.00755857, dtype=float32), 'training/total_loss': Array(0.12559915, dtype=float32), 'training/v_loss': Array(0.09996334, dtype=float32), 'eval/episode_distance_from_origin': Array(7311.6875, dtype=float32), 'eval/episode_distance_reward': Array(36.49772, dtype=float32), 'eval/episode_forward_reward': Array(6082.9204, dtype=float32), 'eval/episode_reward': Array(6054.7534, dtype=float32), 'eval/episode_reward_alive': Array(357.39062, dtype=float32), 'eval/episode_reward_linvel': Array(6082.9204, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.05493, dtype=float32), 'eval/episode_x_position': Array(7263.585, dtype=float32), 'eval/episode_x_velocity': Array(1216.584, dtype=float32), 'eval/episode_y_position': Array(-292.3994, dtype=float32), 'eval/episode_y_velocity': Array(-177.4013, dtype=float32), 'eval/episode_distance_from_origin_std': Array(446.3137, dtype=float32), 'eval/episode_distance_reward_std': Array(5.640527, dtype=float32), 'eval/episode_forward_reward_std': Array(940.082, dtype=float32), 'eval/episode_reward_std': Array(977.1222, dtype=float32), 'eval/episode_reward_alive_std': Array(48.943363, dtype=float32), 'eval/episode_reward_linvel_std': Array(940.082, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.74415, dtype=float32), 'eval/episode_x_position_std': Array(443.11115, dtype=float32), 'eval/episode_x_velocity_std': Array(188.01628, dtype=float32), 'eval/episode_y_position_std': Array(332.90527, dtype=float32), 'eval/episode_y_velocity_std': Array(86.191765, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4402506351471, 'eval/sps': 938.1395842073242, 'num_steps': 78479360}
{'eval/walltime': 131061.81179475784, 'training/sps': 2968.6221137489965, 'training/walltime': 26685.937264680862, 'training/entropy_loss': Array(0.02280522, dtype=float32), 'training/policy_loss': Array(0.01074174, dtype=float32), 'training/total_loss': Array(0.20571354, dtype=float32), 'training/v_loss': Array(0.17216659, dtype=float32), 'eval/episode_distance_from_origin': Array(7254.3887, dtype=float32), 'eval/episode_distance_reward': Array(35.687027, dtype=float32), 'eval/episode_forward_reward': Array(5947.806, dtype=float32), 'eval/episode_reward': Array(5910.128, dtype=float32), 'eval/episode_reward_alive': Array(347.02344, dtype=float32), 'eval/episode_reward_linvel': Array(5947.806, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.38745, dtype=float32), 'eval/episode_x_position': Array(7210.501, dtype=float32), 'eval/episode_x_velocity': Array(1189.5612, dtype=float32), 'eval/episode_y_position': Array(-258.8698, dtype=float32), 'eval/episode_y_velocity': Array(-155.71242, dtype=float32), 'eval/episode_distance_from_origin_std': Array(514.91284, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4443693, dtype=float32), 'eval/episode_forward_reward_std': Array(1074.0537, dtype=float32), 'eval/episode_reward_std': Array(1130.5857, dtype=float32), 'eval/episode_reward_alive_std': Array(58.082672, dtype=float32), 'eval/episode_reward_linvel_std': Array(1074.0537, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.51748, dtype=float32), 'eval/episode_x_position_std': Array(511.3035, dtype=float32), 'eval/episode_x_velocity_std': Array(214.81088, dtype=float32), 'eval/episode_y_position_std': Array(307.7036, dtype=float32), 'eval/episode_y_velocity_std': Array(91.92704, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22986459732056, 'eval/sps': 939.588396262104, 'num_steps': 78561280}
{'eval/walltime': 131198.28153038025, 'training/sps': 2956.204365065145, 'training/walltime': 26713.6484746933, 'training/entropy_loss': Array(0.01963198, dtype=float32), 'training/policy_loss': Array(0.01165653, dtype=float32), 'training/total_loss': Array(0.22447771, dtype=float32), 'training/v_loss': Array(0.1931892, dtype=float32), 'eval/episode_distance_from_origin': Array(7310.962, dtype=float32), 'eval/episode_distance_reward': Array(36.814922, dtype=float32), 'eval/episode_forward_reward': Array(6135.7866, dtype=float32), 'eval/episode_reward': Array(6111.47, dtype=float32), 'eval/episode_reward_alive': Array(353.22266, dtype=float32), 'eval/episode_reward_linvel': Array(6135.7866, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.35452, dtype=float32), 'eval/episode_x_position': Array(7265.9956, dtype=float32), 'eval/episode_x_velocity': Array(1227.1573, dtype=float32), 'eval/episode_y_position': Array(-264.61075, dtype=float32), 'eval/episode_y_velocity': Array(-158.9167, dtype=float32), 'eval/episode_distance_from_origin_std': Array(429.3459, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4917817, dtype=float32), 'eval/episode_forward_reward_std': Array(915.29193, dtype=float32), 'eval/episode_reward_std': Array(953.58466, dtype=float32), 'eval/episode_reward_alive_std': Array(52.656868, dtype=float32), 'eval/episode_reward_linvel_std': Array(915.29193, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.65047, dtype=float32), 'eval/episode_x_position_std': Array(426.4834, dtype=float32), 'eval/episode_x_velocity_std': Array(183.05829, dtype=float32), 'eval/episode_y_position_std': Array(328.611, dtype=float32), 'eval/episode_y_velocity_std': Array(95.69229, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.469735622406, 'eval/sps': 937.9368943320835, 'num_steps': 78643200}
{'eval/walltime': 131334.48726415634, 'training/sps': 2969.710491385125, 'training/walltime': 26741.23365521431, 'training/entropy_loss': Array(0.02067369, dtype=float32), 'training/policy_loss': Array(0.00902276, dtype=float32), 'training/total_loss': Array(0.2617837, dtype=float32), 'training/v_loss': Array(0.23208722, dtype=float32), 'eval/episode_distance_from_origin': Array(7267.0605, dtype=float32), 'eval/episode_distance_reward': Array(35.94484, dtype=float32), 'eval/episode_forward_reward': Array(5990.773, dtype=float32), 'eval/episode_reward': Array(5962.8574, dtype=float32), 'eval/episode_reward_alive': Array(353.27734, dtype=float32), 'eval/episode_reward_linvel': Array(5990.773, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.13733, dtype=float32), 'eval/episode_x_position': Array(7220.4023, dtype=float32), 'eval/episode_x_velocity': Array(1198.1545, dtype=float32), 'eval/episode_y_position': Array(-233.92433, dtype=float32), 'eval/episode_y_velocity': Array(-148.01512, dtype=float32), 'eval/episode_distance_from_origin_std': Array(516.7657, dtype=float32), 'eval/episode_distance_reward_std': Array(5.8232226, dtype=float32), 'eval/episode_forward_reward_std': Array(970.53064, dtype=float32), 'eval/episode_reward_std': Array(1002.4391, dtype=float32), 'eval/episode_reward_alive_std': Array(50.60006, dtype=float32), 'eval/episode_reward_linvel_std': Array(970.53064, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.53678, dtype=float32), 'eval/episode_x_position_std': Array(513.1226, dtype=float32), 'eval/episode_x_velocity_std': Array(194.1062, dtype=float32), 'eval/episode_y_position_std': Array(376.40982, dtype=float32), 'eval/episode_y_velocity_std': Array(104.76542, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20573377609253, 'eval/sps': 939.7548579740272, 'num_steps': 78725120}
{'eval/walltime': 131470.95157265663, 'training/sps': 2958.494687154025, 'training/walltime': 26768.923412561417, 'training/entropy_loss': Array(0.02250176, dtype=float32), 'training/policy_loss': Array(0.00585122, dtype=float32), 'training/total_loss': Array(0.23423228, dtype=float32), 'training/v_loss': Array(0.2058793, dtype=float32), 'eval/episode_distance_from_origin': Array(7258.1177, dtype=float32), 'eval/episode_distance_reward': Array(35.49595, dtype=float32), 'eval/episode_forward_reward': Array(5915.957, dtype=float32), 'eval/episode_reward': Array(5887.2764, dtype=float32), 'eval/episode_reward_alive': Array(359.65234, dtype=float32), 'eval/episode_reward_linvel': Array(5915.957, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.82983, dtype=float32), 'eval/episode_x_position': Array(7213.227, dtype=float32), 'eval/episode_x_velocity': Array(1183.1915, dtype=float32), 'eval/episode_y_position': Array(-226.92862, dtype=float32), 'eval/episode_y_velocity': Array(-144.98819, dtype=float32), 'eval/episode_distance_from_origin_std': Array(497.6315, dtype=float32), 'eval/episode_distance_reward_std': Array(6.025037, dtype=float32), 'eval/episode_forward_reward_std': Array(1004.16614, dtype=float32), 'eval/episode_reward_std': Array(1037.8959, dtype=float32), 'eval/episode_reward_alive_std': Array(47.138702, dtype=float32), 'eval/episode_reward_linvel_std': Array(1004.16614, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.27566, dtype=float32), 'eval/episode_x_position_std': Array(493.92288, dtype=float32), 'eval/episode_x_velocity_std': Array(200.83322, dtype=float32), 'eval/episode_y_position_std': Array(342.05606, dtype=float32), 'eval/episode_y_velocity_std': Array(103.446884, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46430850028992, 'eval/sps': 937.9741956463881, 'num_steps': 78807040}
{'eval/walltime': 131607.18499684334, 'training/sps': 2968.8465797188337, 'training/walltime': 26796.51662015915, 'training/entropy_loss': Array(0.01787712, dtype=float32), 'training/policy_loss': Array(0.00689846, dtype=float32), 'training/total_loss': Array(0.13510138, dtype=float32), 'training/v_loss': Array(0.1103258, dtype=float32), 'eval/episode_distance_from_origin': Array(7260.7344, dtype=float32), 'eval/episode_distance_reward': Array(35.920834, dtype=float32), 'eval/episode_forward_reward': Array(5986.774, dtype=float32), 'eval/episode_reward': Array(5952.865, dtype=float32), 'eval/episode_reward_alive': Array(347.89062, dtype=float32), 'eval/episode_reward_linvel': Array(5986.774, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.72, dtype=float32), 'eval/episode_x_position': Array(7217.3125, dtype=float32), 'eval/episode_x_velocity': Array(1197.3549, dtype=float32), 'eval/episode_y_position': Array(-234.3582, dtype=float32), 'eval/episode_y_velocity': Array(-156.30586, dtype=float32), 'eval/episode_distance_from_origin_std': Array(517.5157, dtype=float32), 'eval/episode_distance_reward_std': Array(5.9328923, dtype=float32), 'eval/episode_forward_reward_std': Array(988.8087, dtype=float32), 'eval/episode_reward_std': Array(1029.6779, dtype=float32), 'eval/episode_reward_alive_std': Array(53.061428, dtype=float32), 'eval/episode_reward_linvel_std': Array(988.8087, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.163506, dtype=float32), 'eval/episode_x_position_std': Array(514.2461, dtype=float32), 'eval/episode_x_velocity_std': Array(197.76173, dtype=float32), 'eval/episode_y_position_std': Array(309.90964, dtype=float32), 'eval/episode_y_velocity_std': Array(91.32857, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23342418670654, 'eval/sps': 939.5638461276382, 'num_steps': 78888960}
{'eval/walltime': 131743.63419270515, 'training/sps': 2961.738798715113, 'training/walltime': 26824.17604780197, 'training/entropy_loss': Array(0.01711605, dtype=float32), 'training/policy_loss': Array(0.01161316, dtype=float32), 'training/total_loss': Array(0.10913683, dtype=float32), 'training/v_loss': Array(0.08040762, dtype=float32), 'eval/episode_distance_from_origin': Array(7232.887, dtype=float32), 'eval/episode_distance_reward': Array(36.24191, dtype=float32), 'eval/episode_forward_reward': Array(6040.2847, dtype=float32), 'eval/episode_reward': Array(6012.541, dtype=float32), 'eval/episode_reward_alive': Array(353.48438, dtype=float32), 'eval/episode_reward_linvel': Array(6040.2847, dtype=float32), 'eval/episode_reward_quadctrl': Array(-417.47067, dtype=float32), 'eval/episode_x_position': Array(7187.8916, dtype=float32), 'eval/episode_x_velocity': Array(1208.0571, dtype=float32), 'eval/episode_y_position': Array(-211.44472, dtype=float32), 'eval/episode_y_velocity': Array(-141.74643, dtype=float32), 'eval/episode_distance_from_origin_std': Array(558.02484, dtype=float32), 'eval/episode_distance_reward_std': Array(5.714673, dtype=float32), 'eval/episode_forward_reward_std': Array(952.43994, dtype=float32), 'eval/episode_reward_std': Array(972.92163, dtype=float32), 'eval/episode_reward_alive_std': Array(43.91188, dtype=float32), 'eval/episode_reward_linvel_std': Array(952.43994, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.54815, dtype=float32), 'eval/episode_x_position_std': Array(554.7801, dtype=float32), 'eval/episode_x_velocity_std': Array(190.48805, dtype=float32), 'eval/episode_y_position_std': Array(342.61966, dtype=float32), 'eval/episode_y_velocity_std': Array(107.90108, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4491958618164, 'eval/sps': 938.0780824067809, 'num_steps': 78970880}
{'eval/walltime': 131879.87454295158, 'training/sps': 2968.073416736083, 'training/walltime': 26851.776443243027, 'training/entropy_loss': Array(0.02186473, dtype=float32), 'training/policy_loss': Array(0.00908466, dtype=float32), 'training/total_loss': Array(0.2109035, dtype=float32), 'training/v_loss': Array(0.1799541, dtype=float32), 'eval/episode_distance_from_origin': Array(7273.2617, dtype=float32), 'eval/episode_distance_reward': Array(36.10083, dtype=float32), 'eval/episode_forward_reward': Array(6016.772, dtype=float32), 'eval/episode_reward': Array(5978.2163, dtype=float32), 'eval/episode_reward_alive': Array(347.28516, dtype=float32), 'eval/episode_reward_linvel': Array(6016.772, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.94238, dtype=float32), 'eval/episode_x_position': Array(7228.4746, dtype=float32), 'eval/episode_x_velocity': Array(1203.3545, dtype=float32), 'eval/episode_y_position': Array(-233.04005, dtype=float32), 'eval/episode_y_velocity': Array(-153.45966, dtype=float32), 'eval/episode_distance_from_origin_std': Array(554.5671, dtype=float32), 'eval/episode_distance_reward_std': Array(6.4192877, dtype=float32), 'eval/episode_forward_reward_std': Array(1069.8743, dtype=float32), 'eval/episode_reward_std': Array(1119.0751, dtype=float32), 'eval/episode_reward_alive_std': Array(54.43415, dtype=float32), 'eval/episode_reward_linvel_std': Array(1069.8743, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.247066, dtype=float32), 'eval/episode_x_position_std': Array(550.949, dtype=float32), 'eval/episode_x_velocity_std': Array(213.97482, dtype=float32), 'eval/episode_y_position_std': Array(334.7634, dtype=float32), 'eval/episode_y_velocity_std': Array(95.50451, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24035024642944, 'eval/sps': 939.5160814580671, 'num_steps': 79052800}
{'eval/walltime': 132016.3220283985, 'training/sps': 2961.0132726620886, 'training/walltime': 26879.44264817238, 'training/entropy_loss': Array(0.01959021, dtype=float32), 'training/policy_loss': Array(0.0081253, dtype=float32), 'training/total_loss': Array(0.21983325, dtype=float32), 'training/v_loss': Array(0.19211775, dtype=float32), 'eval/episode_distance_from_origin': Array(7255.176, dtype=float32), 'eval/episode_distance_reward': Array(35.591553, dtype=float32), 'eval/episode_forward_reward': Array(5931.8926, dtype=float32), 'eval/episode_reward': Array(5893.7554, dtype=float32), 'eval/episode_reward_alive': Array(348.9453, dtype=float32), 'eval/episode_reward_linvel': Array(5931.8926, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.67426, dtype=float32), 'eval/episode_x_position': Array(7206.671, dtype=float32), 'eval/episode_x_velocity': Array(1186.3787, dtype=float32), 'eval/episode_y_position': Array(-282.2836, dtype=float32), 'eval/episode_y_velocity': Array(-163.19576, dtype=float32), 'eval/episode_distance_from_origin_std': Array(532.52277, dtype=float32), 'eval/episode_distance_reward_std': Array(6.566334, dtype=float32), 'eval/episode_forward_reward_std': Array(1094.3815, dtype=float32), 'eval/episode_reward_std': Array(1140.4054, dtype=float32), 'eval/episode_reward_alive_std': Array(55.568836, dtype=float32), 'eval/episode_reward_linvel_std': Array(1094.3815, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.792694, dtype=float32), 'eval/episode_x_position_std': Array(530.8203, dtype=float32), 'eval/episode_x_velocity_std': Array(218.87614, dtype=float32), 'eval/episode_y_position_std': Array(352.1383, dtype=float32), 'eval/episode_y_velocity_std': Array(93.774, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44748544692993, 'eval/sps': 938.0898415294322, 'num_steps': 79134720}
{'eval/walltime': 132152.59105324745, 'training/sps': 2972.283981993981, 'training/walltime': 26907.00394463539, 'training/entropy_loss': Array(0.02022082, dtype=float32), 'training/policy_loss': Array(0.00949551, dtype=float32), 'training/total_loss': Array(0.27086943, dtype=float32), 'training/v_loss': Array(0.24115308, dtype=float32), 'eval/episode_distance_from_origin': Array(7223.0293, dtype=float32), 'eval/episode_distance_reward': Array(36.087505, dtype=float32), 'eval/episode_forward_reward': Array(6014.5513, dtype=float32), 'eval/episode_reward': Array(5982.054, dtype=float32), 'eval/episode_reward_alive': Array(352.29297, dtype=float32), 'eval/episode_reward_linvel': Array(6014.5513, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.87723, dtype=float32), 'eval/episode_x_position': Array(7179.6934, dtype=float32), 'eval/episode_x_velocity': Array(1202.9103, dtype=float32), 'eval/episode_y_position': Array(-227.65425, dtype=float32), 'eval/episode_y_velocity': Array(-155.57324, dtype=float32), 'eval/episode_distance_from_origin_std': Array(494.66553, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2203336, dtype=float32), 'eval/episode_forward_reward_std': Array(870.05035, dtype=float32), 'eval/episode_reward_std': Array(908.40857, dtype=float32), 'eval/episode_reward_alive_std': Array(51.967033, dtype=float32), 'eval/episode_reward_linvel_std': Array(870.05035, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.746304, dtype=float32), 'eval/episode_x_position_std': Array(490.56067, dtype=float32), 'eval/episode_x_velocity_std': Array(174.0102, dtype=float32), 'eval/episode_y_position_std': Array(303.65207, dtype=float32), 'eval/episode_y_velocity_std': Array(89.85877, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.269024848938, 'eval/sps': 939.3183824562869, 'num_steps': 79216640}
{'eval/walltime': 132289.0801358223, 'training/sps': 2952.9142183403806, 'training/walltime': 26934.746030569077, 'training/entropy_loss': Array(0.0215662, dtype=float32), 'training/policy_loss': Array(0.00969414, dtype=float32), 'training/total_loss': Array(0.25665894, dtype=float32), 'training/v_loss': Array(0.22539862, dtype=float32), 'eval/episode_distance_from_origin': Array(7307.042, dtype=float32), 'eval/episode_distance_reward': Array(36.462296, dtype=float32), 'eval/episode_forward_reward': Array(6077.0156, dtype=float32), 'eval/episode_reward': Array(6047.913, dtype=float32), 'eval/episode_reward_alive': Array(355.34766, dtype=float32), 'eval/episode_reward_linvel': Array(6077.0156, dtype=float32), 'eval/episode_reward_quadctrl': Array(-420.91302, dtype=float32), 'eval/episode_x_position': Array(7262.1265, dtype=float32), 'eval/episode_x_velocity': Array(1215.4033, dtype=float32), 'eval/episode_y_position': Array(-271.16022, dtype=float32), 'eval/episode_y_velocity': Array(-166.99823, dtype=float32), 'eval/episode_distance_from_origin_std': Array(457.56998, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1023602, dtype=float32), 'eval/episode_forward_reward_std': Array(850.3889, dtype=float32), 'eval/episode_reward_std': Array(884.74194, dtype=float32), 'eval/episode_reward_alive_std': Array(49.780636, dtype=float32), 'eval/episode_reward_linvel_std': Array(850.3889, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.389463, dtype=float32), 'eval/episode_x_position_std': Array(454.56717, dtype=float32), 'eval/episode_x_velocity_std': Array(170.07771, dtype=float32), 'eval/episode_y_position_std': Array(309.70807, dtype=float32), 'eval/episode_y_velocity_std': Array(91.65054, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48908257484436, 'eval/sps': 937.8039443543821, 'num_steps': 79298560}
{'eval/walltime': 132425.3168168068, 'training/sps': 2960.177186734904, 'training/walltime': 26962.42004966736, 'training/entropy_loss': Array(0.01986217, dtype=float32), 'training/policy_loss': Array(0.00766511, dtype=float32), 'training/total_loss': Array(0.16802062, dtype=float32), 'training/v_loss': Array(0.14049333, dtype=float32), 'eval/episode_distance_from_origin': Array(7226.8984, dtype=float32), 'eval/episode_distance_reward': Array(35.619865, dtype=float32), 'eval/episode_forward_reward': Array(5936.6113, dtype=float32), 'eval/episode_reward': Array(5897.9043, dtype=float32), 'eval/episode_reward_alive': Array(347.95703, dtype=float32), 'eval/episode_reward_linvel': Array(5936.6113, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.28296, dtype=float32), 'eval/episode_x_position': Array(7180.382, dtype=float32), 'eval/episode_x_velocity': Array(1187.3223, dtype=float32), 'eval/episode_y_position': Array(-296.59174, dtype=float32), 'eval/episode_y_velocity': Array(-168.05556, dtype=float32), 'eval/episode_distance_from_origin_std': Array(490.054, dtype=float32), 'eval/episode_distance_reward_std': Array(5.690794, dtype=float32), 'eval/episode_forward_reward_std': Array(948.45874, dtype=float32), 'eval/episode_reward_std': Array(987.7178, dtype=float32), 'eval/episode_reward_alive_std': Array(48.174572, dtype=float32), 'eval/episode_reward_linvel_std': Array(948.45874, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.865114, dtype=float32), 'eval/episode_x_position_std': Array(487.93533, dtype=float32), 'eval/episode_x_velocity_std': Array(189.69173, dtype=float32), 'eval/episode_y_position_std': Array(334.84378, dtype=float32), 'eval/episode_y_velocity_std': Array(91.06186, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23668098449707, 'eval/sps': 939.5413854405749, 'num_steps': 79380480}
{'eval/walltime': 132561.7692141533, 'training/sps': 2959.0824817796724, 'training/walltime': 26990.104306697845, 'training/entropy_loss': Array(0.01627067, dtype=float32), 'training/policy_loss': Array(0.00973932, dtype=float32), 'training/total_loss': Array(0.11874438, dtype=float32), 'training/v_loss': Array(0.0927344, dtype=float32), 'eval/episode_distance_from_origin': Array(7308.216, dtype=float32), 'eval/episode_distance_reward': Array(36.287178, dtype=float32), 'eval/episode_forward_reward': Array(6047.83, dtype=float32), 'eval/episode_reward': Array(6012.4214, dtype=float32), 'eval/episode_reward_alive': Array(352.27734, dtype=float32), 'eval/episode_reward_linvel': Array(6047.83, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.9738, dtype=float32), 'eval/episode_x_position': Array(7259.148, dtype=float32), 'eval/episode_x_velocity': Array(1209.5659, dtype=float32), 'eval/episode_y_position': Array(-358.5769, dtype=float32), 'eval/episode_y_velocity': Array(-175.3958, dtype=float32), 'eval/episode_distance_from_origin_std': Array(436.37607, dtype=float32), 'eval/episode_distance_reward_std': Array(4.875319, dtype=float32), 'eval/episode_forward_reward_std': Array(812.5475, dtype=float32), 'eval/episode_reward_std': Array(844.1613, dtype=float32), 'eval/episode_reward_alive_std': Array(46.70071, dtype=float32), 'eval/episode_reward_linvel_std': Array(812.5475, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.210445, dtype=float32), 'eval/episode_x_position_std': Array(433.7489, dtype=float32), 'eval/episode_x_velocity_std': Array(162.50946, dtype=float32), 'eval/episode_y_position_std': Array(314.3785, dtype=float32), 'eval/episode_y_velocity_std': Array(99.57841, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45239734649658, 'eval/sps': 938.0560729539019, 'num_steps': 79462400}
{'eval/walltime': 132697.98755431175, 'training/sps': 2966.7887205011443, 'training/walltime': 27017.716653823853, 'training/entropy_loss': Array(0.02211606, dtype=float32), 'training/policy_loss': Array(0.01409317, dtype=float32), 'training/total_loss': Array(0.1916126, dtype=float32), 'training/v_loss': Array(0.15540336, dtype=float32), 'eval/episode_distance_from_origin': Array(7111.5176, dtype=float32), 'eval/episode_distance_reward': Array(34.55738, dtype=float32), 'eval/episode_forward_reward': Array(5759.5312, dtype=float32), 'eval/episode_reward': Array(5715.1396, dtype=float32), 'eval/episode_reward_alive': Array(351.77734, dtype=float32), 'eval/episode_reward_linvel': Array(5759.5312, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.72693, dtype=float32), 'eval/episode_x_position': Array(7061.87, dtype=float32), 'eval/episode_x_velocity': Array(1151.9062, dtype=float32), 'eval/episode_y_position': Array(-324.12598, dtype=float32), 'eval/episode_y_velocity': Array(-166.0311, dtype=float32), 'eval/episode_distance_from_origin_std': Array(535.9123, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2271066, dtype=float32), 'eval/episode_forward_reward_std': Array(1037.8444, dtype=float32), 'eval/episode_reward_std': Array(1090.0657, dtype=float32), 'eval/episode_reward_alive_std': Array(52.51149, dtype=float32), 'eval/episode_reward_linvel_std': Array(1037.8444, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.383263, dtype=float32), 'eval/episode_x_position_std': Array(531.16516, dtype=float32), 'eval/episode_x_velocity_std': Array(207.56891, dtype=float32), 'eval/episode_y_position_std': Array(347.59518, dtype=float32), 'eval/episode_y_velocity_std': Array(105.93658, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21834015846252, 'eval/sps': 939.6678879738063, 'num_steps': 79544320}
{'eval/walltime': 132834.58728933334, 'training/sps': 2959.389083733089, 'training/walltime': 27045.398042678833, 'training/entropy_loss': Array(0.01996188, dtype=float32), 'training/policy_loss': Array(0.00886739, dtype=float32), 'training/total_loss': Array(0.2272306, dtype=float32), 'training/v_loss': Array(0.19840133, dtype=float32), 'eval/episode_distance_from_origin': Array(7202.145, dtype=float32), 'eval/episode_distance_reward': Array(34.76034, dtype=float32), 'eval/episode_forward_reward': Array(5793.358, dtype=float32), 'eval/episode_reward': Array(5756.284, dtype=float32), 'eval/episode_reward_alive': Array(354.78906, dtype=float32), 'eval/episode_reward_linvel': Array(5793.358, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.6229, dtype=float32), 'eval/episode_x_position': Array(7153.4287, dtype=float32), 'eval/episode_x_velocity': Array(1158.6716, dtype=float32), 'eval/episode_y_position': Array(-359.58618, dtype=float32), 'eval/episode_y_velocity': Array(-170.66277, dtype=float32), 'eval/episode_distance_from_origin_std': Array(492.26804, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5167813, dtype=float32), 'eval/episode_forward_reward_std': Array(919.45667, dtype=float32), 'eval/episode_reward_std': Array(955.1794, dtype=float32), 'eval/episode_reward_alive_std': Array(49.93717, dtype=float32), 'eval/episode_reward_linvel_std': Array(919.45667, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(33.775208, dtype=float32), 'eval/episode_x_position_std': Array(487.5245, dtype=float32), 'eval/episode_x_velocity_std': Array(183.89119, dtype=float32), 'eval/episode_y_position_std': Array(305.40057, dtype=float32), 'eval/episode_y_velocity_std': Array(86.98438, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5997350215912, 'eval/sps': 937.0442774268054, 'num_steps': 79626240}
{'eval/walltime': 132970.85592913628, 'training/sps': 2971.4079084969585, 'training/walltime': 27072.967465162277, 'training/entropy_loss': Array(0.02069466, dtype=float32), 'training/policy_loss': Array(0.00600161, dtype=float32), 'training/total_loss': Array(0.22159278, dtype=float32), 'training/v_loss': Array(0.1948965, dtype=float32), 'eval/episode_distance_from_origin': Array(7104.663, dtype=float32), 'eval/episode_distance_reward': Array(34.36416, dtype=float32), 'eval/episode_forward_reward': Array(5727.329, dtype=float32), 'eval/episode_reward': Array(5673.148, dtype=float32), 'eval/episode_reward_alive': Array(345.30078, dtype=float32), 'eval/episode_reward_linvel': Array(5727.329, dtype=float32), 'eval/episode_reward_quadctrl': Array(-433.84613, dtype=float32), 'eval/episode_x_position': Array(7054.6587, dtype=float32), 'eval/episode_x_velocity': Array(1145.4657, dtype=float32), 'eval/episode_y_position': Array(-367.193, dtype=float32), 'eval/episode_y_velocity': Array(-177.00592, dtype=float32), 'eval/episode_distance_from_origin_std': Array(553.39734, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2626743, dtype=float32), 'eval/episode_forward_reward_std': Array(1043.7712, dtype=float32), 'eval/episode_reward_std': Array(1095.5314, dtype=float32), 'eval/episode_reward_alive_std': Array(53.546356, dtype=float32), 'eval/episode_reward_linvel_std': Array(1043.7712, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.517143, dtype=float32), 'eval/episode_x_position_std': Array(548.0887, dtype=float32), 'eval/episode_x_velocity_std': Array(208.75418, dtype=float32), 'eval/episode_y_position_std': Array(312.4317, dtype=float32), 'eval/episode_y_velocity_std': Array(90.6511, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26863980293274, 'eval/sps': 939.3210366310944, 'num_steps': 79708160}
{'eval/walltime': 133107.31046247482, 'training/sps': 2953.1399700078678, 'training/walltime': 27100.7074303627, 'training/entropy_loss': Array(0.0221429, dtype=float32), 'training/policy_loss': Array(0.00681461, dtype=float32), 'training/total_loss': Array(0.2322964, dtype=float32), 'training/v_loss': Array(0.20333889, dtype=float32), 'eval/episode_distance_from_origin': Array(7094.9614, dtype=float32), 'eval/episode_distance_reward': Array(34.35449, dtype=float32), 'eval/episode_forward_reward': Array(5725.717, dtype=float32), 'eval/episode_reward': Array(5677.955, dtype=float32), 'eval/episode_reward_alive': Array(345.8203, dtype=float32), 'eval/episode_reward_linvel': Array(5725.717, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.937, dtype=float32), 'eval/episode_x_position': Array(7045.8364, dtype=float32), 'eval/episode_x_velocity': Array(1145.1433, dtype=float32), 'eval/episode_y_position': Array(-317.3921, dtype=float32), 'eval/episode_y_velocity': Array(-166.24417, dtype=float32), 'eval/episode_distance_from_origin_std': Array(530.52826, dtype=float32), 'eval/episode_distance_reward_std': Array(6.3146486, dtype=float32), 'eval/episode_forward_reward_std': Array(1052.434, dtype=float32), 'eval/episode_reward_std': Array(1115.3469, dtype=float32), 'eval/episode_reward_alive_std': Array(61.686348, dtype=float32), 'eval/episode_reward_linvel_std': Array(1052.434, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.59129, dtype=float32), 'eval/episode_x_position_std': Array(524.0984, dtype=float32), 'eval/episode_x_velocity_std': Array(210.48672, dtype=float32), 'eval/episode_y_position_std': Array(339.2246, dtype=float32), 'eval/episode_y_velocity_std': Array(96.71168, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45453333854675, 'eval/sps': 938.041389086203, 'num_steps': 79790080}
{'eval/walltime': 133243.66748285294, 'training/sps': 2956.4830236178673, 'training/walltime': 27128.416028499603, 'training/entropy_loss': Array(0.02299197, dtype=float32), 'training/policy_loss': Array(0.01003474, dtype=float32), 'training/total_loss': Array(0.21409577, dtype=float32), 'training/v_loss': Array(0.18106905, dtype=float32), 'eval/episode_distance_from_origin': Array(7095.048, dtype=float32), 'eval/episode_distance_reward': Array(34.368782, dtype=float32), 'eval/episode_forward_reward': Array(5728.0986, dtype=float32), 'eval/episode_reward': Array(5681.9297, dtype=float32), 'eval/episode_reward_alive': Array(347.71875, dtype=float32), 'eval/episode_reward_linvel': Array(5728.0986, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.25488, dtype=float32), 'eval/episode_x_position': Array(7043.5664, dtype=float32), 'eval/episode_x_velocity': Array(1145.6196, dtype=float32), 'eval/episode_y_position': Array(-334.34927, dtype=float32), 'eval/episode_y_velocity': Array(-170.19467, dtype=float32), 'eval/episode_distance_from_origin_std': Array(509.3248, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2552147, dtype=float32), 'eval/episode_forward_reward_std': Array(1042.5287, dtype=float32), 'eval/episode_reward_std': Array(1089.4248, dtype=float32), 'eval/episode_reward_alive_std': Array(52.95044, dtype=float32), 'eval/episode_reward_linvel_std': Array(1042.5287, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.455963, dtype=float32), 'eval/episode_x_position_std': Array(509.10974, dtype=float32), 'eval/episode_x_velocity_std': Array(208.50569, dtype=float32), 'eval/episode_y_position_std': Array(326.17944, dtype=float32), 'eval/episode_y_velocity_std': Array(92.2907, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3570203781128, 'eval/sps': 938.7122103802276, 'num_steps': 79872000}
{'eval/walltime': 133380.09859609604, 'training/sps': 2956.2930824168216, 'training/walltime': 27156.126406908035, 'training/entropy_loss': Array(0.01438695, dtype=float32), 'training/policy_loss': Array(0.00984092, dtype=float32), 'training/total_loss': Array(0.10277192, dtype=float32), 'training/v_loss': Array(0.07854406, dtype=float32), 'eval/episode_distance_from_origin': Array(7181.9062, dtype=float32), 'eval/episode_distance_reward': Array(34.9061, dtype=float32), 'eval/episode_forward_reward': Array(5817.6514, dtype=float32), 'eval/episode_reward': Array(5774.8804, dtype=float32), 'eval/episode_reward_alive': Array(351.7578, dtype=float32), 'eval/episode_reward_linvel': Array(5817.6514, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.43414, dtype=float32), 'eval/episode_x_position': Array(7129.336, dtype=float32), 'eval/episode_x_velocity': Array(1163.5303, dtype=float32), 'eval/episode_y_position': Array(-378.44165, dtype=float32), 'eval/episode_y_velocity': Array(-184.51309, dtype=float32), 'eval/episode_distance_from_origin_std': Array(538.65857, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7624207, dtype=float32), 'eval/episode_forward_reward_std': Array(960.39734, dtype=float32), 'eval/episode_reward_std': Array(1001.4406, dtype=float32), 'eval/episode_reward_alive_std': Array(51.831345, dtype=float32), 'eval/episode_reward_linvel_std': Array(960.39734, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.96642, dtype=float32), 'eval/episode_x_position_std': Array(532.56134, dtype=float32), 'eval/episode_x_velocity_std': Array(192.07942, dtype=float32), 'eval/episode_y_position_std': Array(317.07898, dtype=float32), 'eval/episode_y_velocity_std': Array(90.60944, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.43111324310303, 'eval/sps': 938.2024155437342, 'num_steps': 79953920}
{'eval/walltime': 133516.45630788803, 'training/sps': 2966.260828391276, 'training/walltime': 27183.743668079376, 'training/entropy_loss': Array(0.02073024, dtype=float32), 'training/policy_loss': Array(0.01349756, dtype=float32), 'training/total_loss': Array(0.17048758, dtype=float32), 'training/v_loss': Array(0.1362598, dtype=float32), 'eval/episode_distance_from_origin': Array(7260.9707, dtype=float32), 'eval/episode_distance_reward': Array(36.0596, dtype=float32), 'eval/episode_forward_reward': Array(6009.8994, dtype=float32), 'eval/episode_reward': Array(5970.579, dtype=float32), 'eval/episode_reward_alive': Array(354.33984, dtype=float32), 'eval/episode_reward_linvel': Array(6009.8994, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.721, dtype=float32), 'eval/episode_x_position': Array(7210.213, dtype=float32), 'eval/episode_x_velocity': Array(1201.98, dtype=float32), 'eval/episode_y_position': Array(-379.33524, dtype=float32), 'eval/episode_y_velocity': Array(-196.64308, dtype=float32), 'eval/episode_distance_from_origin_std': Array(451.31677, dtype=float32), 'eval/episode_distance_reward_std': Array(5.4552693, dtype=float32), 'eval/episode_forward_reward_std': Array(909.2057, dtype=float32), 'eval/episode_reward_std': Array(951.4752, dtype=float32), 'eval/episode_reward_alive_std': Array(48.332867, dtype=float32), 'eval/episode_reward_linvel_std': Array(909.2057, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.929525, dtype=float32), 'eval/episode_x_position_std': Array(446.32138, dtype=float32), 'eval/episode_x_velocity_std': Array(181.84119, dtype=float32), 'eval/episode_y_position_std': Array(288.0176, dtype=float32), 'eval/episode_y_velocity_std': Array(65.033936, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3577117919922, 'eval/sps': 938.7074505566542, 'num_steps': 80035840}
{'eval/walltime': 133652.8989365101, 'training/sps': 2953.7863004273877, 'training/walltime': 27211.477563381195, 'training/entropy_loss': Array(0.02234332, dtype=float32), 'training/policy_loss': Array(0.01091157, dtype=float32), 'training/total_loss': Array(0.22288576, dtype=float32), 'training/v_loss': Array(0.18963087, dtype=float32), 'eval/episode_distance_from_origin': Array(7190.9326, dtype=float32), 'eval/episode_distance_reward': Array(34.72226, dtype=float32), 'eval/episode_forward_reward': Array(5787.012, dtype=float32), 'eval/episode_reward': Array(5733.993, dtype=float32), 'eval/episode_reward_alive': Array(342.78906, dtype=float32), 'eval/episode_reward_linvel': Array(5787.012, dtype=float32), 'eval/episode_reward_quadctrl': Array(-430.53033, dtype=float32), 'eval/episode_x_position': Array(7141.0454, dtype=float32), 'eval/episode_x_velocity': Array(1157.4025, dtype=float32), 'eval/episode_y_position': Array(-348.7719, dtype=float32), 'eval/episode_y_velocity': Array(-165.46255, dtype=float32), 'eval/episode_distance_from_origin_std': Array(526.9728, dtype=float32), 'eval/episode_distance_reward_std': Array(6.0060563, dtype=float32), 'eval/episode_forward_reward_std': Array(1001.00214, dtype=float32), 'eval/episode_reward_std': Array(1058.6279, dtype=float32), 'eval/episode_reward_alive_std': Array(58.08233, dtype=float32), 'eval/episode_reward_linvel_std': Array(1001.00214, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.698307, dtype=float32), 'eval/episode_x_position_std': Array(521.5785, dtype=float32), 'eval/episode_x_velocity_std': Array(200.20052, dtype=float32), 'eval/episode_y_position_std': Array(337.48184, dtype=float32), 'eval/episode_y_velocity_std': Array(97.29562, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44262862205505, 'eval/sps': 938.1232338652676, 'num_steps': 80117760}
{'eval/walltime': 133789.1032717228, 'training/sps': 2965.2521041842874, 'training/walltime': 27239.104219436646, 'training/entropy_loss': Array(0.02170394, dtype=float32), 'training/policy_loss': Array(0.00542297, dtype=float32), 'training/total_loss': Array(0.23375472, dtype=float32), 'training/v_loss': Array(0.20662782, dtype=float32), 'eval/episode_distance_from_origin': Array(7160.8027, dtype=float32), 'eval/episode_distance_reward': Array(34.833267, dtype=float32), 'eval/episode_forward_reward': Array(5805.5117, dtype=float32), 'eval/episode_reward': Array(5766.413, dtype=float32), 'eval/episode_reward_alive': Array(355.69922, dtype=float32), 'eval/episode_reward_linvel': Array(5805.5117, dtype=float32), 'eval/episode_reward_quadctrl': Array(-429.63077, dtype=float32), 'eval/episode_x_position': Array(7106.716, dtype=float32), 'eval/episode_x_velocity': Array(1161.102, dtype=float32), 'eval/episode_y_position': Array(-372.13837, dtype=float32), 'eval/episode_y_velocity': Array(-183.93253, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.87573, dtype=float32), 'eval/episode_distance_reward_std': Array(5.615348, dtype=float32), 'eval/episode_forward_reward_std': Array(935.8844, dtype=float32), 'eval/episode_reward_std': Array(962.5411, dtype=float32), 'eval/episode_reward_alive_std': Array(41.934536, dtype=float32), 'eval/episode_reward_linvel_std': Array(935.8844, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.964317, dtype=float32), 'eval/episode_x_position_std': Array(486.2727, dtype=float32), 'eval/episode_x_velocity_std': Array(187.17693, dtype=float32), 'eval/episode_y_position_std': Array(358.00397, dtype=float32), 'eval/episode_y_velocity_std': Array(95.67029, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20433521270752, 'eval/sps': 939.7645074960722, 'num_steps': 80199680}
{'eval/walltime': 133925.57134199142, 'training/sps': 2953.421706755861, 'training/walltime': 27266.84153842926, 'training/entropy_loss': Array(0.02278521, dtype=float32), 'training/policy_loss': Array(0.00706181, dtype=float32), 'training/total_loss': Array(0.24840136, dtype=float32), 'training/v_loss': Array(0.21855435, dtype=float32), 'eval/episode_distance_from_origin': Array(7187.044, dtype=float32), 'eval/episode_distance_reward': Array(35.546963, dtype=float32), 'eval/episode_forward_reward': Array(5924.461, dtype=float32), 'eval/episode_reward': Array(5890.2764, dtype=float32), 'eval/episode_reward_alive': Array(356.8789, dtype=float32), 'eval/episode_reward_linvel': Array(5924.461, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.60977, dtype=float32), 'eval/episode_x_position': Array(7139.732, dtype=float32), 'eval/episode_x_velocity': Array(1184.8921, dtype=float32), 'eval/episode_y_position': Array(-294.91577, dtype=float32), 'eval/episode_y_velocity': Array(-165.74327, dtype=float32), 'eval/episode_distance_from_origin_std': Array(487.03903, dtype=float32), 'eval/episode_distance_reward_std': Array(5.633374, dtype=float32), 'eval/episode_forward_reward_std': Array(938.8899, dtype=float32), 'eval/episode_reward_std': Array(970.4487, dtype=float32), 'eval/episode_reward_alive_std': Array(50.948418, dtype=float32), 'eval/episode_reward_linvel_std': Array(938.8899, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.593668, dtype=float32), 'eval/episode_x_position_std': Array(484.6587, dtype=float32), 'eval/episode_x_velocity_std': Array(187.77798, dtype=float32), 'eval/episode_y_position_std': Array(330.91037, dtype=float32), 'eval/episode_y_velocity_std': Array(98.379166, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46807026863098, 'eval/sps': 937.9483402090908, 'num_steps': 80281600}
{'eval/walltime': 134061.82075953484, 'training/sps': 2965.0710902780584, 'training/walltime': 27294.46988105774, 'training/entropy_loss': Array(0.0237151, dtype=float32), 'training/policy_loss': Array(0.00756258, dtype=float32), 'training/total_loss': Array(0.2164863, dtype=float32), 'training/v_loss': Array(0.18520865, dtype=float32), 'eval/episode_distance_from_origin': Array(7254.29, dtype=float32), 'eval/episode_distance_reward': Array(35.8041, dtype=float32), 'eval/episode_forward_reward': Array(5967.317, dtype=float32), 'eval/episode_reward': Array(5925.7275, dtype=float32), 'eval/episode_reward_alive': Array(353.97656, dtype=float32), 'eval/episode_reward_linvel': Array(5967.317, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.3704, dtype=float32), 'eval/episode_x_position': Array(7206.768, dtype=float32), 'eval/episode_x_velocity': Array(1193.4634, dtype=float32), 'eval/episode_y_position': Array(-278.40674, dtype=float32), 'eval/episode_y_velocity': Array(-162.72533, dtype=float32), 'eval/episode_distance_from_origin_std': Array(531.32263, dtype=float32), 'eval/episode_distance_reward_std': Array(6.5894465, dtype=float32), 'eval/episode_forward_reward_std': Array(1098.2347, dtype=float32), 'eval/episode_reward_std': Array(1150.7653, dtype=float32), 'eval/episode_reward_alive_std': Array(50.774467, dtype=float32), 'eval/episode_reward_linvel_std': Array(1098.2347, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.803226, dtype=float32), 'eval/episode_x_position_std': Array(527.85925, dtype=float32), 'eval/episode_x_velocity_std': Array(219.64697, dtype=float32), 'eval/episode_y_position_std': Array(333.19983, dtype=float32), 'eval/episode_y_velocity_std': Array(98.81596, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24941754341125, 'eval/sps': 939.4535573645087, 'num_steps': 80363520}
{'eval/walltime': 134198.31022810936, 'training/sps': 2952.7030911891547, 'training/walltime': 27322.213950634003, 'training/entropy_loss': Array(0.01638668, dtype=float32), 'training/policy_loss': Array(0.00777917, dtype=float32), 'training/total_loss': Array(0.10357994, dtype=float32), 'training/v_loss': Array(0.07941408, dtype=float32), 'eval/episode_distance_from_origin': Array(7179.3857, dtype=float32), 'eval/episode_distance_reward': Array(34.910156, dtype=float32), 'eval/episode_forward_reward': Array(5818.3276, dtype=float32), 'eval/episode_reward': Array(5768.877, dtype=float32), 'eval/episode_reward_alive': Array(349.3086, dtype=float32), 'eval/episode_reward_linvel': Array(5818.3276, dtype=float32), 'eval/episode_reward_quadctrl': Array(-433.66913, dtype=float32), 'eval/episode_x_position': Array(7130.924, dtype=float32), 'eval/episode_x_velocity': Array(1163.6656, dtype=float32), 'eval/episode_y_position': Array(-316.05954, dtype=float32), 'eval/episode_y_velocity': Array(-173.82657, dtype=float32), 'eval/episode_distance_from_origin_std': Array(485.86688, dtype=float32), 'eval/episode_distance_reward_std': Array(5.1929555, dtype=float32), 'eval/episode_forward_reward_std': Array(865.4871, dtype=float32), 'eval/episode_reward_std': Array(899.71265, dtype=float32), 'eval/episode_reward_alive_std': Array(52.637104, dtype=float32), 'eval/episode_reward_linvel_std': Array(865.4871, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.71777, dtype=float32), 'eval/episode_x_position_std': Array(480.67096, dtype=float32), 'eval/episode_x_velocity_std': Array(173.0974, dtype=float32), 'eval/episode_y_position_std': Array(316.2334, dtype=float32), 'eval/episode_y_velocity_std': Array(82.53384, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48946857452393, 'eval/sps': 937.8012921935539, 'num_steps': 80445440}
{'eval/walltime': 134334.55185580254, 'training/sps': 2962.044393780111, 'training/walltime': 27349.87052464485, 'training/entropy_loss': Array(0.01908524, dtype=float32), 'training/policy_loss': Array(0.01044391, dtype=float32), 'training/total_loss': Array(0.13937467, dtype=float32), 'training/v_loss': Array(0.10984552, dtype=float32), 'eval/episode_distance_from_origin': Array(7115.5703, dtype=float32), 'eval/episode_distance_reward': Array(34.814674, dtype=float32), 'eval/episode_forward_reward': Array(5802.413, dtype=float32), 'eval/episode_reward': Array(5769.083, dtype=float32), 'eval/episode_reward_alive': Array(355.76172, dtype=float32), 'eval/episode_reward_linvel': Array(5802.413, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.90567, dtype=float32), 'eval/episode_x_position': Array(7066.5356, dtype=float32), 'eval/episode_x_velocity': Array(1160.4825, dtype=float32), 'eval/episode_y_position': Array(-300.5728, dtype=float32), 'eval/episode_y_velocity': Array(-167.39658, dtype=float32), 'eval/episode_distance_from_origin_std': Array(489.65475, dtype=float32), 'eval/episode_distance_reward_std': Array(5.147752, dtype=float32), 'eval/episode_forward_reward_std': Array(857.95435, dtype=float32), 'eval/episode_reward_std': Array(872.56775, dtype=float32), 'eval/episode_reward_alive_std': Array(46.876667, dtype=float32), 'eval/episode_reward_linvel_std': Array(857.95435, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.603941, dtype=float32), 'eval/episode_x_position_std': Array(484.75204, dtype=float32), 'eval/episode_x_velocity_std': Array(171.59073, dtype=float32), 'eval/episode_y_position_std': Array(343.18524, dtype=float32), 'eval/episode_y_velocity_std': Array(98.91553, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.24162769317627, 'eval/sps': 939.5072722432759, 'num_steps': 80527360}
{'eval/walltime': 134471.01811027527, 'training/sps': 2952.3874464389146, 'training/walltime': 27377.617560386658, 'training/entropy_loss': Array(0.02240063, dtype=float32), 'training/policy_loss': Array(0.0097105, dtype=float32), 'training/total_loss': Array(0.21220982, dtype=float32), 'training/v_loss': Array(0.1800987, dtype=float32), 'eval/episode_distance_from_origin': Array(7127.1816, dtype=float32), 'eval/episode_distance_reward': Array(35.28755, dtype=float32), 'eval/episode_forward_reward': Array(5881.226, dtype=float32), 'eval/episode_reward': Array(5844.972, dtype=float32), 'eval/episode_reward_alive': Array(354.65625, dtype=float32), 'eval/episode_reward_linvel': Array(5881.226, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.198, dtype=float32), 'eval/episode_x_position': Array(7079.925, dtype=float32), 'eval/episode_x_velocity': Array(1176.2451, dtype=float32), 'eval/episode_y_position': Array(-292.766, dtype=float32), 'eval/episode_y_velocity': Array(-170.76318, dtype=float32), 'eval/episode_distance_from_origin_std': Array(492.90958, dtype=float32), 'eval/episode_distance_reward_std': Array(5.197132, dtype=float32), 'eval/episode_forward_reward_std': Array(866.18304, dtype=float32), 'eval/episode_reward_std': Array(888.5313, dtype=float32), 'eval/episode_reward_alive_std': Array(46.761143, dtype=float32), 'eval/episode_reward_linvel_std': Array(866.18304, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.25752, dtype=float32), 'eval/episode_x_position_std': Array(489.40848, dtype=float32), 'eval/episode_x_velocity_std': Array(173.23654, dtype=float32), 'eval/episode_y_position_std': Array(305.35367, dtype=float32), 'eval/episode_y_velocity_std': Array(96.62169, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.46625447273254, 'eval/sps': 937.9608203841764, 'num_steps': 80609280}
{'eval/walltime': 134607.40229463577, 'training/sps': 2966.92331681342, 'training/walltime': 27405.22865486145, 'training/entropy_loss': Array(0.02002215, dtype=float32), 'training/policy_loss': Array(0.00518278, dtype=float32), 'training/total_loss': Array(0.1994549, dtype=float32), 'training/v_loss': Array(0.17424998, dtype=float32), 'eval/episode_distance_from_origin': Array(7132.5454, dtype=float32), 'eval/episode_distance_reward': Array(36.044243, dtype=float32), 'eval/episode_forward_reward': Array(6007.341, dtype=float32), 'eval/episode_reward': Array(5971.663, dtype=float32), 'eval/episode_reward_alive': Array(355.4297, dtype=float32), 'eval/episode_reward_linvel': Array(6007.341, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.1507, dtype=float32), 'eval/episode_x_position': Array(7085.4385, dtype=float32), 'eval/episode_x_velocity': Array(1201.468, dtype=float32), 'eval/episode_y_position': Array(-261.76306, dtype=float32), 'eval/episode_y_velocity': Array(-170.84433, dtype=float32), 'eval/episode_distance_from_origin_std': Array(564.3957, dtype=float32), 'eval/episode_distance_reward_std': Array(5.502052, dtype=float32), 'eval/episode_forward_reward_std': Array(917.00385, dtype=float32), 'eval/episode_reward_std': Array(931.7761, dtype=float32), 'eval/episode_reward_alive_std': Array(42.00966, dtype=float32), 'eval/episode_reward_linvel_std': Array(917.00385, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.810596, dtype=float32), 'eval/episode_x_position_std': Array(561.2811, dtype=float32), 'eval/episode_x_velocity_std': Array(183.40076, dtype=float32), 'eval/episode_y_position_std': Array(318.11374, dtype=float32), 'eval/episode_y_velocity_std': Array(96.917946, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38418436050415, 'eval/sps': 938.525244698885, 'num_steps': 80691200}
{'eval/walltime': 134743.85527276993, 'training/sps': 2948.112993657279, 'training/walltime': 27433.015920877457, 'training/entropy_loss': Array(0.02091637, dtype=float32), 'training/policy_loss': Array(0.00412198, dtype=float32), 'training/total_loss': Array(0.28115398, dtype=float32), 'training/v_loss': Array(0.25611562, dtype=float32), 'eval/episode_distance_from_origin': Array(7100.9497, dtype=float32), 'eval/episode_distance_reward': Array(35.251728, dtype=float32), 'eval/episode_forward_reward': Array(5875.256, dtype=float32), 'eval/episode_reward': Array(5833.096, dtype=float32), 'eval/episode_reward_alive': Array(350.58984, dtype=float32), 'eval/episode_reward_linvel': Array(5875.256, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.00165, dtype=float32), 'eval/episode_x_position': Array(7054.8633, dtype=float32), 'eval/episode_x_velocity': Array(1175.0511, dtype=float32), 'eval/episode_y_position': Array(-215.31364, dtype=float32), 'eval/episode_y_velocity': Array(-155.55618, dtype=float32), 'eval/episode_distance_from_origin_std': Array(567.8108, dtype=float32), 'eval/episode_distance_reward_std': Array(6.2635, dtype=float32), 'eval/episode_forward_reward_std': Array(1043.9106, dtype=float32), 'eval/episode_reward_std': Array(1086.6571, dtype=float32), 'eval/episode_reward_alive_std': Array(54.08408, dtype=float32), 'eval/episode_reward_linvel_std': Array(1043.9106, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.322372, dtype=float32), 'eval/episode_x_position_std': Array(562.09326, dtype=float32), 'eval/episode_x_velocity_std': Array(208.7821, dtype=float32), 'eval/episode_y_position_std': Array(344.00333, dtype=float32), 'eval/episode_y_velocity_std': Array(105.244736, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45297813415527, 'eval/sps': 938.0520802862607, 'num_steps': 80773120}
{'eval/walltime': 134880.11506295204, 'training/sps': 2961.1826902041116, 'training/walltime': 27460.68054294586, 'training/entropy_loss': Array(0.02188425, dtype=float32), 'training/policy_loss': Array(0.00676551, dtype=float32), 'training/total_loss': Array(0.2426062, dtype=float32), 'training/v_loss': Array(0.21395642, dtype=float32), 'eval/episode_distance_from_origin': Array(7156.8525, dtype=float32), 'eval/episode_distance_reward': Array(35.4772, dtype=float32), 'eval/episode_forward_reward': Array(5912.834, dtype=float32), 'eval/episode_reward': Array(5872.3145, dtype=float32), 'eval/episode_reward_alive': Array(347.78906, dtype=float32), 'eval/episode_reward_linvel': Array(5912.834, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.78552, dtype=float32), 'eval/episode_x_position': Array(7108.4844, dtype=float32), 'eval/episode_x_velocity': Array(1182.5667, dtype=float32), 'eval/episode_y_position': Array(-255.30989, dtype=float32), 'eval/episode_y_velocity': Array(-159.08551, dtype=float32), 'eval/episode_distance_from_origin_std': Array(580.0238, dtype=float32), 'eval/episode_distance_reward_std': Array(6.196919, dtype=float32), 'eval/episode_forward_reward_std': Array(1032.8135, dtype=float32), 'eval/episode_reward_std': Array(1075.9054, dtype=float32), 'eval/episode_reward_alive_std': Array(57.939342, dtype=float32), 'eval/episode_reward_linvel_std': Array(1032.8135, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.461021, dtype=float32), 'eval/episode_x_position_std': Array(576.42883, dtype=float32), 'eval/episode_x_velocity_std': Array(206.56259, dtype=float32), 'eval/episode_y_position_std': Array(358.5171, dtype=float32), 'eval/episode_y_velocity_std': Array(104.57973, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25979018211365, 'eval/sps': 939.3820424127008, 'num_steps': 80855040}
{'eval/walltime': 135016.59310770035, 'training/sps': 2948.6322947291983, 'training/walltime': 27488.462915182114, 'training/entropy_loss': Array(0.0177666, dtype=float32), 'training/policy_loss': Array(0.00707983, dtype=float32), 'training/total_loss': Array(0.15611002, dtype=float32), 'training/v_loss': Array(0.13126358, dtype=float32), 'eval/episode_distance_from_origin': Array(7180.204, dtype=float32), 'eval/episode_distance_reward': Array(35.975914, dtype=float32), 'eval/episode_forward_reward': Array(5995.952, dtype=float32), 'eval/episode_reward': Array(5961.8877, dtype=float32), 'eval/episode_reward_alive': Array(352.3125, dtype=float32), 'eval/episode_reward_linvel': Array(5995.952, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.35388, dtype=float32), 'eval/episode_x_position': Array(7132.8574, dtype=float32), 'eval/episode_x_velocity': Array(1199.1906, dtype=float32), 'eval/episode_y_position': Array(-237.81354, dtype=float32), 'eval/episode_y_velocity': Array(-158.51006, dtype=float32), 'eval/episode_distance_from_origin_std': Array(532.46796, dtype=float32), 'eval/episode_distance_reward_std': Array(6.050234, dtype=float32), 'eval/episode_forward_reward_std': Array(1008.36633, dtype=float32), 'eval/episode_reward_std': Array(1047.3179, dtype=float32), 'eval/episode_reward_alive_std': Array(52.19835, dtype=float32), 'eval/episode_reward_linvel_std': Array(1008.36633, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(32.62895, dtype=float32), 'eval/episode_x_position_std': Array(534.21405, dtype=float32), 'eval/episode_x_velocity_std': Array(201.67322, dtype=float32), 'eval/episode_y_position_std': Array(356.8065, dtype=float32), 'eval/episode_y_velocity_std': Array(108.21044, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47804474830627, 'eval/sps': 937.8797903798993, 'num_steps': 80936960}
{'eval/walltime': 135152.81986165047, 'training/sps': 2958.8704717031746, 'training/walltime': 27516.14915585518, 'training/entropy_loss': Array(0.01727404, dtype=float32), 'training/policy_loss': Array(0.00964419, dtype=float32), 'training/total_loss': Array(0.1518896, dtype=float32), 'training/v_loss': Array(0.12497137, dtype=float32), 'eval/episode_distance_from_origin': Array(7170.9414, dtype=float32), 'eval/episode_distance_reward': Array(35.96444, dtype=float32), 'eval/episode_forward_reward': Array(5994.039, dtype=float32), 'eval/episode_reward': Array(5963.543, dtype=float32), 'eval/episode_reward_alive': Array(358.60156, dtype=float32), 'eval/episode_reward_linvel': Array(5994.039, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.06168, dtype=float32), 'eval/episode_x_position': Array(7124.382, dtype=float32), 'eval/episode_x_velocity': Array(1198.8077, dtype=float32), 'eval/episode_y_position': Array(-276.64404, dtype=float32), 'eval/episode_y_velocity': Array(-174.68375, dtype=float32), 'eval/episode_distance_from_origin_std': Array(471.62274, dtype=float32), 'eval/episode_distance_reward_std': Array(5.2760377, dtype=float32), 'eval/episode_forward_reward_std': Array(879.3351, dtype=float32), 'eval/episode_reward_std': Array(915.07526, dtype=float32), 'eval/episode_reward_alive_std': Array(47.544567, dtype=float32), 'eval/episode_reward_linvel_std': Array(879.3351, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.87497, dtype=float32), 'eval/episode_x_position_std': Array(467.01816, dtype=float32), 'eval/episode_x_velocity_std': Array(175.86696, dtype=float32), 'eval/episode_y_position_std': Array(287.43597, dtype=float32), 'eval/episode_y_velocity_std': Array(93.983284, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.22675395011902, 'eval/sps': 939.6098511373813, 'num_steps': 81018880}
{'eval/walltime': 135289.26863479614, 'training/sps': 2936.857992740401, 'training/walltime': 27544.04291176796, 'training/entropy_loss': Array(0.02157782, dtype=float32), 'training/policy_loss': Array(0.00793222, dtype=float32), 'training/total_loss': Array(0.22097033, dtype=float32), 'training/v_loss': Array(0.19146028, dtype=float32), 'eval/episode_distance_from_origin': Array(7198.069, dtype=float32), 'eval/episode_distance_reward': Array(36.484337, dtype=float32), 'eval/episode_forward_reward': Array(6080.6885, dtype=float32), 'eval/episode_reward': Array(6055.9873, dtype=float32), 'eval/episode_reward_alive': Array(360.1797, dtype=float32), 'eval/episode_reward_linvel': Array(6080.6885, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.36453, dtype=float32), 'eval/episode_x_position': Array(7151.4946, dtype=float32), 'eval/episode_x_velocity': Array(1216.1377, dtype=float32), 'eval/episode_y_position': Array(-243.37512, dtype=float32), 'eval/episode_y_velocity': Array(-170.5078, dtype=float32), 'eval/episode_distance_from_origin_std': Array(554.2871, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1935983, dtype=float32), 'eval/episode_forward_reward_std': Array(1032.2603, dtype=float32), 'eval/episode_reward_std': Array(1058.4111, dtype=float32), 'eval/episode_reward_alive_std': Array(49.2739, dtype=float32), 'eval/episode_reward_linvel_std': Array(1032.2603, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.58506, dtype=float32), 'eval/episode_x_position_std': Array(552.4654, dtype=float32), 'eval/episode_x_velocity_std': Array(206.45209, dtype=float32), 'eval/episode_y_position_std': Array(332.9593, dtype=float32), 'eval/episode_y_velocity_std': Array(95.1022, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44877314567566, 'eval/sps': 938.0809885578409, 'num_steps': 81100800}
{'eval/walltime': 135425.53208756447, 'training/sps': 2957.696226325327, 'training/walltime': 27571.740144252777, 'training/entropy_loss': Array(0.02014159, dtype=float32), 'training/policy_loss': Array(0.0060724, dtype=float32), 'training/total_loss': Array(0.21756482, dtype=float32), 'training/v_loss': Array(0.19135082, dtype=float32), 'eval/episode_distance_from_origin': Array(7223.077, dtype=float32), 'eval/episode_distance_reward': Array(36.647133, dtype=float32), 'eval/episode_forward_reward': Array(6107.8203, dtype=float32), 'eval/episode_reward': Array(6080.2856, dtype=float32), 'eval/episode_reward_alive': Array(359.14844, dtype=float32), 'eval/episode_reward_linvel': Array(6107.8203, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.33084, dtype=float32), 'eval/episode_x_position': Array(7175.5234, dtype=float32), 'eval/episode_x_velocity': Array(1221.5642, dtype=float32), 'eval/episode_y_position': Array(-269.964, dtype=float32), 'eval/episode_y_velocity': Array(-172.47232, dtype=float32), 'eval/episode_distance_from_origin_std': Array(511.57755, dtype=float32), 'eval/episode_distance_reward_std': Array(6.14224, dtype=float32), 'eval/episode_forward_reward_std': Array(1023.70056, dtype=float32), 'eval/episode_reward_std': Array(1064.6353, dtype=float32), 'eval/episode_reward_alive_std': Array(48.430496, dtype=float32), 'eval/episode_reward_linvel_std': Array(1023.70056, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(29.714167, dtype=float32), 'eval/episode_x_position_std': Array(510.09003, dtype=float32), 'eval/episode_x_velocity_std': Array(204.74007, dtype=float32), 'eval/episode_y_position_std': Array(309.07428, dtype=float32), 'eval/episode_y_velocity_std': Array(95.123184, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2634527683258, 'eval/sps': 939.3567930325729, 'num_steps': 81182720}
{'eval/walltime': 135562.01973319054, 'training/sps': 2940.258210547452, 'training/walltime': 27599.60164284706, 'training/entropy_loss': Array(0.02055455, dtype=float32), 'training/policy_loss': Array(0.00705607, dtype=float32), 'training/total_loss': Array(0.26220804, dtype=float32), 'training/v_loss': Array(0.23459743, dtype=float32), 'eval/episode_distance_from_origin': Array(7140.008, dtype=float32), 'eval/episode_distance_reward': Array(35.537315, dtype=float32), 'eval/episode_forward_reward': Array(5922.8535, dtype=float32), 'eval/episode_reward': Array(5891.487, dtype=float32), 'eval/episode_reward_alive': Array(359.8828, dtype=float32), 'eval/episode_reward_linvel': Array(5922.8535, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.78644, dtype=float32), 'eval/episode_x_position': Array(7091.6924, dtype=float32), 'eval/episode_x_velocity': Array(1184.5706, dtype=float32), 'eval/episode_y_position': Array(-257.04343, dtype=float32), 'eval/episode_y_velocity': Array(-159.70844, dtype=float32), 'eval/episode_distance_from_origin_std': Array(538.64386, dtype=float32), 'eval/episode_distance_reward_std': Array(5.5353403, dtype=float32), 'eval/episode_forward_reward_std': Array(922.5516, dtype=float32), 'eval/episode_reward_std': Array(947.1357, dtype=float32), 'eval/episode_reward_alive_std': Array(45.06664, dtype=float32), 'eval/episode_reward_linvel_std': Array(922.5516, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.262321, dtype=float32), 'eval/episode_x_position_std': Array(534.89484, dtype=float32), 'eval/episode_x_velocity_std': Array(184.51018, dtype=float32), 'eval/episode_y_position_std': Array(351.92557, dtype=float32), 'eval/episode_y_velocity_std': Array(105.86689, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48764562606812, 'eval/sps': 937.813817601327, 'num_steps': 81264640}
{'eval/walltime': 135698.25577902794, 'training/sps': 2946.035874313196, 'training/walltime': 27627.408500432968, 'training/entropy_loss': Array(0.02118812, dtype=float32), 'training/policy_loss': Array(0.01271333, dtype=float32), 'training/total_loss': Array(0.28627604, dtype=float32), 'training/v_loss': Array(0.2523746, dtype=float32), 'eval/episode_distance_from_origin': Array(7096.627, dtype=float32), 'eval/episode_distance_reward': Array(34.75559, dtype=float32), 'eval/episode_forward_reward': Array(5792.5664, dtype=float32), 'eval/episode_reward': Array(5754.539, dtype=float32), 'eval/episode_reward_alive': Array(353.2422, dtype=float32), 'eval/episode_reward_linvel': Array(5792.5664, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.02515, dtype=float32), 'eval/episode_x_position': Array(7045.5635, dtype=float32), 'eval/episode_x_velocity': Array(1158.5132, dtype=float32), 'eval/episode_y_position': Array(-389.27856, dtype=float32), 'eval/episode_y_velocity': Array(-192.8676, dtype=float32), 'eval/episode_distance_from_origin_std': Array(452.1404, dtype=float32), 'eval/episode_distance_reward_std': Array(5.367145, dtype=float32), 'eval/episode_forward_reward_std': Array(894.5186, dtype=float32), 'eval/episode_reward_std': Array(934.17334, dtype=float32), 'eval/episode_reward_alive_std': Array(49.408176, dtype=float32), 'eval/episode_reward_linvel_std': Array(894.5186, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(28.915485, dtype=float32), 'eval/episode_x_position_std': Array(446.79346, dtype=float32), 'eval/episode_x_velocity_std': Array(178.90372, dtype=float32), 'eval/episode_y_position_std': Array(276.39694, dtype=float32), 'eval/episode_y_velocity_std': Array(81.49355, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23604583740234, 'eval/sps': 939.5457656835397, 'num_steps': 81346560}
{'eval/walltime': 135834.70250988007, 'training/sps': 2942.237165216823, 'training/walltime': 27655.251259326935, 'training/entropy_loss': Array(0.01917923, dtype=float32), 'training/policy_loss': Array(0.00599428, dtype=float32), 'training/total_loss': Array(0.19204652, dtype=float32), 'training/v_loss': Array(0.16687302, dtype=float32), 'eval/episode_distance_from_origin': Array(7129.767, dtype=float32), 'eval/episode_distance_reward': Array(34.76642, dtype=float32), 'eval/episode_forward_reward': Array(5794.371, dtype=float32), 'eval/episode_reward': Array(5747.419, dtype=float32), 'eval/episode_reward_alive': Array(344.98438, dtype=float32), 'eval/episode_reward_linvel': Array(5794.371, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.7026, dtype=float32), 'eval/episode_x_position': Array(7079.454, dtype=float32), 'eval/episode_x_velocity': Array(1158.8741, dtype=float32), 'eval/episode_y_position': Array(-359.64514, dtype=float32), 'eval/episode_y_velocity': Array(-178.62244, dtype=float32), 'eval/episode_distance_from_origin_std': Array(555.97144, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1870594, dtype=float32), 'eval/episode_forward_reward_std': Array(1031.171, dtype=float32), 'eval/episode_reward_std': Array(1073.9866, dtype=float32), 'eval/episode_reward_alive_std': Array(52.517326, dtype=float32), 'eval/episode_reward_linvel_std': Array(1031.171, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.321007, dtype=float32), 'eval/episode_x_position_std': Array(551.0495, dtype=float32), 'eval/episode_x_velocity_std': Array(206.23418, dtype=float32), 'eval/episode_y_position_std': Array(311.05673, dtype=float32), 'eval/episode_y_velocity_std': Array(79.18256, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44673085212708, 'eval/sps': 938.0950294713829, 'num_steps': 81428480}
{'eval/walltime': 135970.8862607479, 'training/sps': 2957.7608705124953, 'training/walltime': 27682.94788646698, 'training/entropy_loss': Array(0.01605557, dtype=float32), 'training/policy_loss': Array(0.01074351, dtype=float32), 'training/total_loss': Array(0.12906457, dtype=float32), 'training/v_loss': Array(0.10226549, dtype=float32), 'eval/episode_distance_from_origin': Array(7174.7197, dtype=float32), 'eval/episode_distance_reward': Array(35.353493, dtype=float32), 'eval/episode_forward_reward': Array(5892.217, dtype=float32), 'eval/episode_reward': Array(5850.186, dtype=float32), 'eval/episode_reward_alive': Array(351.26953, dtype=float32), 'eval/episode_reward_linvel': Array(5892.217, dtype=float32), 'eval/episode_reward_quadctrl': Array(-428.65442, dtype=float32), 'eval/episode_x_position': Array(7122.3647, dtype=float32), 'eval/episode_x_velocity': Array(1178.4435, dtype=float32), 'eval/episode_y_position': Array(-386.77484, dtype=float32), 'eval/episode_y_velocity': Array(-190.56537, dtype=float32), 'eval/episode_distance_from_origin_std': Array(490.6488, dtype=float32), 'eval/episode_distance_reward_std': Array(5.648449, dtype=float32), 'eval/episode_forward_reward_std': Array(941.40173, dtype=float32), 'eval/episode_reward_std': Array(982.0286, dtype=float32), 'eval/episode_reward_alive_std': Array(50.52691, dtype=float32), 'eval/episode_reward_linvel_std': Array(941.40173, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.696568, dtype=float32), 'eval/episode_x_position_std': Array(485.41934, dtype=float32), 'eval/episode_x_velocity_std': Array(188.28044, dtype=float32), 'eval/episode_y_position_std': Array(300.9934, dtype=float32), 'eval/episode_y_velocity_std': Array(86.22678, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.18375086784363, 'eval/sps': 939.9065540808509, 'num_steps': 81510400}
{'eval/walltime': 136107.33276224136, 'training/sps': 2945.5869031007946, 'training/walltime': 27710.758982419968, 'training/entropy_loss': Array(0.02248328, dtype=float32), 'training/policy_loss': Array(0.00896919, dtype=float32), 'training/total_loss': Array(0.20748758, dtype=float32), 'training/v_loss': Array(0.17603512, dtype=float32), 'eval/episode_distance_from_origin': Array(7137.1914, dtype=float32), 'eval/episode_distance_reward': Array(35.0156, dtype=float32), 'eval/episode_forward_reward': Array(5835.9023, dtype=float32), 'eval/episode_reward': Array(5801.686, dtype=float32), 'eval/episode_reward_alive': Array(356.78906, dtype=float32), 'eval/episode_reward_linvel': Array(5835.9023, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.0204, dtype=float32), 'eval/episode_x_position': Array(7090.603, dtype=float32), 'eval/episode_x_velocity': Array(1167.1804, dtype=float32), 'eval/episode_y_position': Array(-311.88397, dtype=float32), 'eval/episode_y_velocity': Array(-166.16324, dtype=float32), 'eval/episode_distance_from_origin_std': Array(514.7529, dtype=float32), 'eval/episode_distance_reward_std': Array(6.1599407, dtype=float32), 'eval/episode_forward_reward_std': Array(1026.6501, dtype=float32), 'eval/episode_reward_std': Array(1065.0446, dtype=float32), 'eval/episode_reward_alive_std': Array(52.81071, dtype=float32), 'eval/episode_reward_linvel_std': Array(1026.6501, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.72012, dtype=float32), 'eval/episode_x_position_std': Array(509.46494, dtype=float32), 'eval/episode_x_velocity_std': Array(205.33002, dtype=float32), 'eval/episode_y_position_std': Array(297.02393, dtype=float32), 'eval/episode_y_velocity_std': Array(98.11458, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44650149345398, 'eval/sps': 938.0966063548416, 'num_steps': 81592320}
{'eval/walltime': 136243.60011267662, 'training/sps': 2955.982849284445, 'training/walltime': 27738.472269058228, 'training/entropy_loss': Array(0.02015394, dtype=float32), 'training/policy_loss': Array(0.00611811, dtype=float32), 'training/total_loss': Array(0.2008419, dtype=float32), 'training/v_loss': Array(0.17456985, dtype=float32), 'eval/episode_distance_from_origin': Array(7163.4233, dtype=float32), 'eval/episode_distance_reward': Array(35.173546, dtype=float32), 'eval/episode_forward_reward': Array(5862.2256, dtype=float32), 'eval/episode_reward': Array(5829.0615, dtype=float32), 'eval/episode_reward_alive': Array(352.80078, dtype=float32), 'eval/episode_reward_linvel': Array(5862.2256, dtype=float32), 'eval/episode_reward_quadctrl': Array(-421.1388, dtype=float32), 'eval/episode_x_position': Array(7116.2075, dtype=float32), 'eval/episode_x_velocity': Array(1172.4453, dtype=float32), 'eval/episode_y_position': Array(-315.5268, dtype=float32), 'eval/episode_y_velocity': Array(-167.49158, dtype=float32), 'eval/episode_distance_from_origin_std': Array(506.27896, dtype=float32), 'eval/episode_distance_reward_std': Array(5.7594104, dtype=float32), 'eval/episode_forward_reward_std': Array(959.89496, dtype=float32), 'eval/episode_reward_std': Array(982.40393, dtype=float32), 'eval/episode_reward_alive_std': Array(46.184048, dtype=float32), 'eval/episode_reward_linvel_std': Array(959.89496, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(35.858944, dtype=float32), 'eval/episode_x_position_std': Array(502.8829, dtype=float32), 'eval/episode_x_velocity_std': Array(191.97905, dtype=float32), 'eval/episode_y_position_std': Array(310.531, dtype=float32), 'eval/episode_y_velocity_std': Array(85.70161, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26735043525696, 'eval/sps': 939.3299245281435, 'num_steps': 81674240}
{'eval/walltime': 136380.10276031494, 'training/sps': 2942.4333677636055, 'training/walltime': 27766.31317138672, 'training/entropy_loss': Array(0.02098149, dtype=float32), 'training/policy_loss': Array(0.00684743, dtype=float32), 'training/total_loss': Array(0.22177184, dtype=float32), 'training/v_loss': Array(0.1939429, dtype=float32), 'eval/episode_distance_from_origin': Array(7113.041, dtype=float32), 'eval/episode_distance_reward': Array(34.148575, dtype=float32), 'eval/episode_forward_reward': Array(5691.398, dtype=float32), 'eval/episode_reward': Array(5641.661, dtype=float32), 'eval/episode_reward_alive': Array(348.6875, dtype=float32), 'eval/episode_reward_linvel': Array(5691.398, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.572, dtype=float32), 'eval/episode_x_position': Array(7065.16, dtype=float32), 'eval/episode_x_velocity': Array(1138.2795, dtype=float32), 'eval/episode_y_position': Array(-350.74695, dtype=float32), 'eval/episode_y_velocity': Array(-175.43611, dtype=float32), 'eval/episode_distance_from_origin_std': Array(482.53043, dtype=float32), 'eval/episode_distance_reward_std': Array(5.609661, dtype=float32), 'eval/episode_forward_reward_std': Array(934.93665, dtype=float32), 'eval/episode_reward_std': Array(984.80786, dtype=float32), 'eval/episode_reward_alive_std': Array(54.27174, dtype=float32), 'eval/episode_reward_linvel_std': Array(934.93665, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.549618, dtype=float32), 'eval/episode_x_position_std': Array(476.6672, dtype=float32), 'eval/episode_x_velocity_std': Array(186.98738, dtype=float32), 'eval/episode_y_position_std': Array(276.06296, dtype=float32), 'eval/episode_y_velocity_std': Array(77.902954, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50264763832092, 'eval/sps': 937.7107493119867, 'num_steps': 81756160}
{'eval/walltime': 136516.16302156448, 'training/sps': 2952.820526940851, 'training/walltime': 27794.056137561798, 'training/entropy_loss': Array(0.02232839, dtype=float32), 'training/policy_loss': Array(0.00536202, dtype=float32), 'training/total_loss': Array(0.2644828, dtype=float32), 'training/v_loss': Array(0.2367924, dtype=float32), 'eval/episode_distance_from_origin': Array(7068.172, dtype=float32), 'eval/episode_distance_reward': Array(34.768204, dtype=float32), 'eval/episode_forward_reward': Array(5794.669, dtype=float32), 'eval/episode_reward': Array(5757.6387, dtype=float32), 'eval/episode_reward_alive': Array(354.51172, dtype=float32), 'eval/episode_reward_linvel': Array(5794.669, dtype=float32), 'eval/episode_reward_quadctrl': Array(-426.30878, dtype=float32), 'eval/episode_x_position': Array(7021.3877, dtype=float32), 'eval/episode_x_velocity': Array(1158.9336, dtype=float32), 'eval/episode_y_position': Array(-285.12668, dtype=float32), 'eval/episode_y_velocity': Array(-163.21088, dtype=float32), 'eval/episode_distance_from_origin_std': Array(535.2885, dtype=float32), 'eval/episode_distance_reward_std': Array(5.93814, dtype=float32), 'eval/episode_forward_reward_std': Array(989.6839, dtype=float32), 'eval/episode_reward_std': Array(1029.5636, dtype=float32), 'eval/episode_reward_alive_std': Array(49.067375, dtype=float32), 'eval/episode_reward_linvel_std': Array(989.6839, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.749733, dtype=float32), 'eval/episode_x_position_std': Array(528.73517, dtype=float32), 'eval/episode_x_velocity_std': Array(197.9369, dtype=float32), 'eval/episode_y_position_std': Array(304.68744, dtype=float32), 'eval/episode_y_velocity_std': Array(94.0926, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.06026124954224, 'eval/sps': 940.7596224237784, 'num_steps': 81838080}