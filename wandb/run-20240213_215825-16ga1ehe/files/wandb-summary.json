{"eval/walltime": 61188.70417261124, "eval/episode_distance_from_origin": 6378.15625, "eval/episode_distance_reward": 28.067516326904297, "eval/episode_forward_reward": 4677.892578125, "eval/episode_reward": 4681.0185546875, "eval/episode_reward_alive": 379.984375, "eval/episode_reward_linvel": 4677.892578125, "eval/episode_reward_quadctrl": -404.92498779296875, "eval/episode_x_position": 6322.32080078125, "eval/episode_x_velocity": 935.5784301757812, "eval/episode_y_position": -265.7785949707031, "eval/episode_y_velocity": -192.11660766601562, "eval/episode_distance_from_origin_std": 457.7985534667969, "eval/episode_distance_reward_std": 5.242646217346191, "eval/episode_forward_reward_std": 873.7675170898438, "eval/episode_reward_std": 877.8480834960938, "eval/episode_reward_alive_std": 50.92629623413086, "eval/episode_reward_linvel_std": 873.7675170898438, "eval/episode_reward_quadctrl_std": 31.222501754760742, "eval/episode_x_position_std": 456.25201416015625, "eval/episode_x_velocity_std": 174.75357055664062, "eval/episode_y_position_std": 302.3756103515625, "eval/episode_y_velocity_std": 91.31578826904297, "eval/avg_episode_length": 1000.0, "eval/epoch_eval_time": 136.5252070426941, "eval/sps": 937.5558021308981, "num_steps": 36618240, "_timestamp": 1707935177.678472, "_runtime": 73672.51153206825, "_step": 447, "training/sps": 2946.598866476977, "training/walltime": 12452.30843281746, "training/entropy_loss": 0.014140999875962734, "training/policy_loss": 0.006259426474571228, "training/total_loss": 0.1198490634560585, "training/v_loss": 0.09944863617420197}