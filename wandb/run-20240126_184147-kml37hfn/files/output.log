
{'eval/walltime': 40.66858196258545, 'eval/episode_distance_from_origin': Array(14.328537, dtype=float32), 'eval/episode_forward_reward': Array(-0.89434296, dtype=float32), 'eval/episode_reward': Array(66.12729, dtype=float32), 'eval/episode_reward_alive': Array(86.640625, dtype=float32), 'eval/episode_reward_linvel': Array(-0.89434296, dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.618992, dtype=float32), 'eval/episode_x_position': Array(0.21098383, dtype=float32), 'eval/episode_x_velocity': Array(-0.35773724, dtype=float32), 'eval/episode_y_position': Array(-0.05601216, dtype=float32), 'eval/episode_y_velocity': Array(-0.28648117, dtype=float32), 'eval/episode_distance_from_origin_std': Array(2.9885452, dtype=float32), 'eval/episode_forward_reward_std': Array(7.695574, dtype=float32), 'eval/episode_reward_std': Array(16.959248, dtype=float32), 'eval/episode_reward_alive_std': Array(16.690067, dtype=float32), 'eval/episode_reward_linvel_std': Array(7.695574, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.058913, dtype=float32), 'eval/episode_x_position_std': Array(0.6686824, dtype=float32), 'eval/episode_x_velocity_std': Array(3.0782294, dtype=float32), 'eval/episode_y_position_std': Array(0.54379195, dtype=float32), 'eval/episode_y_velocity_std': Array(3.29707, dtype=float32), 'eval/avg_episode_length': Array(17.328125, dtype=float32), 'eval/epoch_eval_time': 40.66858196258545, 'eval/sps': 1573.6963747317068, 'num_steps': 0}
{'eval/walltime': 46.49107050895691, 'training/sps': 44.44982356835477, 'training/walltime': 28.796514749526978, 'training/entropy_loss': Array(-0.01339989, dtype=float32), 'training/policy_loss': Array(0.25460866, dtype=float32), 'training/total_loss': Array(10.276596, dtype=float32), 'training/v_loss': Array(10.035387, dtype=float32), 'eval/episode_distance_from_origin': Array(13.1584835, dtype=float32), 'eval/episode_forward_reward': Array(3.5259905, dtype=float32), 'eval/episode_reward': Array(76.352295, dtype=float32), 'eval/episode_reward_alive': Array(82.03125, dtype=float32), 'eval/episode_reward_linvel': Array(3.5259905, dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.204945, dtype=float32), 'eval/episode_x_position': Array(0.4747681, dtype=float32), 'eval/episode_x_velocity': Array(1.4103961, dtype=float32), 'eval/episode_y_position': Array(0.10053211, dtype=float32), 'eval/episode_y_velocity': Array(0.6150347, dtype=float32), 'eval/episode_distance_from_origin_std': Array(3.3872702, dtype=float32), 'eval/episode_forward_reward_std': Array(3.7045226, dtype=float32), 'eval/episode_reward_std': Array(18.44238, dtype=float32), 'eval/episode_reward_alive_std': Array(20.391075, dtype=float32), 'eval/episode_reward_linvel_std': Array(3.7045226, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.3178773, dtype=float32), 'eval/episode_x_position_std': Array(0.2735399, dtype=float32), 'eval/episode_x_velocity_std': Array(1.4818089, dtype=float32), 'eval/episode_y_position_std': Array(0.36432326, dtype=float32), 'eval/episode_y_velocity_std': Array(1.9688417, dtype=float32), 'eval/avg_episode_length': Array(16.40625, dtype=float32), 'eval/epoch_eval_time': 5.82248854637146, 'eval/sps': 10991.86361472268, 'num_steps': 1280}
{'eval/walltime': 52.300532579422, 'training/sps': 704.423916914149, 'training/walltime': 30.61360239982605, 'training/entropy_loss': Array(-0.01338359, dtype=float32), 'training/policy_loss': Array(-0.10031797, dtype=float32), 'training/total_loss': Array(5.8804426, dtype=float32), 'training/v_loss': Array(5.9941444, dtype=float32), 'eval/episode_distance_from_origin': Array(15.630066, dtype=float32), 'eval/episode_forward_reward': Array(3.9488726, dtype=float32), 'eval/episode_reward': Array(90.33247, dtype=float32), 'eval/episode_reward_alive': Array(97.5, dtype=float32), 'eval/episode_reward_linvel': Array(3.9488726, dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.116398, dtype=float32), 'eval/episode_x_position': Array(0.6051891, dtype=float32), 'eval/episode_x_velocity': Array(1.5795491, dtype=float32), 'eval/episode_y_position': Array(0.05493193, dtype=float32), 'eval/episode_y_velocity': Array(0.38355643, dtype=float32), 'eval/episode_distance_from_origin_std': Array(4.0993977, dtype=float32), 'eval/episode_forward_reward_std': Array(5.9702888, dtype=float32), 'eval/episode_reward_std': Array(23.31391, dtype=float32), 'eval/episode_reward_alive_std': Array(25., dtype=float32), 'eval/episode_reward_linvel_std': Array(5.9702888, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.9547758, dtype=float32), 'eval/episode_x_position_std': Array(0.5217583, dtype=float32), 'eval/episode_x_velocity_std': Array(2.3881156, dtype=float32), 'eval/episode_y_position_std': Array(0.58149683, dtype=float32), 'eval/episode_y_velocity_std': Array(2.7359035, dtype=float32), 'eval/avg_episode_length': Array(19.5, dtype=float32), 'eval/epoch_eval_time': 5.809462070465088, 'eval/sps': 11016.510517449055, 'num_steps': 2560}
{'eval/walltime': 58.08664584159851, 'training/sps': 705.3059405637524, 'training/walltime': 32.428417682647705, 'training/entropy_loss': Array(-0.01323088, dtype=float32), 'training/policy_loss': Array(-0.0708212, dtype=float32), 'training/total_loss': Array(7.2250295, dtype=float32), 'training/v_loss': Array(7.3090816, dtype=float32), 'eval/episode_distance_from_origin': Array(16.356043, dtype=float32), 'eval/episode_forward_reward': Array(5.2390194, dtype=float32), 'eval/episode_reward': Array(95.705215, dtype=float32), 'eval/episode_reward_alive': Array(102.03125, dtype=float32), 'eval/episode_reward_linvel': Array(5.2390194, dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.565054, dtype=float32), 'eval/episode_x_position': Array(0.7479804, dtype=float32), 'eval/episode_x_velocity': Array(2.0956078, dtype=float32), 'eval/episode_y_position': Array(0.26716298, dtype=float32), 'eval/episode_y_velocity': Array(1.1741166, dtype=float32), 'eval/episode_distance_from_origin_std': Array(5.381278, dtype=float32), 'eval/episode_forward_reward_std': Array(6.1073327, dtype=float32), 'eval/episode_reward_std': Array(30.259295, dtype=float32), 'eval/episode_reward_alive_std': Array(32.7898, dtype=float32), 'eval/episode_reward_linvel_std': Array(6.1073327, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.774472, dtype=float32), 'eval/episode_x_position_std': Array(0.58772033, dtype=float32), 'eval/episode_x_velocity_std': Array(2.442933, dtype=float32), 'eval/episode_y_position_std': Array(0.9681904, dtype=float32), 'eval/episode_y_velocity_std': Array(3.494365, dtype=float32), 'eval/avg_episode_length': Array(20.40625, dtype=float32), 'eval/epoch_eval_time': 5.786113262176514, 'eval/sps': 11060.965643096599, 'num_steps': 3840}
{'eval/walltime': 63.88897728919983, 'training/sps': 701.6224601400263, 'training/walltime': 34.25276064872742, 'training/entropy_loss': Array(-0.01314647, dtype=float32), 'training/policy_loss': Array(-0.07170565, dtype=float32), 'training/total_loss': Array(9.172178, dtype=float32), 'training/v_loss': Array(9.2570305, dtype=float32), 'eval/episode_distance_from_origin': Array(19.049416, dtype=float32), 'eval/episode_forward_reward': Array(6.9669914, dtype=float32), 'eval/episode_reward': Array(111.919235, dtype=float32), 'eval/episode_reward_alive': Array(118.24219, dtype=float32), 'eval/episode_reward_linvel': Array(6.9669914, dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.289946, dtype=float32), 'eval/episode_x_position': Array(1.0338058, dtype=float32), 'eval/episode_x_velocity': Array(2.7867966, dtype=float32), 'eval/episode_y_position': Array(0.24989288, dtype=float32), 'eval/episode_y_velocity': Array(1.2246655, dtype=float32), 'eval/episode_distance_from_origin_std': Array(5.591723, dtype=float32), 'eval/episode_forward_reward_std': Array(7.174996, dtype=float32), 'eval/episode_reward_std': Array(32.897175, dtype=float32), 'eval/episode_reward_alive_std': Array(33.392727, dtype=float32), 'eval/episode_reward_linvel_std': Array(7.174996, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.7847316, dtype=float32), 'eval/episode_x_position_std': Array(0.8555537, dtype=float32), 'eval/episode_x_velocity_std': Array(2.8699985, dtype=float32), 'eval/episode_y_position_std': Array(1.1621258, dtype=float32), 'eval/episode_y_velocity_std': Array(4.848507, dtype=float32), 'eval/avg_episode_length': Array(23.648438, dtype=float32), 'eval/epoch_eval_time': 5.802331447601318, 'eval/sps': 11030.048968756788, 'num_steps': 5120}
{'eval/walltime': 69.70474982261658, 'training/sps': 704.2308900614901, 'training/walltime': 36.07034635543823, 'training/entropy_loss': Array(-0.01302426, dtype=float32), 'training/policy_loss': Array(-0.06404327, dtype=float32), 'training/total_loss': Array(9.641134, dtype=float32), 'training/v_loss': Array(9.718201, dtype=float32), 'eval/episode_distance_from_origin': Array(21.31837, dtype=float32), 'eval/episode_forward_reward': Array(7.526716, dtype=float32), 'eval/episode_reward': Array(125.00663, dtype=float32), 'eval/episode_reward_alive': Array(132.57812, dtype=float32), 'eval/episode_reward_linvel': Array(7.526716, dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.098204, dtype=float32), 'eval/episode_x_position': Array(1.2173297, dtype=float32), 'eval/episode_x_velocity': Array(3.0106864, dtype=float32), 'eval/episode_y_position': Array(0.16317785, dtype=float32), 'eval/episode_y_velocity': Array(0.9443228, dtype=float32), 'eval/episode_distance_from_origin_std': Array(6.878702, dtype=float32), 'eval/episode_forward_reward_std': Array(11.948896, dtype=float32), 'eval/episode_reward_std': Array(42.00551, dtype=float32), 'eval/episode_reward_alive_std': Array(41.09813, dtype=float32), 'eval/episode_reward_linvel_std': Array(11.948896, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.741978, dtype=float32), 'eval/episode_x_position_std': Array(1.5449754, dtype=float32), 'eval/episode_x_velocity_std': Array(4.7795587, dtype=float32), 'eval/episode_y_position_std': Array(1.7027954, dtype=float32), 'eval/episode_y_velocity_std': Array(5.6634116, dtype=float32), 'eval/avg_episode_length': Array(26.515625, dtype=float32), 'eval/epoch_eval_time': 5.815772533416748, 'eval/sps': 11004.556941019184, 'num_steps': 6400}
{'eval/walltime': 75.52252650260925, 'training/sps': 702.9594139077495, 'training/walltime': 37.89121961593628, 'training/entropy_loss': Array(-0.01289656, dtype=float32), 'training/policy_loss': Array(-0.07512006, dtype=float32), 'training/total_loss': Array(8.830888, dtype=float32), 'training/v_loss': Array(8.918905, dtype=float32), 'eval/episode_distance_from_origin': Array(23.461048, dtype=float32), 'eval/episode_forward_reward': Array(11.3805065, dtype=float32), 'eval/episode_reward': Array(140.34332, dtype=float32), 'eval/episode_reward_alive': Array(145.54688, dtype=float32), 'eval/episode_reward_linvel': Array(11.3805065, dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.584053, dtype=float32), 'eval/episode_x_position': Array(1.773282, dtype=float32), 'eval/episode_x_velocity': Array(4.5522027, dtype=float32), 'eval/episode_y_position': Array(0.03863447, dtype=float32), 'eval/episode_y_velocity': Array(0.62753016, dtype=float32), 'eval/episode_distance_from_origin_std': Array(6.8729587, dtype=float32), 'eval/episode_forward_reward_std': Array(11.600475, dtype=float32), 'eval/episode_reward_std': Array(40.721836, dtype=float32), 'eval/episode_reward_alive_std': Array(40.884907, dtype=float32), 'eval/episode_reward_linvel_std': Array(11.600475, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.851179, dtype=float32), 'eval/episode_x_position_std': Array(1.3993585, dtype=float32), 'eval/episode_x_velocity_std': Array(4.6401906, dtype=float32), 'eval/episode_y_position_std': Array(1.746833, dtype=float32), 'eval/episode_y_velocity_std': Array(6.5136433, dtype=float32), 'eval/avg_episode_length': Array(29.109375, dtype=float32), 'eval/epoch_eval_time': 5.817776679992676, 'eval/sps': 11000.766017729056, 'num_steps': 7680}
{'eval/walltime': 81.32924914360046, 'training/sps': 703.5870625752, 'training/walltime': 39.71046853065491, 'training/entropy_loss': Array(-0.01288462, dtype=float32), 'training/policy_loss': Array(-0.07026932, dtype=float32), 'training/total_loss': Array(8.292616, dtype=float32), 'training/v_loss': Array(8.37577, dtype=float32), 'eval/episode_distance_from_origin': Array(25.673311, dtype=float32), 'eval/episode_forward_reward': Array(12.518809, dtype=float32), 'eval/episode_reward': Array(153.07407, dtype=float32), 'eval/episode_reward_alive': Array(158.75, dtype=float32), 'eval/episode_reward_linvel': Array(12.518809, dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.194752, dtype=float32), 'eval/episode_x_position': Array(2.0707269, dtype=float32), 'eval/episode_x_velocity': Array(5.0075245, dtype=float32), 'eval/episode_y_position': Array(0.5333521, dtype=float32), 'eval/episode_y_velocity': Array(2.5309649, dtype=float32), 'eval/episode_distance_from_origin_std': Array(6.456972, dtype=float32), 'eval/episode_forward_reward_std': Array(12.979754, dtype=float32), 'eval/episode_reward_std': Array(39.468803, dtype=float32), 'eval/episode_reward_alive_std': Array(38.714703, dtype=float32), 'eval/episode_reward_linvel_std': Array(12.979754, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.6079717, dtype=float32), 'eval/episode_x_position_std': Array(1.5984387, dtype=float32), 'eval/episode_x_velocity_std': Array(5.191902, dtype=float32), 'eval/episode_y_position_std': Array(1.7359263, dtype=float32), 'eval/episode_y_velocity_std': Array(6.511791, dtype=float32), 'eval/avg_episode_length': Array(31.75, dtype=float32), 'eval/epoch_eval_time': 5.806722640991211, 'eval/sps': 11021.707761312182, 'num_steps': 8960}
{'eval/walltime': 87.1309323310852, 'training/sps': 700.8642441567874, 'training/walltime': 41.53678512573242, 'training/entropy_loss': Array(-0.01275693, dtype=float32), 'training/policy_loss': Array(-0.05134809, dtype=float32), 'training/total_loss': Array(8.62657, dtype=float32), 'training/v_loss': Array(8.690676, dtype=float32), 'eval/episode_distance_from_origin': Array(25.918827, dtype=float32), 'eval/episode_forward_reward': Array(14.437708, dtype=float32), 'eval/episode_reward': Array(156.47137, dtype=float32), 'eval/episode_reward_alive': Array(160.54688, dtype=float32), 'eval/episode_reward_linvel': Array(14.437708, dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.51321, dtype=float32), 'eval/episode_x_position': Array(2.1633358, dtype=float32), 'eval/episode_x_velocity': Array(5.775083, dtype=float32), 'eval/episode_y_position': Array(0.83864963, dtype=float32), 'eval/episode_y_velocity': Array(3.076836, dtype=float32), 'eval/episode_distance_from_origin_std': Array(6.6478567, dtype=float32), 'eval/episode_forward_reward_std': Array(13.504417, dtype=float32), 'eval/episode_reward_std': Array(38.918385, dtype=float32), 'eval/episode_reward_alive_std': Array(39.41087, dtype=float32), 'eval/episode_reward_linvel_std': Array(13.504417, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.527249, dtype=float32), 'eval/episode_x_position_std': Array(1.600192, dtype=float32), 'eval/episode_x_velocity_std': Array(5.4017673, dtype=float32), 'eval/episode_y_position_std': Array(1.9748694, dtype=float32), 'eval/episode_y_velocity_std': Array(6.905165, dtype=float32), 'eval/avg_episode_length': Array(32.109375, dtype=float32), 'eval/epoch_eval_time': 5.801683187484741, 'eval/sps': 11031.281428475679, 'num_steps': 10240}
{'eval/walltime': 92.94812750816345, 'training/sps': 700.6145514655957, 'training/walltime': 43.363752603530884, 'training/entropy_loss': Array(-0.01268517, dtype=float32), 'training/policy_loss': Array(-0.05679182, dtype=float32), 'training/total_loss': Array(7.279586, dtype=float32), 'training/v_loss': Array(7.349063, dtype=float32), 'eval/episode_distance_from_origin': Array(27.80352, dtype=float32), 'eval/episode_forward_reward': Array(17.870876, dtype=float32), 'eval/episode_reward': Array(169.87149, dtype=float32), 'eval/episode_reward_alive': Array(171.64062, dtype=float32), 'eval/episode_reward_linvel': Array(17.870876, dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.64001, dtype=float32), 'eval/episode_x_position': Array(2.906217, dtype=float32), 'eval/episode_x_velocity': Array(7.1483507, dtype=float32), 'eval/episode_y_position': Array(0.3906184, dtype=float32), 'eval/episode_y_velocity': Array(1.4059622, dtype=float32), 'eval/episode_distance_from_origin_std': Array(6.6779876, dtype=float32), 'eval/episode_forward_reward_std': Array(15.249979, dtype=float32), 'eval/episode_reward_std': Array(42.554844, dtype=float32), 'eval/episode_reward_alive_std': Array(38.76063, dtype=float32), 'eval/episode_reward_linvel_std': Array(15.249979, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.6616416, dtype=float32), 'eval/episode_x_position_std': Array(2.2465997, dtype=float32), 'eval/episode_x_velocity_std': Array(6.0999913, dtype=float32), 'eval/episode_y_position_std': Array(2.303158, dtype=float32), 'eval/episode_y_velocity_std': Array(8.114568, dtype=float32), 'eval/avg_episode_length': Array(34.328125, dtype=float32), 'eval/epoch_eval_time': 5.817195177078247, 'eval/sps': 11001.865684717275, 'num_steps': 11520}