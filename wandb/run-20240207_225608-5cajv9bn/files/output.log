
{'eval/walltime': 152.49571871757507, 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(-196.03223, dtype=float32), 'eval/episode_reward_alive': Array(16.953125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-212.98535, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(26.82512, dtype=float32), 'eval/episode_reward_alive_std': Array(26.599125, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.2792692, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 152.49571871757507, 'eval/sps': 839.3678266932752, 'num_steps': 0}
{'eval/walltime': 272.47291350364685, 'training/sps': 492.53699733229695, 'training/walltime': 166.32253098487854, 'training/entropy_loss': Array(-0.00506965, dtype=float32), 'training/policy_loss': Array(0.03548273, dtype=float32), 'training/total_loss': Array(0.03330919, dtype=float32), 'training/v_loss': Array(0.0028961, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(3088.9312, dtype=float32), 'eval/episode_reward_alive': Array(3323.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-234.85806, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1503.8839, dtype=float32), 'eval/episode_reward_alive_std': Array(1511.6631, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.998808, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.97719478607178, 'eval/sps': 1066.8694182109648, 'num_steps': 81920}
{'eval/walltime': 392.39071798324585, 'training/sps': 583.6268562182456, 'training/walltime': 306.6861882209778, 'training/entropy_loss': Array(-0.00507604, dtype=float32), 'training/policy_loss': Array(0.27361506, dtype=float32), 'training/total_loss': Array(0.45661765, dtype=float32), 'training/v_loss': Array(0.18807863, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(-68.46585, dtype=float32), 'eval/episode_reward_alive': Array(142.96875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-211.4346, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(247.3734, dtype=float32), 'eval/episode_reward_alive_std': Array(249.19357, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.4934385, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.917804479599, 'eval/sps': 1067.3977943098182, 'num_steps': 163840}
{'eval/walltime': 512.0667088031769, 'training/sps': 584.8083486241627, 'training/walltime': 446.76626777648926, 'training/entropy_loss': Array(-0.00505249, dtype=float32), 'training/policy_loss': Array(-0.02149034, dtype=float32), 'training/total_loss': Array(0.01888224, dtype=float32), 'training/v_loss': Array(0.04542508, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(3222.9067, dtype=float32), 'eval/episode_reward_alive': Array(3448.5547, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-225.64816, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(1525.5024, dtype=float32), 'eval/episode_reward_alive_std': Array(1532.3943, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.092565, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.67599081993103, 'eval/sps': 1069.554545761761, 'num_steps': 245760}
{'eval/walltime': 632.1245472431183, 'training/sps': 584.6848941414919, 'training/walltime': 586.8759248256683, 'training/entropy_loss': Array(-0.00470911, dtype=float32), 'training/policy_loss': Array(-0.0258971, dtype=float32), 'training/total_loss': Array(0.11185601, dtype=float32), 'training/v_loss': Array(0.14246224, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4659.0947, dtype=float32), 'eval/episode_reward_alive': Array(4920.2344, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-261.14, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(142.7782, dtype=float32), 'eval/episode_reward_alive_std': Array(144.37616, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.5974364, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.0578384399414, 'eval/sps': 1066.1527948800415, 'num_steps': 327680}
{'eval/walltime': 752.0222146511078, 'training/sps': 584.1513481159703, 'training/walltime': 727.1135537624359, 'training/entropy_loss': Array(-0.00399422, dtype=float32), 'training/policy_loss': Array(0.00725561, dtype=float32), 'training/total_loss': Array(0.05078548, dtype=float32), 'training/v_loss': Array(0.04752409, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4681.447, dtype=float32), 'eval/episode_reward_alive': Array(4931.836, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-250.3891, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(92.602875, dtype=float32), 'eval/episode_reward_alive_std': Array(92.46805, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.8574376, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8976674079895, 'eval/sps': 1067.5770660695155, 'num_steps': 409600}
{'eval/walltime': 871.9147493839264, 'training/sps': 583.7602322301514, 'training/walltime': 867.4451410770416, 'training/entropy_loss': Array(-0.0042175, dtype=float32), 'training/policy_loss': Array(-0.00491787, dtype=float32), 'training/total_loss': Array(0.00966913, dtype=float32), 'training/v_loss': Array(0.0188045, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4711.6787, dtype=float32), 'eval/episode_reward_alive': Array(4957.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-246.21136, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(56.633587, dtype=float32), 'eval/episode_reward_alive_std': Array(56.866787, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.549801, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8925347328186, 'eval/sps': 1067.622769718306, 'num_steps': 491520}
{'eval/walltime': 991.8982787132263, 'training/sps': 585.1936617368999, 'training/walltime': 1007.4329867362976, 'training/entropy_loss': Array(-0.00404886, dtype=float32), 'training/policy_loss': Array(-0.00660274, dtype=float32), 'training/total_loss': Array(4.2644737e-05, dtype=float32), 'training/v_loss': Array(0.01069424, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4733.8784, dtype=float32), 'eval/episode_reward_alive': Array(4970.039, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-236.16031, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(33.41347, dtype=float32), 'eval/episode_reward_alive_std': Array(33.31605, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.7406785, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98352932929993, 'eval/sps': 1066.8130927262403, 'num_steps': 573440}
{'eval/walltime': 1111.7807626724243, 'training/sps': 585.3977223687875, 'training/walltime': 1147.3720347881317, 'training/entropy_loss': Array(-0.00414847, dtype=float32), 'training/policy_loss': Array(-0.00868626, dtype=float32), 'training/total_loss': Array(-0.00584453, dtype=float32), 'training/v_loss': Array(0.0069902, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4753.0796, dtype=float32), 'eval/episode_reward_alive': Array(4979.453, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-226.3735, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(23.717295, dtype=float32), 'eval/episode_reward_alive_std': Array(23.719011, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.3378432, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.882483959198, 'eval/sps': 1067.7122776632223, 'num_steps': 655360}
{'eval/walltime': 1231.5709109306335, 'training/sps': 584.8822111793562, 'training/walltime': 1287.434424161911, 'training/entropy_loss': Array(-0.00415751, dtype=float32), 'training/policy_loss': Array(-0.01022425, dtype=float32), 'training/total_loss': Array(-0.01051587, dtype=float32), 'training/v_loss': Array(0.00386589, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4769.7275, dtype=float32), 'eval/episode_reward_alive': Array(4986.0547, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-216.32747, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(16.456337, dtype=float32), 'eval/episode_reward_alive_std': Array(16.55545, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.6931856, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79014825820923, 'eval/sps': 1068.5352832529627, 'num_steps': 737280}
{'eval/walltime': 1351.4276292324066, 'training/sps': 582.3336865291997, 'training/walltime': 1428.1097824573517, 'training/entropy_loss': Array(-0.00414538, dtype=float32), 'training/policy_loss': Array(-0.00922004, dtype=float32), 'training/total_loss': Array(-0.01110995, dtype=float32), 'training/v_loss': Array(0.00225547, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4782., dtype=float32), 'eval/episode_reward_alive': Array(4987.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-205.96872, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.95481, dtype=float32), 'eval/episode_reward_alive_std': Array(11.649797, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.1307294, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85671830177307, 'eval/sps': 1067.9418042943903, 'num_steps': 819200}
{'eval/walltime': 1471.3401052951813, 'training/sps': 584.1701842021287, 'training/walltime': 1568.342889547348, 'training/entropy_loss': Array(-0.00401186, dtype=float32), 'training/policy_loss': Array(-0.01115113, dtype=float32), 'training/total_loss': Array(-0.0131577, dtype=float32), 'training/v_loss': Array(0.00200529, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4790.6606, dtype=float32), 'eval/episode_reward_alive': Array(4987.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-197.30792, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.334238, dtype=float32), 'eval/episode_reward_alive_std': Array(11.633019, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.4412818, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.91247606277466, 'eval/sps': 1067.445225073924, 'num_steps': 901120}
{'eval/walltime': 1591.2527198791504, 'training/sps': 584.9382930004641, 'training/walltime': 1708.391850233078, 'training/entropy_loss': Array(-0.00375983, dtype=float32), 'training/policy_loss': Array(-0.01352488, dtype=float32), 'training/total_loss': Array(-0.01602046, dtype=float32), 'training/v_loss': Array(0.00126425, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4801.9126, dtype=float32), 'eval/episode_reward_alive': Array(4988.242, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-186.32916, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.134739, dtype=float32), 'eval/episode_reward_alive_std': Array(10.617457, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.8324265, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.91261458396912, 'eval/sps': 1067.4439919777387, 'num_steps': 983040}
{'eval/walltime': 1711.0703647136688, 'training/sps': 585.2768393049408, 'training/walltime': 1848.3598012924194, 'training/entropy_loss': Array(-0.0035767, dtype=float32), 'training/policy_loss': Array(-0.01209081, dtype=float32), 'training/total_loss': Array(-0.01446447, dtype=float32), 'training/v_loss': Array(0.00120304, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4814.3633, dtype=float32), 'eval/episode_reward_alive': Array(4989.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-174.66063, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.263198, dtype=float32), 'eval/episode_reward_alive_std': Array(10.251879, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.524025, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81764483451843, 'eval/sps': 1068.2900684350984, 'num_steps': 1064960}
{'eval/walltime': 1830.8471298217773, 'training/sps': 584.9379434763727, 'training/walltime': 1988.4088456630707, 'training/entropy_loss': Array(-0.00340807, dtype=float32), 'training/policy_loss': Array(-0.0138876, dtype=float32), 'training/total_loss': Array(-0.01634727, dtype=float32), 'training/v_loss': Array(0.0009484, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4827.078, dtype=float32), 'eval/episode_reward_alive': Array(4990.625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-163.54726, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.470849, dtype=float32), 'eval/episode_reward_alive_std': Array(9.621753, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.4548883, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77676510810852, 'eval/sps': 1068.6546750905263, 'num_steps': 1146880}
{'eval/walltime': 1950.7272527217865, 'training/sps': 585.1506677541288, 'training/walltime': 2128.4069769382477, 'training/entropy_loss': Array(-0.00327741, dtype=float32), 'training/policy_loss': Array(-0.01209687, dtype=float32), 'training/total_loss': Array(-0.01432049, dtype=float32), 'training/v_loss': Array(0.00105379, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4836.285, dtype=float32), 'eval/episode_reward_alive': Array(4990.3516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-154.06653, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.854109, dtype=float32), 'eval/episode_reward_alive_std': Array(9.543968, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.058237, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88012290000916, 'eval/sps': 1067.73330643616, 'num_steps': 1228800}
{'eval/walltime': 2070.8689131736755, 'training/sps': 585.4052674989871, 'training/walltime': 2268.344221353531, 'training/entropy_loss': Array(-0.00301864, dtype=float32), 'training/policy_loss': Array(-0.01581262, dtype=float32), 'training/total_loss': Array(-0.01818297, dtype=float32), 'training/v_loss': Array(0.00064829, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4849.157, dtype=float32), 'eval/episode_reward_alive': Array(4990.4297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-141.27267, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.75387, dtype=float32), 'eval/episode_reward_alive_std': Array(9.417142, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.313921, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.14166045188904, 'eval/sps': 1065.408947392215, 'num_steps': 1310720}
{'eval/walltime': 2190.7313256263733, 'training/sps': 585.1190200240322, 'training/walltime': 2408.34992480278, 'training/entropy_loss': Array(-0.00278515, dtype=float32), 'training/policy_loss': Array(-0.01335249, dtype=float32), 'training/total_loss': Array(-0.01534539, dtype=float32), 'training/v_loss': Array(0.00079225, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4858.213, dtype=float32), 'eval/episode_reward_alive': Array(4990.1562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-131.94337, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.229683, dtype=float32), 'eval/episode_reward_alive_std': Array(8.881544, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.3625517, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86241245269775, 'eval/sps': 1067.8910709436425, 'num_steps': 1392640}
{'eval/walltime': 2310.7471265792847, 'training/sps': 585.4275070664288, 'training/walltime': 2548.281853199005, 'training/entropy_loss': Array(-0.00246362, dtype=float32), 'training/policy_loss': Array(-0.01541083, dtype=float32), 'training/total_loss': Array(-0.01723199, dtype=float32), 'training/v_loss': Array(0.00064247, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4867.3486, dtype=float32), 'eval/episode_reward_alive': Array(4990.9375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-123.588425, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(14.110201, dtype=float32), 'eval/episode_reward_alive_std': Array(9.222721, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.059366, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01580095291138, 'eval/sps': 1066.5262322435465, 'num_steps': 1474560}
{'eval/walltime': 2430.736941576004, 'training/sps': 585.1560071513829, 'training/walltime': 2688.2787070274353, 'training/entropy_loss': Array(-0.00221895, dtype=float32), 'training/policy_loss': Array(-0.01624712, dtype=float32), 'training/total_loss': Array(-0.01795819, dtype=float32), 'training/v_loss': Array(0.00050788, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4875.9956, dtype=float32), 'eval/episode_reward_alive': Array(4990.9375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-114.94158, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.922728, dtype=float32), 'eval/episode_reward_alive_std': Array(8.632017, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.102424, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98981499671936, 'eval/sps': 1066.757207713835, 'num_steps': 1556480}
{'eval/walltime': 2550.6291546821594, 'training/sps': 584.3276142133053, 'training/walltime': 2828.4740324020386, 'training/entropy_loss': Array(-0.00199274, dtype=float32), 'training/policy_loss': Array(-0.01398821, dtype=float32), 'training/total_loss': Array(-0.01523792, dtype=float32), 'training/v_loss': Array(0.00074302, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4886.7246, dtype=float32), 'eval/episode_reward_alive': Array(4992.1094, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-105.384865, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.845786, dtype=float32), 'eval/episode_reward_alive_std': Array(8.741276, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.4486623, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8922131061554, 'eval/sps': 1067.6256337570962, 'num_steps': 1638400}
{'eval/walltime': 2670.4086351394653, 'training/sps': 585.3670341945541, 'training/walltime': 2968.42041683197, 'training/entropy_loss': Array(-0.00161098, dtype=float32), 'training/policy_loss': Array(-0.01588134, dtype=float32), 'training/total_loss': Array(-0.01701573, dtype=float32), 'training/v_loss': Array(0.00047659, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4895.0957, dtype=float32), 'eval/episode_reward_alive': Array(4991.875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-96.77948, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.579949, dtype=float32), 'eval/episode_reward_alive_std': Array(8.546746, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.200358, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77948045730591, 'eval/sps': 1068.630449149629, 'num_steps': 1720320}
{'eval/walltime': 2790.381362915039, 'training/sps': 585.5192101394772, 'training/walltime': 3108.330429315567, 'training/entropy_loss': Array(-0.00129063, dtype=float32), 'training/policy_loss': Array(-0.0122034, dtype=float32), 'training/total_loss': Array(-0.01294918, dtype=float32), 'training/v_loss': Array(0.00054484, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4904.8115, dtype=float32), 'eval/episode_reward_alive': Array(4992.1875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-87.375496, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.822533, dtype=float32), 'eval/episode_reward_alive_std': Array(8.449066, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.8607903, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.97272777557373, 'eval/sps': 1066.9091415462558, 'num_steps': 1802240}
{'eval/walltime': 2910.1049847602844, 'training/sps': 585.0666124950342, 'training/walltime': 3248.3486738204956, 'training/entropy_loss': Array(-0.00080051, dtype=float32), 'training/policy_loss': Array(-0.01469267, dtype=float32), 'training/total_loss': Array(-0.01505078, dtype=float32), 'training/v_loss': Array(0.0004424, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4909.2197, dtype=float32), 'eval/episode_reward_alive': Array(4991.5234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-82.304016, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.662337, dtype=float32), 'eval/episode_reward_alive_std': Array(8.672842, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.5668144, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72362184524536, 'eval/sps': 1069.1290325768182, 'num_steps': 1884160}
{'eval/walltime': 3029.891487121582, 'training/sps': 585.4919122988804, 'training/walltime': 3388.2652094364166, 'training/entropy_loss': Array(-0.00055858, dtype=float32), 'training/policy_loss': Array(-0.00908104, dtype=float32), 'training/total_loss': Array(-0.00903527, dtype=float32), 'training/v_loss': Array(0.00060435, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4916.7173, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-76.87659, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.482252, dtype=float32), 'eval/episode_reward_alive_std': Array(8.36047, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.020534, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78650236129761, 'eval/sps': 1068.5678058612064, 'num_steps': 1966080}
{'eval/walltime': 3149.963468313217, 'training/sps': 585.194205916711, 'training/walltime': 3528.2529249191284, 'training/entropy_loss': Array(-6.938114e-05, dtype=float32), 'training/policy_loss': Array(-0.00900693, dtype=float32), 'training/total_loss': Array(-0.00832347, dtype=float32), 'training/v_loss': Array(0.00075283, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4920.3174, dtype=float32), 'eval/episode_reward_alive': Array(4992.3438, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-72.026, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.233814, dtype=float32), 'eval/episode_reward_alive_std': Array(8.4534, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.9067626, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.07198119163513, 'eval/sps': 1066.0272174214542, 'num_steps': 2048000}
{'eval/walltime': 3269.991913795471, 'training/sps': 585.4428923260961, 'training/walltime': 3668.1811759471893, 'training/entropy_loss': Array(-0.00011712, dtype=float32), 'training/policy_loss': Array(-0.01013467, dtype=float32), 'training/total_loss': Array(-0.00958448, dtype=float32), 'training/v_loss': Array(0.0006673, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4927.454, dtype=float32), 'eval/episode_reward_alive': Array(4990.742, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-63.287773, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.974873, dtype=float32), 'eval/episode_reward_alive_std': Array(8.884894, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.185252, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02844548225403, 'eval/sps': 1066.4138778580161, 'num_steps': 2129920}
{'eval/walltime': 3389.690752029419, 'training/sps': 585.0118288130187, 'training/walltime': 3808.212532520294, 'training/entropy_loss': Array(0.00056621, dtype=float32), 'training/policy_loss': Array(-0.00798942, dtype=float32), 'training/total_loss': Array(-0.00653736, dtype=float32), 'training/v_loss': Array(0.00088585, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4934.3135, dtype=float32), 'eval/episode_reward_alive': Array(4990.8203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-56.50699, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.56669, dtype=float32), 'eval/episode_reward_alive_std': Array(8.286315, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.3931146, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69883823394775, 'eval/sps': 1069.3503954468454, 'num_steps': 2211840}
{'eval/walltime': 3509.7642085552216, 'training/sps': 583.9448247747365, 'training/walltime': 3948.499759197235, 'training/entropy_loss': Array(0.00117287, dtype=float32), 'training/policy_loss': Array(-0.01046254, dtype=float32), 'training/total_loss': Array(-0.00884494, dtype=float32), 'training/v_loss': Array(0.00044474, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4942.6035, dtype=float32), 'eval/episode_reward_alive': Array(4992.7344, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-50.130905, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.962692, dtype=float32), 'eval/episode_reward_alive_std': Array(8.26465, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.4640868, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.07345652580261, 'eval/sps': 1066.0141192195467, 'num_steps': 2293760}
{'eval/walltime': 3629.5591740608215, 'training/sps': 583.4819579500913, 'training/walltime': 4088.8982734680176, 'training/entropy_loss': Array(0.00169099, dtype=float32), 'training/policy_loss': Array(-0.00689214, dtype=float32), 'training/total_loss': Array(-0.00479679, dtype=float32), 'training/v_loss': Array(0.00040437, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4944.6953, dtype=float32), 'eval/episode_reward_alive': Array(4991.7188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-47.023308, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.082215, dtype=float32), 'eval/episode_reward_alive_std': Array(8.441839, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.58491, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79496550559998, 'eval/sps': 1068.4923148462067, 'num_steps': 2375680}
{'eval/walltime': 3749.538628101349, 'training/sps': 581.6690421437022, 'training/walltime': 4229.734374523163, 'training/entropy_loss': Array(0.0019484, dtype=float32), 'training/policy_loss': Array(-0.00717246, dtype=float32), 'training/total_loss': Array(-0.00495905, dtype=float32), 'training/v_loss': Array(0.00026502, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4945.1885, dtype=float32), 'eval/episode_reward_alive': Array(4991.25, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-46.06122, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(14.295028, dtype=float32), 'eval/episode_reward_alive_std': Array(8.637671, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(11.063142, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.97945404052734, 'eval/sps': 1066.8493286922562, 'num_steps': 2457600}
{'eval/walltime': 3869.3183081150055, 'training/sps': 585.1954906236134, 'training/walltime': 4369.721782684326, 'training/entropy_loss': Array(0.00223026, dtype=float32), 'training/policy_loss': Array(-0.00653654, dtype=float32), 'training/total_loss': Array(-0.00382112, dtype=float32), 'training/v_loss': Array(0.00048516, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4947.158, dtype=float32), 'eval/episode_reward_alive': Array(4991.758, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-44.599087, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(15.183085, dtype=float32), 'eval/episode_reward_alive_std': Array(8.163128, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.8689575, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77968001365662, 'eval/sps': 1068.6286687809331, 'num_steps': 2539520}
{'eval/walltime': 3989.4187707901, 'training/sps': 584.2932942176717, 'training/walltime': 4509.925342798233, 'training/entropy_loss': Array(0.00242598, dtype=float32), 'training/policy_loss': Array(-0.00913609, dtype=float32), 'training/total_loss': Array(-0.00646956, dtype=float32), 'training/v_loss': Array(0.00024054, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4943.4805, dtype=float32), 'eval/episode_reward_alive': Array(4992.0703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-48.58979, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(26.024853, dtype=float32), 'eval/episode_reward_alive_std': Array(7.992363, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(25.234543, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.1004626750946, 'eval/sps': 1065.7744120959455, 'num_steps': 2621440}
{'eval/walltime': 4109.116270303726, 'training/sps': 584.816881912888, 'training/walltime': 4650.003378391266, 'training/entropy_loss': Array(0.00203365, dtype=float32), 'training/policy_loss': Array(-0.00292151, dtype=float32), 'training/total_loss': Array(0.00195888, dtype=float32), 'training/v_loss': Array(0.00284674, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4951.0757, dtype=float32), 'eval/episode_reward_alive': Array(4991.7188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-40.642735, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(17.400118, dtype=float32), 'eval/episode_reward_alive_std': Array(7.9411287, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(15.98956, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.6974995136261, 'eval/sps': 1069.3623552714964, 'num_steps': 2703360}
{'eval/walltime': 4229.371233463287, 'training/sps': 582.8011599839665, 'training/walltime': 4790.565898895264, 'training/entropy_loss': Array(0.00291925, dtype=float32), 'training/policy_loss': Array(-0.00836433, dtype=float32), 'training/total_loss': Array(-0.00499339, dtype=float32), 'training/v_loss': Array(0.00045169, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4953.5767, dtype=float32), 'eval/episode_reward_alive': Array(4990.8203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-37.244034, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(15.616445, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8505907, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(13.401638, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.25496315956116, 'eval/sps': 1064.4051325362952, 'num_steps': 2785280}
{'eval/walltime': 4349.185346603394, 'training/sps': 584.6581555411524, 'training/walltime': 4930.681963682175, 'training/entropy_loss': Array(0.00313248, dtype=float32), 'training/policy_loss': Array(-0.01013982, dtype=float32), 'training/total_loss': Array(-0.00662109, dtype=float32), 'training/v_loss': Array(0.00038625, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4957.7446, dtype=float32), 'eval/episode_reward_alive': Array(4992.3438, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-34.599514, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.054741, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8794007, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.294421, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8141131401062, 'eval/sps': 1068.321557831184, 'num_steps': 2867200}
{'eval/walltime': 4469.744725227356, 'training/sps': 582.8673467872276, 'training/walltime': 5071.228522777557, 'training/entropy_loss': Array(0.00326186, dtype=float32), 'training/policy_loss': Array(-0.00707067, dtype=float32), 'training/total_loss': Array(-0.00340106, dtype=float32), 'training/v_loss': Array(0.00040775, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4955.254, dtype=float32), 'eval/episode_reward_alive': Array(4992.8516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-37.59811, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(17.159721, dtype=float32), 'eval/episode_reward_alive_std': Array(8.307649, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.03598, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.5593786239624, 'eval/sps': 1061.7174827953095, 'num_steps': 2949120}
{'eval/walltime': 4589.461867809296, 'training/sps': 584.3824159209868, 'training/walltime': 5211.410701036453, 'training/entropy_loss': Array(0.00307315, dtype=float32), 'training/policy_loss': Array(-0.0059708, dtype=float32), 'training/total_loss': Array(-0.00248784, dtype=float32), 'training/v_loss': Array(0.00040982, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4954.138, dtype=float32), 'eval/episode_reward_alive': Array(4993.203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-39.065407, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(19.02449, dtype=float32), 'eval/episode_reward_alive_std': Array(8.094519, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.03749, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7171425819397, 'eval/sps': 1069.1868953720739, 'num_steps': 3031040}
{'eval/walltime': 4709.665923833847, 'training/sps': 583.7633762173207, 'training/walltime': 5351.741532564163, 'training/entropy_loss': Array(0.00279064, dtype=float32), 'training/policy_loss': Array(-0.00792732, dtype=float32), 'training/total_loss': Array(-0.00443008, dtype=float32), 'training/v_loss': Array(0.00070661, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4951.061, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-42.961975, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(18.890776, dtype=float32), 'eval/episode_reward_alive_std': Array(7.6561503, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.28382, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.20405602455139, 'eval/sps': 1064.855914461458, 'num_steps': 3112960}
{'eval/walltime': 4829.476466417313, 'training/sps': 584.0654451062447, 'training/walltime': 5491.999787330627, 'training/entropy_loss': Array(0.0025127, dtype=float32), 'training/policy_loss': Array(-0.00962425, dtype=float32), 'training/total_loss': Array(-0.00672622, dtype=float32), 'training/v_loss': Array(0.00038533, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4953.407, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-40.03065, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(19.06347, dtype=float32), 'eval/episode_reward_alive_std': Array(7.9488106, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.884281, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81054258346558, 'eval/sps': 1068.3533956189979, 'num_steps': 3194880}
{'eval/walltime': 4949.350514650345, 'training/sps': 583.6802118018346, 'training/walltime': 5632.350613594055, 'training/entropy_loss': Array(0.00271468, dtype=float32), 'training/policy_loss': Array(-0.00822325, dtype=float32), 'training/total_loss': Array(-0.00517569, dtype=float32), 'training/v_loss': Array(0.00033289, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4953.3765, dtype=float32), 'eval/episode_reward_alive': Array(4991.4844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-38.108177, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(18.66527, dtype=float32), 'eval/episode_reward_alive_std': Array(8.1815195, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(17.794788, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87404823303223, 'eval/sps': 1067.7874142631033, 'num_steps': 3276800}
{'eval/walltime': 5069.129195213318, 'training/sps': 584.8538856037378, 'training/walltime': 5772.419786453247, 'training/entropy_loss': Array(0.00341926, dtype=float32), 'training/policy_loss': Array(-0.00826379, dtype=float32), 'training/total_loss': Array(-0.00447911, dtype=float32), 'training/v_loss': Array(0.00036542, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4958.2812, dtype=float32), 'eval/episode_reward_alive': Array(4992.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-34.492264, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(17.777704, dtype=float32), 'eval/episode_reward_alive_std': Array(8.334055, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(16.222769, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77868056297302, 'eval/sps': 1068.6375855735416, 'num_steps': 3358720}
{'eval/walltime': 5189.035961151123, 'training/sps': 583.1066193744138, 'training/walltime': 5912.908673524857, 'training/entropy_loss': Array(0.00321151, dtype=float32), 'training/policy_loss': Array(-0.00851918, dtype=float32), 'training/total_loss': Array(-0.00496769, dtype=float32), 'training/v_loss': Array(0.00033999, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.25, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-32.71899, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(14.780509, dtype=float32), 'eval/episode_reward_alive_std': Array(7.891785, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(13.238194, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90676593780518, 'eval/sps': 1067.496058282422, 'num_steps': 3440640}
{'eval/walltime': 5308.837639093399, 'training/sps': 584.4124154709507, 'training/walltime': 6053.083655834198, 'training/entropy_loss': Array(0.00364506, dtype=float32), 'training/policy_loss': Array(-0.00845916, dtype=float32), 'training/total_loss': Array(-0.00461398, dtype=float32), 'training/v_loss': Array(0.00020012, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.7393, dtype=float32), 'eval/episode_reward_alive': Array(4991.7188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-30.980087, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(15.726184, dtype=float32), 'eval/episode_reward_alive_std': Array(8.183384, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.9600725, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.801677942276, 'eval/sps': 1068.432447679691, 'num_steps': 3522560}
{'eval/walltime': 5428.827832698822, 'training/sps': 582.2247410204897, 'training/walltime': 6193.7853372097015, 'training/entropy_loss': Array(0.00380155, dtype=float32), 'training/policy_loss': Array(-0.00788005, dtype=float32), 'training/total_loss': Array(-0.00391582, dtype=float32), 'training/v_loss': Array(0.00016268, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.4146, dtype=float32), 'eval/episode_reward_alive': Array(4991.367, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-30.952717, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(14.499269, dtype=float32), 'eval/episode_reward_alive_std': Array(8.094048, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.921982, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99019360542297, 'eval/sps': 1066.7538417424057, 'num_steps': 3604480}
{'eval/walltime': 5548.587429285049, 'training/sps': 584.2760269387445, 'training/walltime': 6333.993040800095, 'training/entropy_loss': Array(0.00394889, dtype=float32), 'training/policy_loss': Array(-0.0069861, dtype=float32), 'training/total_loss': Array(-0.0027748, dtype=float32), 'training/v_loss': Array(0.00026242, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.504, dtype=float32), 'eval/episode_reward_alive': Array(4991.0938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-27.589884, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(13.095736, dtype=float32), 'eval/episode_reward_alive_std': Array(8.383799, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(10.402458, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.75959658622742, 'eval/sps': 1068.807875516176, 'num_steps': 3686400}
{'eval/walltime': 5668.6032774448395, 'training/sps': 581.7319404756443, 'training/walltime': 6474.813914299011, 'training/entropy_loss': Array(0.00428401, dtype=float32), 'training/policy_loss': Array(-0.00530695, dtype=float32), 'training/total_loss': Array(-0.00078116, dtype=float32), 'training/v_loss': Array(0.00024178, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4964.836, dtype=float32), 'eval/episode_reward_alive': Array(4990.8984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-26.062954, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(28.93789, dtype=float32), 'eval/episode_reward_alive_std': Array(22.80551, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(11.932076, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01584815979004, 'eval/sps': 1066.5258127374962, 'num_steps': 3768320}
{'eval/walltime': 5788.461183786392, 'training/sps': 585.1841277910713, 'training/walltime': 6614.804040670395, 'training/entropy_loss': Array(0.00507908, dtype=float32), 'training/policy_loss': Array(-0.00609015, dtype=float32), 'training/total_loss': Array(-0.0008337, dtype=float32), 'training/v_loss': Array(0.00017737, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4968.6294, dtype=float32), 'eval/episode_reward_alive': Array(4991.6016, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-22.972307, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.874544, dtype=float32), 'eval/episode_reward_alive_std': Array(8.360379, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.4526324, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85790634155273, 'eval/sps': 1067.9312187820565, 'num_steps': 3850240}
{'eval/walltime': 5908.6087255477905, 'training/sps': 582.4232874971417, 'training/walltime': 6755.457757234573, 'training/entropy_loss': Array(0.00562972, dtype=float32), 'training/policy_loss': Array(-0.00622354, dtype=float32), 'training/total_loss': Array(-9.626472e-05, dtype=float32), 'training/v_loss': Array(0.00049756, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4970.706, dtype=float32), 'eval/episode_reward_alive': Array(4992.9297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-22.223906, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.734829, dtype=float32), 'eval/episode_reward_alive_std': Array(7.6935277, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.1195076, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.14754176139832, 'eval/sps': 1065.3567948497516, 'num_steps': 3932160}
{'eval/walltime': 6028.439935922623, 'training/sps': 585.141819796163, 'training/walltime': 6895.458005428314, 'training/entropy_loss': Array(0.00517955, dtype=float32), 'training/policy_loss': Array(-0.00304921, dtype=float32), 'training/total_loss': Array(0.0024567, dtype=float32), 'training/v_loss': Array(0.00032635, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.3535, dtype=float32), 'eval/episode_reward_alive': Array(4992.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.536934, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9167457, dtype=float32), 'eval/episode_reward_alive_std': Array(7.644682, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.8265474, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83121037483215, 'eval/sps': 1068.1691322287063, 'num_steps': 4014080}
{'eval/walltime': 6148.4743576049805, 'training/sps': 581.9384594918903, 'training/walltime': 7036.228904247284, 'training/entropy_loss': Array(0.00571722, dtype=float32), 'training/policy_loss': Array(-0.00746443, dtype=float32), 'training/total_loss': Array(-0.00165121, dtype=float32), 'training/v_loss': Array(9.5995536e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.258, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.257744, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.045335, dtype=float32), 'eval/episode_reward_alive_std': Array(7.5093527, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.144911, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.03442168235779, 'eval/sps': 1066.360783898482, 'num_steps': 4096000}
{'eval/walltime': 6268.264431476593, 'training/sps': 585.1753764882864, 'training/walltime': 7176.221124172211, 'training/entropy_loss': Array(0.00579988, dtype=float32), 'training/policy_loss': Array(-0.00715104, dtype=float32), 'training/total_loss': Array(-0.00124335, dtype=float32), 'training/v_loss': Array(0.00010781, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.282, dtype=float32), 'eval/episode_reward_alive': Array(4992.422, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.139732, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.358324, dtype=float32), 'eval/episode_reward_alive_std': Array(7.9790835, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.0673575, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79007387161255, 'eval/sps': 1068.5359467862638, 'num_steps': 4177920}
{'eval/walltime': 6388.432034730911, 'training/sps': 583.765219978231, 'training/walltime': 7316.551512479782, 'training/entropy_loss': Array(0.00612921, dtype=float32), 'training/policy_loss': Array(-0.00714713, dtype=float32), 'training/total_loss': Array(-0.00089575, dtype=float32), 'training/v_loss': Array(0.00012217, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.8184, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.579752, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.017833, dtype=float32), 'eval/episode_reward_alive_std': Array(8.075173, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.1272955, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.16760325431824, 'eval/sps': 1065.1789378631906, 'num_steps': 4259840}
{'eval/walltime': 6508.206383228302, 'training/sps': 584.9914573911894, 'training/walltime': 7456.587745428085, 'training/entropy_loss': Array(0.00655591, dtype=float32), 'training/policy_loss': Array(-0.00654759, dtype=float32), 'training/total_loss': Array(9.929319e-05, dtype=float32), 'training/v_loss': Array(9.096773e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.5674, dtype=float32), 'eval/episode_reward_alive': Array(4992.8125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.245224, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.619822, dtype=float32), 'eval/episode_reward_alive_std': Array(7.7245045, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.637339, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77434849739075, 'eval/sps': 1068.6762366550333, 'num_steps': 4341760}
{'eval/walltime': 6628.257528305054, 'training/sps': 582.9989029170024, 'training/walltime': 7597.102589607239, 'training/entropy_loss': Array(0.00658023, dtype=float32), 'training/policy_loss': Array(-0.00358405, dtype=float32), 'training/total_loss': Array(0.00312995, dtype=float32), 'training/v_loss': Array(0.00013378, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4970.0527, dtype=float32), 'eval/episode_reward_alive': Array(4991.992, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.939205, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.336456, dtype=float32), 'eval/episode_reward_alive_std': Array(7.9387264, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.600858, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.05114507675171, 'eval/sps': 1066.2122374440194, 'num_steps': 4423680}
{'eval/walltime': 6748.092269420624, 'training/sps': 584.3670058461092, 'training/walltime': 7737.288464546204, 'training/entropy_loss': Array(0.00667825, dtype=float32), 'training/policy_loss': Array(-0.00508855, dtype=float32), 'training/total_loss': Array(0.00170428, dtype=float32), 'training/v_loss': Array(0.00011459, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.868, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.64751, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.97993, dtype=float32), 'eval/episode_reward_alive_std': Array(7.739897, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.790622, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83474111557007, 'eval/sps': 1068.1376603180147, 'num_steps': 4505600}
{'eval/walltime': 6868.030050992966, 'training/sps': 582.9864768079944, 'training/walltime': 7877.806303739548, 'training/entropy_loss': Array(0.00638022, dtype=float32), 'training/policy_loss': Array(-0.0055462, dtype=float32), 'training/total_loss': Array(0.00104808, dtype=float32), 'training/v_loss': Array(0.00021406, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.0654, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.56771, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.694118, dtype=float32), 'eval/episode_reward_alive_std': Array(7.544525, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.017197, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.93778157234192, 'eval/sps': 1067.2200062562877, 'num_steps': 4587520}
{'eval/walltime': 6987.858680009842, 'training/sps': 584.2880609688488, 'training/walltime': 8018.011119604111, 'training/entropy_loss': Array(0.00695428, dtype=float32), 'training/policy_loss': Array(-0.00151197, dtype=float32), 'training/total_loss': Array(0.00597119, dtype=float32), 'training/v_loss': Array(0.00052888, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.709, dtype=float32), 'eval/episode_reward_alive': Array(4992.7344, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.025082, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.025899, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8774643, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.049644, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82862901687622, 'eval/sps': 1068.1921428139929, 'num_steps': 4669440}
{'eval/walltime': 7107.994045972824, 'training/sps': 580.7292500212515, 'training/walltime': 8159.075135231018, 'training/entropy_loss': Array(0.00625124, dtype=float32), 'training/policy_loss': Array(-0.00771358, dtype=float32), 'training/total_loss': Array(-0.00135609, dtype=float32), 'training/v_loss': Array(0.00010625, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.1465, dtype=float32), 'eval/episode_reward_alive': Array(4992.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.627354, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(13.651834, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4427133, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(11.317949, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.13536596298218, 'eval/sps': 1065.4647694621515, 'num_steps': 4751360}
{'eval/walltime': 7227.852937221527, 'training/sps': 584.7970336662829, 'training/walltime': 8299.157925128937, 'training/entropy_loss': Array(0.00684207, dtype=float32), 'training/policy_loss': Array(-0.00653209, dtype=float32), 'training/total_loss': Array(0.00040084, dtype=float32), 'training/v_loss': Array(9.08559e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.2715, dtype=float32), 'eval/episode_reward_alive': Array(4991.953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.681065, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.317341, dtype=float32), 'eval/episode_reward_alive_std': Array(7.936131, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.487095, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.858891248703, 'eval/sps': 1067.922443353864, 'num_steps': 4833280}
{'eval/walltime': 7347.876287460327, 'training/sps': 583.7027101859559, 'training/walltime': 8439.503341674805, 'training/entropy_loss': Array(0.00776386, dtype=float32), 'training/policy_loss': Array(-0.0053814, dtype=float32), 'training/total_loss': Array(0.00245226, dtype=float32), 'training/v_loss': Array(6.979413e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.1353, dtype=float32), 'eval/episode_reward_alive': Array(4994.1406, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.005323, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(13.685341, dtype=float32), 'eval/episode_reward_alive_std': Array(7.23785, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(10.165174, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02335023880005, 'eval/sps': 1066.4591493682647, 'num_steps': 4915200}
{'eval/walltime': 7467.585283041, 'training/sps': 584.5137719612627, 'training/walltime': 8579.654017210007, 'training/entropy_loss': Array(0.00775376, dtype=float32), 'training/policy_loss': Array(-0.00633049, dtype=float32), 'training/total_loss': Array(0.00150228, dtype=float32), 'training/v_loss': Array(7.9020145e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.548, dtype=float32), 'eval/episode_reward_alive': Array(4994.1406, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.59306, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.182873, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8496513, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.965396, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.70899558067322, 'eval/sps': 1069.259660722317, 'num_steps': 4997120}
{'eval/walltime': 7587.709792613983, 'training/sps': 584.0561980705216, 'training/walltime': 8719.914492607117, 'training/entropy_loss': Array(0.00832338, dtype=float32), 'training/policy_loss': Array(-0.00634225, dtype=float32), 'training/total_loss': Array(0.00203546, dtype=float32), 'training/v_loss': Array(5.4335993e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.6626, dtype=float32), 'eval/episode_reward_alive': Array(4993.242, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.578976, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.232326, dtype=float32), 'eval/episode_reward_alive_std': Array(7.59291, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.408225, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.12450957298279, 'eval/sps': 1065.5610620597988, 'num_steps': 5079040}
{'eval/walltime': 7707.502614498138, 'training/sps': 584.9660839921435, 'training/walltime': 8859.95679974556, 'training/entropy_loss': Array(0.00761781, dtype=float32), 'training/policy_loss': Array(-0.00613786, dtype=float32), 'training/total_loss': Array(0.00156958, dtype=float32), 'training/v_loss': Array(8.963399e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.3105, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.657944, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.098731, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3802285, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.085332, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79282188415527, 'eval/sps': 1068.5114348819782, 'num_steps': 5160960}
{'eval/walltime': 7827.64253616333, 'training/sps': 584.3979271982439, 'training/walltime': 9000.13525724411, 'training/entropy_loss': Array(0.00815688, dtype=float32), 'training/policy_loss': Array(-0.00912315, dtype=float32), 'training/total_loss': Array(-0.00091473, dtype=float32), 'training/v_loss': Array(5.154554e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.3174, dtype=float32), 'eval/episode_reward_alive': Array(4992.2266, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.908732, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.698182, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3103256, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.4255943, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.13992166519165, 'eval/sps': 1065.424367070198, 'num_steps': 5242880}
{'eval/walltime': 7947.405920505524, 'training/sps': 584.8234525058739, 'training/walltime': 9140.211719036102, 'training/entropy_loss': Array(0.00862884, dtype=float32), 'training/policy_loss': Array(-0.00423819, dtype=float32), 'training/total_loss': Array(0.00446585, dtype=float32), 'training/v_loss': Array(7.519685e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.103, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.022153, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.77639, dtype=float32), 'eval/episode_reward_alive_std': Array(7.447735, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.6895394, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7633843421936, 'eval/sps': 1068.7740723347658, 'num_steps': 5324800}
{'eval/walltime': 8067.459399938583, 'training/sps': 582.6375079288946, 'training/walltime': 9280.813720941544, 'training/entropy_loss': Array(0.0094764, dtype=float32), 'training/policy_loss': Array(-0.00531985, dtype=float32), 'training/total_loss': Array(0.00420489, dtype=float32), 'training/v_loss': Array(4.8337366e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.4854, dtype=float32), 'eval/episode_reward_alive': Array(4993.9062, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.421129, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.319795, dtype=float32), 'eval/episode_reward_alive_std': Array(6.957951, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.316623, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.05347943305969, 'eval/sps': 1066.1915056895223, 'num_steps': 5406720}
{'eval/walltime': 8187.269167900085, 'training/sps': 584.4249163581819, 'training/walltime': 9420.985704898834, 'training/entropy_loss': Array(0.00893435, dtype=float32), 'training/policy_loss': Array(0.00348153, dtype=float32), 'training/total_loss': Array(0.01253075, dtype=float32), 'training/v_loss': Array(0.00011488, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.567, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.909491, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.197096, dtype=float32), 'eval/episode_reward_alive_std': Array(7.249962, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.6972146, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80976796150208, 'eval/sps': 1068.360302985727, 'num_steps': 5488640}
{'eval/walltime': 8307.289471387863, 'training/sps': 581.2229117231683, 'training/walltime': 9561.929907798767, 'training/entropy_loss': Array(0.00960354, dtype=float32), 'training/policy_loss': Array(-0.00066843, dtype=float32), 'training/total_loss': Array(0.0090075, dtype=float32), 'training/v_loss': Array(7.238852e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.449, dtype=float32), 'eval/episode_reward_alive': Array(4993.242, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.79336, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0114064, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0597296, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.2411358, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02030348777771, 'eval/sps': 1066.4862217502632, 'num_steps': 5570560}
{'eval/walltime': 8427.058889389038, 'training/sps': 585.2224438590268, 'training/walltime': 9701.910868644714, 'training/entropy_loss': Array(0.01073424, dtype=float32), 'training/policy_loss': Array(0.00227569, dtype=float32), 'training/total_loss': Array(0.01306917, dtype=float32), 'training/v_loss': Array(5.9243666e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.2715, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.384739, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.493149, dtype=float32), 'eval/episode_reward_alive_std': Array(7.340425, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(10.9444065, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76941800117493, 'eval/sps': 1068.7202303909028, 'num_steps': 5652480}
{'eval/walltime': 8547.0115275383, 'training/sps': 581.2137298959098, 'training/walltime': 9842.857298135757, 'training/entropy_loss': Array(0.00964655, dtype=float32), 'training/policy_loss': Array(-0.0042949, dtype=float32), 'training/total_loss': Array(0.00540448, dtype=float32), 'training/v_loss': Array(5.2831096e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.8643, dtype=float32), 'eval/episode_reward_alive': Array(4992.1875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.3229885, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(14.195813, dtype=float32), 'eval/episode_reward_alive_std': Array(10.999823, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.8035865, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95263814926147, 'eval/sps': 1067.0878271199413, 'num_steps': 5734400}
{'eval/walltime': 8666.882331609726, 'training/sps': 584.4469791046827, 'training/walltime': 9983.023990631104, 'training/entropy_loss': Array(0.00959075, dtype=float32), 'training/policy_loss': Array(0.00508279, dtype=float32), 'training/total_loss': Array(0.014774, dtype=float32), 'training/v_loss': Array(0.00010047, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.58, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.857117, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7820706, dtype=float32), 'eval/episode_reward_alive_std': Array(7.064159, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.42258, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87080407142639, 'eval/sps': 1067.8163126671757, 'num_steps': 5816320}
{'eval/walltime': 8786.904884338379, 'training/sps': 581.7631982325208, 'training/walltime': 10123.837297916412, 'training/entropy_loss': Array(0.01048897, dtype=float32), 'training/policy_loss': Array(0.0025508, dtype=float32), 'training/total_loss': Array(0.01309683, dtype=float32), 'training/v_loss': Array(5.706089e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.197, dtype=float32), 'eval/episode_reward_alive': Array(4993.2812, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.084661, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.193549, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9439015, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.421863, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02255272865295, 'eval/sps': 1066.4662356364179, 'num_steps': 5898240}
{'eval/walltime': 8906.690052986145, 'training/sps': 585.5055938260331, 'training/walltime': 10263.750564098358, 'training/entropy_loss': Array(0.01110819, dtype=float32), 'training/policy_loss': Array(-0.00249793, dtype=float32), 'training/total_loss': Array(0.00864501, dtype=float32), 'training/v_loss': Array(3.474499e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.801, dtype=float32), 'eval/episode_reward_alive': Array(4990.9766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.1761, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(29.20856, dtype=float32), 'eval/episode_reward_alive_std': Array(25.920992, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.51524, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78516864776611, 'eval/sps': 1068.5797035223115, 'num_steps': 5980160}
{'eval/walltime': 9026.738114595413, 'training/sps': 583.3351618098495, 'training/walltime': 10404.184409618378, 'training/entropy_loss': Array(0.01043739, dtype=float32), 'training/policy_loss': Array(-0.00365886, dtype=float32), 'training/total_loss': Array(0.0068907, dtype=float32), 'training/v_loss': Array(0.00011217, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.3896, dtype=float32), 'eval/episode_reward_alive': Array(4992.539, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.149338, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.01542, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4476323, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.3744369, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04806160926819, 'eval/sps': 1066.2396233986162, 'num_steps': 6062080}
{'eval/walltime': 9146.386364936829, 'training/sps': 585.2349963702125, 'training/walltime': 10544.162368059158, 'training/entropy_loss': Array(0.01144093, dtype=float32), 'training/policy_loss': Array(0.01148118, dtype=float32), 'training/total_loss': Array(0.02298541, dtype=float32), 'training/v_loss': Array(6.330405e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.713, dtype=float32), 'eval/episode_reward_alive': Array(4995.3125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.5990715, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.540372, dtype=float32), 'eval/episode_reward_alive_std': Array(6.782042, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.0405407, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.6482503414154, 'eval/sps': 1069.8025222663343, 'num_steps': 6144000}
{'eval/walltime': 9266.339341640472, 'training/sps': 575.8943567593449, 'training/walltime': 10686.4106798172, 'training/entropy_loss': Array(0.01145024, dtype=float32), 'training/policy_loss': Array(-0.00251822, dtype=float32), 'training/total_loss': Array(0.00899452, dtype=float32), 'training/v_loss': Array(6.250052e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.287, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.720956, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2517715, dtype=float32), 'eval/episode_reward_alive_std': Array(7.324505, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3832, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9529767036438, 'eval/sps': 1067.0848153792565, 'num_steps': 6225920}
{'eval/walltime': 9386.303229093552, 'training/sps': 584.1333215916428, 'training/walltime': 10826.652636528015, 'training/entropy_loss': Array(0.01198126, dtype=float32), 'training/policy_loss': Array(-0.00295522, dtype=float32), 'training/total_loss': Array(0.00908517, dtype=float32), 'training/v_loss': Array(5.91327e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.3774, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.631044, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4130354, dtype=float32), 'eval/episode_reward_alive_std': Array(7.40407, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.9501406, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96388745307922, 'eval/sps': 1066.9877637140085, 'num_steps': 6307840}
{'eval/walltime': 9506.35166311264, 'training/sps': 583.1996853807235, 'training/walltime': 10967.119104623795, 'training/entropy_loss': Array(0.01223462, dtype=float32), 'training/policy_loss': Array(-0.00232102, dtype=float32), 'training/total_loss': Array(0.00994982, dtype=float32), 'training/v_loss': Array(3.62191e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.8535, dtype=float32), 'eval/episode_reward_alive': Array(4994.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.209678, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.842832, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6950893, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.7515209, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04843401908875, 'eval/sps': 1066.2363157494156, 'num_steps': 6389760}
{'eval/walltime': 9626.29834651947, 'training/sps': 585.2255637452142, 'training/walltime': 11107.09931921959, 'training/entropy_loss': Array(0.01162561, dtype=float32), 'training/policy_loss': Array(-0.0024228, dtype=float32), 'training/total_loss': Array(0.00926066, dtype=float32), 'training/v_loss': Array(5.784379e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.8193, dtype=float32), 'eval/episode_reward_alive': Array(4992.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.071482, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.349867, dtype=float32), 'eval/episode_reward_alive_std': Array(7.5417943, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.9504832, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94668340682983, 'eval/sps': 1067.1408026002293, 'num_steps': 6471680}
{'eval/walltime': 9746.333537101746, 'training/sps': 584.2694666537353, 'training/walltime': 11247.30859708786, 'training/entropy_loss': Array(0.01186795, dtype=float32), 'training/policy_loss': Array(-0.00055577, dtype=float32), 'training/total_loss': Array(0.01136051, dtype=float32), 'training/v_loss': Array(4.8325477e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.907, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.8038845, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0676894, dtype=float32), 'eval/episode_reward_alive_std': Array(7.050213, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.6627598, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.03519058227539, 'eval/sps': 1066.3539531956283, 'num_steps': 6553600}
{'eval/walltime': 9866.203824520111, 'training/sps': 585.0801715359827, 'training/walltime': 11387.323596715927, 'training/entropy_loss': Array(0.01154458, dtype=float32), 'training/policy_loss': Array(0.0002718, dtype=float32), 'training/total_loss': Array(0.01192558, dtype=float32), 'training/v_loss': Array(0.0001092, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.455, dtype=float32), 'eval/episode_reward_alive': Array(4992.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.4352, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.735616, dtype=float32), 'eval/episode_reward_alive_std': Array(7.224345, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.3042712, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87028741836548, 'eval/sps': 1067.8209150634684, 'num_steps': 6635520}
{'eval/walltime': 9986.194483995438, 'training/sps': 583.2174721756512, 'training/walltime': 11527.785780906677, 'training/entropy_loss': Array(0.01119358, dtype=float32), 'training/policy_loss': Array(-0.00396023, dtype=float32), 'training/total_loss': Array(0.0072786, dtype=float32), 'training/v_loss': Array(4.524911e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.3643, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.385368, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.952949, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1260962, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.344402, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99065947532654, 'eval/sps': 1066.7497000157784, 'num_steps': 6717440}
{'eval/walltime': 10105.958739995956, 'training/sps': 584.2972805714925, 'training/walltime': 11667.988384485245, 'training/entropy_loss': Array(0.01065133, dtype=float32), 'training/policy_loss': Array(-0.00450497, dtype=float32), 'training/total_loss': Array(0.00620334, dtype=float32), 'training/v_loss': Array(5.6976038e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.7197, dtype=float32), 'eval/episode_reward_alive': Array(4994.453, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.733749, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4342647, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8532147, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.0826366, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7642560005188, 'eval/sps': 1068.766293671507, 'num_steps': 6799360}
{'eval/walltime': 10225.77660560608, 'training/sps': 582.5619611626414, 'training/walltime': 11808.608619689941, 'training/entropy_loss': Array(0.01113296, dtype=float32), 'training/policy_loss': Array(2.29617e-05, dtype=float32), 'training/total_loss': Array(0.01122098, dtype=float32), 'training/v_loss': Array(6.5062006e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.5723, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.552844, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.264375, dtype=float32), 'eval/episode_reward_alive_std': Array(7.6801286, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.2845142, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81786561012268, 'eval/sps': 1068.2881000109057, 'num_steps': 6881280}
{'eval/walltime': 10345.637283563614, 'training/sps': 583.7030483194575, 'training/walltime': 11948.953954935074, 'training/entropy_loss': Array(0.01107783, dtype=float32), 'training/policy_loss': Array(-0.0049047, dtype=float32), 'training/total_loss': Array(0.00619717, dtype=float32), 'training/v_loss': Array(2.4049223e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.6035, dtype=float32), 'eval/episode_reward_alive': Array(4990.039, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.435502, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(25.93817, dtype=float32), 'eval/episode_reward_alive_std': Array(23.630424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.967939, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86067795753479, 'eval/sps': 1067.906524317749, 'num_steps': 6963200}
{'eval/walltime': 10465.547753572464, 'training/sps': 582.1769245214543, 'training/walltime': 12089.667192697525, 'training/entropy_loss': Array(0.01033972, dtype=float32), 'training/policy_loss': Array(-0.00463687, dtype=float32), 'training/total_loss': Array(0.00637794, dtype=float32), 'training/v_loss': Array(0.00067509, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.415, dtype=float32), 'eval/episode_reward_alive': Array(4986.836, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.42061, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(71.13032, dtype=float32), 'eval/episode_reward_alive_std': Array(69.27603, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.233085, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9104700088501, 'eval/sps': 1067.4630830031176, 'num_steps': 7045120}
{'eval/walltime': 10585.350598096848, 'training/sps': 584.4537332585411, 'training/walltime': 12229.832265377045, 'training/entropy_loss': Array(0.01067283, dtype=float32), 'training/policy_loss': Array(-0.00807279, dtype=float32), 'training/total_loss': Array(0.00275712, dtype=float32), 'training/v_loss': Array(0.00015708, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.3516, dtype=float32), 'eval/episode_reward_alive': Array(4983.164, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.812443, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(70.6323, dtype=float32), 'eval/episode_reward_alive_std': Array(68.84899, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.8953032, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80284452438354, 'eval/sps': 1068.4220438017069, 'num_steps': 7127040}
{'eval/walltime': 10705.211856126785, 'training/sps': 583.6992346722323, 'training/walltime': 12370.178517580032, 'training/entropy_loss': Array(0.00948082, dtype=float32), 'training/policy_loss': Array(-0.00572665, dtype=float32), 'training/total_loss': Array(0.00400499, dtype=float32), 'training/v_loss': Array(0.00025082, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.09, dtype=float32), 'eval/episode_reward_alive': Array(4989.6875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.597057, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(32.99734, dtype=float32), 'eval/episode_reward_alive_std': Array(31.485052, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.1196723, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86125802993774, 'eval/sps': 1067.9013561498698, 'num_steps': 7208960}
{'eval/walltime': 10825.142323970795, 'training/sps': 584.3585433225846, 'training/walltime': 12510.366422653198, 'training/entropy_loss': Array(0.00955288, dtype=float32), 'training/policy_loss': Array(-0.00923462, dtype=float32), 'training/total_loss': Array(0.00040327, dtype=float32), 'training/v_loss': Array(8.500747e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4961.548, dtype=float32), 'eval/episode_reward_alive': Array(4981.7188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.170994, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(49.42323, dtype=float32), 'eval/episode_reward_alive_std': Array(46.822628, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.252294, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9304678440094, 'eval/sps': 1067.2850886105643, 'num_steps': 7290880}
{'eval/walltime': 10944.988010406494, 'training/sps': 579.8641502623337, 'training/walltime': 12651.64089179039, 'training/entropy_loss': Array(0.0078954, dtype=float32), 'training/policy_loss': Array(-0.00670362, dtype=float32), 'training/total_loss': Array(0.00156228, dtype=float32), 'training/v_loss': Array(0.0003705, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4948.454, dtype=float32), 'eval/episode_reward_alive': Array(4972.0703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-23.616142, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(77.551544, dtype=float32), 'eval/episode_reward_alive_std': Array(76.41511, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.166117, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84568643569946, 'eval/sps': 1068.040108966922, 'num_steps': 7372800}
{'eval/walltime': 11064.92857503891, 'training/sps': 585.3675767023402, 'training/walltime': 12791.587146520615, 'training/entropy_loss': Array(0.0070232, dtype=float32), 'training/policy_loss': Array(-0.00892199, dtype=float32), 'training/total_loss': Array(0.00070114, dtype=float32), 'training/v_loss': Array(0.00259993, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.6465, dtype=float32), 'eval/episode_reward_alive': Array(4986.4844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.838068, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(83.94107, dtype=float32), 'eval/episode_reward_alive_std': Array(83.84873, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.6258948, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94056463241577, 'eval/sps': 1067.195242846189, 'num_steps': 7454720}
{'eval/walltime': 11184.76318526268, 'training/sps': 580.78693750604, 'training/walltime': 12932.637150764465, 'training/entropy_loss': Array(0.00681333, dtype=float32), 'training/policy_loss': Array(-0.01096983, dtype=float32), 'training/total_loss': Array(-0.00361839, dtype=float32), 'training/v_loss': Array(0.0005381, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.5933, dtype=float32), 'eval/episode_reward_alive': Array(4994.1797, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.586306, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6401963, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8686714, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.6071815, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83461022377014, 'eval/sps': 1068.1388270131845, 'num_steps': 7536640}
{'eval/walltime': 11304.631166934967, 'training/sps': 585.4138351727945, 'training/walltime': 13072.572347164154, 'training/entropy_loss': Array(0.00846374, dtype=float32), 'training/policy_loss': Array(-0.00686661, dtype=float32), 'training/total_loss': Array(0.00176664, dtype=float32), 'training/v_loss': Array(0.00016951, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.0225, dtype=float32), 'eval/episode_reward_alive': Array(4993.047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.023979, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1363344, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2412224, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.5301497, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86798167228699, 'eval/sps': 1067.8414553599937, 'num_steps': 7618560}
{'eval/walltime': 11424.485149145126, 'training/sps': 582.5212926038397, 'training/walltime': 13213.202399730682, 'training/entropy_loss': Array(0.00970171, dtype=float32), 'training/policy_loss': Array(-0.00640152, dtype=float32), 'training/total_loss': Array(0.00340872, dtype=float32), 'training/v_loss': Array(0.00010853, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.688, dtype=float32), 'eval/episode_reward_alive': Array(4993.9453, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.25713, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.595107, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0059223, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.3272557, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8539822101593, 'eval/sps': 1067.9661838482511, 'num_steps': 7700480}
{'eval/walltime': 11544.361819028854, 'training/sps': 585.4396773544446, 'training/walltime': 13353.131419181824, 'training/entropy_loss': Array(0.00936718, dtype=float32), 'training/policy_loss': Array(-0.00465501, dtype=float32), 'training/total_loss': Array(0.00484243, dtype=float32), 'training/v_loss': Array(0.00013027, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.9727, dtype=float32), 'eval/episode_reward_alive': Array(4993.3203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.347609, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.692381, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8544393, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.7732381, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87666988372803, 'eval/sps': 1067.7640622162014, 'num_steps': 7782400}
{'eval/walltime': 11664.247583150864, 'training/sps': 584.3064736366624, 'training/walltime': 13493.331816911697, 'training/entropy_loss': Array(0.00878531, dtype=float32), 'training/policy_loss': Array(-0.00396207, dtype=float32), 'training/total_loss': Array(0.00490467, dtype=float32), 'training/v_loss': Array(8.142421e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4954.369, dtype=float32), 'eval/episode_reward_alive': Array(4971.5625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.193642, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(247.76642, dtype=float32), 'eval/episode_reward_alive_std': Array(247.80894, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.84028643, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88576412200928, 'eval/sps': 1067.6830642688549, 'num_steps': 7864320}
{'eval/walltime': 11784.11884880066, 'training/sps': 584.5166277508489, 'training/walltime': 13633.48180770874, 'training/entropy_loss': Array(0.00860193, dtype=float32), 'training/policy_loss': Array(-0.00204288, dtype=float32), 'training/total_loss': Array(0.00686455, dtype=float32), 'training/v_loss': Array(0.00030551, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.4287, dtype=float32), 'eval/episode_reward_alive': Array(4988.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.243263, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(37.261326, dtype=float32), 'eval/episode_reward_alive_std': Array(37.32503, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.4060487, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87126564979553, 'eval/sps': 1067.8122009152103, 'num_steps': 7946240}
{'eval/walltime': 11903.911232709885, 'training/sps': 584.2455248007874, 'training/walltime': 13773.696831226349, 'training/entropy_loss': Array(0.00874553, dtype=float32), 'training/policy_loss': Array(-0.00693453, dtype=float32), 'training/total_loss': Array(0.00193069, dtype=float32), 'training/v_loss': Array(0.0001197, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.6885, dtype=float32), 'eval/episode_reward_alive': Array(4982.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.084831, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(73.11013, dtype=float32), 'eval/episode_reward_alive_std': Array(73.5798, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1888548, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79238390922546, 'eval/sps': 1068.51534148443, 'num_steps': 8028160}
{'eval/walltime': 12023.65935087204, 'training/sps': 585.6112743095508, 'training/walltime': 13913.58484840393, 'training/entropy_loss': Array(0.00875995, dtype=float32), 'training/policy_loss': Array(-0.00563162, dtype=float32), 'training/total_loss': Array(0.00657839, dtype=float32), 'training/v_loss': Array(0.00345006, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.7866, dtype=float32), 'eval/episode_reward_alive': Array(4987.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.181765, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(67.16697, dtype=float32), 'eval/episode_reward_alive_std': Array(67.20548, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9074338, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74811816215515, 'eval/sps': 1068.9103258113057, 'num_steps': 8110080}
{'eval/walltime': 12143.561892747879, 'training/sps': 582.8972028475708, 'training/walltime': 14054.124208688736, 'training/entropy_loss': Array(0.00898444, dtype=float32), 'training/policy_loss': Array(-0.01243326, dtype=float32), 'training/total_loss': Array(-0.00335953, dtype=float32), 'training/v_loss': Array(8.929049e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4945.16, dtype=float32), 'eval/episode_reward_alive': Array(4961.914, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.752945, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(201.63629, dtype=float32), 'eval/episode_reward_alive_std': Array(199.73236, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.6008132, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90254187583923, 'eval/sps': 1067.5336652374376, 'num_steps': 8192000}
{'eval/walltime': 12263.381365537643, 'training/sps': 585.2507393539448, 'training/walltime': 14194.098401784897, 'training/entropy_loss': Array(0.00862835, dtype=float32), 'training/policy_loss': Array(-4.7290312e-05, dtype=float32), 'training/total_loss': Array(0.01171109, dtype=float32), 'training/v_loss': Array(0.00313003, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4778.3804, dtype=float32), 'eval/episode_reward_alive': Array(4798.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.603483, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(567.2514, dtype=float32), 'eval/episode_reward_alive_std': Array(563.52765, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.44103, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8194727897644, 'eval/sps': 1068.2737706965977, 'num_steps': 8273920}
{'eval/walltime': 12383.276596784592, 'training/sps': 583.9361075222862, 'training/walltime': 14334.387722730637, 'training/entropy_loss': Array(0.00774746, dtype=float32), 'training/policy_loss': Array(-0.0093087, dtype=float32), 'training/total_loss': Array(0.01203459, dtype=float32), 'training/v_loss': Array(0.01359584, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4751.7764, dtype=float32), 'eval/episode_reward_alive': Array(4777.1094, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-25.332504, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(443.09637, dtype=float32), 'eval/episode_reward_alive_std': Array(438.06464, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.61126, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.89523124694824, 'eval/sps': 1067.598758255517, 'num_steps': 8355840}
{'eval/walltime': 12502.9638235569, 'training/sps': 585.4369561773623, 'training/walltime': 14474.317392587662, 'training/entropy_loss': Array(0.0077221, dtype=float32), 'training/policy_loss': Array(-0.00763508, dtype=float32), 'training/total_loss': Array(0.01202174, dtype=float32), 'training/v_loss': Array(0.01193472, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4926.4644, dtype=float32), 'eval/episode_reward_alive': Array(4952.6953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-26.231281, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(140.45636, dtype=float32), 'eval/episode_reward_alive_std': Array(137.62622, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.057955, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.68722677230835, 'eval/sps': 1069.4541385231173, 'num_steps': 8437760}
{'eval/walltime': 12622.940656423569, 'training/sps': 581.3823711732642, 'training/walltime': 14615.222937822342, 'training/entropy_loss': Array(0.00721681, dtype=float32), 'training/policy_loss': Array(-0.01326857, dtype=float32), 'training/total_loss': Array(0.00389897, dtype=float32), 'training/v_loss': Array(0.00995073, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4933.8633, dtype=float32), 'eval/episode_reward_alive': Array(4963.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-29.730637, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(139.75198, dtype=float32), 'eval/episode_reward_alive_std': Array(140.40808, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(10.226079, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9768328666687, 'eval/sps': 1066.8726365051452, 'num_steps': 8519680}
{'eval/walltime': 12742.690167665482, 'training/sps': 585.2819905844173, 'training/walltime': 14755.189656972885, 'training/entropy_loss': Array(0.00724764, dtype=float32), 'training/policy_loss': Array(-0.00731186, dtype=float32), 'training/total_loss': Array(0.00566242, dtype=float32), 'training/v_loss': Array(0.00572665, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4927.3984, dtype=float32), 'eval/episode_reward_alive': Array(4955.586, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-28.1872, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(182.22208, dtype=float32), 'eval/episode_reward_alive_std': Array(182.65898, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.793566, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74951124191284, 'eval/sps': 1068.8978908767308, 'num_steps': 8601600}
{'eval/walltime': 12862.55317902565, 'training/sps': 584.8228901027263, 'training/walltime': 14895.266253471375, 'training/entropy_loss': Array(0.00718079, dtype=float32), 'training/policy_loss': Array(-0.00533098, dtype=float32), 'training/total_loss': Array(0.00285856, dtype=float32), 'training/v_loss': Array(0.00100875, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4962.794, dtype=float32), 'eval/episode_reward_alive': Array(4986.5234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-23.72934, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(49.236893, dtype=float32), 'eval/episode_reward_alive_std': Array(48.900246, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.391382, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86301136016846, 'eval/sps': 1067.8857351195795, 'num_steps': 8683520}
{'eval/walltime': 12982.369820833206, 'training/sps': 584.8490076534646, 'training/walltime': 15035.336594581604, 'training/entropy_loss': Array(0.00763964, dtype=float32), 'training/policy_loss': Array(-0.00562066, dtype=float32), 'training/total_loss': Array(0.0034732, dtype=float32), 'training/v_loss': Array(0.00145422, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4964.8203, dtype=float32), 'eval/episode_reward_alive': Array(4990.8984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-26.07727, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(25.085283, dtype=float32), 'eval/episode_reward_alive_std': Array(22.976154, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.771436, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81664180755615, 'eval/sps': 1068.2990114644306, 'num_steps': 8765440}
{'eval/walltime': 13102.319966554642, 'training/sps': 584.3652069803139, 'training/walltime': 15175.522901058197, 'training/entropy_loss': Array(0.00767568, dtype=float32), 'training/policy_loss': Array(-0.01117983, dtype=float32), 'training/total_loss': Array(-0.00332665, dtype=float32), 'training/v_loss': Array(0.00017749, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4968.4385, dtype=float32), 'eval/episode_reward_alive': Array(4991.133, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-22.693707, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(21.791548, dtype=float32), 'eval/episode_reward_alive_std': Array(20.881126, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.9634433, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95014572143555, 'eval/sps': 1067.1099999933215, 'num_steps': 8847360}
{'eval/walltime': 13222.176403045654, 'training/sps': 585.8268808711114, 'training/walltime': 15315.359434127808, 'training/entropy_loss': Array(0.00780005, dtype=float32), 'training/policy_loss': Array(-0.01168206, dtype=float32), 'training/total_loss': Array(-0.00379063, dtype=float32), 'training/v_loss': Array(9.137958e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.9893, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.66661, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.02436, dtype=float32), 'eval/episode_reward_alive_std': Array(6.929824, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.6625004, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85643649101257, 'eval/sps': 1067.9443152775368, 'num_steps': 8929280}
{'eval/walltime': 13342.143767118454, 'training/sps': 584.3114568122336, 'training/walltime': 15455.558636188507, 'training/entropy_loss': Array(0.00856982, dtype=float32), 'training/policy_loss': Array(-0.01173295, dtype=float32), 'training/total_loss': Array(-0.00310563, dtype=float32), 'training/v_loss': Array(5.7498342e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.076, dtype=float32), 'eval/episode_reward_alive': Array(4992.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.697517, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1635976, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0657787, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.624236, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96736407279968, 'eval/sps': 1066.9568427153729, 'num_steps': 9011200}
{'eval/walltime': 13461.87405014038, 'training/sps': 584.9580094246271, 'training/walltime': 15595.60287642479, 'training/entropy_loss': Array(0.00855291, dtype=float32), 'training/policy_loss': Array(-0.01013856, dtype=float32), 'training/total_loss': Array(-0.00151718, dtype=float32), 'training/v_loss': Array(6.84706e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.1846, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.47173, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.576654, dtype=float32), 'eval/episode_reward_alive_std': Array(7.287015, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.4440649, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.73028302192688, 'eval/sps': 1069.0695517403783, 'num_steps': 9093120}
{'eval/walltime': 13581.721098184586, 'training/sps': 584.2918068009806, 'training/walltime': 15735.80679345131, 'training/entropy_loss': Array(0.00900318, dtype=float32), 'training/policy_loss': Array(-0.0127472, dtype=float32), 'training/total_loss': Array(-0.00370323, dtype=float32), 'training/v_loss': Array(4.0793377e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.4893, dtype=float32), 'eval/episode_reward_alive': Array(4994.1016, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.61302, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.222433, dtype=float32), 'eval/episode_reward_alive_std': Array(7.246594, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.250284, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84704804420471, 'eval/sps': 1068.027974729825, 'num_steps': 9175040}
{'eval/walltime': 13701.572084188461, 'training/sps': 585.3127137132718, 'training/walltime': 15875.766165733337, 'training/entropy_loss': Array(0.00865343, dtype=float32), 'training/policy_loss': Array(-0.01010103, dtype=float32), 'training/total_loss': Array(-0.0013851, dtype=float32), 'training/v_loss': Array(6.249748e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.9233, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.592342, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.338229, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1904716, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.9770286, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85098600387573, 'eval/sps': 1067.992882393648, 'num_steps': 9256960}
{'eval/walltime': 13821.518748760223, 'training/sps': 583.922525045288, 'training/walltime': 16016.05874991417, 'training/entropy_loss': Array(0.0085294, dtype=float32), 'training/policy_loss': Array(-0.01616208, dtype=float32), 'training/total_loss': Array(-0.00759039, dtype=float32), 'training/v_loss': Array(4.2284984e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.7954, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.56371, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.605645, dtype=float32), 'eval/episode_reward_alive_std': Array(7.018652, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.0920472, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94666457176208, 'eval/sps': 1067.1409701719529, 'num_steps': 9338880}
{'eval/walltime': 13941.384162902832, 'training/sps': 585.8621124927625, 'training/walltime': 16155.886873722076, 'training/entropy_loss': Array(0.00876931, dtype=float32), 'training/policy_loss': Array(-0.00990039, dtype=float32), 'training/total_loss': Array(-0.00107146, dtype=float32), 'training/v_loss': Array(5.9612103e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.458, dtype=float32), 'eval/episode_reward_alive': Array(4994.7266, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.268637, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.76662, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7981095, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.7022653, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86541414260864, 'eval/sps': 1067.864328635392, 'num_steps': 9420800}
{'eval/walltime': 14061.348125457764, 'training/sps': 584.1381657631559, 'training/walltime': 16296.127667427063, 'training/entropy_loss': Array(0.00874519, dtype=float32), 'training/policy_loss': Array(-0.01279323, dtype=float32), 'training/total_loss': Array(-0.00400988, dtype=float32), 'training/v_loss': Array(3.8155325e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.478, dtype=float32), 'eval/episode_reward_alive': Array(4994.5703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.092503, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.501688, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7322493, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.5547073, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96396255493164, 'eval/sps': 1066.9870957404282, 'num_steps': 9502720}
{'eval/walltime': 14181.122255325317, 'training/sps': 585.9652735814333, 'training/walltime': 16435.93117403984, 'training/entropy_loss': Array(0.00912109, dtype=float32), 'training/policy_loss': Array(-0.00631423, dtype=float32), 'training/total_loss': Array(0.00285773, dtype=float32), 'training/v_loss': Array(5.0867457e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.924, dtype=float32), 'eval/episode_reward_alive': Array(4992.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.849974, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7911077, dtype=float32), 'eval/episode_reward_alive_std': Array(7.175495, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.8803765, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77412986755371, 'eval/sps': 1068.6781873643538, 'num_steps': 9584640}
{'eval/walltime': 14301.197143316269, 'training/sps': 582.0165853359487, 'training/walltime': 16576.683176755905, 'training/entropy_loss': Array(0.00903587, dtype=float32), 'training/policy_loss': Array(-0.00760126, dtype=float32), 'training/total_loss': Array(0.00148304, dtype=float32), 'training/v_loss': Array(4.8427806e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.298, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.218262, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.558474, dtype=float32), 'eval/episode_reward_alive_std': Array(6.741875, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.571343, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.07488799095154, 'eval/sps': 1066.0014107999473, 'num_steps': 9666560}
{'eval/walltime': 14421.039801836014, 'training/sps': 585.2381044284376, 'training/walltime': 16716.660391807556, 'training/entropy_loss': Array(0.00952266, dtype=float32), 'training/policy_loss': Array(-0.00911497, dtype=float32), 'training/total_loss': Array(0.00043687, dtype=float32), 'training/v_loss': Array(2.9178449e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.523, dtype=float32), 'eval/episode_reward_alive': Array(4994.1797, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.656883, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6673007, dtype=float32), 'eval/episode_reward_alive_std': Array(6.897048, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.5110964, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84265851974487, 'eval/sps': 1068.067093812936, 'num_steps': 9748480}
{'eval/walltime': 14541.095268249512, 'training/sps': 584.4750067815181, 'training/walltime': 16856.82036280632, 'training/entropy_loss': Array(0.00936988, dtype=float32), 'training/policy_loss': Array(-0.00626792, dtype=float32), 'training/total_loss': Array(0.00314956, dtype=float32), 'training/v_loss': Array(4.760213e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.5664, dtype=float32), 'eval/episode_reward_alive': Array(4992.5, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.933847, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(15.728107, dtype=float32), 'eval/episode_reward_alive_std': Array(15.7619, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2624526, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.05546641349792, 'eval/sps': 1066.173859665326, 'num_steps': 9830400}
{'eval/walltime': 14660.843987941742, 'training/sps': 585.3186134416022, 'training/walltime': 16996.778324365616, 'training/entropy_loss': Array(0.00935442, dtype=float32), 'training/policy_loss': Array(-0.00670819, dtype=float32), 'training/total_loss': Array(0.00267777, dtype=float32), 'training/v_loss': Array(3.155086e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.2334, dtype=float32), 'eval/episode_reward_alive': Array(4993.9453, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.711857, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.5817103, dtype=float32), 'eval/episode_reward_alive_std': Array(6.779229, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1621076, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74871969223022, 'eval/sps': 1068.9049563868127, 'num_steps': 9912320}
{'eval/walltime': 14780.900140047073, 'training/sps': 584.2824582077269, 'training/walltime': 17136.984484672546, 'training/entropy_loss': Array(0.00934604, dtype=float32), 'training/policy_loss': Array(-0.00615381, dtype=float32), 'training/total_loss': Array(0.00323571, dtype=float32), 'training/v_loss': Array(4.348336e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.9727, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.855696, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.796014, dtype=float32), 'eval/episode_reward_alive_std': Array(6.973285, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2601658, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.05615210533142, 'eval/sps': 1066.16777029218, 'num_steps': 9994240}
{'eval/walltime': 14900.600853204727, 'training/sps': 585.3021469460164, 'training/walltime': 17276.946383714676, 'training/entropy_loss': Array(0.00950761, dtype=float32), 'training/policy_loss': Array(-0.00789756, dtype=float32), 'training/total_loss': Array(0.0016479, dtype=float32), 'training/v_loss': Array(3.784797e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.7617, dtype=float32), 'eval/episode_reward_alive': Array(4994.414, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.65253, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.441468, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6620746, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1651857, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.70071315765381, 'eval/sps': 1069.3336457520975, 'num_steps': 10076160}
{'eval/walltime': 15020.646265745163, 'training/sps': 583.4704227794348, 'training/walltime': 17417.347673654556, 'training/entropy_loss': Array(0.0100021, dtype=float32), 'training/policy_loss': Array(-0.00371977, dtype=float32), 'training/total_loss': Array(0.00632678, dtype=float32), 'training/v_loss': Array(4.444889e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.3604, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.23298, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.699806, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8161545, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7021856, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04541254043579, 'eval/sps': 1066.2631523456575, 'num_steps': 10158080}
{'eval/walltime': 15140.32357597351, 'training/sps': 585.4168394037166, 'training/walltime': 17557.282151937485, 'training/entropy_loss': Array(0.00970723, dtype=float32), 'training/policy_loss': Array(-0.00238805, dtype=float32), 'training/total_loss': Array(0.00735064, dtype=float32), 'training/v_loss': Array(3.1454467e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.2866, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.07314, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7930603, dtype=float32), 'eval/episode_reward_alive_std': Array(7.074088, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2472736, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.67731022834778, 'eval/sps': 1069.5427542261125, 'num_steps': 10240000}
{'eval/walltime': 15260.445709705353, 'training/sps': 583.6200259961219, 'training/walltime': 17697.647451877594, 'training/entropy_loss': Array(0.01027904, dtype=float32), 'training/policy_loss': Array(0.00308819, dtype=float32), 'training/total_loss': Array(0.01371947, dtype=float32), 'training/v_loss': Array(0.00035225, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.2, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.92532, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8395743, dtype=float32), 'eval/episode_reward_alive_std': Array(7.180703, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.0402182, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.12213373184204, 'eval/sps': 1065.5821373082194, 'num_steps': 10321920}
{'eval/walltime': 15380.131433010101, 'training/sps': 585.6949470312701, 'training/walltime': 17837.515484571457, 'training/entropy_loss': Array(0.01035965, dtype=float32), 'training/policy_loss': Array(-0.00795325, dtype=float32), 'training/total_loss': Array(0.00244894, dtype=float32), 'training/v_loss': Array(4.253043e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.145, dtype=float32), 'eval/episode_reward_alive': Array(4992.5, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.354603, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.520067, dtype=float32), 'eval/episode_reward_alive_std': Array(6.731456, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8885832, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.68572330474854, 'eval/sps': 1069.467572787118, 'num_steps': 10403840}
{'eval/walltime': 15500.318572044373, 'training/sps': 584.3076073885804, 'training/walltime': 17977.71561026573, 'training/entropy_loss': Array(0.01081313, dtype=float32), 'training/policy_loss': Array(-0.00534064, dtype=float32), 'training/total_loss': Array(0.00550049, dtype=float32), 'training/v_loss': Array(2.7993356e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.6665, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.966059, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7708, dtype=float32), 'eval/episode_reward_alive_std': Array(6.895278, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7499897, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.18713903427124, 'eval/sps': 1065.0057986944921, 'num_steps': 10485760}
{'eval/walltime': 15620.148047685623, 'training/sps': 585.5487347811044, 'training/walltime': 18117.61856818199, 'training/entropy_loss': Array(0.01079897, dtype=float32), 'training/policy_loss': Array(-0.00276861, dtype=float32), 'training/total_loss': Array(0.00807176, dtype=float32), 'training/v_loss': Array(4.1402473e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.1084, dtype=float32), 'eval/episode_reward_alive': Array(4989.2188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.110382, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(46.511036, dtype=float32), 'eval/episode_reward_alive_std': Array(47.034885, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.84619385, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82947564125061, 'eval/sps': 1068.18459577684, 'num_steps': 10567680}
{'eval/walltime': 15740.127103090286, 'training/sps': 583.1068420275304, 'training/walltime': 18258.10740160942, 'training/entropy_loss': Array(0.01105894, dtype=float32), 'training/policy_loss': Array(-0.00289665, dtype=float32), 'training/total_loss': Array(0.0081921, dtype=float32), 'training/v_loss': Array(2.9810559e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.034, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.622193, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.489479, dtype=float32), 'eval/episode_reward_alive_std': Array(6.52332, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7165777, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.97905540466309, 'eval/sps': 1066.8528733476358, 'num_steps': 10649600}
{'eval/walltime': 15859.874846696854, 'training/sps': 585.9770325269527, 'training/walltime': 18397.90810275078, 'training/entropy_loss': Array(0.01130346, dtype=float32), 'training/policy_loss': Array(-0.00349237, dtype=float32), 'training/total_loss': Array(0.0078539, dtype=float32), 'training/v_loss': Array(4.2818e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.1885, dtype=float32), 'eval/episode_reward_alive': Array(4992.1094, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.920849, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7795806, dtype=float32), 'eval/episode_reward_alive_std': Array(6.835379, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.775399, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74774360656738, 'eval/sps': 1068.9136692257475, 'num_steps': 10731520}
{'eval/walltime': 15980.030364990234, 'training/sps': 583.4831707449173, 'training/walltime': 18538.30632519722, 'training/entropy_loss': Array(0.01151139, dtype=float32), 'training/policy_loss': Array(-0.00327237, dtype=float32), 'training/total_loss': Array(0.00826704, dtype=float32), 'training/v_loss': Array(2.802062e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.516, dtype=float32), 'eval/episode_reward_alive': Array(4992.8516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.335199, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.552201, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6931515, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.71299493, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.15551829338074, 'eval/sps': 1065.2860710688758, 'num_steps': 10813440}
{'eval/walltime': 16099.851984024048, 'training/sps': 585.2812488424382, 'training/walltime': 18678.273221731186, 'training/entropy_loss': Array(0.01201503, dtype=float32), 'training/policy_loss': Array(-0.00335056, dtype=float32), 'training/total_loss': Array(0.00869983, dtype=float32), 'training/v_loss': Array(3.53599e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.511, dtype=float32), 'eval/episode_reward_alive': Array(4993.2812, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.770152, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6180286, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8304663, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8048906, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82161903381348, 'eval/sps': 1068.2546357838696, 'num_steps': 10895360}
{'eval/walltime': 16219.820711374283, 'training/sps': 584.2996712175471, 'training/walltime': 18818.475251674652, 'training/entropy_loss': Array(0.01194902, dtype=float32), 'training/policy_loss': Array(-0.0024229, dtype=float32), 'training/total_loss': Array(0.00956397, dtype=float32), 'training/v_loss': Array(3.784772e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.3496, dtype=float32), 'eval/episode_reward_alive': Array(4993.3203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.970566, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7897797, dtype=float32), 'eval/episode_reward_alive_std': Array(6.99546, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7442792, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96872735023499, 'eval/sps': 1066.944718237434, 'num_steps': 10977280}
{'eval/walltime': 16339.678915977478, 'training/sps': 585.4378080387289, 'training/walltime': 18958.40471792221, 'training/entropy_loss': Array(0.01198244, dtype=float32), 'training/policy_loss': Array(-0.00270156, dtype=float32), 'training/total_loss': Array(0.00930439, dtype=float32), 'training/v_loss': Array(2.3511337e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.107, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.720806, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.258673, dtype=float32), 'eval/episode_reward_alive_std': Array(6.3886, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.786185, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85820460319519, 'eval/sps': 1067.9285612842207, 'num_steps': 11059200}
{'eval/walltime': 16459.76879477501, 'training/sps': 584.5672172395493, 'training/walltime': 19098.542579889297, 'training/entropy_loss': Array(0.01194201, dtype=float32), 'training/policy_loss': Array(-0.00281218, dtype=float32), 'training/total_loss': Array(0.00916249, dtype=float32), 'training/v_loss': Array(3.2661017e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.7183, dtype=float32), 'eval/episode_reward_alive': Array(4993.2812, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.563249, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7479553, dtype=float32), 'eval/episode_reward_alive_std': Array(6.887418, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7239319, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.08987879753113, 'eval/sps': 1065.8683419591518, 'num_steps': 11141120}
{'eval/walltime': 16579.66511440277, 'training/sps': 585.59123637431, 'training/walltime': 19238.435383796692, 'training/entropy_loss': Array(0.01226722, dtype=float32), 'training/policy_loss': Array(-0.00409201, dtype=float32), 'training/total_loss': Array(0.00820101, dtype=float32), 'training/v_loss': Array(2.5799869e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.0576, dtype=float32), 'eval/episode_reward_alive': Array(4993.164, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.106846, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.776765, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7277145, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.68402874, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.89631962776184, 'eval/sps': 1067.589066932141, 'num_steps': 11223040}
{'eval/walltime': 16699.628381729126, 'training/sps': 584.2758103466409, 'training/walltime': 19378.643139362335, 'training/entropy_loss': Array(0.01225721, dtype=float32), 'training/policy_loss': Array(-0.00096049, dtype=float32), 'training/total_loss': Array(0.01133317, dtype=float32), 'training/v_loss': Array(3.6443555e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.1772, dtype=float32), 'eval/episode_reward_alive': Array(4993.3203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.142882, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8655953, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7104554, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.86331224, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96326732635498, 'eval/sps': 1066.9932792992495, 'num_steps': 11304960}
{'eval/walltime': 16819.518363952637, 'training/sps': 585.8603243891372, 'training/walltime': 19518.4716899395, 'training/entropy_loss': Array(0.01272145, dtype=float32), 'training/policy_loss': Array(0.0128731, dtype=float32), 'training/total_loss': Array(0.02561982, dtype=float32), 'training/v_loss': Array(2.5274292e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.631, dtype=float32), 'eval/episode_reward_alive': Array(4994.8047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.173357, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.189617, dtype=float32), 'eval/episode_reward_alive_std': Array(6.2936707, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.49822003, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88998222351074, 'eval/sps': 1067.6454998664506, 'num_steps': 11386880}
{'eval/walltime': 16939.593087673187, 'training/sps': 584.3480497362888, 'training/walltime': 19658.66211247444, 'training/entropy_loss': Array(0.01244002, dtype=float32), 'training/policy_loss': Array(0.00170718, dtype=float32), 'training/total_loss': Array(0.01418164, dtype=float32), 'training/v_loss': Array(3.4438643e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.256, dtype=float32), 'eval/episode_reward_alive': Array(4994.414, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.158199, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6298532, dtype=float32), 'eval/episode_reward_alive_std': Array(6.573535, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.52011776, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.07472372055054, 'eval/sps': 1066.0028691624887, 'num_steps': 11468800}
{'eval/walltime': 17059.420606136322, 'training/sps': 586.0935432374998, 'training/walltime': 19798.435022354126, 'training/entropy_loss': Array(0.01247992, dtype=float32), 'training/policy_loss': Array(0.00450536, dtype=float32), 'training/total_loss': Array(0.01700848, dtype=float32), 'training/v_loss': Array(2.3202094e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.8765, dtype=float32), 'eval/episode_reward_alive': Array(4994.1406, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.264607, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9522233, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8496513, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7158256, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82751846313477, 'eval/sps': 1068.2020427501343, 'num_steps': 11550720}
{'eval/walltime': 17179.46692752838, 'training/sps': 584.2486680567787, 'training/walltime': 19938.64929151535, 'training/entropy_loss': Array(0.01242605, dtype=float32), 'training/policy_loss': Array(0.00522793, dtype=float32), 'training/total_loss': Array(0.01768768, dtype=float32), 'training/v_loss': Array(3.370407e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.531, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.297227, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6991763, dtype=float32), 'eval/episode_reward_alive_std': Array(6.569472, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.48557377, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04632139205933, 'eval/sps': 1066.2550798367636, 'num_steps': 11632640}
{'eval/walltime': 17299.342680215836, 'training/sps': 585.2747297690112, 'training/walltime': 20078.617747068405, 'training/entropy_loss': Array(0.01239935, dtype=float32), 'training/policy_loss': Array(-0.00120794, dtype=float32), 'training/total_loss': Array(0.01122704, dtype=float32), 'training/v_loss': Array(3.563839e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.0034, dtype=float32), 'eval/episode_reward_alive': Array(4994.297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.293468, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.655194, dtype=float32), 'eval/episode_reward_alive_std': Array(6.636028, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.32521114, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87575268745422, 'eval/sps': 1067.7722319185573, 'num_steps': 11714560}
{'eval/walltime': 17419.506935834885, 'training/sps': 582.7550080665118, 'training/walltime': 20219.19139957428, 'training/entropy_loss': Array(0.01251226, dtype=float32), 'training/policy_loss': Array(-0.0097373, dtype=float32), 'training/total_loss': Array(0.00279611, dtype=float32), 'training/v_loss': Array(2.114937e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.163, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.313073, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.925278, dtype=float32), 'eval/episode_reward_alive_std': Array(6.947307, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.51547784, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.16425561904907, 'eval/sps': 1065.2086124994792, 'num_steps': 11796480}
{'eval/walltime': 17539.29921936989, 'training/sps': 585.471497452631, 'training/walltime': 20359.112813949585, 'training/entropy_loss': Array(0.01232097, dtype=float32), 'training/policy_loss': Array(0.00256255, dtype=float32), 'training/total_loss': Array(0.01491622, dtype=float32), 'training/v_loss': Array(3.2704498e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.6807, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.186619, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.029175, dtype=float32), 'eval/episode_reward_alive_std': Array(6.965732, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.6390967, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79228353500366, 'eval/sps': 1068.51623679582, 'num_steps': 11878400}
{'eval/walltime': 17659.40511226654, 'training/sps': 582.6882499293883, 'training/walltime': 20499.702571868896, 'training/entropy_loss': Array(0.01262119, dtype=float32), 'training/policy_loss': Array(-0.00786352, dtype=float32), 'training/total_loss': Array(0.00478286, dtype=float32), 'training/v_loss': Array(2.5186915e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.398, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.039302, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8662896, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8393965, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.28092226, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.10589289665222, 'eval/sps': 1065.7262263571067, 'num_steps': 11960320}
{'eval/walltime': 17779.236698627472, 'training/sps': 585.610221328177, 'training/walltime': 20639.59084057808, 'training/entropy_loss': Array(0.01257987, dtype=float32), 'training/policy_loss': Array(-0.00419717, dtype=float32), 'training/total_loss': Array(0.00841592, dtype=float32), 'training/v_loss': Array(3.3217853e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.8984, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.930022, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1945295, dtype=float32), 'eval/episode_reward_alive_std': Array(7.13936, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.32547405, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8315863609314, 'eval/sps': 1068.1657807188285, 'num_steps': 12042240}
{'eval/walltime': 17899.25649523735, 'training/sps': 583.8105589362784, 'training/walltime': 20779.9103307724, 'training/entropy_loss': Array(0.01265644, dtype=float32), 'training/policy_loss': Array(-0.00816002, dtype=float32), 'training/total_loss': Array(0.00451978, dtype=float32), 'training/v_loss': Array(2.336422e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.3013, dtype=float32), 'eval/episode_reward_alive': Array(4993.3203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.019384, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.056298, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9393954, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.34422418, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01979660987854, 'eval/sps': 1066.490725826348, 'num_steps': 12124160}
{'eval/walltime': 18019.06615638733, 'training/sps': 585.2622224075756, 'training/walltime': 20919.881777524948, 'training/entropy_loss': Array(0.01277448, dtype=float32), 'training/policy_loss': Array(-0.00630359, dtype=float32), 'training/total_loss': Array(0.00650197, dtype=float32), 'training/v_loss': Array(3.1080883e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.496, dtype=float32), 'eval/episode_reward_alive': Array(4994.297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.800632, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7465067, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6946335, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.33907774, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80966114997864, 'eval/sps': 1068.3612554397314, 'num_steps': 12206080}
{'eval/walltime': 18139.034774541855, 'training/sps': 583.4533556853594, 'training/walltime': 21060.287174463272, 'training/entropy_loss': Array(0.01280947, dtype=float32), 'training/policy_loss': Array(0.01790068, dtype=float32), 'training/total_loss': Array(0.03077836, dtype=float32), 'training/v_loss': Array(6.821036e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.332, dtype=float32), 'eval/episode_reward_alive': Array(4994.883, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.550568, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.349195, dtype=float32), 'eval/episode_reward_alive_std': Array(6.3265576, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.27698007, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96861815452576, 'eval/sps': 1066.9456893729443, 'num_steps': 12288000}
{'eval/walltime': 18258.87175130844, 'training/sps': 585.3531646862374, 'training/walltime': 21200.236874818802, 'training/entropy_loss': Array(0.01303605, dtype=float32), 'training/policy_loss': Array(-0.00884451, dtype=float32), 'training/total_loss': Array(0.00422787, dtype=float32), 'training/v_loss': Array(3.633318e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.9785, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.458723, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8120666, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8107796, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2491336, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8369767665863, 'eval/sps': 1068.1177333880285, 'num_steps': 12369920}
{'eval/walltime': 18378.805057048798, 'training/sps': 583.4758296481117, 'training/walltime': 21340.636863708496, 'training/entropy_loss': Array(0.01291116, dtype=float32), 'training/policy_loss': Array(-0.01078787, dtype=float32), 'training/total_loss': Array(0.00215811, dtype=float32), 'training/v_loss': Array(3.482285e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.965, dtype=float32), 'eval/episode_reward_alive': Array(4993.242, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.277338, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.981214, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9481854, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21984997, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.93330574035645, 'eval/sps': 1067.2598342040794, 'num_steps': 12451840}
{'eval/walltime': 18498.557037830353, 'training/sps': 585.0853313096628, 'training/walltime': 21480.650628566742, 'training/entropy_loss': Array(0.01324022, dtype=float32), 'training/policy_loss': Array(0.00307312, dtype=float32), 'training/total_loss': Array(0.01633577, dtype=float32), 'training/v_loss': Array(2.2423985e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.0044, dtype=float32), 'eval/episode_reward_alive': Array(4993.047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.042378, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2226357, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1325173, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21259719, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.75198078155518, 'eval/sps': 1068.875847936832, 'num_steps': 12533760}
{'eval/walltime': 18618.581171035767, 'training/sps': 583.4383115915185, 'training/walltime': 21621.05964589119, 'training/entropy_loss': Array(0.01320266, dtype=float32), 'training/policy_loss': Array(-0.00384633, dtype=float32), 'training/total_loss': Array(0.00939227, dtype=float32), 'training/v_loss': Array(3.594323e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.3013, dtype=float32), 'eval/episode_reward_alive': Array(4994.1406, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.839167, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.883866, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8210773, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20548281, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02413320541382, 'eval/sps': 1066.4521924181363, 'num_steps': 12615680}
{'eval/walltime': 18738.371262073517, 'training/sps': 585.5515537922215, 'training/walltime': 21760.961930274963, 'training/entropy_loss': Array(0.01344947, dtype=float32), 'training/policy_loss': Array(-0.01068133, dtype=float32), 'training/total_loss': Array(0.0027881, dtype=float32), 'training/v_loss': Array(1.995251e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.954, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.71728, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0616465, dtype=float32), 'eval/episode_reward_alive_std': Array(6.973285, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.36343205, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79009103775024, 'eval/sps': 1068.5357936631212, 'num_steps': 12697600}
{'eval/walltime': 18858.21255660057, 'training/sps': 583.7569216581849, 'training/walltime': 21901.294313430786, 'training/entropy_loss': Array(0.01349937, dtype=float32), 'training/policy_loss': Array(-0.0065952, dtype=float32), 'training/total_loss': Array(0.00694194, dtype=float32), 'training/v_loss': Array(3.7764476e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.831, dtype=float32), 'eval/episode_reward_alive': Array(4992.3438, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.512564, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.355725, dtype=float32), 'eval/episode_reward_alive_std': Array(7.287015, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2884573, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84129452705383, 'eval/sps': 1068.0792501878755, 'num_steps': 12779520}
{'eval/walltime': 18978.078556776047, 'training/sps': 585.6697361869449, 'training/walltime': 22041.168366909027, 'training/entropy_loss': Array(0.01389455, dtype=float32), 'training/policy_loss': Array(-0.00766635, dtype=float32), 'training/total_loss': Array(0.00625063, dtype=float32), 'training/v_loss': Array(2.2435806e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.128, dtype=float32), 'eval/episode_reward_alive': Array(4993.3203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.1923485, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3663545, dtype=float32), 'eval/episode_reward_alive_std': Array(7.296118, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.434496, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86600017547607, 'eval/sps': 1067.859107775485, 'num_steps': 12861440}
{'eval/walltime': 19098.06981444359, 'training/sps': 583.8549763204308, 'training/walltime': 22181.477182149887, 'training/entropy_loss': Array(0.01376905, dtype=float32), 'training/policy_loss': Array(-0.00530868, dtype=float32), 'training/total_loss': Array(0.00849295, dtype=float32), 'training/v_loss': Array(3.2583775e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.682, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.325688, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.592933, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3511224, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.94518334, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9912576675415, 'eval/sps': 1066.7443819502937, 'num_steps': 12943360}
{'eval/walltime': 19217.584500551224, 'training/sps': 585.5704034458442, 'training/walltime': 22321.37496304512, 'training/entropy_loss': Array(0.01393415, dtype=float32), 'training/policy_loss': Array(-0.00323001, dtype=float32), 'training/total_loss': Array(0.01074074, dtype=float32), 'training/v_loss': Array(3.6603582e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.7266, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.3987, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0826106, dtype=float32), 'eval/episode_reward_alive_std': Array(7.043392, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1656686, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.5146861076355, 'eval/sps': 1070.9980854128887, 'num_steps': 13025280}
{'eval/walltime': 19337.481551408768, 'training/sps': 581.4590469368926, 'training/walltime': 22462.261927366257, 'training/entropy_loss': Array(0.01415275, dtype=float32), 'training/policy_loss': Array(-0.00583673, dtype=float32), 'training/total_loss': Array(0.00833871, dtype=float32), 'training/v_loss': Array(2.2695753e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.824, dtype=float32), 'eval/episode_reward_alive': Array(4994.1016, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.277059, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.925026, dtype=float32), 'eval/episode_reward_alive_std': Array(6.627169, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2229694, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.89705085754395, 'eval/sps': 1067.5825559052623, 'num_steps': 13107200}
{'eval/walltime': 19457.051196813583, 'training/sps': 584.9700845110469, 'training/walltime': 22602.303276777267, 'training/entropy_loss': Array(0.01427075, dtype=float32), 'training/policy_loss': Array(-0.00061874, dtype=float32), 'training/total_loss': Array(0.01368107, dtype=float32), 'training/v_loss': Array(2.9065246e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.2764, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.848928, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.370195, dtype=float32), 'eval/episode_reward_alive_std': Array(7.071068, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.92380345, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.56964540481567, 'eval/sps': 1070.5058091177111, 'num_steps': 13189120}
{'eval/walltime': 19576.98810648918, 'training/sps': 581.8565098339528, 'training/walltime': 22743.094002008438, 'training/entropy_loss': Array(0.0142958, dtype=float32), 'training/policy_loss': Array(-0.00665907, dtype=float32), 'training/total_loss': Array(0.0076579, dtype=float32), 'training/v_loss': Array(2.1171198e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.9517, dtype=float32), 'eval/episode_reward_alive': Array(4993.9062, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.954741, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.808293, dtype=float32), 'eval/episode_reward_alive_std': Array(6.5531926, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1687632, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.93690967559814, 'eval/sps': 1067.2277645489671, 'num_steps': 13271040}
{'eval/walltime': 19696.863615751266, 'training/sps': 585.4543260608522, 'training/walltime': 22883.019520282745, 'training/entropy_loss': Array(0.01406006, dtype=float32), 'training/policy_loss': Array(0.00151266, dtype=float32), 'training/total_loss': Array(0.01560679, dtype=float32), 'training/v_loss': Array(3.4072422e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.3984, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.07798, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2085094, dtype=float32), 'eval/episode_reward_alive_std': Array(6.947307, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3376646, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87550926208496, 'eval/sps': 1067.7744001917222, 'num_steps': 13352960}
{'eval/walltime': 19816.687850236893, 'training/sps': 582.1577176619566, 'training/walltime': 23023.73740053177, 'training/entropy_loss': Array(0.01438612, dtype=float32), 'training/policy_loss': Array(0.00378648, dtype=float32), 'training/total_loss': Array(0.01819203, dtype=float32), 'training/v_loss': Array(1.9435403e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.1074, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.900176, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6328516, dtype=float32), 'eval/episode_reward_alive_std': Array(7.10798, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3846897, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82423448562622, 'eval/sps': 1068.231318559807, 'num_steps': 13434880}
{'eval/walltime': 19936.40602993965, 'training/sps': 585.4824673997608, 'training/walltime': 23163.656193256378, 'training/entropy_loss': Array(0.01435287, dtype=float32), 'training/policy_loss': Array(0.00254664, dtype=float32), 'training/total_loss': Array(0.01693284, dtype=float32), 'training/v_loss': Array(3.332681e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.365, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.071398, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.229977, dtype=float32), 'eval/episode_reward_alive_std': Array(7.228146, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.6574817, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.71817970275879, 'eval/sps': 1069.1776329860984, 'num_steps': 13516800}
{'eval/walltime': 20056.43268609047, 'training/sps': 583.7056948969661, 'training/walltime': 23304.000892162323, 'training/entropy_loss': Array(0.01460305, dtype=float32), 'training/policy_loss': Array(0.00631236, dtype=float32), 'training/total_loss': Array(0.02093343, dtype=float32), 'training/v_loss': Array(1.8020623e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.221, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.568314, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.930187, dtype=float32), 'eval/episode_reward_alive_std': Array(6.753069, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.301611, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02665615081787, 'eval/sps': 1066.4297757255133, 'num_steps': 13598720}
{'eval/walltime': 20176.082763433456, 'training/sps': 585.0155819388657, 'training/walltime': 23444.03135037422, 'training/entropy_loss': Array(0.01431301, dtype=float32), 'training/policy_loss': Array(-0.00155113, dtype=float32), 'training/total_loss': Array(0.01279875, dtype=float32), 'training/v_loss': Array(3.6873353e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.269, dtype=float32), 'eval/episode_reward_alive': Array(4992.617, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.34836, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7610083, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6428075, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1037098, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.65007734298706, 'eval/sps': 1069.7861868745574, 'num_steps': 13680640}
{'eval/walltime': 20296.098494529724, 'training/sps': 583.9526957325216, 'training/walltime': 23584.316686153412, 'training/entropy_loss': Array(0.0144241, dtype=float32), 'training/policy_loss': Array(-0.00096702, dtype=float32), 'training/total_loss': Array(0.01348437, dtype=float32), 'training/v_loss': Array(2.729004e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.9014, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.5354805, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2613974, dtype=float32), 'eval/episode_reward_alive_std': Array(6.924537, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3725373, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.0157310962677, 'eval/sps': 1066.5268530283577, 'num_steps': 13762560}
{'eval/walltime': 20415.798152446747, 'training/sps': 585.3603017964883, 'training/walltime': 23724.26468014717, 'training/entropy_loss': Array(0.01440983, dtype=float32), 'training/policy_loss': Array(-0.00250523, dtype=float32), 'training/total_loss': Array(0.01192297, dtype=float32), 'training/v_loss': Array(1.8372804e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.6743, dtype=float32), 'eval/episode_reward_alive': Array(4994.297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.62201, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4203115, dtype=float32), 'eval/episode_reward_alive_std': Array(6.895831, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.4588101, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.6996579170227, 'eval/sps': 1069.3430727156397, 'num_steps': 13844480}
{'eval/walltime': 20535.788821220398, 'training/sps': 584.1113043649501, 'training/walltime': 23864.511923074722, 'training/entropy_loss': Array(0.01459859, dtype=float32), 'training/policy_loss': Array(0.00271786, dtype=float32), 'training/total_loss': Array(0.01734422, dtype=float32), 'training/v_loss': Array(2.7766935e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.4185, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.941015, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1293845, dtype=float32), 'eval/episode_reward_alive_std': Array(6.763568, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.5862422, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99066877365112, 'eval/sps': 1066.7496173511424, 'num_steps': 13926400}
{'eval/walltime': 20655.585971593857, 'training/sps': 585.8736545147515, 'training/walltime': 24004.337292194366, 'training/entropy_loss': Array(0.01475535, dtype=float32), 'training/policy_loss': Array(-0.00341053, dtype=float32), 'training/total_loss': Array(0.01136411, dtype=float32), 'training/v_loss': Array(1.9288585e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.0947, dtype=float32), 'eval/episode_reward_alive': Array(4993.5547, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.459956, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1001053, dtype=float32), 'eval/episode_reward_alive_std': Array(6.706816, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.222641, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79715037345886, 'eval/sps': 1068.4728276170956, 'num_steps': 14008320}
{'eval/walltime': 20775.65171766281, 'training/sps': 584.8261500652112, 'training/walltime': 24144.41310787201, 'training/entropy_loss': Array(0.01436821, dtype=float32), 'training/policy_loss': Array(0.00348872, dtype=float32), 'training/total_loss': Array(0.01788259, dtype=float32), 'training/v_loss': Array(2.5659063e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.3525, dtype=float32), 'eval/episode_reward_alive': Array(4994.5703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.21746, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9278007, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7322493, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2441866, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.06574606895447, 'eval/sps': 1066.0825771780808, 'num_steps': 14090240}
{'eval/walltime': 20895.25040078163, 'training/sps': 585.4857007992849, 'training/walltime': 24284.331127882004, 'training/entropy_loss': Array(0.01468699, dtype=float32), 'training/policy_loss': Array(0.00321597, dtype=float32), 'training/total_loss': Array(0.01791952, dtype=float32), 'training/v_loss': Array(1.6556845e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.7695, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.902186, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.858978, dtype=float32), 'eval/episode_reward_alive_std': Array(6.599135, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8510595, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.59868311882019, 'eval/sps': 1070.2458978819457, 'num_steps': 14172160}
{'eval/walltime': 21015.137333869934, 'training/sps': 583.512039524404, 'training/walltime': 24424.722404241562, 'training/entropy_loss': Array(0.01424399, dtype=float32), 'training/policy_loss': Array(0.00473709, dtype=float32), 'training/total_loss': Array(0.0190045, dtype=float32), 'training/v_loss': Array(2.3424698e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.0967, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.88793, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.938495, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6543975, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1644987, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88693308830261, 'eval/sps': 1067.6726537471911, 'num_steps': 14254080}
{'eval/walltime': 21134.81736779213, 'training/sps': 585.5931525791773, 'training/walltime': 24564.614750385284, 'training/entropy_loss': Array(0.01465284, dtype=float32), 'training/policy_loss': Array(0.00323425, dtype=float32), 'training/total_loss': Array(0.01790296, dtype=float32), 'training/v_loss': Array(1.5860332e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.909, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.52866, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.83382, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7241983, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.97733074, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.68003392219543, 'eval/sps': 1069.518413432381, 'num_steps': 14336000}
{'eval/walltime': 21254.743275165558, 'training/sps': 583.4040939970719, 'training/walltime': 24705.032002925873, 'training/entropy_loss': Array(0.01461068, dtype=float32), 'training/policy_loss': Array(0.00048153, dtype=float32), 'training/total_loss': Array(0.01512107, dtype=float32), 'training/v_loss': Array(2.8857154e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.9365, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.501625, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.030754, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8393965, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.0165857, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.92590737342834, 'eval/sps': 1067.3256746887087, 'num_steps': 14417920}
{'eval/walltime': 21374.437480211258, 'training/sps': 585.4193479402104, 'training/walltime': 24844.965881586075, 'training/entropy_loss': Array(0.01473951, dtype=float32), 'training/policy_loss': Array(0.0012376, dtype=float32), 'training/total_loss': Array(0.0160066, dtype=float32), 'training/v_loss': Array(2.949272e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.332, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.182947, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9166408, dtype=float32), 'eval/episode_reward_alive_std': Array(6.856776, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1302197, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69420504570007, 'eval/sps': 1069.3917884422951, 'num_steps': 14499840}
{'eval/walltime': 21494.451300382614, 'training/sps': 580.9815189707374, 'training/walltime': 24985.968645572662, 'training/entropy_loss': Array(0.0147574, dtype=float32), 'training/policy_loss': Array(3.627586e-05, dtype=float32), 'training/total_loss': Array(0.01481209, dtype=float32), 'training/v_loss': Array(1.8410687e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.6597, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.090178, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.987311, dtype=float32), 'eval/episode_reward_alive_std': Array(6.903351, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3268934, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.0138201713562, 'eval/sps': 1066.5438348453629, 'num_steps': 14581760}
{'eval/walltime': 21614.277976989746, 'training/sps': 585.1305935685718, 'training/walltime': 25125.971579790115, 'training/entropy_loss': Array(0.01465846, dtype=float32), 'training/policy_loss': Array(0.00185634, dtype=float32), 'training/total_loss': Array(0.01654281, dtype=float32), 'training/v_loss': Array(2.8011367e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.692, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.057889, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7771854, dtype=float32), 'eval/episode_reward_alive_std': Array(6.731456, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21101245, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82667660713196, 'eval/sps': 1068.209547525593, 'num_steps': 14663680}
{'eval/walltime': 21734.420432567596, 'training/sps': 580.0311602337022, 'training/walltime': 25267.205371379852, 'training/entropy_loss': Array(0.01484159, dtype=float32), 'training/policy_loss': Array(-0.00200674, dtype=float32), 'training/total_loss': Array(0.01285232, dtype=float32), 'training/v_loss': Array(1.7464105e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.9717, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.997196, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0449834, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9999304, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22201, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.14245557785034, 'eval/sps': 1065.4018963101523, 'num_steps': 14745600}
{'eval/walltime': 21854.275844097137, 'training/sps': 585.8223432511908, 'training/walltime': 25407.042987585068, 'training/entropy_loss': Array(0.014899, dtype=float32), 'training/policy_loss': Array(0.00022253, dtype=float32), 'training/total_loss': Array(0.01514416, dtype=float32), 'training/v_loss': Array(2.2630382e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.8906, dtype=float32), 'eval/episode_reward_alive': Array(4994.7656, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.875181, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.4596667, dtype=float32), 'eval/episode_reward_alive_std': Array(6.3694634, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.27513972, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85541152954102, 'eval/sps': 1067.9534479630197, 'num_steps': 14827520}
{'eval/walltime': 21974.25728392601, 'training/sps': 583.4927989690045, 'training/walltime': 25547.438893318176, 'training/entropy_loss': Array(0.01502813, dtype=float32), 'training/policy_loss': Array(0.0007889, dtype=float32), 'training/total_loss': Array(0.01583406, dtype=float32), 'training/v_loss': Array(1.703066e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.843, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.751141, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.660801, dtype=float32), 'eval/episode_reward_alive_std': Array(6.5829296, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.41860232, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98143982887268, 'eval/sps': 1066.8316714865568, 'num_steps': 14909440}
{'eval/walltime': 22093.975821971893, 'training/sps': 585.6076971825582, 'training/walltime': 25687.327764987946, 'training/entropy_loss': Array(0.01495527, dtype=float32), 'training/policy_loss': Array(-0.00033166, dtype=float32), 'training/total_loss': Array(0.01465157, dtype=float32), 'training/v_loss': Array(2.7960425e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.7876, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.728016, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.843364, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7707834, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.158791, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.71853804588318, 'eval/sps': 1069.174432709351, 'num_steps': 14991360}
{'eval/walltime': 22214.184281110764, 'training/sps': 584.6867646217877, 'training/walltime': 25827.436973810196, 'training/entropy_loss': Array(0.0152083, dtype=float32), 'training/policy_loss': Array(0.00352758, dtype=float32), 'training/total_loss': Array(0.01875722, dtype=float32), 'training/v_loss': Array(2.1348027e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.75, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.765595, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9430413, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7707834, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.50196415, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.20845913887024, 'eval/sps': 1064.8169098659573, 'num_steps': 15073280}
{'eval/walltime': 22333.807018995285, 'training/sps': 585.6357265002518, 'training/walltime': 25967.319150209427, 'training/entropy_loss': Array(0.01504951, dtype=float32), 'training/policy_loss': Array(0.00053202, dtype=float32), 'training/total_loss': Array(0.01560542, dtype=float32), 'training/v_loss': Array(2.3888293e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.343, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.641133, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.921691, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7707834, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.40087456, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.62273788452148, 'eval/sps': 1070.0306836612078, 'num_steps': 15155200}
{'eval/walltime': 22453.9147939682, 'training/sps': 583.4393478604917, 'training/walltime': 26107.72791814804, 'training/entropy_loss': Array(0.01522505, dtype=float32), 'training/policy_loss': Array(0.00161449, dtype=float32), 'training/total_loss': Array(0.01686397, dtype=float32), 'training/v_loss': Array(2.4421519e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.373, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.595238, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.26782, dtype=float32), 'eval/episode_reward_alive_std': Array(7.192593, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.14168347, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.10777497291565, 'eval/sps': 1065.709526538678, 'num_steps': 15237120}
{'eval/walltime': 22573.525846481323, 'training/sps': 585.0507738205058, 'training/walltime': 26247.74995326996, 'training/entropy_loss': Array(0.01539721, dtype=float32), 'training/policy_loss': Array(0.0379915, dtype=float32), 'training/total_loss': Array(0.05340424, dtype=float32), 'training/v_loss': Array(1.5521817e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.185, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.470854, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.002139, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8794007, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.304911, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.61105251312256, 'eval/sps': 1070.1352200371039, 'num_steps': 15319040}
{'eval/walltime': 22693.37966799736, 'training/sps': 584.135182586119, 'training/walltime': 26387.991463184357, 'training/entropy_loss': Array(0.01502419, dtype=float32), 'training/policy_loss': Array(0.01701242, dtype=float32), 'training/total_loss': Array(0.03209295, dtype=float32), 'training/v_loss': Array(5.633627e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.4756, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.532429, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.020243, dtype=float32), 'eval/episode_reward_alive_std': Array(7.9387264, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.16851072, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85382151603699, 'eval/sps': 1067.967615724902, 'num_steps': 15400960}
{'eval/walltime': 22813.113617420197, 'training/sps': 585.2532664045137, 'training/walltime': 26527.96505188942, 'training/entropy_loss': Array(0.0149828, dtype=float32), 'training/policy_loss': Array(0.00542402, dtype=float32), 'training/total_loss': Array(0.02045555, dtype=float32), 'training/v_loss': Array(4.8726622e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.0117, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.620722, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7424917, dtype=float32), 'eval/episode_reward_alive_std': Array(7.647376, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18218413, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7339494228363, 'eval/sps': 1069.036815514808, 'num_steps': 15482880}
{'eval/walltime': 22933.12632918358, 'training/sps': 584.3038285638424, 'training/walltime': 26668.16608428955, 'training/entropy_loss': Array(0.01469479, dtype=float32), 'training/policy_loss': Array(0.00130259, dtype=float32), 'training/total_loss': Array(0.01604365, dtype=float32), 'training/v_loss': Array(4.6274334e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.079, dtype=float32), 'eval/episode_reward_alive': Array(4992.6953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.616287, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.598363, dtype=float32), 'eval/episode_reward_alive_std': Array(7.497456, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19627567, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01271176338196, 'eval/sps': 1066.553685182665, 'num_steps': 15564800}
{'eval/walltime': 23052.784616708755, 'training/sps': 585.3144406452678, 'training/walltime': 26808.1250436306, 'training/entropy_loss': Array(0.01494799, dtype=float32), 'training/policy_loss': Array(0.01411133, dtype=float32), 'training/total_loss': Array(0.0290902, dtype=float32), 'training/v_loss': Array(3.0870848e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.7666, dtype=float32), 'eval/episode_reward_alive': Array(4992.578, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.811652, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.208769, dtype=float32), 'eval/episode_reward_alive_std': Array(8.148628, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.5130605, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.658287525177, 'eval/sps': 1069.7127850260088, 'num_steps': 15646720}
{'eval/walltime': 23172.79766702652, 'training/sps': 582.8819056100352, 'training/walltime': 26948.668092250824, 'training/entropy_loss': Array(0.01469631, dtype=float32), 'training/policy_loss': Array(0.044586, dtype=float32), 'training/total_loss': Array(0.05936554, dtype=float32), 'training/v_loss': Array(8.322214e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.5156, dtype=float32), 'eval/episode_reward_alive': Array(4992.0312, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.515613, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.829186, dtype=float32), 'eval/episode_reward_alive_std': Array(7.817186, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.0928947, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01305031776428, 'eval/sps': 1066.550676456338, 'num_steps': 15728640}
{'eval/walltime': 23292.49056649208, 'training/sps': 584.960488137786, 'training/walltime': 27088.711739063263, 'training/entropy_loss': Array(0.01533436, dtype=float32), 'training/policy_loss': Array(0.11221595, dtype=float32), 'training/total_loss': Array(0.12761945, dtype=float32), 'training/v_loss': Array(6.914102e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.281, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.313103, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.057451, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7005568, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.3235357, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69289946556091, 'eval/sps': 1069.4034530998163, 'num_steps': 15810560}
{'eval/walltime': 23412.53050136566, 'training/sps': 583.4355059563301, 'training/walltime': 27229.121431589127, 'training/entropy_loss': Array(0.01500832, dtype=float32), 'training/policy_loss': Array(0.06063332, dtype=float32), 'training/total_loss': Array(0.07577546, dtype=float32), 'training/v_loss': Array(0.00013382, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.2793, dtype=float32), 'eval/episode_reward_alive': Array(4993.164, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.885256, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0680532, dtype=float32), 'eval/episode_reward_alive_std': Array(6.927952, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1961355, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.03993487358093, 'eval/sps': 1066.3118081062119, 'num_steps': 15892480}
{'eval/walltime': 23532.17975473404, 'training/sps': 584.4537551297668, 'training/walltime': 27369.286499023438, 'training/entropy_loss': Array(0.01539976, dtype=float32), 'training/policy_loss': Array(0.23455298, dtype=float32), 'training/total_loss': Array(0.25000146, dtype=float32), 'training/v_loss': Array(4.8726513e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4931.4897, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-61.90895, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(11.834104, dtype=float32), 'eval/episode_reward_alive_std': Array(6.729529, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.316095, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.64925336837769, 'eval/sps': 1069.7935540467765, 'num_steps': 15974400}
{'eval/walltime': 23652.355358362198, 'training/sps': 582.9282625662167, 'training/walltime': 27509.81837105751, 'training/entropy_loss': Array(0.01306972, dtype=float32), 'training/policy_loss': Array(0.03402609, dtype=float32), 'training/total_loss': Array(0.0472199, dtype=float32), 'training/v_loss': Array(0.0001241, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4935.9736, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-57.42534, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.828613, dtype=float32), 'eval/episode_reward_alive_std': Array(6.729529, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.819594, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.17560362815857, 'eval/sps': 1065.1080263848833, 'num_steps': 16056320}
{'eval/walltime': 23771.97652196884, 'training/sps': 585.2858289298018, 'training/walltime': 27649.784172296524, 'training/entropy_loss': Array(0.0122454, dtype=float32), 'training/policy_loss': Array(0.0485217, dtype=float32), 'training/total_loss': Array(0.06115878, dtype=float32), 'training/v_loss': Array(0.00039169, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4942.536, dtype=float32), 'eval/episode_reward_alive': Array(4994.258, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-51.72199, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9841247, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6758027, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.1255517, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.62116360664368, 'eval/sps': 1070.0447658318128, 'num_steps': 16138240}
{'eval/walltime': 23891.79260158539, 'training/sps': 579.0566853101363, 'training/walltime': 27791.25564146042, 'training/entropy_loss': Array(0.01199529, dtype=float32), 'training/policy_loss': Array(-0.00357775, dtype=float32), 'training/total_loss': Array(0.00846013, dtype=float32), 'training/v_loss': Array(4.258673e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4943.767, dtype=float32), 'eval/episode_reward_alive': Array(4992.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-49.12359, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.955982, dtype=float32), 'eval/episode_reward_alive_std': Array(6.89229, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.4357708, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81607961654663, 'eval/sps': 1068.3040240478972, 'num_steps': 16220160}
{'eval/walltime': 24011.510833740234, 'training/sps': 584.7990860126595, 'training/walltime': 27931.337939739227, 'training/entropy_loss': Array(0.01174489, dtype=float32), 'training/policy_loss': Array(-0.00350552, dtype=float32), 'training/total_loss': Array(0.00828246, dtype=float32), 'training/v_loss': Array(4.309496e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4947.24, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-46.470497, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.721888, dtype=float32), 'eval/episode_reward_alive_std': Array(6.966608, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.5253823, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.71823215484619, 'eval/sps': 1069.1771645478525, 'num_steps': 16302080}
{'eval/walltime': 24131.59389591217, 'training/sps': 579.8190004596265, 'training/walltime': 28072.623409748077, 'training/entropy_loss': Array(0.01125961, dtype=float32), 'training/policy_loss': Array(-0.01342366, dtype=float32), 'training/total_loss': Array(-0.00213968, dtype=float32), 'training/v_loss': Array(2.4369343e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4949.2153, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-44.30011, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2286654, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0533504, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.1145139, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.08306217193604, 'eval/sps': 1065.9288469570206, 'num_steps': 16384000}
{'eval/walltime': 24251.24004840851, 'training/sps': 585.4897074308999, 'training/walltime': 28212.54047226906, 'training/entropy_loss': Array(0.01120646, dtype=float32), 'training/policy_loss': Array(-0.00892488, dtype=float32), 'training/total_loss': Array(0.00231308, dtype=float32), 'training/v_loss': Array(3.1496544e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4949.6797, dtype=float32), 'eval/episode_reward_alive': Array(4992.8516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-43.171707, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.678499, dtype=float32), 'eval/episode_reward_alive_std': Array(7.034613, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.5469527, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.64615249633789, 'eval/sps': 1069.8212799105079, 'num_steps': 16465920}
{'eval/walltime': 24371.414225578308, 'training/sps': 583.5247873265223, 'training/walltime': 28352.928681612015, 'training/entropy_loss': Array(0.01087081, dtype=float32), 'training/policy_loss': Array(-0.00446336, dtype=float32), 'training/total_loss': Array(0.00644238, dtype=float32), 'training/v_loss': Array(3.4929122e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4951.425, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-42.168716, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.551674, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2332106, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.6127577, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.1741771697998, 'eval/sps': 1065.1206691362881, 'num_steps': 16547840}
{'eval/walltime': 24491.042551517487, 'training/sps': 584.5958661577649, 'training/walltime': 28493.05967593193, 'training/entropy_loss': Array(0.01087892, dtype=float32), 'training/policy_loss': Array(-0.01442808, dtype=float32), 'training/total_loss': Array(-0.0035268, dtype=float32), 'training/v_loss': Array(2.23566e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4953.0283, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-40.682373, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8763027, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1601677, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.3585799, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.62832593917847, 'eval/sps': 1069.9807005999387, 'num_steps': 16629760}
{'eval/walltime': 24611.141891479492, 'training/sps': 583.2852883445247, 'training/walltime': 28633.505529165268, 'training/entropy_loss': Array(0.01089579, dtype=float32), 'training/policy_loss': Array(0.0006332, dtype=float32), 'training/total_loss': Array(0.01156924, dtype=float32), 'training/v_loss': Array(4.0245344e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4953.7573, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-39.602207, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.841494, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1836777, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.076069, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.09933996200562, 'eval/sps': 1065.7843751722019, 'num_steps': 16711680}
{'eval/walltime': 24730.710195302963, 'training/sps': 584.9646289999581, 'training/walltime': 28773.548184633255, 'training/entropy_loss': Array(0.01082286, dtype=float32), 'training/policy_loss': Array(-0.01138055, dtype=float32), 'training/total_loss': Array(-0.00053289, dtype=float32), 'training/v_loss': Array(2.4801251e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4954.034, dtype=float32), 'eval/episode_reward_alive': Array(4992.461, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-38.426315, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.137879, dtype=float32), 'eval/episode_reward_alive_std': Array(7.288585, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.5105214, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.56830382347107, 'eval/sps': 1070.517820416499, 'num_steps': 16793600}
{'eval/walltime': 24850.907643556595, 'training/sps': 581.3741975141255, 'training/walltime': 28914.45571088791, 'training/entropy_loss': Array(0.01096751, dtype=float32), 'training/policy_loss': Array(0.01456362, dtype=float32), 'training/total_loss': Array(0.02557573, dtype=float32), 'training/v_loss': Array(4.460469e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4956.1455, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-37.604416, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.055535, dtype=float32), 'eval/episode_reward_alive_std': Array(7.153452, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.158122, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.19744825363159, 'eval/sps': 1064.9144541729709, 'num_steps': 16875520}
{'eval/walltime': 24970.575593709946, 'training/sps': 584.8363562224588, 'training/walltime': 29054.52908205986, 'training/entropy_loss': Array(0.01110258, dtype=float32), 'training/policy_loss': Array(-0.00223959, dtype=float32), 'training/total_loss': Array(0.00890275, dtype=float32), 'training/v_loss': Array(3.9761682e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4952.4375, dtype=float32), 'eval/episode_reward_alive': Array(4992.1094, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-39.671967, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.992344, dtype=float32), 'eval/episode_reward_alive_std': Array(7.61909, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.790094, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.66795015335083, 'eval/sps': 1069.626410713745, 'num_steps': 16957440}
{'eval/walltime': 25090.62538433075, 'training/sps': 584.4301679638899, 'training/walltime': 29194.699806451797, 'training/entropy_loss': Array(0.01131759, dtype=float32), 'training/policy_loss': Array(0.00731922, dtype=float32), 'training/total_loss': Array(0.01870148, dtype=float32), 'training/v_loss': Array(6.466487e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4952.9663, dtype=float32), 'eval/episode_reward_alive': Array(4992.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-39.923843, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.203916, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1427784, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.8951592, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04979062080383, 'eval/sps': 1066.2242669319446, 'num_steps': 17039360}
{'eval/walltime': 25210.608124256134, 'training/sps': 584.8430198318765, 'training/walltime': 29334.77158164978, 'training/entropy_loss': Array(0.011395, dtype=float32), 'training/policy_loss': Array(0.00424991, dtype=float32), 'training/total_loss': Array(0.01570396, dtype=float32), 'training/v_loss': Array(5.9037204e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4954.4106, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-38.949043, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(10.267836, dtype=float32), 'eval/episode_reward_alive_std': Array(6.990769, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.712297, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98273992538452, 'eval/sps': 1066.8201116227326, 'num_steps': 17121280}
{'eval/walltime': 25330.420272111893, 'training/sps': 580.4276444386019, 'training/walltime': 29475.90889787674, 'training/entropy_loss': Array(0.01166228, dtype=float32), 'training/policy_loss': Array(-0.00164221, dtype=float32), 'training/total_loss': Array(0.01007483, dtype=float32), 'training/v_loss': Array(5.4747325e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4952.553, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-40.415405, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.893016, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0555134, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.18973, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81214785575867, 'eval/sps': 1068.3390815603996, 'num_steps': 17203200}
{'eval/walltime': 25450.264533042908, 'training/sps': 584.6972425175387, 'training/walltime': 29616.015595912933, 'training/entropy_loss': Array(0.0118758, dtype=float32), 'training/policy_loss': Array(0.00660946, dtype=float32), 'training/total_loss': Array(0.01856249, dtype=float32), 'training/v_loss': Array(7.722975e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4953.176, dtype=float32), 'eval/episode_reward_alive': Array(4992.7344, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-39.559223, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(9.372634, dtype=float32), 'eval/episode_reward_alive_std': Array(6.955758, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.0608034, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84426093101501, 'eval/sps': 1068.0528129225947, 'num_steps': 17285120}
{'eval/walltime': 25570.40853381157, 'training/sps': 581.4779587569876, 'training/walltime': 29756.897978067398, 'training/entropy_loss': Array(0.01178376, dtype=float32), 'training/policy_loss': Array(0.01532091, dtype=float32), 'training/total_loss': Array(0.0271646, dtype=float32), 'training/v_loss': Array(5.9933023e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4957.21, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-36.30548, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.140571, dtype=float32), 'eval/episode_reward_alive_std': Array(6.99775, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.771159, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.1440007686615, 'eval/sps': 1065.388194009498, 'num_steps': 17367040}
{'eval/walltime': 25690.585075378418, 'training/sps': 583.8972194808309, 'training/walltime': 29897.196642398834, 'training/entropy_loss': Array(0.01177313, dtype=float32), 'training/policy_loss': Array(-0.01092689, dtype=float32), 'training/total_loss': Array(0.00089755, dtype=float32), 'training/v_loss': Array(5.1309107e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4957.4893, dtype=float32), 'eval/episode_reward_alive': Array(4992.9297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-35.4411, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.373503, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1678357, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.01206, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.17654156684875, 'eval/sps': 1065.09971356431, 'num_steps': 17448960}
{'eval/walltime': 25810.682601451874, 'training/sps': 580.6203996487957, 'training/walltime': 30038.287103652954, 'training/entropy_loss': Array(0.01169001, dtype=float32), 'training/policy_loss': Array(-0.01792686, dtype=float32), 'training/total_loss': Array(-0.00619748, dtype=float32), 'training/v_loss': Array(3.9376097e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.38, dtype=float32), 'eval/episode_reward_alive': Array(4993.086, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-32.70655, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8725576, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1567574, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.102803, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.09752607345581, 'eval/sps': 1065.8004722071523, 'num_steps': 17530880}
{'eval/walltime': 25930.682204961777, 'training/sps': 585.0328033080799, 'training/walltime': 30178.31343984604, 'training/entropy_loss': Array(0.01183147, dtype=float32), 'training/policy_loss': Array(-0.01296676, dtype=float32), 'training/total_loss': Array(-0.00108614, dtype=float32), 'training/v_loss': Array(4.915388e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4961.541, dtype=float32), 'eval/episode_reward_alive': Array(4994.297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-32.75611, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.722222, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0360227, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.6719158, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99960350990295, 'eval/sps': 1066.6701910347297, 'num_steps': 17612800}
{'eval/walltime': 26050.865924358368, 'training/sps': 581.9925517360806, 'training/walltime': 30319.071254968643, 'training/entropy_loss': Array(0.01162401, dtype=float32), 'training/policy_loss': Array(-0.01424953, dtype=float32), 'training/total_loss': Array(-0.00259866, dtype=float32), 'training/v_loss': Array(2.6864333e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4962.4673, dtype=float32), 'eval/episode_reward_alive': Array(4993.9453, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-31.477993, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7199216, dtype=float32), 'eval/episode_reward_alive_std': Array(7.225507, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.5126927, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.18371939659119, 'eval/sps': 1065.0361017503217, 'num_steps': 17694720}
{'eval/walltime': 26170.995352983475, 'training/sps': 584.7843874695668, 'training/walltime': 30459.157074213028, 'training/entropy_loss': Array(0.01186126, dtype=float32), 'training/policy_loss': Array(-0.010962, dtype=float32), 'training/total_loss': Array(0.00092495, dtype=float32), 'training/v_loss': Array(2.5690199e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4961.7754, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-31.193062, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6504006, dtype=float32), 'eval/episode_reward_alive_std': Array(7.083142, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.5010817, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.12942862510681, 'eval/sps': 1065.5174295339007, 'num_steps': 17776640}
{'eval/walltime': 26291.310238599777, 'training/sps': 575.6981061717032, 'training/walltime': 30601.453877210617, 'training/entropy_loss': Array(0.01170465, dtype=float32), 'training/policy_loss': Array(-0.00861091, dtype=float32), 'training/total_loss': Array(0.00312563, dtype=float32), 'training/v_loss': Array(3.18921e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4962.0215, dtype=float32), 'eval/episode_reward_alive': Array(4992.0703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-30.048828, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2571964, dtype=float32), 'eval/episode_reward_alive_std': Array(7.085619, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.930114, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.31488561630249, 'eval/sps': 1063.8750088514084, 'num_steps': 17858560}
{'eval/walltime': 26411.201208114624, 'training/sps': 584.8178534077156, 'training/walltime': 30741.531680107117, 'training/entropy_loss': Array(0.01192808, dtype=float32), 'training/policy_loss': Array(-0.00973953, dtype=float32), 'training/total_loss': Array(0.00220911, dtype=float32), 'training/v_loss': Array(2.056321e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.0874, dtype=float32), 'eval/episode_reward_alive': Array(4992.383, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-29.295055, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7918763, dtype=float32), 'eval/episode_reward_alive_std': Array(7.394171, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.7596323, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8909695148468, 'eval/sps': 1067.636707901916, 'num_steps': 17940480}
{'eval/walltime': 26531.29510498047, 'training/sps': 583.3855103372973, 'training/walltime': 30881.953405618668, 'training/entropy_loss': Array(0.01197296, dtype=float32), 'training/policy_loss': Array(-0.00637462, dtype=float32), 'training/total_loss': Array(0.00562693, dtype=float32), 'training/v_loss': Array(2.8598528e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.3623, dtype=float32), 'eval/episode_reward_alive': Array(4991.797, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-28.434767, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9153423, dtype=float32), 'eval/episode_reward_alive_std': Array(6.83895, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.6725374, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.09389686584473, 'eval/sps': 1065.832680431605, 'num_steps': 18022400}
{'eval/walltime': 26651.080436706543, 'training/sps': 583.604693770587, 'training/walltime': 31022.32239317894, 'training/entropy_loss': Array(0.01186858, dtype=float32), 'training/policy_loss': Array(-0.00536523, dtype=float32), 'training/total_loss': Array(0.00652505, dtype=float32), 'training/v_loss': Array(2.1699925e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4966.0073, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-28.016718, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.629931, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2634196, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.946456, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78533172607422, 'eval/sps': 1068.5782487350882, 'num_steps': 18104320}
{'eval/walltime': 26771.226663827896, 'training/sps': 584.5518511188315, 'training/walltime': 31162.463938951492, 'training/entropy_loss': Array(0.01216601, dtype=float32), 'training/policy_loss': Array(0.00156156, dtype=float32), 'training/total_loss': Array(0.01375741, dtype=float32), 'training/v_loss': Array(2.9839965e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.551, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-27.847473, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5264482, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8446374, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.1276028, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.14622712135315, 'eval/sps': 1065.3684519840492, 'num_steps': 18186240}
{'eval/walltime': 26891.023701667786, 'training/sps': 584.1051449625796, 'training/walltime': 31302.71266078949, 'training/entropy_loss': Array(0.01192818, dtype=float32), 'training/policy_loss': Array(-0.00644958, dtype=float32), 'training/total_loss': Array(0.00550541, dtype=float32), 'training/v_loss': Array(2.6819846e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.743, dtype=float32), 'eval/episode_reward_alive': Array(4994.6094, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-26.865744, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3929973, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6909857, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.1781294, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79703783988953, 'eval/sps': 1068.4738313068628, 'num_steps': 18268160}
{'eval/walltime': 27011.16089439392, 'training/sps': 584.2995211805819, 'training/walltime': 31442.91472673416, 'training/entropy_loss': Array(0.01227396, dtype=float32), 'training/policy_loss': Array(-0.00514856, dtype=float32), 'training/total_loss': Array(0.00716355, dtype=float32), 'training/v_loss': Array(3.813796e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.08, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-26.513412, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9762273, dtype=float32), 'eval/episode_reward_alive_std': Array(7.179003, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.5600116, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.13719272613525, 'eval/sps': 1065.4485683862183, 'num_steps': 18350080}
{'eval/walltime': 27130.92042541504, 'training/sps': 584.2471292082006, 'training/walltime': 31583.129365205765, 'training/entropy_loss': Array(0.0121098, dtype=float32), 'training/policy_loss': Array(-0.00414676, dtype=float32), 'training/total_loss': Array(0.00798669, dtype=float32), 'training/v_loss': Array(2.3653978e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4968.263, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-25.760693, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.672418, dtype=float32), 'eval/episode_reward_alive_std': Array(7.475444, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.5377848, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.75953102111816, 'eval/sps': 1068.8084606596258, 'num_steps': 18432000}
{'eval/walltime': 27250.936302423477, 'training/sps': 583.7912193380527, 'training/walltime': 31723.453503847122, 'training/entropy_loss': Array(0.01242332, dtype=float32), 'training/policy_loss': Array(-0.00316012, dtype=float32), 'training/total_loss': Array(0.00929496, dtype=float32), 'training/v_loss': Array(3.1763342e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.344, dtype=float32), 'eval/episode_reward_alive': Array(4993.164, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-25.819614, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9778786, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1499314, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.4363122, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01587700843811, 'eval/sps': 1066.5255563728501, 'num_steps': 18513920}
{'eval/walltime': 27371.235372543335, 'training/sps': 584.183276623259, 'training/walltime': 31863.68346810341, 'training/entropy_loss': Array(0.01244504, dtype=float32), 'training/policy_loss': Array(-0.00241281, dtype=float32), 'training/total_loss': Array(0.01006871, dtype=float32), 'training/v_loss': Array(3.648533e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4969.3726, dtype=float32), 'eval/episode_reward_alive': Array(4994.297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-24.924065, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.650074, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0913234, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.6041462, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.29907011985779, 'eval/sps': 1064.0148745328581, 'num_steps': 18595840}
{'eval/walltime': 27491.27214741707, 'training/sps': 577.5694410294345, 'training/walltime': 32005.519227027893, 'training/entropy_loss': Array(0.01239413, dtype=float32), 'training/policy_loss': Array(-0.00437767, dtype=float32), 'training/total_loss': Array(0.0080393, dtype=float32), 'training/v_loss': Array(2.2846387e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4968.418, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-24.980488, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.453874, dtype=float32), 'eval/episode_reward_alive_std': Array(7.233105, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.3790772, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.03677487373352, 'eval/sps': 1066.339879046592, 'num_steps': 18677760}
{'eval/walltime': 27611.35390305519, 'training/sps': 583.6730511551162, 'training/walltime': 32145.8717751503, 'training/entropy_loss': Array(0.01268749, dtype=float32), 'training/policy_loss': Array(-0.00136485, dtype=float32), 'training/total_loss': Array(0.01136059, dtype=float32), 'training/v_loss': Array(3.795822e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4968.121, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-25.277687, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.031357, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1516385, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.0928893, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.08175563812256, 'eval/sps': 1065.9404446562207, 'num_steps': 18759680}
{'eval/walltime': 27731.4330534935, 'training/sps': 577.7225228271366, 'training/walltime': 32287.669951200485, 'training/entropy_loss': Array(0.01268497, dtype=float32), 'training/policy_loss': Array(-0.00220764, dtype=float32), 'training/total_loss': Array(0.01051184, dtype=float32), 'training/v_loss': Array(3.4510835e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.9434, dtype=float32), 'eval/episode_reward_alive': Array(4992.3438, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-24.40081, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.281639, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4722795, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.4845316, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.07915043830872, 'eval/sps': 1065.9635709678064, 'num_steps': 18841600}
{'eval/walltime': 27851.253058195114, 'training/sps': 584.0912140512473, 'training/walltime': 32427.922018051147, 'training/entropy_loss': Array(0.01313304, dtype=float32), 'training/policy_loss': Array(-0.0027673, dtype=float32), 'training/total_loss': Array(0.01041224, dtype=float32), 'training/v_loss': Array(4.6499328e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4969.85, dtype=float32), 'eval/episode_reward_alive': Array(4994.492, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-24.642426, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.905677, dtype=float32), 'eval/episode_reward_alive_std': Array(6.927071, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.0961666, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82000470161438, 'eval/sps': 1068.2690283542895, 'num_steps': 18923520}
{'eval/walltime': 27971.22344970703, 'training/sps': 579.1947209727907, 'training/walltime': 32569.35977125168, 'training/entropy_loss': Array(0.01300763, dtype=float32), 'training/policy_loss': Array(-0.00150124, dtype=float32), 'training/total_loss': Array(0.01154104, dtype=float32), 'training/v_loss': Array(3.465156e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4969.397, dtype=float32), 'eval/episode_reward_alive': Array(4994.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-24.665625, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.650878, dtype=float32), 'eval/episode_reward_alive_std': Array(6.952686, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.8014107, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.97039151191711, 'eval/sps': 1066.9299181813979, 'num_steps': 19005440}
{'eval/walltime': 28091.33174943924, 'training/sps': 584.0889134792874, 'training/walltime': 32709.61239051819, 'training/entropy_loss': Array(0.0132752, dtype=float32), 'training/policy_loss': Array(-0.00022874, dtype=float32), 'training/total_loss': Array(0.01310573, dtype=float32), 'training/v_loss': Array(5.9272046e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4969.841, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-23.127548, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6598277, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0277767, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.9449904, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.10829973220825, 'eval/sps': 1065.704870399356, 'num_steps': 19087360}
{'eval/walltime': 28210.94938516617, 'training/sps': 578.9324855571967, 'training/walltime': 32851.114209890366, 'training/entropy_loss': Array(0.01320184, dtype=float32), 'training/policy_loss': Array(0.00211738, dtype=float32), 'training/total_loss': Array(0.01535592, dtype=float32), 'training/v_loss': Array(3.6703765e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4970.0283, dtype=float32), 'eval/episode_reward_alive': Array(4992.9297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-22.901543, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7570057, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4615507, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.0379102, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.61763572692871, 'eval/sps': 1070.0763246333267, 'num_steps': 19169280}
{'eval/walltime': 28330.968171834946, 'training/sps': 582.020546599713, 'training/walltime': 32991.86525464058, 'training/entropy_loss': Array(0.0133361, dtype=float32), 'training/policy_loss': Array(-0.0027049, dtype=float32), 'training/total_loss': Array(0.01065883, dtype=float32), 'training/v_loss': Array(2.7634005e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.4414, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-22.269852, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.247854, dtype=float32), 'eval/episode_reward_alive_std': Array(7.506406, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.69152, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01878666877747, 'eval/sps': 1066.4997001948432, 'num_steps': 19251200}
{'eval/walltime': 28450.71039223671, 'training/sps': 584.1909017242762, 'training/walltime': 33132.093388557434, 'training/entropy_loss': Array(0.01343055, dtype=float32), 'training/policy_loss': Array(-0.00131822, dtype=float32), 'training/total_loss': Array(0.0121609, dtype=float32), 'training/v_loss': Array(4.8575588e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.0625, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-22.6097, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9332204, dtype=float32), 'eval/episode_reward_alive_std': Array(6.94522, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.4947896, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74222040176392, 'eval/sps': 1068.962973715781, 'num_steps': 19333120}
{'eval/walltime': 28570.579337358475, 'training/sps': 581.5923356013875, 'training/walltime': 33272.94806456566, 'training/entropy_loss': Array(0.01344071, dtype=float32), 'training/policy_loss': Array(-0.0002054, dtype=float32), 'training/total_loss': Array(0.01325697, dtype=float32), 'training/v_loss': Array(2.1660599e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4970.6016, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-22.875319, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.384036, dtype=float32), 'eval/episode_reward_alive_std': Array(7.168687, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.500715, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86894512176514, 'eval/sps': 1067.8328725590702, 'num_steps': 19415040}
{'eval/walltime': 28690.25307059288, 'training/sps': 578.2467374930968, 'training/walltime': 33414.61769223213, 'training/entropy_loss': Array(0.01374773, dtype=float32), 'training/policy_loss': Array(-0.00224203, dtype=float32), 'training/total_loss': Array(0.01154357, dtype=float32), 'training/v_loss': Array(3.7874444e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.7686, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.981525, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5050206, dtype=float32), 'eval/episode_reward_alive_std': Array(7.153452, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.6053689, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.67373323440552, 'eval/sps': 1069.5747223769295, 'num_steps': 19496960}
{'eval/walltime': 28810.179595708847, 'training/sps': 585.1842892456488, 'training/walltime': 33554.607779979706, 'training/entropy_loss': Array(0.01363876, dtype=float32), 'training/policy_loss': Array(-0.00532484, dtype=float32), 'training/total_loss': Array(0.00833952, dtype=float32), 'training/v_loss': Array(2.5600533e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.835, dtype=float32), 'eval/episode_reward_alive': Array(4992.9297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.094711, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8312163, dtype=float32), 'eval/episode_reward_alive_std': Array(7.5137205, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.3440335, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9265251159668, 'eval/sps': 1067.3201768851911, 'num_steps': 19578880}
{'eval/walltime': 28929.836976766586, 'training/sps': 578.6348340896639, 'training/walltime': 33696.182388305664, 'training/entropy_loss': Array(0.01374048, dtype=float32), 'training/policy_loss': Array(0.01123651, dtype=float32), 'training/total_loss': Array(0.02501171, dtype=float32), 'training/v_loss': Array(3.4718076e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.1143, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.713652, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4135394, dtype=float32), 'eval/episode_reward_alive_std': Array(7.084434, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.9119092, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.65738105773926, 'eval/sps': 1069.720888661562, 'num_steps': 19660800}
{'eval/walltime': 29049.659108400345, 'training/sps': 584.8859895239415, 'training/walltime': 33836.243872880936, 'training/entropy_loss': Array(0.01382357, dtype=float32), 'training/policy_loss': Array(-0.00417404, dtype=float32), 'training/total_loss': Array(0.00967452, dtype=float32), 'training/v_loss': Array(2.4983354e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.0713, dtype=float32), 'eval/episode_reward_alive': Array(4993.9062, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.835, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9081206, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2061577, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.0968542, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82213163375854, 'eval/sps': 1068.2500657828177, 'num_steps': 19742720}
{'eval/walltime': 29169.362183094025, 'training/sps': 583.5004942461735, 'training/walltime': 33976.63792705536, 'training/entropy_loss': Array(0.01363192, dtype=float32), 'training/policy_loss': Array(-0.00315646, dtype=float32), 'training/total_loss': Array(0.01051216, dtype=float32), 'training/v_loss': Array(3.6696518e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.382, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.05534, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.851345, dtype=float32), 'eval/episode_reward_alive_std': Array(7.119241, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.6878433, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.70307469367981, 'eval/sps': 1069.3125496362732, 'num_steps': 19824640}
{'eval/walltime': 29289.157549858093, 'training/sps': 584.9547549629111, 'training/walltime': 34116.68294644356, 'training/entropy_loss': Array(0.01372642, dtype=float32), 'training/policy_loss': Array(-0.00376234, dtype=float32), 'training/total_loss': Array(0.0099906, dtype=float32), 'training/v_loss': Array(2.6523354e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.826, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.18122, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8219852, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2170544, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.6574754, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7953667640686, 'eval/sps': 1068.488735896523, 'num_steps': 19906560}
{'eval/walltime': 29408.880459547043, 'training/sps': 581.6996520363339, 'training/walltime': 34257.51163649559, 'training/entropy_loss': Array(0.01360938, dtype=float32), 'training/policy_loss': Array(-0.0052875, dtype=float32), 'training/total_loss': Array(0.00834534, dtype=float32), 'training/v_loss': Array(2.3461944e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.6387, dtype=float32), 'eval/episode_reward_alive': Array(4992.6953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.056568, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.559575, dtype=float32), 'eval/episode_reward_alive_std': Array(7.178046, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3851848, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72290968894958, 'eval/sps': 1069.1353921530558, 'num_steps': 19988480}
{'eval/walltime': 29528.661438703537, 'training/sps': 585.2650217131995, 'training/walltime': 34397.48241376877, 'training/entropy_loss': Array(0.01390677, dtype=float32), 'training/policy_loss': Array(-0.00339178, dtype=float32), 'training/total_loss': Array(0.0105523, dtype=float32), 'training/v_loss': Array(3.7308433e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.0127, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.77627, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2963696, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0085354, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.6035593, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78097915649414, 'eval/sps': 1068.6170784492226, 'num_steps': 20070400}
{'eval/walltime': 29648.39862680435, 'training/sps': 584.050653365069, 'training/walltime': 34537.74422073364, 'training/entropy_loss': Array(0.01375535, dtype=float32), 'training/policy_loss': Array(-0.00491519, dtype=float32), 'training/total_loss': Array(0.00886087, dtype=float32), 'training/v_loss': Array(2.0718828e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.6855, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.90776, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6370077, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2332106, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.6257597, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.73718810081482, 'eval/sps': 1069.007899970293, 'num_steps': 20152320}
{'eval/walltime': 29768.07235455513, 'training/sps': 585.1520210299924, 'training/walltime': 34677.74202823639, 'training/entropy_loss': Array(0.01384541, dtype=float32), 'training/policy_loss': Array(-0.00284853, dtype=float32), 'training/total_loss': Array(0.0110214, dtype=float32), 'training/v_loss': Array(2.4519873e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.3867, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.480883, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.813834, dtype=float32), 'eval/episode_reward_alive_std': Array(6.591153, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.4348447, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.6737277507782, 'eval/sps': 1069.5747713864262, 'num_steps': 20234240}
{'eval/walltime': 29887.663643360138, 'training/sps': 583.6741457648945, 'training/walltime': 34818.094313144684, 'training/entropy_loss': Array(0.01371346, dtype=float32), 'training/policy_loss': Array(-0.0045605, dtype=float32), 'training/total_loss': Array(0.00917219, dtype=float32), 'training/v_loss': Array(1.9228211e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.881, dtype=float32), 'eval/episode_reward_alive': Array(4994.2188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.33753, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5140963, dtype=float32), 'eval/episode_reward_alive_std': Array(7.083142, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.711933, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.59128880500793, 'eval/sps': 1070.3120710464318, 'num_steps': 20316160}
{'eval/walltime': 30007.399720191956, 'training/sps': 584.6374337136953, 'training/walltime': 34958.2153441906, 'training/entropy_loss': Array(0.01373384, dtype=float32), 'training/policy_loss': Array(-0.00249468, dtype=float32), 'training/total_loss': Array(0.01126747, dtype=float32), 'training/v_loss': Array(2.8310522e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.3657, dtype=float32), 'eval/episode_reward_alive': Array(4992.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.408068, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3554134, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0657787, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2068033, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.73607683181763, 'eval/sps': 1069.017821418936, 'num_steps': 20398080}
{'eval/walltime': 30127.149826526642, 'training/sps': 578.9689122095239, 'training/walltime': 35099.70826077461, 'training/entropy_loss': Array(0.014023, dtype=float32), 'training/policy_loss': Array(-0.00299515, dtype=float32), 'training/total_loss': Array(0.01104819, dtype=float32), 'training/v_loss': Array(2.0337127e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.471, dtype=float32), 'eval/episode_reward_alive': Array(4992.6953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.224262, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4318852, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0128884, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.5226028, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.75010633468628, 'eval/sps': 1068.8925790366843, 'num_steps': 20480000}
{'eval/walltime': 30246.892773866653, 'training/sps': 584.4385271879803, 'training/walltime': 35239.87698030472, 'training/entropy_loss': Array(0.01405538, dtype=float32), 'training/policy_loss': Array(-0.00014301, dtype=float32), 'training/total_loss': Array(0.01396464, dtype=float32), 'training/v_loss': Array(5.2272342e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.8086, dtype=float32), 'eval/episode_reward_alive': Array(4994.375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.566593, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0583444, dtype=float32), 'eval/episode_reward_alive_std': Array(6.846532, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3603826, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7429473400116, 'eval/sps': 1068.9564842306945, 'num_steps': 20561920}
{'eval/walltime': 30366.52852010727, 'training/sps': 580.5345363470203, 'training/walltime': 35380.98830938339, 'training/entropy_loss': Array(0.01406782, dtype=float32), 'training/policy_loss': Array(0.00309153, dtype=float32), 'training/total_loss': Array(0.01718242, dtype=float32), 'training/v_loss': Array(2.306276e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.876, dtype=float32), 'eval/episode_reward_alive': Array(4992.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.897146, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.716911, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4427133, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.096969, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.63574624061584, 'eval/sps': 1069.9143359925356, 'num_steps': 20643840}
{'eval/walltime': 30486.37208390236, 'training/sps': 585.5037370597342, 'training/walltime': 35520.902019262314, 'training/entropy_loss': Array(0.01413269, dtype=float32), 'training/policy_loss': Array(-0.00430971, dtype=float32), 'training/total_loss': Array(0.00984254, dtype=float32), 'training/v_loss': Array(1.9554887e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.0327, dtype=float32), 'eval/episode_reward_alive': Array(4994.414, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.381298, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8101096, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9209003, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9825308, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84356379508972, 'eval/sps': 1068.0590258385196, 'num_steps': 20725760}
{'eval/walltime': 30606.055166721344, 'training/sps': 581.0256542822704, 'training/walltime': 35661.894072532654, 'training/entropy_loss': Array(0.01459985, dtype=float32), 'training/policy_loss': Array(-0.00243494, dtype=float32), 'training/total_loss': Array(0.01218615, dtype=float32), 'training/v_loss': Array(2.1244741e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.629, dtype=float32), 'eval/episode_reward_alive': Array(4992.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.261995, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.325765, dtype=float32), 'eval/episode_reward_alive_std': Array(7.224345, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.0094293, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.68308281898499, 'eval/sps': 1069.49116771661, 'num_steps': 20807680}
{'eval/walltime': 30726.046093463898, 'training/sps': 585.4186267961061, 'training/walltime': 35801.82812356949, 'training/entropy_loss': Array(0.01469475, dtype=float32), 'training/policy_loss': Array(-0.00434558, dtype=float32), 'training/total_loss': Array(0.01036303, dtype=float32), 'training/v_loss': Array(1.3864455e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.695, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.781754, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9292445, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7765274, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.97583216, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99092674255371, 'eval/sps': 1066.7473239425024, 'num_steps': 20889600}
{'eval/walltime': 30845.76219725609, 'training/sps': 581.9529098513206, 'training/walltime': 35942.59552693367, 'training/entropy_loss': Array(0.01512787, dtype=float32), 'training/policy_loss': Array(-0.00101466, dtype=float32), 'training/total_loss': Array(0.01413544, dtype=float32), 'training/v_loss': Array(2.2230364e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.926, dtype=float32), 'eval/episode_reward_alive': Array(4993.5547, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.628622, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9575305, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7648087, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.0622104, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.71610379219055, 'eval/sps': 1069.1961728239091, 'num_steps': 20971520}
{'eval/walltime': 30965.554033041, 'training/sps': 585.3872163607609, 'training/walltime': 36082.53708648682, 'training/entropy_loss': Array(0.01517591, dtype=float32), 'training/policy_loss': Array(-0.0023742, dtype=float32), 'training/total_loss': Array(0.01281811, dtype=float32), 'training/v_loss': Array(1.6397073e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.089, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.427054, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.068408, dtype=float32), 'eval/episode_reward_alive_std': Array(6.99775, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.92975414, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79183578491211, 'eval/sps': 1068.5202306259482, 'num_steps': 21053440}
{'eval/walltime': 31085.34524321556, 'training/sps': 582.5258246591071, 'training/walltime': 36223.166044950485, 'training/entropy_loss': Array(0.01513935, dtype=float32), 'training/policy_loss': Array(0.00352994, dtype=float32), 'training/total_loss': Array(0.01868784, dtype=float32), 'training/v_loss': Array(1.8557212e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.508, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.148252, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1135874, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1517453, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9294751, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79121017456055, 'eval/sps': 1068.5258109795998, 'num_steps': 21135360}
{'eval/walltime': 31205.120355844498, 'training/sps': 585.3249859199394, 'training/walltime': 36363.12248277664, 'training/entropy_loss': Array(0.0152975, dtype=float32), 'training/policy_loss': Array(-0.00050924, dtype=float32), 'training/total_loss': Array(0.014806, dtype=float32), 'training/v_loss': Array(1.7742641e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.7593, dtype=float32), 'eval/episode_reward_alive': Array(4993.9062, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.147116, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.328617, dtype=float32), 'eval/episode_reward_alive_std': Array(7.069341, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.95784587, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77511262893677, 'eval/sps': 1068.669418801082, 'num_steps': 21217280}
{'eval/walltime': 31324.88069176674, 'training/sps': 584.0800320713377, 'training/walltime': 36503.37723469734, 'training/entropy_loss': Array(0.01541121, dtype=float32), 'training/policy_loss': Array(0.00628765, dtype=float32), 'training/total_loss': Array(0.02171933, dtype=float32), 'training/v_loss': Array(2.0469493e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.653, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.097115, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9616327, dtype=float32), 'eval/episode_reward_alive_std': Array(6.731456, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.82966965, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76033592224121, 'eval/sps': 1068.8012772702032, 'num_steps': 21299200}
{'eval/walltime': 31444.60899591446, 'training/sps': 585.5796535821072, 'training/walltime': 36643.272805690765, 'training/entropy_loss': Array(0.01583024, dtype=float32), 'training/policy_loss': Array(-0.00135511, dtype=float32), 'training/total_loss': Array(0.0144945, dtype=float32), 'training/v_loss': Array(1.9366918e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.369, dtype=float32), 'eval/episode_reward_alive': Array(4994.258, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.888443, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9346223, dtype=float32), 'eval/episode_reward_alive_std': Array(6.763004, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8732297, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72830414772034, 'eval/sps': 1069.08722136475, 'num_steps': 21381120}
{'eval/walltime': 31564.35644674301, 'training/sps': 584.1562889205485, 'training/walltime': 36783.5092484951, 'training/entropy_loss': Array(0.01584911, dtype=float32), 'training/policy_loss': Array(0.00082495, dtype=float32), 'training/total_loss': Array(0.01668704, dtype=float32), 'training/v_loss': Array(1.2981931e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.465, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.894374, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2069945, dtype=float32), 'eval/episode_reward_alive_std': Array(6.990769, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9621296, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74745082855225, 'eval/sps': 1068.916282679481, 'num_steps': 21463040}
{'eval/walltime': 31684.195518493652, 'training/sps': 585.2571223170213, 'training/walltime': 36923.4819149971, 'training/entropy_loss': Array(0.01610732, dtype=float32), 'training/policy_loss': Array(0.00295801, dtype=float32), 'training/total_loss': Array(0.01909319, dtype=float32), 'training/v_loss': Array(2.7862603e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.69, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.333624, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.074231, dtype=float32), 'eval/episode_reward_alive_std': Array(6.762101, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1574658, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83907175064087, 'eval/sps': 1068.0990609334847, 'num_steps': 21544960}
{'eval/walltime': 31804.05042886734, 'training/sps': 583.6827867824095, 'training/walltime': 37063.83212208748, 'training/entropy_loss': Array(0.01602917, dtype=float32), 'training/policy_loss': Array(0.02321271, dtype=float32), 'training/total_loss': Array(0.0392532, dtype=float32), 'training/v_loss': Array(1.1319506e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.033, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.794992, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7219934, dtype=float32), 'eval/episode_reward_alive_std': Array(6.599135, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.9503064, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85491037368774, 'eval/sps': 1067.9579134548364, 'num_steps': 21626880}
{'eval/walltime': 31923.83331990242, 'training/sps': 585.6294640376167, 'training/walltime': 37203.715794324875, 'training/entropy_loss': Array(0.01479945, dtype=float32), 'training/policy_loss': Array(0.01050383, dtype=float32), 'training/total_loss': Array(0.02533853, dtype=float32), 'training/v_loss': Array(3.525277e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.6406, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.382774, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.527417, dtype=float32), 'eval/episode_reward_alive_std': Array(6.645563, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.8777899, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78289103507996, 'eval/sps': 1068.6000220391538, 'num_steps': 21708800}
{'eval/walltime': 32043.572633981705, 'training/sps': 583.9512437923097, 'training/walltime': 37344.001478910446, 'training/entropy_loss': Array(0.01477175, dtype=float32), 'training/policy_loss': Array(0.00814958, dtype=float32), 'training/total_loss': Array(0.02294543, dtype=float32), 'training/v_loss': Array(2.410472e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.4395, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.685877, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6009707, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7023783, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.8482684, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.73931407928467, 'eval/sps': 1068.9889196729953, 'num_steps': 21790720}
{'eval/walltime': 32163.426648139954, 'training/sps': 585.598102833129, 'training/walltime': 37483.892642498016, 'training/entropy_loss': Array(0.01471971, dtype=float32), 'training/policy_loss': Array(0.02349101, dtype=float32), 'training/total_loss': Array(0.03825256, dtype=float32), 'training/v_loss': Array(4.1846524e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.1367, dtype=float32), 'eval/episode_reward_alive': Array(4993.9062, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.770058, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.712646, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8732243, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.564995, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8540141582489, 'eval/sps': 1067.9658991729352, 'num_steps': 21872640}
{'eval/walltime': 32283.153167009354, 'training/sps': 582.9042742595673, 'training/walltime': 37624.43029785156, 'training/entropy_loss': Array(0.01460143, dtype=float32), 'training/policy_loss': Array(0.00644138, dtype=float32), 'training/total_loss': Array(0.02107418, dtype=float32), 'training/v_loss': Array(3.1374748e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.9414, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.45705, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.367656, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8160424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3448039, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72651886940002, 'eval/sps': 1069.1031628475296, 'num_steps': 21954560}
{'eval/walltime': 32403.075286865234, 'training/sps': 585.3547163472105, 'training/walltime': 37764.37962722778, 'training/entropy_loss': Array(0.01458352, dtype=float32), 'training/policy_loss': Array(0.00182177, dtype=float32), 'training/total_loss': Array(0.01642145, dtype=float32), 'training/v_loss': Array(1.6159715e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.7705, dtype=float32), 'eval/episode_reward_alive': Array(4994.1797, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.409328, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.010873, dtype=float32), 'eval/episode_reward_alive_std': Array(6.45832, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.1949644, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.92211985588074, 'eval/sps': 1067.3593841888974, 'num_steps': 22036480}
{'eval/walltime': 32522.706715106964, 'training/sps': 583.0344432069537, 'training/walltime': 37904.885905981064, 'training/entropy_loss': Array(0.01495771, dtype=float32), 'training/policy_loss': Array(0.00722702, dtype=float32), 'training/total_loss': Array(0.02220639, dtype=float32), 'training/v_loss': Array(2.1660786e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.545, dtype=float32), 'eval/episode_reward_alive': Array(4994.258, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.712386, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9331856, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6464815, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8217422, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.63142824172974, 'eval/sps': 1069.952953678364, 'num_steps': 22118400}
{'eval/walltime': 32642.579275369644, 'training/sps': 585.233471260707, 'training/walltime': 38044.86422920227, 'training/entropy_loss': Array(0.01495013, dtype=float32), 'training/policy_loss': Array(-0.0006291, dtype=float32), 'training/total_loss': Array(0.01433437, dtype=float32), 'training/v_loss': Array(1.3345791e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.4463, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.577168, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2140846, dtype=float32), 'eval/episode_reward_alive_std': Array(6.762101, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.88073343, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87256026268005, 'eval/sps': 1067.8006686393455, 'num_steps': 22200320}
{'eval/walltime': 32762.431911706924, 'training/sps': 581.9922875441175, 'training/walltime': 38185.622108221054, 'training/entropy_loss': Array(0.01513821, dtype=float32), 'training/policy_loss': Array(-0.00190816, dtype=float32), 'training/total_loss': Array(0.01324557, dtype=float32), 'training/v_loss': Array(1.5514164e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.0586, dtype=float32), 'eval/episode_reward_alive': Array(4993.047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.988052, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.257156, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9942603, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7183525, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85263633728027, 'eval/sps': 1067.9781764649051, 'num_steps': 22282240}
{'eval/walltime': 32882.37448000908, 'training/sps': 585.4018564576767, 'training/walltime': 38325.56016802788, 'training/entropy_loss': Array(0.01529912, dtype=float32), 'training/policy_loss': Array(-0.00287195, dtype=float32), 'training/total_loss': Array(0.0124395, dtype=float32), 'training/v_loss': Array(1.2327036e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.615, dtype=float32), 'eval/episode_reward_alive': Array(4992.383, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.767633, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0600843, dtype=float32), 'eval/episode_reward_alive_std': Array(6.672145, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8015839, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94256830215454, 'eval/sps': 1067.1774150904248, 'num_steps': 22364160}
{'eval/walltime': 33002.166090250015, 'training/sps': 582.846924725408, 'training/walltime': 38466.11165165901, 'training/entropy_loss': Array(0.01540524, dtype=float32), 'training/policy_loss': Array(-0.00164312, dtype=float32), 'training/total_loss': Array(0.01378019, dtype=float32), 'training/v_loss': Array(1.8072154e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.9326, dtype=float32), 'eval/episode_reward_alive': Array(4994.2188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.285822, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2793913, dtype=float32), 'eval/episode_reward_alive_std': Array(6.859001, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.76303816, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79161024093628, 'eval/sps': 1068.5222424388005, 'num_steps': 22446080}
{'eval/walltime': 33122.02143263817, 'training/sps': 584.5479557650276, 'training/walltime': 38606.25413131714, 'training/entropy_loss': Array(0.01571794, dtype=float32), 'training/policy_loss': Array(-0.00111958, dtype=float32), 'training/total_loss': Array(0.01460949, dtype=float32), 'training/v_loss': Array(1.1126498e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.607, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.064726, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.283518, dtype=float32), 'eval/episode_reward_alive_std': Array(6.94522, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.6878758, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85534238815308, 'eval/sps': 1067.9540640372154, 'num_steps': 22528000}
{'eval/walltime': 33241.661190748215, 'training/sps': 582.6280373310396, 'training/walltime': 38746.85841870308, 'training/entropy_loss': Array(0.01562395, dtype=float32), 'training/policy_loss': Array(0.00012682, dtype=float32), 'training/total_loss': Array(0.01577167, dtype=float32), 'training/v_loss': Array(2.0896674e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.9033, dtype=float32), 'eval/episode_reward_alive': Array(4994.6875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.784042, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.738616, dtype=float32), 'eval/episode_reward_alive_std': Array(6.517704, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.62910706, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.63975811004639, 'eval/sps': 1069.8784586497052, 'num_steps': 22609920}
{'eval/walltime': 33361.523641586304, 'training/sps': 585.5711938225927, 'training/walltime': 38886.7560107708, 'training/entropy_loss': Array(0.0160671, dtype=float32), 'training/policy_loss': Array(0.00126112, dtype=float32), 'training/total_loss': Array(0.01735171, dtype=float32), 'training/v_loss': Array(2.34945e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.3696, dtype=float32), 'eval/episode_reward_alive': Array(4994.1016, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.731665, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.891024, dtype=float32), 'eval/episode_reward_alive_std': Array(6.597632, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.63064414, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86245083808899, 'eval/sps': 1067.8907289565043, 'num_steps': 22691840}
{'eval/walltime': 33481.24294638634, 'training/sps': 579.3290334719475, 'training/walltime': 39028.16097283363, 'training/entropy_loss': Array(0.01590484, dtype=float32), 'training/policy_loss': Array(0.0022667, dtype=float32), 'training/total_loss': Array(0.01818501, dtype=float32), 'training/v_loss': Array(1.3466619e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.101, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.570787, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0670767, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7743883, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7145894, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.71930480003357, 'eval/sps': 1069.1675850757538, 'num_steps': 22773760}
{'eval/walltime': 33601.09261083603, 'training/sps': 585.5191841973385, 'training/walltime': 39168.07099151611, 'training/entropy_loss': Array(0.01622321, dtype=float32), 'training/policy_loss': Array(0.0038833, dtype=float32), 'training/total_loss': Array(0.02012991, dtype=float32), 'training/v_loss': Array(2.3401106e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.6113, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.513899, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.26644, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7604084, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8751583, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84966444969177, 'eval/sps': 1068.0046589010637, 'num_steps': 22855680}
{'eval/walltime': 33720.81677722931, 'training/sps': 583.1966711966819, 'training/walltime': 39308.538185596466, 'training/entropy_loss': Array(0.01625934, dtype=float32), 'training/policy_loss': Array(-9.350188e-06, dtype=float32), 'training/total_loss': Array(0.01626349, dtype=float32), 'training/v_loss': Array(1.3503381e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.8174, dtype=float32), 'eval/episode_reward_alive': Array(4994.1016, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.284277, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9271913, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6858525, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7290543, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72416639328003, 'eval/sps': 1069.1241697982246, 'num_steps': 22937600}
{'eval/walltime': 33840.77006363869, 'training/sps': 585.0385977812072, 'training/walltime': 39448.563134908676, 'training/entropy_loss': Array(0.01625496, dtype=float32), 'training/policy_loss': Array(0.00192372, dtype=float32), 'training/total_loss': Array(0.01819417, dtype=float32), 'training/v_loss': Array(1.5487054e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.7363, dtype=float32), 'eval/episode_reward_alive': Array(4994.5312, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.794765, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9501143, dtype=float32), 'eval/episode_reward_alive_std': Array(6.715115, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.62156296, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95328640937805, 'eval/sps': 1067.0820602877025, 'num_steps': 23019520}
{'eval/walltime': 33960.45113945007, 'training/sps': 584.5855918086072, 'training/walltime': 39588.696592092514, 'training/entropy_loss': Array(0.01632625, dtype=float32), 'training/policy_loss': Array(0.03448994, dtype=float32), 'training/total_loss': Array(0.05082896, dtype=float32), 'training/v_loss': Array(1.2766884e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.1094, dtype=float32), 'eval/episode_reward_alive': Array(4994.297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.187798, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5625362, dtype=float32), 'eval/episode_reward_alive_std': Array(7.493079, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.68026817, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.68107581138611, 'eval/sps': 1069.5091026899213, 'num_steps': 23101440}
{'eval/walltime': 34080.52377605438, 'training/sps': 584.8956481702916, 'training/walltime': 39728.75576376915, 'training/entropy_loss': Array(0.01460331, dtype=float32), 'training/policy_loss': Array(0.02111278, dtype=float32), 'training/total_loss': Array(0.03576567, dtype=float32), 'training/v_loss': Array(4.958324e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.554, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.195351, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.110146, dtype=float32), 'eval/episode_reward_alive_std': Array(8.052562, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8225139, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.07263660430908, 'eval/sps': 1066.02139854574, 'num_steps': 23183360}
{'eval/walltime': 34200.26809883118, 'training/sps': 583.922670919342, 'training/walltime': 39869.04831290245, 'training/entropy_loss': Array(0.01471316, dtype=float32), 'training/policy_loss': Array(0.00216275, dtype=float32), 'training/total_loss': Array(0.01695657, dtype=float32), 'training/v_loss': Array(8.0663245e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.819, dtype=float32), 'eval/episode_reward_alive': Array(4991.914, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.095294, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.249284, dtype=float32), 'eval/episode_reward_alive_std': Array(8.151904, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.64470637, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74432277679443, 'eval/sps': 1068.9442057189992, 'num_steps': 23265280}
{'eval/walltime': 34320.31337976456, 'training/sps': 585.3267797313107, 'training/walltime': 40009.00432181358, 'training/entropy_loss': Array(0.01466631, dtype=float32), 'training/policy_loss': Array(-0.00391911, dtype=float32), 'training/total_loss': Array(0.01078098, dtype=float32), 'training/v_loss': Array(3.3779397e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.551, dtype=float32), 'eval/episode_reward_alive': Array(4991.4844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.93379, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.582151, dtype=float32), 'eval/episode_reward_alive_std': Array(8.532094, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.5364972, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04528093338013, 'eval/sps': 1066.2643213025124, 'num_steps': 23347200}
{'eval/walltime': 34440.1617910862, 'training/sps': 583.6286713593147, 'training/walltime': 40149.367542505264, 'training/entropy_loss': Array(0.01488634, dtype=float32), 'training/policy_loss': Array(0.00105555, dtype=float32), 'training/total_loss': Array(0.01598701, dtype=float32), 'training/v_loss': Array(4.5121553e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.1216, dtype=float32), 'eval/episode_reward_alive': Array(4992.8125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.691065, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.538829, dtype=float32), 'eval/episode_reward_alive_std': Array(8.495173, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.4061342, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84841132164001, 'eval/sps': 1068.0158258959593, 'num_steps': 23429120}
{'eval/walltime': 34560.15822672844, 'training/sps': 585.407229364437, 'training/walltime': 40289.3043179512, 'training/entropy_loss': Array(0.01513023, dtype=float32), 'training/policy_loss': Array(0.00275981, dtype=float32), 'training/total_loss': Array(0.01793522, dtype=float32), 'training/v_loss': Array(4.5182474e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.496, dtype=float32), 'eval/episode_reward_alive': Array(4992.0312, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.535513, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.682206, dtype=float32), 'eval/episode_reward_alive_std': Array(8.602268, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.43685657, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99643564224243, 'eval/sps': 1066.6983507878467, 'num_steps': 23511040}
{'eval/walltime': 34680.10074543953, 'training/sps': 583.7890024633518, 'training/walltime': 40429.628989458084, 'training/entropy_loss': Array(0.01539531, dtype=float32), 'training/policy_loss': Array(0.00926986, dtype=float32), 'training/total_loss': Array(0.02470808, dtype=float32), 'training/v_loss': Array(4.2919168e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.285, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.425236, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.559734, dtype=float32), 'eval/episode_reward_alive_std': Array(7.5323806, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.43238962, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94251871109009, 'eval/sps': 1067.1778563223127, 'num_steps': 23592960}
{'eval/walltime': 34800.17243719101, 'training/sps': 585.3513637327237, 'training/walltime': 40569.57912039757, 'training/entropy_loss': Array(0.01558329, dtype=float32), 'training/policy_loss': Array(0.02001548, dtype=float32), 'training/total_loss': Array(0.03563979, dtype=float32), 'training/v_loss': Array(4.10109e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.412, dtype=float32), 'eval/episode_reward_alive': Array(4994.5703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.157896, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0154257, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9604726, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.30294812, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.0716917514801, 'eval/sps': 1066.0297871452467, 'num_steps': 23674880}
{'eval/walltime': 34919.948858976364, 'training/sps': 583.4532407588174, 'training/walltime': 40709.98454499245, 'training/entropy_loss': Array(0.01738151, dtype=float32), 'training/policy_loss': Array(0.08129388, dtype=float32), 'training/total_loss': Array(0.09871746, dtype=float32), 'training/v_loss': Array(4.2060183e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.6133, dtype=float32), 'eval/episode_reward_alive': Array(4994.6484, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-29.035156, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.3324533, dtype=float32), 'eval/episode_reward_alive_std': Array(6.678545, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.7482364, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77642178535461, 'eval/sps': 1068.657738243195, 'num_steps': 23756800}
{'eval/walltime': 35040.00067925453, 'training/sps': 585.3737896849013, 'training/walltime': 40849.929314374924, 'training/entropy_loss': Array(0.02149827, dtype=float32), 'training/policy_loss': Array(0.06712444, dtype=float32), 'training/total_loss': Array(0.08867495, dtype=float32), 'training/v_loss': Array(5.2221905e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4917.798, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-75.71778, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7879043, dtype=float32), 'eval/episode_reward_alive_std': Array(7.378161, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.2880967, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.05182027816772, 'eval/sps': 1066.2062408001464, 'num_steps': 23838720}
{'eval/walltime': 35159.84163284302, 'training/sps': 584.8307280097611, 'training/walltime': 40990.00403356552, 'training/entropy_loss': Array(0.02480351, dtype=float32), 'training/policy_loss': Array(0.11147971, dtype=float32), 'training/total_loss': Array(0.1363489, dtype=float32), 'training/v_loss': Array(6.567365e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4937.3145, dtype=float32), 'eval/episode_reward_alive': Array(4995.3125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-57.99797, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.481624, dtype=float32), 'eval/episode_reward_alive_std': Array(6.4876685, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.3819714, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84095358848572, 'eval/sps': 1068.0822887936215, 'num_steps': 23920640}
{'eval/walltime': 35280.01304602623, 'training/sps': 585.6041819792418, 'training/walltime': 41129.893744945526, 'training/entropy_loss': Array(0.02270968, dtype=float32), 'training/policy_loss': Array(0.12731388, dtype=float32), 'training/total_loss': Array(0.15006487, dtype=float32), 'training/v_loss': Array(4.1295953e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4952.4136, dtype=float32), 'eval/episode_reward_alive': Array(4994.336, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-41.92275, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0227923, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7422147, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8469634, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.17141318321228, 'eval/sps': 1065.1451673024126, 'num_steps': 24002560}
{'eval/walltime': 35399.8512070179, 'training/sps': 583.7496232590387, 'training/walltime': 41270.22788262367, 'training/entropy_loss': Array(0.02160186, dtype=float32), 'training/policy_loss': Array(0.11846936, dtype=float32), 'training/total_loss': Array(0.14009486, dtype=float32), 'training/v_loss': Array(2.3639415e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4943.962, dtype=float32), 'eval/episode_reward_alive': Array(4993.164, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-49.201855, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9356794, dtype=float32), 'eval/episode_reward_alive_std': Array(7.095088, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2789776, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8381609916687, 'eval/sps': 1068.1071783878485, 'num_steps': 24084480}
{'eval/walltime': 35519.94216823578, 'training/sps': 585.6533617317152, 'training/walltime': 41410.10584688187, 'training/entropy_loss': Array(0.02205055, dtype=float32), 'training/policy_loss': Array(0.00901305, dtype=float32), 'training/total_loss': Array(0.03108877, dtype=float32), 'training/v_loss': Array(2.5168301e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4945.455, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-48.529778, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.688848, dtype=float32), 'eval/episode_reward_alive_std': Array(6.799568, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.4266553, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.09096121788025, 'eval/sps': 1065.8587349281886, 'num_steps': 24166400}
{'eval/walltime': 35639.73816728592, 'training/sps': 583.9548116282461, 'training/walltime': 41550.390674352646, 'training/entropy_loss': Array(0.02224287, dtype=float32), 'training/policy_loss': Array(0.00776563, dtype=float32), 'training/total_loss': Array(0.03002166, dtype=float32), 'training/v_loss': Array(1.3161154e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4945.1685, dtype=float32), 'eval/episode_reward_alive': Array(4993.203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-48.03399, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.585864, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7237444, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3201785, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79599905014038, 'eval/sps': 1068.483096388101, 'num_steps': 24248320}
{'eval/walltime': 35759.88842320442, 'training/sps': 585.4743875488715, 'training/walltime': 41690.31139802933, 'training/entropy_loss': Array(0.02197056, dtype=float32), 'training/policy_loss': Array(0.00614058, dtype=float32), 'training/total_loss': Array(0.02812967, dtype=float32), 'training/v_loss': Array(1.8525634e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4946.1616, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-47.27572, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.161641, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1466227, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.4869008, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.15025591850281, 'eval/sps': 1065.3327287693971, 'num_steps': 24330240}
{'eval/walltime': 35879.72190976143, 'training/sps': 583.4111351172547, 'training/walltime': 41830.726955890656, 'training/entropy_loss': Array(0.02222141, dtype=float32), 'training/policy_loss': Array(0.00834564, dtype=float32), 'training/total_loss': Array(0.03058248, dtype=float32), 'training/v_loss': Array(1.5432517e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4945.4927, dtype=float32), 'eval/episode_reward_alive': Array(4992.0703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-46.577374, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7026973, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9464283, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.2847073, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83348655700684, 'eval/sps': 1068.148842845428, 'num_steps': 24412160}
{'eval/walltime': 35999.818232774734, 'training/sps': 585.731829275962, 'training/walltime': 41970.58618140221, 'training/entropy_loss': Array(0.02194038, dtype=float32), 'training/policy_loss': Array(0.01114853, dtype=float32), 'training/total_loss': Array(0.0331139, dtype=float32), 'training/v_loss': Array(2.4994311e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4947.464, dtype=float32), 'eval/episode_reward_alive': Array(4992.8516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-45.387733, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.606176, dtype=float32), 'eval/episode_reward_alive_std': Array(7.117419, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9453366, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.09632301330566, 'eval/sps': 1065.8111488210898, 'num_steps': 24494080}
{'eval/walltime': 36119.54309129715, 'training/sps': 584.0547376732508, 'training/walltime': 42110.847007513046, 'training/entropy_loss': Array(0.02235218, dtype=float32), 'training/policy_loss': Array(0.0061563, dtype=float32), 'training/total_loss': Array(0.02852232, dtype=float32), 'training/v_loss': Array(1.385072e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4949.1978, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-44.78696, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.336262, dtype=float32), 'eval/episode_reward_alive_std': Array(6.799568, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8656032, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72485852241516, 'eval/sps': 1069.1179891938277, 'num_steps': 24576000}
{'eval/walltime': 36239.820178985596, 'training/sps': 585.5937993011505, 'training/walltime': 42250.73919916153, 'training/entropy_loss': Array(0.02206873, dtype=float32), 'training/policy_loss': Array(0.00732405, dtype=float32), 'training/total_loss': Array(0.0294124, dtype=float32), 'training/v_loss': Array(1.9619802e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4949.224, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-44.135433, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6927977, dtype=float32), 'eval/episode_reward_alive_std': Array(7.074088, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9705269, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.27708768844604, 'eval/sps': 1064.2093391183416, 'num_steps': 24657920}
{'eval/walltime': 36359.627108335495, 'training/sps': 584.1082569191036, 'training/walltime': 42390.9871737957, 'training/entropy_loss': Array(0.02205272, dtype=float32), 'training/policy_loss': Array(0.00406487, dtype=float32), 'training/total_loss': Array(0.02613624, dtype=float32), 'training/v_loss': Array(1.8650357e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4949.28, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-43.68923, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.633331, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9999304, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9263412, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80692934989929, 'eval/sps': 1068.3856158784658, 'num_steps': 24739840}
{'eval/walltime': 36479.89927601814, 'training/sps': 585.6109199883814, 'training/walltime': 42530.87527561188, 'training/entropy_loss': Array(0.02230045, dtype=float32), 'training/policy_loss': Array(0.00343695, dtype=float32), 'training/total_loss': Array(0.02575604, dtype=float32), 'training/v_loss': Array(1.8639448e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4950.621, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-43.089752, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4291234, dtype=float32), 'eval/episode_reward_alive_std': Array(6.966608, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.76575243, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.2721676826477, 'eval/sps': 1064.252873015003, 'num_steps': 24821760}
{'eval/walltime': 36599.904648542404, 'training/sps': 583.9505252681769, 'training/walltime': 42671.1611328125, 'training/entropy_loss': Array(0.02203906, dtype=float32), 'training/policy_loss': Array(0.00839333, dtype=float32), 'training/total_loss': Array(0.03045133, dtype=float32), 'training/v_loss': Array(1.8945539e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4950.675, dtype=float32), 'eval/episode_reward_alive': Array(4993.203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-42.52848, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.748485, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3083425, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.6818438, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.00537252426147, 'eval/sps': 1066.6189130334333, 'num_steps': 24903680}
{'eval/walltime': 36719.840297698975, 'training/sps': 585.362011059007, 'training/walltime': 42811.108718156815, 'training/entropy_loss': Array(0.02230322, dtype=float32), 'training/policy_loss': Array(0.00147909, dtype=float32), 'training/total_loss': Array(0.02380093, dtype=float32), 'training/v_loss': Array(1.8616242e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4952.046, dtype=float32), 'eval/episode_reward_alive': Array(4994.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-42.016647, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.474402, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0917535, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.67603284, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.93564915657043, 'eval/sps': 1067.2389810714405, 'num_steps': 24985600}
{'eval/walltime': 36839.732944488525, 'training/sps': 582.9222952199972, 'training/walltime': 42951.642028808594, 'training/entropy_loss': Array(0.02210748, dtype=float32), 'training/policy_loss': Array(-0.00281427, dtype=float32), 'training/total_loss': Array(0.01931045, dtype=float32), 'training/v_loss': Array(1.7235072e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4952.1553, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-41.51601, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.44585, dtype=float32), 'eval/episode_reward_alive_std': Array(7.13936, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.42388338, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.89264678955078, 'eval/sps': 1067.621771872967, 'num_steps': 25067520}
{'eval/walltime': 36959.777254104614, 'training/sps': 585.6662571749968, 'training/walltime': 43091.51691317558, 'training/entropy_loss': Array(0.02231935, dtype=float32), 'training/policy_loss': Array(0.00433288, dtype=float32), 'training/total_loss': Array(0.02666268, dtype=float32), 'training/v_loss': Array(1.0457039e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4951.593, dtype=float32), 'eval/episode_reward_alive': Array(4992.6953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-41.102005, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8384037, dtype=float32), 'eval/episode_reward_alive_std': Array(7.497456, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.53940594, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04430961608887, 'eval/sps': 1066.2729487916092, 'num_steps': 25149440}
{'eval/walltime': 37079.735964775085, 'training/sps': 584.363687394578, 'training/walltime': 43231.70358419418, 'training/entropy_loss': Array(0.0221604, dtype=float32), 'training/policy_loss': Array(0.01100675, dtype=float32), 'training/total_loss': Array(0.03319706, dtype=float32), 'training/v_loss': Array(2.9912506e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4952.419, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-40.54943, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.450671, dtype=float32), 'eval/episode_reward_alive_std': Array(7.165387, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.4592392, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95871067047119, 'eval/sps': 1067.0338092547393, 'num_steps': 25231360}
{'eval/walltime': 37199.824404001236, 'training/sps': 585.7566719957405, 'training/walltime': 43371.556878089905, 'training/entropy_loss': Array(0.02221413, dtype=float32), 'training/policy_loss': Array(0.01225131, dtype=float32), 'training/total_loss': Array(0.0344866, dtype=float32), 'training/v_loss': Array(2.115866e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4952.723, dtype=float32), 'eval/episode_reward_alive': Array(4992.6953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-39.971794, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.167633, dtype=float32), 'eval/episode_reward_alive_std': Array(7.903281, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3805915, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.08843922615051, 'eval/sps': 1065.8811191554455, 'num_steps': 25313280}
{'eval/walltime': 37319.617797374725, 'training/sps': 583.3769157579085, 'training/walltime': 43511.98067235947, 'training/entropy_loss': Array(0.02221388, dtype=float32), 'training/policy_loss': Array(0.00929948, dtype=float32), 'training/total_loss': Array(0.03153469, dtype=float32), 'training/v_loss': Array(2.1338034e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4953.798, dtype=float32), 'eval/episode_reward_alive': Array(4992.6953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-38.89817, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4147, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1234193, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.4444814, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79339337348938, 'eval/sps': 1068.5063374148208, 'num_steps': 25395200}
{'eval/walltime': 37439.79503130913, 'training/sps': 585.5621056167223, 'training/walltime': 43651.880435705185, 'training/entropy_loss': Array(0.02191687, dtype=float32), 'training/policy_loss': Array(0.00996898, dtype=float32), 'training/total_loss': Array(0.0319152, dtype=float32), 'training/v_loss': Array(2.9353207e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4955.507, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-38.47773, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1507607, dtype=float32), 'eval/episode_reward_alive_std': Array(6.941704, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3563777, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.17723393440247, 'eval/sps': 1065.0935772899177, 'num_steps': 25477120}
{'eval/walltime': 37559.618639707565, 'training/sps': 584.1072768577444, 'training/walltime': 43792.12864565849, 'training/entropy_loss': Array(0.02214134, dtype=float32), 'training/policy_loss': Array(0.00857698, dtype=float32), 'training/total_loss': Array(0.03073523, dtype=float32), 'training/v_loss': Array(1.6906515e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4954.8047, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-38.593292, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5859475, dtype=float32), 'eval/episode_reward_alive_std': Array(7.445993, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2839819, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8236083984375, 'eval/sps': 1068.2369001472093, 'num_steps': 25559040}
{'eval/walltime': 37679.46468782425, 'training/sps': 585.6693698155902, 'training/walltime': 43932.00278663635, 'training/entropy_loss': Array(0.02197889, dtype=float32), 'training/policy_loss': Array(5.58568e-05, dtype=float32), 'training/total_loss': Array(0.02206569, dtype=float32), 'training/v_loss': Array(3.0948337e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4956.9043, dtype=float32), 'eval/episode_reward_alive': Array(4994.336, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-37.43231, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2401857, dtype=float32), 'eval/episode_reward_alive_std': Array(7.108838, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.27129206, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84604811668396, 'eval/sps': 1068.0368857501019, 'num_steps': 25640960}
{'eval/walltime': 37799.22879123688, 'training/sps': 584.2812609655599, 'training/walltime': 44072.20923423767, 'training/entropy_loss': Array(0.02192128, dtype=float32), 'training/policy_loss': Array(0.01242531, dtype=float32), 'training/total_loss': Array(0.034365, dtype=float32), 'training/v_loss': Array(1.8403072e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4957.058, dtype=float32), 'eval/episode_reward_alive': Array(4994.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-37.004417, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.419101, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2819877, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.28237763, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76410341262817, 'eval/sps': 1068.7676553549302, 'num_steps': 25722880}
{'eval/walltime': 37919.251977443695, 'training/sps': 585.4721379202377, 'training/walltime': 44212.13049554825, 'training/entropy_loss': Array(0.02165788, dtype=float32), 'training/policy_loss': Array(0.0235282, dtype=float32), 'training/total_loss': Array(0.0452091, dtype=float32), 'training/v_loss': Array(2.3019025e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4955.7334, dtype=float32), 'eval/episode_reward_alive': Array(4992.539, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-36.805943, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.354071, dtype=float32), 'eval/episode_reward_alive_std': Array(8.26788, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24353403, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02318620681763, 'eval/sps': 1066.460606865053, 'num_steps': 25804800}
{'eval/walltime': 38039.05381178856, 'training/sps': 584.2012456404564, 'training/walltime': 44352.35614657402, 'training/entropy_loss': Array(0.02169518, dtype=float32), 'training/policy_loss': Array(0.01172424, dtype=float32), 'training/total_loss': Array(0.03346676, dtype=float32), 'training/v_loss': Array(4.7345806e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4956.1963, dtype=float32), 'eval/episode_reward_alive': Array(4992.617, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-36.420956, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.95493, dtype=float32), 'eval/episode_reward_alive_std': Array(7.9048257, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.23579755, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80183434486389, 'eval/sps': 1068.4310528295978, 'num_steps': 25886720}
{'eval/walltime': 38158.92560982704, 'training/sps': 585.7611876277812, 'training/walltime': 44492.20836234093, 'training/entropy_loss': Array(0.021552, dtype=float32), 'training/policy_loss': Array(0.03958306, dtype=float32), 'training/total_loss': Array(0.06116877, dtype=float32), 'training/v_loss': Array(3.3716293e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4957.263, dtype=float32), 'eval/episode_reward_alive': Array(4992.422, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-35.159016, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.147647, dtype=float32), 'eval/episode_reward_alive_std': Array(8.172562, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24845238, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87179803848267, 'eval/sps': 1067.8074584224382, 'num_steps': 25968640}
{'eval/walltime': 38278.71183133125, 'training/sps': 582.4750072624727, 'training/walltime': 44632.84958982468, 'training/entropy_loss': Array(0.02127447, dtype=float32), 'training/policy_loss': Array(0.01425705, dtype=float32), 'training/total_loss': Array(0.03557898, dtype=float32), 'training/v_loss': Array(4.747026e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4957.6943, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-34.96212, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8679185, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8794007, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2522932, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78622150421143, 'eval/sps': 1068.5703112815843, 'num_steps': 26050560}
{'eval/walltime': 38398.58770561218, 'training/sps': 585.6507673385685, 'training/walltime': 44772.72817373276, 'training/entropy_loss': Array(0.02156204, dtype=float32), 'training/policy_loss': Array(0.01297749, dtype=float32), 'training/total_loss': Array(0.03456654, dtype=float32), 'training/v_loss': Array(2.7006801e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4959.259, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-33.397522, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.067937, dtype=float32), 'eval/episode_reward_alive_std': Array(8.147505, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.27645105, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87587428092957, 'eval/sps': 1067.771148847111, 'num_steps': 26132480}
{'eval/walltime': 38518.38974452019, 'training/sps': 584.4050370573443, 'training/walltime': 44912.90492582321, 'training/entropy_loss': Array(0.02128554, dtype=float32), 'training/policy_loss': Array(0.01195416, dtype=float32), 'training/total_loss': Array(0.03327188, dtype=float32), 'training/v_loss': Array(3.217609e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.205, dtype=float32), 'eval/episode_reward_alive': Array(4993.164, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-32.95895, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.284859, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3386574, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.32522106, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80203890800476, 'eval/sps': 1068.4292284732348, 'num_steps': 26214400}
{'eval/walltime': 38638.37818837166, 'training/sps': 585.4381013030517, 'training/walltime': 45052.83432197571, 'training/entropy_loss': Array(0.02150859, dtype=float32), 'training/policy_loss': Array(0.0013167, dtype=float32), 'training/total_loss': Array(0.02284433, dtype=float32), 'training/v_loss': Array(1.9044965e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.883, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-32.515396, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.756256, dtype=float32), 'eval/episode_reward_alive_std': Array(7.854477, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.32904792, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98844385147095, 'eval/sps': 1066.769397880068, 'num_steps': 26296320}
{'eval/walltime': 38758.27642130852, 'training/sps': 583.486884465005, 'training/walltime': 45193.231650829315, 'training/entropy_loss': Array(0.02141949, dtype=float32), 'training/policy_loss': Array(0.0097307, dtype=float32), 'training/total_loss': Array(0.03120369, dtype=float32), 'training/v_loss': Array(5.3514243e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.2065, dtype=float32), 'eval/episode_reward_alive': Array(4991.875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-31.668495, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5578604, dtype=float32), 'eval/episode_reward_alive_std': Array(7.629097, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.33886376, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.89823293685913, 'eval/sps': 1067.5720305853667, 'num_steps': 26378240}
{'eval/walltime': 38878.20343184471, 'training/sps': 585.7800927246825, 'training/walltime': 45333.0793530941, 'training/entropy_loss': Array(0.02135139, dtype=float32), 'training/policy_loss': Array(0.00222123, dtype=float32), 'training/total_loss': Array(0.02358902, dtype=float32), 'training/v_loss': Array(1.6397738e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.952, dtype=float32), 'eval/episode_reward_alive': Array(4992.0312, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-31.078468, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6795025, dtype=float32), 'eval/episode_reward_alive_std': Array(7.741868, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.28990808, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.92701053619385, 'eval/sps': 1067.3158567674773, 'num_steps': 26460160}
{'eval/walltime': 38998.03205513954, 'training/sps': 583.1138126404261, 'training/walltime': 45473.56650710106, 'training/entropy_loss': Array(0.02130806, dtype=float32), 'training/policy_loss': Array(0.001449, dtype=float32), 'training/total_loss': Array(0.02278649, dtype=float32), 'training/v_loss': Array(2.9425017e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4961.533, dtype=float32), 'eval/episode_reward_alive': Array(4992.3047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-30.771791, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.396938, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4713607, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3100075, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82862329483032, 'eval/sps': 1068.1921938222101, 'num_steps': 26542080}
{'eval/walltime': 39117.930421590805, 'training/sps': 585.9298357116627, 'training/walltime': 45613.378469228745, 'training/entropy_loss': Array(0.02120669, dtype=float32), 'training/policy_loss': Array(0.00188516, dtype=float32), 'training/total_loss': Array(0.02310784, dtype=float32), 'training/v_loss': Array(1.5999363e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.1265, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-30.232838, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.890107, dtype=float32), 'eval/episode_reward_alive_std': Array(7.9330544, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25192404, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.89836645126343, 'eval/sps': 1067.5708417764786, 'num_steps': 26624000}
{'eval/walltime': 39237.67017912865, 'training/sps': 584.5786844264475, 'training/walltime': 45753.513582229614, 'training/entropy_loss': Array(0.02121383, dtype=float32), 'training/policy_loss': Array(0.00079949, dtype=float32), 'training/total_loss': Array(0.0220364, dtype=float32), 'training/v_loss': Array(2.3086159e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.318, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-29.807262, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8727946, dtype=float32), 'eval/episode_reward_alive_std': Array(7.88095, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26015696, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7397575378418, 'eval/sps': 1068.9849606514167, 'num_steps': 26705920}
{'eval/walltime': 39357.51397919655, 'training/sps': 585.904665586875, 'training/walltime': 45893.331550598145, 'training/entropy_loss': Array(0.02090704, dtype=float32), 'training/policy_loss': Array(-0.00305212, dtype=float32), 'training/total_loss': Array(0.01787912, dtype=float32), 'training/v_loss': Array(2.4198236e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.083, dtype=float32), 'eval/episode_reward_alive': Array(4992.539, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-29.455692, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9477673, dtype=float32), 'eval/episode_reward_alive_std': Array(7.9055977, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25287864, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84380006790161, 'eval/sps': 1068.0569201533765, 'num_steps': 26787840}
{'eval/walltime': 39477.33873987198, 'training/sps': 583.4471625963087, 'training/walltime': 46033.73843789101, 'training/entropy_loss': Array(0.02138145, dtype=float32), 'training/policy_loss': Array(0.00191391, dtype=float32), 'training/total_loss': Array(0.02332487, dtype=float32), 'training/v_loss': Array(2.9508581e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4962.133, dtype=float32), 'eval/episode_reward_alive': Array(4991.172, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-29.039072, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.101869, dtype=float32), 'eval/episode_reward_alive_std': Array(8.040046, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24229111, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8247606754303, 'eval/sps': 1068.2266276059086, 'num_steps': 26869760}
{'eval/walltime': 39597.25730633736, 'training/sps': 585.3646168559062, 'training/walltime': 46173.685400247574, 'training/entropy_loss': Array(0.02102897, dtype=float32), 'training/policy_loss': Array(0.00182581, dtype=float32), 'training/total_loss': Array(0.02288896, dtype=float32), 'training/v_loss': Array(3.4180528e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.437, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-28.54756, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.940549, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8650575, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25347912, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.91856646537781, 'eval/sps': 1067.3910118576628, 'num_steps': 26951680}
{'eval/walltime': 39717.01863884926, 'training/sps': 583.7537826993738, 'training/walltime': 46314.0185379982, 'training/entropy_loss': Array(0.02141527, dtype=float32), 'training/policy_loss': Array(0.00139496, dtype=float32), 'training/total_loss': Array(0.02283275, dtype=float32), 'training/v_loss': Array(2.2520988e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.7305, dtype=float32), 'eval/episode_reward_alive': Array(4991.836, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-28.10526, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.877396, dtype=float32), 'eval/episode_reward_alive_std': Array(8.835985, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22200923, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76133251190186, 'eval/sps': 1068.7923832784625, 'num_steps': 27033600}
{'eval/walltime': 39836.99340677261, 'training/sps': 585.3041908748191, 'training/walltime': 46453.97994828224, 'training/entropy_loss': Array(0.02121018, dtype=float32), 'training/policy_loss': Array(0.01258042, dtype=float32), 'training/total_loss': Array(0.03381794, dtype=float32), 'training/v_loss': Array(2.7340466e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4964.8604, dtype=float32), 'eval/episode_reward_alive': Array(4992.5, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-27.639687, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7489223, dtype=float32), 'eval/episode_reward_alive_std': Array(7.6801286, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22835249, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9747679233551, 'eval/sps': 1066.8909989621463, 'num_steps': 27115520}
{'eval/walltime': 39956.83060669899, 'training/sps': 584.1565640190588, 'training/walltime': 46594.21632504463, 'training/entropy_loss': Array(0.02123417, dtype=float32), 'training/policy_loss': Array(0.02040716, dtype=float32), 'training/total_loss': Array(0.04166365, dtype=float32), 'training/v_loss': Array(2.2320306e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.157, dtype=float32), 'eval/episode_reward_alive': Array(4992.617, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-27.460024, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.688086, dtype=float32), 'eval/episode_reward_alive_std': Array(8.545942, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.29468554, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83719992637634, 'eval/sps': 1068.1157443484876, 'num_steps': 27197440}
{'eval/walltime': 40076.820695877075, 'training/sps': 585.3988055044051, 'training/walltime': 46734.15511417389, 'training/entropy_loss': Array(0.021323, dtype=float32), 'training/policy_loss': Array(0.00269005, dtype=float32), 'training/total_loss': Array(0.02403632, dtype=float32), 'training/v_loss': Array(2.3274326e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.373, dtype=float32), 'eval/episode_reward_alive': Array(4992.7344, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-27.36138, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.197251, dtype=float32), 'eval/episode_reward_alive_std': Array(8.097534, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24460371, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99008917808533, 'eval/sps': 1066.7547701379456, 'num_steps': 27279360}
{'eval/walltime': 40196.542390584946, 'training/sps': 583.5714487947159, 'training/walltime': 46874.532098293304, 'training/entropy_loss': Array(0.02109036, dtype=float32), 'training/policy_loss': Array(0.01873313, dtype=float32), 'training/total_loss': Array(0.03985765, dtype=float32), 'training/v_loss': Array(3.416525e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4966.324, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-27.191517, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8876405, dtype=float32), 'eval/episode_reward_alive_std': Array(7.7902026, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2365446, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72169470787048, 'eval/sps': 1069.1462421437416, 'num_steps': 27361280}
{'eval/walltime': 40316.57404112816, 'training/sps': 585.5512095221522, 'training/walltime': 47014.43446493149, 'training/entropy_loss': Array(0.02127811, dtype=float32), 'training/policy_loss': Array(0.03519655, dtype=float32), 'training/total_loss': Array(0.05649358, dtype=float32), 'training/v_loss': Array(1.8915787e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.1494, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-26.36605, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7558575, dtype=float32), 'eval/episode_reward_alive_std': Array(7.638292, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25529104, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.03165054321289, 'eval/sps': 1066.3854026894214, 'num_steps': 27443200}
{'eval/walltime': 40436.302402973175, 'training/sps': 584.1706361003775, 'training/walltime': 47154.66746354103, 'training/entropy_loss': Array(0.02064622, dtype=float32), 'training/policy_loss': Array(0.00687144, dtype=float32), 'training/total_loss': Array(0.02754792, dtype=float32), 'training/v_loss': Array(3.0264448e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.4717, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-26.27843, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.235518, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1260962, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2292717, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72836184501648, 'eval/sps': 1069.0867061698448, 'num_steps': 27525120}
{'eval/walltime': 40556.35941576958, 'training/sps': 585.5954949570572, 'training/walltime': 47294.55925011635, 'training/entropy_loss': Array(0.02132607, dtype=float32), 'training/policy_loss': Array(0.00613012, dtype=float32), 'training/total_loss': Array(0.02747513, dtype=float32), 'training/v_loss': Array(1.8946856e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.4917, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-25.633202, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.601515, dtype=float32), 'eval/episode_reward_alive_std': Array(7.5, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22795808, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.05701279640198, 'eval/sps': 1066.1601269146026, 'num_steps': 27607040}
{'eval/walltime': 40676.10012984276, 'training/sps': 582.8738459599466, 'training/walltime': 47435.10424208641, 'training/entropy_loss': Array(0.02081923, dtype=float32), 'training/policy_loss': Array(0.00610465, dtype=float32), 'training/total_loss': Array(0.02694189, dtype=float32), 'training/v_loss': Array(1.800406e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.6997, dtype=float32), 'eval/episode_reward_alive': Array(4993.086, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-25.386213, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.837964, dtype=float32), 'eval/episode_reward_alive_std': Array(7.708586, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2645356, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74071407318115, 'eval/sps': 1068.9764211842855, 'num_steps': 27688960}
{'eval/walltime': 40796.11326289177, 'training/sps': 585.5664974991485, 'training/walltime': 47575.00295615196, 'training/entropy_loss': Array(0.02137181, dtype=float32), 'training/policy_loss': Array(0.03545846, dtype=float32), 'training/total_loss': Array(0.05684618, dtype=float32), 'training/v_loss': Array(1.5905498e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.432, dtype=float32), 'eval/episode_reward_alive': Array(4992.422, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-24.989735, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.418673, dtype=float32), 'eval/episode_reward_alive_std': Array(8.267604, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.35311425, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01313304901123, 'eval/sps': 1066.5499412279078, 'num_steps': 27770880}
{'eval/walltime': 40915.86583638191, 'training/sps': 582.4898891462442, 'training/walltime': 47715.640590429306, 'training/entropy_loss': Array(0.02104119, dtype=float32), 'training/policy_loss': Array(0.00716983, dtype=float32), 'training/total_loss': Array(0.02823249, dtype=float32), 'training/v_loss': Array(2.1463464e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.7056, dtype=float32), 'eval/episode_reward_alive': Array(4992.9297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-25.223803, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.151529, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0024366, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37697455, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.75257349014282, 'eval/sps': 1068.8705575962929, 'num_steps': 27852800}
{'eval/walltime': 41035.94367170334, 'training/sps': 585.8022319436164, 'training/walltime': 47855.48300743103, 'training/entropy_loss': Array(0.02162142, dtype=float32), 'training/policy_loss': Array(0.00612858, dtype=float32), 'training/total_loss': Array(0.02776555, dtype=float32), 'training/v_loss': Array(1.5553795e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.6484, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-25.94498, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.037065, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8046837, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.5157762, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.07783532142639, 'eval/sps': 1065.9752456177064, 'num_steps': 27934720}
{'eval/walltime': 41155.70417499542, 'training/sps': 583.7744687125968, 'training/walltime': 47995.81117248535, 'training/entropy_loss': Array(0.02052743, dtype=float32), 'training/policy_loss': Array(0.09141156, dtype=float32), 'training/total_loss': Array(0.11198641, dtype=float32), 'training/v_loss': Array(4.7416906e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.883, dtype=float32), 'eval/episode_reward_alive': Array(4994.375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-33.492485, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.279129, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9877124, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.6371033, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76050329208374, 'eval/sps': 1068.7997835799083, 'num_steps': 28016640}
{'eval/walltime': 41275.69376993179, 'training/sps': 585.3537959200751, 'training/walltime': 48135.76072192192, 'training/entropy_loss': Array(0.02134417, dtype=float32), 'training/policy_loss': Array(0.03509432, dtype=float32), 'training/total_loss': Array(0.05646668, dtype=float32), 'training/v_loss': Array(2.8191522e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4961.0107, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-32.855927, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.295125, dtype=float32), 'eval/episode_reward_alive_std': Array(6.965732, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.7908976, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98959493637085, 'eval/sps': 1066.759164141499, 'num_steps': 28098560}
{'eval/walltime': 41395.351383686066, 'training/sps': 582.0736394422281, 'training/walltime': 48276.49892830849, 'training/entropy_loss': Array(0.02121815, dtype=float32), 'training/policy_loss': Array(-0.0022109, dtype=float32), 'training/total_loss': Array(0.0190216, dtype=float32), 'training/v_loss': Array(1.4349693e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4958.71, dtype=float32), 'eval/episode_reward_alive': Array(4992.1484, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-33.438606, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.230283, dtype=float32), 'eval/episode_reward_alive_std': Array(7.798327, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.9380545, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.65761375427246, 'eval/sps': 1069.7188083899064, 'num_steps': 28180480}
{'eval/walltime': 41515.36397433281, 'training/sps': 585.6067130810674, 'training/walltime': 48416.388035058975, 'training/entropy_loss': Array(0.02092823, dtype=float32), 'training/policy_loss': Array(0.00083637, dtype=float32), 'training/total_loss': Array(0.0217816, dtype=float32), 'training/v_loss': Array(1.7008344e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4959.0317, dtype=float32), 'eval/episode_reward_alive': Array(4992.8516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-33.819748, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.688657, dtype=float32), 'eval/episode_reward_alive_std': Array(7.36025, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.91177773, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01259064674377, 'eval/sps': 1066.554761548037, 'num_steps': 28262400}
{'eval/walltime': 41635.24786925316, 'training/sps': 584.9149455099829, 'training/walltime': 48556.44258594513, 'training/entropy_loss': Array(0.02122112, dtype=float32), 'training/policy_loss': Array(0.02142256, dtype=float32), 'training/total_loss': Array(0.04265237, dtype=float32), 'training/v_loss': Array(8.690506e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.0547, dtype=float32), 'eval/episode_reward_alive': Array(4994.883, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-34.827866, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.928393, dtype=float32), 'eval/episode_reward_alive_std': Array(6.686765, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.72473246, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88389492034912, 'eval/sps': 1067.6997113335633, 'num_steps': 28344320}
{'eval/walltime': 41755.24404144287, 'training/sps': 585.3364569300509, 'training/walltime': 48696.39628100395, 'training/entropy_loss': Array(0.02071142, dtype=float32), 'training/policy_loss': Array(0.01383979, dtype=float32), 'training/total_loss': Array(0.03456768, dtype=float32), 'training/v_loss': Array(1.6478636e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4956.8984, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-35.758553, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.985983, dtype=float32), 'eval/episode_reward_alive_std': Array(7.754472, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.8491757, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99617218971252, 'eval/sps': 1066.7006927323775, 'num_steps': 28426240}
{'eval/walltime': 41875.23474383354, 'training/sps': 583.9653913368751, 'training/walltime': 48836.67856693268, 'training/entropy_loss': Array(0.02070343, dtype=float32), 'training/policy_loss': Array(-0.003357, dtype=float32), 'training/total_loss': Array(0.01735552, dtype=float32), 'training/v_loss': Array(9.089304e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4955.702, dtype=float32), 'eval/episode_reward_alive': Array(4992.1484, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-36.446136, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.465689, dtype=float32), 'eval/episode_reward_alive_std': Array(7.36025, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.78216296, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99070239067078, 'eval/sps': 1066.7493184867958, 'num_steps': 28508160}
{'eval/walltime': 41995.11184954643, 'training/sps': 585.5806605462865, 'training/walltime': 48976.573897361755, 'training/entropy_loss': Array(0.0198922, dtype=float32), 'training/policy_loss': Array(0.02054818, dtype=float32), 'training/total_loss': Array(0.0404546, dtype=float32), 'training/v_loss': Array(1.42259305e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4956.3545, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-36.30227, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.394565, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2601624, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.6051299, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87710571289062, 'eval/sps': 1067.7601802179306, 'num_steps': 28590080}
{'eval/walltime': 42114.88334727287, 'training/sps': 584.0412449804218, 'training/walltime': 49116.837963819504, 'training/entropy_loss': Array(0.02049882, dtype=float32), 'training/policy_loss': Array(-0.00195951, dtype=float32), 'training/total_loss': Array(0.01854732, dtype=float32), 'training/v_loss': Array(8.007046e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4956.958, dtype=float32), 'eval/episode_reward_alive': Array(4993.203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-36.244904, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.789405, dtype=float32), 'eval/episode_reward_alive_std': Array(7.647875, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.32252654, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77149772644043, 'eval/sps': 1068.7016730170108, 'num_steps': 28672000}
{'eval/walltime': 42234.890845537186, 'training/sps': 585.1773976063746, 'training/walltime': 49256.82970023155, 'training/entropy_loss': Array(0.01972899, dtype=float32), 'training/policy_loss': Array(0.00135491, dtype=float32), 'training/total_loss': Array(0.0211002, dtype=float32), 'training/v_loss': Array(1.6303551e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4958.128, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-35.66099, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1276903, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0085354, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24993838, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.00749826431274, 'eval/sps': 1066.6000195928093, 'num_steps': 28753920}
{'eval/walltime': 42354.68686699867, 'training/sps': 584.5460821949129, 'training/walltime': 49396.97262907028, 'training/entropy_loss': Array(0.01987136, dtype=float32), 'training/policy_loss': Array(0.00912297, dtype=float32), 'training/total_loss': Array(0.02901062, dtype=float32), 'training/v_loss': Array(1.6292364e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4957.6445, dtype=float32), 'eval/episode_reward_alive': Array(4992.383, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-34.737755, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3473296, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2339487, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22202803, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79602146148682, 'eval/sps': 1068.4828964971152, 'num_steps': 28835840}
{'eval/walltime': 42474.69501590729, 'training/sps': 585.455729621972, 'training/walltime': 49536.89781188965, 'training/entropy_loss': Array(0.01972311, dtype=float32), 'training/policy_loss': Array(0.01146074, dtype=float32), 'training/total_loss': Array(0.03119702, dtype=float32), 'training/v_loss': Array(1.3177863e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4959.7075, dtype=float32), 'eval/episode_reward_alive': Array(4994.1406, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-34.433487, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.240738, dtype=float32), 'eval/episode_reward_alive_std': Array(7.101644, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22732444, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.00814890861511, 'eval/sps': 1066.5942368419549, 'num_steps': 28917760}
{'eval/walltime': 42594.54691171646, 'training/sps': 584.7095973852881, 'training/walltime': 49677.001549482346, 'training/entropy_loss': Array(0.01926693, dtype=float32), 'training/policy_loss': Array(0.00540878, dtype=float32), 'training/total_loss': Array(0.02468817, dtype=float32), 'training/v_loss': Array(1.2454891e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4959.216, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-34.143166, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.462623, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3449965, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.208325, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85189580917358, 'eval/sps': 1067.9847751745178, 'num_steps': 28999680}
{'eval/walltime': 42714.50707197189, 'training/sps': 585.4978735069925, 'training/walltime': 49816.91666054726, 'training/entropy_loss': Array(0.01931525, dtype=float32), 'training/policy_loss': Array(0.00680305, dtype=float32), 'training/total_loss': Array(0.02614294, dtype=float32), 'training/v_loss': Array(2.4639177e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4959.1865, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-34.212067, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5426183, dtype=float32), 'eval/episode_reward_alive_std': Array(7.419716, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21000579, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96016025543213, 'eval/sps': 1067.0209153392975, 'num_steps': 29081600}
{'eval/walltime': 42834.231843709946, 'training/sps': 583.8810154264374, 'training/walltime': 49957.21921849251, 'training/entropy_loss': Array(0.01911468, dtype=float32), 'training/policy_loss': Array(0.01409416, dtype=float32), 'training/total_loss': Array(0.03322856, dtype=float32), 'training/v_loss': Array(1.9727215e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4959.3047, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-34.17128, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2687855, dtype=float32), 'eval/episode_reward_alive_std': Array(7.14139, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22281815, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72477173805237, 'eval/sps': 1069.1187641606293, 'num_steps': 29163520}
{'eval/walltime': 42954.228266239166, 'training/sps': 585.3821230673065, 'training/walltime': 50097.16199564934, 'training/entropy_loss': Array(0.01954569, dtype=float32), 'training/policy_loss': Array(0.02349827, dtype=float32), 'training/total_loss': Array(0.04305658, dtype=float32), 'training/v_loss': Array(1.2618781e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.1953, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-33.633553, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1776996, dtype=float32), 'eval/episode_reward_alive_std': Array(7.084434, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19308323, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.99642252922058, 'eval/sps': 1066.6984673549784, 'num_steps': 29245440}
{'eval/walltime': 43073.92413306236, 'training/sps': 583.754625702374, 'training/walltime': 50237.49493074417, 'training/entropy_loss': Array(0.01888063, dtype=float32), 'training/policy_loss': Array(0.00183001, dtype=float32), 'training/total_loss': Array(0.02072671, dtype=float32), 'training/v_loss': Array(1.6080572e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4960.008, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-33.390366, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0688334, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9578414, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2070928, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69586682319641, 'eval/sps': 1069.3769417207168, 'num_steps': 29327360}
{'eval/walltime': 43193.81580781937, 'training/sps': 585.341986189306, 'training/walltime': 50377.44730377197, 'training/entropy_loss': Array(0.01919118, dtype=float32), 'training/policy_loss': Array(0.00691802, dtype=float32), 'training/total_loss': Array(0.02611747, dtype=float32), 'training/v_loss': Array(8.272493e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4961.202, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-32.50853, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0846157, dtype=float32), 'eval/episode_reward_alive_std': Array(6.966608, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21747185, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.89167475700378, 'eval/sps': 1067.630427712601, 'num_steps': 29409280}
{'eval/walltime': 43313.513766765594, 'training/sps': 583.9307814329474, 'training/walltime': 50517.73790431023, 'training/entropy_loss': Array(0.01894928, dtype=float32), 'training/policy_loss': Array(-0.00491845, dtype=float32), 'training/total_loss': Array(0.01404299, dtype=float32), 'training/v_loss': Array(1.217111e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4961.4365, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-32.235146, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.256087, dtype=float32), 'eval/episode_reward_alive_std': Array(7.13936, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22175138, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69795894622803, 'eval/sps': 1069.3582507743638, 'num_steps': 29491200}
{'eval/walltime': 43433.42800426483, 'training/sps': 585.2510912456748, 'training/walltime': 50657.71201324463, 'training/entropy_loss': Array(0.0190265, dtype=float32), 'training/policy_loss': Array(-0.00195639, dtype=float32), 'training/total_loss': Array(0.0170805, dtype=float32), 'training/v_loss': Array(1.038784e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4961.9478, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-31.723913, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.098373, dtype=float32), 'eval/episode_reward_alive_std': Array(7.001238, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21501894, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.91423749923706, 'eval/sps': 1067.4295452265574, 'num_steps': 29573120}
{'eval/walltime': 43553.27406787872, 'training/sps': 584.0813992643408, 'training/walltime': 50797.966436862946, 'training/entropy_loss': Array(0.01907174, dtype=float32), 'training/policy_loss': Array(-0.00711367, dtype=float32), 'training/total_loss': Array(0.01196683, dtype=float32), 'training/v_loss': Array(8.756218e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.283, dtype=float32), 'eval/episode_reward_alive': Array(4994.492, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-31.20909, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7952785, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7268076, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19311303, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8460636138916, 'eval/sps': 1068.036747643026, 'num_steps': 29655040}
{'eval/walltime': 43673.21852302551, 'training/sps': 585.6580225134248, 'training/walltime': 50937.843287944794, 'training/entropy_loss': Array(0.01889174, dtype=float32), 'training/policy_loss': Array(-0.00309196, dtype=float32), 'training/total_loss': Array(0.01580995, dtype=float32), 'training/v_loss': Array(1.0170605e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.357, dtype=float32), 'eval/episode_reward_alive': Array(4994.2188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-30.86206, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.144233, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0277767, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20634405, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94445514678955, 'eval/sps': 1067.160627336645, 'num_steps': 29736960}
{'eval/walltime': 43793.07710623741, 'training/sps': 584.9436842882225, 'training/walltime': 51077.89095783234, 'training/entropy_loss': Array(0.01904738, dtype=float32), 'training/policy_loss': Array(-0.00142739, dtype=float32), 'training/total_loss': Array(0.01762886, dtype=float32), 'training/v_loss': Array(8.872517e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4962.57, dtype=float32), 'eval/episode_reward_alive': Array(4992.6562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-30.086496, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.337141, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2332106, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19843979, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8585832118988, 'eval/sps': 1067.9251879167296, 'num_steps': 29818880}
{'eval/walltime': 43912.98056101799, 'training/sps': 585.087202360332, 'training/walltime': 51217.90427494049, 'training/entropy_loss': Array(0.01874425, dtype=float32), 'training/policy_loss': Array(-8.6017535e-05, dtype=float32), 'training/total_loss': Array(0.01866665, dtype=float32), 'training/v_loss': Array(8.414464e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4964.1577, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-29.475508, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8867326, dtype=float32), 'eval/episode_reward_alive_std': Array(6.781029, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19389565, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90345478057861, 'eval/sps': 1067.5255373937134, 'num_steps': 29900800}
{'eval/walltime': 44032.91393780708, 'training/sps': 583.4293102742112, 'training/walltime': 51358.31545853615, 'training/entropy_loss': Array(0.01904794, dtype=float32), 'training/policy_loss': Array(0.00576752, dtype=float32), 'training/total_loss': Array(0.02482651, dtype=float32), 'training/v_loss': Array(1.1047647e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.268, dtype=float32), 'eval/episode_reward_alive': Array(4992.578, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-29.310282, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1578174, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0706363, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18061343, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.93337678909302, 'eval/sps': 1067.259201957537, 'num_steps': 29982720}
{'eval/walltime': 44152.954966545105, 'training/sps': 585.2553289325726, 'training/walltime': 51498.28855395317, 'training/entropy_loss': Array(0.01866605, dtype=float32), 'training/policy_loss': Array(-0.0019641, dtype=float32), 'training/total_loss': Array(0.01671615, dtype=float32), 'training/v_loss': Array(1.4199069e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4964.7803, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-28.85261, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.513416, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4139557, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20062847, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04102873802185, 'eval/sps': 1066.302091423657, 'num_steps': 30064640}
{'eval/walltime': 44272.93270158768, 'training/sps': 583.5594066029291, 'training/walltime': 51638.66843485832, 'training/entropy_loss': Array(0.01885369, dtype=float32), 'training/policy_loss': Array(-0.0010598, dtype=float32), 'training/total_loss': Array(0.01780378, dtype=float32), 'training/v_loss': Array(9.886927e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4963.74, dtype=float32), 'eval/episode_reward_alive': Array(4992.3047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-28.56474, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.618136, dtype=float32), 'eval/episode_reward_alive_std': Array(7.497456, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19921963, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.97773504257202, 'eval/sps': 1066.8646141267911, 'num_steps': 30146560}
{'eval/walltime': 44392.86094999313, 'training/sps': 585.8926208206406, 'training/walltime': 51778.48927760124, 'training/entropy_loss': Array(0.01887142, dtype=float32), 'training/policy_loss': Array(-0.00796646, dtype=float32), 'training/total_loss': Array(0.0109118, dtype=float32), 'training/v_loss': Array(6.849927e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.378, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-28.255398, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1706457, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0907855, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.17344823, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.92824840545654, 'eval/sps': 1067.3048402012366, 'num_steps': 30228480}
{'eval/walltime': 44512.55203986168, 'training/sps': 582.2428857435175, 'training/walltime': 51919.18657422066, 'training/entropy_loss': Array(0.01888673, dtype=float32), 'training/policy_loss': Array(-0.00499719, dtype=float32), 'training/total_loss': Array(0.0138957, dtype=float32), 'training/v_loss': Array(6.1470964e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4964.169, dtype=float32), 'eval/episode_reward_alive': Array(4992.1875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-28.018215, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1088996, dtype=float32), 'eval/episode_reward_alive_std': Array(7.036456, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.15503392, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69108986854553, 'eval/sps': 1069.4196212982938, 'num_steps': 30310400}
{'eval/walltime': 44632.61015057564, 'training/sps': 585.2540389785701, 'training/walltime': 52059.15997815132, 'training/entropy_loss': Array(0.01910081, dtype=float32), 'training/policy_loss': Array(-0.00325308, dtype=float32), 'training/total_loss': Array(0.01585518, dtype=float32), 'training/v_loss': Array(7.447372e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.9243, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-27.552406, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.277871, dtype=float32), 'eval/episode_reward_alive_std': Array(7.195881, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1704787, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.05811071395874, 'eval/sps': 1066.1503770033746, 'num_steps': 30392320}
{'eval/walltime': 44752.42245364189, 'training/sps': 584.4991503978187, 'training/walltime': 52199.31415963173, 'training/entropy_loss': Array(0.01868225, dtype=float32), 'training/policy_loss': Array(0.00884664, dtype=float32), 'training/total_loss': Array(0.02754957, dtype=float32), 'training/v_loss': Array(2.067195e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4965.964, dtype=float32), 'eval/episode_reward_alive': Array(4993.242, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-27.278841, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5675006, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4631867, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18948813, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81230306625366, 'eval/sps': 1068.337697583684, 'num_steps': 30474240}
{'eval/walltime': 44872.33670639992, 'training/sps': 585.6386960762865, 'training/walltime': 52339.19562673569, 'training/entropy_loss': Array(0.0189525, dtype=float32), 'training/policy_loss': Array(-0.00266541, dtype=float32), 'training/total_loss': Array(0.01629477, dtype=float32), 'training/v_loss': Array(7.677818e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4967.705, dtype=float32), 'eval/episode_reward_alive': Array(4994.414, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-26.708939, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.188452, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0882025, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18825811, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.91425275802612, 'eval/sps': 1067.4294093988146, 'num_steps': 30556160}
{'eval/walltime': 44992.14036607742, 'training/sps': 583.1822797635533, 'training/walltime': 52479.66628718376, 'training/entropy_loss': Array(0.01868414, dtype=float32), 'training/policy_loss': Array(0.01515081, dtype=float32), 'training/total_loss': Array(0.03384535, dtype=float32), 'training/v_loss': Array(1.0389771e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4968.7744, dtype=float32), 'eval/episode_reward_alive': Array(4994.7656, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-25.991991, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.892426, dtype=float32), 'eval/episode_reward_alive_std': Array(6.842519, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1526175, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8036596775055, 'eval/sps': 1068.4147741776662, 'num_steps': 30638080}
{'eval/walltime': 45112.17258524895, 'training/sps': 585.78107840765, 'training/walltime': 52619.51375412941, 'training/entropy_loss': Array(0.01896193, dtype=float32), 'training/policy_loss': Array(0.07291939, dtype=float32), 'training/total_loss': Array(0.09189308, dtype=float32), 'training/v_loss': Array(1.17539885e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.3423, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.641624, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1192226, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0809875, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21212018, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.03221917152405, 'eval/sps': 1066.3803509047027, 'num_steps': 30720000}
{'eval/walltime': 45231.9802339077, 'training/sps': 582.9407969623817, 'training/walltime': 52760.04260444641, 'training/entropy_loss': Array(0.01794687, dtype=float32), 'training/policy_loss': Array(-0.00058286, dtype=float32), 'training/total_loss': Array(0.01737343, dtype=float32), 'training/v_loss': Array(9.425096e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.816, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.309086, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.967968, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9315853, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18981975, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80764865875244, 'eval/sps': 1068.3792014363105, 'num_steps': 30801920}
{'eval/walltime': 45351.99027585983, 'training/sps': 585.3264596563247, 'training/walltime': 52899.99868988991, 'training/entropy_loss': Array(0.01801056, dtype=float32), 'training/policy_loss': Array(0.02118337, dtype=float32), 'training/total_loss': Array(0.03920569, dtype=float32), 'training/v_loss': Array(1.176478e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.076, dtype=float32), 'eval/episode_reward_alive': Array(4992.7344, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.657963, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2866945, dtype=float32), 'eval/episode_reward_alive_std': Array(7.20404, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21947363, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.01004195213318, 'eval/sps': 1066.5774123389913, 'num_steps': 30883840}
{'eval/walltime': 45471.80240273476, 'training/sps': 583.8108495806247, 'training/walltime': 53040.318110227585, 'training/entropy_loss': Array(0.01803005, dtype=float32), 'training/policy_loss': Array(0.01249488, dtype=float32), 'training/total_loss': Array(0.03053359, dtype=float32), 'training/v_loss': Array(8.661806e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.33, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.341347, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4938145, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4342003, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20887475, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8121268749237, 'eval/sps': 1068.3392686420125, 'num_steps': 30965760}
{'eval/walltime': 45591.73275923729, 'training/sps': 585.4640134630486, 'training/walltime': 53180.24131321907, 'training/entropy_loss': Array(0.01792403, dtype=float32), 'training/policy_loss': Array(0.08312586, dtype=float32), 'training/total_loss': Array(0.10107075, dtype=float32), 'training/v_loss': Array(2.0861247e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.128, dtype=float32), 'eval/episode_reward_alive': Array(4993.9062, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.778883, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8666635, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8296685, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26997957, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.93035650253296, 'eval/sps': 1067.2860794614298, 'num_steps': 31047680}
{'eval/walltime': 45711.51940751076, 'training/sps': 583.7843098861354, 'training/walltime': 53320.56711268425, 'training/entropy_loss': Array(0.01550141, dtype=float32), 'training/policy_loss': Array(0.02519225, dtype=float32), 'training/total_loss': Array(0.04071532, dtype=float32), 'training/v_loss': Array(2.1662176e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4971.976, dtype=float32), 'eval/episode_reward_alive': Array(4992.0703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-20.094112, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.35745, dtype=float32), 'eval/episode_reward_alive_std': Array(8.467016, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.735737, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78664827346802, 'eval/sps': 1068.566504238279, 'num_steps': 31129600}
{'eval/walltime': 45831.64713096619, 'training/sps': 585.693019178115, 'training/walltime': 53460.43560576439, 'training/entropy_loss': Array(0.01540837, dtype=float32), 'training/policy_loss': Array(0.00686969, dtype=float32), 'training/total_loss': Array(0.02230867, dtype=float32), 'training/v_loss': Array(3.0604675e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.636, dtype=float32), 'eval/episode_reward_alive': Array(4993.5547, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.918266, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.614431, dtype=float32), 'eval/episode_reward_alive_std': Array(7.5558424, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.29310468, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.12772345542908, 'eval/sps': 1065.5325541692443, 'num_steps': 31211520}
{'eval/walltime': 45951.36634373665, 'training/sps': 584.6242274238774, 'training/walltime': 53600.55980205536, 'training/entropy_loss': Array(0.01557733, dtype=float32), 'training/policy_loss': Array(0.00551659, dtype=float32), 'training/total_loss': Array(0.02111357, dtype=float32), 'training/v_loss': Array(1.9651974e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4972.7646, dtype=float32), 'eval/episode_reward_alive': Array(4992.3047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.540077, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.203743, dtype=float32), 'eval/episode_reward_alive_std': Array(8.146662, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26559535, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.71921277046204, 'eval/sps': 1069.1684069574926, 'num_steps': 31293440}
{'eval/walltime': 46071.57198691368, 'training/sps': 585.7676985687663, 'training/walltime': 53740.41046333313, 'training/entropy_loss': Array(0.01535016, dtype=float32), 'training/policy_loss': Array(0.01519704, dtype=float32), 'training/total_loss': Array(0.03058802, dtype=float32), 'training/v_loss': Array(4.082077e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.1074, dtype=float32), 'eval/episode_reward_alive': Array(4991.914, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.806402, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.219737, dtype=float32), 'eval/episode_reward_alive_std': Array(8.175829, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26603746, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.20564317703247, 'eval/sps': 1064.8418544833908, 'num_steps': 31375360}
{'eval/walltime': 46191.573653936386, 'training/sps': 584.5635673273536, 'training/walltime': 53880.5492002964, 'training/entropy_loss': Array(0.01554075, dtype=float32), 'training/policy_loss': Array(0.00162977, dtype=float32), 'training/total_loss': Array(0.01719636, dtype=float32), 'training/v_loss': Array(2.5837533e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.9434, dtype=float32), 'eval/episode_reward_alive': Array(4992.5, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-18.555943, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.096188, dtype=float32), 'eval/episode_reward_alive_std': Array(8.052562, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22678989, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.00166702270508, 'eval/sps': 1066.6518488929123, 'num_steps': 31457280}
{'eval/walltime': 46311.80065512657, 'training/sps': 585.5875716674276, 'training/walltime': 54020.44287967682, 'training/entropy_loss': Array(0.01538117, dtype=float32), 'training/policy_loss': Array(0.01374211, dtype=float32), 'training/total_loss': Array(0.02913976, dtype=float32), 'training/v_loss': Array(1.648097e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4973.8154, dtype=float32), 'eval/episode_reward_alive': Array(4991.797, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.980902, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.479538, dtype=float32), 'eval/episode_reward_alive_std': Array(8.402343, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22528541, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.22700119018555, 'eval/sps': 1064.6526881055483, 'num_steps': 31539200}
{'eval/walltime': 46431.63868498802, 'training/sps': 584.3822976464368, 'training/walltime': 54160.625086307526, 'training/entropy_loss': Array(0.01549384, dtype=float32), 'training/policy_loss': Array(-0.00017522, dtype=float32), 'training/total_loss': Array(0.01533992, dtype=float32), 'training/v_loss': Array(2.130837e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.8115, dtype=float32), 'eval/episode_reward_alive': Array(4993.242, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.430553, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.537974, dtype=float32), 'eval/episode_reward_alive_std': Array(8.49149, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21764663, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8380298614502, 'eval/sps': 1068.1083471414393, 'num_steps': 31621120}
{'eval/walltime': 46551.804243803024, 'training/sps': 585.9167707961469, 'training/walltime': 54300.44016599655, 'training/entropy_loss': Array(0.01573583, dtype=float32), 'training/policy_loss': Array(-0.00212742, dtype=float32), 'training/total_loss': Array(0.01362301, dtype=float32), 'training/v_loss': Array(1.4603573e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4974.34, dtype=float32), 'eval/episode_reward_alive': Array(4991.133, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.793243, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.775489, dtype=float32), 'eval/episode_reward_alive_std': Array(8.710062, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20880513, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.16555881500244, 'eval/sps': 1065.1970603079278, 'num_steps': 31703040}
{'eval/walltime': 46671.49958753586, 'training/sps': 584.6653871381641, 'training/walltime': 54440.55449771881, 'training/entropy_loss': Array(0.01576291, dtype=float32), 'training/policy_loss': Array(0.00154987, dtype=float32), 'training/total_loss': Array(0.01733731, dtype=float32), 'training/v_loss': Array(2.4533587e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.054, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.344143, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.091701, dtype=float32), 'eval/episode_reward_alive_std': Array(8.050951, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21169148, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69534373283386, 'eval/sps': 1069.3816150919167, 'num_steps': 31784960}
{'eval/walltime': 46791.477058410645, 'training/sps': 585.765051234656, 'training/walltime': 54580.405791044235, 'training/entropy_loss': Array(0.01593366, dtype=float32), 'training/policy_loss': Array(-0.00295303, dtype=float32), 'training/total_loss': Array(0.01299862, dtype=float32), 'training/v_loss': Array(1.7988294e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.3345, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.673439, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.075901, dtype=float32), 'eval/episode_reward_alive_std': Array(8.036533, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21042906, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.97747087478638, 'eval/sps': 1066.8669631616613, 'num_steps': 31866880}
{'eval/walltime': 46911.1963057518, 'training/sps': 584.1621951538018, 'training/walltime': 54720.64081597328, 'training/entropy_loss': Array(0.0159958, dtype=float32), 'training/policy_loss': Array(-0.00213159, dtype=float32), 'training/total_loss': Array(0.01389227, dtype=float32), 'training/v_loss': Array(2.8052842e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.1445, dtype=float32), 'eval/episode_reward_alive': Array(4992.461, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.315695, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.507565, dtype=float32), 'eval/episode_reward_alive_std': Array(8.454753, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24396223, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.719247341156, 'eval/sps': 1069.1680982193857, 'num_steps': 31948800}
{'eval/walltime': 47031.06473779678, 'training/sps': 584.4350518530256, 'training/walltime': 54860.81036901474, 'training/entropy_loss': Array(0.01613564, dtype=float32), 'training/policy_loss': Array(0.02046072, dtype=float32), 'training/total_loss': Array(0.03661996, dtype=float32), 'training/v_loss': Array(2.3597217e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.2163, dtype=float32), 'eval/episode_reward_alive': Array(4990.8594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.643187, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.750636, dtype=float32), 'eval/episode_reward_alive_std': Array(8.685237, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2395298, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86843204498291, 'eval/sps': 1067.8374432391472, 'num_steps': 32030720}
{'eval/walltime': 47150.79839897156, 'training/sps': 582.6938952824042, 'training/walltime': 55001.39876484871, 'training/entropy_loss': Array(0.01587493, dtype=float32), 'training/policy_loss': Array(-5.3345924e-05, dtype=float32), 'training/total_loss': Array(0.01583971, dtype=float32), 'training/v_loss': Array(1.8119084e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.9995, dtype=float32), 'eval/episode_reward_alive': Array(4992.422, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.422394, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.221725, dtype=float32), 'eval/episode_reward_alive_std': Array(8.172562, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2212865, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.73366117477417, 'eval/sps': 1069.0393891251645, 'num_steps': 32112640}
{'eval/walltime': 47270.77955651283, 'training/sps': 584.4279372873568, 'training/walltime': 55141.57002425194, 'training/entropy_loss': Array(0.01593161, dtype=float32), 'training/policy_loss': Array(0.00017148, dtype=float32), 'training/total_loss': Array(0.01612131, dtype=float32), 'training/v_loss': Array(1.821963e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.8633, dtype=float32), 'eval/episode_reward_alive': Array(4992.0312, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.168498, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.3820915, dtype=float32), 'eval/episode_reward_alive_std': Array(8.325354, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1953058, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98115754127502, 'eval/sps': 1066.8341814919263, 'num_steps': 32194560}
{'eval/walltime': 47390.39786529541, 'training/sps': 582.8023027298156, 'training/walltime': 55282.13226914406, 'training/entropy_loss': Array(0.01597184, dtype=float32), 'training/policy_loss': Array(-0.00653832, dtype=float32), 'training/total_loss': Array(0.00944682, dtype=float32), 'training/v_loss': Array(1.3299126e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.4136, dtype=float32), 'eval/episode_reward_alive': Array(4990.4688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.055656, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.783356, dtype=float32), 'eval/episode_reward_alive_std': Array(8.715054, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1953142, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.61830878257751, 'eval/sps': 1070.0703036410366, 'num_steps': 32276480}
{'eval/walltime': 47510.26238632202, 'training/sps': 584.4370201440629, 'training/walltime': 55422.30135011673, 'training/entropy_loss': Array(0.01602655, dtype=float32), 'training/policy_loss': Array(0.00330921, dtype=float32), 'training/total_loss': Array(0.01935885, dtype=float32), 'training/v_loss': Array(2.3092485e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.959, dtype=float32), 'eval/episode_reward_alive': Array(4991.758, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.798314, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.275794, dtype=float32), 'eval/episode_reward_alive_std': Array(8.21084, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21394007, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86452102661133, 'eval/sps': 1067.8722853410686, 'num_steps': 32358400}
{'eval/walltime': 47630.07645940781, 'training/sps': 583.4837781350706, 'training/walltime': 55562.69942641258, 'training/entropy_loss': Array(0.01631779, dtype=float32), 'training/policy_loss': Array(-0.00259785, dtype=float32), 'training/total_loss': Array(0.01373236, dtype=float32), 'training/v_loss': Array(1.24195485e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.2603, dtype=float32), 'eval/episode_reward_alive': Array(4992.9297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.669576, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.097382, dtype=float32), 'eval/episode_reward_alive_std': Array(7.992363, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20659791, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81407308578491, 'eval/sps': 1068.321914975331, 'num_steps': 32440320}
{'eval/walltime': 47749.932252168655, 'training/sps': 584.8883511385501, 'training/walltime': 55702.760345458984, 'training/entropy_loss': Array(0.01629594, dtype=float32), 'training/policy_loss': Array(0.00499584, dtype=float32), 'training/total_loss': Array(0.02130684, dtype=float32), 'training/v_loss': Array(1.5058126e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.85, dtype=float32), 'eval/episode_reward_alive': Array(4992.2266, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.37656, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.641122, dtype=float32), 'eval/episode_reward_alive_std': Array(8.565205, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21006168, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.855792760849, 'eval/sps': 1067.9500510701332, 'num_steps': 32522240}
{'eval/walltime': 47869.77995181084, 'training/sps': 584.0354116760559, 'training/walltime': 55843.0258128643, 'training/entropy_loss': Array(0.01662051, dtype=float32), 'training/policy_loss': Array(0.07200871, dtype=float32), 'training/total_loss': Array(0.08864863, dtype=float32), 'training/v_loss': Array(1.9403378e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.6167, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.016251, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2568545, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2271957, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24396487, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8476996421814, 'eval/sps': 1068.0221679861875, 'num_steps': 32604160}
{'eval/walltime': 47989.73279285431, 'training/sps': 584.1031739415379, 'training/walltime': 55983.27500796318, 'training/entropy_loss': Array(0.01659739, dtype=float32), 'training/policy_loss': Array(0.00358081, dtype=float32), 'training/total_loss': Array(0.02020519, dtype=float32), 'training/v_loss': Array(2.699405e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.045, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.744889, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1693926, dtype=float32), 'eval/episode_reward_alive_std': Array(7.119134, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.23899665, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95284104347229, 'eval/sps': 1067.0860221944333, 'num_steps': 32686080}
{'eval/walltime': 48109.67027950287, 'training/sps': 583.7029610591615, 'training/walltime': 56123.62036418915, 'training/entropy_loss': Array(0.01672927, dtype=float32), 'training/policy_loss': Array(-0.00210007, dtype=float32), 'training/total_loss': Array(0.01464478, dtype=float32), 'training/v_loss': Array(1.5581278e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.7324, dtype=float32), 'eval/episode_reward_alive': Array(4992.1484, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.4156685, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1999025, dtype=float32), 'eval/episode_reward_alive_std': Array(7.172092, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.28071555, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.93748664855957, 'eval/sps': 1067.2226305280615, 'num_steps': 32768000}
{'eval/walltime': 48229.54135131836, 'training/sps': 584.1768227073668, 'training/walltime': 56263.85187768936, 'training/entropy_loss': Array(0.0166138, dtype=float32), 'training/policy_loss': Array(0.0433326, dtype=float32), 'training/total_loss': Array(0.0599637, dtype=float32), 'training/v_loss': Array(1.7292434e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.285, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.425407, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6477327, dtype=float32), 'eval/episode_reward_alive_std': Array(7.5840626, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22355127, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87107181549072, 'eval/sps': 1067.8139275923184, 'num_steps': 32849920}
{'eval/walltime': 48349.38462805748, 'training/sps': 583.6713646312386, 'training/walltime': 56404.20483136177, 'training/entropy_loss': Array(0.01693923, dtype=float32), 'training/policy_loss': Array(0.00759943, dtype=float32), 'training/total_loss': Array(0.02456378, dtype=float32), 'training/v_loss': Array(2.5122295e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.1, dtype=float32), 'eval/episode_reward_alive': Array(4993.2812, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.181093, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.539354, dtype=float32), 'eval/episode_reward_alive_std': Array(7.5113845, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19273393, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84327673912048, 'eval/sps': 1068.0615841190272, 'num_steps': 32931840}
{'eval/walltime': 48469.17492508888, 'training/sps': 584.7625579932386, 'training/walltime': 56544.29588007927, 'training/entropy_loss': Array(0.01711011, dtype=float32), 'training/policy_loss': Array(-0.00312751, dtype=float32), 'training/total_loss': Array(0.01399432, dtype=float32), 'training/v_loss': Array(1.1727763e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.914, dtype=float32), 'eval/episode_reward_alive': Array(4991.953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.03953, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.956632, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8867564, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22941959, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79029703140259, 'eval/sps': 1068.5339561888327, 'num_steps': 33013760}
{'eval/walltime': 48588.94980597496, 'training/sps': 581.5491407722042, 'training/walltime': 56685.16101813316, 'training/entropy_loss': Array(0.01706821, dtype=float32), 'training/policy_loss': Array(0.02670719, dtype=float32), 'training/total_loss': Array(0.04381661, dtype=float32), 'training/v_loss': Array(4.1205196e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.673, dtype=float32), 'eval/episode_reward_alive': Array(4992.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.101051, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.983095, dtype=float32), 'eval/episode_reward_alive_std': Array(7.900964, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19227985, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77488088607788, 'eval/sps': 1068.6714864842597, 'num_steps': 33095680}
{'eval/walltime': 48708.83485174179, 'training/sps': 584.3890801231864, 'training/walltime': 56825.34159779549, 'training/entropy_loss': Array(0.0171324, dtype=float32), 'training/policy_loss': Array(-0.00103881, dtype=float32), 'training/total_loss': Array(0.01611296, dtype=float32), 'training/v_loss': Array(1.9372117e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.9297, dtype=float32), 'eval/episode_reward_alive': Array(4992.8125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.882357, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.9001365, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8499103, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20526414, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88504576683044, 'eval/sps': 1067.6894618612623, 'num_steps': 33177600}
{'eval/walltime': 48828.49795341492, 'training/sps': 583.9529855259641, 'training/walltime': 56965.62686395645, 'training/entropy_loss': Array(0.0170125, dtype=float32), 'training/policy_loss': Array(-0.00166158, dtype=float32), 'training/total_loss': Array(0.01537115, dtype=float32), 'training/v_loss': Array(2.0223344e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.0693, dtype=float32), 'eval/episode_reward_alive': Array(4992.617, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.547433, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.871644, dtype=float32), 'eval/episode_reward_alive_std': Array(7.7803044, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1995919, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.66310167312622, 'eval/sps': 1069.669749574493, 'num_steps': 33259520}
{'eval/walltime': 48948.257997751236, 'training/sps': 584.8852189168933, 'training/walltime': 57105.6885330677, 'training/entropy_loss': Array(0.01730127, dtype=float32), 'training/policy_loss': Array(-0.00028377, dtype=float32), 'training/total_loss': Array(0.01702634, dtype=float32), 'training/v_loss': Array(8.838329e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.8696, dtype=float32), 'eval/episode_reward_alive': Array(4992.2656, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.395938, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6234174, dtype=float32), 'eval/episode_reward_alive_std': Array(7.548266, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18098155, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76004433631897, 'eval/sps': 1068.80387953549, 'num_steps': 33341440}
{'eval/walltime': 49068.08950090408, 'training/sps': 584.2920065138036, 'training/walltime': 57245.89240217209, 'training/entropy_loss': Array(0.01719323, dtype=float32), 'training/policy_loss': Array(-0.001851, dtype=float32), 'training/total_loss': Array(0.01535923, dtype=float32), 'training/v_loss': Array(1.7002672e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.9736, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.151739, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7708488, dtype=float32), 'eval/episode_reward_alive_std': Array(7.7055173, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2089962, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83150315284729, 'eval/sps': 1068.1665224271921, 'num_steps': 33423360}
{'eval/walltime': 49187.95529961586, 'training/sps': 584.4372716488729, 'training/walltime': 57386.06142282486, 'training/entropy_loss': Array(0.01742297, dtype=float32), 'training/policy_loss': Array(0.00441606, dtype=float32), 'training/total_loss': Array(0.0218537, dtype=float32), 'training/v_loss': Array(1.4669575e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.9087, dtype=float32), 'eval/episode_reward_alive': Array(4992.8125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.903893, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.302571, dtype=float32), 'eval/episode_reward_alive_std': Array(8.214649, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18491955, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86579871177673, 'eval/sps': 1067.8609025730714, 'num_steps': 33505280}
{'eval/walltime': 49307.64512038231, 'training/sps': 584.1561846413975, 'training/walltime': 57526.29789066315, 'training/entropy_loss': Array(0.01737867, dtype=float32), 'training/policy_loss': Array(-0.00410256, dtype=float32), 'training/total_loss': Array(0.01328558, dtype=float32), 'training/v_loss': Array(9.471387e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.9023, dtype=float32), 'eval/episode_reward_alive': Array(4991.4844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.5819645, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.194769, dtype=float32), 'eval/episode_reward_alive_std': Array(8.109586, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20595017, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.68982076644897, 'eval/sps': 1069.4309606308684, 'num_steps': 33587200}
{'eval/walltime': 49427.52250647545, 'training/sps': 584.949903213292, 'training/walltime': 57666.34407162666, 'training/entropy_loss': Array(0.01756378, dtype=float32), 'training/policy_loss': Array(0.00335827, dtype=float32), 'training/total_loss': Array(0.02093938, dtype=float32), 'training/v_loss': Array(1.7324002e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.331, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.496719, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.8909245, dtype=float32), 'eval/episode_reward_alive_std': Array(7.818357, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19042397, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87738609313965, 'eval/sps': 1067.7576828422787, 'num_steps': 33669120}
{'eval/walltime': 49547.265447854996, 'training/sps': 582.195652232444, 'training/walltime': 57807.05278301239, 'training/entropy_loss': Array(0.0176292, dtype=float32), 'training/policy_loss': Array(-0.00364079, dtype=float32), 'training/total_loss': Array(0.01399536, dtype=float32), 'training/v_loss': Array(6.9417756e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.9937, dtype=float32), 'eval/episode_reward_alive': Array(4994.2188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.224733, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2474294, dtype=float32), 'eval/episode_reward_alive_std': Array(7.192593, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19443981, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74294137954712, 'eval/sps': 1068.9565374403207, 'num_steps': 33751040}
{'eval/walltime': 49667.096600055695, 'training/sps': 584.8043055268342, 'training/walltime': 57947.13383102417, 'training/entropy_loss': Array(0.01764222, dtype=float32), 'training/policy_loss': Array(0.00576605, dtype=float32), 'training/total_loss': Array(0.0234194, dtype=float32), 'training/v_loss': Array(1.1133604e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.0117, dtype=float32), 'eval/episode_reward_alive': Array(4993.164, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.152703, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.955717, dtype=float32), 'eval/episode_reward_alive_std': Array(7.8777547, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.17659725, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83115220069885, 'eval/sps': 1068.169650790135, 'num_steps': 33832960}
{'eval/walltime': 49786.84485912323, 'training/sps': 582.5240726642467, 'training/walltime': 58087.7632124424, 'training/entropy_loss': Array(0.01787541, dtype=float32), 'training/policy_loss': Array(0.00175474, dtype=float32), 'training/total_loss': Array(0.01964131, dtype=float32), 'training/v_loss': Array(1.1164006e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.7783, dtype=float32), 'eval/episode_reward_alive': Array(4994.7656, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.986924, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.18165, dtype=float32), 'eval/episode_reward_alive_std': Array(7.122241, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.17526291, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7482590675354, 'eval/sps': 1068.9090680459146, 'num_steps': 33914880}
{'eval/walltime': 49906.69020986557, 'training/sps': 584.8309549677808, 'training/walltime': 58227.83787727356, 'training/entropy_loss': Array(0.01787607, dtype=float32), 'training/policy_loss': Array(0.00654711, dtype=float32), 'training/total_loss': Array(0.02443975, dtype=float32), 'training/v_loss': Array(1.6561422e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.8623, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.770145, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3762207, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3078203, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20011337, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84535074234009, 'eval/sps': 1068.0431006054785, 'num_steps': 33996800}
{'eval/walltime': 50026.421020030975, 'training/sps': 583.5887240132319, 'training/walltime': 58368.21070599556, 'training/entropy_loss': Array(0.01816651, dtype=float32), 'training/policy_loss': Array(0.00086793, dtype=float32), 'training/total_loss': Array(0.01904202, dtype=float32), 'training/v_loss': Array(7.571186e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.874, dtype=float32), 'eval/episode_reward_alive': Array(4992.3047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.430085, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.041428, dtype=float32), 'eval/episode_reward_alive_std': Array(7.977075, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.16529073, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.73081016540527, 'eval/sps': 1069.0648449064283, 'num_steps': 34078720}
{'eval/walltime': 50146.21112346649, 'training/sps': 584.9459696904737, 'training/walltime': 58508.25782871246, 'training/entropy_loss': Array(0.01819833, dtype=float32), 'training/policy_loss': Array(0.01063286, dtype=float32), 'training/total_loss': Array(0.02884615, dtype=float32), 'training/v_loss': Array(1.4958945e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.247, dtype=float32), 'eval/episode_reward_alive': Array(4992.539, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.292377, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.903906, dtype=float32), 'eval/episode_reward_alive_std': Array(7.83113, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.17866027, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79010343551636, 'eval/sps': 1068.535683074212, 'num_steps': 34160640}
{'eval/walltime': 50265.91020703316, 'training/sps': 584.4378392751488, 'training/walltime': 58648.426713228226, 'training/entropy_loss': Array(0.01828918, dtype=float32), 'training/policy_loss': Array(0.00794609, dtype=float32), 'training/total_loss': Array(0.02625103, dtype=float32), 'training/v_loss': Array(1.576199e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.3936, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.966253, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.684467, dtype=float32), 'eval/episode_reward_alive_std': Array(7.631897, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.17002456, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69908356666565, 'eval/sps': 1069.3482037288213, 'num_steps': 34242560}
{'eval/walltime': 50385.785517692566, 'training/sps': 585.3256559804882, 'training/walltime': 58788.3829908371, 'training/entropy_loss': Array(0.01850284, dtype=float32), 'training/policy_loss': Array(0.00864422, dtype=float32), 'training/total_loss': Array(0.02715272, dtype=float32), 'training/v_loss': Array(5.6664708e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.279, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.729192, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.510897, dtype=float32), 'eval/episode_reward_alive_std': Array(7.456641, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.14800596, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87531065940857, 'eval/sps': 1067.7761692203278, 'num_steps': 34324480}
{'eval/walltime': 50505.47451233864, 'training/sps': 581.7441535998573, 'training/walltime': 58929.20090794563, 'training/entropy_loss': Array(0.01842545, dtype=float32), 'training/policy_loss': Array(0.00130656, dtype=float32), 'training/total_loss': Array(0.01974262, dtype=float32), 'training/v_loss': Array(1.0609677e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.0024, dtype=float32), 'eval/episode_reward_alive': Array(4992.578, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.575987, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.802951, dtype=float32), 'eval/episode_reward_alive_std': Array(7.730428, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.15020466, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.68899464607239, 'eval/sps': 1069.43834208403, 'num_steps': 34406400}
{'eval/walltime': 50625.287801742554, 'training/sps': 583.4647673238223, 'training/walltime': 59069.60355877876, 'training/entropy_loss': Array(0.01852283, dtype=float32), 'training/policy_loss': Array(0.00231965, dtype=float32), 'training/total_loss': Array(0.02084905, dtype=float32), 'training/v_loss': Array(6.5749637e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.8306, dtype=float32), 'eval/episode_reward_alive': Array(4991.4062, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.575745, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.913443, dtype=float32), 'eval/episode_reward_alive_std': Array(7.854574, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1455775, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8132894039154, 'eval/sps': 1068.328902718675, 'num_steps': 34488320}
{'eval/walltime': 50745.00750732422, 'training/sps': 582.5522658521719, 'training/walltime': 59210.22613430023, 'training/entropy_loss': Array(0.01818583, dtype=float32), 'training/policy_loss': Array(0.01899529, dtype=float32), 'training/total_loss': Array(0.03719295, dtype=float32), 'training/v_loss': Array(1.183454e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.2026, dtype=float32), 'eval/episode_reward_alive': Array(4992.8516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.649085, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7163544, dtype=float32), 'eval/episode_reward_alive_std': Array(7.6720777, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.14465182, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.71970558166504, 'eval/sps': 1069.1640058593919, 'num_steps': 34570240}
{'eval/walltime': 50864.76297211647, 'training/sps': 584.4558299212148, 'training/walltime': 59350.39070415497, 'training/entropy_loss': Array(0.01840146, dtype=float32), 'training/policy_loss': Array(0.00581699, dtype=float32), 'training/total_loss': Array(0.02422793, dtype=float32), 'training/v_loss': Array(9.4904235e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.3174, dtype=float32), 'eval/episode_reward_alive': Array(4992.8516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.534159, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(8.233912, dtype=float32), 'eval/episode_reward_alive_std': Array(8.189255, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.12914658, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.75546479225159, 'eval/sps': 1068.844751444544, 'num_steps': 34652160}
{'eval/walltime': 50984.48566412926, 'training/sps': 579.3296283370313, 'training/walltime': 59491.79552102089, 'training/entropy_loss': Array(0.01828606, dtype=float32), 'training/policy_loss': Array(0.00811123, dtype=float32), 'training/total_loss': Array(0.02640606, dtype=float32), 'training/v_loss': Array(8.764588e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.671, dtype=float32), 'eval/episode_reward_alive': Array(4992.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.220217, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.699909, dtype=float32), 'eval/episode_reward_alive_std': Array(7.644682, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.13375911, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72269201278687, 'eval/sps': 1069.1373360225568, 'num_steps': 34734080}
{'eval/walltime': 51104.25948214531, 'training/sps': 585.0471348022119, 'training/walltime': 59631.81842708588, 'training/entropy_loss': Array(0.01862468, dtype=float32), 'training/policy_loss': Array(0.00239191, dtype=float32), 'training/total_loss': Array(0.02102235, dtype=float32), 'training/v_loss': Array(5.7676452e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.04, dtype=float32), 'eval/episode_reward_alive': Array(4993.3203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.280618, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4719496, dtype=float32), 'eval/episode_reward_alive_std': Array(7.402421, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.14732344, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77381801605225, 'eval/sps': 1068.6809698497318, 'num_steps': 34816000}
{'eval/walltime': 51224.11159682274, 'training/sps': 583.6049772711647, 'training/walltime': 59772.187346458435, 'training/entropy_loss': Array(0.01855053, dtype=float32), 'training/policy_loss': Array(0.0060855, dtype=float32), 'training/total_loss': Array(0.02464294, dtype=float32), 'training/v_loss': Array(6.9076523e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.453, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.218403, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4451547, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3814692, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.15184106, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8521146774292, 'eval/sps': 1067.9828248713013, 'num_steps': 34897920}
{'eval/walltime': 51344.134583473206, 'training/sps': 584.3613608237514, 'training/walltime': 59912.37457561493, 'training/entropy_loss': Array(0.01861287, dtype=float32), 'training/policy_loss': Array(0.01124318, dtype=float32), 'training/total_loss': Array(0.02986494, dtype=float32), 'training/v_loss': Array(8.897247e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.1904, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.286591, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5377207, dtype=float32), 'eval/episode_reward_alive_std': Array(7.488496, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1544899, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02298665046692, 'eval/sps': 1066.4623800169536, 'num_steps': 34979840}
{'eval/walltime': 51463.86039471626, 'training/sps': 582.4426116035287, 'training/walltime': 60053.02362561226, 'training/entropy_loss': Array(0.01883212, dtype=float32), 'training/policy_loss': Array(0.02027703, dtype=float32), 'training/total_loss': Array(0.03911554, dtype=float32), 'training/v_loss': Array(6.3871266e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.5815, dtype=float32), 'eval/episode_reward_alive': Array(4992.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.309517, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.109555, dtype=float32), 'eval/episode_reward_alive_std': Array(7.032552, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.14495087, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72581124305725, 'eval/sps': 1069.1094816651123, 'num_steps': 35061760}
{'eval/walltime': 51583.69860267639, 'training/sps': 583.9924348540856, 'training/walltime': 60193.29941534996, 'training/entropy_loss': Array(0.01866425, dtype=float32), 'training/policy_loss': Array(0.00621992, dtype=float32), 'training/total_loss': Array(0.0248945, dtype=float32), 'training/v_loss': Array(1.0338413e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.2637, dtype=float32), 'eval/episode_reward_alive': Array(4992.617, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.353226, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.475456, dtype=float32), 'eval/episode_reward_alive_std': Array(7.394171, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.14234002, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83820796012878, 'eval/sps': 1068.1067597621848, 'num_steps': 35143680}
{'eval/walltime': 51703.39596700668, 'training/sps': 584.3047546346974, 'training/walltime': 60333.500225543976, 'training/entropy_loss': Array(0.01884528, dtype=float32), 'training/policy_loss': Array(0.00133694, dtype=float32), 'training/total_loss': Array(0.02018939, dtype=float32), 'training/v_loss': Array(7.169696e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.748, dtype=float32), 'eval/episode_reward_alive': Array(4994.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.314702, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.365346, dtype=float32), 'eval/episode_reward_alive_std': Array(7.3087597, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.13648756, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69736433029175, 'eval/sps': 1069.36356298371, 'num_steps': 35225600}
{'eval/walltime': 51823.16981601715, 'training/sps': 585.1322207768908, 'training/walltime': 60473.50277042389, 'training/entropy_loss': Array(0.01878119, dtype=float32), 'training/policy_loss': Array(0.00705513, dtype=float32), 'training/total_loss': Array(0.02584914, dtype=float32), 'training/v_loss': Array(1.28209695e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.3267, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.267045, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5031886, dtype=float32), 'eval/episode_reward_alive_std': Array(7.419819, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1761997, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77384901046753, 'eval/sps': 1068.6806933023715, 'num_steps': 35307520}
{'eval/walltime': 51943.053069114685, 'training/sps': 579.4422429640703, 'training/walltime': 60614.880105257034, 'training/entropy_loss': Array(0.01917968, dtype=float32), 'training/policy_loss': Array(0.0072168, dtype=float32), 'training/total_loss': Array(0.02640299, dtype=float32), 'training/v_loss': Array(6.509525e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.5474, dtype=float32), 'eval/episode_reward_alive': Array(4992.6953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.1474285, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5094886, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4188933, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.17406772, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88325309753418, 'eval/sps': 1067.7054275117328, 'num_steps': 35389440}
{'eval/walltime': 52062.84170603752, 'training/sps': 583.5158120785245, 'training/walltime': 60755.27047395706, 'training/entropy_loss': Array(0.01922096, dtype=float32), 'training/policy_loss': Array(0.0022128, dtype=float32), 'training/total_loss': Array(0.02144104, dtype=float32), 'training/v_loss': Array(7.279189e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.624, dtype=float32), 'eval/episode_reward_alive': Array(4992.6953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.071369, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5574937, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4713607, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.15789703, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7886369228363, 'eval/sps': 1068.5487646249217, 'num_steps': 35471360}
{'eval/walltime': 52182.72365999222, 'training/sps': 583.399305577711, 'training/walltime': 60895.68887901306, 'training/entropy_loss': Array(0.0192758, dtype=float32), 'training/policy_loss': Array(0.04743567, dtype=float32), 'training/total_loss': Array(0.06672423, dtype=float32), 'training/v_loss': Array(1.2756802e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4987.7686, dtype=float32), 'eval/episode_reward_alive': Array(4995.1953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-7.426651, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.5242324, dtype=float32), 'eval/episode_reward_alive_std': Array(6.4166026, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19788125, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88195395469666, 'eval/sps': 1067.7169980760502, 'num_steps': 35553280}
{'eval/walltime': 52302.46730589867, 'training/sps': 584.8039372514213, 'training/walltime': 61035.770015239716, 'training/entropy_loss': Array(0.02023664, dtype=float32), 'training/policy_loss': Array(0.12652358, dtype=float32), 'training/total_loss': Array(0.14677052, dtype=float32), 'training/v_loss': Array(1.02994e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.6396, dtype=float32), 'eval/episode_reward_alive': Array(4994.492, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.852732, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6274815, dtype=float32), 'eval/episode_reward_alive_std': Array(6.5203958, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24136019, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74364590644836, 'eval/sps': 1068.950248099194, 'num_steps': 35635200}
{'eval/walltime': 52422.30727767944, 'training/sps': 582.6821373004589, 'training/walltime': 61176.36124801636, 'training/entropy_loss': Array(0.02007946, dtype=float32), 'training/policy_loss': Array(0.01556553, dtype=float32), 'training/total_loss': Array(0.03565329, dtype=float32), 'training/v_loss': Array(8.300762e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.7334, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.860195, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9280534, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8161545, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26798704, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83997178077698, 'eval/sps': 1068.0910392247933, 'num_steps': 35717120}
{'eval/walltime': 52542.03230214119, 'training/sps': 584.5149264048766, 'training/walltime': 61316.51164674759, 'training/entropy_loss': Array(0.02001421, dtype=float32), 'training/policy_loss': Array(0.0318881, dtype=float32), 'training/total_loss': Array(0.05190862, dtype=float32), 'training/v_loss': Array(6.3121297e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.952, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.680333, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.857891, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7521653, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.28356925, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.72502446174622, 'eval/sps': 1069.1165073923016, 'num_steps': 35799040}
{'eval/walltime': 52661.847964048386, 'training/sps': 582.3500180047693, 'training/walltime': 61457.1830599308, 'training/entropy_loss': Array(0.01984018, dtype=float32), 'training/policy_loss': Array(0.01469877, dtype=float32), 'training/total_loss': Array(0.0345499, dtype=float32), 'training/v_loss': Array(1.0943848e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.202, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.664835, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9394584, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8526583, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.27319494, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81566190719604, 'eval/sps': 1068.307748440627, 'num_steps': 35880960}
{'eval/walltime': 52781.70499134064, 'training/sps': 584.3597557888924, 'training/walltime': 61597.3706741333, 'training/entropy_loss': Array(0.02003855, dtype=float32), 'training/policy_loss': Array(0.0078307, dtype=float32), 'training/total_loss': Array(0.02787367, dtype=float32), 'training/v_loss': Array(4.4212356e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.634, dtype=float32), 'eval/episode_reward_alive': Array(4994.1797, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.545932, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.5966196, dtype=float32), 'eval/episode_reward_alive_std': Array(6.5185237, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.27431884, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85702729225159, 'eval/sps': 1067.9390511487752, 'num_steps': 35962880}
{'eval/walltime': 52901.45047068596, 'training/sps': 583.3445415170618, 'training/walltime': 61737.80226159096, 'training/entropy_loss': Array(0.02001689, dtype=float32), 'training/policy_loss': Array(0.00819184, dtype=float32), 'training/total_loss': Array(0.02821722, dtype=float32), 'training/v_loss': Array(8.488061e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.873, dtype=float32), 'eval/episode_reward_alive': Array(4994.414, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.54114, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.5741925, dtype=float32), 'eval/episode_reward_alive_std': Array(6.4837866, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24455516, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74547934532166, 'eval/sps': 1068.9338812605524, 'num_steps': 36044800}
{'eval/walltime': 53021.45619702339, 'training/sps': 582.8671668334956, 'training/walltime': 61878.34886407852, 'training/entropy_loss': Array(0.01996319, dtype=float32), 'training/policy_loss': Array(0.06045997, dtype=float32), 'training/total_loss': Array(0.08042765, dtype=float32), 'training/v_loss': Array(4.4734843e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.62, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.403443, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.752436, dtype=float32), 'eval/episode_reward_alive_std': Array(6.645563, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.23046695, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.00572633743286, 'eval/sps': 1066.6157683183283, 'num_steps': 36126720}
{'eval/walltime': 53141.16057920456, 'training/sps': 584.4951125689427, 'training/walltime': 62018.50401377678, 'training/entropy_loss': Array(0.02005181, dtype=float32), 'training/policy_loss': Array(0.01413037, dtype=float32), 'training/total_loss': Array(0.03419004, dtype=float32), 'training/v_loss': Array(7.857148e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.7373, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.285688, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.777348, dtype=float32), 'eval/episode_reward_alive_std': Array(6.645563, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.23225299, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7043821811676, 'eval/sps': 1069.3008699236868, 'num_steps': 36208640}
{'eval/walltime': 53261.13059043884, 'training/sps': 584.5124693645555, 'training/walltime': 62158.65500164032, 'training/entropy_loss': Array(0.02009893, dtype=float32), 'training/policy_loss': Array(0.02141526, dtype=float32), 'training/total_loss': Array(0.04152102, dtype=float32), 'training/v_loss': Array(6.831668e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.0547, dtype=float32), 'eval/episode_reward_alive': Array(4994.2188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.164315, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.441732, dtype=float32), 'eval/episode_reward_alive_std': Array(6.325713, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24620295, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.97001123428345, 'eval/sps': 1066.933300106434, 'num_steps': 36290560}
{'eval/walltime': 53380.99081373215, 'training/sps': 584.809493282748, 'training/walltime': 62298.734807014465, 'training/entropy_loss': Array(0.02021092, dtype=float32), 'training/policy_loss': Array(0.02155825, dtype=float32), 'training/total_loss': Array(0.04177519, dtype=float32), 'training/v_loss': Array(6.025847e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.2217, dtype=float32), 'eval/episode_reward_alive': Array(4995.1953, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.974226, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.457591, dtype=float32), 'eval/episode_reward_alive_std': Array(6.324628, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2515151, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86022329330444, 'eval/sps': 1067.910575193716, 'num_steps': 36372480}
{'eval/walltime': 53501.35581088066, 'training/sps': 584.6359216647306, 'training/walltime': 62438.85620045662, 'training/entropy_loss': Array(0.01999483, dtype=float32), 'training/policy_loss': Array(0.01729206, dtype=float32), 'training/total_loss': Array(0.03729663, dtype=float32), 'training/v_loss': Array(9.740968e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.911, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.916743, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0046353, dtype=float32), 'eval/episode_reward_alive_std': Array(6.888747, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25987813, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.3649971485138, 'eval/sps': 1063.4320860080747, 'num_steps': 36454400}
{'eval/walltime': 53621.10365319252, 'training/sps': 581.90295315474, 'training/walltime': 62579.63568878174, 'training/entropy_loss': Array(0.0202073, dtype=float32), 'training/policy_loss': Array(0.00755116, dtype=float32), 'training/total_loss': Array(0.02776273, dtype=float32), 'training/v_loss': Array(4.268636e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.997, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.791573, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.115246, dtype=float32), 'eval/episode_reward_alive_std': Array(6.980612, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2562548, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74784231185913, 'eval/sps': 1068.9127881456918, 'num_steps': 36536320}
{'eval/walltime': 53740.998082876205, 'training/sps': 584.8951065369015, 'training/walltime': 62719.69499015808, 'training/entropy_loss': Array(0.02014627, dtype=float32), 'training/policy_loss': Array(0.00295427, dtype=float32), 'training/total_loss': Array(0.02311254, dtype=float32), 'training/v_loss': Array(1.2007248e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.3813, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.642129, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1104403, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9613495, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25820503, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8944296836853, 'eval/sps': 1067.6058957676303, 'num_steps': 36618240}
{'eval/walltime': 53860.89689850807, 'training/sps': 582.7974806891061, 'training/walltime': 62860.25839805603, 'training/entropy_loss': Array(0.02039223, dtype=float32), 'training/policy_loss': Array(0.02897332, dtype=float32), 'training/total_loss': Array(0.04937579, dtype=float32), 'training/v_loss': Array(1.0246043e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.3525, dtype=float32), 'eval/episode_reward_alive': Array(4994.414, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.062041, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.831697, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6620746, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.30383727, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.89881563186646, 'eval/sps': 1067.5668423031564, 'num_steps': 36700160}
{'eval/walltime': 53980.75149726868, 'training/sps': 584.6890131937289, 'training/walltime': 63000.36706805229, 'training/entropy_loss': Array(0.02013269, dtype=float32), 'training/policy_loss': Array(0.00916249, dtype=float32), 'training/total_loss': Array(0.02930906, dtype=float32), 'training/v_loss': Array(1.3876916e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.991, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.992998, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.969764, dtype=float32), 'eval/episode_reward_alive_std': Array(6.885202, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24782547, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85459876060486, 'eval/sps': 1067.9606900663412, 'num_steps': 36782080}
{'eval/walltime': 54100.62698292732, 'training/sps': 575.0760844842608, 'training/walltime': 63142.81778407097, 'training/entropy_loss': Array(0.02042329, dtype=float32), 'training/policy_loss': Array(0.038004, dtype=float32), 'training/total_loss': Array(0.05843577, dtype=float32), 'training/v_loss': Array(8.476287e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.0103, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.856637, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.181666, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0493474, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3585564, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87548565864563, 'eval/sps': 1067.7746104361115, 'num_steps': 36864000}
{'eval/walltime': 54220.47766447067, 'training/sps': 584.3033685104211, 'training/walltime': 63283.0189268589, 'training/entropy_loss': Array(0.02017651, dtype=float32), 'training/policy_loss': Array(0.01135214, dtype=float32), 'training/total_loss': Array(0.03153494, dtype=float32), 'training/v_loss': Array(6.2896725e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.338, dtype=float32), 'eval/episode_reward_alive': Array(4994.1797, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.8419895, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.870963, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7249923, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37273705, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85068154335022, 'eval/sps': 1067.9955954501781, 'num_steps': 36945920}
{'eval/walltime': 54340.333310842514, 'training/sps': 582.205941395534, 'training/walltime': 63423.72515153885, 'training/entropy_loss': Array(0.02034059, dtype=float32), 'training/policy_loss': Array(0.00235503, dtype=float32), 'training/total_loss': Array(0.02270113, dtype=float32), 'training/v_loss': Array(5.5163923e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.3623, dtype=float32), 'eval/episode_reward_alive': Array(4994.2188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.856509, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7357554, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6272845, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.36805576, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85564637184143, 'eval/sps': 1067.9513554404557, 'num_steps': 37027840}
{'eval/walltime': 54460.18466114998, 'training/sps': 584.7005259540398, 'training/walltime': 63563.83106279373, 'training/entropy_loss': Array(0.02037103, dtype=float32), 'training/policy_loss': Array(0.07759479, dtype=float32), 'training/total_loss': Array(0.09796904, dtype=float32), 'training/v_loss': Array(3.214822e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.484, dtype=float32), 'eval/episode_reward_alive': Array(4994.414, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.929754, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.674224, dtype=float32), 'eval/episode_reward_alive_std': Array(6.5437555, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22018686, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8513503074646, 'eval/sps': 1067.9896360919672, 'num_steps': 37109760}
{'eval/walltime': 54580.060292482376, 'training/sps': 582.2326820958101, 'training/walltime': 63704.53082513809, 'training/entropy_loss': Array(0.01854151, dtype=float32), 'training/policy_loss': Array(0.01931647, dtype=float32), 'training/total_loss': Array(0.03786589, dtype=float32), 'training/v_loss': Array(7.906571e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.8555, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.738211, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.224813, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0969157, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.23449735, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87563133239746, 'eval/sps': 1067.773312868525, 'num_steps': 37191680}
{'eval/walltime': 54699.85326170921, 'training/sps': 584.755181682589, 'training/walltime': 63844.6236410141, 'training/entropy_loss': Array(0.01859201, dtype=float32), 'training/policy_loss': Array(0.01156799, dtype=float32), 'training/total_loss': Array(0.03016543, dtype=float32), 'training/v_loss': Array(5.427524e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.6963, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.897749, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.663561, dtype=float32), 'eval/episode_reward_alive_std': Array(6.52332, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21494147, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79296922683716, 'eval/sps': 1068.5101206367312, 'num_steps': 37273600}
{'eval/walltime': 54819.76964402199, 'training/sps': 582.9500245371065, 'training/walltime': 63985.15026688576, 'training/entropy_loss': Array(0.01847801, dtype=float32), 'training/policy_loss': Array(0.01203967, dtype=float32), 'training/total_loss': Array(0.03052194, dtype=float32), 'training/v_loss': Array(4.2609927e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.1514, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.832994, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9300113, dtype=float32), 'eval/episode_reward_alive_std': Array(6.799568, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21273498, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.91638231277466, 'eval/sps': 1067.4104532785275, 'num_steps': 37355520}
{'eval/walltime': 54939.52458834648, 'training/sps': 584.297237846076, 'training/walltime': 64125.352880716324, 'training/entropy_loss': Array(0.01865835, dtype=float32), 'training/policy_loss': Array(-0.00090159, dtype=float32), 'training/total_loss': Array(0.01776361, dtype=float32), 'training/v_loss': Array(6.8481463e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.0576, dtype=float32), 'eval/episode_reward_alive': Array(4993.9453, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.887663, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.581064, dtype=float32), 'eval/episode_reward_alive_std': Array(6.484728, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20723921, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.75494432449341, 'eval/sps': 1068.8493967578108, 'num_steps': 37437440}
{'eval/walltime': 55059.4001185894, 'training/sps': 583.1650384968572, 'training/walltime': 64265.82769417763, 'training/entropy_loss': Array(0.01881707, dtype=float32), 'training/policy_loss': Array(0.00779249, dtype=float32), 'training/total_loss': Array(0.02661615, dtype=float32), 'training/v_loss': Array(6.586226e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.774, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.015049, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.866377, dtype=float32), 'eval/episode_reward_alive_std': Array(6.724085, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21855001, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87553024291992, 'eval/sps': 1067.77421330789, 'num_steps': 37519360}
{'eval/walltime': 55179.57306313515, 'training/sps': 582.9730937629353, 'training/walltime': 64406.34875917435, 'training/entropy_loss': Array(0.01861187, dtype=float32), 'training/policy_loss': Array(0.00572856, dtype=float32), 'training/total_loss': Array(0.02434508, dtype=float32), 'training/v_loss': Array(4.6425243e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.8574, dtype=float32), 'eval/episode_reward_alive': Array(4993.5938, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.736418, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0248294, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9015822, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22394441, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.17294454574585, 'eval/sps': 1065.1315941690573, 'num_steps': 37601280}
{'eval/walltime': 55299.40114736557, 'training/sps': 582.6382350812025, 'training/walltime': 64546.950585603714, 'training/entropy_loss': Array(0.01890321, dtype=float32), 'training/policy_loss': Array(0.00210918, dtype=float32), 'training/total_loss': Array(0.02101919, dtype=float32), 'training/v_loss': Array(6.7943038e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.005, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.783679, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8475947, dtype=float32), 'eval/episode_reward_alive_std': Array(6.724085, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20622736, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82808423042297, 'eval/sps': 1068.1969992432064, 'num_steps': 37683200}
{'eval/walltime': 55419.2235956192, 'training/sps': 584.798139463147, 'training/walltime': 64687.03311061859, 'training/entropy_loss': Array(0.01874593, dtype=float32), 'training/policy_loss': Array(0.00987749, dtype=float32), 'training/total_loss': Array(0.02863389, dtype=float32), 'training/v_loss': Array(1.0471365e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.449, dtype=float32), 'eval/episode_reward_alive': Array(4993.203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.753977, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.862957, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6946335, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25190136, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82244825363159, 'eval/sps': 1068.2472430296095, 'num_steps': 37765120}
{'eval/walltime': 55539.134248018265, 'training/sps': 577.7724045357094, 'training/walltime': 64828.819044589996, 'training/entropy_loss': Array(0.01896158, dtype=float32), 'training/policy_loss': Array(0.02166052, dtype=float32), 'training/total_loss': Array(0.04062638, dtype=float32), 'training/v_loss': Array(4.2803267e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.17, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.657628, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.748939, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6580653, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21602327, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.91065239906311, 'eval/sps': 1067.46145933737, 'num_steps': 37847040}
{'eval/walltime': 55659.05351352692, 'training/sps': 584.7870209705576, 'training/walltime': 64968.90423297882, 'training/entropy_loss': Array(0.01883443, dtype=float32), 'training/policy_loss': Array(0.00910272, dtype=float32), 'training/total_loss': Array(0.02794661, dtype=float32), 'training/v_loss': Array(9.465977e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.3574, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.509594, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.5858793, dtype=float32), 'eval/episode_reward_alive_std': Array(6.4715376, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21153888, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.91926550865173, 'eval/sps': 1067.3847897339338, 'num_steps': 37928960}
{'eval/walltime': 55778.83949303627, 'training/sps': 582.8396886093169, 'training/walltime': 65109.457461595535, 'training/entropy_loss': Array(0.01910666, dtype=float32), 'training/policy_loss': Array(0.0006898, dtype=float32), 'training/total_loss': Array(0.01980239, dtype=float32), 'training/v_loss': Array(5.9300783e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.5195, dtype=float32), 'eval/episode_reward_alive': Array(4993.9844, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.464249, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.814217, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7128425, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21790667, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78597950935364, 'eval/sps': 1068.5724700360693, 'num_steps': 38010880}
{'eval/walltime': 55898.69356584549, 'training/sps': 584.3375793831452, 'training/walltime': 65249.65039610863, 'training/entropy_loss': Array(0.01905056, dtype=float32), 'training/policy_loss': Array(0.0032832, dtype=float32), 'training/total_loss': Array(0.0223386, dtype=float32), 'training/v_loss': Array(4.8362176e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.297, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.45353, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7888093, dtype=float32), 'eval/episode_reward_alive_std': Array(6.643841, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24483447, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85407280921936, 'eval/sps': 1067.965376560437, 'num_steps': 38092800}
{'eval/walltime': 56018.581887960434, 'training/sps': 584.5992310110231, 'training/walltime': 65389.78058385849, 'training/entropy_loss': Array(0.01924478, dtype=float32), 'training/policy_loss': Array(0.00793967, dtype=float32), 'training/total_loss': Array(0.0271875, dtype=float32), 'training/v_loss': Array(3.0382666e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.916, dtype=float32), 'eval/episode_reward_alive': Array(4993.242, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.326286, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.002257, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8917365, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22008929, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88832211494446, 'eval/sps': 1067.6602836869997, 'num_steps': 38174720}
{'eval/walltime': 56138.34781742096, 'training/sps': 583.9882114657336, 'training/walltime': 65530.057388067245, 'training/entropy_loss': Array(0.01926796, dtype=float32), 'training/policy_loss': Array(0.00793332, dtype=float32), 'training/total_loss': Array(0.027208, dtype=float32), 'training/v_loss': Array(6.7234823e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.822, dtype=float32), 'eval/episode_reward_alive': Array(4992.9297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.1082, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.193252, dtype=float32), 'eval/episode_reward_alive_std': Array(7.058, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.23669796, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76592946052551, 'eval/sps': 1068.7513600617813, 'num_steps': 38256640}
{'eval/walltime': 56258.27061295509, 'training/sps': 583.2250948541958, 'training/walltime': 65670.51773643494, 'training/entropy_loss': Array(0.01935906, dtype=float32), 'training/policy_loss': Array(0.00670928, dtype=float32), 'training/total_loss': Array(0.02607309, dtype=float32), 'training/v_loss': Array(4.745736e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.034, dtype=float32), 'eval/episode_reward_alive': Array(4995.039, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.004559, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.5742254, dtype=float32), 'eval/episode_reward_alive_std': Array(6.449809, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22078173, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.92279553413391, 'eval/sps': 1067.353370390428, 'num_steps': 38338560}
{'eval/walltime': 56378.23263883591, 'training/sps': 583.8477121764238, 'training/walltime': 65810.82829737663, 'training/entropy_loss': Array(0.01956148, dtype=float32), 'training/policy_loss': Array(0.0084488, dtype=float32), 'training/total_loss': Array(0.02801417, dtype=float32), 'training/v_loss': Array(3.8875964e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.7383, dtype=float32), 'eval/episode_reward_alive': Array(4994.375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.636257, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6280513, dtype=float32), 'eval/episode_reward_alive_std': Array(6.4951906, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24081868, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9620258808136, 'eval/sps': 1067.0043212438943, 'num_steps': 38420480}
{'eval/walltime': 56498.134001255035, 'training/sps': 580.9364926160524, 'training/walltime': 65951.84198999405, 'training/entropy_loss': Array(0.01958859, dtype=float32), 'training/policy_loss': Array(0.01002809, dtype=float32), 'training/total_loss': Array(0.02962602, dtype=float32), 'training/v_loss': Array(9.335892e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.784, dtype=float32), 'eval/episode_reward_alive': Array(4994.258, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.474204, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.92456, dtype=float32), 'eval/episode_reward_alive_std': Array(6.820518, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22834034, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90136241912842, 'eval/sps': 1067.5441664504353, 'num_steps': 38502400}
{'eval/walltime': 56617.987865448, 'training/sps': 584.5407002227238, 'training/walltime': 66091.98620915413, 'training/entropy_loss': Array(0.01967829, dtype=float32), 'training/policy_loss': Array(0.02095301, dtype=float32), 'training/total_loss': Array(0.04063737, dtype=float32), 'training/v_loss': Array(6.0763523e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.6104, dtype=float32), 'eval/episode_reward_alive': Array(4994.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.4520855, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9463477, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8393965, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22780535, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85386419296265, 'eval/sps': 1067.967235448681, 'num_steps': 38584320}
{'eval/walltime': 56737.78915476799, 'training/sps': 581.3245801020911, 'training/walltime': 66232.90576219559, 'training/entropy_loss': Array(0.01972169, dtype=float32), 'training/policy_loss': Array(0.00264427, dtype=float32), 'training/total_loss': Array(0.02237799, dtype=float32), 'training/v_loss': Array(1.2023078e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.1377, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.299463, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1680207, dtype=float32), 'eval/episode_reward_alive_std': Array(7.064159, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25517192, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80128931999207, 'eval/sps': 1068.4359135577329, 'num_steps': 38666240}
{'eval/walltime': 56857.55360913277, 'training/sps': 584.8310813874559, 'training/walltime': 66372.98039674759, 'training/entropy_loss': Array(0.01984542, dtype=float32), 'training/policy_loss': Array(0.02499463, dtype=float32), 'training/total_loss': Array(0.04484676, dtype=float32), 'training/v_loss': Array(6.7082856e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.0957, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.02903, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0521946, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9597054, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25558463, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76445436477661, 'eval/sps': 1068.7645234882439, 'num_steps': 38748160}
{'eval/walltime': 56977.4677400589, 'training/sps': 581.7162828186666, 'training/walltime': 66513.80506062508, 'training/entropy_loss': Array(0.01994003, dtype=float32), 'training/policy_loss': Array(0.00582102, dtype=float32), 'training/total_loss': Array(0.02577187, dtype=float32), 'training/v_loss': Array(1.0816134e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.0664, dtype=float32), 'eval/episode_reward_alive': Array(4994.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.996216, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9871917, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8962736, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25388604, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9141309261322, 'eval/sps': 1067.4304938994117, 'num_steps': 38830080}
{'eval/walltime': 57097.61378931999, 'training/sps': 584.11449483353, 'training/walltime': 66654.05153751373, 'training/entropy_loss': Array(0.02018525, dtype=float32), 'training/policy_loss': Array(0.01620948, dtype=float32), 'training/total_loss': Array(0.03641322, dtype=float32), 'training/v_loss': Array(1.847709e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.1133, dtype=float32), 'eval/episode_reward_alive': Array(4994.0625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.948925, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7313495, dtype=float32), 'eval/episode_reward_alive_std': Array(6.665853, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22363545, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.14604926109314, 'eval/sps': 1065.3700291204682, 'num_steps': 38912000}
{'eval/walltime': 57217.456485033035, 'training/sps': 583.9416639467258, 'training/walltime': 66794.33952355385, 'training/entropy_loss': Array(0.01991315, dtype=float32), 'training/policy_loss': Array(0.00567159, dtype=float32), 'training/total_loss': Array(0.02560106, dtype=float32), 'training/v_loss': Array(1.6326267e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.307, dtype=float32), 'eval/episode_reward_alive': Array(4993.242, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.934693, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0873494, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0041795, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21398161, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84269571304321, 'eval/sps': 1068.0667623372642, 'num_steps': 38993920}
{'eval/walltime': 57337.45798897743, 'training/sps': 584.4776683177946, 'training/walltime': 66934.49885630608, 'training/entropy_loss': Array(0.01978576, dtype=float32), 'training/policy_loss': Array(0.02658891, dtype=float32), 'training/total_loss': Array(0.04638628, dtype=float32), 'training/v_loss': Array(1.1605198e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.793, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.87891, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.683041, dtype=float32), 'eval/episode_reward_alive_std': Array(6.599135, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20208776, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.00150394439697, 'eval/sps': 1066.6532984395692, 'num_steps': 39075840}
{'eval/walltime': 57457.36721038818, 'training/sps': 583.466785559854, 'training/walltime': 67074.90102148056, 'training/entropy_loss': Array(0.01954967, dtype=float32), 'training/policy_loss': Array(0.00520959, dtype=float32), 'training/total_loss': Array(0.02476325, dtype=float32), 'training/v_loss': Array(3.9861748e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.051, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.8165245, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8650646, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7954154, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20548584, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90922141075134, 'eval/sps': 1067.4741983482115, 'num_steps': 39157760}
{'eval/walltime': 57577.43601727486, 'training/sps': 583.2951219436713, 'training/walltime': 67215.34450697899, 'training/entropy_loss': Array(0.01952159, dtype=float32), 'training/policy_loss': Array(0.01093621, dtype=float32), 'training/total_loss': Array(0.0304669, dtype=float32), 'training/v_loss': Array(9.100619e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.0635, dtype=float32), 'eval/episode_reward_alive': Array(4993.9062, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.843124, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.980237, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9015822, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1946834, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.06880688667297, 'eval/sps': 1066.0554003906518, 'num_steps': 39239680}
{'eval/walltime': 57697.31560730934, 'training/sps': 583.6825914519353, 'training/walltime': 67355.69476103783, 'training/entropy_loss': Array(0.01982839, dtype=float32), 'training/policy_loss': Array(0.01730108, dtype=float32), 'training/total_loss': Array(0.03713953, dtype=float32), 'training/v_loss': Array(1.0056635e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.0493, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.739843, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1826253, dtype=float32), 'eval/episode_reward_alive_std': Array(7.091646, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21054356, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87959003448486, 'eval/sps': 1067.738052517357, 'num_steps': 39321600}
{'eval/walltime': 57817.13530540466, 'training/sps': 584.6042539943998, 'training/walltime': 67495.82374477386, 'training/entropy_loss': Array(0.01953696, dtype=float32), 'training/policy_loss': Array(0.00068441, dtype=float32), 'training/total_loss': Array(0.02024164, dtype=float32), 'training/v_loss': Array(2.0259195e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.034, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.637325, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8783646, dtype=float32), 'eval/episode_reward_alive_std': Array(6.803158, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21062058, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81969809532166, 'eval/sps': 1068.2717619449397, 'num_steps': 39403520}
{'eval/walltime': 57936.990850925446, 'training/sps': 582.5758863897295, 'training/walltime': 67636.44061875343, 'training/entropy_loss': Array(0.0196543, dtype=float32), 'training/policy_loss': Array(0.00739104, dtype=float32), 'training/total_loss': Array(0.02705114, dtype=float32), 'training/v_loss': Array(5.800181e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.9165, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.598817, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9606566, dtype=float32), 'eval/episode_reward_alive_std': Array(6.885202, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2109866, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85554552078247, 'eval/sps': 1067.95225405574, 'num_steps': 39485440}
{'eval/walltime': 58057.01377868652, 'training/sps': 584.9879366345708, 'training/walltime': 67776.47769451141, 'training/entropy_loss': Array(0.01961943, dtype=float32), 'training/policy_loss': Array(0.00892982, dtype=float32), 'training/total_loss': Array(0.02856265, dtype=float32), 'training/v_loss': Array(1.339727e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.168, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.582324, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.04583, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9597054, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21094324, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02292776107788, 'eval/sps': 1066.46290327796, 'num_steps': 39567360}
{'eval/walltime': 58176.813989400864, 'training/sps': 582.0372124971334, 'training/walltime': 67917.22470903397, 'training/entropy_loss': Array(0.01944758, dtype=float32), 'training/policy_loss': Array(0.00433247, dtype=float32), 'training/total_loss': Array(0.02379075, dtype=float32), 'training/v_loss': Array(1.0688177e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.7217, dtype=float32), 'eval/episode_reward_alive': Array(4993.2812, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.55879, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8352547, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7730365, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1699572, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80021071434021, 'eval/sps': 1068.44553308184, 'num_steps': 39649280}
{'eval/walltime': 58296.770865917206, 'training/sps': 583.9915852086532, 'training/walltime': 68057.50070285797, 'training/entropy_loss': Array(0.0196989, dtype=float32), 'training/policy_loss': Array(0.01361098, dtype=float32), 'training/total_loss': Array(0.03331628, dtype=float32), 'training/v_loss': Array(6.3934144e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.8857, dtype=float32), 'eval/episode_reward_alive': Array(4994.492, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.606436, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.668781, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6096473, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18921623, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95687651634216, 'eval/sps': 1067.0501243216522, 'num_steps': 39731200}
{'eval/walltime': 58416.587874650955, 'training/sps': 583.0446126464412, 'training/walltime': 68198.00453090668, 'training/entropy_loss': Array(0.01959222, dtype=float32), 'training/policy_loss': Array(0.01799843, dtype=float32), 'training/total_loss': Array(0.0375963, dtype=float32), 'training/v_loss': Array(5.652393e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.5986, dtype=float32), 'eval/episode_reward_alive': Array(4994.2188, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.620176, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.890245, dtype=float32), 'eval/episode_reward_alive_std': Array(6.801812, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18208277, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81700873374939, 'eval/sps': 1068.295739918148, 'num_steps': 39813120}
{'eval/walltime': 58536.42826747894, 'training/sps': 583.899085917034, 'training/walltime': 68338.30274677277, 'training/entropy_loss': Array(0.01926989, dtype=float32), 'training/policy_loss': Array(0.00974517, dtype=float32), 'training/total_loss': Array(0.02901861, dtype=float32), 'training/v_loss': Array(3.55638e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.923, dtype=float32), 'eval/episode_reward_alive': Array(4994.492, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.569337, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6522274, dtype=float32), 'eval/episode_reward_alive_std': Array(6.5800314, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.17748486, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84039282798767, 'eval/sps': 1068.0872865939632, 'num_steps': 39895040}
{'eval/walltime': 58656.45350027084, 'training/sps': 582.6403809814755, 'training/walltime': 68478.90405535698, 'training/entropy_loss': Array(0.01923927, dtype=float32), 'training/policy_loss': Array(0.00302371, dtype=float32), 'training/total_loss': Array(0.02227245, dtype=float32), 'training/v_loss': Array(9.4671195e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4986.815, dtype=float32), 'eval/episode_reward_alive': Array(4995.1562, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.341343, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.4284825, dtype=float32), 'eval/episode_reward_alive_std': Array(6.341132, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18715842, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02523279190063, 'eval/sps': 1066.4424223356932, 'num_steps': 39976960}
{'eval/walltime': 58776.50005817413, 'training/sps': 584.6858960408854, 'training/walltime': 68619.01347231865, 'training/entropy_loss': Array(0.01920476, dtype=float32), 'training/policy_loss': Array(-0.00129679, dtype=float32), 'training/total_loss': Array(0.01791145, dtype=float32), 'training/v_loss': Array(3.481263e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.568, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.2991085, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6542044, dtype=float32), 'eval/episode_reward_alive_std': Array(6.591153, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.16611992, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.0465579032898, 'eval/sps': 1066.2529791409559, 'num_steps': 40058880}
{'eval/walltime': 58896.26833033562, 'training/sps': 583.5233860716479, 'training/walltime': 68759.40201878548, 'training/entropy_loss': Array(0.01908977, dtype=float32), 'training/policy_loss': Array(0.00792233, dtype=float32), 'training/total_loss': Array(0.02702346, dtype=float32), 'training/v_loss': Array(1.1359134e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.4355, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.236046, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9745927, dtype=float32), 'eval/episode_reward_alive_std': Array(6.888747, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.17577626, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76827216148376, 'eval/sps': 1068.7304549857527, 'num_steps': 40140800}
{'eval/walltime': 59016.30880975723, 'training/sps': 583.5815983200847, 'training/walltime': 68899.77656149864, 'training/entropy_loss': Array(0.01926482, dtype=float32), 'training/policy_loss': Array(0.02357087, dtype=float32), 'training/total_loss': Array(0.04284004, dtype=float32), 'training/v_loss': Array(4.351001e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.1514, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.325064, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.960379, dtype=float32), 'eval/episode_reward_alive_std': Array(6.890851, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.16666897, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.0404794216156, 'eval/sps': 1066.3069709212702, 'num_steps': 40222720}
{'eval/walltime': 59136.236053943634, 'training/sps': 582.2688592024032, 'training/walltime': 69040.46758198738, 'training/entropy_loss': Array(0.01944367, dtype=float32), 'training/policy_loss': Array(0.00115166, dtype=float32), 'training/total_loss': Array(0.02060335, dtype=float32), 'training/v_loss': Array(8.02013e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.9453, dtype=float32), 'eval/episode_reward_alive': Array(4993.3203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.374953, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9991436, dtype=float32), 'eval/episode_reward_alive_std': Array(6.911193, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20456235, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.92724418640137, 'eval/sps': 1067.3137773519688, 'num_steps': 40304640}
{'eval/walltime': 59256.07635974884, 'training/sps': 583.7661235145914, 'training/walltime': 69180.79775309563, 'training/entropy_loss': Array(0.01951414, dtype=float32), 'training/policy_loss': Array(0.00700839, dtype=float32), 'training/total_loss': Array(0.02652795, dtype=float32), 'training/v_loss': Array(5.4185025e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.4873, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.262772, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.097416, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0156074, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20873326, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8403058052063, 'eval/sps': 1068.0880621921713, 'num_steps': 40386560}
{'eval/walltime': 59375.88480257988, 'training/sps': 582.6130693559205, 'training/walltime': 69321.40565276146, 'training/entropy_loss': Array(0.01962992, dtype=float32), 'training/policy_loss': Array(0.0047896, dtype=float32), 'training/total_loss': Array(0.02442345, dtype=float32), 'training/v_loss': Array(3.9258066e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4986.265, dtype=float32), 'eval/episode_reward_alive': Array(4994.492, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.22719, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.5206037, dtype=float32), 'eval/episode_reward_alive_std': Array(6.429906, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20224364, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80844283103943, 'eval/sps': 1068.37211948838, 'num_steps': 40468480}
{'eval/walltime': 59495.71062994003, 'training/sps': 584.4241787750847, 'training/walltime': 69461.57781362534, 'training/entropy_loss': Array(0.01952541, dtype=float32), 'training/policy_loss': Array(0.01122319, dtype=float32), 'training/total_loss': Array(0.03075574, dtype=float32), 'training/v_loss': Array(7.147452e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.241, dtype=float32), 'eval/episode_reward_alive': Array(4992.1875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-7.9459996, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9005647, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8107796, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19099206, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8258273601532, 'eval/sps': 1068.2171182951918, 'num_steps': 40550400}
{'eval/walltime': 59615.49077010155, 'training/sps': 583.2759372765677, 'training/walltime': 69602.02591848373, 'training/entropy_loss': Array(0.0196458, dtype=float32), 'training/policy_loss': Array(0.02289661, dtype=float32), 'training/total_loss': Array(0.04255016, dtype=float32), 'training/v_loss': Array(7.745757e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.116, dtype=float32), 'eval/episode_reward_alive': Array(4993.086, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-7.9696918, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9700813, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8784394, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18742445, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78014016151428, 'eval/sps': 1068.624563532835, 'num_steps': 40632320}
{'eval/walltime': 59735.36497712135, 'training/sps': 584.7690467527876, 'training/walltime': 69742.1154127121, 'training/entropy_loss': Array(0.01934152, dtype=float32), 'training/policy_loss': Array(0.00122141, dtype=float32), 'training/total_loss': Array(0.02057004, dtype=float32), 'training/v_loss': Array(7.106242e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.5303, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-7.90746, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6670213, dtype=float32), 'eval/episode_reward_alive_std': Array(6.606992, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18383723, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87420701980591, 'eval/sps': 1067.785999859432, 'num_steps': 40714240}
{'eval/walltime': 59855.08134818077, 'training/sps': 582.0769526430817, 'training/walltime': 69882.85281801224, 'training/entropy_loss': Array(0.01961027, dtype=float32), 'training/policy_loss': Array(0.000178, dtype=float32), 'training/total_loss': Array(0.0197916, dtype=float32), 'training/v_loss': Array(3.3237661e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.498, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-7.978475, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2660394, dtype=float32), 'eval/episode_reward_alive_std': Array(7.195881, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18250348, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.71637105941772, 'eval/sps': 1069.1937858396236, 'num_steps': 40796160}
{'eval/walltime': 59975.358637571335, 'training/sps': 585.1697277963848, 'training/walltime': 70022.84638929367, 'training/entropy_loss': Array(0.01965492, dtype=float32), 'training/policy_loss': Array(0.00202095, dtype=float32), 'training/total_loss': Array(0.021689, dtype=float32), 'training/v_loss': Array(1.3123281e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.8516, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.015534, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7787166, dtype=float32), 'eval/episode_reward_alive_std': Array(6.708636, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21956857, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.27728939056396, 'eval/sps': 1064.2075544649072, 'num_steps': 40878080}
{'eval/walltime': 60095.2155456543, 'training/sps': 573.5695344492609, 'training/walltime': 70165.67126941681, 'training/entropy_loss': Array(0.01974379, dtype=float32), 'training/policy_loss': Array(0.01632682, dtype=float32), 'training/total_loss': Array(0.03607602, dtype=float32), 'training/v_loss': Array(5.415834e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4986.1514, dtype=float32), 'eval/episode_reward_alive': Array(4994.1797, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.028204, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.179978, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1199913, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20124093, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85690808296204, 'eval/sps': 1067.9401133174695, 'num_steps': 40960000}
{'eval/walltime': 60214.97839665413, 'training/sps': 583.8262224006859, 'training/walltime': 70305.98699498177, 'training/entropy_loss': Array(0.01984745, dtype=float32), 'training/policy_loss': Array(0.01149618, dtype=float32), 'training/total_loss': Array(0.03134864, dtype=float32), 'training/v_loss': Array(5.016732e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.9434, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.064631, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.15759, dtype=float32), 'eval/episode_reward_alive_std': Array(7.10798, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18227492, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76285099983215, 'eval/sps': 1068.7788319282695, 'num_steps': 41041920}
{'eval/walltime': 60334.92660856247, 'training/sps': 582.7058553335073, 'training/walltime': 70446.57250523567, 'training/entropy_loss': Array(0.01998644, dtype=float32), 'training/policy_loss': Array(0.00965452, dtype=float32), 'training/total_loss': Array(0.02965101, dtype=float32), 'training/v_loss': Array(1.005752e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.016, dtype=float32), 'eval/episode_reward_alive': Array(4992.1484, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.13177, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3905473, dtype=float32), 'eval/episode_reward_alive_std': Array(7.333666, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25094146, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94821190834045, 'eval/sps': 1067.1272040121148, 'num_steps': 41123840}
{'eval/walltime': 60454.89178419113, 'training/sps': 584.9689203016186, 'training/walltime': 70586.614133358, 'training/entropy_loss': Array(0.0202764, dtype=float32), 'training/policy_loss': Array(0.00563568, dtype=float32), 'training/total_loss': Array(0.02592092, dtype=float32), 'training/v_loss': Array(8.83444e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.871, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.137257, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.714482, dtype=float32), 'eval/episode_reward_alive_std': Array(6.683113, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.23552406, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96517562866211, 'eval/sps': 1066.9763064925503, 'num_steps': 41205760}
{'eval/walltime': 60574.71858406067, 'training/sps': 580.8379900040943, 'training/walltime': 70727.65174007416, 'training/entropy_loss': Array(0.02038131, dtype=float32), 'training/policy_loss': Array(0.00382342, dtype=float32), 'training/total_loss': Array(0.0242147, dtype=float32), 'training/v_loss': Array(9.9828285e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4986.676, dtype=float32), 'eval/episode_reward_alive': Array(4994.8047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.129086, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.914605, dtype=float32), 'eval/episode_reward_alive_std': Array(6.858, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20119435, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82679986953735, 'eval/sps': 1068.2084486889519, 'num_steps': 41287680}
{'eval/walltime': 60694.49648308754, 'training/sps': 584.3917518102395, 'training/walltime': 70867.83167886734, 'training/entropy_loss': Array(0.02028191, dtype=float32), 'training/policy_loss': Array(-0.00059312, dtype=float32), 'training/total_loss': Array(0.01969424, dtype=float32), 'training/v_loss': Array(5.449644e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.877, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.146438, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0268807, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9613495, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20715867, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77789902687073, 'eval/sps': 1068.6445583027362, 'num_steps': 41369600}
{'eval/walltime': 60814.37210726738, 'training/sps': 582.9497535409305, 'training/walltime': 71008.35837006569, 'training/entropy_loss': Array(0.02028028, dtype=float32), 'training/policy_loss': Array(0.00477918, dtype=float32), 'training/total_loss': Array(0.02506835, dtype=float32), 'training/v_loss': Array(8.891244e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.4546, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.177917, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.072078, dtype=float32), 'eval/episode_reward_alive_std': Array(7.007664, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.20913458, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87562417984009, 'eval/sps': 1067.7733765788075, 'num_steps': 41451520}
{'eval/walltime': 60934.336139917374, 'training/sps': 584.7742617498051, 'training/walltime': 71148.4466149807, 'training/entropy_loss': Array(0.02020168, dtype=float32), 'training/policy_loss': Array(0.0571533, dtype=float32), 'training/total_loss': Array(0.07736132, dtype=float32), 'training/v_loss': Array(6.339972e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.677, dtype=float32), 'eval/episode_reward_alive': Array(4993.086, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.4091215, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.385005, dtype=float32), 'eval/episode_reward_alive_std': Array(6.3467846, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19952737, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9640326499939, 'eval/sps': 1066.9864722991747, 'num_steps': 41533440}
{'eval/walltime': 61054.07821273804, 'training/sps': 574.4880310108459, 'training/walltime': 71291.04314541817, 'training/entropy_loss': Array(0.01978732, dtype=float32), 'training/policy_loss': Array(0.00914738, dtype=float32), 'training/total_loss': Array(0.02894267, dtype=float32), 'training/v_loss': Array(7.974074e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.948, dtype=float32), 'eval/episode_reward_alive': Array(4994.336, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.387616, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6664248, dtype=float32), 'eval/episode_reward_alive_std': Array(6.625327, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2045015, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74207282066345, 'eval/sps': 1068.9642912036804, 'num_steps': 41615360}
{'eval/walltime': 61174.00165462494, 'training/sps': 584.6004315459328, 'training/walltime': 71431.1730453968, 'training/entropy_loss': Array(0.01971695, dtype=float32), 'training/policy_loss': Array(0.00342117, dtype=float32), 'training/total_loss': Array(0.02314608, dtype=float32), 'training/v_loss': Array(7.960826e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.4536, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.335435, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7033367, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6068764, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.23351412, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.92344188690186, 'eval/sps': 1067.3476176635677, 'num_steps': 41697280}
{'eval/walltime': 61293.70703601837, 'training/sps': 582.8048284512882, 'training/walltime': 71571.73468112946, 'training/entropy_loss': Array(0.01991916, dtype=float32), 'training/policy_loss': Array(0.0132857, dtype=float32), 'training/total_loss': Array(0.0332074, dtype=float32), 'training/v_loss': Array(2.5464528e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4986.5044, dtype=float32), 'eval/episode_reward_alive': Array(4994.883, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.37801, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.489618, dtype=float32), 'eval/episode_reward_alive_std': Array(6.4185047, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.21233661, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.70538139343262, 'eval/sps': 1069.291944188421, 'num_steps': 41779200}
{'eval/walltime': 61413.56256484985, 'training/sps': 583.5716460331049, 'training/walltime': 71712.11161780357, 'training/entropy_loss': Array(0.0198449, dtype=float32), 'training/policy_loss': Array(0.0048945, dtype=float32), 'training/total_loss': Array(0.02474855, dtype=float32), 'training/v_loss': Array(9.144231e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4986.002, dtype=float32), 'eval/episode_reward_alive': Array(4994.297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.294775, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.652485, dtype=float32), 'eval/episode_reward_alive_std': Array(6.5769, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.22421356, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85552883148193, 'eval/sps': 1067.952402762907, 'num_steps': 41861120}
{'eval/walltime': 61533.327389001846, 'training/sps': 582.7478226617643, 'training/walltime': 71852.68700361252, 'training/entropy_loss': Array(0.01996176, dtype=float32), 'training/policy_loss': Array(0.00738155, dtype=float32), 'training/total_loss': Array(0.0273492, dtype=float32), 'training/v_loss': Array(5.9010417e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4986.55, dtype=float32), 'eval/episode_reward_alive': Array(4994.6875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.138288, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.448144, dtype=float32), 'eval/episode_reward_alive_std': Array(6.3967156, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.19321607, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7648241519928, 'eval/sps': 1068.7612235588974, 'num_steps': 41943040}
{'eval/walltime': 61653.28337430954, 'training/sps': 585.3368019447953, 'training/walltime': 71992.64061617851, 'training/entropy_loss': Array(0.01991263, dtype=float32), 'training/policy_loss': Array(0.00202841, dtype=float32), 'training/total_loss': Array(0.02194642, dtype=float32), 'training/v_loss': Array(5.376196e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4986.4956, dtype=float32), 'eval/episode_reward_alive': Array(4994.6094, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.113852, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.5895915, dtype=float32), 'eval/episode_reward_alive_std': Array(6.543406, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.18104425, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95598530769348, 'eval/sps': 1067.058051931908, 'num_steps': 42024960}
{'eval/walltime': 61773.32990336418, 'training/sps': 582.9438164142165, 'training/walltime': 72133.16873860359, 'training/entropy_loss': Array(0.02005148, dtype=float32), 'training/policy_loss': Array(0.00770302, dtype=float32), 'training/total_loss': Array(0.02775725, dtype=float32), 'training/v_loss': Array(2.745205e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.3745, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.102404, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7199607, dtype=float32), 'eval/episode_reward_alive_std': Array(6.660242, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.1944147, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.04652905464172, 'eval/sps': 1066.2532353745778, 'num_steps': 42106880}
{'eval/walltime': 61893.1005051136, 'training/sps': 584.2634589011789, 'training/walltime': 72273.37945818901, 'training/entropy_loss': Array(0.01996359, dtype=float32), 'training/policy_loss': Array(0.01211826, dtype=float32), 'training/total_loss': Array(0.03209037, dtype=float32), 'training/v_loss': Array(8.5320335e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.1323, dtype=float32), 'eval/episode_reward_alive': Array(4993.203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.070832, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.5045004, dtype=float32), 'eval/episode_reward_alive_std': Array(6.4570203, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.17492265, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77060174942017, 'eval/sps': 1068.709667734634, 'num_steps': 42188800}
{'eval/walltime': 62012.985919713974, 'training/sps': 583.2888688412842, 'training/walltime': 72413.82444930077, 'training/entropy_loss': Array(0.01993801, dtype=float32), 'training/policy_loss': Array(0.07964218, dtype=float32), 'training/total_loss': Array(0.0995852, dtype=float32), 'training/v_loss': Array(5.0195226e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.0737, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.949703, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0955663, dtype=float32), 'eval/episode_reward_alive_std': Array(6.790923, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.6944877, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88541460037231, 'eval/sps': 1067.6861770606288, 'num_steps': 42270720}
{'eval/walltime': 62133.20671582222, 'training/sps': 583.8596948369498, 'training/walltime': 72554.13213062286, 'training/entropy_loss': Array(0.02350584, dtype=float32), 'training/policy_loss': Array(0.10766098, dtype=float32), 'training/total_loss': Array(0.13118115, dtype=float32), 'training/v_loss': Array(1.433876e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4970.206, dtype=float32), 'eval/episode_reward_alive': Array(4989.961, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-19.75504, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(13.476588, dtype=float32), 'eval/episode_reward_alive_std': Array(13.397412, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.8075035, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.22079610824585, 'eval/sps': 1064.7076391404846, 'num_steps': 42352640}
{'eval/walltime': 62252.94256687164, 'training/sps': 583.1052953340586, 'training/walltime': 72694.62133669853, 'training/entropy_loss': Array(0.0216687, dtype=float32), 'training/policy_loss': Array(0.10727024, dtype=float32), 'training/total_loss': Array(0.1298429, dtype=float32), 'training/v_loss': Array(0.00090397, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4945.105, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-48.60615, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(12.476772, dtype=float32), 'eval/episode_reward_alive_std': Array(6.796314, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(10.387113, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.73585104942322, 'eval/sps': 1069.019837234594, 'num_steps': 42434560}
{'eval/walltime': 62373.016744852066, 'training/sps': 583.3598590858064, 'training/walltime': 72835.04923677444, 'training/entropy_loss': Array(0.02334204, dtype=float32), 'training/policy_loss': Array(0.17284477, dtype=float32), 'training/total_loss': Array(0.19684729, dtype=float32), 'training/v_loss': Array(0.0006605, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.536, dtype=float32), 'eval/episode_reward_alive': Array(4992.8516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.315369, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.573471, dtype=float32), 'eval/episode_reward_alive_std': Array(7.439432, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.41117448, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.07417798042297, 'eval/sps': 1066.0077141720617, 'num_steps': 42516480}
{'eval/walltime': 62492.79950261116, 'training/sps': 584.1896045392041, 'training/walltime': 72975.27768206596, 'training/entropy_loss': Array(0.01667621, dtype=float32), 'training/policy_loss': Array(0.02743685, dtype=float32), 'training/total_loss': Array(0.04415562, dtype=float32), 'training/v_loss': Array(4.2565298e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.346, dtype=float32), 'eval/episode_reward_alive': Array(4992.5, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.153479, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2945213, dtype=float32), 'eval/episode_reward_alive_std': Array(7.153452, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.36396933, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78275775909424, 'eval/sps': 1068.6012110142947, 'num_steps': 42598400}
{'eval/walltime': 62612.58344078064, 'training/sps': 584.951101205561, 'training/walltime': 73115.32357621193, 'training/entropy_loss': Array(0.01643051, dtype=float32), 'training/policy_loss': Array(-0.00296346, dtype=float32), 'training/total_loss': Array(0.01348304, dtype=float32), 'training/v_loss': Array(1.598461e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.0635, dtype=float32), 'eval/episode_reward_alive': Array(4994.1016, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.0388, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.001025, dtype=float32), 'eval/episode_reward_alive_std': Array(6.887307, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.35777956, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78393816947937, 'eval/sps': 1068.5906804875285, 'num_steps': 42680320}
{'eval/walltime': 62732.56498289108, 'training/sps': 583.7680932533883, 'training/walltime': 73255.65327382088, 'training/entropy_loss': Array(0.01651835, dtype=float32), 'training/policy_loss': Array(-0.00248153, dtype=float32), 'training/total_loss': Array(0.01405525, dtype=float32), 'training/v_loss': Array(1.8433195e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.38, dtype=float32), 'eval/episode_reward_alive': Array(4994.336, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.955927, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0099044, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8855343, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3299329, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98154211044312, 'eval/sps': 1066.830762036513, 'num_steps': 42762240}
{'eval/walltime': 62852.45909643173, 'training/sps': 585.4682871548067, 'training/walltime': 73395.57545542717, 'training/entropy_loss': Array(0.01659807, dtype=float32), 'training/policy_loss': Array(-0.01006445, dtype=float32), 'training/total_loss': Array(0.00654713, dtype=float32), 'training/v_loss': Array(1.3512102e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4975.41, dtype=float32), 'eval/episode_reward_alive': Array(4992.5, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-17.09021, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7217298, dtype=float32), 'eval/episode_reward_alive_std': Array(7.603453, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37944508, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.89411354064941, 'eval/sps': 1067.6087108863967, 'num_steps': 42844160}
{'eval/walltime': 62972.32850146294, 'training/sps': 583.7928639029591, 'training/walltime': 73535.89919877052, 'training/entropy_loss': Array(0.01661059, dtype=float32), 'training/policy_loss': Array(-0.00781237, dtype=float32), 'training/total_loss': Array(0.00881158, dtype=float32), 'training/v_loss': Array(1.3361259e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.839, dtype=float32), 'eval/episode_reward_alive': Array(4993.711, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.872534, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.051353, dtype=float32), 'eval/episode_reward_alive_std': Array(6.91031, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.41987658, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86940503120422, 'eval/sps': 1067.8287755468482, 'num_steps': 42926080}
{'eval/walltime': 63092.18642115593, 'training/sps': 584.4267861694967, 'training/walltime': 73676.07073426247, 'training/entropy_loss': Array(0.01670815, dtype=float32), 'training/policy_loss': Array(-0.01097816, dtype=float32), 'training/total_loss': Array(0.00573867, dtype=float32), 'training/v_loss': Array(8.68071e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.694, dtype=float32), 'eval/episode_reward_alive': Array(4993.164, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.470032, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7241893, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6400504, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3372322, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85791969299316, 'eval/sps': 1067.9310998210394, 'num_steps': 43008000}
{'eval/walltime': 63211.9467318058, 'training/sps': 581.749344332936, 'training/walltime': 73816.88739490509, 'training/entropy_loss': Array(0.01659416, dtype=float32), 'training/policy_loss': Array(0.00796727, dtype=float32), 'training/total_loss': Array(0.02458197, dtype=float32), 'training/v_loss': Array(2.0533733e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.7705, dtype=float32), 'eval/episode_reward_alive': Array(4994.258, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.487171, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.928522, dtype=float32), 'eval/episode_reward_alive_std': Array(6.763004, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37295178, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76031064987183, 'eval/sps': 1068.8015028135449, 'num_steps': 43089920}
{'eval/walltime': 63331.906131505966, 'training/sps': 584.2804243892981, 'training/walltime': 73957.09404325485, 'training/entropy_loss': Array(0.01669273, dtype=float32), 'training/policy_loss': Array(-0.00873793, dtype=float32), 'training/total_loss': Array(0.00796472, dtype=float32), 'training/v_loss': Array(9.918007e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4976.9424, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-16.417032, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3007264, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1836777, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3673231, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9593997001648, 'eval/sps': 1067.0276803646273, 'num_steps': 43171840}
{'eval/walltime': 63451.774825811386, 'training/sps': 583.7005980999294, 'training/walltime': 74097.4399676323, 'training/entropy_loss': Array(0.01672989, dtype=float32), 'training/policy_loss': Array(-0.00823968, dtype=float32), 'training/total_loss': Array(0.0085001, dtype=float32), 'training/v_loss': Array(9.894913e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.7627, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.987731, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9576993, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7892375, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.40150604, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86869430541992, 'eval/sps': 1067.8351069200928, 'num_steps': 43253760}
{'eval/walltime': 63571.72723698616, 'training/sps': 584.7060820105875, 'training/walltime': 74237.54454755783, 'training/entropy_loss': Array(0.01677079, dtype=float32), 'training/policy_loss': Array(-0.0123629, dtype=float32), 'training/total_loss': Array(0.00442127, dtype=float32), 'training/v_loss': Array(1.33812155e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.001, dtype=float32), 'eval/episode_reward_alive': Array(4992.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.7728405, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1616607, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0657787, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.29458654, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95241117477417, 'eval/sps': 1067.089846268286, 'num_steps': 43335680}
{'eval/walltime': 63691.527097940445, 'training/sps': 583.1366355376931, 'training/walltime': 74378.02620315552, 'training/entropy_loss': Array(0.01679173, dtype=float32), 'training/policy_loss': Array(-0.01444934, dtype=float32), 'training/total_loss': Array(0.00234712, dtype=float32), 'training/v_loss': Array(4.728343e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.672, dtype=float32), 'eval/episode_reward_alive': Array(4993.4375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.765813, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2075667, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0917535, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.301552, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79986095428467, 'eval/sps': 1068.4486524474723, 'num_steps': 43417600}
{'eval/walltime': 63811.64591002464, 'training/sps': 583.2161951489925, 'training/walltime': 74518.48869490623, 'training/entropy_loss': Array(0.01684596, dtype=float32), 'training/policy_loss': Array(-0.00660727, dtype=float32), 'training/total_loss': Array(0.01024944, dtype=float32), 'training/v_loss': Array(1.0738098e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.3096, dtype=float32), 'eval/episode_reward_alive': Array(4993.008, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.698014, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.158962, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0804486, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.29363245, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.118812084198, 'eval/sps': 1065.6116038699886, 'num_steps': 43499520}
{'eval/walltime': 63931.47896003723, 'training/sps': 581.012535008005, 'training/walltime': 74659.48393177986, 'training/entropy_loss': Array(0.01678305, dtype=float32), 'training/policy_loss': Array(-0.01209564, dtype=float32), 'training/total_loss': Array(0.00469313, dtype=float32), 'training/v_loss': Array(5.7290113e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.324, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.464575, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.107141, dtype=float32), 'eval/episode_reward_alive_std': Array(6.896163, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.41900414, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8330500125885, 'eval/sps': 1068.1527340458542, 'num_steps': 43581440}
{'eval/walltime': 64051.42594957352, 'training/sps': 585.1085828033129, 'training/walltime': 74799.49213266373, 'training/entropy_loss': Array(0.01688508, dtype=float32), 'training/policy_loss': Array(-0.00991176, dtype=float32), 'training/total_loss': Array(0.00698175, dtype=float32), 'training/v_loss': Array(8.431343e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4977.3696, dtype=float32), 'eval/episode_reward_alive': Array(4992.539, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-15.169515, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.161081, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9595957, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.47598884, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9469895362854, 'eval/sps': 1067.1380790368105, 'num_steps': 43663360}
{'eval/walltime': 64171.21196722984, 'training/sps': 583.2026471314833, 'training/walltime': 74939.95788741112, 'training/entropy_loss': Array(0.01685804, dtype=float32), 'training/policy_loss': Array(-0.00746306, dtype=float32), 'training/total_loss': Array(0.00940429, dtype=float32), 'training/v_loss': Array(9.316938e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.46, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.938345, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2094603, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0692334, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.40338784, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7860176563263, 'eval/sps': 1068.5721297392167, 'num_steps': 43745280}
{'eval/walltime': 64291.15334510803, 'training/sps': 583.2175266226485, 'training/walltime': 75080.42005848885, 'training/entropy_loss': Array(0.01702636, dtype=float32), 'training/policy_loss': Array(-0.013098, dtype=float32), 'training/total_loss': Array(0.00393137, dtype=float32), 'training/v_loss': Array(3.012849e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.4746, dtype=float32), 'eval/episode_reward_alive': Array(4993.047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.572271, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0788264, dtype=float32), 'eval/episode_reward_alive_std': Array(6.938186, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3062943, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.94137787818909, 'eval/sps': 1067.1880068777862, 'num_steps': 43827200}
{'eval/walltime': 64410.9797437191, 'training/sps': 581.8625194270278, 'training/walltime': 75221.2093296051, 'training/entropy_loss': Array(0.01696135, dtype=float32), 'training/policy_loss': Array(-0.00322475, dtype=float32), 'training/total_loss': Array(0.01374549, dtype=float32), 'training/v_loss': Array(8.889085e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.139, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.337748, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.023629, dtype=float32), 'eval/episode_reward_alive_std': Array(6.862448, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3013614, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82639861106873, 'eval/sps': 1068.2120257612103, 'num_steps': 43909120}
{'eval/walltime': 64531.2067489624, 'training/sps': 584.5947641096058, 'training/walltime': 75361.3405880928, 'training/entropy_loss': Array(0.01715954, dtype=float32), 'training/policy_loss': Array(-0.01094892, dtype=float32), 'training/total_loss': Array(0.00621729, dtype=float32), 'training/v_loss': Array(6.6641733e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4978.511, dtype=float32), 'eval/episode_reward_alive': Array(4992.578, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-14.066811, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.6419873, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4473248, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.34485024, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.22700524330139, 'eval/sps': 1064.6526522137729, 'num_steps': 43991040}
{'eval/walltime': 64651.04455327988, 'training/sps': 583.4104278276668, 'training/walltime': 75501.756316185, 'training/entropy_loss': Array(0.01730886, dtype=float32), 'training/policy_loss': Array(-0.01074057, dtype=float32), 'training/total_loss': Array(0.00657549, dtype=float32), 'training/v_loss': Array(7.1981394e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.583, dtype=float32), 'eval/episode_reward_alive': Array(4994.297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.713686, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8490624, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6653953, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.31423554, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83780431747437, 'eval/sps': 1068.110357403598, 'num_steps': 44072960}
{'eval/walltime': 64770.95129466057, 'training/sps': 584.6100628590423, 'training/walltime': 75641.88390755653, 'training/entropy_loss': Array(0.017265, dtype=float32), 'training/policy_loss': Array(-0.01220697, dtype=float32), 'training/total_loss': Array(0.00506061, dtype=float32), 'training/v_loss': Array(2.5799507e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.1997, dtype=float32), 'eval/episode_reward_alive': Array(4993.5547, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.354687, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.007329, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8508763, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2891145, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90674138069153, 'eval/sps': 1067.4962769075112, 'num_steps': 44154880}
{'eval/walltime': 64890.811101436615, 'training/sps': 581.1666238878994, 'training/walltime': 75782.84176135063, 'training/entropy_loss': Array(0.01753896, dtype=float32), 'training/policy_loss': Array(-0.00858168, dtype=float32), 'training/total_loss': Array(0.00896119, dtype=float32), 'training/v_loss': Array(3.9092774e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.013, dtype=float32), 'eval/episode_reward_alive': Array(4993.086, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-13.07297, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.290293, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1019664, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.33747616, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85980677604675, 'eval/sps': 1067.914286222427, 'num_steps': 44236800}
{'eval/walltime': 65010.68505978584, 'training/sps': 584.6351835489321, 'training/walltime': 75922.96333169937, 'training/entropy_loss': Array(0.01744826, dtype=float32), 'training/policy_loss': Array(-0.00363182, dtype=float32), 'training/total_loss': Array(0.01382428, dtype=float32), 'training/v_loss': Array(7.843415e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4980.6904, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.668751, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.277103, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1290936, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26727045, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.8739583492279, 'eval/sps': 1067.788214910686, 'num_steps': 44318720}
{'eval/walltime': 65130.50135016441, 'training/sps': 581.2259832118802, 'training/walltime': 76063.90678977966, 'training/entropy_loss': Array(0.01769146, dtype=float32), 'training/policy_loss': Array(0.00373324, dtype=float32), 'training/total_loss': Array(0.02143006, dtype=float32), 'training/v_loss': Array(5.369061e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.1177, dtype=float32), 'eval/episode_reward_alive': Array(4993.828, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.710358, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4549117, dtype=float32), 'eval/episode_reward_alive_std': Array(7.328358, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.24310105, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81629037857056, 'eval/sps': 1068.3021448550298, 'num_steps': 44400640}
{'eval/walltime': 65250.45593929291, 'training/sps': 584.794753408905, 'training/walltime': 76203.99012589455, 'training/entropy_loss': Array(0.01758647, dtype=float32), 'training/policy_loss': Array(-0.0034231, dtype=float32), 'training/total_loss': Array(0.01416926, dtype=float32), 'training/v_loss': Array(5.8966007e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4979.661, dtype=float32), 'eval/episode_reward_alive': Array(4992.383, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.721032, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.955298, dtype=float32), 'eval/episode_reward_alive_std': Array(6.816938, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2661501, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.95458912849426, 'eval/sps': 1067.0704716673038, 'num_steps': 44482560}
{'eval/walltime': 65370.31491565704, 'training/sps': 580.7501688519466, 'training/walltime': 76345.0490603447, 'training/entropy_loss': Array(0.01779404, dtype=float32), 'training/policy_loss': Array(0.01369739, dtype=float32), 'training/total_loss': Array(0.03149899, dtype=float32), 'training/v_loss': Array(7.5600306e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.5366, dtype=float32), 'eval/episode_reward_alive': Array(4993.672, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-12.134703, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.158962, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0290794, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2270462, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85897636413574, 'eval/sps': 1067.9216849902969, 'num_steps': 44564480}
{'eval/walltime': 65490.10671377182, 'training/sps': 584.2748754256879, 'training/walltime': 76485.25704026222, 'training/entropy_loss': Array(0.01790363, dtype=float32), 'training/policy_loss': Array(-0.0052828, dtype=float32), 'training/total_loss': Array(0.01262474, dtype=float32), 'training/v_loss': Array(3.902706e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4981.1123, dtype=float32), 'eval/episode_reward_alive': Array(4992.9297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.817947, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1555305, dtype=float32), 'eval/episode_reward_alive_std': Array(7.058, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2265326, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79179811477661, 'eval/sps': 1068.5205666364473, 'num_steps': 44646400}
{'eval/walltime': 65609.87734436989, 'training/sps': 582.9993203611615, 'training/walltime': 76625.77178382874, 'training/entropy_loss': Array(0.0180793, dtype=float32), 'training/policy_loss': Array(-0.00062534, dtype=float32), 'training/total_loss': Array(0.01746109, dtype=float32), 'training/v_loss': Array(7.129345e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.3877, dtype=float32), 'eval/episode_reward_alive': Array(4994.7656, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.378341, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.7702713, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6397057, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25357732, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77063059806824, 'eval/sps': 1068.7094103190311, 'num_steps': 44728320}
{'eval/walltime': 65729.7348484993, 'training/sps': 584.1430715865882, 'training/walltime': 76766.01139974594, 'training/entropy_loss': Array(0.01814889, dtype=float32), 'training/policy_loss': Array(-0.00265445, dtype=float32), 'training/total_loss': Array(0.0154991, dtype=float32), 'training/v_loss': Array(4.6572322e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.6445, dtype=float32), 'eval/episode_reward_alive': Array(4993.9453, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.300451, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.072967, dtype=float32), 'eval/episode_reward_alive_std': Array(6.949942, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25344333, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.85750412940979, 'eval/sps': 1067.934802495126, 'num_steps': 44810240}
{'eval/walltime': 65849.48631978035, 'training/sps': 583.0108448257803, 'training/walltime': 76906.52336573601, 'training/entropy_loss': Array(0.01815489, dtype=float32), 'training/policy_loss': Array(-0.0084519, dtype=float32), 'training/total_loss': Array(0.00970568, dtype=float32), 'training/v_loss': Array(2.686485e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.9004, dtype=float32), 'eval/episode_reward_alive': Array(4994.1406, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.240057, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.871947, dtype=float32), 'eval/episode_reward_alive_std': Array(6.7055645, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2782247, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.75147128105164, 'eval/sps': 1068.8803956286217, 'num_steps': 44892160}
{'eval/walltime': 65969.46662378311, 'training/sps': 584.447232606313, 'training/walltime': 77046.68999743462, 'training/entropy_loss': Array(0.0181758, dtype=float32), 'training/policy_loss': Array(0.00855717, dtype=float32), 'training/total_loss': Array(0.0267431, dtype=float32), 'training/v_loss': Array(1.0127133e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.544, dtype=float32), 'eval/episode_reward_alive': Array(4993.633, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.089079, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9409885, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8668942, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2524747, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.98030400276184, 'eval/sps': 1066.8417709381163, 'num_steps': 44974080}
{'eval/walltime': 66089.43172121048, 'training/sps': 583.7521929015179, 'training/walltime': 77187.02351737022, 'training/entropy_loss': Array(0.01813693, dtype=float32), 'training/policy_loss': Array(-0.00629526, dtype=float32), 'training/total_loss': Array(0.01184572, dtype=float32), 'training/v_loss': Array(4.04393e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.7993, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-11.06726, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1735587, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0493474, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25508237, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96509742736816, 'eval/sps': 1066.9770020192457, 'num_steps': 45056000}
{'eval/walltime': 66209.21198558807, 'training/sps': 584.2233342167937, 'training/walltime': 77327.24386668205, 'training/entropy_loss': Array(0.01839354, dtype=float32), 'training/policy_loss': Array(-0.0025794, dtype=float32), 'training/total_loss': Array(0.01581979, dtype=float32), 'training/v_loss': Array(5.64896e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.6475, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.828688, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.6672983, dtype=float32), 'eval/episode_reward_alive_std': Array(6.54189, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.28940737, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.780264377594, 'eval/sps': 1068.6234553339623, 'num_steps': 45137920}
{'eval/walltime': 66328.99978971481, 'training/sps': 583.0564762865927, 'training/walltime': 77467.74483585358, 'training/entropy_loss': Array(0.01827461, dtype=float32), 'training/policy_loss': Array(0.00067203, dtype=float32), 'training/total_loss': Array(0.0189568, dtype=float32), 'training/v_loss': Array(1.0155875e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.409, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.949984, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.091364, dtype=float32), 'eval/episode_reward_alive_std': Array(6.990769, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26054198, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7878041267395, 'eval/sps': 1068.5561934549842, 'num_steps': 45219840}
{'eval/walltime': 66448.69947528839, 'training/sps': 584.2015932913995, 'training/walltime': 77607.97040343285, 'training/entropy_loss': Array(0.01856828, dtype=float32), 'training/policy_loss': Array(0.0183523, dtype=float32), 'training/total_loss': Array(0.03692605, dtype=float32), 'training/v_loss': Array(5.4796037e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.0464, dtype=float32), 'eval/episode_reward_alive': Array(4993.086, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.039391, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.194919, dtype=float32), 'eval/episode_reward_alive_std': Array(7.074412, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25882003, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.69968557357788, 'eval/sps': 1069.3428256444336, 'num_steps': 45301760}
{'eval/walltime': 66568.44368076324, 'training/sps': 583.1328777814596, 'training/walltime': 77748.45296430588, 'training/entropy_loss': Array(0.01839869, dtype=float32), 'training/policy_loss': Array(0.01363916, dtype=float32), 'training/total_loss': Array(0.03204621, dtype=float32), 'training/v_loss': Array(8.367514e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.6514, dtype=float32), 'eval/episode_reward_alive': Array(4993.789, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.138035, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.076196, dtype=float32), 'eval/episode_reward_alive_std': Array(6.952576, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25294006, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74420547485352, 'eval/sps': 1068.9452528613606, 'num_steps': 45383680}
{'eval/walltime': 66688.32929229736, 'training/sps': 584.8155172468141, 'training/walltime': 77888.53132677078, 'training/entropy_loss': Array(0.01865914, dtype=float32), 'training/policy_loss': Array(0.00031498, dtype=float32), 'training/total_loss': Array(0.01897908, dtype=float32), 'training/v_loss': Array(4.957232e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.9756, dtype=float32), 'eval/episode_reward_alive': Array(4992.7344, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.758584, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5445323, dtype=float32), 'eval/episode_reward_alive_std': Array(7.417762, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26508304, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88561153411865, 'eval/sps': 1067.6844231934542, 'num_steps': 45465600}
{'eval/walltime': 66808.13025403023, 'training/sps': 581.3179472527737, 'training/walltime': 78029.45248770714, 'training/entropy_loss': Array(0.01880237, dtype=float32), 'training/policy_loss': Array(0.00288408, dtype=float32), 'training/total_loss': Array(0.02169594, dtype=float32), 'training/v_loss': Array(9.4881725e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.677, dtype=float32), 'eval/episode_reward_alive': Array(4993.3594, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.682884, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0026665, dtype=float32), 'eval/episode_reward_alive_std': Array(6.8781066, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.31728032, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80096173286438, 'eval/sps': 1068.4388351190207, 'num_steps': 45547520}
{'eval/walltime': 66927.97544956207, 'training/sps': 584.9385529032644, 'training/walltime': 78169.50138616562, 'training/entropy_loss': Array(0.01898982, dtype=float32), 'training/policy_loss': Array(0.00494137, dtype=float32), 'training/total_loss': Array(0.02393571, dtype=float32), 'training/v_loss': Array(4.516224e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.987, dtype=float32), 'eval/episode_reward_alive': Array(4994.258, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.270951, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1165586, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0181084, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25470522, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84519553184509, 'eval/sps': 1068.0444838190283, 'num_steps': 45629440}
{'eval/walltime': 67047.74678635597, 'training/sps': 584.2120428785864, 'training/walltime': 78309.72444558144, 'training/entropy_loss': Array(0.01928625, dtype=float32), 'training/policy_loss': Array(0.00884113, dtype=float32), 'training/total_loss': Array(0.02813574, dtype=float32), 'training/v_loss': Array(8.368692e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.7812, dtype=float32), 'eval/episode_reward_alive': Array(4995.078, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.29668, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.843071, dtype=float32), 'eval/episode_reward_alive_std': Array(6.731003, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2835755, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77133679389954, 'eval/sps': 1068.7031089939342, 'num_steps': 45711360}
{'eval/walltime': 67167.65433883667, 'training/sps': 584.6048289077053, 'training/walltime': 78449.85329151154, 'training/entropy_loss': Array(0.01918453, dtype=float32), 'training/policy_loss': Array(-0.00049412, dtype=float32), 'training/total_loss': Array(0.01869636, dtype=float32), 'training/v_loss': Array(5.9533504e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.826, dtype=float32), 'eval/episode_reward_alive': Array(4994.0234, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.197233, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8340917, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6748886, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.30820978, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90755248069763, 'eval/sps': 1067.4890559592154, 'num_steps': 45793280}
{'eval/walltime': 67287.49055194855, 'training/sps': 581.6424368821994, 'training/walltime': 78590.69583463669, 'training/entropy_loss': Array(0.01935216, dtype=float32), 'training/policy_loss': Array(0.03944876, dtype=float32), 'training/total_loss': Array(0.05880943, dtype=float32), 'training/v_loss': Array(8.5027195e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.537, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.213547, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3406334, dtype=float32), 'eval/episode_reward_alive_std': Array(7.180703, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.31223947, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83621311187744, 'eval/sps': 1068.1245399543873, 'num_steps': 45875200}
{'eval/walltime': 67407.45630598068, 'training/sps': 584.5547729168771, 'training/walltime': 78730.83667993546, 'training/entropy_loss': Array(0.01919733, dtype=float32), 'training/policy_loss': Array(0.01256563, dtype=float32), 'training/total_loss': Array(0.03176983, dtype=float32), 'training/v_loss': Array(6.8716404e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.0664, dtype=float32), 'eval/episode_reward_alive': Array(4994.297, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.230761, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9659147, dtype=float32), 'eval/episode_reward_alive_std': Array(6.75273, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.34444493, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96575403213501, 'eval/sps': 1066.9711621677707, 'num_steps': 45957120}
{'eval/walltime': 67527.23099327087, 'training/sps': 582.8872185156221, 'training/walltime': 78871.37844753265, 'training/entropy_loss': Array(0.01941803, dtype=float32), 'training/policy_loss': Array(0.02028027, dtype=float32), 'training/total_loss': Array(0.03970493, dtype=float32), 'training/v_loss': Array(6.6197563e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.634, dtype=float32), 'eval/episode_reward_alive': Array(4992.7734, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.139932, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2283397, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0657787, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3155711, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77468729019165, 'eval/sps': 1068.6732138142006, 'num_steps': 46039040}
{'eval/walltime': 67647.13699650764, 'training/sps': 584.7634825331562, 'training/walltime': 79011.46927475929, 'training/entropy_loss': Array(0.01947186, dtype=float32), 'training/policy_loss': Array(0.00109951, dtype=float32), 'training/total_loss': Array(0.02057583, dtype=float32), 'training/v_loss': Array(4.459168e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.292, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.223574, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.237597, dtype=float32), 'eval/episode_reward_alive_std': Array(7.025605, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.39254966, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.90600323677063, 'eval/sps': 1067.502848437427, 'num_steps': 46120960}
{'eval/walltime': 67766.93225359917, 'training/sps': 578.5047158915273, 'training/walltime': 79153.07572627068, 'training/entropy_loss': Array(0.01958189, dtype=float32), 'training/policy_loss': Array(0.02632358, dtype=float32), 'training/total_loss': Array(0.04591116, dtype=float32), 'training/v_loss': Array(5.6962062e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.1084, dtype=float32), 'eval/episode_reward_alive': Array(4994.336, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.227026, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.742222, dtype=float32), 'eval/episode_reward_alive_std': Array(6.625327, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2747714, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79525709152222, 'eval/sps': 1068.4897140978583, 'num_steps': 46202880}
{'eval/walltime': 67886.75587201118, 'training/sps': 583.9234727317694, 'training/walltime': 79293.36808276176, 'training/entropy_loss': Array(0.01953978, dtype=float32), 'training/policy_loss': Array(0.00706019, dtype=float32), 'training/total_loss': Array(0.02660561, dtype=float32), 'training/v_loss': Array(5.638449e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.918, dtype=float32), 'eval/episode_reward_alive': Array(4993.203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.285547, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.620763, dtype=float32), 'eval/episode_reward_alive_std': Array(7.4407654, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.39103547, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82361841201782, 'eval/sps': 1068.23681087536, 'num_steps': 46284800}
{'eval/walltime': 68006.5221221447, 'training/sps': 581.4786515282161, 'training/walltime': 79434.25029706955, 'training/entropy_loss': Array(0.01957982, dtype=float32), 'training/policy_loss': Array(0.00187717, dtype=float32), 'training/total_loss': Array(0.02146039, dtype=float32), 'training/v_loss': Array(3.4016982e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.374, dtype=float32), 'eval/episode_reward_alive': Array(4994.5703, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.19677, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.781506, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6151857, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.33454213, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.7662501335144, 'eval/sps': 1068.7484984902399, 'num_steps': 46366720}
{'eval/walltime': 68126.46276283264, 'training/sps': 584.7680147119222, 'training/walltime': 79574.34003853798, 'training/entropy_loss': Array(0.0195343, dtype=float32), 'training/policy_loss': Array(0.01253998, dtype=float32), 'training/total_loss': Array(0.03208304, dtype=float32), 'training/v_loss': Array(8.762313e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.738, dtype=float32), 'eval/episode_reward_alive': Array(4994.922, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.184114, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.32715, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0982056, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.40085536, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9406406879425, 'eval/sps': 1067.1945661273069, 'num_steps': 46448640}
{'eval/walltime': 68246.27734684944, 'training/sps': 583.1167517477709, 'training/walltime': 79714.82648444176, 'training/entropy_loss': Array(0.01953875, dtype=float32), 'training/policy_loss': Array(0.00197558, dtype=float32), 'training/total_loss': Array(0.02152305, dtype=float32), 'training/v_loss': Array(8.719723e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.5205, dtype=float32), 'eval/episode_reward_alive': Array(4992.8516, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.331219, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3357263, dtype=float32), 'eval/episode_reward_alive_std': Array(7.117419, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.42794994, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.81458401679993, 'eval/sps': 1068.3173592795042, 'num_steps': 46530560}
{'eval/walltime': 68366.12593007088, 'training/sps': 583.9304410508129, 'training/walltime': 79855.11716675758, 'training/entropy_loss': Array(0.01974036, dtype=float32), 'training/policy_loss': Array(0.00108456, dtype=float32), 'training/total_loss': Array(0.02083501, dtype=float32), 'training/v_loss': Array(1.0097071e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.6426, dtype=float32), 'eval/episode_reward_alive': Array(4993.867, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.224583, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3273544, dtype=float32), 'eval/episode_reward_alive_std': Array(7.104544, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.43569848, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.84858322143555, 'eval/sps': 1068.0142940321928, 'num_steps': 46612480}
{'eval/walltime': 68486.24995446205, 'training/sps': 582.1482153119423, 'training/walltime': 79995.8373439312, 'training/entropy_loss': Array(0.01959328, dtype=float32), 'training/policy_loss': Array(0.02843919, dtype=float32), 'training/total_loss': Array(0.04804329, dtype=float32), 'training/v_loss': Array(1.0816884e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.76, dtype=float32), 'eval/episode_reward_alive': Array(4992.9688, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.208653, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4441075, dtype=float32), 'eval/episode_reward_alive_std': Array(7.192593, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.44436178, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.12402439117432, 'eval/sps': 1065.5653658686808, 'num_steps': 46694400}
{'eval/walltime': 68606.02040362358, 'training/sps': 584.4179431907688, 'training/walltime': 80136.01100039482, 'training/entropy_loss': Array(0.01982305, dtype=float32), 'training/policy_loss': Array(0.01115647, dtype=float32), 'training/total_loss': Array(0.03098945, dtype=float32), 'training/v_loss': Array(9.922958e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.435, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.314848, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3062806, dtype=float32), 'eval/episode_reward_alive_std': Array(7.071068, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.4541084, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.77044916152954, 'eval/sps': 1068.7110292737702, 'num_steps': 46776320}
{'eval/walltime': 68725.82207202911, 'training/sps': 584.1331130497776, 'training/walltime': 80276.25300717354, 'training/entropy_loss': Array(0.01959623, dtype=float32), 'training/policy_loss': Array(0.00728525, dtype=float32), 'training/total_loss': Array(0.02689463, dtype=float32), 'training/v_loss': Array(1.3151577e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.8545, dtype=float32), 'eval/episode_reward_alive': Array(4992.8906, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.03565, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3081055, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1427784, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.40944394, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.80166840553284, 'eval/sps': 1068.4325327316437, 'num_steps': 46858240}
{'eval/walltime': 68845.43497896194, 'training/sps': 584.4934660337076, 'training/walltime': 80416.40855169296, 'training/entropy_loss': Array(0.01978983, dtype=float32), 'training/policy_loss': Array(0.02238109, dtype=float32), 'training/total_loss': Array(0.04217483, dtype=float32), 'training/v_loss': Array(3.9131683e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.366, dtype=float32), 'eval/episode_reward_alive': Array(4994.6094, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.243639, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.9239407, dtype=float32), 'eval/episode_reward_alive_std': Array(6.6617312, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.44061646, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.61290693283081, 'eval/sps': 1070.1186291867232, 'num_steps': 46940160}
{'eval/walltime': 68965.23410534859, 'training/sps': 582.5152417434875, 'training/walltime': 80557.04006505013, 'training/entropy_loss': Array(0.01954321, dtype=float32), 'training/policy_loss': Array(0.03118496, dtype=float32), 'training/total_loss': Array(0.05073871, dtype=float32), 'training/v_loss': Array(1.05397485e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.5474, dtype=float32), 'eval/episode_reward_alive': Array(4992.8125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.265217, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.7699428, dtype=float32), 'eval/episode_reward_alive_std': Array(7.5454354, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.5106687, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79912638664246, 'eval/sps': 1068.4552038125041, 'num_steps': 47022080}
{'eval/walltime': 69085.07282185555, 'training/sps': 585.1655441672095, 'training/walltime': 80697.03463721275, 'training/entropy_loss': Array(0.01969096, dtype=float32), 'training/policy_loss': Array(0.0089841, dtype=float32), 'training/total_loss': Array(0.02867975, dtype=float32), 'training/v_loss': Array(4.6929495e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.3555, dtype=float32), 'eval/episode_reward_alive': Array(4993.3203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.964535, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.363849, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2692995, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3108105, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.83871650695801, 'eval/sps': 1068.1022271510071, 'num_steps': 47104000}
{'eval/walltime': 69204.87223887444, 'training/sps': 582.4432385502357, 'training/walltime': 80837.68353581429, 'training/entropy_loss': Array(0.01977425, dtype=float32), 'training/policy_loss': Array(0.0243967, dtype=float32), 'training/total_loss': Array(0.04418274, dtype=float32), 'training/v_loss': Array(1.1784588e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.593, dtype=float32), 'eval/episode_reward_alive': Array(4991.6016, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.008875, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.569257, dtype=float32), 'eval/episode_reward_alive_std': Array(7.445993, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.31992823, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79941701889038, 'eval/sps': 1068.452611750327, 'num_steps': 47185920}
{'eval/walltime': 69324.65875315666, 'training/sps': 584.6475308201054, 'training/walltime': 80977.80214691162, 'training/entropy_loss': Array(0.01978436, dtype=float32), 'training/policy_loss': Array(0.00775012, dtype=float32), 'training/total_loss': Array(0.02754369, dtype=float32), 'training/v_loss': Array(9.199222e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.245, dtype=float32), 'eval/episode_reward_alive': Array(4993.2812, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.036123, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.0765934, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9439015, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2966618, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.78651428222656, 'eval/sps': 1068.567699519345, 'num_steps': 47267840}
{'eval/walltime': 69444.48620247841, 'training/sps': 583.3127283899565, 'training/walltime': 81118.24139332771, 'training/entropy_loss': Array(0.01986911, dtype=float32), 'training/policy_loss': Array(0.0144995, dtype=float32), 'training/total_loss': Array(0.03437778, dtype=float32), 'training/v_loss': Array(9.175783e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.4404, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.03641, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3127375, dtype=float32), 'eval/episode_reward_alive_std': Array(7.168687, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.33839285, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82744932174683, 'eval/sps': 1068.202659111179, 'num_steps': 47349760}
{'eval/walltime': 69564.06706666946, 'training/sps': 584.7328608183877, 'training/walltime': 81258.33955693245, 'training/entropy_loss': Array(0.01987656, dtype=float32), 'training/policy_loss': Array(0.01199785, dtype=float32), 'training/total_loss': Array(0.0318898, dtype=float32), 'training/v_loss': Array(1.538792e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.273, dtype=float32), 'eval/episode_reward_alive': Array(4993.2812, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.00795, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.349431, dtype=float32), 'eval/episode_reward_alive_std': Array(7.219697, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3108963, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.5808641910553, 'eval/sps': 1070.4053768627512, 'num_steps': 47431680}
{'eval/walltime': 69683.89006948471, 'training/sps': 583.714356681309, 'training/walltime': 81398.6821732521, 'training/entropy_loss': Array(0.01994483, dtype=float32), 'training/policy_loss': Array(0.00331634, dtype=float32), 'training/total_loss': Array(0.02327006, dtype=float32), 'training/v_loss': Array(8.879936e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.8174, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.932742, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.451007, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2618437, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3277604, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.82300281524658, 'eval/sps': 1068.2422989963072, 'num_steps': 47513600}
{'eval/walltime': 69803.91026449203, 'training/sps': 584.6531545124581, 'training/walltime': 81538.79943656921, 'training/entropy_loss': Array(0.01997098, dtype=float32), 'training/policy_loss': Array(0.02172328, dtype=float32), 'training/total_loss': Array(0.04170533, dtype=float32), 'training/v_loss': Array(1.1073882e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.5024, dtype=float32), 'eval/episode_reward_alive': Array(4992.461, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.958257, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.8743467, dtype=float32), 'eval/episode_reward_alive_std': Array(6.760296, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2928464, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.02019500732422, 'eval/sps': 1066.487185695614, 'num_steps': 47595520}
{'eval/walltime': 69923.77861166, 'training/sps': 584.5734172221175, 'training/walltime': 81678.93581223488, 'training/entropy_loss': Array(0.01993428, dtype=float32), 'training/policy_loss': Array(0.03795519, dtype=float32), 'training/total_loss': Array(0.05789928, dtype=float32), 'training/v_loss': Array(9.813185e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.302, dtype=float32), 'eval/episode_reward_alive': Array(4992.3047, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.002903, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.253894, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0959477, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.33356112, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86834716796875, 'eval/sps': 1067.83819935914, 'num_steps': 47677440}
{'eval/walltime': 70043.5408153534, 'training/sps': 584.8022461764939, 'training/walltime': 81819.0173535347, 'training/entropy_loss': Array(0.0199497, dtype=float32), 'training/policy_loss': Array(0.00734694, dtype=float32), 'training/total_loss': Array(0.02730911, dtype=float32), 'training/v_loss': Array(1.2475084e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.6543, dtype=float32), 'eval/episode_reward_alive': Array(4993.75, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.095541, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.1442943, dtype=float32), 'eval/episode_reward_alive_std': Array(7.0156074, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.32565814, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.76220369338989, 'eval/sps': 1068.7846086040647, 'num_steps': 47759360}
{'eval/walltime': 70163.41492915154, 'training/sps': 584.3968189385743, 'training/walltime': 81959.19607686996, 'training/entropy_loss': Array(0.01986952, dtype=float32), 'training/policy_loss': Array(0.00367214, dtype=float32), 'training/total_loss': Array(0.02355334, dtype=float32), 'training/v_loss': Array(1.1687898e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.157, dtype=float32), 'eval/episode_reward_alive': Array(4993.203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.045856, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3309927, dtype=float32), 'eval/episode_reward_alive_std': Array(7.146196, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.354235, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.87411379814148, 'eval/sps': 1067.7868302371091, 'num_steps': 47841280}
{'eval/walltime': 70283.27729296684, 'training/sps': 585.0541269773549, 'training/walltime': 82099.21730947495, 'training/entropy_loss': Array(0.02010611, dtype=float32), 'training/policy_loss': Array(0.02019699, dtype=float32), 'training/total_loss': Array(0.04031407, dtype=float32), 'training/v_loss': Array(1.0968677e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.363, dtype=float32), 'eval/episode_reward_alive': Array(4993.3203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.957578, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.5559597, dtype=float32), 'eval/episode_reward_alive_std': Array(7.428759, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2751538, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.86236381530762, 'eval/sps': 1067.8915042692752, 'num_steps': 47923200}
{'eval/walltime': 70403.24258255959, 'training/sps': 583.102143588048, 'training/walltime': 82239.70727491379, 'training/entropy_loss': Array(0.02008912, dtype=float32), 'training/policy_loss': Array(0.00347078, dtype=float32), 'training/total_loss': Array(0.02356828, dtype=float32), 'training/v_loss': Array(8.37995e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.579, dtype=float32), 'eval/episode_reward_alive': Array(4993.5156, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.93647, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.3990026, dtype=float32), 'eval/episode_reward_alive_std': Array(7.271503, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.26860058, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96528959274292, 'eval/sps': 1066.9752928912458, 'num_steps': 48005120}
{'eval/walltime': 70523.16880989075, 'training/sps': 584.7929857489, 'training/walltime': 82379.79103446007, 'training/entropy_loss': Array(0.02038329, dtype=float32), 'training/policy_loss': Array(0.00390358, dtype=float32), 'training/total_loss': Array(0.02429261, dtype=float32), 'training/v_loss': Array(5.7382645e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4985.766, dtype=float32), 'eval/episode_reward_alive': Array(4994.6484, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.882521, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.745248, dtype=float32), 'eval/episode_reward_alive_std': Array(6.619797, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.25012037, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.9262273311615, 'eval/sps': 1067.322827112236, 'num_steps': 48087040}
{'eval/walltime': 70643.04882311821, 'training/sps': 583.5876594598969, 'training/walltime': 82520.16411924362, 'training/entropy_loss': Array(0.02023463, dtype=float32), 'training/policy_loss': Array(0.01946429, dtype=float32), 'training/total_loss': Array(0.03970864, dtype=float32), 'training/v_loss': Array(9.721977e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.126, dtype=float32), 'eval/episode_reward_alive': Array(4993.203, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.076807, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.227196, dtype=float32), 'eval/episode_reward_alive_std': Array(6.9802837, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.38237944, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.88001322746277, 'eval/sps': 1067.7342832547924, 'num_steps': 48168960}
{'eval/walltime': 70762.84557747841, 'training/sps': 584.385815092379, 'training/walltime': 82660.34548211098, 'training/entropy_loss': Array(0.02013714, dtype=float32), 'training/policy_loss': Array(0.0095176, dtype=float32), 'training/total_loss': Array(0.02966168, dtype=float32), 'training/v_loss': Array(6.93406e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.365, dtype=float32), 'eval/episode_reward_alive': Array(4993.3984, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.033037, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.392655, dtype=float32), 'eval/episode_reward_alive_std': Array(7.2600574, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.2785426, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.79675436019897, 'eval/sps': 1068.4763596777916, 'num_steps': 48250880}
{'eval/walltime': 70882.9140651226, 'training/sps': 582.8801109318189, 'training/walltime': 82800.88896346092, 'training/entropy_loss': Array(0.0201117, dtype=float32), 'training/policy_loss': Array(0.01109485, dtype=float32), 'training/total_loss': Array(0.03121708, dtype=float32), 'training/v_loss': Array(1.0532014e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4982.788, dtype=float32), 'eval/episode_reward_alive': Array(4991.875, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.086628, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(6.98652, dtype=float32), 'eval/episode_reward_alive_std': Array(6.817945, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.297916, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.06848764419556, 'eval/sps': 1066.058234857661, 'num_steps': 48332800}
{'eval/walltime': 71002.66076183319, 'training/sps': 584.6169202529642, 'training/walltime': 82941.01491117477, 'training/entropy_loss': Array(0.02003968, dtype=float32), 'training/policy_loss': Array(0.04760754, dtype=float32), 'training/total_loss': Array(0.06765526, dtype=float32), 'training/v_loss': Array(8.037539e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.8687, dtype=float32), 'eval/episode_reward_alive': Array(4994.1406, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.271756, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.2960114, dtype=float32), 'eval/episode_reward_alive_std': Array(7.1564374, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.31047693, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.74669671058655, 'eval/sps': 1068.9230142970932, 'num_steps': 48414720}
{'eval/walltime': 71122.71263980865, 'training/sps': 583.4463006666456, 'training/walltime': 83081.4220058918, 'training/entropy_loss': Array(0.0201295, dtype=float32), 'training/policy_loss': Array(0.01179762, dtype=float32), 'training/total_loss': Array(0.03193973, dtype=float32), 'training/v_loss': Array(1.2603836e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4984.244, dtype=float32), 'eval/episode_reward_alive': Array(4993.4766, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.233061, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.4245567, dtype=float32), 'eval/episode_reward_alive_std': Array(7.276852, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.33272165, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.05187797546387, 'eval/sps': 1066.205728378198, 'num_steps': 48496640}
{'eval/walltime': 71242.68100452423, 'training/sps': 584.7640199419868, 'training/walltime': 83221.5127043724, 'training/entropy_loss': Array(0.0200399, dtype=float32), 'training/policy_loss': Array(0.01267548, dtype=float32), 'training/total_loss': Array(0.03273157, dtype=float32), 'training/v_loss': Array(1.6178761e-05, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.2344, dtype=float32), 'eval/episode_reward_alive': Array(4992.617, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.383385, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.682814, dtype=float32), 'eval/episode_reward_alive_std': Array(7.525084, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.37699383, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 119.96836471557617, 'eval/sps': 1066.9479433471101, 'num_steps': 48578560}
{'eval/walltime': 71362.793364048, 'training/sps': 583.1554656244683, 'training/walltime': 83361.9898238182, 'training/entropy_loss': Array(0.02005212, dtype=float32), 'training/policy_loss': Array(0.02089046, dtype=float32), 'training/total_loss': Array(0.04095162, dtype=float32), 'training/v_loss': Array(9.048505e-06, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(4983.7744, dtype=float32), 'eval/episode_reward_alive': Array(4993.125, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-9.350528, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.329462, dtype=float32), 'eval/episode_reward_alive_std': Array(7.153452, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(0.3205773, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 120.1123595237732, 'eval/sps': 1065.6688496296308, 'num_steps': 48660480}
Traceback (most recent call last):
  File "/home/jovyan/Brax-Rodent-Run/serevr_run.py", line 308, in <module>
    make_inference_fn, params, _ = train_fn(environment=env, progress_fn=wandb_progress, policy_params_fn=policy_params_fn)
  File "/opt/conda/lib/python3.10/site-packages/brax/training/agents/ppo/train.py", line 423, in train
    training_epoch_with_timing(training_state, env_state, epoch_keys)
  File "/opt/conda/lib/python3.10/site-packages/brax/training/agents/ppo/train.py", line 350, in training_epoch_with_timing
    result = training_epoch(training_state, env_state, key)
  File "/opt/conda/lib/python3.10/site-packages/flax/struct.py", line 135, in clz_from_iterable
    def clz_from_iterable(meta, data):
KeyboardInterrupt