
{'eval/walltime': 189.9718143939972, 'eval/episode_distance_from_origin': Array(3040.2224, dtype=float32), 'eval/episode_distance_reward': Array(0.04533512, dtype=float32), 'eval/episode_forward_reward': Array(7.555855, dtype=float32), 'eval/episode_reward': Array(-203.19293, dtype=float32), 'eval/episode_reward_alive': Array(1.8320312, dtype=float32), 'eval/episode_reward_linvel': Array(7.555855, dtype=float32), 'eval/episode_reward_quadctrl': Array(-212.62614, dtype=float32), 'eval/episode_x_position': Array(3019.607, dtype=float32), 'eval/episode_x_velocity': Array(1.5111728, dtype=float32), 'eval/episode_y_position': Array(-0.82050574, dtype=float32), 'eval/episode_y_velocity': Array(-1.7427936, dtype=float32), 'eval/episode_distance_from_origin_std': Array(52.39384, dtype=float32), 'eval/episode_distance_reward_std': Array(0.37555018, dtype=float32), 'eval/episode_forward_reward_std': Array(62.59169, dtype=float32), 'eval/episode_reward_std': Array(62.78486, dtype=float32), 'eval/episode_reward_alive_std': Array(2.5975327, dtype=float32), 'eval/episode_reward_linvel_std': Array(62.59169, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.1954284, dtype=float32), 'eval/episode_x_position_std': Array(52.66544, dtype=float32), 'eval/episode_x_velocity_std': Array(12.518339, dtype=float32), 'eval/episode_y_position_std': Array(56.790268, dtype=float32), 'eval/episode_y_velocity_std': Array(12.377631, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 189.9718143939972, 'eval/sps': 673.7841632366101, 'num_steps': 0}
{'eval/walltime': 326.333945274353, 'training/sps': 406.38887451883784, 'training/walltime': 201.58032155036926, 'training/entropy_loss': Array(-0.00506623, dtype=float32), 'training/policy_loss': Array(-0.00839677, dtype=float32), 'training/total_loss': Array(-0.00167435, dtype=float32), 'training/v_loss': Array(0.01178865, dtype=float32), 'eval/episode_distance_from_origin': Array(3168.5627, dtype=float32), 'eval/episode_distance_reward': Array(0.69345206, dtype=float32), 'eval/episode_forward_reward': Array(115.57534, dtype=float32), 'eval/episode_reward': Array(-96.67026, dtype=float32), 'eval/episode_reward_alive': Array(3.5703125, dtype=float32), 'eval/episode_reward_linvel': Array(115.57534, dtype=float32), 'eval/episode_reward_quadctrl': Array(-216.50937, dtype=float32), 'eval/episode_x_position': Array(3146.5103, dtype=float32), 'eval/episode_x_velocity': Array(23.115068, dtype=float32), 'eval/episode_y_position': Array(8.035863, dtype=float32), 'eval/episode_y_velocity': Array(-0.08790153, dtype=float32), 'eval/episode_distance_from_origin_std': Array(56.759323, dtype=float32), 'eval/episode_distance_reward_std': Array(0.36376348, dtype=float32), 'eval/episode_forward_reward_std': Array(60.62725, dtype=float32), 'eval/episode_reward_std': Array(61.53671, dtype=float32), 'eval/episode_reward_alive_std': Array(5.6863785, dtype=float32), 'eval/episode_reward_linvel_std': Array(60.62725, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.6015704, dtype=float32), 'eval/episode_x_position_std': Array(57.556393, dtype=float32), 'eval/episode_x_velocity_std': Array(12.125451, dtype=float32), 'eval/episode_y_position_std': Array(108.24672, dtype=float32), 'eval/episode_y_velocity_std': Array(19.480907, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.36213088035583, 'eval/sps': 938.677029858878, 'num_steps': 81920}
{'eval/walltime': 462.8178503513336, 'training/sps': 509.44060027860803, 'training/walltime': 362.384152173996, 'training/entropy_loss': Array(-0.00498943, dtype=float32), 'training/policy_loss': Array(-0.0541669, dtype=float32), 'training/total_loss': Array(-0.04506525, dtype=float32), 'training/v_loss': Array(0.01409108, dtype=float32), 'eval/episode_distance_from_origin': Array(3228.2185, dtype=float32), 'eval/episode_distance_reward': Array(1.0103085, dtype=float32), 'eval/episode_forward_reward': Array(168.38477, dtype=float32), 'eval/episode_reward': Array(-37.201313, dtype=float32), 'eval/episode_reward_alive': Array(9.925781, dtype=float32), 'eval/episode_reward_linvel': Array(168.38477, dtype=float32), 'eval/episode_reward_quadctrl': Array(-216.52219, dtype=float32), 'eval/episode_x_position': Array(3207.2544, dtype=float32), 'eval/episode_x_velocity': Array(33.676952, dtype=float32), 'eval/episode_y_position': Array(-15.432281, dtype=float32), 'eval/episode_y_velocity': Array(-3.7667074, dtype=float32), 'eval/episode_distance_from_origin_std': Array(63.132057, dtype=float32), 'eval/episode_distance_reward_std': Array(0.35016158, dtype=float32), 'eval/episode_forward_reward_std': Array(58.360268, dtype=float32), 'eval/episode_reward_std': Array(62.264683, dtype=float32), 'eval/episode_reward_alive_std': Array(11.684673, dtype=float32), 'eval/episode_reward_linvel_std': Array(58.360268, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(3.9878726, dtype=float32), 'eval/episode_x_position_std': Array(63.26165, dtype=float32), 'eval/episode_x_velocity_std': Array(11.672054, dtype=float32), 'eval/episode_y_position_std': Array(86.37349, dtype=float32), 'eval/episode_y_velocity_std': Array(15.933057, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4839050769806, 'eval/sps': 937.8395198159413, 'num_steps': 163840}
{'eval/walltime': 599.1546244621277, 'training/sps': 508.14416016437826, 'training/walltime': 523.598245382309, 'training/entropy_loss': Array(-0.00477863, dtype=float32), 'training/policy_loss': Array(-0.04516975, dtype=float32), 'training/total_loss': Array(-0.04081134, dtype=float32), 'training/v_loss': Array(0.00913704, dtype=float32), 'eval/episode_distance_from_origin': Array(3251.605, dtype=float32), 'eval/episode_distance_reward': Array(1.153384, dtype=float32), 'eval/episode_forward_reward': Array(192.23068, dtype=float32), 'eval/episode_reward': Array(-7.035603, dtype=float32), 'eval/episode_reward_alive': Array(18.878906, dtype=float32), 'eval/episode_reward_linvel': Array(192.23068, dtype=float32), 'eval/episode_reward_quadctrl': Array(-219.29857, dtype=float32), 'eval/episode_x_position': Array(3230.4785, dtype=float32), 'eval/episode_x_velocity': Array(38.44613, dtype=float32), 'eval/episode_y_position': Array(-10.719793, dtype=float32), 'eval/episode_y_velocity': Array(-3.0836804, dtype=float32), 'eval/episode_distance_from_origin_std': Array(52.2189, dtype=float32), 'eval/episode_distance_reward_std': Array(0.29757494, dtype=float32), 'eval/episode_forward_reward_std': Array(49.595844, dtype=float32), 'eval/episode_reward_std': Array(54.5042, dtype=float32), 'eval/episode_reward_alive_std': Array(16.06575, dtype=float32), 'eval/episode_reward_linvel_std': Array(49.595844, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.804868, dtype=float32), 'eval/episode_x_position_std': Array(52.365807, dtype=float32), 'eval/episode_x_velocity_std': Array(9.919165, dtype=float32), 'eval/episode_y_position_std': Array(78.9844, dtype=float32), 'eval/episode_y_velocity_std': Array(14.725353, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33677411079407, 'eval/sps': 938.8516109085932, 'num_steps': 245760}
{'eval/walltime': 735.4238014221191, 'training/sps': 509.7322304430027, 'training/walltime': 684.3100762367249, 'training/entropy_loss': Array(-0.00455044, dtype=float32), 'training/policy_loss': Array(-0.02528274, dtype=float32), 'training/total_loss': Array(-0.02236966, dtype=float32), 'training/v_loss': Array(0.00746352, dtype=float32), 'eval/episode_distance_from_origin': Array(3273.5771, dtype=float32), 'eval/episode_distance_reward': Array(1.2611816, dtype=float32), 'eval/episode_forward_reward': Array(210.19696, dtype=float32), 'eval/episode_reward': Array(16.515831, dtype=float32), 'eval/episode_reward_alive': Array(26.054688, dtype=float32), 'eval/episode_reward_linvel': Array(210.19696, dtype=float32), 'eval/episode_reward_quadctrl': Array(-220.99698, dtype=float32), 'eval/episode_x_position': Array(3253.0933, dtype=float32), 'eval/episode_x_velocity': Array(42.03939, dtype=float32), 'eval/episode_y_position': Array(18.75365, dtype=float32), 'eval/episode_y_velocity': Array(1.7634149, dtype=float32), 'eval/episode_distance_from_origin_std': Array(44.64143, dtype=float32), 'eval/episode_distance_reward_std': Array(0.2497666, dtype=float32), 'eval/episode_forward_reward_std': Array(41.62776, dtype=float32), 'eval/episode_reward_std': Array(46.041252, dtype=float32), 'eval/episode_reward_alive_std': Array(12.9484005, dtype=float32), 'eval/episode_reward_linvel_std': Array(41.62776, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.1787033, dtype=float32), 'eval/episode_x_position_std': Array(44.844418, dtype=float32), 'eval/episode_x_velocity_std': Array(8.325553, dtype=float32), 'eval/episode_y_position_std': Array(64.43912, dtype=float32), 'eval/episode_y_velocity_std': Array(12.212731, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26917695999146, 'eval/sps': 939.3173339381123, 'num_steps': 327680}
{'eval/walltime': 871.5209715366364, 'training/sps': 510.799347750054, 'training/walltime': 844.6861619949341, 'training/entropy_loss': Array(-0.00435271, dtype=float32), 'training/policy_loss': Array(-0.03051282, dtype=float32), 'training/total_loss': Array(-0.03088977, dtype=float32), 'training/v_loss': Array(0.00397577, dtype=float32), 'eval/episode_distance_from_origin': Array(3266.7107, dtype=float32), 'eval/episode_distance_reward': Array(1.2248297, dtype=float32), 'eval/episode_forward_reward': Array(204.13828, dtype=float32), 'eval/episode_reward': Array(12.569764, dtype=float32), 'eval/episode_reward_alive': Array(29.730469, dtype=float32), 'eval/episode_reward_linvel': Array(204.13828, dtype=float32), 'eval/episode_reward_quadctrl': Array(-222.52382, dtype=float32), 'eval/episode_x_position': Array(3246.5686, dtype=float32), 'eval/episode_x_velocity': Array(40.82766, dtype=float32), 'eval/episode_y_position': Array(10.909193, dtype=float32), 'eval/episode_y_velocity': Array(0.27956372, dtype=float32), 'eval/episode_distance_from_origin_std': Array(40.422413, dtype=float32), 'eval/episode_distance_reward_std': Array(0.23498423, dtype=float32), 'eval/episode_forward_reward_std': Array(39.16406, dtype=float32), 'eval/episode_reward_std': Array(39.47487, dtype=float32), 'eval/episode_reward_alive_std': Array(8.613194, dtype=float32), 'eval/episode_reward_linvel_std': Array(39.16406, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(2.8389735, dtype=float32), 'eval/episode_x_position_std': Array(40.72029, dtype=float32), 'eval/episode_x_velocity_std': Array(7.8328123, dtype=float32), 'eval/episode_y_position_std': Array(65.9237, dtype=float32), 'eval/episode_y_velocity_std': Array(12.103838, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.0971701145172, 'eval/sps': 940.5044931668751, 'num_steps': 409600}
{'eval/walltime': 1007.7819283008575, 'training/sps': 508.7780988633946, 'training/walltime': 1005.6993820667267, 'training/entropy_loss': Array(-0.00405189, dtype=float32), 'training/policy_loss': Array(-0.02057345, dtype=float32), 'training/total_loss': Array(-0.01975009, dtype=float32), 'training/v_loss': Array(0.00487525, dtype=float32), 'eval/episode_distance_from_origin': Array(3271.486, dtype=float32), 'eval/episode_distance_reward': Array(1.2573842, dtype=float32), 'eval/episode_forward_reward': Array(209.564, dtype=float32), 'eval/episode_reward': Array(25.793268, dtype=float32), 'eval/episode_reward_alive': Array(42.679688, dtype=float32), 'eval/episode_reward_linvel': Array(209.564, dtype=float32), 'eval/episode_reward_quadctrl': Array(-227.70782, dtype=float32), 'eval/episode_x_position': Array(3249.4138, dtype=float32), 'eval/episode_x_velocity': Array(41.912796, dtype=float32), 'eval/episode_y_position': Array(22.35237, dtype=float32), 'eval/episode_y_velocity': Array(2.0169282, dtype=float32), 'eval/episode_distance_from_origin_std': Array(44.14398, dtype=float32), 'eval/episode_distance_reward_std': Array(0.2620101, dtype=float32), 'eval/episode_forward_reward_std': Array(43.668358, dtype=float32), 'eval/episode_reward_std': Array(64.88734, dtype=float32), 'eval/episode_reward_alive_std': Array(48.68853, dtype=float32), 'eval/episode_reward_linvel_std': Array(43.668358, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.718451, dtype=float32), 'eval/episode_x_position_std': Array(44.199257, dtype=float32), 'eval/episode_x_velocity_std': Array(8.733667, dtype=float32), 'eval/episode_y_position_std': Array(80.1455, dtype=float32), 'eval/episode_y_velocity_std': Array(15.040771, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2609567642212, 'eval/sps': 939.3740000041573, 'num_steps': 491520}
{'eval/walltime': 1144.0788042545319, 'training/sps': 510.0307441184491, 'training/walltime': 1166.317150592804, 'training/entropy_loss': Array(-0.0038919, dtype=float32), 'training/policy_loss': Array(-0.01970825, dtype=float32), 'training/total_loss': Array(-0.01932023, dtype=float32), 'training/v_loss': Array(0.00427993, dtype=float32), 'eval/episode_distance_from_origin': Array(3279.8794, dtype=float32), 'eval/episode_distance_reward': Array(1.3236041, dtype=float32), 'eval/episode_forward_reward': Array(220.6007, dtype=float32), 'eval/episode_reward': Array(209.8678, dtype=float32), 'eval/episode_reward_alive': Array(246.51172, dtype=float32), 'eval/episode_reward_linvel': Array(220.6007, dtype=float32), 'eval/episode_reward_quadctrl': Array(-258.56818, dtype=float32), 'eval/episode_x_position': Array(3245.7004, dtype=float32), 'eval/episode_x_velocity': Array(44.12014, dtype=float32), 'eval/episode_y_position': Array(43.59285, dtype=float32), 'eval/episode_y_velocity': Array(15.138994, dtype=float32), 'eval/episode_distance_from_origin_std': Array(45.721943, dtype=float32), 'eval/episode_distance_reward_std': Array(0.3619123, dtype=float32), 'eval/episode_forward_reward_std': Array(60.318737, dtype=float32), 'eval/episode_reward_std': Array(100.30987, dtype=float32), 'eval/episode_reward_alive_std': Array(88.05096, dtype=float32), 'eval/episode_reward_linvel_std': Array(60.318737, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.500662, dtype=float32), 'eval/episode_x_position_std': Array(46.503426, dtype=float32), 'eval/episode_x_velocity_std': Array(12.063748, dtype=float32), 'eval/episode_y_position_std': Array(77.73192, dtype=float32), 'eval/episode_y_velocity_std': Array(21.380665, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29687595367432, 'eval/sps': 939.126440752066, 'num_steps': 573440}
{'eval/walltime': 1280.3853948116302, 'training/sps': 510.26685169554855, 'training/walltime': 1326.860599040985, 'training/entropy_loss': Array(-0.0030109, dtype=float32), 'training/policy_loss': Array(0.01952446, dtype=float32), 'training/total_loss': Array(0.02806308, dtype=float32), 'training/v_loss': Array(0.01154952, dtype=float32), 'eval/episode_distance_from_origin': Array(3329.7893, dtype=float32), 'eval/episode_distance_reward': Array(1.6974213, dtype=float32), 'eval/episode_forward_reward': Array(282.90356, dtype=float32), 'eval/episode_reward': Array(299.46954, dtype=float32), 'eval/episode_reward_alive': Array(278.11328, dtype=float32), 'eval/episode_reward_linvel': Array(282.90356, dtype=float32), 'eval/episode_reward_quadctrl': Array(-263.24472, dtype=float32), 'eval/episode_x_position': Array(3295.7673, dtype=float32), 'eval/episode_x_velocity': Array(56.580715, dtype=float32), 'eval/episode_y_position': Array(38.65518, dtype=float32), 'eval/episode_y_velocity': Array(6.7880354, dtype=float32), 'eval/episode_distance_from_origin_std': Array(45.95596, dtype=float32), 'eval/episode_distance_reward_std': Array(0.34074458, dtype=float32), 'eval/episode_forward_reward_std': Array(56.79071, dtype=float32), 'eval/episode_reward_std': Array(94.38071, dtype=float32), 'eval/episode_reward_alive_std': Array(77.201195, dtype=float32), 'eval/episode_reward_linvel_std': Array(56.79071, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.2338614, dtype=float32), 'eval/episode_x_position_std': Array(46.14871, dtype=float32), 'eval/episode_x_velocity_std': Array(11.358158, dtype=float32), 'eval/episode_y_position_std': Array(69.7233, dtype=float32), 'eval/episode_y_velocity_std': Array(17.099777, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3065905570984, 'eval/sps': 939.0595089852329, 'num_steps': 655360}
{'eval/walltime': 1416.5317096710205, 'training/sps': 509.62850751988174, 'training/walltime': 1487.605139017105, 'training/entropy_loss': Array(-0.00272813, dtype=float32), 'training/policy_loss': Array(-0.00397468, dtype=float32), 'training/total_loss': Array(0.00214381, dtype=float32), 'training/v_loss': Array(0.00884661, dtype=float32), 'eval/episode_distance_from_origin': Array(3341.359, dtype=float32), 'eval/episode_distance_reward': Array(1.8153664, dtype=float32), 'eval/episode_forward_reward': Array(302.56107, dtype=float32), 'eval/episode_reward': Array(340.03668, dtype=float32), 'eval/episode_reward_alive': Array(300.6211, dtype=float32), 'eval/episode_reward_linvel': Array(302.56107, dtype=float32), 'eval/episode_reward_quadctrl': Array(-264.96085, dtype=float32), 'eval/episode_x_position': Array(3307.394, dtype=float32), 'eval/episode_x_velocity': Array(60.51221, dtype=float32), 'eval/episode_y_position': Array(36.19185, dtype=float32), 'eval/episode_y_velocity': Array(-0.06809539, dtype=float32), 'eval/episode_distance_from_origin_std': Array(45.76274, dtype=float32), 'eval/episode_distance_reward_std': Array(0.34203836, dtype=float32), 'eval/episode_forward_reward_std': Array(57.006386, dtype=float32), 'eval/episode_reward_std': Array(90.56421, dtype=float32), 'eval/episode_reward_alive_std': Array(68.67177, dtype=float32), 'eval/episode_reward_linvel_std': Array(57.006386, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.3790765, dtype=float32), 'eval/episode_x_position_std': Array(45.97282, dtype=float32), 'eval/episode_x_velocity_std': Array(11.401279, dtype=float32), 'eval/episode_y_position_std': Array(72.40562, dtype=float32), 'eval/episode_y_velocity_std': Array(14.94154, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.14631485939026, 'eval/sps': 940.1649991936716, 'num_steps': 737280}
{'eval/walltime': 1553.0575461387634, 'training/sps': 508.9307189084769, 'training/walltime': 1648.5700738430023, 'training/entropy_loss': Array(-0.00243378, dtype=float32), 'training/policy_loss': Array(-0.01358185, dtype=float32), 'training/total_loss': Array(-0.00826271, dtype=float32), 'training/v_loss': Array(0.00775293, dtype=float32), 'eval/episode_distance_from_origin': Array(3387.2764, dtype=float32), 'eval/episode_distance_reward': Array(2.2835126, dtype=float32), 'eval/episode_forward_reward': Array(380.5855, dtype=float32), 'eval/episode_reward': Array(416.75092, dtype=float32), 'eval/episode_reward_alive': Array(303.4961, dtype=float32), 'eval/episode_reward_linvel': Array(380.5855, dtype=float32), 'eval/episode_reward_quadctrl': Array(-269.61414, dtype=float32), 'eval/episode_x_position': Array(3353.4053, dtype=float32), 'eval/episode_x_velocity': Array(76.1171, dtype=float32), 'eval/episode_y_position': Array(42.078007, dtype=float32), 'eval/episode_y_velocity': Array(0.05949438, dtype=float32), 'eval/episode_distance_from_origin_std': Array(45.896755, dtype=float32), 'eval/episode_distance_reward_std': Array(0.40488315, dtype=float32), 'eval/episode_forward_reward_std': Array(67.480515, dtype=float32), 'eval/episode_reward_std': Array(81.07357, dtype=float32), 'eval/episode_reward_alive_std': Array(48.685272, dtype=float32), 'eval/episode_reward_linvel_std': Array(67.480515, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.344229, dtype=float32), 'eval/episode_x_position_std': Array(46.399784, dtype=float32), 'eval/episode_x_velocity_std': Array(13.496104, dtype=float32), 'eval/episode_y_position_std': Array(69.36044, dtype=float32), 'eval/episode_y_velocity_std': Array(19.171085, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.52583646774292, 'eval/sps': 937.5514797174868, 'num_steps': 819200}
{'eval/walltime': 1689.4094927310944, 'training/sps': 510.86793676916204, 'training/walltime': 1808.9246275424957, 'training/entropy_loss': Array(-0.00201643, dtype=float32), 'training/policy_loss': Array(-0.00730606, dtype=float32), 'training/total_loss': Array(0.00162239, dtype=float32), 'training/v_loss': Array(0.01094489, dtype=float32), 'eval/episode_distance_from_origin': Array(3438.5996, dtype=float32), 'eval/episode_distance_reward': Array(2.6568062, dtype=float32), 'eval/episode_forward_reward': Array(442.80103, dtype=float32), 'eval/episode_reward': Array(428.18445, dtype=float32), 'eval/episode_reward_alive': Array(253.82812, dtype=float32), 'eval/episode_reward_linvel': Array(442.80103, dtype=float32), 'eval/episode_reward_quadctrl': Array(-271.1016, dtype=float32), 'eval/episode_x_position': Array(3405.8655, dtype=float32), 'eval/episode_x_velocity': Array(88.56021, dtype=float32), 'eval/episode_y_position': Array(-35.12236, dtype=float32), 'eval/episode_y_velocity': Array(-19.6667, dtype=float32), 'eval/episode_distance_from_origin_std': Array(55.014763, dtype=float32), 'eval/episode_distance_reward_std': Array(0.47785524, dtype=float32), 'eval/episode_forward_reward_std': Array(79.64252, dtype=float32), 'eval/episode_reward_std': Array(88.24105, dtype=float32), 'eval/episode_reward_alive_std': Array(35.803032, dtype=float32), 'eval/episode_reward_linvel_std': Array(79.64252, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.1906376, dtype=float32), 'eval/episode_x_position_std': Array(55.317818, dtype=float32), 'eval/episode_x_velocity_std': Array(15.928517, dtype=float32), 'eval/episode_y_position_std': Array(82.25894, dtype=float32), 'eval/episode_y_velocity_std': Array(19.026398, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.35194659233093, 'eval/sps': 938.7471407555198, 'num_steps': 901120}
{'eval/walltime': 1826.026912689209, 'training/sps': 510.9234817606147, 'training/walltime': 1969.2617483139038, 'training/entropy_loss': Array(-0.00165654, dtype=float32), 'training/policy_loss': Array(-0.00389561, dtype=float32), 'training/total_loss': Array(0.01333443, dtype=float32), 'training/v_loss': Array(0.01888658, dtype=float32), 'eval/episode_distance_from_origin': Array(3454.2085, dtype=float32), 'eval/episode_distance_reward': Array(2.8258185, dtype=float32), 'eval/episode_forward_reward': Array(470.96976, dtype=float32), 'eval/episode_reward': Array(415.42627, dtype=float32), 'eval/episode_reward_alive': Array(206.97266, dtype=float32), 'eval/episode_reward_linvel': Array(470.96976, dtype=float32), 'eval/episode_reward_quadctrl': Array(-265.34195, dtype=float32), 'eval/episode_x_position': Array(3421.9624, dtype=float32), 'eval/episode_x_velocity': Array(94.193954, dtype=float32), 'eval/episode_y_position': Array(-71.006516, dtype=float32), 'eval/episode_y_velocity': Array(-30.659195, dtype=float32), 'eval/episode_distance_from_origin_std': Array(58.171375, dtype=float32), 'eval/episode_distance_reward_std': Array(0.47696516, dtype=float32), 'eval/episode_forward_reward_std': Array(79.49416, dtype=float32), 'eval/episode_reward_std': Array(88.154396, dtype=float32), 'eval/episode_reward_alive_std': Array(27.870607, dtype=float32), 'eval/episode_reward_linvel_std': Array(79.49416, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.980277, dtype=float32), 'eval/episode_x_position_std': Array(58.101284, dtype=float32), 'eval/episode_x_velocity_std': Array(15.898833, dtype=float32), 'eval/episode_y_position_std': Array(79.085915, dtype=float32), 'eval/episode_y_velocity_std': Array(17.60658, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.61741995811462, 'eval/sps': 936.9229783379262, 'num_steps': 983040}
{'eval/walltime': 1962.2634439468384, 'training/sps': 508.2540429491072, 'training/walltime': 2130.440987586975, 'training/entropy_loss': Array(-0.00164816, dtype=float32), 'training/policy_loss': Array(-0.00832584, dtype=float32), 'training/total_loss': Array(0.0063952, dtype=float32), 'training/v_loss': Array(0.01636919, dtype=float32), 'eval/episode_distance_from_origin': Array(3499.0146, dtype=float32), 'eval/episode_distance_reward': Array(3.2711468, dtype=float32), 'eval/episode_forward_reward': Array(545.19104, dtype=float32), 'eval/episode_reward': Array(478.82208, dtype=float32), 'eval/episode_reward_alive': Array(195.82422, dtype=float32), 'eval/episode_reward_linvel': Array(545.19104, dtype=float32), 'eval/episode_reward_quadctrl': Array(-265.46448, dtype=float32), 'eval/episode_x_position': Array(3467.1272, dtype=float32), 'eval/episode_x_velocity': Array(109.03823, dtype=float32), 'eval/episode_y_position': Array(-87.6974, dtype=float32), 'eval/episode_y_velocity': Array(-37.088573, dtype=float32), 'eval/episode_distance_from_origin_std': Array(55.638103, dtype=float32), 'eval/episode_distance_reward_std': Array(0.4396085, dtype=float32), 'eval/episode_forward_reward_std': Array(73.268074, dtype=float32), 'eval/episode_reward_std': Array(73.42701, dtype=float32), 'eval/episode_reward_alive_std': Array(17.608656, dtype=float32), 'eval/episode_reward_linvel_std': Array(73.268074, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.814427, dtype=float32), 'eval/episode_x_position_std': Array(55.690163, dtype=float32), 'eval/episode_x_velocity_std': Array(14.65362, dtype=float32), 'eval/episode_y_position_std': Array(74.098946, dtype=float32), 'eval/episode_y_velocity_std': Array(18.167501, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2365312576294, 'eval/sps': 939.5424180166938, 'num_steps': 1064960}
{'eval/walltime': 2098.21368598938, 'training/sps': 509.854079704828, 'training/walltime': 2291.114410161972, 'training/entropy_loss': Array(-0.00138882, dtype=float32), 'training/policy_loss': Array(-0.00529449, dtype=float32), 'training/total_loss': Array(0.00731859, dtype=float32), 'training/v_loss': Array(0.0140019, dtype=float32), 'eval/episode_distance_from_origin': Array(3510.6287, dtype=float32), 'eval/episode_distance_reward': Array(3.3717778, dtype=float32), 'eval/episode_forward_reward': Array(561.9629, dtype=float32), 'eval/episode_reward': Array(505.9633, dtype=float32), 'eval/episode_reward_alive': Array(207.32031, dtype=float32), 'eval/episode_reward_linvel': Array(561.9629, dtype=float32), 'eval/episode_reward_quadctrl': Array(-266.6917, dtype=float32), 'eval/episode_x_position': Array(3478.3022, dtype=float32), 'eval/episode_x_velocity': Array(112.39258, dtype=float32), 'eval/episode_y_position': Array(-76.78799, dtype=float32), 'eval/episode_y_velocity': Array(-36.08808, dtype=float32), 'eval/episode_distance_from_origin_std': Array(54.35408, dtype=float32), 'eval/episode_distance_reward_std': Array(0.46788657, dtype=float32), 'eval/episode_forward_reward_std': Array(77.98108, dtype=float32), 'eval/episode_reward_std': Array(78.13407, dtype=float32), 'eval/episode_reward_alive_std': Array(19.510788, dtype=float32), 'eval/episode_reward_linvel_std': Array(77.98108, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.119905, dtype=float32), 'eval/episode_x_position_std': Array(54.201744, dtype=float32), 'eval/episode_x_velocity_std': Array(15.596214, dtype=float32), 'eval/episode_y_position_std': Array(78.64273, dtype=float32), 'eval/episode_y_velocity_std': Array(20.932384, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 135.9502420425415, 'eval/sps': 941.5209423455552, 'num_steps': 1146880}
{'eval/walltime': 2234.3443043231964, 'training/sps': 511.7604088004253, 'training/walltime': 2451.1893174648285, 'training/entropy_loss': Array(-0.00122858, dtype=float32), 'training/policy_loss': Array(-0.010879, dtype=float32), 'training/total_loss': Array(0.00091923, dtype=float32), 'training/v_loss': Array(0.01302681, dtype=float32), 'eval/episode_distance_from_origin': Array(3570.3003, dtype=float32), 'eval/episode_distance_reward': Array(3.9654984, dtype=float32), 'eval/episode_forward_reward': Array(660.916, dtype=float32), 'eval/episode_reward': Array(602.1739, dtype=float32), 'eval/episode_reward_alive': Array(203.72266, dtype=float32), 'eval/episode_reward_linvel': Array(660.916, dtype=float32), 'eval/episode_reward_quadctrl': Array(-266.4303, dtype=float32), 'eval/episode_x_position': Array(3536.5586, dtype=float32), 'eval/episode_x_velocity': Array(132.1832, dtype=float32), 'eval/episode_y_position': Array(-108.6883, dtype=float32), 'eval/episode_y_velocity': Array(-49.14412, dtype=float32), 'eval/episode_distance_from_origin_std': Array(54.276672, dtype=float32), 'eval/episode_distance_reward_std': Array(0.48329777, dtype=float32), 'eval/episode_forward_reward_std': Array(80.54915, dtype=float32), 'eval/episode_reward_std': Array(82.39005, dtype=float32), 'eval/episode_reward_alive_std': Array(19.615126, dtype=float32), 'eval/episode_reward_linvel_std': Array(80.54915, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.071537, dtype=float32), 'eval/episode_x_position_std': Array(54.22943, dtype=float32), 'eval/episode_x_velocity_std': Array(16.109823, dtype=float32), 'eval/episode_y_position_std': Array(94.594246, dtype=float32), 'eval/episode_y_velocity_std': Array(26.027225, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.13061833381653, 'eval/sps': 940.2734048127306, 'num_steps': 1228800}
{'eval/walltime': 2370.561648130417, 'training/sps': 509.5784363568949, 'training/walltime': 2611.949652194977, 'training/entropy_loss': Array(-0.00101994, dtype=float32), 'training/policy_loss': Array(-0.00857526, dtype=float32), 'training/total_loss': Array(0.0040117, dtype=float32), 'training/v_loss': Array(0.0136069, dtype=float32), 'eval/episode_distance_from_origin': Array(3607.629, dtype=float32), 'eval/episode_distance_reward': Array(4.3494024, dtype=float32), 'eval/episode_forward_reward': Array(724.8998, dtype=float32), 'eval/episode_reward': Array(662.1218, dtype=float32), 'eval/episode_reward_alive': Array(197.17578, dtype=float32), 'eval/episode_reward_linvel': Array(724.8998, dtype=float32), 'eval/episode_reward_quadctrl': Array(-264.30316, dtype=float32), 'eval/episode_x_position': Array(3572.5762, dtype=float32), 'eval/episode_x_velocity': Array(144.97995, dtype=float32), 'eval/episode_y_position': Array(-137.27148, dtype=float32), 'eval/episode_y_velocity': Array(-64.355484, dtype=float32), 'eval/episode_distance_from_origin_std': Array(55.907215, dtype=float32), 'eval/episode_distance_reward_std': Array(0.52166206, dtype=float32), 'eval/episode_forward_reward_std': Array(86.94304, dtype=float32), 'eval/episode_reward_std': Array(89.57817, dtype=float32), 'eval/episode_reward_alive_std': Array(16.349167, dtype=float32), 'eval/episode_reward_linvel_std': Array(86.94304, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.5308595, dtype=float32), 'eval/episode_x_position_std': Array(54.843838, dtype=float32), 'eval/episode_x_velocity_std': Array(17.388618, dtype=float32), 'eval/episode_y_position_std': Array(80.180984, dtype=float32), 'eval/episode_y_velocity_std': Array(22.219604, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21734380722046, 'eval/sps': 939.6747611020082, 'num_steps': 1310720}
{'eval/walltime': 2506.5405242443085, 'training/sps': 510.9846689913741, 'training/walltime': 2772.267573595047, 'training/entropy_loss': Array(-0.0009315, dtype=float32), 'training/policy_loss': Array(-0.01208362, dtype=float32), 'training/total_loss': Array(0.00233019, dtype=float32), 'training/v_loss': Array(0.01534531, dtype=float32), 'eval/episode_distance_from_origin': Array(3686.65, dtype=float32), 'eval/episode_distance_reward': Array(5.2179155, dtype=float32), 'eval/episode_forward_reward': Array(869.651, dtype=float32), 'eval/episode_reward': Array(813.1212, dtype=float32), 'eval/episode_reward_alive': Array(199.07812, dtype=float32), 'eval/episode_reward_linvel': Array(869.651, dtype=float32), 'eval/episode_reward_quadctrl': Array(-260.8258, dtype=float32), 'eval/episode_x_position': Array(3648.4165, dtype=float32), 'eval/episode_x_velocity': Array(173.93019, dtype=float32), 'eval/episode_y_position': Array(-190.10432, dtype=float32), 'eval/episode_y_velocity': Array(-78.522354, dtype=float32), 'eval/episode_distance_from_origin_std': Array(62.707947, dtype=float32), 'eval/episode_distance_reward_std': Array(0.5767247, dtype=float32), 'eval/episode_forward_reward_std': Array(96.12024, dtype=float32), 'eval/episode_reward_std': Array(95.71344, dtype=float32), 'eval/episode_reward_alive_std': Array(22.175035, dtype=float32), 'eval/episode_reward_linvel_std': Array(96.12024, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(6.1872964, dtype=float32), 'eval/episode_x_position_std': Array(62.397522, dtype=float32), 'eval/episode_x_velocity_std': Array(19.224072, dtype=float32), 'eval/episode_y_position_std': Array(90.84087, dtype=float32), 'eval/episode_y_velocity_std': Array(28.486027, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 135.9788761138916, 'eval/sps': 941.3226793608094, 'num_steps': 1392640}
{'eval/walltime': 2642.709614276886, 'training/sps': 511.350726740282, 'training/walltime': 2932.470729112625, 'training/entropy_loss': Array(-0.00102625, dtype=float32), 'training/policy_loss': Array(-0.01365651, dtype=float32), 'training/total_loss': Array(0.00084787, dtype=float32), 'training/v_loss': Array(0.01553063, dtype=float32), 'eval/episode_distance_from_origin': Array(3782.2153, dtype=float32), 'eval/episode_distance_reward': Array(6.14773, dtype=float32), 'eval/episode_forward_reward': Array(1024.6198, dtype=float32), 'eval/episode_reward': Array(971.75476, dtype=float32), 'eval/episode_reward_alive': Array(203.15625, dtype=float32), 'eval/episode_reward_linvel': Array(1024.6198, dtype=float32), 'eval/episode_reward_quadctrl': Array(-262.169, dtype=float32), 'eval/episode_x_position': Array(3747.3545, dtype=float32), 'eval/episode_x_velocity': Array(204.92397, dtype=float32), 'eval/episode_y_position': Array(-149.95827, dtype=float32), 'eval/episode_y_velocity': Array(-48.20762, dtype=float32), 'eval/episode_distance_from_origin_std': Array(59.837402, dtype=float32), 'eval/episode_distance_reward_std': Array(0.6983232, dtype=float32), 'eval/episode_forward_reward_std': Array(116.38697, dtype=float32), 'eval/episode_reward_std': Array(122.67083, dtype=float32), 'eval/episode_reward_alive_std': Array(23.666527, dtype=float32), 'eval/episode_reward_linvel_std': Array(116.38697, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(12.782336, dtype=float32), 'eval/episode_x_position_std': Array(60.82955, dtype=float32), 'eval/episode_x_velocity_std': Array(23.2774, dtype=float32), 'eval/episode_y_position_std': Array(96.89124, dtype=float32), 'eval/episode_y_velocity_std': Array(44.150566, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.16909003257751, 'eval/sps': 940.0077504327662, 'num_steps': 1474560}
{'eval/walltime': 2779.09587597847, 'training/sps': 511.90411341984077, 'training/walltime': 3092.5006992816925, 'training/entropy_loss': Array(-0.00065655, dtype=float32), 'training/policy_loss': Array(-0.00254034, dtype=float32), 'training/total_loss': Array(0.01449203, dtype=float32), 'training/v_loss': Array(0.01768893, dtype=float32), 'eval/episode_distance_from_origin': Array(3820.8115, dtype=float32), 'eval/episode_distance_reward': Array(6.114017, dtype=float32), 'eval/episode_forward_reward': Array(1019.0012, dtype=float32), 'eval/episode_reward': Array(941.2391, dtype=float32), 'eval/episode_reward_alive': Array(190.35547, dtype=float32), 'eval/episode_reward_linvel': Array(1019.0012, dtype=float32), 'eval/episode_reward_quadctrl': Array(-274.23172, dtype=float32), 'eval/episode_x_position': Array(3788.552, dtype=float32), 'eval/episode_x_velocity': Array(203.80026, dtype=float32), 'eval/episode_y_position': Array(-96.43536, dtype=float32), 'eval/episode_y_velocity': Array(-20.98507, dtype=float32), 'eval/episode_distance_from_origin_std': Array(69.47559, dtype=float32), 'eval/episode_distance_reward_std': Array(1.041086, dtype=float32), 'eval/episode_forward_reward_std': Array(173.51369, dtype=float32), 'eval/episode_reward_std': Array(201.23752, dtype=float32), 'eval/episode_reward_alive_std': Array(41.68966, dtype=float32), 'eval/episode_reward_linvel_std': Array(173.51369, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.467821, dtype=float32), 'eval/episode_x_position_std': Array(69.482864, dtype=float32), 'eval/episode_x_velocity_std': Array(34.702744, dtype=float32), 'eval/episode_y_position_std': Array(112.182274, dtype=float32), 'eval/episode_y_velocity_std': Array(48.169067, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.38626170158386, 'eval/sps': 938.5109497323624, 'num_steps': 1556480}
{'eval/walltime': 2915.1432750225067, 'training/sps': 512.0457705402931, 'training/walltime': 3252.486397266388, 'training/entropy_loss': Array(-0.00037178, dtype=float32), 'training/policy_loss': Array(0.04268506, dtype=float32), 'training/total_loss': Array(0.06528043, dtype=float32), 'training/v_loss': Array(0.02296715, dtype=float32), 'eval/episode_distance_from_origin': Array(3849.9604, dtype=float32), 'eval/episode_distance_reward': Array(6.3373337, dtype=float32), 'eval/episode_forward_reward': Array(1056.2207, dtype=float32), 'eval/episode_reward': Array(984.43066, dtype=float32), 'eval/episode_reward_alive': Array(187.71875, dtype=float32), 'eval/episode_reward_linvel': Array(1056.2207, dtype=float32), 'eval/episode_reward_quadctrl': Array(-265.84607, dtype=float32), 'eval/episode_x_position': Array(3818.2876, dtype=float32), 'eval/episode_x_velocity': Array(211.24411, dtype=float32), 'eval/episode_y_position': Array(-94.23752, dtype=float32), 'eval/episode_y_velocity': Array(-11.892613, dtype=float32), 'eval/episode_distance_from_origin_std': Array(77.48478, dtype=float32), 'eval/episode_distance_reward_std': Array(1.0758617, dtype=float32), 'eval/episode_forward_reward_std': Array(179.30954, dtype=float32), 'eval/episode_reward_std': Array(192.55101, dtype=float32), 'eval/episode_reward_alive_std': Array(40.768436, dtype=float32), 'eval/episode_reward_linvel_std': Array(179.30954, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(19.823193, dtype=float32), 'eval/episode_x_position_std': Array(77.61216, dtype=float32), 'eval/episode_x_velocity_std': Array(35.86192, dtype=float32), 'eval/episode_y_position_std': Array(110.99569, dtype=float32), 'eval/episode_y_velocity_std': Array(49.233837, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.04739904403687, 'eval/sps': 940.8485638050896, 'num_steps': 1638400}
{'eval/walltime': 3051.0156633853912, 'training/sps': 512.2935245015011, 'training/walltime': 3412.3947234153748, 'training/entropy_loss': Array(-0.00014201, dtype=float32), 'training/policy_loss': Array(0.00074638, dtype=float32), 'training/total_loss': Array(0.02059567, dtype=float32), 'training/v_loss': Array(0.0199913, dtype=float32), 'eval/episode_distance_from_origin': Array(3891.3713, dtype=float32), 'eval/episode_distance_reward': Array(6.520468, dtype=float32), 'eval/episode_forward_reward': Array(1086.7429, dtype=float32), 'eval/episode_reward': Array(1018.73645, dtype=float32), 'eval/episode_reward_alive': Array(200.2461, dtype=float32), 'eval/episode_reward_linvel': Array(1086.7429, dtype=float32), 'eval/episode_reward_quadctrl': Array(-274.77304, dtype=float32), 'eval/episode_x_position': Array(3860.4302, dtype=float32), 'eval/episode_x_velocity': Array(217.34859, dtype=float32), 'eval/episode_y_position': Array(-33.55918, dtype=float32), 'eval/episode_y_velocity': Array(16.472067, dtype=float32), 'eval/episode_distance_from_origin_std': Array(68.356026, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1197038, dtype=float32), 'eval/episode_forward_reward_std': Array(186.61668, dtype=float32), 'eval/episode_reward_std': Array(197.88057, dtype=float32), 'eval/episode_reward_alive_std': Array(45.543934, dtype=float32), 'eval/episode_reward_linvel_std': Array(186.61668, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.052101, dtype=float32), 'eval/episode_x_position_std': Array(68.89794, dtype=float32), 'eval/episode_x_velocity_std': Array(37.32335, dtype=float32), 'eval/episode_y_position_std': Array(120.5699, dtype=float32), 'eval/episode_y_velocity_std': Array(49.505188, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 135.87238836288452, 'eval/sps': 942.060425537975, 'num_steps': 1720320}
{'eval/walltime': 3186.935924768448, 'training/sps': 512.1493561477118, 'training/walltime': 3572.3480632305145, 'training/entropy_loss': Array(0.0003648, dtype=float32), 'training/policy_loss': Array(0.01060394, dtype=float32), 'training/total_loss': Array(0.03081897, dtype=float32), 'training/v_loss': Array(0.01985022, dtype=float32), 'eval/episode_distance_from_origin': Array(3919.3965, dtype=float32), 'eval/episode_distance_reward': Array(6.7096987, dtype=float32), 'eval/episode_forward_reward': Array(1118.2815, dtype=float32), 'eval/episode_reward': Array(1053.3723, dtype=float32), 'eval/episode_reward_alive': Array(210.6836, dtype=float32), 'eval/episode_reward_linvel': Array(1118.2815, dtype=float32), 'eval/episode_reward_quadctrl': Array(-282.30252, dtype=float32), 'eval/episode_x_position': Array(3888.1758, dtype=float32), 'eval/episode_x_velocity': Array(223.65628, dtype=float32), 'eval/episode_y_position': Array(-48.79286, dtype=float32), 'eval/episode_y_velocity': Array(8.884762, dtype=float32), 'eval/episode_distance_from_origin_std': Array(69.99118, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1364253, dtype=float32), 'eval/episode_forward_reward_std': Array(189.40321, dtype=float32), 'eval/episode_reward_std': Array(194.58705, dtype=float32), 'eval/episode_reward_alive_std': Array(45.995026, dtype=float32), 'eval/episode_reward_linvel_std': Array(189.40321, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.177807, dtype=float32), 'eval/episode_x_position_std': Array(69.66803, dtype=float32), 'eval/episode_x_velocity_std': Array(37.880653, dtype=float32), 'eval/episode_y_position_std': Array(123.73447, dtype=float32), 'eval/episode_y_velocity_std': Array(54.50602, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 135.92026138305664, 'eval/sps': 941.728618658734, 'num_steps': 1802240}
{'eval/walltime': 3323.0421538352966, 'training/sps': 512.186193632502, 'training/walltime': 3732.2898988723755, 'training/entropy_loss': Array(0.00123054, dtype=float32), 'training/policy_loss': Array(0.02866545, dtype=float32), 'training/total_loss': Array(0.05190024, dtype=float32), 'training/v_loss': Array(0.02200424, dtype=float32), 'eval/episode_distance_from_origin': Array(3936.5781, dtype=float32), 'eval/episode_distance_reward': Array(7.3622494, dtype=float32), 'eval/episode_forward_reward': Array(1227.0393, dtype=float32), 'eval/episode_reward': Array(1153.6973, dtype=float32), 'eval/episode_reward_alive': Array(199.5664, dtype=float32), 'eval/episode_reward_linvel': Array(1227.0393, dtype=float32), 'eval/episode_reward_quadctrl': Array(-280.2708, dtype=float32), 'eval/episode_x_position': Array(3899.608, dtype=float32), 'eval/episode_x_velocity': Array(245.40787, dtype=float32), 'eval/episode_y_position': Array(-194.51254, dtype=float32), 'eval/episode_y_velocity': Array(-47.306683, dtype=float32), 'eval/episode_distance_from_origin_std': Array(52.760193, dtype=float32), 'eval/episode_distance_reward_std': Array(0.95386726, dtype=float32), 'eval/episode_forward_reward_std': Array(158.97743, dtype=float32), 'eval/episode_reward_std': Array(173.16632, dtype=float32), 'eval/episode_reward_alive_std': Array(32.105194, dtype=float32), 'eval/episode_reward_linvel_std': Array(158.97743, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(26.752127, dtype=float32), 'eval/episode_x_position_std': Array(53.00411, dtype=float32), 'eval/episode_x_velocity_std': Array(31.795464, dtype=float32), 'eval/episode_y_position_std': Array(121.73619, dtype=float32), 'eval/episode_y_velocity_std': Array(59.1398, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.10622906684875, 'eval/sps': 940.4418951107126, 'num_steps': 1884160}
{'eval/walltime': 3459.1099305152893, 'training/sps': 512.5397652141875, 'training/walltime': 3892.1213998794556, 'training/entropy_loss': Array(0.00145869, dtype=float32), 'training/policy_loss': Array(0.01312658, dtype=float32), 'training/total_loss': Array(0.03285424, dtype=float32), 'training/v_loss': Array(0.01826897, dtype=float32), 'eval/episode_distance_from_origin': Array(3985.5679, dtype=float32), 'eval/episode_distance_reward': Array(7.4143906, dtype=float32), 'eval/episode_forward_reward': Array(1235.7295, dtype=float32), 'eval/episode_reward': Array(1152.064, dtype=float32), 'eval/episode_reward_alive': Array(198.83594, dtype=float32), 'eval/episode_reward_linvel': Array(1235.7295, dtype=float32), 'eval/episode_reward_quadctrl': Array(-289.91602, dtype=float32), 'eval/episode_x_position': Array(3950.0054, dtype=float32), 'eval/episode_x_velocity': Array(247.14592, dtype=float32), 'eval/episode_y_position': Array(-191.16006, dtype=float32), 'eval/episode_y_velocity': Array(-40.409473, dtype=float32), 'eval/episode_distance_from_origin_std': Array(71.318, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1698838, dtype=float32), 'eval/episode_forward_reward_std': Array(194.97954, dtype=float32), 'eval/episode_reward_std': Array(215.68958, dtype=float32), 'eval/episode_reward_alive_std': Array(46.17211, dtype=float32), 'eval/episode_reward_linvel_std': Array(194.97954, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.847355, dtype=float32), 'eval/episode_x_position_std': Array(70.33518, dtype=float32), 'eval/episode_x_velocity_std': Array(38.99594, dtype=float32), 'eval/episode_y_position_std': Array(118.449234, dtype=float32), 'eval/episode_y_velocity_std': Array(53.808823, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.06777667999268, 'eval/sps': 940.7076614548744, 'num_steps': 1966080}
{'eval/walltime': 3595.376733779907, 'training/sps': 511.76487395684774, 'training/walltime': 4052.1949105262756, 'training/entropy_loss': Array(0.00108722, dtype=float32), 'training/policy_loss': Array(0.00117854, dtype=float32), 'training/total_loss': Array(0.02525265, dtype=float32), 'training/v_loss': Array(0.02298688, dtype=float32), 'eval/episode_distance_from_origin': Array(4028.115, dtype=float32), 'eval/episode_distance_reward': Array(7.69468, dtype=float32), 'eval/episode_forward_reward': Array(1282.4445, dtype=float32), 'eval/episode_reward': Array(1223.9365, dtype=float32), 'eval/episode_reward_alive': Array(227.34375, dtype=float32), 'eval/episode_reward_linvel': Array(1282.4445, dtype=float32), 'eval/episode_reward_quadctrl': Array(-293.54633, dtype=float32), 'eval/episode_x_position': Array(3994.4043, dtype=float32), 'eval/episode_x_velocity': Array(256.48886, dtype=float32), 'eval/episode_y_position': Array(-164.16072, dtype=float32), 'eval/episode_y_velocity': Array(-34.154465, dtype=float32), 'eval/episode_distance_from_origin_std': Array(78.78578, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1469193, dtype=float32), 'eval/episode_forward_reward_std': Array(191.15193, dtype=float32), 'eval/episode_reward_std': Array(190.5216, dtype=float32), 'eval/episode_reward_alive_std': Array(43.51139, dtype=float32), 'eval/episode_reward_linvel_std': Array(191.15193, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.38081, dtype=float32), 'eval/episode_x_position_std': Array(77.29061, dtype=float32), 'eval/episode_x_velocity_std': Array(38.23037, dtype=float32), 'eval/episode_y_position_std': Array(110.61962, dtype=float32), 'eval/episode_y_velocity_std': Array(50.197456, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26680326461792, 'eval/sps': 939.3336963474184, 'num_steps': 2048000}
{'eval/walltime': 3731.298933029175, 'training/sps': 512.3684679548265, 'training/walltime': 4212.079847097397, 'training/entropy_loss': Array(0.00174258, dtype=float32), 'training/policy_loss': Array(-0.00016285, dtype=float32), 'training/total_loss': Array(0.02156194, dtype=float32), 'training/v_loss': Array(0.01998221, dtype=float32), 'eval/episode_distance_from_origin': Array(4056.1047, dtype=float32), 'eval/episode_distance_reward': Array(7.9989104, dtype=float32), 'eval/episode_forward_reward': Array(1333.1487, dtype=float32), 'eval/episode_reward': Array(1277.9965, dtype=float32), 'eval/episode_reward_alive': Array(231.07812, dtype=float32), 'eval/episode_reward_linvel': Array(1333.1487, dtype=float32), 'eval/episode_reward_quadctrl': Array(-294.22934, dtype=float32), 'eval/episode_x_position': Array(4022.316, dtype=float32), 'eval/episode_x_velocity': Array(266.62976, dtype=float32), 'eval/episode_y_position': Array(-169.21559, dtype=float32), 'eval/episode_y_velocity': Array(-27.890945, dtype=float32), 'eval/episode_distance_from_origin_std': Array(93.09319, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3764657, dtype=float32), 'eval/episode_forward_reward_std': Array(229.40907, dtype=float32), 'eval/episode_reward_std': Array(237.52, dtype=float32), 'eval/episode_reward_alive_std': Array(58.399197, dtype=float32), 'eval/episode_reward_linvel_std': Array(229.40907, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.09622, dtype=float32), 'eval/episode_x_position_std': Array(91.41219, dtype=float32), 'eval/episode_x_velocity_std': Array(45.88178, dtype=float32), 'eval/episode_y_position_std': Array(104.89659, dtype=float32), 'eval/episode_y_velocity_std': Array(48.62176, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 135.92219924926758, 'eval/sps': 941.7151922715798, 'num_steps': 2129920}
{'eval/walltime': 3867.3803193569183, 'training/sps': 512.5612537626567, 'training/walltime': 4371.904647350311, 'training/entropy_loss': Array(0.00237966, dtype=float32), 'training/policy_loss': Array(0.01656219, dtype=float32), 'training/total_loss': Array(0.04007337, dtype=float32), 'training/v_loss': Array(0.02113152, dtype=float32), 'eval/episode_distance_from_origin': Array(4076.5713, dtype=float32), 'eval/episode_distance_reward': Array(7.9634957, dtype=float32), 'eval/episode_forward_reward': Array(1327.2466, dtype=float32), 'eval/episode_reward': Array(1277.1501, dtype=float32), 'eval/episode_reward_alive': Array(230.38281, dtype=float32), 'eval/episode_reward_linvel': Array(1327.2466, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.44287, dtype=float32), 'eval/episode_x_position': Array(4043.1323, dtype=float32), 'eval/episode_x_velocity': Array(265.4493, dtype=float32), 'eval/episode_y_position': Array(-174.28795, dtype=float32), 'eval/episode_y_velocity': Array(-36.25335, dtype=float32), 'eval/episode_distance_from_origin_std': Array(88.477776, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2170845, dtype=float32), 'eval/episode_forward_reward_std': Array(202.84558, dtype=float32), 'eval/episode_reward_std': Array(208.86282, dtype=float32), 'eval/episode_reward_alive_std': Array(59.163654, dtype=float32), 'eval/episode_reward_linvel_std': Array(202.84558, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(27.3667, dtype=float32), 'eval/episode_x_position_std': Array(86.760605, dtype=float32), 'eval/episode_x_velocity_std': Array(40.569126, dtype=float32), 'eval/episode_y_position_std': Array(88.089165, dtype=float32), 'eval/episode_y_velocity_std': Array(38.783485, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.08138632774353, 'eval/sps': 940.6135802564503, 'num_steps': 2211840}
{'eval/walltime': 4003.693530321121, 'training/sps': 511.4238614749282, 'training/walltime': 4532.084893465042, 'training/entropy_loss': Array(0.00165646, dtype=float32), 'training/policy_loss': Array(0.00120882, dtype=float32), 'training/total_loss': Array(0.02431355, dtype=float32), 'training/v_loss': Array(0.02144828, dtype=float32), 'eval/episode_distance_from_origin': Array(4096.747, dtype=float32), 'eval/episode_distance_reward': Array(8.037217, dtype=float32), 'eval/episode_forward_reward': Array(1339.5332, dtype=float32), 'eval/episode_reward': Array(1283.1406, dtype=float32), 'eval/episode_reward_alive': Array(234.47266, dtype=float32), 'eval/episode_reward_linvel': Array(1339.5332, dtype=float32), 'eval/episode_reward_quadctrl': Array(-298.90244, dtype=float32), 'eval/episode_x_position': Array(4062.613, dtype=float32), 'eval/episode_x_velocity': Array(267.90665, dtype=float32), 'eval/episode_y_position': Array(-183.8338, dtype=float32), 'eval/episode_y_velocity': Array(-39.40242, dtype=float32), 'eval/episode_distance_from_origin_std': Array(85.44109, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2814252, dtype=float32), 'eval/episode_forward_reward_std': Array(213.56873, dtype=float32), 'eval/episode_reward_std': Array(216.12527, dtype=float32), 'eval/episode_reward_alive_std': Array(67.75785, dtype=float32), 'eval/episode_reward_linvel_std': Array(213.56873, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.343845, dtype=float32), 'eval/episode_x_position_std': Array(83.62857, dtype=float32), 'eval/episode_x_velocity_std': Array(42.713795, dtype=float32), 'eval/episode_y_position_std': Array(104.642975, dtype=float32), 'eval/episode_y_velocity_std': Array(40.450977, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31321096420288, 'eval/sps': 939.0139011076043, 'num_steps': 2293760}
{'eval/walltime': 4140.103454351425, 'training/sps': 510.81122677966385, 'training/walltime': 4692.4572496414185, 'training/entropy_loss': Array(0.00266319, dtype=float32), 'training/policy_loss': Array(0.00566493, dtype=float32), 'training/total_loss': Array(0.02854307, dtype=float32), 'training/v_loss': Array(0.02021495, dtype=float32), 'eval/episode_distance_from_origin': Array(4155.026, dtype=float32), 'eval/episode_distance_reward': Array(8.733676, dtype=float32), 'eval/episode_forward_reward': Array(1455.6088, dtype=float32), 'eval/episode_reward': Array(1406.2854, dtype=float32), 'eval/episode_reward_alive': Array(242.32031, dtype=float32), 'eval/episode_reward_linvel': Array(1455.6088, dtype=float32), 'eval/episode_reward_quadctrl': Array(-300.37756, dtype=float32), 'eval/episode_x_position': Array(4119.9497, dtype=float32), 'eval/episode_x_velocity': Array(291.12177, dtype=float32), 'eval/episode_y_position': Array(-205.87926, dtype=float32), 'eval/episode_y_velocity': Array(-45.681145, dtype=float32), 'eval/episode_distance_from_origin_std': Array(89.50185, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3630321, dtype=float32), 'eval/episode_forward_reward_std': Array(227.16936, dtype=float32), 'eval/episode_reward_std': Array(240.20651, dtype=float32), 'eval/episode_reward_alive_std': Array(58.00639, dtype=float32), 'eval/episode_reward_linvel_std': Array(227.16936, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(34.503067, dtype=float32), 'eval/episode_x_position_std': Array(87.51776, dtype=float32), 'eval/episode_x_velocity_std': Array(45.43389, dtype=float32), 'eval/episode_y_position_std': Array(99.58219, dtype=float32), 'eval/episode_y_velocity_std': Array(36.374737, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.40992403030396, 'eval/sps': 938.3481510594811, 'num_steps': 2375680}
{'eval/walltime': 4276.902556657791, 'training/sps': 508.33731048910204, 'training/walltime': 4853.610087156296, 'training/entropy_loss': Array(0.00275655, dtype=float32), 'training/policy_loss': Array(0.00817576, dtype=float32), 'training/total_loss': Array(0.03242427, dtype=float32), 'training/v_loss': Array(0.02149196, dtype=float32), 'eval/episode_distance_from_origin': Array(4143.088, dtype=float32), 'eval/episode_distance_reward': Array(8.393822, dtype=float32), 'eval/episode_forward_reward': Array(1398.9669, dtype=float32), 'eval/episode_reward': Array(1350.1672, dtype=float32), 'eval/episode_reward_alive': Array(258.23828, dtype=float32), 'eval/episode_reward_linvel': Array(1398.9669, dtype=float32), 'eval/episode_reward_quadctrl': Array(-315.43173, dtype=float32), 'eval/episode_x_position': Array(4108.951, dtype=float32), 'eval/episode_x_velocity': Array(279.79333, dtype=float32), 'eval/episode_y_position': Array(-188.61592, dtype=float32), 'eval/episode_y_velocity': Array(-37.38759, dtype=float32), 'eval/episode_distance_from_origin_std': Array(88.51125, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2943887, dtype=float32), 'eval/episode_forward_reward_std': Array(215.72917, dtype=float32), 'eval/episode_reward_std': Array(215.48183, dtype=float32), 'eval/episode_reward_alive_std': Array(62.630394, dtype=float32), 'eval/episode_reward_linvel_std': Array(215.72917, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(39.403255, dtype=float32), 'eval/episode_x_position_std': Array(86.87837, dtype=float32), 'eval/episode_x_velocity_std': Array(43.14585, dtype=float32), 'eval/episode_y_position_std': Array(98.13014, dtype=float32), 'eval/episode_y_velocity_std': Array(36.86026, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.79910230636597, 'eval/sps': 935.6786546255246, 'num_steps': 2457600}
{'eval/walltime': 4413.571530818939, 'training/sps': 510.4552462182618, 'training/walltime': 5014.09428358078, 'training/entropy_loss': Array(0.00284004, dtype=float32), 'training/policy_loss': Array(0.02861335, dtype=float32), 'training/total_loss': Array(0.04941894, dtype=float32), 'training/v_loss': Array(0.01796554, dtype=float32), 'eval/episode_distance_from_origin': Array(4127.2764, dtype=float32), 'eval/episode_distance_reward': Array(7.970874, dtype=float32), 'eval/episode_forward_reward': Array(1328.4767, dtype=float32), 'eval/episode_reward': Array(1264.9211, dtype=float32), 'eval/episode_reward_alive': Array(249.03516, dtype=float32), 'eval/episode_reward_linvel': Array(1328.4767, dtype=float32), 'eval/episode_reward_quadctrl': Array(-320.5616, dtype=float32), 'eval/episode_x_position': Array(4094.966, dtype=float32), 'eval/episode_x_velocity': Array(265.6953, dtype=float32), 'eval/episode_y_position': Array(-160.6449, dtype=float32), 'eval/episode_y_velocity': Array(-30.554464, dtype=float32), 'eval/episode_distance_from_origin_std': Array(101.2698, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2146599, dtype=float32), 'eval/episode_forward_reward_std': Array(202.44164, dtype=float32), 'eval/episode_reward_std': Array(216.07423, dtype=float32), 'eval/episode_reward_alive_std': Array(76.812, dtype=float32), 'eval/episode_reward_linvel_std': Array(202.44164, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.721653, dtype=float32), 'eval/episode_x_position_std': Array(99.77137, dtype=float32), 'eval/episode_x_velocity_std': Array(40.488308, dtype=float32), 'eval/episode_y_position_std': Array(93.40234, dtype=float32), 'eval/episode_y_velocity_std': Array(30.991373, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66897416114807, 'eval/sps': 936.5695527140902, 'num_steps': 2539520}
{'eval/walltime': 4550.086510181427, 'training/sps': 508.19976609321253, 'training/walltime': 5175.2907371521, 'training/entropy_loss': Array(0.00444024, dtype=float32), 'training/policy_loss': Array(0.01980475, dtype=float32), 'training/total_loss': Array(0.04259311, dtype=float32), 'training/v_loss': Array(0.01834813, dtype=float32), 'eval/episode_distance_from_origin': Array(4152.991, dtype=float32), 'eval/episode_distance_reward': Array(8.385135, dtype=float32), 'eval/episode_forward_reward': Array(1397.5195, dtype=float32), 'eval/episode_reward': Array(1341.4795, dtype=float32), 'eval/episode_reward_alive': Array(262.90625, dtype=float32), 'eval/episode_reward_linvel': Array(1397.5195, dtype=float32), 'eval/episode_reward_quadctrl': Array(-327.33163, dtype=float32), 'eval/episode_x_position': Array(4120.5576, dtype=float32), 'eval/episode_x_velocity': Array(279.50394, dtype=float32), 'eval/episode_y_position': Array(-158.63156, dtype=float32), 'eval/episode_y_velocity': Array(-24.336992, dtype=float32), 'eval/episode_distance_from_origin_std': Array(99.764244, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3154316, dtype=float32), 'eval/episode_forward_reward_std': Array(219.23643, dtype=float32), 'eval/episode_reward_std': Array(227.09933, dtype=float32), 'eval/episode_reward_alive_std': Array(67.47311, dtype=float32), 'eval/episode_reward_linvel_std': Array(219.23643, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.194466, dtype=float32), 'eval/episode_x_position_std': Array(99.06122, dtype=float32), 'eval/episode_x_velocity_std': Array(43.847282, dtype=float32), 'eval/episode_y_position_std': Array(92.8217, dtype=float32), 'eval/episode_y_velocity_std': Array(33.88931, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.5149793624878, 'eval/sps': 937.6260436601759, 'num_steps': 2621440}
{'eval/walltime': 4686.880891561508, 'training/sps': 509.2836999169805, 'training/walltime': 5336.144108295441, 'training/entropy_loss': Array(0.00400046, dtype=float32), 'training/policy_loss': Array(0.02057952, dtype=float32), 'training/total_loss': Array(0.04345425, dtype=float32), 'training/v_loss': Array(0.01887427, dtype=float32), 'eval/episode_distance_from_origin': Array(4166.155, dtype=float32), 'eval/episode_distance_reward': Array(8.569183, dtype=float32), 'eval/episode_forward_reward': Array(1428.194, dtype=float32), 'eval/episode_reward': Array(1372.2097, dtype=float32), 'eval/episode_reward_alive': Array(271.3086, dtype=float32), 'eval/episode_reward_linvel': Array(1428.194, dtype=float32), 'eval/episode_reward_quadctrl': Array(-335.86203, dtype=float32), 'eval/episode_x_position': Array(4132.7305, dtype=float32), 'eval/episode_x_velocity': Array(285.6388, dtype=float32), 'eval/episode_y_position': Array(-171.57553, dtype=float32), 'eval/episode_y_velocity': Array(-27.669748, dtype=float32), 'eval/episode_distance_from_origin_std': Array(103.898575, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4147254, dtype=float32), 'eval/episode_forward_reward_std': Array(235.7852, dtype=float32), 'eval/episode_reward_std': Array(243.23224, dtype=float32), 'eval/episode_reward_alive_std': Array(62.656902, dtype=float32), 'eval/episode_reward_linvel_std': Array(235.7852, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.23128, dtype=float32), 'eval/episode_x_position_std': Array(102.964516, dtype=float32), 'eval/episode_x_velocity_std': Array(47.157043, dtype=float32), 'eval/episode_y_position_std': Array(107.612656, dtype=float32), 'eval/episode_y_velocity_std': Array(40.89168, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.79438138008118, 'eval/sps': 935.7109459368355, 'num_steps': 2703360}
{'eval/walltime': 4823.6733186244965, 'training/sps': 506.8712791588332, 'training/walltime': 5497.763050556183, 'training/entropy_loss': Array(0.00429107, dtype=float32), 'training/policy_loss': Array(0.05632447, dtype=float32), 'training/total_loss': Array(0.08062179, dtype=float32), 'training/v_loss': Array(0.02000625, dtype=float32), 'eval/episode_distance_from_origin': Array(4129.8027, dtype=float32), 'eval/episode_distance_reward': Array(9.705624, dtype=float32), 'eval/episode_forward_reward': Array(1617.5969, dtype=float32), 'eval/episode_reward': Array(1599.3574, dtype=float32), 'eval/episode_reward_alive': Array(262.64062, dtype=float32), 'eval/episode_reward_linvel': Array(1617.5969, dtype=float32), 'eval/episode_reward_quadctrl': Array(-290.58563, dtype=float32), 'eval/episode_x_position': Array(4084.0862, dtype=float32), 'eval/episode_x_velocity': Array(323.51938, dtype=float32), 'eval/episode_y_position': Array(-311.32846, dtype=float32), 'eval/episode_y_velocity': Array(-118.42664, dtype=float32), 'eval/episode_distance_from_origin_std': Array(64.970535, dtype=float32), 'eval/episode_distance_reward_std': Array(0.8762555, dtype=float32), 'eval/episode_forward_reward_std': Array(146.04019, dtype=float32), 'eval/episode_reward_std': Array(154.49017, dtype=float32), 'eval/episode_reward_alive_std': Array(18.621008, dtype=float32), 'eval/episode_reward_linvel_std': Array(146.04019, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(4.5332522, dtype=float32), 'eval/episode_x_position_std': Array(65.293175, dtype=float32), 'eval/episode_x_velocity_std': Array(29.20807, dtype=float32), 'eval/episode_y_position_std': Array(80.8503, dtype=float32), 'eval/episode_y_velocity_std': Array(32.662987, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.79242706298828, 'eval/sps': 935.7243141907288, 'num_steps': 2785280}
{'eval/walltime': 4960.594176530838, 'training/sps': 509.3034736374095, 'training/walltime': 5658.610176563263, 'training/entropy_loss': Array(0.00097298, dtype=float32), 'training/policy_loss': Array(-0.00244582, dtype=float32), 'training/total_loss': Array(0.03316163, dtype=float32), 'training/v_loss': Array(0.03463447, dtype=float32), 'eval/episode_distance_from_origin': Array(4150.1797, dtype=float32), 'eval/episode_distance_reward': Array(9.805018, dtype=float32), 'eval/episode_forward_reward': Array(1634.1626, dtype=float32), 'eval/episode_reward': Array(1612.9359, dtype=float32), 'eval/episode_reward_alive': Array(261.73047, dtype=float32), 'eval/episode_reward_linvel': Array(1634.1626, dtype=float32), 'eval/episode_reward_quadctrl': Array(-292.7622, dtype=float32), 'eval/episode_x_position': Array(4103.7715, dtype=float32), 'eval/episode_x_velocity': Array(326.83252, dtype=float32), 'eval/episode_y_position': Array(-319.26587, dtype=float32), 'eval/episode_y_velocity': Array(-118.29385, dtype=float32), 'eval/episode_distance_from_origin_std': Array(77.98032, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1058499, dtype=float32), 'eval/episode_forward_reward_std': Array(184.30573, dtype=float32), 'eval/episode_reward_std': Array(194.41374, dtype=float32), 'eval/episode_reward_alive_std': Array(21.597607, dtype=float32), 'eval/episode_reward_linvel_std': Array(184.30573, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.5440893, dtype=float32), 'eval/episode_x_position_std': Array(77.05013, dtype=float32), 'eval/episode_x_velocity_std': Array(36.86116, dtype=float32), 'eval/episode_y_position_std': Array(89.58866, dtype=float32), 'eval/episode_y_velocity_std': Array(39.683815, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.92085790634155, 'eval/sps': 934.8466110806601, 'num_steps': 2867200}
{'eval/walltime': 5097.300400972366, 'training/sps': 509.4559891001209, 'training/walltime': 5819.409149885178, 'training/entropy_loss': Array(0.00113072, dtype=float32), 'training/policy_loss': Array(-0.00044178, dtype=float32), 'training/total_loss': Array(0.05400477, dtype=float32), 'training/v_loss': Array(0.05331583, dtype=float32), 'eval/episode_distance_from_origin': Array(4153.135, dtype=float32), 'eval/episode_distance_reward': Array(9.652273, dtype=float32), 'eval/episode_forward_reward': Array(1608.7056, dtype=float32), 'eval/episode_reward': Array(1587.9487, dtype=float32), 'eval/episode_reward_alive': Array(258.77734, dtype=float32), 'eval/episode_reward_linvel': Array(1608.7056, dtype=float32), 'eval/episode_reward_quadctrl': Array(-289.18652, dtype=float32), 'eval/episode_x_position': Array(4106.914, dtype=float32), 'eval/episode_x_velocity': Array(321.74115, dtype=float32), 'eval/episode_y_position': Array(-320.8048, dtype=float32), 'eval/episode_y_velocity': Array(-114.73253, dtype=float32), 'eval/episode_distance_from_origin_std': Array(72.34143, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1564491, dtype=float32), 'eval/episode_forward_reward_std': Array(192.73882, dtype=float32), 'eval/episode_reward_std': Array(202.02487, dtype=float32), 'eval/episode_reward_alive_std': Array(24.569242, dtype=float32), 'eval/episode_reward_linvel_std': Array(192.73882, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(7.3178277, dtype=float32), 'eval/episode_x_position_std': Array(71.85709, dtype=float32), 'eval/episode_x_velocity_std': Array(38.54776, dtype=float32), 'eval/episode_y_position_std': Array(82.76138, dtype=float32), 'eval/episode_y_velocity_std': Array(41.721027, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.70622444152832, 'eval/sps': 936.314352348659, 'num_steps': 2949120}
{'eval/walltime': 5233.752739429474, 'training/sps': 509.81934624601814, 'training/walltime': 5980.093518972397, 'training/entropy_loss': Array(0.00121745, dtype=float32), 'training/policy_loss': Array(-0.00409596, dtype=float32), 'training/total_loss': Array(0.02731241, dtype=float32), 'training/v_loss': Array(0.03019093, dtype=float32), 'eval/episode_distance_from_origin': Array(4172.99, dtype=float32), 'eval/episode_distance_reward': Array(9.974014, dtype=float32), 'eval/episode_forward_reward': Array(1662.3284, dtype=float32), 'eval/episode_reward': Array(1648.3105, dtype=float32), 'eval/episode_reward_alive': Array(265.3203, dtype=float32), 'eval/episode_reward_linvel': Array(1662.3284, dtype=float32), 'eval/episode_reward_quadctrl': Array(-289.312, dtype=float32), 'eval/episode_x_position': Array(4124.6035, dtype=float32), 'eval/episode_x_velocity': Array(332.46564, dtype=float32), 'eval/episode_y_position': Array(-345.40747, dtype=float32), 'eval/episode_y_velocity': Array(-119.91853, dtype=float32), 'eval/episode_distance_from_origin_std': Array(73.383255, dtype=float32), 'eval/episode_distance_reward_std': Array(1.1253016, dtype=float32), 'eval/episode_forward_reward_std': Array(187.54749, dtype=float32), 'eval/episode_reward_std': Array(194.44167, dtype=float32), 'eval/episode_reward_alive_std': Array(18.71254, dtype=float32), 'eval/episode_reward_linvel_std': Array(187.54749, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(5.664339, dtype=float32), 'eval/episode_x_position_std': Array(73.53472, dtype=float32), 'eval/episode_x_velocity_std': Array(37.509506, dtype=float32), 'eval/episode_y_position_std': Array(87.66179, dtype=float32), 'eval/episode_y_velocity_std': Array(39.954742, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45233845710754, 'eval/sps': 938.0564777952526, 'num_steps': 3031040}
{'eval/walltime': 5370.41193318367, 'training/sps': 507.973794076997, 'training/walltime': 6141.3616807460785, 'training/entropy_loss': Array(0.00121228, dtype=float32), 'training/policy_loss': Array(-0.00520285, dtype=float32), 'training/total_loss': Array(0.01718412, dtype=float32), 'training/v_loss': Array(0.0211747, dtype=float32), 'eval/episode_distance_from_origin': Array(4200.951, dtype=float32), 'eval/episode_distance_reward': Array(10.101318, dtype=float32), 'eval/episode_forward_reward': Array(1683.5459, dtype=float32), 'eval/episode_reward': Array(1671.56, dtype=float32), 'eval/episode_reward_alive': Array(263.95703, dtype=float32), 'eval/episode_reward_linvel': Array(1683.5459, dtype=float32), 'eval/episode_reward_quadctrl': Array(-286.0439, dtype=float32), 'eval/episode_x_position': Array(4151.3677, dtype=float32), 'eval/episode_x_velocity': Array(336.7091, dtype=float32), 'eval/episode_y_position': Array(-363.14725, dtype=float32), 'eval/episode_y_velocity': Array(-115.42838, dtype=float32), 'eval/episode_distance_from_origin_std': Array(92.8416, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4645576, dtype=float32), 'eval/episode_forward_reward_std': Array(244.08957, dtype=float32), 'eval/episode_reward_std': Array(254.28973, dtype=float32), 'eval/episode_reward_alive_std': Array(30.69342, dtype=float32), 'eval/episode_reward_linvel_std': Array(244.08957, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(8.693979, dtype=float32), 'eval/episode_x_position_std': Array(90.48241, dtype=float32), 'eval/episode_x_velocity_std': Array(48.817905, dtype=float32), 'eval/episode_y_position_std': Array(96.73701, dtype=float32), 'eval/episode_y_velocity_std': Array(46.089203, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.65919375419617, 'eval/sps': 936.6365809989254, 'num_steps': 3112960}
{'eval/walltime': 5506.973476409912, 'training/sps': 510.6111263998401, 'training/walltime': 6301.796884298325, 'training/entropy_loss': Array(0.00135873, dtype=float32), 'training/policy_loss': Array(-0.0039854, dtype=float32), 'training/total_loss': Array(0.02179501, dtype=float32), 'training/v_loss': Array(0.02442168, dtype=float32), 'eval/episode_distance_from_origin': Array(4240.7686, dtype=float32), 'eval/episode_distance_reward': Array(10.175808, dtype=float32), 'eval/episode_forward_reward': Array(1695.9607, dtype=float32), 'eval/episode_reward': Array(1685.81, dtype=float32), 'eval/episode_reward_alive': Array(265.72266, dtype=float32), 'eval/episode_reward_linvel': Array(1695.9607, dtype=float32), 'eval/episode_reward_quadctrl': Array(-286.049, dtype=float32), 'eval/episode_x_position': Array(4189.707, dtype=float32), 'eval/episode_x_velocity': Array(339.19208, dtype=float32), 'eval/episode_y_position': Array(-384.78168, dtype=float32), 'eval/episode_y_velocity': Array(-118.46562, dtype=float32), 'eval/episode_distance_from_origin_std': Array(102.15117, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8005381, dtype=float32), 'eval/episode_forward_reward_std': Array(300.08533, dtype=float32), 'eval/episode_reward_std': Array(314.00598, dtype=float32), 'eval/episode_reward_alive_std': Array(32.822784, dtype=float32), 'eval/episode_reward_linvel_std': Array(300.08533, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(9.2690525, dtype=float32), 'eval/episode_x_position_std': Array(98.49476, dtype=float32), 'eval/episode_x_velocity_std': Array(60.01705, dtype=float32), 'eval/episode_y_position_std': Array(96.756, dtype=float32), 'eval/episode_y_velocity_std': Array(45.71436, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.56154322624207, 'eval/sps': 937.3063380511296, 'num_steps': 3194880}
{'eval/walltime': 5643.488841056824, 'training/sps': 510.25656120979176, 'training/walltime': 6462.34357047081, 'training/entropy_loss': Array(0.00149716, dtype=float32), 'training/policy_loss': Array(-0.00306857, dtype=float32), 'training/total_loss': Array(0.02678129, dtype=float32), 'training/v_loss': Array(0.02835269, dtype=float32), 'eval/episode_distance_from_origin': Array(4262.48, dtype=float32), 'eval/episode_distance_reward': Array(10.28298, dtype=float32), 'eval/episode_forward_reward': Array(1713.8228, dtype=float32), 'eval/episode_reward': Array(1700.2588, dtype=float32), 'eval/episode_reward_alive': Array(264.96094, dtype=float32), 'eval/episode_reward_linvel': Array(1713.8228, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.80792, dtype=float32), 'eval/episode_x_position': Array(4213.424, dtype=float32), 'eval/episode_x_velocity': Array(342.76456, dtype=float32), 'eval/episode_y_position': Array(-373.88306, dtype=float32), 'eval/episode_y_velocity': Array(-108.91886, dtype=float32), 'eval/episode_distance_from_origin_std': Array(102.86063, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7375818, dtype=float32), 'eval/episode_forward_reward_std': Array(289.59283, dtype=float32), 'eval/episode_reward_std': Array(303.95285, dtype=float32), 'eval/episode_reward_alive_std': Array(35.728065, dtype=float32), 'eval/episode_reward_linvel_std': Array(289.59283, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.873862, dtype=float32), 'eval/episode_x_position_std': Array(99.21122, dtype=float32), 'eval/episode_x_velocity_std': Array(57.91856, dtype=float32), 'eval/episode_y_position_std': Array(95.445496, dtype=float32), 'eval/episode_y_velocity_std': Array(39.378143, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.51536464691162, 'eval/sps': 937.623397418041, 'num_steps': 3276800}
{'eval/walltime': 5780.170056819916, 'training/sps': 510.9738989213836, 'training/walltime': 6622.664870977402, 'training/entropy_loss': Array(0.00165933, dtype=float32), 'training/policy_loss': Array(-0.00364047, dtype=float32), 'training/total_loss': Array(0.02326152, dtype=float32), 'training/v_loss': Array(0.02524266, dtype=float32), 'eval/episode_distance_from_origin': Array(4287.412, dtype=float32), 'eval/episode_distance_reward': Array(10.394973, dtype=float32), 'eval/episode_forward_reward': Array(1732.4878, dtype=float32), 'eval/episode_reward': Array(1718.2255, dtype=float32), 'eval/episode_reward_alive': Array(263.48047, dtype=float32), 'eval/episode_reward_linvel': Array(1732.4878, dtype=float32), 'eval/episode_reward_quadctrl': Array(-288.13773, dtype=float32), 'eval/episode_x_position': Array(4242.337, dtype=float32), 'eval/episode_x_velocity': Array(346.49756, dtype=float32), 'eval/episode_y_position': Array(-340.59042, dtype=float32), 'eval/episode_y_velocity': Array(-98.72841, dtype=float32), 'eval/episode_distance_from_origin_std': Array(105.92221, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7746965, dtype=float32), 'eval/episode_forward_reward_std': Array(295.77826, dtype=float32), 'eval/episode_reward_std': Array(309.27652, dtype=float32), 'eval/episode_reward_alive_std': Array(40.50301, dtype=float32), 'eval/episode_reward_linvel_std': Array(295.77826, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(14.247765, dtype=float32), 'eval/episode_x_position_std': Array(104.389946, dtype=float32), 'eval/episode_x_velocity_std': Array(59.155674, dtype=float32), 'eval/episode_y_position_std': Array(99.388954, dtype=float32), 'eval/episode_y_velocity_std': Array(37.779488, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.68121576309204, 'eval/sps': 936.4856705830076, 'num_steps': 3358720}
{'eval/walltime': 5916.371442556381, 'training/sps': 509.2248905911766, 'training/walltime': 6783.536818742752, 'training/entropy_loss': Array(0.00173943, dtype=float32), 'training/policy_loss': Array(-0.00341317, dtype=float32), 'training/total_loss': Array(0.02029825, dtype=float32), 'training/v_loss': Array(0.02197199, dtype=float32), 'eval/episode_distance_from_origin': Array(4296.958, dtype=float32), 'eval/episode_distance_reward': Array(10.103836, dtype=float32), 'eval/episode_forward_reward': Array(1683.966, dtype=float32), 'eval/episode_reward': Array(1663.0568, dtype=float32), 'eval/episode_reward_alive': Array(258.04297, dtype=float32), 'eval/episode_reward_linvel': Array(1683.966, dtype=float32), 'eval/episode_reward_quadctrl': Array(-289.05612, dtype=float32), 'eval/episode_x_position': Array(4256.875, dtype=float32), 'eval/episode_x_velocity': Array(336.79315, dtype=float32), 'eval/episode_y_position': Array(-288.44348, dtype=float32), 'eval/episode_y_velocity': Array(-79.38963, dtype=float32), 'eval/episode_distance_from_origin_std': Array(103.66079, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7810307, dtype=float32), 'eval/episode_forward_reward_std': Array(296.83398, dtype=float32), 'eval/episode_reward_std': Array(307.78232, dtype=float32), 'eval/episode_reward_alive_std': Array(45.80291, dtype=float32), 'eval/episode_reward_linvel_std': Array(296.83398, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(18.50307, dtype=float32), 'eval/episode_x_position_std': Array(101.62546, dtype=float32), 'eval/episode_x_velocity_std': Array(59.366833, dtype=float32), 'eval/episode_y_position_std': Array(106.61477, dtype=float32), 'eval/episode_y_velocity_std': Array(38.460964, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20138573646545, 'eval/sps': 939.7848583395897, 'num_steps': 3440640}
{'eval/walltime': 6052.74560046196, 'training/sps': 511.6176357710837, 'training/walltime': 6943.656396865845, 'training/entropy_loss': Array(0.00199118, dtype=float32), 'training/policy_loss': Array(-0.00335123, dtype=float32), 'training/total_loss': Array(0.02122525, dtype=float32), 'training/v_loss': Array(0.0225853, dtype=float32), 'eval/episode_distance_from_origin': Array(4292.129, dtype=float32), 'eval/episode_distance_reward': Array(9.903395, dtype=float32), 'eval/episode_forward_reward': Array(1650.5597, dtype=float32), 'eval/episode_reward': Array(1637.323, dtype=float32), 'eval/episode_reward_alive': Array(268.84766, dtype=float32), 'eval/episode_reward_linvel': Array(1650.5597, dtype=float32), 'eval/episode_reward_quadctrl': Array(-291.98798, dtype=float32), 'eval/episode_x_position': Array(4253.7197, dtype=float32), 'eval/episode_x_velocity': Array(330.11194, dtype=float32), 'eval/episode_y_position': Array(-271.57916, dtype=float32), 'eval/episode_y_velocity': Array(-66.523636, dtype=float32), 'eval/episode_distance_from_origin_std': Array(116.37236, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6904557, dtype=float32), 'eval/episode_forward_reward_std': Array(281.7387, dtype=float32), 'eval/episode_reward_std': Array(286.1421, dtype=float32), 'eval/episode_reward_alive_std': Array(46.819286, dtype=float32), 'eval/episode_reward_linvel_std': Array(281.7387, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(23.791212, dtype=float32), 'eval/episode_x_position_std': Array(115.334724, dtype=float32), 'eval/episode_x_velocity_std': Array(56.347725, dtype=float32), 'eval/episode_y_position_std': Array(97.47318, dtype=float32), 'eval/episode_y_velocity_std': Array(38.17958, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3741579055786, 'eval/sps': 938.59424663596, 'num_steps': 3522560}
{'eval/walltime': 6188.952739953995, 'training/sps': 509.5865455728935, 'training/walltime': 7104.414173364639, 'training/entropy_loss': Array(0.00204684, dtype=float32), 'training/policy_loss': Array(-0.00278923, dtype=float32), 'training/total_loss': Array(0.02246576, dtype=float32), 'training/v_loss': Array(0.02320815, dtype=float32), 'eval/episode_distance_from_origin': Array(4309.037, dtype=float32), 'eval/episode_distance_reward': Array(10.040107, dtype=float32), 'eval/episode_forward_reward': Array(1673.3444, dtype=float32), 'eval/episode_reward': Array(1662.3469, dtype=float32), 'eval/episode_reward_alive': Array(279.03125, dtype=float32), 'eval/episode_reward_linvel': Array(1673.3444, dtype=float32), 'eval/episode_reward_quadctrl': Array(-300.0687, dtype=float32), 'eval/episode_x_position': Array(4272.533, dtype=float32), 'eval/episode_x_velocity': Array(334.66888, dtype=float32), 'eval/episode_y_position': Array(-241.9081, dtype=float32), 'eval/episode_y_velocity': Array(-56.90547, dtype=float32), 'eval/episode_distance_from_origin_std': Array(116.268425, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7401491, dtype=float32), 'eval/episode_forward_reward_std': Array(290.02106, dtype=float32), 'eval/episode_reward_std': Array(297.86984, dtype=float32), 'eval/episode_reward_alive_std': Array(53.86607, dtype=float32), 'eval/episode_reward_linvel_std': Array(290.02106, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.802301, dtype=float32), 'eval/episode_x_position_std': Array(115.36501, dtype=float32), 'eval/episode_x_velocity_std': Array(58.004242, dtype=float32), 'eval/episode_y_position_std': Array(112.42761, dtype=float32), 'eval/episode_y_velocity_std': Array(41.47115, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2071394920349, 'eval/sps': 939.7451593019113, 'num_steps': 3604480}
{'eval/walltime': 6325.621183872223, 'training/sps': 511.4066896130067, 'training/walltime': 7264.599797964096, 'training/entropy_loss': Array(0.00312301, dtype=float32), 'training/policy_loss': Array(0.00149789, dtype=float32), 'training/total_loss': Array(0.02636553, dtype=float32), 'training/v_loss': Array(0.02174463, dtype=float32), 'eval/episode_distance_from_origin': Array(4335.419, dtype=float32), 'eval/episode_distance_reward': Array(10.322639, dtype=float32), 'eval/episode_forward_reward': Array(1720.4324, dtype=float32), 'eval/episode_reward': Array(1716.6611, dtype=float32), 'eval/episode_reward_alive': Array(286.875, dtype=float32), 'eval/episode_reward_linvel': Array(1720.4324, dtype=float32), 'eval/episode_reward_quadctrl': Array(-300.96893, dtype=float32), 'eval/episode_x_position': Array(4300.4766, dtype=float32), 'eval/episode_x_velocity': Array(344.0865, dtype=float32), 'eval/episode_y_position': Array(-221.43967, dtype=float32), 'eval/episode_y_velocity': Array(-47.06775, dtype=float32), 'eval/episode_distance_from_origin_std': Array(111.62431, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7652441, dtype=float32), 'eval/episode_forward_reward_std': Array(294.20312, dtype=float32), 'eval/episode_reward_std': Array(297.71893, dtype=float32), 'eval/episode_reward_alive_std': Array(53.444553, dtype=float32), 'eval/episode_reward_linvel_std': Array(294.20312, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(30.695114, dtype=float32), 'eval/episode_x_position_std': Array(109.88511, dtype=float32), 'eval/episode_x_velocity_std': Array(58.84062, dtype=float32), 'eval/episode_y_position_std': Array(107.082794, dtype=float32), 'eval/episode_y_velocity_std': Array(42.05444, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.66844391822815, 'eval/sps': 936.5731863939661, 'num_steps': 3686400}
{'eval/walltime': 6461.927002906799, 'training/sps': 505.233905331579, 'training/walltime': 7426.742518663406, 'training/entropy_loss': Array(0.00344791, dtype=float32), 'training/policy_loss': Array(0.00502427, dtype=float32), 'training/total_loss': Array(0.03234819, dtype=float32), 'training/v_loss': Array(0.02387602, dtype=float32), 'eval/episode_distance_from_origin': Array(4286.5195, dtype=float32), 'eval/episode_distance_reward': Array(9.382469, dtype=float32), 'eval/episode_forward_reward': Array(1563.7395, dtype=float32), 'eval/episode_reward': Array(1569.0043, dtype=float32), 'eval/episode_reward_alive': Array(307.91016, dtype=float32), 'eval/episode_reward_linvel': Array(1563.7395, dtype=float32), 'eval/episode_reward_quadctrl': Array(-312.02795, dtype=float32), 'eval/episode_x_position': Array(4252.912, dtype=float32), 'eval/episode_x_velocity': Array(312.74792, dtype=float32), 'eval/episode_y_position': Array(-191.3769, dtype=float32), 'eval/episode_y_velocity': Array(-33.02282, dtype=float32), 'eval/episode_distance_from_origin_std': Array(100.056145, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5934098, dtype=float32), 'eval/episode_forward_reward_std': Array(265.56442, dtype=float32), 'eval/episode_reward_std': Array(260.562, dtype=float32), 'eval/episode_reward_alive_std': Array(52.57778, dtype=float32), 'eval/episode_reward_linvel_std': Array(265.56442, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.471375, dtype=float32), 'eval/episode_x_position_std': Array(98.69841, dtype=float32), 'eval/episode_x_velocity_std': Array(53.11292, dtype=float32), 'eval/episode_y_position_std': Array(105.58547, dtype=float32), 'eval/episode_y_velocity_std': Array(36.28056, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30581903457642, 'eval/sps': 939.0648242796626, 'num_steps': 3768320}
{'eval/walltime': 6598.198709964752, 'training/sps': 511.81536430568866, 'training/walltime': 7586.800238132477, 'training/entropy_loss': Array(0.003965, dtype=float32), 'training/policy_loss': Array(0.02271172, dtype=float32), 'training/total_loss': Array(0.04926012, dtype=float32), 'training/v_loss': Array(0.0225834, dtype=float32), 'eval/episode_distance_from_origin': Array(4327.2217, dtype=float32), 'eval/episode_distance_reward': Array(9.788249, dtype=float32), 'eval/episode_forward_reward': Array(1631.3674, dtype=float32), 'eval/episode_reward': Array(1630.8467, dtype=float32), 'eval/episode_reward_alive': Array(306.09375, dtype=float32), 'eval/episode_reward_linvel': Array(1631.3674, dtype=float32), 'eval/episode_reward_quadctrl': Array(-316.4029, dtype=float32), 'eval/episode_x_position': Array(4292.169, dtype=float32), 'eval/episode_x_velocity': Array(326.2735, dtype=float32), 'eval/episode_y_position': Array(-211.92728, dtype=float32), 'eval/episode_y_velocity': Array(-36.90974, dtype=float32), 'eval/episode_distance_from_origin_std': Array(116.0362, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6543576, dtype=float32), 'eval/episode_forward_reward_std': Array(275.7227, dtype=float32), 'eval/episode_reward_std': Array(288.042, dtype=float32), 'eval/episode_reward_alive_std': Array(59.84001, dtype=float32), 'eval/episode_reward_linvel_std': Array(275.7227, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.735584, dtype=float32), 'eval/episode_x_position_std': Array(114.27711, dtype=float32), 'eval/episode_x_velocity_std': Array(55.14454, dtype=float32), 'eval/episode_y_position_std': Array(122.73583, dtype=float32), 'eval/episode_y_velocity_std': Array(40.378525, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27170705795288, 'eval/sps': 939.2998940386419, 'num_steps': 3850240}
{'eval/walltime': 6734.4353613853455, 'training/sps': 507.5765689036074, 'training/walltime': 7748.194607019424, 'training/entropy_loss': Array(0.00452178, dtype=float32), 'training/policy_loss': Array(0.02519106, dtype=float32), 'training/total_loss': Array(0.04913008, dtype=float32), 'training/v_loss': Array(0.01941724, dtype=float32), 'eval/episode_distance_from_origin': Array(4288.9995, dtype=float32), 'eval/episode_distance_reward': Array(8.908352, dtype=float32), 'eval/episode_forward_reward': Array(1484.7197, dtype=float32), 'eval/episode_reward': Array(1489.1704, dtype=float32), 'eval/episode_reward_alive': Array(321.6953, dtype=float32), 'eval/episode_reward_linvel': Array(1484.7197, dtype=float32), 'eval/episode_reward_quadctrl': Array(-326.15292, dtype=float32), 'eval/episode_x_position': Array(4255.336, dtype=float32), 'eval/episode_x_velocity': Array(296.94394, dtype=float32), 'eval/episode_y_position': Array(-173.68616, dtype=float32), 'eval/episode_y_velocity': Array(-17.919659, dtype=float32), 'eval/episode_distance_from_origin_std': Array(136.71693, dtype=float32), 'eval/episode_distance_reward_std': Array(1.569365, dtype=float32), 'eval/episode_forward_reward_std': Array(261.55734, dtype=float32), 'eval/episode_reward_std': Array(267.36816, dtype=float32), 'eval/episode_reward_alive_std': Array(66.40931, dtype=float32), 'eval/episode_reward_linvel_std': Array(261.55734, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(46.01075, dtype=float32), 'eval/episode_x_position_std': Array(134.5233, dtype=float32), 'eval/episode_x_velocity_std': Array(52.3115, dtype=float32), 'eval/episode_y_position_std': Array(123.20802, dtype=float32), 'eval/episode_y_velocity_std': Array(37.12548, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23665142059326, 'eval/sps': 939.5415893248517, 'num_steps': 3932160}
{'eval/walltime': 6870.699112892151, 'training/sps': 512.5766841182406, 'training/walltime': 7908.014595985413, 'training/entropy_loss': Array(0.0065422, dtype=float32), 'training/policy_loss': Array(0.04066371, dtype=float32), 'training/total_loss': Array(0.0654571, dtype=float32), 'training/v_loss': Array(0.0182512, dtype=float32), 'eval/episode_distance_from_origin': Array(4300.4565, dtype=float32), 'eval/episode_distance_reward': Array(9.065365, dtype=float32), 'eval/episode_forward_reward': Array(1510.8896, dtype=float32), 'eval/episode_reward': Array(1517.5435, dtype=float32), 'eval/episode_reward_alive': Array(338.54297, dtype=float32), 'eval/episode_reward_linvel': Array(1510.8896, dtype=float32), 'eval/episode_reward_quadctrl': Array(-340.95428, dtype=float32), 'eval/episode_x_position': Array(4265.172, dtype=float32), 'eval/episode_x_velocity': Array(302.17792, dtype=float32), 'eval/episode_y_position': Array(-208.42764, dtype=float32), 'eval/episode_y_velocity': Array(-18.542076, dtype=float32), 'eval/episode_distance_from_origin_std': Array(122.87381, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5546647, dtype=float32), 'eval/episode_forward_reward_std': Array(259.10754, dtype=float32), 'eval/episode_reward_std': Array(256.86932, dtype=float32), 'eval/episode_reward_alive_std': Array(48.964355, dtype=float32), 'eval/episode_reward_linvel_std': Array(259.10754, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.75113, dtype=float32), 'eval/episode_x_position_std': Array(121.19143, dtype=float32), 'eval/episode_x_velocity_std': Array(51.82149, dtype=float32), 'eval/episode_y_position_std': Array(110.33418, dtype=float32), 'eval/episode_y_velocity_std': Array(39.76584, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26375150680542, 'eval/sps': 939.3547336292683, 'num_steps': 4014080}
{'eval/walltime': 7007.146056652069, 'training/sps': 508.88962774551356, 'training/walltime': 8068.9925282001495, 'training/entropy_loss': Array(0.00727424, dtype=float32), 'training/policy_loss': Array(0.06810479, dtype=float32), 'training/total_loss': Array(0.09329151, dtype=float32), 'training/v_loss': Array(0.01791247, dtype=float32), 'eval/episode_distance_from_origin': Array(4286.8213, dtype=float32), 'eval/episode_distance_reward': Array(8.616879, dtype=float32), 'eval/episode_forward_reward': Array(1436.1401, dtype=float32), 'eval/episode_reward': Array(1341.4701, dtype=float32), 'eval/episode_reward_alive': Array(291.375, dtype=float32), 'eval/episode_reward_linvel': Array(1436.1401, dtype=float32), 'eval/episode_reward_quadctrl': Array(-394.6621, dtype=float32), 'eval/episode_x_position': Array(4249.712, dtype=float32), 'eval/episode_x_velocity': Array(287.22806, dtype=float32), 'eval/episode_y_position': Array(-239.28235, dtype=float32), 'eval/episode_y_velocity': Array(-53.273933, dtype=float32), 'eval/episode_distance_from_origin_std': Array(126.09898, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2810006, dtype=float32), 'eval/episode_forward_reward_std': Array(213.49666, dtype=float32), 'eval/episode_reward_std': Array(223.9688, dtype=float32), 'eval/episode_reward_alive_std': Array(80.89125, dtype=float32), 'eval/episode_reward_linvel_std': Array(213.49666, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(51.852055, dtype=float32), 'eval/episode_x_position_std': Array(122.67108, dtype=float32), 'eval/episode_x_velocity_std': Array(42.699303, dtype=float32), 'eval/episode_y_position_std': Array(150.61287, dtype=float32), 'eval/episode_y_velocity_std': Array(43.66243, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4469437599182, 'eval/sps': 938.0935656955364, 'num_steps': 4096000}
{'eval/walltime': 7143.425430774689, 'training/sps': 512.5722078431147, 'training/walltime': 8228.8139128685, 'training/entropy_loss': Array(0.01278813, dtype=float32), 'training/policy_loss': Array(0.05650514, dtype=float32), 'training/total_loss': Array(0.09525107, dtype=float32), 'training/v_loss': Array(0.0259578, dtype=float32), 'eval/episode_distance_from_origin': Array(4306.538, dtype=float32), 'eval/episode_distance_reward': Array(8.708671, dtype=float32), 'eval/episode_forward_reward': Array(1451.4396, dtype=float32), 'eval/episode_reward': Array(1304.0769, dtype=float32), 'eval/episode_reward_alive': Array(245.26562, dtype=float32), 'eval/episode_reward_linvel': Array(1451.4396, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.3368, dtype=float32), 'eval/episode_x_position': Array(4268.621, dtype=float32), 'eval/episode_x_velocity': Array(290.2879, dtype=float32), 'eval/episode_y_position': Array(-248.23564, dtype=float32), 'eval/episode_y_velocity': Array(-58.554676, dtype=float32), 'eval/episode_distance_from_origin_std': Array(156.47867, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5516115, dtype=float32), 'eval/episode_forward_reward_std': Array(258.5981, dtype=float32), 'eval/episode_reward_std': Array(286.63342, dtype=float32), 'eval/episode_reward_alive_std': Array(72.74352, dtype=float32), 'eval/episode_reward_linvel_std': Array(258.5981, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.136852, dtype=float32), 'eval/episode_x_position_std': Array(152.60439, dtype=float32), 'eval/episode_x_velocity_std': Array(51.719643, dtype=float32), 'eval/episode_y_position_std': Array(161.42647, dtype=float32), 'eval/episode_y_velocity_std': Array(47.94853, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27937412261963, 'eval/sps': 939.2470491156635, 'num_steps': 4177920}
{'eval/walltime': 7279.674299001694, 'training/sps': 511.6984961340706, 'training/walltime': 8388.908188343048, 'training/entropy_loss': Array(0.01774187, dtype=float32), 'training/policy_loss': Array(0.0715174, dtype=float32), 'training/total_loss': Array(0.11082429, dtype=float32), 'training/v_loss': Array(0.02156501, dtype=float32), 'eval/episode_distance_from_origin': Array(4330.6377, dtype=float32), 'eval/episode_distance_reward': Array(8.968802, dtype=float32), 'eval/episode_forward_reward': Array(1494.794, dtype=float32), 'eval/episode_reward': Array(1366.44, dtype=float32), 'eval/episode_reward_alive': Array(241.10156, dtype=float32), 'eval/episode_reward_linvel': Array(1494.794, dtype=float32), 'eval/episode_reward_quadctrl': Array(-378.42426, dtype=float32), 'eval/episode_x_position': Array(4290.541, dtype=float32), 'eval/episode_x_velocity': Array(298.95874, dtype=float32), 'eval/episode_y_position': Array(-264.91708, dtype=float32), 'eval/episode_y_velocity': Array(-59.256844, dtype=float32), 'eval/episode_distance_from_origin_std': Array(137.85524, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4676598, dtype=float32), 'eval/episode_forward_reward_std': Array(244.60652, dtype=float32), 'eval/episode_reward_std': Array(286.93814, dtype=float32), 'eval/episode_reward_alive_std': Array(73.31874, dtype=float32), 'eval/episode_reward_linvel_std': Array(244.60652, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(63.671276, dtype=float32), 'eval/episode_x_position_std': Array(131.61523, dtype=float32), 'eval/episode_x_velocity_std': Array(48.921303, dtype=float32), 'eval/episode_y_position_std': Array(185.41612, dtype=float32), 'eval/episode_y_velocity_std': Array(55.091682, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.248868227005, 'eval/sps': 939.457344972132, 'num_steps': 4259840}
{'eval/walltime': 7415.955622673035, 'training/sps': 511.8284228427041, 'training/walltime': 8548.961824178696, 'training/entropy_loss': Array(0.01319221, dtype=float32), 'training/policy_loss': Array(0.04722344, dtype=float32), 'training/total_loss': Array(0.08663102, dtype=float32), 'training/v_loss': Array(0.02621537, dtype=float32), 'eval/episode_distance_from_origin': Array(4332.844, dtype=float32), 'eval/episode_distance_reward': Array(9.051538, dtype=float32), 'eval/episode_forward_reward': Array(1508.5828, dtype=float32), 'eval/episode_reward': Array(1386.5671, dtype=float32), 'eval/episode_reward_alive': Array(248.96875, dtype=float32), 'eval/episode_reward_linvel': Array(1508.5828, dtype=float32), 'eval/episode_reward_quadctrl': Array(-380.03607, dtype=float32), 'eval/episode_x_position': Array(4293.6685, dtype=float32), 'eval/episode_x_velocity': Array(301.71655, dtype=float32), 'eval/episode_y_position': Array(-259.57153, dtype=float32), 'eval/episode_y_velocity': Array(-59.429302, dtype=float32), 'eval/episode_distance_from_origin_std': Array(128.86182, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3281976, dtype=float32), 'eval/episode_forward_reward_std': Array(221.36285, dtype=float32), 'eval/episode_reward_std': Array(259.17987, dtype=float32), 'eval/episode_reward_alive_std': Array(69.642975, dtype=float32), 'eval/episode_reward_linvel_std': Array(221.36285, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.07434, dtype=float32), 'eval/episode_x_position_std': Array(122.97474, dtype=float32), 'eval/episode_x_velocity_std': Array(44.27262, dtype=float32), 'eval/episode_y_position_std': Array(175.2214, dtype=float32), 'eval/episode_y_velocity_std': Array(47.48352, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28132367134094, 'eval/sps': 939.2336128807175, 'num_steps': 4341760}
{'eval/walltime': 7552.11770772934, 'training/sps': 510.3932319393213, 'training/walltime': 8709.46551990509, 'training/entropy_loss': Array(0.01561214, dtype=float32), 'training/policy_loss': Array(0.05407808, dtype=float32), 'training/total_loss': Array(0.09214522, dtype=float32), 'training/v_loss': Array(0.022455, dtype=float32), 'eval/episode_distance_from_origin': Array(4338.5513, dtype=float32), 'eval/episode_distance_reward': Array(8.902461, dtype=float32), 'eval/episode_forward_reward': Array(1483.7368, dtype=float32), 'eval/episode_reward': Array(1337.6251, dtype=float32), 'eval/episode_reward_alive': Array(243.78516, dtype=float32), 'eval/episode_reward_linvel': Array(1483.7368, dtype=float32), 'eval/episode_reward_quadctrl': Array(-398.79926, dtype=float32), 'eval/episode_x_position': Array(4298.3027, dtype=float32), 'eval/episode_x_velocity': Array(296.74738, dtype=float32), 'eval/episode_y_position': Array(-284.36383, dtype=float32), 'eval/episode_y_velocity': Array(-64.33485, dtype=float32), 'eval/episode_distance_from_origin_std': Array(144.91165, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4346433, dtype=float32), 'eval/episode_forward_reward_std': Array(239.10405, dtype=float32), 'eval/episode_reward_std': Array(276.2866, dtype=float32), 'eval/episode_reward_alive_std': Array(82.18136, dtype=float32), 'eval/episode_reward_linvel_std': Array(239.10405, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.16982, dtype=float32), 'eval/episode_x_position_std': Array(138.30428, dtype=float32), 'eval/episode_x_velocity_std': Array(47.8208, dtype=float32), 'eval/episode_y_position_std': Array(167.9749, dtype=float32), 'eval/episode_y_velocity_std': Array(46.900856, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.16208505630493, 'eval/sps': 940.056109944778, 'num_steps': 4423680}
{'eval/walltime': 7688.471353530884, 'training/sps': 511.03499334003, 'training/walltime': 8869.767653942108, 'training/entropy_loss': Array(0.01528559, dtype=float32), 'training/policy_loss': Array(0.04460732, dtype=float32), 'training/total_loss': Array(0.08460017, dtype=float32), 'training/v_loss': Array(0.02470726, dtype=float32), 'eval/episode_distance_from_origin': Array(4337.7793, dtype=float32), 'eval/episode_distance_reward': Array(8.844598, dtype=float32), 'eval/episode_forward_reward': Array(1474.094, dtype=float32), 'eval/episode_reward': Array(1347.7915, dtype=float32), 'eval/episode_reward_alive': Array(257.2578, dtype=float32), 'eval/episode_reward_linvel': Array(1474.094, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.40482, dtype=float32), 'eval/episode_x_position': Array(4299.2686, dtype=float32), 'eval/episode_x_velocity': Array(294.81882, dtype=float32), 'eval/episode_y_position': Array(-244.2207, dtype=float32), 'eval/episode_y_velocity': Array(-55.116844, dtype=float32), 'eval/episode_distance_from_origin_std': Array(145.84071, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4168518, dtype=float32), 'eval/episode_forward_reward_std': Array(236.13843, dtype=float32), 'eval/episode_reward_std': Array(264.09033, dtype=float32), 'eval/episode_reward_alive_std': Array(88.74428, dtype=float32), 'eval/episode_reward_linvel_std': Array(236.13843, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.11052, dtype=float32), 'eval/episode_x_position_std': Array(139.4568, dtype=float32), 'eval/episode_x_velocity_std': Array(47.227688, dtype=float32), 'eval/episode_y_position_std': Array(188.15034, dtype=float32), 'eval/episode_y_velocity_std': Array(50.259396, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3536458015442, 'eval/sps': 938.7354422946454, 'num_steps': 4505600}
{'eval/walltime': 7824.66937994957, 'training/sps': 510.0341661515953, 'training/walltime': 9030.384344816208, 'training/entropy_loss': Array(0.01481134, dtype=float32), 'training/policy_loss': Array(0.03242376, dtype=float32), 'training/total_loss': Array(0.06910267, dtype=float32), 'training/v_loss': Array(0.02186757, dtype=float32), 'eval/episode_distance_from_origin': Array(4355.804, dtype=float32), 'eval/episode_distance_reward': Array(9.082116, dtype=float32), 'eval/episode_forward_reward': Array(1513.6788, dtype=float32), 'eval/episode_reward': Array(1367.1333, dtype=float32), 'eval/episode_reward_alive': Array(237.25, dtype=float32), 'eval/episode_reward_linvel': Array(1513.6788, dtype=float32), 'eval/episode_reward_quadctrl': Array(-392.87793, dtype=float32), 'eval/episode_x_position': Array(4314.2925, dtype=float32), 'eval/episode_x_velocity': Array(302.73578, dtype=float32), 'eval/episode_y_position': Array(-292.66913, dtype=float32), 'eval/episode_y_velocity': Array(-67.966934, dtype=float32), 'eval/episode_distance_from_origin_std': Array(140.81409, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5963776, dtype=float32), 'eval/episode_forward_reward_std': Array(266.05954, dtype=float32), 'eval/episode_reward_std': Array(311.852, dtype=float32), 'eval/episode_reward_alive_std': Array(75.95864, dtype=float32), 'eval/episode_reward_linvel_std': Array(266.05954, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.40829, dtype=float32), 'eval/episode_x_position_std': Array(135.88725, dtype=float32), 'eval/episode_x_velocity_std': Array(53.211887, dtype=float32), 'eval/episode_y_position_std': Array(178.55412, dtype=float32), 'eval/episode_y_velocity_std': Array(48.659702, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1980264186859, 'eval/sps': 939.8080380879794, 'num_steps': 4587520}
{'eval/walltime': 7961.16935801506, 'training/sps': 510.3213944105382, 'training/walltime': 9190.91063451767, 'training/entropy_loss': Array(0.01700194, dtype=float32), 'training/policy_loss': Array(0.063985, dtype=float32), 'training/total_loss': Array(0.0993325, dtype=float32), 'training/v_loss': Array(0.01834558, dtype=float32), 'eval/episode_distance_from_origin': Array(4343.324, dtype=float32), 'eval/episode_distance_reward': Array(8.865208, dtype=float32), 'eval/episode_forward_reward': Array(1477.5283, dtype=float32), 'eval/episode_reward': Array(1375.6074, dtype=float32), 'eval/episode_reward_alive': Array(276.35156, dtype=float32), 'eval/episode_reward_linvel': Array(1477.5283, dtype=float32), 'eval/episode_reward_quadctrl': Array(-387.1377, dtype=float32), 'eval/episode_x_position': Array(4302.7803, dtype=float32), 'eval/episode_x_velocity': Array(295.50568, dtype=float32), 'eval/episode_y_position': Array(-249.54086, dtype=float32), 'eval/episode_y_velocity': Array(-54.45112, dtype=float32), 'eval/episode_distance_from_origin_std': Array(141.54422, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3795798, dtype=float32), 'eval/episode_forward_reward_std': Array(229.9267, dtype=float32), 'eval/episode_reward_std': Array(259.78406, dtype=float32), 'eval/episode_reward_alive_std': Array(87.243164, dtype=float32), 'eval/episode_reward_linvel_std': Array(229.9267, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.39675, dtype=float32), 'eval/episode_x_position_std': Array(134.42398, dtype=float32), 'eval/episode_x_velocity_std': Array(45.985302, dtype=float32), 'eval/episode_y_position_std': Array(214.32172, dtype=float32), 'eval/episode_y_velocity_std': Array(54.13345, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49997806549072, 'eval/sps': 937.7290884148526, 'num_steps': 4669440}
{'eval/walltime': 8097.742914676666, 'training/sps': 507.4246361867983, 'training/walltime': 9352.353327989578, 'training/entropy_loss': Array(0.01429814, dtype=float32), 'training/policy_loss': Array(0.03588253, dtype=float32), 'training/total_loss': Array(0.07318588, dtype=float32), 'training/v_loss': Array(0.02300521, dtype=float32), 'eval/episode_distance_from_origin': Array(4345.357, dtype=float32), 'eval/episode_distance_reward': Array(8.897413, dtype=float32), 'eval/episode_forward_reward': Array(1482.8953, dtype=float32), 'eval/episode_reward': Array(1404.5116, dtype=float32), 'eval/episode_reward_alive': Array(305.80078, dtype=float32), 'eval/episode_reward_linvel': Array(1482.8953, dtype=float32), 'eval/episode_reward_quadctrl': Array(-393.08167, dtype=float32), 'eval/episode_x_position': Array(4308.0347, dtype=float32), 'eval/episode_x_velocity': Array(296.57904, dtype=float32), 'eval/episode_y_position': Array(-217.29756, dtype=float32), 'eval/episode_y_velocity': Array(-44.43064, dtype=float32), 'eval/episode_distance_from_origin_std': Array(160.12773, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4208581, dtype=float32), 'eval/episode_forward_reward_std': Array(236.80634, dtype=float32), 'eval/episode_reward_std': Array(260.247, dtype=float32), 'eval/episode_reward_alive_std': Array(91.244865, dtype=float32), 'eval/episode_reward_linvel_std': Array(236.80634, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.647755, dtype=float32), 'eval/episode_x_position_std': Array(155.11821, dtype=float32), 'eval/episode_x_velocity_std': Array(47.361248, dtype=float32), 'eval/episode_y_position_std': Array(189.34203, dtype=float32), 'eval/episode_y_velocity_std': Array(47.764637, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.57355666160583, 'eval/sps': 937.2238896666585, 'num_steps': 4751360}
{'eval/walltime': 8234.079580068588, 'training/sps': 511.25050063053914, 'training/walltime': 9512.587889909744, 'training/entropy_loss': Array(0.01362337, dtype=float32), 'training/policy_loss': Array(0.09576908, dtype=float32), 'training/total_loss': Array(0.12767714, dtype=float32), 'training/v_loss': Array(0.01828469, dtype=float32), 'eval/episode_distance_from_origin': Array(4374.9126, dtype=float32), 'eval/episode_distance_reward': Array(9.262637, dtype=float32), 'eval/episode_forward_reward': Array(1543.7676, dtype=float32), 'eval/episode_reward': Array(1412.6094, dtype=float32), 'eval/episode_reward_alive': Array(188.22656, dtype=float32), 'eval/episode_reward_linvel': Array(1543.7676, dtype=float32), 'eval/episode_reward_quadctrl': Array(-328.6474, dtype=float32), 'eval/episode_x_position': Array(4338.2773, dtype=float32), 'eval/episode_x_velocity': Array(308.75354, dtype=float32), 'eval/episode_y_position': Array(-168.46521, dtype=float32), 'eval/episode_y_velocity': Array(-34.53411, dtype=float32), 'eval/episode_distance_from_origin_std': Array(179.32242, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7549101, dtype=float32), 'eval/episode_forward_reward_std': Array(292.48218, dtype=float32), 'eval/episode_reward_std': Array(329.12222, dtype=float32), 'eval/episode_reward_alive_std': Array(53.060913, dtype=float32), 'eval/episode_reward_linvel_std': Array(292.48218, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(56.993507, dtype=float32), 'eval/episode_x_position_std': Array(173.40067, dtype=float32), 'eval/episode_x_velocity_std': Array(58.49639, dtype=float32), 'eval/episode_y_position_std': Array(233.49277, dtype=float32), 'eval/episode_y_velocity_std': Array(56.61281, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.336665391922, 'eval/sps': 938.8523595765167, 'num_steps': 4833280}
{'eval/walltime': 8370.181489229202, 'training/sps': 507.48755765365087, 'training/walltime': 9674.010566711426, 'training/entropy_loss': Array(0.00745172, dtype=float32), 'training/policy_loss': Array(0.02232445, dtype=float32), 'training/total_loss': Array(0.05680148, dtype=float32), 'training/v_loss': Array(0.0270253, dtype=float32), 'eval/episode_distance_from_origin': Array(4369.953, dtype=float32), 'eval/episode_distance_reward': Array(9.19981, dtype=float32), 'eval/episode_forward_reward': Array(1533.2965, dtype=float32), 'eval/episode_reward': Array(1404.6807, dtype=float32), 'eval/episode_reward_alive': Array(185.32812, dtype=float32), 'eval/episode_reward_linvel': Array(1533.2965, dtype=float32), 'eval/episode_reward_quadctrl': Array(-323.1441, dtype=float32), 'eval/episode_x_position': Array(4333.3125, dtype=float32), 'eval/episode_x_velocity': Array(306.6593, dtype=float32), 'eval/episode_y_position': Array(-147.88524, dtype=float32), 'eval/episode_y_velocity': Array(-28.221233, dtype=float32), 'eval/episode_distance_from_origin_std': Array(168.29807, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7655948, dtype=float32), 'eval/episode_forward_reward_std': Array(294.2627, dtype=float32), 'eval/episode_reward_std': Array(327.21954, dtype=float32), 'eval/episode_reward_alive_std': Array(53.494648, dtype=float32), 'eval/episode_reward_linvel_std': Array(294.2627, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.48056, dtype=float32), 'eval/episode_x_position_std': Array(162.39531, dtype=float32), 'eval/episode_x_velocity_std': Array(58.852554, dtype=float32), 'eval/episode_y_position_std': Array(244.98254, dtype=float32), 'eval/episode_y_velocity_std': Array(59.790947, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.101909160614, 'eval/sps': 940.4717449550767, 'num_steps': 4915200}
{'eval/walltime': 8506.691256284714, 'training/sps': 511.793662289874, 'training/walltime': 9834.075073242188, 'training/entropy_loss': Array(0.00932939, dtype=float32), 'training/policy_loss': Array(0.02176375, dtype=float32), 'training/total_loss': Array(0.05437509, dtype=float32), 'training/v_loss': Array(0.02328196, dtype=float32), 'eval/episode_distance_from_origin': Array(4345.124, dtype=float32), 'eval/episode_distance_reward': Array(9.00486, dtype=float32), 'eval/episode_forward_reward': Array(1500.8042, dtype=float32), 'eval/episode_reward': Array(1369.8191, dtype=float32), 'eval/episode_reward_alive': Array(193.30469, dtype=float32), 'eval/episode_reward_linvel': Array(1500.8042, dtype=float32), 'eval/episode_reward_quadctrl': Array(-333.29456, dtype=float32), 'eval/episode_x_position': Array(4308.1294, dtype=float32), 'eval/episode_x_velocity': Array(300.16083, dtype=float32), 'eval/episode_y_position': Array(-150.95818, dtype=float32), 'eval/episode_y_velocity': Array(-30.288895, dtype=float32), 'eval/episode_distance_from_origin_std': Array(176.85759, dtype=float32), 'eval/episode_distance_reward_std': Array(1.646118, dtype=float32), 'eval/episode_forward_reward_std': Array(274.34973, dtype=float32), 'eval/episode_reward_std': Array(302.4807, dtype=float32), 'eval/episode_reward_alive_std': Array(58.510292, dtype=float32), 'eval/episode_reward_linvel_std': Array(274.34973, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(55.547413, dtype=float32), 'eval/episode_x_position_std': Array(169.53839, dtype=float32), 'eval/episode_x_velocity_std': Array(54.869946, dtype=float32), 'eval/episode_y_position_std': Array(246.60898, dtype=float32), 'eval/episode_y_velocity_std': Array(57.868546, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50976705551147, 'eval/sps': 937.6618447231618, 'num_steps': 4997120}
{'eval/walltime': 8642.910145044327, 'training/sps': 510.9047565096895, 'training/walltime': 9994.418070554733, 'training/entropy_loss': Array(0.00781459, dtype=float32), 'training/policy_loss': Array(0.01279849, dtype=float32), 'training/total_loss': Array(0.04951794, dtype=float32), 'training/v_loss': Array(0.02890485, dtype=float32), 'eval/episode_distance_from_origin': Array(4338.248, dtype=float32), 'eval/episode_distance_reward': Array(8.861023, dtype=float32), 'eval/episode_forward_reward': Array(1476.8322, dtype=float32), 'eval/episode_reward': Array(1329.1028, dtype=float32), 'eval/episode_reward_alive': Array(187.08984, dtype=float32), 'eval/episode_reward_linvel': Array(1476.8322, dtype=float32), 'eval/episode_reward_quadctrl': Array(-343.6801, dtype=float32), 'eval/episode_x_position': Array(4302.9775, dtype=float32), 'eval/episode_x_velocity': Array(295.3664, dtype=float32), 'eval/episode_y_position': Array(-108.737976, dtype=float32), 'eval/episode_y_velocity': Array(-23.554573, dtype=float32), 'eval/episode_distance_from_origin_std': Array(178.51715, dtype=float32), 'eval/episode_distance_reward_std': Array(1.674588, dtype=float32), 'eval/episode_forward_reward_std': Array(279.09482, dtype=float32), 'eval/episode_reward_std': Array(313.9346, dtype=float32), 'eval/episode_reward_alive_std': Array(48.079254, dtype=float32), 'eval/episode_reward_linvel_std': Array(279.09482, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(60.00406, dtype=float32), 'eval/episode_x_position_std': Array(172.16331, dtype=float32), 'eval/episode_x_velocity_std': Array(55.81895, dtype=float32), 'eval/episode_y_position_std': Array(243.02121, dtype=float32), 'eval/episode_y_velocity_std': Array(57.00461, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.21888875961304, 'eval/sps': 939.6641036022764, 'num_steps': 5079040}
{'eval/walltime': 8779.361516237259, 'training/sps': 512.5396864656602, 'training/walltime': 10154.249596118927, 'training/entropy_loss': Array(0.01139921, dtype=float32), 'training/policy_loss': Array(0.04891837, dtype=float32), 'training/total_loss': Array(0.08473922, dtype=float32), 'training/v_loss': Array(0.02442164, dtype=float32), 'eval/episode_distance_from_origin': Array(4324.028, dtype=float32), 'eval/episode_distance_reward': Array(8.807249, dtype=float32), 'eval/episode_forward_reward': Array(1467.8699, dtype=float32), 'eval/episode_reward': Array(1316.7119, dtype=float32), 'eval/episode_reward_alive': Array(202.40234, dtype=float32), 'eval/episode_reward_linvel': Array(1467.8699, dtype=float32), 'eval/episode_reward_quadctrl': Array(-362.3674, dtype=float32), 'eval/episode_x_position': Array(4290.2207, dtype=float32), 'eval/episode_x_velocity': Array(293.57394, dtype=float32), 'eval/episode_y_position': Array(-127.84743, dtype=float32), 'eval/episode_y_velocity': Array(-28.690586, dtype=float32), 'eval/episode_distance_from_origin_std': Array(175.27968, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5781752, dtype=float32), 'eval/episode_forward_reward_std': Array(263.0255, dtype=float32), 'eval/episode_reward_std': Array(297.26407, dtype=float32), 'eval/episode_reward_alive_std': Array(60.336884, dtype=float32), 'eval/episode_reward_linvel_std': Array(263.0255, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(65.21279, dtype=float32), 'eval/episode_x_position_std': Array(171.92047, dtype=float32), 'eval/episode_x_velocity_std': Array(52.6051, dtype=float32), 'eval/episode_y_position_std': Array(201.74855, dtype=float32), 'eval/episode_y_velocity_std': Array(51.9772, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.45137119293213, 'eval/sps': 938.0631274054218, 'num_steps': 5160960}
{'eval/walltime': 8915.646109342575, 'training/sps': 508.30340298997106, 'training/walltime': 10315.413183689117, 'training/entropy_loss': Array(0.0113399, dtype=float32), 'training/policy_loss': Array(0.02813564, dtype=float32), 'training/total_loss': Array(0.06415883, dtype=float32), 'training/v_loss': Array(0.02468328, dtype=float32), 'eval/episode_distance_from_origin': Array(4278.743, dtype=float32), 'eval/episode_distance_reward': Array(8.345353, dtype=float32), 'eval/episode_forward_reward': Array(1390.8882, dtype=float32), 'eval/episode_reward': Array(1227.5752, dtype=float32), 'eval/episode_reward_alive': Array(190.9414, dtype=float32), 'eval/episode_reward_linvel': Array(1390.8882, dtype=float32), 'eval/episode_reward_quadctrl': Array(-362.59967, dtype=float32), 'eval/episode_x_position': Array(4245.0796, dtype=float32), 'eval/episode_x_velocity': Array(278.17764, dtype=float32), 'eval/episode_y_position': Array(-93.865974, dtype=float32), 'eval/episode_y_velocity': Array(-21.454954, dtype=float32), 'eval/episode_distance_from_origin_std': Array(188.21861, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5896338, dtype=float32), 'eval/episode_forward_reward_std': Array(264.9359, dtype=float32), 'eval/episode_reward_std': Array(296.70535, dtype=float32), 'eval/episode_reward_alive_std': Array(66.203514, dtype=float32), 'eval/episode_reward_linvel_std': Array(264.9359, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(67.870415, dtype=float32), 'eval/episode_x_position_std': Array(183.28201, dtype=float32), 'eval/episode_x_velocity_std': Array(52.987198, dtype=float32), 'eval/episode_y_position_std': Array(214.81136, dtype=float32), 'eval/episode_y_velocity_std': Array(54.775253, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.28459310531616, 'eval/sps': 939.2110808966197, 'num_steps': 5242880}
{'eval/walltime': 9051.85395026207, 'training/sps': 510.2793561794358, 'training/walltime': 10475.952697992325, 'training/entropy_loss': Array(0.01211683, dtype=float32), 'training/policy_loss': Array(0.03074419, dtype=float32), 'training/total_loss': Array(0.06534991, dtype=float32), 'training/v_loss': Array(0.02248889, dtype=float32), 'eval/episode_distance_from_origin': Array(4349.26, dtype=float32), 'eval/episode_distance_reward': Array(8.943275, dtype=float32), 'eval/episode_forward_reward': Array(1490.54, dtype=float32), 'eval/episode_reward': Array(1335.2185, dtype=float32), 'eval/episode_reward_alive': Array(208.1875, dtype=float32), 'eval/episode_reward_linvel': Array(1490.54, dtype=float32), 'eval/episode_reward_quadctrl': Array(-372.45224, dtype=float32), 'eval/episode_x_position': Array(4312.331, dtype=float32), 'eval/episode_x_velocity': Array(298.108, dtype=float32), 'eval/episode_y_position': Array(-159.92183, dtype=float32), 'eval/episode_y_velocity': Array(-37.93836, dtype=float32), 'eval/episode_distance_from_origin_std': Array(188.44077, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6637418, dtype=float32), 'eval/episode_forward_reward_std': Array(277.2869, dtype=float32), 'eval/episode_reward_std': Array(310.19742, dtype=float32), 'eval/episode_reward_alive_std': Array(62.760178, dtype=float32), 'eval/episode_reward_linvel_std': Array(277.2869, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.06844, dtype=float32), 'eval/episode_x_position_std': Array(180.06978, dtype=float32), 'eval/episode_x_velocity_std': Array(55.457317, dtype=float32), 'eval/episode_y_position_std': Array(245.07875, dtype=float32), 'eval/episode_y_velocity_std': Array(62.247883, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20784091949463, 'eval/sps': 939.7403199104679, 'num_steps': 5324800}
{'eval/walltime': 9188.201548576355, 'training/sps': 510.251194105664, 'training/walltime': 10636.501072883606, 'training/entropy_loss': Array(0.01356097, dtype=float32), 'training/policy_loss': Array(0.04405058, dtype=float32), 'training/total_loss': Array(0.07740444, dtype=float32), 'training/v_loss': Array(0.01979289, dtype=float32), 'eval/episode_distance_from_origin': Array(4397.676, dtype=float32), 'eval/episode_distance_reward': Array(9.240474, dtype=float32), 'eval/episode_forward_reward': Array(1540.0732, dtype=float32), 'eval/episode_reward': Array(1382.3777, dtype=float32), 'eval/episode_reward_alive': Array(196.63281, dtype=float32), 'eval/episode_reward_linvel': Array(1540.0732, dtype=float32), 'eval/episode_reward_quadctrl': Array(-363.56897, dtype=float32), 'eval/episode_x_position': Array(4356.707, dtype=float32), 'eval/episode_x_velocity': Array(308.01468, dtype=float32), 'eval/episode_y_position': Array(-215.7739, dtype=float32), 'eval/episode_y_velocity': Array(-49.333427, dtype=float32), 'eval/episode_distance_from_origin_std': Array(185.18582, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7236301, dtype=float32), 'eval/episode_forward_reward_std': Array(287.26816, dtype=float32), 'eval/episode_reward_std': Array(321.6932, dtype=float32), 'eval/episode_reward_alive_std': Array(53.567295, dtype=float32), 'eval/episode_reward_linvel_std': Array(287.26816, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(59.21649, dtype=float32), 'eval/episode_x_position_std': Array(176.03793, dtype=float32), 'eval/episode_x_velocity_std': Array(57.45365, dtype=float32), 'eval/episode_y_position_std': Array(268.69016, dtype=float32), 'eval/episode_y_velocity_std': Array(65.4029, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34759831428528, 'eval/sps': 938.777078456169, 'num_steps': 5406720}
{'eval/walltime': 9324.573465824127, 'training/sps': 511.5273189564528, 'training/walltime': 10796.648922204971, 'training/entropy_loss': Array(0.01048189, dtype=float32), 'training/policy_loss': Array(0.02517427, dtype=float32), 'training/total_loss': Array(0.0617272, dtype=float32), 'training/v_loss': Array(0.02607104, dtype=float32), 'eval/episode_distance_from_origin': Array(4456.4424, dtype=float32), 'eval/episode_distance_reward': Array(9.768103, dtype=float32), 'eval/episode_forward_reward': Array(1628.01, dtype=float32), 'eval/episode_reward': Array(1483.7036, dtype=float32), 'eval/episode_reward_alive': Array(209.5, dtype=float32), 'eval/episode_reward_linvel': Array(1628.01, dtype=float32), 'eval/episode_reward_quadctrl': Array(-363.57452, dtype=float32), 'eval/episode_x_position': Array(4414.8203, dtype=float32), 'eval/episode_x_velocity': Array(325.602, dtype=float32), 'eval/episode_y_position': Array(-269.3239, dtype=float32), 'eval/episode_y_velocity': Array(-59.11878, dtype=float32), 'eval/episode_distance_from_origin_std': Array(176.6918, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6772678, dtype=float32), 'eval/episode_forward_reward_std': Array(279.5416, dtype=float32), 'eval/episode_reward_std': Array(317.70944, dtype=float32), 'eval/episode_reward_alive_std': Array(59.371872, dtype=float32), 'eval/episode_reward_linvel_std': Array(279.5416, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(54.540897, dtype=float32), 'eval/episode_x_position_std': Array(167.62042, dtype=float32), 'eval/episode_x_velocity_std': Array(55.9083, dtype=float32), 'eval/episode_y_position_std': Array(235.37764, dtype=float32), 'eval/episode_y_velocity_std': Array(59.317867, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37191724777222, 'eval/sps': 938.6096682019847, 'num_steps': 5488640}
{'eval/walltime': 9460.866895914078, 'training/sps': 507.3893240819981, 'training/walltime': 10958.102851390839, 'training/entropy_loss': Array(0.01304376, dtype=float32), 'training/policy_loss': Array(0.04196486, dtype=float32), 'training/total_loss': Array(0.07939157, dtype=float32), 'training/v_loss': Array(0.02438295, dtype=float32), 'eval/episode_distance_from_origin': Array(4405.8813, dtype=float32), 'eval/episode_distance_reward': Array(9.453985, dtype=float32), 'eval/episode_forward_reward': Array(1575.6577, dtype=float32), 'eval/episode_reward': Array(1428.9087, dtype=float32), 'eval/episode_reward_alive': Array(203.71484, dtype=float32), 'eval/episode_reward_linvel': Array(1575.6577, dtype=float32), 'eval/episode_reward_quadctrl': Array(-359.91776, dtype=float32), 'eval/episode_x_position': Array(4367.5986, dtype=float32), 'eval/episode_x_velocity': Array(315.13153, dtype=float32), 'eval/episode_y_position': Array(-200.78452, dtype=float32), 'eval/episode_y_velocity': Array(-42.90561, dtype=float32), 'eval/episode_distance_from_origin_std': Array(177.9144, dtype=float32), 'eval/episode_distance_reward_std': Array(1.693334, dtype=float32), 'eval/episode_forward_reward_std': Array(282.21902, dtype=float32), 'eval/episode_reward_std': Array(317.6341, dtype=float32), 'eval/episode_reward_alive_std': Array(57.3548, dtype=float32), 'eval/episode_reward_linvel_std': Array(282.21902, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(49.48074, dtype=float32), 'eval/episode_x_position_std': Array(170.71066, dtype=float32), 'eval/episode_x_velocity_std': Array(56.44381, dtype=float32), 'eval/episode_y_position_std': Array(240.62704, dtype=float32), 'eval/episode_y_velocity_std': Array(59.14058, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.29343008995056, 'eval/sps': 939.1501843891001, 'num_steps': 5570560}
{'eval/walltime': 9597.311378479004, 'training/sps': 508.9436698604804, 'training/walltime': 11119.063690185547, 'training/entropy_loss': Array(0.01114841, dtype=float32), 'training/policy_loss': Array(0.02210628, dtype=float32), 'training/total_loss': Array(0.06122177, dtype=float32), 'training/v_loss': Array(0.02796708, dtype=float32), 'eval/episode_distance_from_origin': Array(4456.796, dtype=float32), 'eval/episode_distance_reward': Array(9.788065, dtype=float32), 'eval/episode_forward_reward': Array(1631.3367, dtype=float32), 'eval/episode_reward': Array(1495.5743, dtype=float32), 'eval/episode_reward_alive': Array(217.32422, dtype=float32), 'eval/episode_reward_linvel': Array(1631.3367, dtype=float32), 'eval/episode_reward_quadctrl': Array(-362.87506, dtype=float32), 'eval/episode_x_position': Array(4416.2124, dtype=float32), 'eval/episode_x_velocity': Array(326.2674, dtype=float32), 'eval/episode_y_position': Array(-266.02313, dtype=float32), 'eval/episode_y_velocity': Array(-58.213043, dtype=float32), 'eval/episode_distance_from_origin_std': Array(148.90004, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3955654, dtype=float32), 'eval/episode_forward_reward_std': Array(232.59105, dtype=float32), 'eval/episode_reward_std': Array(262.71823, dtype=float32), 'eval/episode_reward_alive_std': Array(65.56123, dtype=float32), 'eval/episode_reward_linvel_std': Array(232.59105, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(50.968674, dtype=float32), 'eval/episode_x_position_std': Array(142.79518, dtype=float32), 'eval/episode_x_velocity_std': Array(46.518208, dtype=float32), 'eval/episode_y_position_std': Array(219.98242, dtype=float32), 'eval/episode_y_velocity_std': Array(50.675728, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.44448256492615, 'eval/sps': 938.1104870920091, 'num_steps': 5652480}
{'eval/walltime': 9733.632662773132, 'training/sps': 510.1056085502475, 'training/walltime': 11279.65788602829, 'training/entropy_loss': Array(0.01429294, dtype=float32), 'training/policy_loss': Array(0.10514319, dtype=float32), 'training/total_loss': Array(0.14052245, dtype=float32), 'training/v_loss': Array(0.02108632, dtype=float32), 'eval/episode_distance_from_origin': Array(4467.005, dtype=float32), 'eval/episode_distance_reward': Array(9.868357, dtype=float32), 'eval/episode_forward_reward': Array(1644.7177, dtype=float32), 'eval/episode_reward': Array(1554.429, dtype=float32), 'eval/episode_reward_alive': Array(297.46484, dtype=float32), 'eval/episode_reward_linvel': Array(1644.7177, dtype=float32), 'eval/episode_reward_quadctrl': Array(-397.62207, dtype=float32), 'eval/episode_x_position': Array(4425.0645, dtype=float32), 'eval/episode_x_velocity': Array(328.94348, dtype=float32), 'eval/episode_y_position': Array(-249.47331, dtype=float32), 'eval/episode_y_velocity': Array(-51.9582, dtype=float32), 'eval/episode_distance_from_origin_std': Array(169.81305, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6567731, dtype=float32), 'eval/episode_forward_reward_std': Array(276.1249, dtype=float32), 'eval/episode_reward_std': Array(286.7623, dtype=float32), 'eval/episode_reward_alive_std': Array(73.82335, dtype=float32), 'eval/episode_reward_linvel_std': Array(276.1249, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.832752, dtype=float32), 'eval/episode_x_position_std': Array(163.31883, dtype=float32), 'eval/episode_x_velocity_std': Array(55.22499, dtype=float32), 'eval/episode_y_position_std': Array(251.56952, dtype=float32), 'eval/episode_y_velocity_std': Array(62.251846, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.32128429412842, 'eval/sps': 938.9582900629492, 'num_steps': 5734400}
{'eval/walltime': 9870.368555307388, 'training/sps': 509.55549917809304, 'training/walltime': 11440.425457239151, 'training/entropy_loss': Array(0.01590367, dtype=float32), 'training/policy_loss': Array(0.05175538, dtype=float32), 'training/total_loss': Array(0.09371984, dtype=float32), 'training/v_loss': Array(0.02606079, dtype=float32), 'eval/episode_distance_from_origin': Array(4473.7695, dtype=float32), 'eval/episode_distance_reward': Array(9.897142, dtype=float32), 'eval/episode_forward_reward': Array(1649.5157, dtype=float32), 'eval/episode_reward': Array(1588.5028, dtype=float32), 'eval/episode_reward_alive': Array(330.41016, dtype=float32), 'eval/episode_reward_linvel': Array(1649.5157, dtype=float32), 'eval/episode_reward_quadctrl': Array(-401.3202, dtype=float32), 'eval/episode_x_position': Array(4431.2783, dtype=float32), 'eval/episode_x_velocity': Array(329.90317, dtype=float32), 'eval/episode_y_position': Array(-252.63516, dtype=float32), 'eval/episode_y_velocity': Array(-51.3763, dtype=float32), 'eval/episode_distance_from_origin_std': Array(184.9784, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7003567, dtype=float32), 'eval/episode_forward_reward_std': Array(283.38962, dtype=float32), 'eval/episode_reward_std': Array(299.19687, dtype=float32), 'eval/episode_reward_alive_std': Array(68.195335, dtype=float32), 'eval/episode_reward_linvel_std': Array(283.38962, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.715645, dtype=float32), 'eval/episode_x_position_std': Array(177.83145, dtype=float32), 'eval/episode_x_velocity_std': Array(56.6779, dtype=float32), 'eval/episode_y_position_std': Array(258.93613, dtype=float32), 'eval/episode_y_velocity_std': Array(62.8568, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.73589253425598, 'eval/sps': 936.1111967578856, 'num_steps': 5816320}
{'eval/walltime': 10006.64262843132, 'training/sps': 510.98448433172376, 'training/walltime': 11600.743436574936, 'training/entropy_loss': Array(0.01584653, dtype=float32), 'training/policy_loss': Array(0.10287762, dtype=float32), 'training/total_loss': Array(0.13942786, dtype=float32), 'training/v_loss': Array(0.0207037, dtype=float32), 'eval/episode_distance_from_origin': Array(4453.5996, dtype=float32), 'eval/episode_distance_reward': Array(9.71143, dtype=float32), 'eval/episode_forward_reward': Array(1618.5642, dtype=float32), 'eval/episode_reward': Array(1449.7876, dtype=float32), 'eval/episode_reward_alive': Array(268.1328, dtype=float32), 'eval/episode_reward_linvel': Array(1618.5642, dtype=float32), 'eval/episode_reward_quadctrl': Array(-446.62115, dtype=float32), 'eval/episode_x_position': Array(4409.9478, dtype=float32), 'eval/episode_x_velocity': Array(323.71286, dtype=float32), 'eval/episode_y_position': Array(-293.83554, dtype=float32), 'eval/episode_y_velocity': Array(-62.99865, dtype=float32), 'eval/episode_distance_from_origin_std': Array(173.70058, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6922438, dtype=float32), 'eval/episode_forward_reward_std': Array(282.0371, dtype=float32), 'eval/episode_reward_std': Array(315.18408, dtype=float32), 'eval/episode_reward_alive_std': Array(81.00597, dtype=float32), 'eval/episode_reward_linvel_std': Array(282.0371, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.350822, dtype=float32), 'eval/episode_x_position_std': Array(163.79152, dtype=float32), 'eval/episode_x_velocity_std': Array(56.407406, dtype=float32), 'eval/episode_y_position_std': Array(238.1374, dtype=float32), 'eval/episode_y_velocity_std': Array(57.147305, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.27407312393188, 'eval/sps': 939.2835853933332, 'num_steps': 5898240}
{'eval/walltime': 10143.150252342224, 'training/sps': 510.4724141570773, 'training/walltime': 11761.222235679626, 'training/entropy_loss': Array(0.01912161, dtype=float32), 'training/policy_loss': Array(0.04953679, dtype=float32), 'training/total_loss': Array(0.08689225, dtype=float32), 'training/v_loss': Array(0.01823385, dtype=float32), 'eval/episode_distance_from_origin': Array(4437.059, dtype=float32), 'eval/episode_distance_reward': Array(9.571402, dtype=float32), 'eval/episode_forward_reward': Array(1595.2267, dtype=float32), 'eval/episode_reward': Array(1412.5077, dtype=float32), 'eval/episode_reward_alive': Array(260.5586, dtype=float32), 'eval/episode_reward_linvel': Array(1595.2267, dtype=float32), 'eval/episode_reward_quadctrl': Array(-452.8491, dtype=float32), 'eval/episode_x_position': Array(4394.716, dtype=float32), 'eval/episode_x_velocity': Array(319.04538, dtype=float32), 'eval/episode_y_position': Array(-272.65753, dtype=float32), 'eval/episode_y_velocity': Array(-57.807137, dtype=float32), 'eval/episode_distance_from_origin_std': Array(192.80861, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7582793, dtype=float32), 'eval/episode_forward_reward_std': Array(293.04272, dtype=float32), 'eval/episode_reward_std': Array(321.20642, dtype=float32), 'eval/episode_reward_alive_std': Array(84.10837, dtype=float32), 'eval/episode_reward_linvel_std': Array(293.04272, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.552124, dtype=float32), 'eval/episode_x_position_std': Array(182.20598, dtype=float32), 'eval/episode_x_velocity_std': Array(58.608585, dtype=float32), 'eval/episode_y_position_std': Array(243.53268, dtype=float32), 'eval/episode_y_velocity_std': Array(57.49753, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.50762391090393, 'eval/sps': 937.6765658417972, 'num_steps': 5980160}
{'eval/walltime': 10279.4406645298, 'training/sps': 508.06042325227384, 'training/walltime': 11922.462899684906, 'training/entropy_loss': Array(0.01517961, dtype=float32), 'training/policy_loss': Array(0.03668386, dtype=float32), 'training/total_loss': Array(0.0711218, dtype=float32), 'training/v_loss': Array(0.01925834, dtype=float32), 'eval/episode_distance_from_origin': Array(4475.1045, dtype=float32), 'eval/episode_distance_reward': Array(9.935032, dtype=float32), 'eval/episode_forward_reward': Array(1655.8301, dtype=float32), 'eval/episode_reward': Array(1515.1952, dtype=float32), 'eval/episode_reward_alive': Array(293.89062, dtype=float32), 'eval/episode_reward_linvel': Array(1655.8301, dtype=float32), 'eval/episode_reward_quadctrl': Array(-444.46057, dtype=float32), 'eval/episode_x_position': Array(4433.489, dtype=float32), 'eval/episode_x_velocity': Array(331.16602, dtype=float32), 'eval/episode_y_position': Array(-259.48425, dtype=float32), 'eval/episode_y_velocity': Array(-51.145477, dtype=float32), 'eval/episode_distance_from_origin_std': Array(174.80127, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5914012, dtype=float32), 'eval/episode_forward_reward_std': Array(265.2309, dtype=float32), 'eval/episode_reward_std': Array(298.91504, dtype=float32), 'eval/episode_reward_alive_std': Array(80.28221, dtype=float32), 'eval/episode_reward_linvel_std': Array(265.2309, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.030037, dtype=float32), 'eval/episode_x_position_std': Array(163.97914, dtype=float32), 'eval/episode_x_velocity_std': Array(53.046112, dtype=float32), 'eval/episode_y_position_std': Array(244.90001, dtype=float32), 'eval/episode_y_velocity_std': Array(61.47751, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2904121875763, 'eval/sps': 939.1709801554771, 'num_steps': 6062080}
{'eval/walltime': 10415.930252313614, 'training/sps': 511.7375407681698, 'training/walltime': 12082.544960260391, 'training/entropy_loss': Array(0.01709862, dtype=float32), 'training/policy_loss': Array(0.0753411, dtype=float32), 'training/total_loss': Array(0.11027349, dtype=float32), 'training/v_loss': Array(0.01783377, dtype=float32), 'eval/episode_distance_from_origin': Array(4489.918, dtype=float32), 'eval/episode_distance_reward': Array(9.974733, dtype=float32), 'eval/episode_forward_reward': Array(1662.4478, dtype=float32), 'eval/episode_reward': Array(1541.34, dtype=float32), 'eval/episode_reward_alive': Array(300.9414, dtype=float32), 'eval/episode_reward_linvel': Array(1662.4478, dtype=float32), 'eval/episode_reward_quadctrl': Array(-432.0239, dtype=float32), 'eval/episode_x_position': Array(4447.0986, dtype=float32), 'eval/episode_x_velocity': Array(332.48956, dtype=float32), 'eval/episode_y_position': Array(-269.0523, dtype=float32), 'eval/episode_y_velocity': Array(-50.300804, dtype=float32), 'eval/episode_distance_from_origin_std': Array(146.00304, dtype=float32), 'eval/episode_distance_reward_std': Array(1.3344665, dtype=float32), 'eval/episode_forward_reward_std': Array(222.40817, dtype=float32), 'eval/episode_reward_std': Array(237.64882, dtype=float32), 'eval/episode_reward_alive_std': Array(82.94418, dtype=float32), 'eval/episode_reward_linvel_std': Array(222.40817, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.08843, dtype=float32), 'eval/episode_x_position_std': Array(139.09694, dtype=float32), 'eval/episode_x_velocity_std': Array(44.48167, dtype=float32), 'eval/episode_y_position_std': Array(248.97495, dtype=float32), 'eval/episode_y_velocity_std': Array(61.045742, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.48958778381348, 'eval/sps': 937.8004731228277, 'num_steps': 6144000}
{'eval/walltime': 10552.404376268387, 'training/sps': 506.43377150726633, 'training/walltime': 12244.303524971008, 'training/entropy_loss': Array(0.01250949, dtype=float32), 'training/policy_loss': Array(0.04744915, dtype=float32), 'training/total_loss': Array(0.08559403, dtype=float32), 'training/v_loss': Array(0.0256354, dtype=float32), 'eval/episode_distance_from_origin': Array(4404.2305, dtype=float32), 'eval/episode_distance_reward': Array(9.262606, dtype=float32), 'eval/episode_forward_reward': Array(1543.762, dtype=float32), 'eval/episode_reward': Array(1361.9751, dtype=float32), 'eval/episode_reward_alive': Array(266.58594, dtype=float32), 'eval/episode_reward_linvel': Array(1543.762, dtype=float32), 'eval/episode_reward_quadctrl': Array(-457.63544, dtype=float32), 'eval/episode_x_position': Array(4365.6787, dtype=float32), 'eval/episode_x_velocity': Array(308.75238, dtype=float32), 'eval/episode_y_position': Array(-217.03377, dtype=float32), 'eval/episode_y_velocity': Array(-35.797745, dtype=float32), 'eval/episode_distance_from_origin_std': Array(141.03828, dtype=float32), 'eval/episode_distance_reward_std': Array(1.2973261, dtype=float32), 'eval/episode_forward_reward_std': Array(216.218, dtype=float32), 'eval/episode_reward_std': Array(255.10683, dtype=float32), 'eval/episode_reward_alive_std': Array(86.923195, dtype=float32), 'eval/episode_reward_linvel_std': Array(216.218, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(48.93582, dtype=float32), 'eval/episode_x_position_std': Array(134.70657, dtype=float32), 'eval/episode_x_velocity_std': Array(43.24362, dtype=float32), 'eval/episode_y_position_std': Array(223.69843, dtype=float32), 'eval/episode_y_velocity_std': Array(54.50028, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.47412395477295, 'eval/sps': 937.9067349237483, 'num_steps': 6225920}
{'eval/walltime': 10688.783027648926, 'training/sps': 511.7266429106735, 'training/walltime': 12404.388994693756, 'training/entropy_loss': Array(0.01685085, dtype=float32), 'training/policy_loss': Array(0.07231499, dtype=float32), 'training/total_loss': Array(0.10916464, dtype=float32), 'training/v_loss': Array(0.0199988, dtype=float32), 'eval/episode_distance_from_origin': Array(4419.6973, dtype=float32), 'eval/episode_distance_reward': Array(9.529572, dtype=float32), 'eval/episode_forward_reward': Array(1588.2552, dtype=float32), 'eval/episode_reward': Array(1419.9393, dtype=float32), 'eval/episode_reward_alive': Array(268.90234, dtype=float32), 'eval/episode_reward_linvel': Array(1588.2552, dtype=float32), 'eval/episode_reward_quadctrl': Array(-446.74796, dtype=float32), 'eval/episode_x_position': Array(4378.415, dtype=float32), 'eval/episode_x_velocity': Array(317.65103, dtype=float32), 'eval/episode_y_position': Array(-260.7048, dtype=float32), 'eval/episode_y_velocity': Array(-44.227234, dtype=float32), 'eval/episode_distance_from_origin_std': Array(145.85571, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4911866, dtype=float32), 'eval/episode_forward_reward_std': Array(248.52808, dtype=float32), 'eval/episode_reward_std': Array(296.0236, dtype=float32), 'eval/episode_reward_alive_std': Array(80.51936, dtype=float32), 'eval/episode_reward_linvel_std': Array(248.52808, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(52.57004, dtype=float32), 'eval/episode_x_position_std': Array(137.03548, dtype=float32), 'eval/episode_x_velocity_std': Array(49.7056, dtype=float32), 'eval/episode_y_position_std': Array(224.52866, dtype=float32), 'eval/episode_y_velocity_std': Array(55.438892, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37865138053894, 'eval/sps': 938.5633213430166, 'num_steps': 6307840}
{'eval/walltime': 10825.160691738129, 'training/sps': 507.7058449326877, 'training/walltime': 12565.74226808548, 'training/entropy_loss': Array(0.01349601, dtype=float32), 'training/policy_loss': Array(0.02211763, dtype=float32), 'training/total_loss': Array(0.05824888, dtype=float32), 'training/v_loss': Array(0.02263524, dtype=float32), 'eval/episode_distance_from_origin': Array(4449.1963, dtype=float32), 'eval/episode_distance_reward': Array(9.681251, dtype=float32), 'eval/episode_forward_reward': Array(1613.5345, dtype=float32), 'eval/episode_reward': Array(1469.7336, dtype=float32), 'eval/episode_reward_alive': Array(298.6172, dtype=float32), 'eval/episode_reward_linvel': Array(1613.5345, dtype=float32), 'eval/episode_reward_quadctrl': Array(-452.09924, dtype=float32), 'eval/episode_x_position': Array(4408.004, dtype=float32), 'eval/episode_x_velocity': Array(322.7069, dtype=float32), 'eval/episode_y_position': Array(-264.7547, dtype=float32), 'eval/episode_y_velocity': Array(-45.52188, dtype=float32), 'eval/episode_distance_from_origin_std': Array(148.38205, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4448109, dtype=float32), 'eval/episode_forward_reward_std': Array(240.79887, dtype=float32), 'eval/episode_reward_std': Array(289.32242, dtype=float32), 'eval/episode_reward_alive_std': Array(82.222176, dtype=float32), 'eval/episode_reward_linvel_std': Array(240.79887, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(47.843945, dtype=float32), 'eval/episode_x_position_std': Array(142.09383, dtype=float32), 'eval/episode_x_velocity_std': Array(48.159782, dtype=float32), 'eval/episode_y_position_std': Array(219.44423, dtype=float32), 'eval/episode_y_velocity_std': Array(54.74645, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37766408920288, 'eval/sps': 938.5701159705803, 'num_steps': 6389760}
{'eval/walltime': 10961.47259259224, 'training/sps': 510.79149223553185, 'training/walltime': 12726.12082028389, 'training/entropy_loss': Array(0.01494626, dtype=float32), 'training/policy_loss': Array(0.05671722, dtype=float32), 'training/total_loss': Array(0.08979645, dtype=float32), 'training/v_loss': Array(0.01813296, dtype=float32), 'eval/episode_distance_from_origin': Array(4447.0586, dtype=float32), 'eval/episode_distance_reward': Array(9.5518265, dtype=float32), 'eval/episode_forward_reward': Array(1591.9698, dtype=float32), 'eval/episode_reward': Array(1538.1299, dtype=float32), 'eval/episode_reward_alive': Array(374.48438, dtype=float32), 'eval/episode_reward_linvel': Array(1591.9698, dtype=float32), 'eval/episode_reward_quadctrl': Array(-437.8761, dtype=float32), 'eval/episode_x_position': Array(4404.6357, dtype=float32), 'eval/episode_x_velocity': Array(318.39398, dtype=float32), 'eval/episode_y_position': Array(-213.23328, dtype=float32), 'eval/episode_y_velocity': Array(-16.85154, dtype=float32), 'eval/episode_distance_from_origin_std': Array(165.27948, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5432314, dtype=float32), 'eval/episode_forward_reward_std': Array(257.20264, dtype=float32), 'eval/episode_reward_std': Array(258.7348, dtype=float32), 'eval/episode_reward_alive_std': Array(46.92422, dtype=float32), 'eval/episode_reward_linvel_std': Array(257.20264, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(45.14009, dtype=float32), 'eval/episode_x_position_std': Array(161.3005, dtype=float32), 'eval/episode_x_velocity_std': Array(51.44054, dtype=float32), 'eval/episode_y_position_std': Array(261.12253, dtype=float32), 'eval/episode_y_velocity_std': Array(63.39475, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.31190085411072, 'eval/sps': 939.0229260832726, 'num_steps': 6471680}
{'eval/walltime': 11097.680520057678, 'training/sps': 507.4584520250177, 'training/walltime': 12887.552755594254, 'training/entropy_loss': Array(0.01209009, dtype=float32), 'training/policy_loss': Array(0.03386027, dtype=float32), 'training/total_loss': Array(0.06598413, dtype=float32), 'training/v_loss': Array(0.02003377, dtype=float32), 'eval/episode_distance_from_origin': Array(4462.2656, dtype=float32), 'eval/episode_distance_reward': Array(9.690029, dtype=float32), 'eval/episode_forward_reward': Array(1615.0046, dtype=float32), 'eval/episode_reward': Array(1563.3308, dtype=float32), 'eval/episode_reward_alive': Array(372.8789, dtype=float32), 'eval/episode_reward_linvel': Array(1615.0046, dtype=float32), 'eval/episode_reward_quadctrl': Array(-434.2427, dtype=float32), 'eval/episode_x_position': Array(4420.8574, dtype=float32), 'eval/episode_x_velocity': Array(323.00092, dtype=float32), 'eval/episode_y_position': Array(-199.95969, dtype=float32), 'eval/episode_y_velocity': Array(-6.2070513, dtype=float32), 'eval/episode_distance_from_origin_std': Array(156.66252, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7023566, dtype=float32), 'eval/episode_forward_reward_std': Array(283.72202, dtype=float32), 'eval/episode_reward_std': Array(288.86984, dtype=float32), 'eval/episode_reward_alive_std': Array(52.449257, dtype=float32), 'eval/episode_reward_linvel_std': Array(283.72202, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.81462, dtype=float32), 'eval/episode_x_position_std': Array(151.76292, dtype=float32), 'eval/episode_x_velocity_std': Array(56.744392, dtype=float32), 'eval/episode_y_position_std': Array(244.52492, dtype=float32), 'eval/episode_y_velocity_std': Array(62.935616, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20792746543884, 'eval/sps': 939.7397228034212, 'num_steps': 6553600}
{'eval/walltime': 11233.945183515549, 'training/sps': 512.267695125943, 'training/walltime': 13047.469144582748, 'training/entropy_loss': Array(0.012089, dtype=float32), 'training/policy_loss': Array(0.03915739, dtype=float32), 'training/total_loss': Array(0.0697936, dtype=float32), 'training/v_loss': Array(0.01854721, dtype=float32), 'eval/episode_distance_from_origin': Array(4455.976, dtype=float32), 'eval/episode_distance_reward': Array(9.757002, dtype=float32), 'eval/episode_forward_reward': Array(1626.1643, dtype=float32), 'eval/episode_reward': Array(1577.0393, dtype=float32), 'eval/episode_reward_alive': Array(372.71875, dtype=float32), 'eval/episode_reward_linvel': Array(1626.1643, dtype=float32), 'eval/episode_reward_quadctrl': Array(-431.60062, dtype=float32), 'eval/episode_x_position': Array(4415.496, dtype=float32), 'eval/episode_x_velocity': Array(325.23285, dtype=float32), 'eval/episode_y_position': Array(-189.58932, dtype=float32), 'eval/episode_y_velocity': Array(-4.8772125, dtype=float32), 'eval/episode_distance_from_origin_std': Array(149.09392, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6590677, dtype=float32), 'eval/episode_forward_reward_std': Array(276.5076, dtype=float32), 'eval/episode_reward_std': Array(288.29553, dtype=float32), 'eval/episode_reward_alive_std': Array(43.192642, dtype=float32), 'eval/episode_reward_linvel_std': Array(276.5076, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(44.817097, dtype=float32), 'eval/episode_x_position_std': Array(144.48044, dtype=float32), 'eval/episode_x_velocity_std': Array(55.30153, dtype=float32), 'eval/episode_y_position_std': Array(235.80302, dtype=float32), 'eval/episode_y_velocity_std': Array(59.735565, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.26466345787048, 'eval/sps': 939.3484469990585, 'num_steps': 6635520}
{'eval/walltime': 11370.179843902588, 'training/sps': 509.51136648587305, 'training/walltime': 13208.25064110756, 'training/entropy_loss': Array(0.01354967, dtype=float32), 'training/policy_loss': Array(0.04086691, dtype=float32), 'training/total_loss': Array(0.07208735, dtype=float32), 'training/v_loss': Array(0.01767077, dtype=float32), 'eval/episode_distance_from_origin': Array(4474.9346, dtype=float32), 'eval/episode_distance_reward': Array(9.817589, dtype=float32), 'eval/episode_forward_reward': Array(1636.26, dtype=float32), 'eval/episode_reward': Array(1569.7593, dtype=float32), 'eval/episode_reward_alive': Array(364.04688, dtype=float32), 'eval/episode_reward_linvel': Array(1636.26, dtype=float32), 'eval/episode_reward_quadctrl': Array(-440.36517, dtype=float32), 'eval/episode_x_position': Array(4432.4854, dtype=float32), 'eval/episode_x_velocity': Array(327.25195, dtype=float32), 'eval/episode_y_position': Array(-254.39893, dtype=float32), 'eval/episode_y_velocity': Array(-32.69574, dtype=float32), 'eval/episode_distance_from_origin_std': Array(143.84064, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4298354, dtype=float32), 'eval/episode_forward_reward_std': Array(238.30261, dtype=float32), 'eval/episode_reward_std': Array(255.90129, dtype=float32), 'eval/episode_reward_alive_std': Array(60.661087, dtype=float32), 'eval/episode_reward_linvel_std': Array(238.30261, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.638294, dtype=float32), 'eval/episode_x_position_std': Array(136.8305, dtype=float32), 'eval/episode_x_velocity_std': Array(47.660522, dtype=float32), 'eval/episode_y_position_std': Array(238.7587, dtype=float32), 'eval/episode_y_velocity_std': Array(60.316463, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23466038703918, 'eval/sps': 939.5553204768543, 'num_steps': 6717440}
{'eval/walltime': 11506.651849746704, 'training/sps': 511.39771250478134, 'training/walltime': 13368.439077615738, 'training/entropy_loss': Array(0.01260221, dtype=float32), 'training/policy_loss': Array(0.02821058, dtype=float32), 'training/total_loss': Array(0.06162348, dtype=float32), 'training/v_loss': Array(0.02081069, dtype=float32), 'eval/episode_distance_from_origin': Array(4476.746, dtype=float32), 'eval/episode_distance_reward': Array(9.859053, dtype=float32), 'eval/episode_forward_reward': Array(1643.1711, dtype=float32), 'eval/episode_reward': Array(1581.6515, dtype=float32), 'eval/episode_reward_alive': Array(366.10547, dtype=float32), 'eval/episode_reward_linvel': Array(1643.1711, dtype=float32), 'eval/episode_reward_quadctrl': Array(-437.48404, dtype=float32), 'eval/episode_x_position': Array(4434.326, dtype=float32), 'eval/episode_x_velocity': Array(328.63422, dtype=float32), 'eval/episode_y_position': Array(-223.55746, dtype=float32), 'eval/episode_y_velocity': Array(-19.621235, dtype=float32), 'eval/episode_distance_from_origin_std': Array(147.94339, dtype=float32), 'eval/episode_distance_reward_std': Array(1.5145758, dtype=float32), 'eval/episode_forward_reward_std': Array(252.42653, dtype=float32), 'eval/episode_reward_std': Array(279.69833, dtype=float32), 'eval/episode_reward_alive_std': Array(51.072315, dtype=float32), 'eval/episode_reward_linvel_std': Array(252.42653, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.899807, dtype=float32), 'eval/episode_x_position_std': Array(140.76312, dtype=float32), 'eval/episode_x_velocity_std': Array(50.485317, dtype=float32), 'eval/episode_y_position_std': Array(253.88782, dtype=float32), 'eval/episode_y_velocity_std': Array(66.144104, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.4720058441162, 'eval/sps': 937.9212916838544, 'num_steps': 6799360}
{'eval/walltime': 11642.903411149979, 'training/sps': 511.14622967659267, 'training/walltime': 13528.70632648468, 'training/entropy_loss': Array(0.01370023, dtype=float32), 'training/policy_loss': Array(0.05722047, dtype=float32), 'training/total_loss': Array(0.08817124, dtype=float32), 'training/v_loss': Array(0.01725055, dtype=float32), 'eval/episode_distance_from_origin': Array(4489.4033, dtype=float32), 'eval/episode_distance_reward': Array(9.981558, dtype=float32), 'eval/episode_forward_reward': Array(1663.5898, dtype=float32), 'eval/episode_reward': Array(1622.9072, dtype=float32), 'eval/episode_reward_alive': Array(376.9297, dtype=float32), 'eval/episode_reward_linvel': Array(1663.5898, dtype=float32), 'eval/episode_reward_quadctrl': Array(-427.59363, dtype=float32), 'eval/episode_x_position': Array(4448.2363, dtype=float32), 'eval/episode_x_velocity': Array(332.7179, dtype=float32), 'eval/episode_y_position': Array(-189.00772, dtype=float32), 'eval/episode_y_velocity': Array(-3.920658, dtype=float32), 'eval/episode_distance_from_origin_std': Array(134.12888, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4376817, dtype=float32), 'eval/episode_forward_reward_std': Array(239.6113, dtype=float32), 'eval/episode_reward_std': Array(253.1967, dtype=float32), 'eval/episode_reward_alive_std': Array(40.55849, dtype=float32), 'eval/episode_reward_linvel_std': Array(239.6113, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.154797, dtype=float32), 'eval/episode_x_position_std': Array(130.02992, dtype=float32), 'eval/episode_x_velocity_std': Array(47.922256, dtype=float32), 'eval/episode_y_position_std': Array(251.31404, dtype=float32), 'eval/episode_y_velocity_std': Array(63.400425, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.25156140327454, 'eval/sps': 939.4387754658331, 'num_steps': 6881280}
{'eval/walltime': 11779.109228372574, 'training/sps': 512.1118057207814, 'training/walltime': 13688.671394824982, 'training/entropy_loss': Array(0.01180397, dtype=float32), 'training/policy_loss': Array(0.03827877, dtype=float32), 'training/total_loss': Array(0.06887874, dtype=float32), 'training/v_loss': Array(0.01879601, dtype=float32), 'eval/episode_distance_from_origin': Array(4490.1357, dtype=float32), 'eval/episode_distance_reward': Array(9.784974, dtype=float32), 'eval/episode_forward_reward': Array(1630.8269, dtype=float32), 'eval/episode_reward': Array(1596.2714, dtype=float32), 'eval/episode_reward_alive': Array(379.1953, dtype=float32), 'eval/episode_reward_linvel': Array(1630.8269, dtype=float32), 'eval/episode_reward_quadctrl': Array(-423.53568, dtype=float32), 'eval/episode_x_position': Array(4450.6885, dtype=float32), 'eval/episode_x_velocity': Array(326.16537, dtype=float32), 'eval/episode_y_position': Array(-214.25516, dtype=float32), 'eval/episode_y_velocity': Array(-18.088219, dtype=float32), 'eval/episode_distance_from_origin_std': Array(140.48811, dtype=float32), 'eval/episode_distance_reward_std': Array(1.4022309, dtype=float32), 'eval/episode_forward_reward_std': Array(233.70303, dtype=float32), 'eval/episode_reward_std': Array(249.045, dtype=float32), 'eval/episode_reward_alive_std': Array(48.092896, dtype=float32), 'eval/episode_reward_linvel_std': Array(233.70303, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.585526, dtype=float32), 'eval/episode_x_position_std': Array(136.4897, dtype=float32), 'eval/episode_x_velocity_std': Array(46.74061, dtype=float32), 'eval/episode_y_position_std': Array(213.02544, dtype=float32), 'eval/episode_y_velocity_std': Array(51.931488, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.20581722259521, 'eval/sps': 939.754282233153, 'num_steps': 6963200}
{'eval/walltime': 11915.221628904343, 'training/sps': 506.7385744207726, 'training/walltime': 13850.332661867142, 'training/entropy_loss': Array(0.01070318, dtype=float32), 'training/policy_loss': Array(0.07031322, dtype=float32), 'training/total_loss': Array(0.09717701, dtype=float32), 'training/v_loss': Array(0.01616061, dtype=float32), 'eval/episode_distance_from_origin': Array(4492.5557, dtype=float32), 'eval/episode_distance_reward': Array(9.959692, dtype=float32), 'eval/episode_forward_reward': Array(1659.9437, dtype=float32), 'eval/episode_reward': Array(1582.3411, dtype=float32), 'eval/episode_reward_alive': Array(338.28125, dtype=float32), 'eval/episode_reward_linvel': Array(1659.9437, dtype=float32), 'eval/episode_reward_quadctrl': Array(-425.84363, dtype=float32), 'eval/episode_x_position': Array(4450.617, dtype=float32), 'eval/episode_x_velocity': Array(331.9887, dtype=float32), 'eval/episode_y_position': Array(-231.27153, dtype=float32), 'eval/episode_y_velocity': Array(-19.283314, dtype=float32), 'eval/episode_distance_from_origin_std': Array(152.94223, dtype=float32), 'eval/episode_distance_reward_std': Array(1.6361736, dtype=float32), 'eval/episode_forward_reward_std': Array(272.69226, dtype=float32), 'eval/episode_reward_std': Array(311.67007, dtype=float32), 'eval/episode_reward_alive_std': Array(67.45278, dtype=float32), 'eval/episode_reward_linvel_std': Array(272.69226, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.265118, dtype=float32), 'eval/episode_x_position_std': Array(146.18916, dtype=float32), 'eval/episode_x_velocity_std': Array(54.538475, dtype=float32), 'eval/episode_y_position_std': Array(239.17564, dtype=float32), 'eval/episode_y_velocity_std': Array(64.954994, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1124005317688, 'eval/sps': 940.3992545860996, 'num_steps': 7045120}
{'eval/walltime': 12051.461815357208, 'training/sps': 511.6624167909918, 'training/walltime': 14010.438226222992, 'training/entropy_loss': Array(0.01037294, dtype=float32), 'training/policy_loss': Array(0.00105265, dtype=float32), 'training/total_loss': Array(0.03224637, dtype=float32), 'training/v_loss': Array(0.02082078, dtype=float32), 'eval/episode_distance_from_origin': Array(4498.577, dtype=float32), 'eval/episode_distance_reward': Array(10.147394, dtype=float32), 'eval/episode_forward_reward': Array(1691.2263, dtype=float32), 'eval/episode_reward': Array(1596.4469, dtype=float32), 'eval/episode_reward_alive': Array(317.83984, dtype=float32), 'eval/episode_reward_linvel': Array(1691.2263, dtype=float32), 'eval/episode_reward_quadctrl': Array(-422.76675, dtype=float32), 'eval/episode_x_position': Array(4456.2734, dtype=float32), 'eval/episode_x_velocity': Array(338.2453, dtype=float32), 'eval/episode_y_position': Array(-220.1069, dtype=float32), 'eval/episode_y_velocity': Array(-16.120087, dtype=float32), 'eval/episode_distance_from_origin_std': Array(186.26788, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8596023, dtype=float32), 'eval/episode_forward_reward_std': Array(309.93124, dtype=float32), 'eval/episode_reward_std': Array(364.0032, dtype=float32), 'eval/episode_reward_alive_std': Array(85.30298, dtype=float32), 'eval/episode_reward_linvel_std': Array(309.93124, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.77092, dtype=float32), 'eval/episode_x_position_std': Array(179.05455, dtype=float32), 'eval/episode_x_velocity_std': Array(61.986233, dtype=float32), 'eval/episode_y_position_std': Array(256.97128, dtype=float32), 'eval/episode_y_velocity_std': Array(73.268234, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2401864528656, 'eval/sps': 939.5172109829986, 'num_steps': 7127040}
{'eval/walltime': 12187.58155989647, 'training/sps': 510.01541215672347, 'training/walltime': 14171.060823202133, 'training/entropy_loss': Array(0.01074051, dtype=float32), 'training/policy_loss': Array(0.0021918, dtype=float32), 'training/total_loss': Array(0.03365251, dtype=float32), 'training/v_loss': Array(0.0207202, dtype=float32), 'eval/episode_distance_from_origin': Array(4513.4775, dtype=float32), 'eval/episode_distance_reward': Array(10.326237, dtype=float32), 'eval/episode_forward_reward': Array(1721.034, dtype=float32), 'eval/episode_reward': Array(1674.5044, dtype=float32), 'eval/episode_reward_alive': Array(357.55078, dtype=float32), 'eval/episode_reward_linvel': Array(1721.034, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.40668, dtype=float32), 'eval/episode_x_position': Array(4470.9463, dtype=float32), 'eval/episode_x_velocity': Array(344.2068, dtype=float32), 'eval/episode_y_position': Array(-212.83757, dtype=float32), 'eval/episode_y_velocity': Array(-8.042919, dtype=float32), 'eval/episode_distance_from_origin_std': Array(169.18239, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9059118, dtype=float32), 'eval/episode_forward_reward_std': Array(317.64777, dtype=float32), 'eval/episode_reward_std': Array(343.46182, dtype=float32), 'eval/episode_reward_alive_std': Array(56.94689, dtype=float32), 'eval/episode_reward_linvel_std': Array(317.64777, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(42.807446, dtype=float32), 'eval/episode_x_position_std': Array(164.32196, dtype=float32), 'eval/episode_x_velocity_std': Array(63.52959, dtype=float32), 'eval/episode_y_position_std': Array(248.85919, dtype=float32), 'eval/episode_y_velocity_std': Array(74.54601, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.11974453926086, 'eval/sps': 940.3485176471302, 'num_steps': 7208960}
{'eval/walltime': 12324.078855514526, 'training/sps': 512.2335835366467, 'training/walltime': 14330.9878616333, 'training/entropy_loss': Array(0.01081597, dtype=float32), 'training/policy_loss': Array(0.00885637, dtype=float32), 'training/total_loss': Array(0.04266074, dtype=float32), 'training/v_loss': Array(0.0229884, dtype=float32), 'eval/episode_distance_from_origin': Array(4551.8296, dtype=float32), 'eval/episode_distance_reward': Array(10.456288, dtype=float32), 'eval/episode_forward_reward': Array(1742.7119, dtype=float32), 'eval/episode_reward': Array(1715.1763, dtype=float32), 'eval/episode_reward_alive': Array(372.27734, dtype=float32), 'eval/episode_reward_linvel': Array(1742.7119, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.2691, dtype=float32), 'eval/episode_x_position': Array(4509.4287, dtype=float32), 'eval/episode_x_velocity': Array(348.5424, dtype=float32), 'eval/episode_y_position': Array(-223.94147, dtype=float32), 'eval/episode_y_velocity': Array(-5.5668955, dtype=float32), 'eval/episode_distance_from_origin_std': Array(162.48541, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7535341, dtype=float32), 'eval/episode_forward_reward_std': Array(292.2515, dtype=float32), 'eval/episode_reward_std': Array(310.7943, dtype=float32), 'eval/episode_reward_alive_std': Array(57.341557, dtype=float32), 'eval/episode_reward_linvel_std': Array(292.2515, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.915897, dtype=float32), 'eval/episode_x_position_std': Array(158.43848, dtype=float32), 'eval/episode_x_velocity_std': Array(58.45034, dtype=float32), 'eval/episode_y_position_std': Array(231.56313, dtype=float32), 'eval/episode_y_velocity_std': Array(70.9439, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.49729561805725, 'eval/sps': 937.7475166846226, 'num_steps': 7290880}
{'eval/walltime': 12460.433763980865, 'training/sps': 509.59890563305976, 'training/walltime': 14491.741739034653, 'training/entropy_loss': Array(0.00974093, dtype=float32), 'training/policy_loss': Array(0.00245961, dtype=float32), 'training/total_loss': Array(0.03892202, dtype=float32), 'training/v_loss': Array(0.02672148, dtype=float32), 'eval/episode_distance_from_origin': Array(4543.7524, dtype=float32), 'eval/episode_distance_reward': Array(10.570242, dtype=float32), 'eval/episode_forward_reward': Array(1761.7037, dtype=float32), 'eval/episode_reward': Array(1732.6381, dtype=float32), 'eval/episode_reward_alive': Array(367.9922, dtype=float32), 'eval/episode_reward_linvel': Array(1761.7037, dtype=float32), 'eval/episode_reward_quadctrl': Array(-407.62814, dtype=float32), 'eval/episode_x_position': Array(4497.401, dtype=float32), 'eval/episode_x_velocity': Array(352.34073, dtype=float32), 'eval/episode_y_position': Array(-261.18643, dtype=float32), 'eval/episode_y_velocity': Array(-12.041639, dtype=float32), 'eval/episode_distance_from_origin_std': Array(170.516, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9341124, dtype=float32), 'eval/episode_forward_reward_std': Array(322.3483, dtype=float32), 'eval/episode_reward_std': Array(333.63504, dtype=float32), 'eval/episode_reward_alive_std': Array(55.1239, dtype=float32), 'eval/episode_reward_linvel_std': Array(322.3483, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(41.220676, dtype=float32), 'eval/episode_x_position_std': Array(166.62111, dtype=float32), 'eval/episode_x_velocity_std': Array(64.46963, dtype=float32), 'eval/episode_y_position_std': Array(255.9885, dtype=float32), 'eval/episode_y_velocity_std': Array(77.28228, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.3549084663391, 'eval/sps': 938.7267494781706, 'num_steps': 7372800}
{'eval/walltime': 12596.558741092682, 'training/sps': 511.8135765090365, 'training/walltime': 14651.800017595291, 'training/entropy_loss': Array(0.01061657, dtype=float32), 'training/policy_loss': Array(0.00547172, dtype=float32), 'training/total_loss': Array(0.03911167, dtype=float32), 'training/v_loss': Array(0.02302338, dtype=float32), 'eval/episode_distance_from_origin': Array(4532.411, dtype=float32), 'eval/episode_distance_reward': Array(10.339722, dtype=float32), 'eval/episode_forward_reward': Array(1723.2831, dtype=float32), 'eval/episode_reward': Array(1696.1299, dtype=float32), 'eval/episode_reward_alive': Array(373.26172, dtype=float32), 'eval/episode_reward_linvel': Array(1723.2831, dtype=float32), 'eval/episode_reward_quadctrl': Array(-410.75482, dtype=float32), 'eval/episode_x_position': Array(4488.6016, dtype=float32), 'eval/episode_x_velocity': Array(344.6566, dtype=float32), 'eval/episode_y_position': Array(-227.58917, dtype=float32), 'eval/episode_y_velocity': Array(-7.9143887, dtype=float32), 'eval/episode_distance_from_origin_std': Array(161.54079, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7719902, dtype=float32), 'eval/episode_forward_reward_std': Array(295.3281, dtype=float32), 'eval/episode_reward_std': Array(308.0619, dtype=float32), 'eval/episode_reward_alive_std': Array(52.225174, dtype=float32), 'eval/episode_reward_linvel_std': Array(295.3281, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(43.504017, dtype=float32), 'eval/episode_x_position_std': Array(157.01184, dtype=float32), 'eval/episode_x_velocity_std': Array(59.065605, dtype=float32), 'eval/episode_y_position_std': Array(251.19675, dtype=float32), 'eval/episode_y_velocity_std': Array(72.33718, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.1249771118164, 'eval/sps': 940.3123711444789, 'num_steps': 7454720}
{'eval/walltime': 12732.893943309784, 'training/sps': 509.69832487245225, 'training/walltime': 14812.522539138794, 'training/entropy_loss': Array(0.01026076, dtype=float32), 'training/policy_loss': Array(0.00308286, dtype=float32), 'training/total_loss': Array(0.03904536, dtype=float32), 'training/v_loss': Array(0.02570175, dtype=float32), 'eval/episode_distance_from_origin': Array(4552.8994, dtype=float32), 'eval/episode_distance_reward': Array(10.41641, dtype=float32), 'eval/episode_forward_reward': Array(1736.0642, dtype=float32), 'eval/episode_reward': Array(1699.1127, dtype=float32), 'eval/episode_reward_alive': Array(367.70703, dtype=float32), 'eval/episode_reward_linvel': Array(1736.0642, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.07495, dtype=float32), 'eval/episode_x_position': Array(4509.0234, dtype=float32), 'eval/episode_x_velocity': Array(347.21283, dtype=float32), 'eval/episode_y_position': Array(-259.30188, dtype=float32), 'eval/episode_y_velocity': Array(-17.960867, dtype=float32), 'eval/episode_distance_from_origin_std': Array(160.48064, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7778788, dtype=float32), 'eval/episode_forward_reward_std': Array(296.3096, dtype=float32), 'eval/episode_reward_std': Array(308.8268, dtype=float32), 'eval/episode_reward_alive_std': Array(61.248676, dtype=float32), 'eval/episode_reward_linvel_std': Array(296.3096, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.675117, dtype=float32), 'eval/episode_x_position_std': Array(157.03648, dtype=float32), 'eval/episode_x_velocity_std': Array(59.261944, dtype=float32), 'eval/episode_y_position_std': Array(233.39111, dtype=float32), 'eval/episode_y_velocity_std': Array(66.43366, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.33520221710205, 'eval/sps': 938.862435515158, 'num_steps': 7536640}
{'eval/walltime': 12869.069528579712, 'training/sps': 511.84317015383164, 'training/walltime': 14972.571563482285, 'training/entropy_loss': Array(0.01138005, dtype=float32), 'training/policy_loss': Array(0.00533904, dtype=float32), 'training/total_loss': Array(0.0390985, dtype=float32), 'training/v_loss': Array(0.02237941, dtype=float32), 'eval/episode_distance_from_origin': Array(4574.2305, dtype=float32), 'eval/episode_distance_reward': Array(10.660141, dtype=float32), 'eval/episode_forward_reward': Array(1776.686, dtype=float32), 'eval/episode_reward': Array(1741.0892, dtype=float32), 'eval/episode_reward_alive': Array(368.2422, dtype=float32), 'eval/episode_reward_linvel': Array(1776.686, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.4992, dtype=float32), 'eval/episode_x_position': Array(4528.472, dtype=float32), 'eval/episode_x_velocity': Array(355.33722, dtype=float32), 'eval/episode_y_position': Array(-287.97156, dtype=float32), 'eval/episode_y_velocity': Array(-19.388882, dtype=float32), 'eval/episode_distance_from_origin_std': Array(162.07297, dtype=float32), 'eval/episode_distance_reward_std': Array(1.7810378, dtype=float32), 'eval/episode_forward_reward_std': Array(296.83542, dtype=float32), 'eval/episode_reward_std': Array(316.67783, dtype=float32), 'eval/episode_reward_alive_std': Array(58.30429, dtype=float32), 'eval/episode_reward_linvel_std': Array(296.83542, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.293827, dtype=float32), 'eval/episode_x_position_std': Array(157.11569, dtype=float32), 'eval/episode_x_velocity_std': Array(59.367046, dtype=float32), 'eval/episode_y_position_std': Array(226.56859, dtype=float32), 'eval/episode_y_velocity_std': Array(71.14862, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.17558526992798, 'eval/sps': 939.9629143967159, 'num_steps': 7618560}
{'eval/walltime': 13005.4118745327, 'training/sps': 509.9192677380085, 'training/walltime': 15133.224445581436, 'training/entropy_loss': Array(0.00977449, dtype=float32), 'training/policy_loss': Array(0.00143873, dtype=float32), 'training/total_loss': Array(0.03440519, dtype=float32), 'training/v_loss': Array(0.02319198, dtype=float32), 'eval/episode_distance_from_origin': Array(4630.0728, dtype=float32), 'eval/episode_distance_reward': Array(11.139731, dtype=float32), 'eval/episode_forward_reward': Array(1856.6171, dtype=float32), 'eval/episode_reward': Array(1817.8787, dtype=float32), 'eval/episode_reward_alive': Array(365.30078, dtype=float32), 'eval/episode_reward_linvel': Array(1856.6171, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.1787, dtype=float32), 'eval/episode_x_position': Array(4582.6533, dtype=float32), 'eval/episode_x_velocity': Array(371.32336, dtype=float32), 'eval/episode_y_position': Array(-294.11816, dtype=float32), 'eval/episode_y_velocity': Array(-18.139221, dtype=float32), 'eval/episode_distance_from_origin_std': Array(156.63116, dtype=float32), 'eval/episode_distance_reward_std': Array(1.8365756, dtype=float32), 'eval/episode_forward_reward_std': Array(306.09192, dtype=float32), 'eval/episode_reward_std': Array(333.29895, dtype=float32), 'eval/episode_reward_alive_std': Array(57.77611, dtype=float32), 'eval/episode_reward_linvel_std': Array(306.09192, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(40.230053, dtype=float32), 'eval/episode_x_position_std': Array(152.07692, dtype=float32), 'eval/episode_x_velocity_std': Array(61.218388, dtype=float32), 'eval/episode_y_position_std': Array(250.90572, dtype=float32), 'eval/episode_y_velocity_std': Array(79.49172, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.34234595298767, 'eval/sps': 938.8132432761264, 'num_steps': 7700480}
{'eval/walltime': 13141.651861667633, 'training/sps': 511.93783179878824, 'training/walltime': 15293.24387550354, 'training/entropy_loss': Array(0.01062621, dtype=float32), 'training/policy_loss': Array(0.00136592, dtype=float32), 'training/total_loss': Array(0.03405919, dtype=float32), 'training/v_loss': Array(0.02206706, dtype=float32), 'eval/episode_distance_from_origin': Array(4625.3896, dtype=float32), 'eval/episode_distance_reward': Array(11.124138, dtype=float32), 'eval/episode_forward_reward': Array(1854.0171, dtype=float32), 'eval/episode_reward': Array(1800.6683, dtype=float32), 'eval/episode_reward_alive': Array(352.44922, dtype=float32), 'eval/episode_reward_linvel': Array(1854.0171, dtype=float32), 'eval/episode_reward_quadctrl': Array(-416.9222, dtype=float32), 'eval/episode_x_position': Array(4574.84, dtype=float32), 'eval/episode_x_velocity': Array(370.80344, dtype=float32), 'eval/episode_y_position': Array(-359.3153, dtype=float32), 'eval/episode_y_velocity': Array(-37.702576, dtype=float32), 'eval/episode_distance_from_origin_std': Array(164.07704, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9325906, dtype=float32), 'eval/episode_forward_reward_std': Array(322.09442, dtype=float32), 'eval/episode_reward_std': Array(353.97986, dtype=float32), 'eval/episode_reward_alive_std': Array(66.75696, dtype=float32), 'eval/episode_reward_linvel_std': Array(322.09442, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(38.17945, dtype=float32), 'eval/episode_x_position_std': Array(160.2276, dtype=float32), 'eval/episode_x_velocity_std': Array(64.4189, dtype=float32), 'eval/episode_y_position_std': Array(228.54811, dtype=float32), 'eval/episode_y_velocity_std': Array(70.65676, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.23998713493347, 'eval/sps': 939.5185854886165, 'num_steps': 7782400}
{'eval/walltime': 13277.955346107483, 'training/sps': 511.5548018167266, 'training/walltime': 15453.383121013641, 'training/entropy_loss': Array(0.01131857, dtype=float32), 'training/policy_loss': Array(0.00878582, dtype=float32), 'training/total_loss': Array(0.04557922, dtype=float32), 'training/v_loss': Array(0.02547483, dtype=float32), 'eval/episode_distance_from_origin': Array(4623.1436, dtype=float32), 'eval/episode_distance_reward': Array(11.177719, dtype=float32), 'eval/episode_forward_reward': Array(1862.9485, dtype=float32), 'eval/episode_reward': Array(1821.8196, dtype=float32), 'eval/episode_reward_alive': Array(362.82422, dtype=float32), 'eval/episode_reward_linvel': Array(1862.9485, dtype=float32), 'eval/episode_reward_quadctrl': Array(-415.13086, dtype=float32), 'eval/episode_x_position': Array(4572.387, dtype=float32), 'eval/episode_x_velocity': Array(372.58972, dtype=float32), 'eval/episode_y_position': Array(-329.503, dtype=float32), 'eval/episode_y_velocity': Array(-24.490547, dtype=float32), 'eval/episode_distance_from_origin_std': Array(173.46628, dtype=float32), 'eval/episode_distance_reward_std': Array(2.0900176, dtype=float32), 'eval/episode_forward_reward_std': Array(348.331, dtype=float32), 'eval/episode_reward_std': Array(372.2999, dtype=float32), 'eval/episode_reward_alive_std': Array(60.523647, dtype=float32), 'eval/episode_reward_linvel_std': Array(348.331, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.19053, dtype=float32), 'eval/episode_x_position_std': Array(168.64307, dtype=float32), 'eval/episode_x_velocity_std': Array(69.66626, dtype=float32), 'eval/episode_y_position_std': Array(260.14566, dtype=float32), 'eval/episode_y_velocity_std': Array(83.798744, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.30348443984985, 'eval/sps': 939.080908503743, 'num_steps': 7864320}
{'eval/walltime': 13414.329292297363, 'training/sps': 511.9753651074846, 'training/walltime': 15613.39081978798, 'training/entropy_loss': Array(0.01143669, dtype=float32), 'training/policy_loss': Array(0.00366863, dtype=float32), 'training/total_loss': Array(0.03755143, dtype=float32), 'training/v_loss': Array(0.02244611, dtype=float32), 'eval/episode_distance_from_origin': Array(4633.4185, dtype=float32), 'eval/episode_distance_reward': Array(11.130152, dtype=float32), 'eval/episode_forward_reward': Array(1855.0212, dtype=float32), 'eval/episode_reward': Array(1837.7615, dtype=float32), 'eval/episode_reward_alive': Array(390.16016, dtype=float32), 'eval/episode_reward_linvel': Array(1855.0212, dtype=float32), 'eval/episode_reward_quadctrl': Array(-418.55005, dtype=float32), 'eval/episode_x_position': Array(4584.955, dtype=float32), 'eval/episode_x_velocity': Array(371.00427, dtype=float32), 'eval/episode_y_position': Array(-272.04584, dtype=float32), 'eval/episode_y_velocity': Array(-8.798247, dtype=float32), 'eval/episode_distance_from_origin_std': Array(190.69002, dtype=float32), 'eval/episode_distance_reward_std': Array(2.156638, dtype=float32), 'eval/episode_forward_reward_std': Array(359.43414, dtype=float32), 'eval/episode_reward_std': Array(370.87244, dtype=float32), 'eval/episode_reward_alive_std': Array(31.315178, dtype=float32), 'eval/episode_reward_linvel_std': Array(359.43414, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(31.849451, dtype=float32), 'eval/episode_x_position_std': Array(188.45325, dtype=float32), 'eval/episode_x_velocity_std': Array(71.8869, dtype=float32), 'eval/episode_y_position_std': Array(267.78522, dtype=float32), 'eval/episode_y_velocity_std': Array(82.32461, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.37394618988037, 'eval/sps': 938.5957037701255, 'num_steps': 7946240}
{'eval/walltime': 13550.60803937912, 'training/sps': 510.360041921911, 'training/walltime': 15773.904953479767, 'training/entropy_loss': Array(0.01056987, dtype=float32), 'training/policy_loss': Array(0.00360401, dtype=float32), 'training/total_loss': Array(0.03525645, dtype=float32), 'training/v_loss': Array(0.02108256, dtype=float32), 'eval/episode_distance_from_origin': Array(4637.3203, dtype=float32), 'eval/episode_distance_reward': Array(11.338467, dtype=float32), 'eval/episode_forward_reward': Array(1889.7388, dtype=float32), 'eval/episode_reward': Array(1861.187, dtype=float32), 'eval/episode_reward_alive': Array(374.1328, dtype=float32), 'eval/episode_reward_linvel': Array(1889.7388, dtype=float32), 'eval/episode_reward_quadctrl': Array(-414.02332, dtype=float32), 'eval/episode_x_position': Array(4590.077, dtype=float32), 'eval/episode_x_velocity': Array(377.94772, dtype=float32), 'eval/episode_y_position': Array(-290.7115, dtype=float32), 'eval/episode_y_velocity': Array(-12.704426, dtype=float32), 'eval/episode_distance_from_origin_std': Array(160.66826, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9521565, dtype=float32), 'eval/episode_forward_reward_std': Array(325.35492, dtype=float32), 'eval/episode_reward_std': Array(345.3863, dtype=float32), 'eval/episode_reward_alive_std': Array(45.71205, dtype=float32), 'eval/episode_reward_linvel_std': Array(325.35492, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(36.99803, dtype=float32), 'eval/episode_x_position_std': Array(157.50594, dtype=float32), 'eval/episode_x_velocity_std': Array(65.070984, dtype=float32), 'eval/episode_y_position_std': Array(235.47797, dtype=float32), 'eval/episode_y_velocity_std': Array(75.37563, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2787470817566, 'eval/sps': 939.2513707453592, 'num_steps': 8028160}
{'eval/walltime': 13686.887067079544, 'training/sps': 512.5755585425559, 'training/walltime': 15933.725293397903, 'training/entropy_loss': Array(0.01067993, dtype=float32), 'training/policy_loss': Array(0.00469384, dtype=float32), 'training/total_loss': Array(0.03760258, dtype=float32), 'training/v_loss': Array(0.0222288, dtype=float32), 'eval/episode_distance_from_origin': Array(4621.3853, dtype=float32), 'eval/episode_distance_reward': Array(11.069975, dtype=float32), 'eval/episode_forward_reward': Array(1844.9913, dtype=float32), 'eval/episode_reward': Array(1805.1509, dtype=float32), 'eval/episode_reward_alive': Array(368.21875, dtype=float32), 'eval/episode_reward_linvel': Array(1844.9913, dtype=float32), 'eval/episode_reward_quadctrl': Array(-419.12924, dtype=float32), 'eval/episode_x_position': Array(4572.1245, dtype=float32), 'eval/episode_x_velocity': Array(368.99826, dtype=float32), 'eval/episode_y_position': Array(-323.5562, dtype=float32), 'eval/episode_y_velocity': Array(-18.07552, dtype=float32), 'eval/episode_distance_from_origin_std': Array(160.34087, dtype=float32), 'eval/episode_distance_reward_std': Array(1.9503953, dtype=float32), 'eval/episode_forward_reward_std': Array(325.06125, dtype=float32), 'eval/episode_reward_std': Array(348.26505, dtype=float32), 'eval/episode_reward_alive_std': Array(58.2239, dtype=float32), 'eval/episode_reward_linvel_std': Array(325.06125, dtype=float32), 'eval/episode_reward_quadctrl_std': Array(37.15446, dtype=float32), 'eval/episode_x_position_std': Array(159.50844, dtype=float32), 'eval/episode_x_velocity_std': Array(65.012245, dtype=float32), 'eval/episode_y_position_std': Array(225.73306, dtype=float32), 'eval/episode_y_velocity_std': Array(78.439766, dtype=float32), 'eval/avg_episode_length': Array(1000., dtype=float32), 'eval/epoch_eval_time': 136.2790277004242, 'eval/sps': 939.2494366879137, 'num_steps': 8110080}