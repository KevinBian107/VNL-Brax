
{'eval/walltime': 992.9788014888763, 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(10.828125, dtype=float32), 'eval/episode_reward_alive': Array(12.890625, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-2.0625, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(7.248221, dtype=float32), 'eval/episode_reward_alive_std': Array(8.628835, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(1.3806137, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(2.578125, dtype=float32), 'eval/epoch_eval_time': 992.9788014888763, 'eval/sps': 128.9050680720236, 'num_steps': 0}
{'eval/walltime': 1951.5923585891724, 'training/sps': 72.3183370374728, 'training/walltime': 35115.851719379425, 'training/entropy_loss': Array(5915.5845, dtype=float32), 'training/policy_loss': Array(0.01476654, dtype=float32), 'training/total_loss': Array(2.494048e+11, dtype=float32), 'training/v_loss': Array(2.494048e+11, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(1875.2383, dtype=float32), 'eval/episode_reward_alive': Array(1939.375, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-64.13672, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2342.693, dtype=float32), 'eval/episode_reward_alive_std': Array(2422.7583, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(80.62851, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(387.875, dtype=float32), 'eval/epoch_eval_time': 958.613557100296, 'eval/sps': 133.5261733489211, 'num_steps': 2539520}
{'eval/walltime': 2909.7497828006744, 'training/sps': 72.44026938848543, 'training/walltime': 70172.5960059166, 'training/entropy_loss': Array(-0.00113325, dtype=float32), 'training/policy_loss': Array(-0.00106102, dtype=float32), 'training/total_loss': Array(0.02268128, dtype=float32), 'training/v_loss': Array(0.02487556, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(2402.7021, dtype=float32), 'eval/episode_reward_alive': Array(2424.6484, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-21.946228, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2473.5894, dtype=float32), 'eval/episode_reward_alive_std': Array(2496.091, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(22.541386, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(484.9297, dtype=float32), 'eval/epoch_eval_time': 958.1574242115021, 'eval/sps': 133.58973876900785, 'num_steps': 5079040}
{'eval/walltime': 3868.5968465805054, 'training/sps': 72.43560485899098, 'training/walltime': 105231.59779024124, 'training/entropy_loss': Array(0.00430812, dtype=float32), 'training/policy_loss': Array(0.00181459, dtype=float32), 'training/total_loss': Array(0.01507785, dtype=float32), 'training/v_loss': Array(0.00895513, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(2453.234, dtype=float32), 'eval/episode_reward_alive': Array(2463.6719, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-10.438173, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2486.5068, dtype=float32), 'eval/episode_reward_alive_std': Array(2497.0032, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(11.0592985, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(492.73438, dtype=float32), 'eval/epoch_eval_time': 958.8470637798309, 'eval/sps': 133.49365590735246, 'num_steps': 7618560}
{'eval/walltime': 4825.162019729614, 'training/sps': 72.38565459915247, 'training/walltime': 140314.79229974747, 'training/entropy_loss': Array(0.00722081, dtype=float32), 'training/policy_loss': Array(0.00133537, dtype=float32), 'training/total_loss': Array(0.01718083, dtype=float32), 'training/v_loss': Array(0.00862465, dtype=float32), 'eval/episode_distance_from_origin': Array(0., dtype=float32), 'eval/episode_distance_reward': Array(0., dtype=float32), 'eval/episode_forward_reward': Array(0., dtype=float32), 'eval/episode_reward': Array(1831.1204, dtype=float32), 'eval/episode_reward_alive': Array(1839.3359, dtype=float32), 'eval/episode_reward_linvel': Array(0., dtype=float32), 'eval/episode_reward_quadctrl': Array(-8.215471, dtype=float32), 'eval/episode_x_position': Array(0., dtype=float32), 'eval/episode_x_velocity': Array(0., dtype=float32), 'eval/episode_y_position': Array(0., dtype=float32), 'eval/episode_y_velocity': Array(0., dtype=float32), 'eval/episode_distance_from_origin_std': Array(0., dtype=float32), 'eval/episode_distance_reward_std': Array(0., dtype=float32), 'eval/episode_forward_reward_std': Array(0., dtype=float32), 'eval/episode_reward_std': Array(2396.9397, dtype=float32), 'eval/episode_reward_alive_std': Array(2407.6028, dtype=float32), 'eval/episode_reward_linvel_std': Array(0., dtype=float32), 'eval/episode_reward_quadctrl_std': Array(11.554059, dtype=float32), 'eval/episode_x_position_std': Array(0., dtype=float32), 'eval/episode_x_velocity_std': Array(0., dtype=float32), 'eval/episode_y_position_std': Array(0., dtype=float32), 'eval/episode_y_velocity_std': Array(0., dtype=float32), 'eval/avg_episode_length': Array(367.8672, dtype=float32), 'eval/epoch_eval_time': 956.5651731491089, 'eval/sps': 133.81210563898236, 'num_steps': 10158080}