{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e19371b8-9c17-4b5a-98ec-1d756117011f",
   "metadata": {},
   "source": [
    "## Initialize the Env"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
<<<<<<< HEAD
   "id": "21f8270c-848f-4b7c-9a2c-8ce6f5758edc",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
=======
   "id": "f2d15035-d974-402d-9b6a-f86e2a29e37c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
>>>>>>> e9d0044a3e8882228286440c2169d3e215f2fbb4
    "from datetime import datetime\n",
    "import functools\n",
    "from IPython.display import HTML\n",
    "import jax\n",
    "from jax import numpy as jp\n",
    "import numpy as np\n",
    "from typing import Any, Dict, Sequence, Tuple, Union, Optional\n",
<<<<<<< HEAD
    "import wandb\n",
    "\n",
=======
    "# import wandb\n",
    "\n",
    "import brax\n",
>>>>>>> e9d0044a3e8882228286440c2169d3e215f2fbb4
    "from brax import base\n",
    "from brax import envs\n",
    "from brax import math\n",
    "from brax.base import Base, Motion, Transform\n",
    "from brax.envs.base import Env, MjxEnv, State\n",
    "from brax.mjx.base import State as MjxState\n",
    "from brax.training.agents.ppo import train as ppo\n",
    "from brax.training.agents.ppo import networks as ppo_networks\n",
    "from brax.io import html, mjcf, model\n",
    "\n",
    "from etils import epath\n",
    "from flax import struct\n",
    "from matplotlib import pyplot as plt\n",
    "import mediapy as media\n",
    "from ml_collections import config_dict\n",
    "import mujoco\n",
    "from mujoco import mjx\n",
    "import os\n",
    "\n",
<<<<<<< HEAD
    "import yaml\n",
    "from typing import List, Dict, Text\n",
    "import mediapy as media\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f2d15035-d974-402d-9b6a-f86e2a29e37c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
=======
    "# os.environ['XLA_PYTHON_CLIENT_PREALLOCATE'] = \"false\"\n",
    "os.environ['XLA_PYTHON_CLIENT_MEM_FRACTION'] = '.3'\n",
    "import yaml\n",
    "from typing import List, Dict, Text\n",
    "\n",
    "# ## TODO:\n",
    "# \n",
    "# - Check the healthy z-range of the rodent. Now the training\n",
    "#     - Check mj_data and how to pull out kinematics of the simulations\n",
    "# - Check the `brax.envs` and how I can pass the custom parameters\n",
    "\n",
    "# In[3]:\n",
    "\n",
    "\n",
>>>>>>> e9d0044a3e8882228286440c2169d3e215f2fbb4
    "def load_params(param_path: Text) -> Dict:\n",
    "    with open(param_path, \"rb\") as file:\n",
    "        params = yaml.safe_load(file)\n",
    "    return params\n",
    "\n",
    "\n",
    "params = load_params(\"params/params.yaml\")\n",
    "\n",
<<<<<<< HEAD
    "class Humanoid(MjxEnv):\n",
    "  '''\n",
    "  This is greatly coustomizable of what reward you want to give: reward engineering\n",
    "  '''\n",
    "  def __init__(\n",
    "      self,\n",
    "      forward_reward_weight=1.25,\n",
    "      ctrl_cost_weight=0.1,\n",
    "      healthy_reward=5.0,\n",
    "      terminate_when_unhealthy=True,\n",
    "      healthy_z_range=(1.0, 1.5),\n",
    "      reset_noise_scale=1e-2,\n",
    "      exclude_current_positions_from_observation=True,\n",
    "      **kwargs,):\n",
    "    '''\n",
    "    Defining initilization of the agent\n",
    "    '''\n",
    "    \n",
    "    mj_model = mujoco.MjModel.from_xml_path(\"./models/humanoid.xml\")\n",
    "    # path = epath.Path(epath.resource_path('mujoco')) / ('mjx/benchmark/model/humanoid')\n",
    "    # mj_model = mujoco.MjModel.from_xml_path((path / 'humanoid.xml').as_posix())\n",
    "\n",
    "    # solver is an optimization system\n",
    "    mj_model.opt.solver = mujoco.mjtSolver.mjSOL_CG\n",
    "\n",
    "    #Iterations for solver\n",
    "    mj_model.opt.iterations = 6\n",
    "    mj_model.opt.ls_iterations = 6\n",
    "\n",
    "    # Defult framne to be 5, but can self define in kwargs\n",
    "    physics_steps_per_control_step = 5\n",
    "    kwargs['n_frames'] = kwargs.get(\n",
    "        'n_frames', physics_steps_per_control_step)\n",
    "\n",
    "    # Parents inheritence from MjxEnv class\n",
    "    super().__init__(model=mj_model, **kwargs)\n",
    "\n",
    "    # Global vraiable for later calling them\n",
    "    self._forward_reward_weight = forward_reward_weight\n",
    "    self._ctrl_cost_weight = ctrl_cost_weight\n",
    "    self._healthy_reward = healthy_reward\n",
    "    self._terminate_when_unhealthy = terminate_when_unhealthy\n",
    "    self._healthy_z_range = healthy_z_range\n",
    "    self._reset_noise_scale = reset_noise_scale\n",
    "    self._exclude_current_positions_from_observation = (exclude_current_positions_from_observation)\n",
    "\n",
    "  def reset(self, rng: jp.ndarray) -> State:\n",
    "    \"\"\"Resets the environment to an initial state.\"\"\"\n",
    "\n",
    "    #Creating randome keys\n",
    "    #rng = random number generator key for starting random initiation\n",
    "    rng, rng1, rng2 = jax.random.split(rng, 3)\n",
    "\n",
    "    low, hi = -self._reset_noise_scale, self._reset_noise_scale\n",
    "\n",
    "    #Vectors of generalized joint position in the configuration space\n",
    "    qpos = self.sys.qpos0 + jax.random.uniform(\n",
    "        rng1, (self.sys.nq,), minval=low, maxval=hi\n",
    "    )\n",
    "\n",
    "    #Vectors of generalized joint velocities in the configuration space\n",
    "    qvel = jax.random.uniform(\n",
    "        rng2, (self.sys.nv,), minval=low, maxval=hi\n",
    "    )\n",
    "\n",
    "    data = self.pipeline_init(qpos, qvel)\n",
    "\n",
    "    #Reset everything\n",
    "    obs = self._get_obs(data.data, jp.zeros(self.sys.nu))\n",
    "    reward, done, zero = jp.zeros(3)\n",
    "    metrics = {\n",
    "        'forward_reward': zero,\n",
    "        'reward_linvel': zero,\n",
    "        'reward_quadctrl': zero,\n",
    "        'reward_alive': zero,\n",
    "        'x_position': zero,\n",
    "        'y_position': zero,\n",
    "        'distance_from_origin': zero,\n",
    "        'x_velocity': zero,\n",
    "        'y_velocity': zero,\n",
    "    }\n",
    "    return State(data, obs, reward, done, metrics)\n",
    "\n",
    "  def step(self, state: State, action: jp.ndarray) -> State:\n",
    "    \"\"\"Runs one timestep of the environment's dynamics.\"\"\"\n",
    "    #Previous Pipeline\n",
    "    data0 = state.pipeline_state\n",
    "\n",
    "    #Current pipeline state, step 1\n",
    "    data = self.pipeline_step(data0, action)\n",
    "\n",
    "    #Running forward (Velocity)\n",
    "    com_before = data0.data.subtree_com[1]\n",
    "    com_after = data.data.subtree_com[1]\n",
    "    velocity = (com_after - com_before) / self.dt\n",
    "    forward_reward = self._forward_reward_weight * velocity[0] * 2\n",
    "\n",
    "    #Height being healthy\n",
    "    min_z, max_z = self._healthy_z_range\n",
    "    is_healthy = jp.where(data.q[2] < min_z, 0.0, 1.0)\n",
    "    is_healthy = jp.where(data.q[2] > max_z, 0.0, is_healthy)\n",
    "\n",
    "    #Termination condition\n",
    "    if self._terminate_when_unhealthy:\n",
    "      healthy_reward = self._healthy_reward\n",
    "    else:\n",
    "      healthy_reward = self._healthy_reward * is_healthy\n",
    "\n",
    "    #Control quad cost\n",
    "    ctrl_cost = self._ctrl_cost_weight * jp.sum(jp.square(action))\n",
    "\n",
    "    #Feedback from env\n",
    "    obs = self._get_obs(data.data, action)\n",
    "    reward = forward_reward + healthy_reward - ctrl_cost\n",
    "\n",
    "    #Termination State\n",
    "    done = 1.0 - is_healthy if self._terminate_when_unhealthy else 0.0\n",
    "\n",
    "    state.metrics.update(\n",
    "        forward_reward=forward_reward,\n",
    "        reward_linvel=forward_reward,\n",
    "        reward_quadctrl=-ctrl_cost,\n",
    "        reward_alive=healthy_reward,\n",
    "        x_position=com_after[0],\n",
    "        y_position=com_after[1],\n",
    "        distance_from_origin=jp.linalg.norm(com_after),\n",
    "        x_velocity=velocity[0],\n",
    "        y_velocity=velocity[1],\n",
    "    )\n",
    "\n",
    "    return state.replace(\n",
    "        pipeline_state=data, obs=obs, reward=reward, done=done\n",
    "    )\n",
    "\n",
    "  def _get_obs(self, data: mjx.Data, action: jp.ndarray) -> jp.ndarray:\n",
    "    \"\"\"Observes humanoid body position, velocities, and angles.\"\"\"\n",
    "    position = data.qpos\n",
    "    if self._exclude_current_positions_from_observation:\n",
    "      position = position[2:]\n",
    "\n",
    "    # external_contact_forces are excluded\n",
    "    # environment observation described later\n",
    "    return jp.concatenate([\n",
    "        position,\n",
    "        data.qvel,\n",
    "        data.cinert[1:].ravel(),\n",
    "        data.cvel[1:].ravel(),\n",
    "        data.qfrc_actuator,\n",
    "    ])\n",
    "\n",
    "# Registering the environment setup in env as humanoid_mjx\n",
    "envs.register_environment('humanoid_mjx', Humanoid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4a329a2b-7830-4977-a063-359c93bf662f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "env_name = 'humanoid_mjx'\n",
    "env = envs.get_environment(env_name)"
=======
    "class Rodent(MjxEnv):\n",
    "    \n",
    "    # Might want to change the terminate_when_unhealthy params to enables\n",
    "    # longer episode length, since the average episode length is too short (1 timestep)\n",
    "    # temp change the `terminate_when_unhealthy` to extend the episode length.\n",
    "    def __init__(\n",
    "            self,\n",
    "            forward_reward_weight=5,\n",
    "            ctrl_cost_weight=0.1,\n",
    "            healthy_reward=0.5,\n",
    "            terminate_when_unhealthy=False,\n",
    "            healthy_z_range=(0.2, 1.0),\n",
    "            reset_noise_scale=1e-2,\n",
    "            exclude_current_positions_from_observation=False,\n",
    "            **kwargs,\n",
    "    ):\n",
    "        params = load_params(\"params/params.yaml\")\n",
    "        mj_model = mujoco.MjModel.from_xml_path(params[\"XML_PATH\"])\n",
    "        mj_model.opt.solver = mujoco.mjtSolver.mjSOL_CG\n",
    "        mj_model.opt.iterations = 6\n",
    "        mj_model.opt.ls_iterations = 6\n",
    "\n",
    "        physics_steps_per_control_step = 5\n",
    "        kwargs['n_frames'] = kwargs.get(\n",
    "            'n_frames', physics_steps_per_control_step)\n",
    "\n",
    "        super().__init__(model=mj_model, **kwargs)\n",
    "\n",
    "        self._forward_reward_weight = forward_reward_weight\n",
    "        self._ctrl_cost_weight = ctrl_cost_weight\n",
    "        self._healthy_reward = healthy_reward\n",
    "        self._terminate_when_unhealthy = terminate_when_unhealthy\n",
    "        self._healthy_z_range = healthy_z_range\n",
    "        self._reset_noise_scale = reset_noise_scale\n",
    "        self._exclude_current_positions_from_observation = (\n",
    "            exclude_current_positions_from_observation\n",
    "        )\n",
    "        self.model=mj_model\n",
    "\n",
    "    def reset(self, rng: jp.ndarray) -> State:\n",
    "        \"\"\"Resets the environment to an initial state.\"\"\"\n",
    "        rng, rng1, rng2 = jax.random.split(rng, 3)\n",
    "\n",
    "        low, hi = -self._reset_noise_scale, self._reset_noise_scale\n",
    "        qpos = self.sys.qpos0 + jax.random.uniform(\n",
    "            rng1, (self.sys.nq,), minval=low, maxval=hi\n",
    "        )\n",
    "        qvel = jax.random.uniform(\n",
    "            rng2, (self.sys.nv,), minval=low, maxval=hi\n",
    "        )\n",
    "\n",
    "        data = self.pipeline_init(qpos, qvel)\n",
    "\n",
    "        obs = self._get_obs(data.data, jp.zeros(self.sys.nu))\n",
    "        reward, done, zero = jp.zeros(3)\n",
    "        metrics = {\n",
    "            'forward_reward': zero,\n",
    "            'reward_linvel': zero,\n",
    "            'reward_quadctrl': zero,\n",
    "            'reward_alive': zero,\n",
    "            'x_position': zero,\n",
    "            'y_position': zero,\n",
    "            'distance_from_origin': zero,\n",
    "            'x_velocity': zero,\n",
    "            'y_velocity': zero,\n",
    "        }\n",
    "        return State(data, obs, reward, done, metrics)\n",
    "\n",
    "    def step(self, state: State, action: jp.ndarray) -> State:\n",
    "        \"\"\"Runs one timestep of the environment's dynamics.\"\"\"\n",
    "        data0 = state.pipeline_state\n",
    "        data = self.pipeline_step(data0, action)\n",
    "        # based on the timestep simulation, calculate the rewards\n",
    "        com_before = data0.data.subtree_com[1]\n",
    "        com_after = data.data.subtree_com[1]\n",
    "        print(f\"ctrl: {action}\")\n",
    "        print(f\"before: {com_before}, after: {com_after}, dt: {self.dt}\")\n",
    "        velocity = (com_after - com_before) / self.dt\n",
    "        print(f\"Velocity: {velocity}\")\n",
    "        forward_reward = self._forward_reward_weight * velocity[0]\n",
    "        print(f\"forward reward: {forward_reward}\")\n",
    "        min_z, max_z = self._healthy_z_range\n",
    "        is_healthy = jp.where(data.q[2] < min_z, 0.0, 1.0)\n",
    "        is_healthy = jp.where(data.q[2] > max_z, 0.0, is_healthy)\n",
    "        if self._terminate_when_unhealthy:\n",
    "            healthy_reward = self._healthy_reward\n",
    "        else:\n",
    "            healthy_reward = self._healthy_reward * is_healthy\n",
    "\n",
    "        ctrl_cost = self._ctrl_cost_weight * jp.sum(jp.square(action))\n",
    "\n",
    "        obs = self._get_obs(data.data, action)\n",
    "        reward = forward_reward + healthy_reward - ctrl_cost\n",
    "        # terminates when unhealthy\n",
    "        done = 1.0 - is_healthy if self._terminate_when_unhealthy else 0.0\n",
    "        state.metrics.update(\n",
    "            forward_reward=forward_reward,\n",
    "            reward_linvel=forward_reward,\n",
    "            reward_quadctrl=-ctrl_cost,\n",
    "            reward_alive=healthy_reward,\n",
    "            x_position=com_after[0],\n",
    "            y_position=com_after[1],\n",
    "            distance_from_origin=jp.linalg.norm(com_after),\n",
    "            x_velocity=velocity[0],\n",
    "            y_velocity=velocity[1],\n",
    "        )\n",
    "\n",
    "        return state.replace(\n",
    "            pipeline_state=data, obs=obs, reward=reward, done=done\n",
    "        )\n",
    "\n",
    "    def _get_obs(\n",
    "            self, data: mjx.Data, action: jp.ndarray\n",
    "    ) -> jp.ndarray:\n",
    "        \"\"\"Observes humanoid body position, velocities, and angles.\"\"\"\n",
    "        position = data.qpos\n",
    "        if self._exclude_current_positions_from_observation:\n",
    "            position = position[2:]\n",
    "            \n",
    "        # external_contact_forces are excluded\n",
    "        return jp.concatenate([\n",
    "            position,\n",
    "            data.qvel,\n",
    "            data.cinert[1:].ravel(),\n",
    "            data.cvel[1:].ravel(),\n",
    "            data.qfrc_actuator,\n",
    "        ])\n",
    "\n",
    "\n",
    "# ## training loop\n",
    "\n",
    "# In[5]:\n",
    "\n",
    "\n",
    "envs.register_environment('rodent', Rodent)\n",
    "\n",
    "# instantiate the environment\n",
    "env_name = 'rodent'\n",
    "env = envs.get_environment(env_name)\n",
    "\n",
    "# Change config to conservative measure for debug purposes.\n",
    "# change eval func to make test the checkpoints\n",
    "config = {\n",
    "    \"env_name\": env_name,\n",
    "    \"algo_name\": \"ppo\",\n",
    "    \"task_name\": \"run\",\n",
    "    \"num_envs\": 128,\n",
    "    \"num_timesteps\": 10_000,\n",
    "    \"eval_every\": 1000,\n",
    "    \"episode_length\": 500,\n",
    "    \"num_evals\": 1000,\n",
    "    \"batch_size\": 256,\n",
    "    \"learning_rate\": 6e-4,\n",
    "    \"terminate_when_unhealthy\": False,\n",
    "    \"run_platform\": \"local\",\n",
    "}\n",
    "\n",
    "train_fn = functools.partial(\n",
    "    ppo.train, num_timesteps=config[\"num_timesteps\"], num_evals=int(config[\"num_timesteps\"]/config[\"eval_every\"]),\n",
    "    reward_scaling=0.1, episode_length=config[\"episode_length\"], normalize_observations=True, action_repeat=1,\n",
    "    unroll_length=10, num_minibatches=8, num_updates_per_batch=4,\n",
    "    discounting=0.98, learning_rate=config[\"learning_rate\"], entropy_cost=1e-3, num_envs=config[\"num_envs\"],\n",
    "    batch_size=config[\"batch_size\"], seed=0)\n"
>>>>>>> e9d0044a3e8882228286440c2169d3e215f2fbb4
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92d52112-95fc-49b1-97ee-60829cf172c0",
   "metadata": {},
   "source": [
    "## Load the Checkpoint"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 8,
   "id": "e5750041-5301-4e6a-9325-55fa0af5210c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from brax.training.agents.ppo import networks as brax_networks\n",
    "\n",
    "def make_inference_fn(observation_size: int, \n",
    "                      action_size: int, \n",
    "                      normalize_observations: bool = False, \n",
    "                      network_factory_kwargs: Optional[Dict[str, Any]] = None):\n",
    "    \n",
    "    normalize = lambda x, y: x\n",
    "    \n",
    "    ppo_network = brax_networks.make_ppo_networks(\n",
    "        observation_size,\n",
    "        action_size,\n",
    "        preprocess_observations_fn=normalize,\n",
    "        **(network_factory_kwargs or {})\n",
    "        )\n",
    "    \n",
    "    make_policy = brax_networks.make_inference_fn(ppo_network)\n",
    "    \n",
    "    return make_policy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "528c6c8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "make_policy = make_inference_fn(observation_size=env.observation_size, action_size=env.action_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4d790f09-52a8-4cd0-8afc-3cc57d3918da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_path = \"./model_checkpoints/11520\"\n",
    "params = model.load_params(model_path)"
=======
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from brax.training.acme import running_statistics\n",
    "from brax.training.acme import specs\n",
    "\n",
    "from jax import numpy as jnp\n",
    "\n",
    "normalize = running_statistics.normalize\n",
    "ppo_network = ppo_networks.make_ppo_networks(\n",
    "      env.observation_size,\n",
    "      env.action_size,\n",
    "      preprocess_observations_fn=normalize)\n",
    "make_policy = ppo_networks.make_inference_fn(ppo_network)\n",
    "\n",
    "policy = make_policy((running_statistics.init_state(\n",
    "          specs.Array(env.observation_size, jnp.dtype('float32'))), ppo_network.policy_network.init(jax.random.PRNGKey(0))))"
>>>>>>> e9d0044a3e8882228286440c2169d3e215f2fbb4
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4b353a-7b58-416f-903e-bf9bbc8c12ec",
   "metadata": {},
   "source": [
    "## Render the Clip"
   ]
  },
  {
   "cell_type": "code",
<<<<<<< HEAD
   "execution_count": 11,
   "id": "9a39db86-dc57-41ce-89ce-3b92774d304e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  7%|▋         | 17/250 [00:40<09:15,  2.38s/it] \n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Program 'ffmpeg' is not found; perhaps install ffmpeg using 'apt install ffmpeg'.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[11], line 26\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m state\u001b[38;5;241m.\u001b[39mdone:\n\u001b[1;32m     24\u001b[0m         \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[0;32m---> 26\u001b[0m \u001b[43mmedia\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mshow_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrender\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrollout\u001b[49m\u001b[43m[\u001b[49m\u001b[43m:\u001b[49m\u001b[43m:\u001b[49m\u001b[43mrender_every\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcamera\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mside\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdt\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m/\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mrender_every\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/salk/rodent/Brax-Rodent-Run/.venv/lib/python3.10/site-packages/mediapy/__init__.py:1858\u001b[0m, in \u001b[0;36mshow_video\u001b[0;34m(images, title, **kwargs)\u001b[0m\n\u001b[1;32m   1835\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mshow_video\u001b[39m(\n\u001b[1;32m   1836\u001b[0m     images: Iterable[_NDArray], \u001b[38;5;241m*\u001b[39m, title: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any\n\u001b[1;32m   1837\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m   1838\u001b[0m \u001b[38;5;250m  \u001b[39m\u001b[38;5;124;03m\"\"\"Displays a video in the IPython notebook and optionally saves it to a file.\u001b[39;00m\n\u001b[1;32m   1839\u001b[0m \n\u001b[1;32m   1840\u001b[0m \u001b[38;5;124;03m  See `show_videos`.\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1856\u001b[0m \u001b[38;5;124;03m    html string if `return_html` is `True`.\u001b[39;00m\n\u001b[1;32m   1857\u001b[0m \u001b[38;5;124;03m  \"\"\"\u001b[39;00m\n\u001b[0;32m-> 1858\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mshow_videos\u001b[49m\u001b[43m(\u001b[49m\u001b[43m[\u001b[49m\u001b[43mimages\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mtitle\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/salk/rodent/Brax-Rodent-Run/.venv/lib/python3.10/site-packages/mediapy/__init__.py:1940\u001b[0m, in \u001b[0;36mshow_videos\u001b[0;34m(videos, titles, width, height, downsample, columns, fps, bps, qp, codec, ylabel, html_class, return_html, **kwargs)\u001b[0m\n\u001b[1;32m   1938\u001b[0m   video \u001b[38;5;241m=\u001b[39m [resize_image(image, (h, w)) \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m video]\n\u001b[1;32m   1939\u001b[0m   first_image \u001b[38;5;241m=\u001b[39m video[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m-> 1940\u001b[0m data \u001b[38;5;241m=\u001b[39m \u001b[43mcompress_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1941\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvideo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbps\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mqp\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mqp\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcodec\u001b[49m\n\u001b[1;32m   1942\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1943\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m title \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m _config\u001b[38;5;241m.\u001b[39mshow_save_dir:\n\u001b[1;32m   1944\u001b[0m   suffix \u001b[38;5;241m=\u001b[39m _filename_suffix_from_codec(codec)\n",
      "File \u001b[0;32m~/Desktop/salk/rodent/Brax-Rodent-Run/.venv/lib/python3.10/site-packages/mediapy/__init__.py:1777\u001b[0m, in \u001b[0;36mcompress_video\u001b[0;34m(images, codec, **kwargs)\u001b[0m\n\u001b[1;32m   1775\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m tempfile\u001b[38;5;241m.\u001b[39mTemporaryDirectory() \u001b[38;5;28;01mas\u001b[39;00m directory_name:\n\u001b[1;32m   1776\u001b[0m   tmp_path \u001b[38;5;241m=\u001b[39m pathlib\u001b[38;5;241m.\u001b[39mPath(directory_name) \u001b[38;5;241m/\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfile\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuffix\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m-> 1777\u001b[0m   \u001b[43mwrite_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtmp_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcodec\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcodec\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1778\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m tmp_path\u001b[38;5;241m.\u001b[39mread_bytes()\n",
      "File \u001b[0;32m~/Desktop/salk/rodent/Brax-Rodent-Run/.venv/lib/python3.10/site-packages/mediapy/__init__.py:1747\u001b[0m, in \u001b[0;36mwrite_video\u001b[0;34m(path, images, **kwargs)\u001b[0m\n\u001b[1;32m   1745\u001b[0m   dtype \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdtype(np\u001b[38;5;241m.\u001b[39muint16)\n\u001b[1;32m   1746\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m {\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mgetattr\u001b[39m(images, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m), \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m-> 1747\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m VideoWriter(path, shape\u001b[38;5;241m=\u001b[39mshape, dtype\u001b[38;5;241m=\u001b[39mdtype, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;28;01mas\u001b[39;00m writer:\n\u001b[1;32m   1748\u001b[0m   \u001b[38;5;28;01mfor\u001b[39;00m image \u001b[38;5;129;01min\u001b[39;00m images:\n\u001b[1;32m   1749\u001b[0m     writer\u001b[38;5;241m.\u001b[39madd_image(image)\n",
      "File \u001b[0;32m~/Desktop/salk/rodent/Brax-Rodent-Run/.venv/lib/python3.10/site-packages/mediapy/__init__.py:1567\u001b[0m, in \u001b[0;36mVideoWriter.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1566\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__enter__\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mVideoWriter\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m-> 1567\u001b[0m   ffmpeg_path \u001b[38;5;241m=\u001b[39m \u001b[43m_get_ffmpeg_path\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1568\u001b[0m   input_pix_fmt \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_pix_fmt(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_format)\n\u001b[1;32m   1569\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/Desktop/salk/rodent/Brax-Rodent-Run/.venv/lib/python3.10/site-packages/mediapy/__init__.py:1167\u001b[0m, in \u001b[0;36m_get_ffmpeg_path\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1165\u001b[0m path \u001b[38;5;241m=\u001b[39m _search_for_ffmpeg_path()\n\u001b[1;32m   1166\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m path:\n\u001b[0;32m-> 1167\u001b[0m   \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m   1168\u001b[0m       \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mProgram \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m_config\u001b[38;5;241m.\u001b[39mffmpeg_name_or_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m is not found;\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1169\u001b[0m       \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m perhaps install ffmpeg using \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapt install ffmpeg\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1170\u001b[0m   )\n\u001b[1;32m   1171\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m path\n",
      "\u001b[0;31mRuntimeError\u001b[0m: Program 'ffmpeg' is not found; perhaps install ffmpeg using 'apt install ffmpeg'."
     ]
=======
   "execution_count": 3,
   "id": "9a39db86-dc57-41ce-89ce-3b92774d304e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ctrl: [-0.6370708  -0.3482559   0.10377432  0.55797046  0.79056996  0.29568014\n",
      " -0.31648472 -0.15698154  0.50336546 -0.43145445 -0.2229965  -0.01717176\n",
      "  0.5612398   0.06434826  0.19633472 -0.04198172 -0.69958824 -0.9620247\n",
      " -0.18112917 -0.29634222  0.18516451 -0.14323595 -0.03801239 -0.9238169\n",
      " -0.21924546 -0.32650632 -0.7392438  -0.42401308 -0.63045025  0.8308515 ]\n",
      "before: [ 0.00519511 -0.009522    0.06621409], after: [ 0.00523799 -0.0095851   0.06576587], dt: 0.010000000707805157\n",
      "Velocity: [ 0.0042879  -0.00631008 -0.04482194]\n",
      "forward reward: 0.021439509466290474\n",
      "ctrl: [ 0.02897984 -0.876971    0.4768817   0.00411633  0.08936576 -0.57039016\n",
      " -0.19994807 -0.745237    0.47518378 -0.6305245  -0.1275613   0.5274634\n",
      "  0.25489166 -0.9055261   0.44542506  0.3553282  -0.95515573  0.56783026\n",
      " -0.47847816  0.6754393  -0.78877074 -0.6533349  -0.19162056  0.47283491\n",
      " -0.02315265  0.39470723  0.7062775   0.9328591   0.22889231  0.22771196]\n",
      "before: [ 0.00523799 -0.0095851   0.06576587], after: [ 0.0050302  -0.00980194  0.06456375], dt: 0.010000000707805157\n",
      "Velocity: [-0.02077902 -0.0216838  -0.12021213]\n",
      "forward reward: -0.10389507561922073\n",
      "ctrl: [ 0.8579471   0.864429   -0.28908628 -0.413521   -0.02990075 -0.13060638\n",
      " -0.79477     0.8334704  -0.42729494  0.43701732 -0.26536074  0.69721955\n",
      " -0.23991498 -0.18992916  0.14223516 -0.33979675 -0.12384786  0.21220939\n",
      " -0.07636748 -0.7702617   0.30733     0.02303283  0.4508191  -0.19077979\n",
      " -0.5994512   0.49178848  0.6340972   0.6614851  -0.2449374  -0.22783186]\n",
      "before: [ 0.0050302  -0.00980194  0.06456375], after: [ 0.00450547 -0.01019727  0.06312232], dt: 0.010000000707805157\n",
      "Velocity: [-0.05247332 -0.03953343 -0.14414339]\n",
      "forward reward: -0.2623665928840637\n",
      "ctrl: [ 0.49929795  0.6747804  -0.7084918  -0.3903875  -0.60719883  0.09064007\n",
      "  0.34567395  0.92359716 -0.38948947  0.04371779 -0.70261216  0.00273032\n",
      "  0.23843704  0.44759032 -0.40016374 -0.613658    0.03743214  0.5479131\n",
      "  0.04789528 -0.7233359  -0.6900599  -0.0346294  -0.49962756 -0.5223275\n",
      " -0.7750715   0.1726057   0.53778607  0.12193771 -0.02979057  0.42138097]\n",
      "before: [ 0.00450547 -0.01019727  0.06312232], after: [ 0.00382768 -0.01043641  0.06193607], dt: 0.010000000707805157\n",
      "Velocity: [-0.06777897 -0.02391329 -0.11862441]\n",
      "forward reward: -0.33889487385749817\n",
      "ctrl: [-0.9537947  -0.09827383 -0.6357673  -0.6713288   0.32462442 -0.32333168\n",
      " -0.02411141  0.14833656  0.5894463  -0.9254224  -0.63312614  0.63707936\n",
      "  0.00399375  0.31960028 -0.6290321   0.2282545  -0.2998148  -0.4157726\n",
      " -0.12076072  0.06603312  0.4643408  -0.41260567  0.36153874  0.50167936\n",
      "  0.4923044   0.36774257 -0.83294475 -0.19698085 -0.14067096 -0.6479655 ]\n",
      "before: [ 0.00382768 -0.01043641  0.06193607], after: [ 0.00314959 -0.01040738  0.0607685 ], dt: 0.010000000707805157\n",
      "Velocity: [-0.06780826  0.00290247 -0.11675692]\n",
      "forward reward: -0.3390413224697113\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table class=\"show_videos\" style=\"border-spacing:0px;\"><tr><td style=\"padding:1px;\"><video controls width=\"320\" height=\"240\" style=\"object-fit:cover;\" loop autoplay muted>\n",
       "      <source src=\"data:video/mp4;base64,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\" type=\"video/mp4\"/>\n",
       "      This browser does not support the video tag.\n",
       "      </video></td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
>>>>>>> e9d0044a3e8882228286440c2169d3e215f2fbb4
    }
   ],
   "source": [
    "# define the jit reset/step functions\n",
    "jit_reset = jax.jit(env.reset)\n",
    "jit_step = jax.jit(env.step)\n",
<<<<<<< HEAD
    "jit_inference_fn = jax.jit(make_policy(params, deterministic=False))\n",
    "\n",
    "# initialize the state\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = jit_reset(rng)\n",
    "rollout = [state.pipeline_state]\n",
    "\n",
    "# grab a trajectory\n",
    "n_steps = 250\n",
    "render_every = 1\n",
    "\n",
    "# might becasue brax does not clip the action to the xml limit in the model\n",
    "for i in tqdm(range(n_steps)):\n",
    "    act_rng, rng = jax.random.split(rng)\n",
    "    ctrl, _ = jit_inference_fn(state.obs, act_rng)\n",
    "\n",
    "    state = jit_step(state, ctrl)\n",
    "    rollout.append(state.pipeline_state)\n",
    "\n",
    "    if state.done:\n",
    "        break\n",
    "\n",
    "media.show_video(env.render(rollout[::render_every], camera='side'), fps=1.0 / env.dt / render_every)\n"
   ]
=======
    "\n",
    "# initialize the state\n",
    "rng = jax.random.PRNGKey(0)\n",
    "state = env.reset(rng)\n",
    "rollout = [state.pipeline_state]\n",
    "\n",
    "# grab a trajectory\n",
    "n_steps = 5\n",
    "render_every = 1\n",
    "\n",
    "jit_policy = jax.jit(policy)\n",
    "# might becasue brax does not clip the action to the xml limit in the model\n",
    "for i in range(n_steps):\n",
    "  act_rng, rng = jax.random.split(rng)\n",
    "  ctrl, _ = jit_policy(state.obs, act_rng)\n",
    "  state = env.step(state, ctrl)\n",
    "  rollout.append(state.pipeline_state)\n",
    "\n",
    "  if state.done:\n",
    "    break\n",
    "\n",
    "media.show_video(env.render(rollout[::render_every], camera='side'), fps=1.0 / env.dt / render_every)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b65a7d48-087a-468f-91ce-c8a7865ec632",
   "metadata": {},
   "outputs": [],
   "source": []
>>>>>>> e9d0044a3e8882228286440c2169d3e215f2fbb4
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
<<<<<<< HEAD
   "version": "3.10.9"
=======
   "version": "3.11.5"
>>>>>>> e9d0044a3e8882228286440c2169d3e215f2fbb4
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
